/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_frequency_pen', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=False, train_type='l2p', eval_task_id=False, frequency_penalization=True, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=False, prompts_per_task=4, prompts_per_class=1, freeze_keys=False)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 207410
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 1 day, 14:59:04  Lr: 0.001875  Loss: 2.2273  Acc@1: 25.0000 (25.0000)  Acc@5: 75.0000 (75.0000)  time: 30.6496  data: 0.3093  max mem: 2497
Train: Epoch[1/5]  [  10/4579]  eta: 3:56:18  Lr: 0.001875  Loss: 2.1184  Acc@1: 18.7500 (15.9091)  Acc@5: 56.2500 (56.2500)  time: 3.1032  data: 0.0289  max mem: 2500
Train: Epoch[1/5]  [  20/4579]  eta: 2:16:04  Lr: 0.001875  Loss: 2.3578  Acc@1: 12.5000 (16.3690)  Acc@5: 56.2500 (59.5238)  time: 0.3479  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [  30/4579]  eta: 1:40:31  Lr: 0.001875  Loss: 1.8557  Acc@1: 12.5000 (18.3468)  Acc@5: 62.5000 (61.2903)  time: 0.3482  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [  40/4579]  eta: 1:22:15  Lr: 0.001875  Loss: 1.9211  Acc@1: 18.7500 (19.3598)  Acc@5: 68.7500 (64.1768)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [  50/4579]  eta: 1:11:08  Lr: 0.001875  Loss: 1.7980  Acc@1: 18.7500 (20.3431)  Acc@5: 68.7500 (63.9706)  time: 0.3483  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [  60/4579]  eta: 1:03:40  Lr: 0.001875  Loss: 2.0002  Acc@1: 25.0000 (22.2336)  Acc@5: 68.7500 (65.3689)  time: 0.3495  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [  70/4579]  eta: 0:58:14  Lr: 0.001875  Loss: 1.8459  Acc@1: 25.0000 (22.3592)  Acc@5: 68.7500 (66.3732)  time: 0.3482  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [  80/4579]  eta: 0:54:09  Lr: 0.001875  Loss: 1.6593  Acc@1: 25.0000 (22.9938)  Acc@5: 75.0000 (67.9012)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  90/4579]  eta: 0:50:57  Lr: 0.001875  Loss: 1.7135  Acc@1: 25.0000 (23.6951)  Acc@5: 81.2500 (68.7500)  time: 0.3474  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 100/4579]  eta: 0:48:21  Lr: 0.001875  Loss: 1.8031  Acc@1: 31.2500 (24.2574)  Acc@5: 75.0000 (69.3069)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 110/4579]  eta: 0:46:17  Lr: 0.001875  Loss: 1.5636  Acc@1: 31.2500 (25.2252)  Acc@5: 75.0000 (70.3266)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 120/4579]  eta: 0:44:32  Lr: 0.001875  Loss: 1.5686  Acc@1: 31.2500 (25.2583)  Acc@5: 81.2500 (70.7645)  time: 0.3539  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 130/4579]  eta: 0:43:02  Lr: 0.001875  Loss: 1.4694  Acc@1: 31.2500 (25.7156)  Acc@5: 68.7500 (70.9447)  time: 0.3523  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 140/4579]  eta: 0:41:45  Lr: 0.001875  Loss: 1.6951  Acc@1: 25.0000 (25.8865)  Acc@5: 75.0000 (71.5426)  time: 0.3530  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 150/4579]  eta: 0:40:35  Lr: 0.001875  Loss: 1.1696  Acc@1: 31.2500 (26.2831)  Acc@5: 81.2500 (72.3924)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 160/4579]  eta: 0:39:34  Lr: 0.001875  Loss: 1.3938  Acc@1: 37.5000 (26.9410)  Acc@5: 81.2500 (72.8649)  time: 0.3470  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 170/4579]  eta: 0:38:40  Lr: 0.001875  Loss: 1.6021  Acc@1: 37.5000 (27.4854)  Acc@5: 75.0000 (73.2456)  time: 0.3475  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 180/4579]  eta: 0:37:52  Lr: 0.001875  Loss: 1.4339  Acc@1: 31.2500 (28.1077)  Acc@5: 81.2500 (73.6533)  time: 0.3490  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [ 190/4579]  eta: 0:37:08  Lr: 0.001875  Loss: 1.2949  Acc@1: 37.5000 (28.6976)  Acc@5: 81.2500 (74.2801)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 200/4579]  eta: 0:36:28  Lr: 0.001875  Loss: 1.4493  Acc@1: 37.5000 (28.9801)  Acc@5: 81.2500 (74.3781)  time: 0.3491  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 210/4579]  eta: 0:35:52  Lr: 0.001875  Loss: 1.3391  Acc@1: 37.5000 (29.1173)  Acc@5: 81.2500 (74.5853)  time: 0.3490  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 220/4579]  eta: 0:35:18  Lr: 0.001875  Loss: 1.1946  Acc@1: 37.5000 (29.3552)  Acc@5: 81.2500 (74.8303)  time: 0.3470  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 230/4579]  eta: 0:34:48  Lr: 0.001875  Loss: 1.1583  Acc@1: 31.2500 (29.5184)  Acc@5: 81.2500 (75.0541)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 240/4579]  eta: 0:34:19  Lr: 0.001875  Loss: 1.4184  Acc@1: 31.2500 (29.8496)  Acc@5: 75.0000 (75.0519)  time: 0.3497  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 250/4579]  eta: 0:33:53  Lr: 0.001875  Loss: 1.2646  Acc@1: 31.2500 (29.9801)  Acc@5: 75.0000 (75.2241)  time: 0.3492  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 260/4579]  eta: 0:33:29  Lr: 0.001875  Loss: 1.1917  Acc@1: 31.2500 (30.2203)  Acc@5: 81.2500 (75.5747)  time: 0.3505  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 270/4579]  eta: 0:33:05  Lr: 0.001875  Loss: 0.9458  Acc@1: 31.2500 (30.4428)  Acc@5: 81.2500 (75.7380)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 280/4579]  eta: 0:32:43  Lr: 0.001875  Loss: 1.0463  Acc@1: 37.5000 (30.7829)  Acc@5: 81.2500 (75.8007)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 290/4579]  eta: 0:32:22  Lr: 0.001875  Loss: 1.1229  Acc@1: 37.5000 (31.0997)  Acc@5: 81.2500 (76.0954)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 300/4579]  eta: 0:32:02  Lr: 0.001875  Loss: 0.9346  Acc@1: 31.2500 (31.2292)  Acc@5: 87.5000 (76.3497)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 310/4579]  eta: 0:31:44  Lr: 0.001875  Loss: 1.1432  Acc@1: 37.5000 (31.6921)  Acc@5: 87.5000 (76.6278)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 320/4579]  eta: 0:31:26  Lr: 0.001875  Loss: 0.7401  Acc@1: 43.7500 (31.8536)  Acc@5: 81.2500 (76.9665)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 330/4579]  eta: 0:31:09  Lr: 0.001875  Loss: 0.6694  Acc@1: 37.5000 (32.1563)  Acc@5: 81.2500 (77.0770)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 340/4579]  eta: 0:30:54  Lr: 0.001875  Loss: 0.8877  Acc@1: 37.5000 (32.3497)  Acc@5: 87.5000 (77.3827)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 350/4579]  eta: 0:30:39  Lr: 0.001875  Loss: 0.3979  Acc@1: 37.5000 (32.4964)  Acc@5: 87.5000 (77.5641)  time: 0.3534  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 360/4579]  eta: 0:30:26  Lr: 0.001875  Loss: 1.2025  Acc@1: 43.7500 (32.8255)  Acc@5: 87.5000 (77.8047)  time: 0.3554  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [ 370/4579]  eta: 0:30:12  Lr: 0.001875  Loss: 0.9780  Acc@1: 43.7500 (33.0526)  Acc@5: 87.5000 (77.9650)  time: 0.3539  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 380/4579]  eta: 0:29:58  Lr: 0.001875  Loss: 1.0615  Acc@1: 37.5000 (33.1693)  Acc@5: 81.2500 (78.0348)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 390/4579]  eta: 0:29:45  Lr: 0.001875  Loss: 0.2768  Acc@1: 43.7500 (33.5518)  Acc@5: 81.2500 (78.2928)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 400/4579]  eta: 0:29:33  Lr: 0.001875  Loss: 0.3414  Acc@1: 50.0000 (33.9464)  Acc@5: 87.5000 (78.4289)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 410/4579]  eta: 0:29:21  Lr: 0.001875  Loss: 0.5334  Acc@1: 50.0000 (34.2305)  Acc@5: 81.2500 (78.6040)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 420/4579]  eta: 0:29:09  Lr: 0.001875  Loss: 0.6618  Acc@1: 37.5000 (34.3676)  Acc@5: 87.5000 (78.6966)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 430/4579]  eta: 0:28:58  Lr: 0.001875  Loss: 0.7055  Acc@1: 43.7500 (34.7303)  Acc@5: 87.5000 (78.8718)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 440/4579]  eta: 0:28:46  Lr: 0.001875  Loss: 0.0998  Acc@1: 43.7500 (34.9632)  Acc@5: 87.5000 (79.1525)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 450/4579]  eta: 0:28:36  Lr: 0.001875  Loss: 0.2545  Acc@1: 37.5000 (35.2273)  Acc@5: 87.5000 (79.4207)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 460/4579]  eta: 0:28:25  Lr: 0.001875  Loss: 0.5597  Acc@1: 50.0000 (35.5206)  Acc@5: 87.5000 (79.6367)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 470/4579]  eta: 0:28:15  Lr: 0.001875  Loss: 0.5519  Acc@1: 43.7500 (35.6821)  Acc@5: 87.5000 (79.7903)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 480/4579]  eta: 0:28:05  Lr: 0.001875  Loss: 0.5607  Acc@1: 43.7500 (35.7718)  Acc@5: 87.5000 (79.8727)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 490/4579]  eta: 0:27:56  Lr: 0.001875  Loss: 0.5913  Acc@1: 43.7500 (35.9852)  Acc@5: 81.2500 (79.8625)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 500/4579]  eta: 0:27:46  Lr: 0.001875  Loss: 0.5838  Acc@1: 50.0000 (36.1776)  Acc@5: 87.5000 (80.0150)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 510/4579]  eta: 0:27:37  Lr: 0.001875  Loss: 0.5445  Acc@1: 50.0000 (36.4604)  Acc@5: 87.5000 (80.1003)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 520/4579]  eta: 0:27:28  Lr: 0.001875  Loss: -0.0149  Acc@1: 43.7500 (36.7802)  Acc@5: 87.5000 (80.2303)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 530/4579]  eta: 0:27:20  Lr: 0.001875  Loss: 0.3160  Acc@1: 43.7500 (36.8997)  Acc@5: 87.5000 (80.2848)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 540/4579]  eta: 0:27:11  Lr: 0.001875  Loss: 0.4805  Acc@1: 43.7500 (37.0379)  Acc@5: 87.5000 (80.3720)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 550/4579]  eta: 0:27:03  Lr: 0.001875  Loss: 0.5967  Acc@1: 37.5000 (37.1143)  Acc@5: 87.5000 (80.4560)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 560/4579]  eta: 0:26:55  Lr: 0.001875  Loss: 0.7722  Acc@1: 43.7500 (37.1881)  Acc@5: 87.5000 (80.5370)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 570/4579]  eta: 0:26:47  Lr: 0.001875  Loss: 0.4385  Acc@1: 43.7500 (37.4015)  Acc@5: 87.5000 (80.7027)  time: 0.3495  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 580/4579]  eta: 0:26:40  Lr: 0.001875  Loss: 0.4409  Acc@1: 43.7500 (37.5108)  Acc@5: 87.5000 (80.8627)  time: 0.3508  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 590/4579]  eta: 0:26:33  Lr: 0.001875  Loss: 0.3752  Acc@1: 43.7500 (37.7221)  Acc@5: 87.5000 (80.9856)  time: 0.3514  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 600/4579]  eta: 0:26:25  Lr: 0.001875  Loss: 0.1511  Acc@1: 50.0000 (37.9992)  Acc@5: 87.5000 (81.1252)  time: 0.3503  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 610/4579]  eta: 0:26:18  Lr: 0.001875  Loss: 0.2291  Acc@1: 50.0000 (38.1137)  Acc@5: 87.5000 (81.1170)  time: 0.3496  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 620/4579]  eta: 0:26:11  Lr: 0.001875  Loss: 0.6969  Acc@1: 43.7500 (38.2045)  Acc@5: 87.5000 (81.2399)  time: 0.3515  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 630/4579]  eta: 0:26:05  Lr: 0.001875  Loss: 0.4946  Acc@1: 43.7500 (38.3122)  Acc@5: 87.5000 (81.2896)  time: 0.3528  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 640/4579]  eta: 0:25:58  Lr: 0.001875  Loss: -0.0675  Acc@1: 43.7500 (38.4263)  Acc@5: 87.5000 (81.3768)  time: 0.3506  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 650/4579]  eta: 0:25:51  Lr: 0.001875  Loss: 0.5592  Acc@1: 43.7500 (38.4889)  Acc@5: 87.5000 (81.4228)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 660/4579]  eta: 0:25:45  Lr: 0.001875  Loss: 0.6841  Acc@1: 43.7500 (38.5495)  Acc@5: 81.2500 (81.4675)  time: 0.3511  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [ 670/4579]  eta: 0:25:38  Lr: 0.001875  Loss: 0.5587  Acc@1: 43.7500 (38.7109)  Acc@5: 87.5000 (81.5387)  time: 0.3499  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 680/4579]  eta: 0:25:32  Lr: 0.001875  Loss: 0.5453  Acc@1: 50.0000 (38.8583)  Acc@5: 87.5000 (81.6630)  time: 0.3500  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 690/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 0.3388  Acc@1: 50.0000 (39.0014)  Acc@5: 87.5000 (81.8017)  time: 0.3517  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 700/4579]  eta: 0:25:19  Lr: 0.001875  Loss: 0.3531  Acc@1: 50.0000 (39.1049)  Acc@5: 87.5000 (81.9009)  time: 0.3531  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 710/4579]  eta: 0:25:13  Lr: 0.001875  Loss: 0.2286  Acc@1: 43.7500 (39.1350)  Acc@5: 87.5000 (81.9532)  time: 0.3520  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 720/4579]  eta: 0:25:07  Lr: 0.001875  Loss: 0.4853  Acc@1: 43.7500 (39.2424)  Acc@5: 81.2500 (81.9521)  time: 0.3503  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 730/4579]  eta: 0:25:01  Lr: 0.001875  Loss: 0.2932  Acc@1: 43.7500 (39.2869)  Acc@5: 81.2500 (82.0195)  time: 0.3504  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 740/4579]  eta: 0:24:55  Lr: 0.001875  Loss: 0.2492  Acc@1: 50.0000 (39.5074)  Acc@5: 87.5000 (82.0935)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 750/4579]  eta: 0:24:49  Lr: 0.001875  Loss: 0.5580  Acc@1: 50.0000 (39.6055)  Acc@5: 87.5000 (82.1405)  time: 0.3527  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [ 760/4579]  eta: 0:24:44  Lr: 0.001875  Loss: 0.0155  Acc@1: 43.7500 (39.7175)  Acc@5: 87.5000 (82.2273)  time: 0.3532  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [ 770/4579]  eta: 0:24:38  Lr: 0.001875  Loss: 0.4481  Acc@1: 43.7500 (39.7860)  Acc@5: 87.5000 (82.2471)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 780/4579]  eta: 0:24:32  Lr: 0.001875  Loss: 0.6769  Acc@1: 43.7500 (39.9248)  Acc@5: 87.5000 (82.2743)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 790/4579]  eta: 0:24:27  Lr: 0.001875  Loss: 0.0541  Acc@1: 43.7500 (39.9810)  Acc@5: 87.5000 (82.3325)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 800/4579]  eta: 0:24:21  Lr: 0.001875  Loss: 0.4603  Acc@1: 43.7500 (40.1139)  Acc@5: 87.5000 (82.4282)  time: 0.3518  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 810/4579]  eta: 0:24:16  Lr: 0.001875  Loss: 0.1412  Acc@1: 50.0000 (40.1665)  Acc@5: 87.5000 (82.4985)  time: 0.3515  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 820/4579]  eta: 0:24:10  Lr: 0.001875  Loss: 0.0813  Acc@1: 50.0000 (40.3319)  Acc@5: 87.5000 (82.5289)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 830/4579]  eta: 0:24:05  Lr: 0.001875  Loss: -0.1273  Acc@1: 50.0000 (40.4558)  Acc@5: 87.5000 (82.5812)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 840/4579]  eta: 0:23:59  Lr: 0.001875  Loss: 0.7995  Acc@1: 50.0000 (40.5470)  Acc@5: 87.5000 (82.6471)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 850/4579]  eta: 0:23:54  Lr: 0.001875  Loss: 0.2600  Acc@1: 50.0000 (40.6507)  Acc@5: 87.5000 (82.6601)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 860/4579]  eta: 0:23:48  Lr: 0.001875  Loss: 0.3352  Acc@1: 50.0000 (40.7157)  Acc@5: 87.5000 (82.7091)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 870/4579]  eta: 0:23:43  Lr: 0.001875  Loss: 0.0339  Acc@1: 43.7500 (40.7434)  Acc@5: 87.5000 (82.7282)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 880/4579]  eta: 0:23:38  Lr: 0.001875  Loss: 0.4883  Acc@1: 50.0000 (40.8839)  Acc@5: 87.5000 (82.8036)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 890/4579]  eta: 0:23:33  Lr: 0.001875  Loss: 0.3239  Acc@1: 50.0000 (40.9582)  Acc@5: 87.5000 (82.8634)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 900/4579]  eta: 0:23:27  Lr: 0.001875  Loss: 0.5287  Acc@1: 43.7500 (41.0724)  Acc@5: 87.5000 (82.8801)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 910/4579]  eta: 0:23:22  Lr: 0.001875  Loss: 0.1773  Acc@1: 43.7500 (41.1567)  Acc@5: 87.5000 (82.9446)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 920/4579]  eta: 0:23:17  Lr: 0.001875  Loss: 0.5212  Acc@1: 43.7500 (41.1713)  Acc@5: 87.5000 (82.9737)  time: 0.3519  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 930/4579]  eta: 0:23:12  Lr: 0.001875  Loss: 0.7025  Acc@1: 43.7500 (41.1788)  Acc@5: 87.5000 (83.0626)  time: 0.3531  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 940/4579]  eta: 0:23:07  Lr: 0.001875  Loss: -0.1307  Acc@1: 43.7500 (41.2593)  Acc@5: 93.7500 (83.1296)  time: 0.3555  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 950/4579]  eta: 0:23:03  Lr: 0.001875  Loss: 0.0701  Acc@1: 43.7500 (41.2526)  Acc@5: 87.5000 (83.1427)  time: 0.3543  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 960/4579]  eta: 0:22:58  Lr: 0.001875  Loss: 0.2059  Acc@1: 43.7500 (41.3241)  Acc@5: 81.2500 (83.1881)  time: 0.3512  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 970/4579]  eta: 0:22:53  Lr: 0.001875  Loss: 0.1600  Acc@1: 50.0000 (41.4328)  Acc@5: 87.5000 (83.2132)  time: 0.3509  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 980/4579]  eta: 0:22:48  Lr: 0.001875  Loss: 0.2383  Acc@1: 50.0000 (41.5265)  Acc@5: 87.5000 (83.2569)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 990/4579]  eta: 0:22:43  Lr: 0.001875  Loss: 0.6545  Acc@1: 50.0000 (41.5805)  Acc@5: 87.5000 (83.2934)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1000/4579]  eta: 0:22:38  Lr: 0.001875  Loss: -0.0895  Acc@1: 50.0000 (41.6396)  Acc@5: 87.5000 (83.3479)  time: 0.3520  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1010/4579]  eta: 0:22:33  Lr: 0.001875  Loss: 0.0450  Acc@1: 50.0000 (41.7285)  Acc@5: 87.5000 (83.4013)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1020/4579]  eta: 0:22:28  Lr: 0.001875  Loss: 0.3862  Acc@1: 50.0000 (41.8585)  Acc@5: 87.5000 (83.4537)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1030/4579]  eta: 0:22:24  Lr: 0.001875  Loss: 0.7563  Acc@1: 50.0000 (41.9011)  Acc@5: 87.5000 (83.4627)  time: 0.3501  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1040/4579]  eta: 0:22:19  Lr: 0.001875  Loss: 0.6256  Acc@1: 50.0000 (42.0329)  Acc@5: 87.5000 (83.5195)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1050/4579]  eta: 0:22:14  Lr: 0.001875  Loss: 0.2011  Acc@1: 56.2500 (42.1087)  Acc@5: 87.5000 (83.5573)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1060/4579]  eta: 0:22:09  Lr: 0.001875  Loss: -0.1446  Acc@1: 50.0000 (42.1536)  Acc@5: 87.5000 (83.5945)  time: 0.3488  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1070/4579]  eta: 0:22:05  Lr: 0.001875  Loss: -0.0193  Acc@1: 50.0000 (42.2035)  Acc@5: 87.5000 (83.6426)  time: 0.3483  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1080/4579]  eta: 0:22:00  Lr: 0.001875  Loss: -0.0550  Acc@1: 50.0000 (42.3508)  Acc@5: 93.7500 (83.6957)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1090/4579]  eta: 0:21:55  Lr: 0.001875  Loss: 0.1126  Acc@1: 50.0000 (42.4095)  Acc@5: 87.5000 (83.7477)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1100/4579]  eta: 0:21:51  Lr: 0.001875  Loss: 0.2991  Acc@1: 50.0000 (42.5295)  Acc@5: 93.7500 (83.8045)  time: 0.3518  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1110/4579]  eta: 0:21:46  Lr: 0.001875  Loss: -0.0057  Acc@1: 56.2500 (42.6530)  Acc@5: 93.7500 (83.8378)  time: 0.3516  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1120/4579]  eta: 0:21:41  Lr: 0.001875  Loss: -0.0552  Acc@1: 56.2500 (42.7687)  Acc@5: 93.7500 (83.9095)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1130/4579]  eta: 0:21:37  Lr: 0.001875  Loss: 0.0734  Acc@1: 50.0000 (42.8216)  Acc@5: 87.5000 (83.9578)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1140/4579]  eta: 0:21:32  Lr: 0.001875  Loss: -0.1498  Acc@1: 43.7500 (42.8571)  Acc@5: 87.5000 (83.9998)  time: 0.3528  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1150/4579]  eta: 0:21:28  Lr: 0.001875  Loss: 0.0461  Acc@1: 50.0000 (42.9518)  Acc@5: 87.5000 (84.0139)  time: 0.3519  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1160/4579]  eta: 0:21:23  Lr: 0.001875  Loss: -0.2913  Acc@1: 56.2500 (43.0986)  Acc@5: 87.5000 (84.0708)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1170/4579]  eta: 0:21:19  Lr: 0.001875  Loss: -0.0698  Acc@1: 56.2500 (43.1789)  Acc@5: 87.5000 (84.0895)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1180/4579]  eta: 0:21:14  Lr: 0.001875  Loss: 0.4836  Acc@1: 50.0000 (43.2420)  Acc@5: 87.5000 (84.1448)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1190/4579]  eta: 0:21:10  Lr: 0.001875  Loss: 0.0371  Acc@1: 43.7500 (43.2567)  Acc@5: 87.5000 (84.1415)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1200/4579]  eta: 0:21:05  Lr: 0.001875  Loss: 0.7353  Acc@1: 50.0000 (43.3441)  Acc@5: 87.5000 (84.1694)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1210/4579]  eta: 0:21:01  Lr: 0.001875  Loss: 0.1630  Acc@1: 56.2500 (43.4352)  Acc@5: 87.5000 (84.2382)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1220/4579]  eta: 0:20:56  Lr: 0.001875  Loss: 0.2692  Acc@1: 56.2500 (43.5657)  Acc@5: 93.7500 (84.2905)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1230/4579]  eta: 0:20:52  Lr: 0.001875  Loss: -0.0788  Acc@1: 62.5000 (43.6535)  Acc@5: 93.7500 (84.3572)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1240/4579]  eta: 0:20:47  Lr: 0.001875  Loss: 0.2523  Acc@1: 62.5000 (43.7601)  Acc@5: 93.7500 (84.3926)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1250/4579]  eta: 0:20:43  Lr: 0.001875  Loss: 0.2800  Acc@1: 50.0000 (43.8050)  Acc@5: 87.5000 (84.4275)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1260/4579]  eta: 0:20:39  Lr: 0.001875  Loss: 0.1206  Acc@1: 50.0000 (43.8541)  Acc@5: 87.5000 (84.4518)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1270/4579]  eta: 0:20:34  Lr: 0.001875  Loss: 0.1311  Acc@1: 50.0000 (43.9418)  Acc@5: 87.5000 (84.4856)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1280/4579]  eta: 0:20:30  Lr: 0.001875  Loss: 0.0633  Acc@1: 56.2500 (44.0232)  Acc@5: 87.5000 (84.5189)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1290/4579]  eta: 0:20:25  Lr: 0.001875  Loss: -0.2024  Acc@1: 56.2500 (44.1082)  Acc@5: 87.5000 (84.5517)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1300/4579]  eta: 0:20:21  Lr: 0.001875  Loss: -0.2899  Acc@1: 50.0000 (44.1055)  Acc@5: 93.7500 (84.5984)  time: 0.3499  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1310/4579]  eta: 0:20:17  Lr: 0.001875  Loss: -0.1688  Acc@1: 50.0000 (44.2029)  Acc@5: 87.5000 (84.6158)  time: 0.3501  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1320/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.0609  Acc@1: 50.0000 (44.2657)  Acc@5: 87.5000 (84.6612)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1330/4579]  eta: 0:20:08  Lr: 0.001875  Loss: -0.5809  Acc@1: 50.0000 (44.3464)  Acc@5: 93.7500 (84.7201)  time: 0.3495  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1340/4579]  eta: 0:20:04  Lr: 0.001875  Loss: 0.2472  Acc@1: 50.0000 (44.4165)  Acc@5: 93.7500 (84.7735)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1350/4579]  eta: 0:20:00  Lr: 0.001875  Loss: -0.0192  Acc@1: 50.0000 (44.4393)  Acc@5: 87.5000 (84.7798)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1360/4579]  eta: 0:19:55  Lr: 0.001875  Loss: 0.3549  Acc@1: 50.0000 (44.5031)  Acc@5: 87.5000 (84.8044)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1370/4579]  eta: 0:19:51  Lr: 0.001875  Loss: -0.2043  Acc@1: 50.0000 (44.5660)  Acc@5: 87.5000 (84.8468)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1380/4579]  eta: 0:19:47  Lr: 0.001875  Loss: -0.2772  Acc@1: 50.0000 (44.6235)  Acc@5: 93.7500 (84.8796)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1390/4579]  eta: 0:19:43  Lr: 0.001875  Loss: 0.2757  Acc@1: 50.0000 (44.6576)  Acc@5: 87.5000 (84.9164)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1400/4579]  eta: 0:19:38  Lr: 0.001875  Loss: 0.0608  Acc@1: 50.0000 (44.7002)  Acc@5: 93.7500 (84.9661)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1410/4579]  eta: 0:19:34  Lr: 0.001875  Loss: -0.2787  Acc@1: 50.0000 (44.7422)  Acc@5: 87.5000 (84.9575)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1420/4579]  eta: 0:19:30  Lr: 0.001875  Loss: 0.2537  Acc@1: 50.0000 (44.8232)  Acc@5: 87.5000 (84.9842)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1430/4579]  eta: 0:19:26  Lr: 0.001875  Loss: 0.1777  Acc@1: 50.0000 (44.8856)  Acc@5: 87.5000 (84.9930)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1440/4579]  eta: 0:19:21  Lr: 0.001875  Loss: -0.1384  Acc@1: 56.2500 (44.9688)  Acc@5: 87.5000 (85.0191)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1450/4579]  eta: 0:19:17  Lr: 0.001875  Loss: -0.2183  Acc@1: 56.2500 (45.0594)  Acc@5: 87.5000 (85.0103)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1460/4579]  eta: 0:19:13  Lr: 0.001875  Loss: -0.0362  Acc@1: 56.2500 (45.0975)  Acc@5: 81.2500 (85.0017)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1470/4579]  eta: 0:19:09  Lr: 0.001875  Loss: -0.3311  Acc@1: 50.0000 (45.1903)  Acc@5: 87.5000 (85.0527)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1480/4579]  eta: 0:19:04  Lr: 0.001875  Loss: 0.0428  Acc@1: 50.0000 (45.2355)  Acc@5: 87.5000 (85.0439)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1490/4579]  eta: 0:19:00  Lr: 0.001875  Loss: -0.0985  Acc@1: 50.0000 (45.2674)  Acc@5: 87.5000 (85.0771)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1500/4579]  eta: 0:18:56  Lr: 0.001875  Loss: 0.0659  Acc@1: 50.0000 (45.3115)  Acc@5: 87.5000 (85.0849)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1510/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.1279  Acc@1: 56.2500 (45.4128)  Acc@5: 87.5000 (85.1382)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1520/4579]  eta: 0:18:48  Lr: 0.001875  Loss: 0.1248  Acc@1: 56.2500 (45.4635)  Acc@5: 93.7500 (85.1742)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1530/4579]  eta: 0:18:44  Lr: 0.001875  Loss: 0.1162  Acc@1: 50.0000 (45.4809)  Acc@5: 93.7500 (85.1894)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1540/4579]  eta: 0:18:40  Lr: 0.001875  Loss: -0.1936  Acc@1: 50.0000 (45.4940)  Acc@5: 87.5000 (85.1922)  time: 0.3499  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1550/4579]  eta: 0:18:36  Lr: 0.001875  Loss: -0.2297  Acc@1: 56.2500 (45.5674)  Acc@5: 87.5000 (85.2232)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1560/4579]  eta: 0:18:31  Lr: 0.001875  Loss: 0.1935  Acc@1: 56.2500 (45.6799)  Acc@5: 93.7500 (85.2578)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1570/4579]  eta: 0:18:27  Lr: 0.001875  Loss: 0.5349  Acc@1: 50.0000 (45.6875)  Acc@5: 93.7500 (85.2920)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1580/4579]  eta: 0:18:23  Lr: 0.001875  Loss: -0.1661  Acc@1: 50.0000 (45.7424)  Acc@5: 93.7500 (85.3257)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1590/4579]  eta: 0:18:19  Lr: 0.001875  Loss: 0.0667  Acc@1: 50.0000 (45.7613)  Acc@5: 87.5000 (85.3551)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1600/4579]  eta: 0:18:15  Lr: 0.001875  Loss: 0.0593  Acc@1: 56.2500 (45.8542)  Acc@5: 87.5000 (85.3802)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1610/4579]  eta: 0:18:11  Lr: 0.001875  Loss: 0.4559  Acc@1: 62.5000 (45.9381)  Acc@5: 87.5000 (85.3895)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1620/4579]  eta: 0:18:07  Lr: 0.001875  Loss: 0.3298  Acc@1: 56.2500 (45.9863)  Acc@5: 87.5000 (85.4141)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1630/4579]  eta: 0:18:03  Lr: 0.001875  Loss: 0.0336  Acc@1: 56.2500 (46.0492)  Acc@5: 87.5000 (85.4345)  time: 0.3517  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1640/4579]  eta: 0:17:59  Lr: 0.001875  Loss: 0.1295  Acc@1: 56.2500 (46.0885)  Acc@5: 93.7500 (85.4738)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1650/4579]  eta: 0:17:55  Lr: 0.001875  Loss: -0.3679  Acc@1: 50.0000 (46.1538)  Acc@5: 93.7500 (85.4936)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1660/4579]  eta: 0:17:51  Lr: 0.001875  Loss: 0.3650  Acc@1: 56.2500 (46.1845)  Acc@5: 87.5000 (85.5095)  time: 0.3508  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1670/4579]  eta: 0:17:48  Lr: 0.001875  Loss: -0.3897  Acc@1: 56.2500 (46.2522)  Acc@5: 87.5000 (85.5177)  time: 0.3520  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [1680/4579]  eta: 0:17:44  Lr: 0.001875  Loss: 0.1248  Acc@1: 50.0000 (46.2559)  Acc@5: 87.5000 (85.5146)  time: 0.3519  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1690/4579]  eta: 0:17:40  Lr: 0.001875  Loss: -0.1860  Acc@1: 56.2500 (46.3335)  Acc@5: 87.5000 (85.5226)  time: 0.3513  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1700/4579]  eta: 0:17:36  Lr: 0.001875  Loss: -0.0320  Acc@1: 56.2500 (46.4029)  Acc@5: 87.5000 (85.5342)  time: 0.3522  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [1710/4579]  eta: 0:17:32  Lr: 0.001875  Loss: 0.6757  Acc@1: 50.0000 (46.3983)  Acc@5: 87.5000 (85.5348)  time: 0.3513  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [1720/4579]  eta: 0:17:28  Lr: 0.001875  Loss: -0.3062  Acc@1: 50.0000 (46.4664)  Acc@5: 87.5000 (85.5462)  time: 0.3498  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1730/4579]  eta: 0:17:24  Lr: 0.001875  Loss: 0.1396  Acc@1: 56.2500 (46.5013)  Acc@5: 87.5000 (85.5755)  time: 0.3511  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [1740/4579]  eta: 0:17:20  Lr: 0.001875  Loss: 0.1552  Acc@1: 56.2500 (46.5537)  Acc@5: 87.5000 (85.6081)  time: 0.3509  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [1750/4579]  eta: 0:17:16  Lr: 0.001875  Loss: 0.6311  Acc@1: 56.2500 (46.6305)  Acc@5: 93.7500 (85.6475)  time: 0.3522  data: 0.0038  max mem: 2500
Train: Epoch[1/5]  [1760/4579]  eta: 0:17:12  Lr: 0.001875  Loss: 0.0326  Acc@1: 56.2500 (46.7029)  Acc@5: 93.7500 (85.6687)  time: 0.3532  data: 0.0046  max mem: 2500
Train: Epoch[1/5]  [1770/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.1575  Acc@1: 62.5000 (46.7885)  Acc@5: 93.7500 (85.7002)  time: 0.3514  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1780/4579]  eta: 0:17:04  Lr: 0.001875  Loss: -0.0026  Acc@1: 56.2500 (46.8311)  Acc@5: 93.7500 (85.7278)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1790/4579]  eta: 0:17:01  Lr: 0.001875  Loss: 0.2520  Acc@1: 56.2500 (46.8872)  Acc@5: 87.5000 (85.7377)  time: 0.3518  data: 0.0033  max mem: 2500
Train: Epoch[1/5]  [1800/4579]  eta: 0:16:57  Lr: 0.001875  Loss: 0.1644  Acc@1: 50.0000 (46.9461)  Acc@5: 87.5000 (85.7683)  time: 0.3518  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [1810/4579]  eta: 0:16:53  Lr: 0.001875  Loss: 0.5197  Acc@1: 56.2500 (46.9872)  Acc@5: 87.5000 (85.7779)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1820/4579]  eta: 0:16:49  Lr: 0.001875  Loss: -0.2380  Acc@1: 56.2500 (47.0174)  Acc@5: 87.5000 (85.8114)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1830/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.1200  Acc@1: 56.2500 (47.0679)  Acc@5: 87.5000 (85.8138)  time: 0.3515  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [1840/4579]  eta: 0:16:41  Lr: 0.001875  Loss: 0.3716  Acc@1: 56.2500 (47.1245)  Acc@5: 87.5000 (85.8467)  time: 0.3526  data: 0.0036  max mem: 2500
Train: Epoch[1/5]  [1850/4579]  eta: 0:16:37  Lr: 0.001875  Loss: 0.0971  Acc@1: 56.2500 (47.1873)  Acc@5: 87.5000 (85.8624)  time: 0.3518  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [1860/4579]  eta: 0:16:33  Lr: 0.001875  Loss: 0.2309  Acc@1: 56.2500 (47.2495)  Acc@5: 87.5000 (85.8779)  time: 0.3517  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [1870/4579]  eta: 0:16:30  Lr: 0.001875  Loss: -0.3573  Acc@1: 62.5000 (47.3377)  Acc@5: 93.7500 (85.9033)  time: 0.3598  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [1880/4579]  eta: 0:16:26  Lr: 0.001875  Loss: -0.1744  Acc@1: 56.2500 (47.3585)  Acc@5: 93.7500 (85.9184)  time: 0.3606  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [1890/4579]  eta: 0:16:22  Lr: 0.001875  Loss: -0.2551  Acc@1: 50.0000 (47.4088)  Acc@5: 87.5000 (85.9201)  time: 0.3566  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [1900/4579]  eta: 0:16:18  Lr: 0.001875  Loss: 0.1242  Acc@1: 56.2500 (47.4421)  Acc@5: 87.5000 (85.9219)  time: 0.3590  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [1910/4579]  eta: 0:16:15  Lr: 0.001875  Loss: 0.3654  Acc@1: 56.2500 (47.4523)  Acc@5: 87.5000 (85.9465)  time: 0.3543  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [1920/4579]  eta: 0:16:11  Lr: 0.001875  Loss: 0.0502  Acc@1: 50.0000 (47.4818)  Acc@5: 87.5000 (85.9513)  time: 0.3498  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1930/4579]  eta: 0:16:07  Lr: 0.001875  Loss: -0.1000  Acc@1: 56.2500 (47.5466)  Acc@5: 87.5000 (85.9788)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1940/4579]  eta: 0:16:03  Lr: 0.001875  Loss: 0.1026  Acc@1: 56.2500 (47.6043)  Acc@5: 87.5000 (85.9834)  time: 0.3509  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1950/4579]  eta: 0:15:59  Lr: 0.001875  Loss: 0.0408  Acc@1: 56.2500 (47.6518)  Acc@5: 93.7500 (86.0072)  time: 0.3512  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [1960/4579]  eta: 0:15:55  Lr: 0.001875  Loss: -0.1818  Acc@1: 56.2500 (47.7084)  Acc@5: 87.5000 (86.0212)  time: 0.3502  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1970/4579]  eta: 0:15:51  Lr: 0.001875  Loss: 0.2688  Acc@1: 56.2500 (47.7232)  Acc@5: 87.5000 (86.0350)  time: 0.3503  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1980/4579]  eta: 0:15:48  Lr: 0.001875  Loss: 0.1793  Acc@1: 56.2500 (47.7915)  Acc@5: 87.5000 (86.0582)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1990/4579]  eta: 0:15:44  Lr: 0.001875  Loss: -0.1585  Acc@1: 56.2500 (47.8026)  Acc@5: 87.5000 (86.0717)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2000/4579]  eta: 0:15:40  Lr: 0.001875  Loss: 0.2020  Acc@1: 50.0000 (47.8542)  Acc@5: 87.5000 (86.0976)  time: 0.3504  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2010/4579]  eta: 0:15:36  Lr: 0.001875  Loss: -0.0884  Acc@1: 56.2500 (47.8711)  Acc@5: 93.7500 (86.1108)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2020/4579]  eta: 0:15:32  Lr: 0.001875  Loss: 0.6702  Acc@1: 50.0000 (47.8971)  Acc@5: 87.5000 (86.1022)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2030/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.0117  Acc@1: 56.2500 (47.9567)  Acc@5: 87.5000 (86.1183)  time: 0.3510  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2040/4579]  eta: 0:15:25  Lr: 0.001875  Loss: 0.2777  Acc@1: 56.2500 (47.9881)  Acc@5: 87.5000 (86.1036)  time: 0.3524  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [2050/4579]  eta: 0:15:21  Lr: 0.001875  Loss: -0.1453  Acc@1: 62.5000 (48.0619)  Acc@5: 87.5000 (86.1318)  time: 0.3498  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2060/4579]  eta: 0:15:17  Lr: 0.001875  Loss: 0.3818  Acc@1: 62.5000 (48.1077)  Acc@5: 93.7500 (86.1536)  time: 0.3491  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2070/4579]  eta: 0:15:13  Lr: 0.001875  Loss: -0.4938  Acc@1: 50.0000 (48.1289)  Acc@5: 93.7500 (86.1661)  time: 0.3496  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2080/4579]  eta: 0:15:09  Lr: 0.001875  Loss: 0.3884  Acc@1: 50.0000 (48.1559)  Acc@5: 87.5000 (86.1755)  time: 0.3484  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2090/4579]  eta: 0:15:06  Lr: 0.001875  Loss: 0.2356  Acc@1: 50.0000 (48.1827)  Acc@5: 87.5000 (86.1848)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2100/4579]  eta: 0:15:02  Lr: 0.001875  Loss: 0.5859  Acc@1: 56.2500 (48.2241)  Acc@5: 87.5000 (86.1941)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2110/4579]  eta: 0:14:58  Lr: 0.001875  Loss: 0.3258  Acc@1: 62.5000 (48.2976)  Acc@5: 87.5000 (86.2062)  time: 0.3495  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2120/4579]  eta: 0:14:54  Lr: 0.001875  Loss: 0.0083  Acc@1: 56.2500 (48.3145)  Acc@5: 93.7500 (86.2241)  time: 0.3488  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2130/4579]  eta: 0:14:50  Lr: 0.001875  Loss: 0.0584  Acc@1: 56.2500 (48.3576)  Acc@5: 93.7500 (86.2359)  time: 0.3492  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2140/4579]  eta: 0:14:46  Lr: 0.001875  Loss: 0.3304  Acc@1: 56.2500 (48.3565)  Acc@5: 93.7500 (86.2447)  time: 0.3495  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2150/4579]  eta: 0:14:43  Lr: 0.001875  Loss: -0.0012  Acc@1: 56.2500 (48.4164)  Acc@5: 93.7500 (86.2622)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2160/4579]  eta: 0:14:39  Lr: 0.001875  Loss: 0.2664  Acc@1: 62.5000 (48.4556)  Acc@5: 93.7500 (86.2882)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2170/4579]  eta: 0:14:35  Lr: 0.001875  Loss: -0.1238  Acc@1: 56.2500 (48.4857)  Acc@5: 87.5000 (86.2794)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2180/4579]  eta: 0:14:31  Lr: 0.001875  Loss: 0.0336  Acc@1: 56.2500 (48.5242)  Acc@5: 87.5000 (86.2821)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2190/4579]  eta: 0:14:27  Lr: 0.001875  Loss: -0.2529  Acc@1: 56.2500 (48.5652)  Acc@5: 87.5000 (86.2848)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2200/4579]  eta: 0:14:24  Lr: 0.001875  Loss: -0.3395  Acc@1: 56.2500 (48.6057)  Acc@5: 87.5000 (86.3102)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2210/4579]  eta: 0:14:20  Lr: 0.001875  Loss: 0.1078  Acc@1: 56.2500 (48.6431)  Acc@5: 87.5000 (86.3156)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2220/4579]  eta: 0:14:16  Lr: 0.001875  Loss: 0.1144  Acc@1: 56.2500 (48.6915)  Acc@5: 87.5000 (86.3209)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2230/4579]  eta: 0:14:12  Lr: 0.001875  Loss: -0.3271  Acc@1: 56.2500 (48.7310)  Acc@5: 87.5000 (86.3402)  time: 0.3506  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2240/4579]  eta: 0:14:09  Lr: 0.001875  Loss: -0.0452  Acc@1: 56.2500 (48.7533)  Acc@5: 87.5000 (86.3482)  time: 0.3533  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [2250/4579]  eta: 0:14:05  Lr: 0.001875  Loss: -0.3395  Acc@1: 50.0000 (48.7867)  Acc@5: 87.5000 (86.3755)  time: 0.3517  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2260/4579]  eta: 0:14:01  Lr: 0.001875  Loss: 0.0769  Acc@1: 56.2500 (48.8141)  Acc@5: 93.7500 (86.3915)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2270/4579]  eta: 0:13:57  Lr: 0.001875  Loss: 0.0596  Acc@1: 56.2500 (48.8469)  Acc@5: 87.5000 (86.3992)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2280/4579]  eta: 0:13:54  Lr: 0.001875  Loss: 0.3097  Acc@1: 56.2500 (48.8821)  Acc@5: 87.5000 (86.4040)  time: 0.3522  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2290/4579]  eta: 0:13:50  Lr: 0.001875  Loss: 0.3101  Acc@1: 56.2500 (48.9170)  Acc@5: 87.5000 (86.4060)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2300/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.1622  Acc@1: 56.2500 (48.9325)  Acc@5: 87.5000 (86.4189)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2310/4579]  eta: 0:13:42  Lr: 0.001875  Loss: -0.4140  Acc@1: 56.2500 (48.9615)  Acc@5: 87.5000 (86.4371)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2320/4579]  eta: 0:13:38  Lr: 0.001875  Loss: 0.3791  Acc@1: 56.2500 (48.9794)  Acc@5: 87.5000 (86.4498)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2330/4579]  eta: 0:13:35  Lr: 0.001875  Loss: 0.2262  Acc@1: 56.2500 (49.0053)  Acc@5: 87.5000 (86.4516)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2340/4579]  eta: 0:13:31  Lr: 0.001875  Loss: -0.1211  Acc@1: 56.2500 (49.0576)  Acc@5: 93.7500 (86.4908)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2350/4579]  eta: 0:13:27  Lr: 0.001875  Loss: -0.2298  Acc@1: 62.5000 (49.1041)  Acc@5: 93.7500 (86.5137)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2360/4579]  eta: 0:13:23  Lr: 0.001875  Loss: -0.1657  Acc@1: 62.5000 (49.1423)  Acc@5: 93.7500 (86.5205)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2370/4579]  eta: 0:13:20  Lr: 0.001875  Loss: 0.2628  Acc@1: 62.5000 (49.1828)  Acc@5: 87.5000 (86.5299)  time: 0.3526  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2380/4579]  eta: 0:13:16  Lr: 0.001875  Loss: -0.6030  Acc@1: 56.2500 (49.2151)  Acc@5: 93.7500 (86.5550)  time: 0.3566  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2390/4579]  eta: 0:13:12  Lr: 0.001875  Loss: 0.0191  Acc@1: 56.2500 (49.2289)  Acc@5: 93.7500 (86.5694)  time: 0.3542  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2400/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.5673  Acc@1: 56.2500 (49.2815)  Acc@5: 93.7500 (86.5993)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2410/4579]  eta: 0:13:05  Lr: 0.001875  Loss: -0.0205  Acc@1: 56.2500 (49.2923)  Acc@5: 93.7500 (86.6083)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2420/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.3853  Acc@1: 56.2500 (49.3365)  Acc@5: 87.5000 (86.6223)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2430/4579]  eta: 0:12:57  Lr: 0.001875  Loss: 0.6815  Acc@1: 56.2500 (49.3470)  Acc@5: 87.5000 (86.6336)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2440/4579]  eta: 0:12:53  Lr: 0.001875  Loss: 0.1982  Acc@1: 56.2500 (49.3650)  Acc@5: 87.5000 (86.6397)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2450/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -0.2990  Acc@1: 62.5000 (49.4288)  Acc@5: 93.7500 (86.6789)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2460/4579]  eta: 0:12:46  Lr: 0.001875  Loss: 0.2773  Acc@1: 56.2500 (49.4337)  Acc@5: 93.7500 (86.6822)  time: 0.3531  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2470/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.2845  Acc@1: 56.2500 (49.4587)  Acc@5: 87.5000 (86.6780)  time: 0.3533  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2480/4579]  eta: 0:12:39  Lr: 0.001875  Loss: -0.2421  Acc@1: 56.2500 (49.5037)  Acc@5: 87.5000 (86.6939)  time: 0.3508  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2490/4579]  eta: 0:12:35  Lr: 0.001875  Loss: -0.2961  Acc@1: 62.5000 (49.5634)  Acc@5: 93.7500 (86.7222)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2500/4579]  eta: 0:12:31  Lr: 0.001875  Loss: 0.1904  Acc@1: 62.5000 (49.5952)  Acc@5: 93.7500 (86.7353)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2510/4579]  eta: 0:12:27  Lr: 0.001875  Loss: -0.2105  Acc@1: 62.5000 (49.6366)  Acc@5: 93.7500 (86.7558)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2520/4579]  eta: 0:12:24  Lr: 0.001875  Loss: -0.1937  Acc@1: 62.5000 (49.6975)  Acc@5: 93.7500 (86.7637)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2530/4579]  eta: 0:12:20  Lr: 0.001875  Loss: -0.4368  Acc@1: 62.5000 (49.7605)  Acc@5: 93.7500 (86.7888)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2540/4579]  eta: 0:12:16  Lr: 0.001875  Loss: 0.1938  Acc@1: 62.5000 (49.7934)  Acc@5: 93.7500 (86.8064)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2550/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.2883  Acc@1: 56.2500 (49.8358)  Acc@5: 93.7500 (86.8287)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2560/4579]  eta: 0:12:09  Lr: 0.001875  Loss: 0.5111  Acc@1: 56.2500 (49.8682)  Acc@5: 93.7500 (86.8411)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2570/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.3371  Acc@1: 56.2500 (49.8785)  Acc@5: 93.7500 (86.8558)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2580/4579]  eta: 0:12:01  Lr: 0.001875  Loss: -0.0994  Acc@1: 56.2500 (49.9080)  Acc@5: 87.5000 (86.8656)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2590/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 0.2080  Acc@1: 56.2500 (49.9421)  Acc@5: 87.5000 (86.8535)  time: 0.3507  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2600/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.2145  Acc@1: 56.2500 (49.9567)  Acc@5: 87.5000 (86.8656)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2610/4579]  eta: 0:11:50  Lr: 0.001875  Loss: 0.0368  Acc@1: 56.2500 (49.9689)  Acc@5: 87.5000 (86.8633)  time: 0.3518  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [2620/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.0592  Acc@1: 56.2500 (49.9952)  Acc@5: 87.5000 (86.8729)  time: 0.3561  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [2630/4579]  eta: 0:11:43  Lr: 0.001875  Loss: 0.0711  Acc@1: 50.0000 (49.9976)  Acc@5: 87.5000 (86.8729)  time: 0.3594  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2640/4579]  eta: 0:11:39  Lr: 0.001875  Loss: 0.5295  Acc@1: 56.2500 (50.0379)  Acc@5: 87.5000 (86.8847)  time: 0.3593  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2650/4579]  eta: 0:11:36  Lr: 0.001875  Loss: -0.2485  Acc@1: 56.2500 (50.0542)  Acc@5: 93.7500 (86.9082)  time: 0.3567  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2660/4579]  eta: 0:11:32  Lr: 0.001875  Loss: -0.4783  Acc@1: 56.2500 (50.0799)  Acc@5: 93.7500 (86.9269)  time: 0.3531  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2670/4579]  eta: 0:11:28  Lr: 0.001875  Loss: -0.4434  Acc@1: 50.0000 (50.0959)  Acc@5: 87.5000 (86.9337)  time: 0.3538  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [2680/4579]  eta: 0:11:25  Lr: 0.001875  Loss: -0.3098  Acc@1: 56.2500 (50.1352)  Acc@5: 87.5000 (86.9498)  time: 0.3529  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [2690/4579]  eta: 0:11:21  Lr: 0.001875  Loss: 0.7699  Acc@1: 56.2500 (50.1370)  Acc@5: 87.5000 (86.9496)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2700/4579]  eta: 0:11:17  Lr: 0.001875  Loss: -0.0125  Acc@1: 50.0000 (50.1550)  Acc@5: 87.5000 (86.9493)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2710/4579]  eta: 0:11:14  Lr: 0.001875  Loss: 0.2519  Acc@1: 56.2500 (50.1798)  Acc@5: 81.2500 (86.9467)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2720/4579]  eta: 0:11:10  Lr: 0.001875  Loss: -0.2598  Acc@1: 62.5000 (50.2274)  Acc@5: 87.5000 (86.9602)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2730/4579]  eta: 0:11:06  Lr: 0.001875  Loss: 0.2709  Acc@1: 62.5000 (50.2220)  Acc@5: 87.5000 (86.9576)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2740/4579]  eta: 0:11:03  Lr: 0.001875  Loss: 0.1948  Acc@1: 50.0000 (50.2143)  Acc@5: 87.5000 (86.9642)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2750/4579]  eta: 0:10:59  Lr: 0.001875  Loss: -0.0074  Acc@1: 50.0000 (50.2272)  Acc@5: 87.5000 (86.9684)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2760/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.0911  Acc@1: 56.2500 (50.2626)  Acc@5: 87.5000 (86.9794)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2770/4579]  eta: 0:10:52  Lr: 0.001875  Loss: 0.2258  Acc@1: 56.2500 (50.2819)  Acc@5: 87.5000 (86.9767)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2780/4579]  eta: 0:10:48  Lr: 0.001875  Loss: 0.0231  Acc@1: 56.2500 (50.3169)  Acc@5: 93.7500 (86.9853)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2790/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.0298  Acc@1: 56.2500 (50.3269)  Acc@5: 87.5000 (86.9850)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2800/4579]  eta: 0:10:40  Lr: 0.001875  Loss: -0.1051  Acc@1: 56.2500 (50.3481)  Acc@5: 87.5000 (86.9846)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2810/4579]  eta: 0:10:37  Lr: 0.001875  Loss: -0.1171  Acc@1: 56.2500 (50.3669)  Acc@5: 87.5000 (86.9864)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2820/4579]  eta: 0:10:33  Lr: 0.001875  Loss: -0.2424  Acc@1: 62.5000 (50.4054)  Acc@5: 87.5000 (87.0059)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2830/4579]  eta: 0:10:29  Lr: 0.001875  Loss: -0.0748  Acc@1: 62.5000 (50.4217)  Acc@5: 87.5000 (87.0143)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2840/4579]  eta: 0:10:26  Lr: 0.001875  Loss: -0.0862  Acc@1: 62.5000 (50.4730)  Acc@5: 87.5000 (87.0314)  time: 0.3475  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2850/4579]  eta: 0:10:22  Lr: 0.001875  Loss: -0.3356  Acc@1: 62.5000 (50.5217)  Acc@5: 93.7500 (87.0550)  time: 0.3496  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2860/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.3652  Acc@1: 56.2500 (50.5374)  Acc@5: 93.7500 (87.0653)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2870/4579]  eta: 0:10:15  Lr: 0.001875  Loss: 0.1837  Acc@1: 56.2500 (50.5682)  Acc@5: 87.5000 (87.0711)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2880/4579]  eta: 0:10:11  Lr: 0.001875  Loss: -0.4203  Acc@1: 56.2500 (50.5857)  Acc@5: 87.5000 (87.0661)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2890/4579]  eta: 0:10:07  Lr: 0.001875  Loss: -0.5912  Acc@1: 56.2500 (50.6291)  Acc@5: 87.5000 (87.0828)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2900/4579]  eta: 0:10:04  Lr: 0.001875  Loss: -0.1249  Acc@1: 62.5000 (50.6894)  Acc@5: 87.5000 (87.0799)  time: 0.3491  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2910/4579]  eta: 0:10:00  Lr: 0.001875  Loss: 0.0574  Acc@1: 62.5000 (50.7085)  Acc@5: 87.5000 (87.0813)  time: 0.3493  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2920/4579]  eta: 0:09:56  Lr: 0.001875  Loss: -0.0331  Acc@1: 56.2500 (50.7254)  Acc@5: 87.5000 (87.0849)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2930/4579]  eta: 0:09:53  Lr: 0.001875  Loss: 0.3978  Acc@1: 56.2500 (50.7442)  Acc@5: 87.5000 (87.0885)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2940/4579]  eta: 0:09:49  Lr: 0.001875  Loss: -0.1213  Acc@1: 56.2500 (50.7629)  Acc@5: 87.5000 (87.0984)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2950/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.3233  Acc@1: 56.2500 (50.8069)  Acc@5: 87.5000 (87.1061)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2960/4579]  eta: 0:09:42  Lr: 0.001875  Loss: -0.1180  Acc@1: 56.2500 (50.8485)  Acc@5: 93.7500 (87.1243)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2970/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.2889  Acc@1: 56.2500 (50.8793)  Acc@5: 93.7500 (87.1319)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2980/4579]  eta: 0:09:34  Lr: 0.001875  Loss: 0.3843  Acc@1: 56.2500 (50.8848)  Acc@5: 87.5000 (87.1499)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2990/4579]  eta: 0:09:31  Lr: 0.001875  Loss: -0.4007  Acc@1: 62.5000 (50.9194)  Acc@5: 93.7500 (87.1615)  time: 0.3515  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3000/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.0964  Acc@1: 62.5000 (50.9497)  Acc@5: 87.5000 (87.1689)  time: 0.3547  data: 0.0046  max mem: 2500
Train: Epoch[1/5]  [3010/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.1879  Acc@1: 62.5000 (50.9880)  Acc@5: 87.5000 (87.1803)  time: 0.3540  data: 0.0056  max mem: 2500
Train: Epoch[1/5]  [3020/4579]  eta: 0:09:20  Lr: 0.001875  Loss: -0.3044  Acc@1: 62.5000 (51.0075)  Acc@5: 87.5000 (87.1773)  time: 0.3519  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [3030/4579]  eta: 0:09:16  Lr: 0.001875  Loss: -0.0489  Acc@1: 56.2500 (51.0290)  Acc@5: 87.5000 (87.1824)  time: 0.3580  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3040/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.1403  Acc@1: 56.2500 (51.0461)  Acc@5: 87.5000 (87.1835)  time: 0.3612  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [3050/4579]  eta: 0:09:09  Lr: 0.001875  Loss: -0.2715  Acc@1: 56.2500 (51.0632)  Acc@5: 87.5000 (87.1989)  time: 0.3585  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [3060/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 0.4059  Acc@1: 56.2500 (51.1067)  Acc@5: 93.7500 (87.2101)  time: 0.3553  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3070/4579]  eta: 0:09:02  Lr: 0.001875  Loss: 0.2840  Acc@1: 56.2500 (51.1092)  Acc@5: 87.5000 (87.2090)  time: 0.3540  data: 0.0032  max mem: 2500
Train: Epoch[1/5]  [3080/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.1968  Acc@1: 50.0000 (51.1117)  Acc@5: 87.5000 (87.2119)  time: 0.3536  data: 0.0033  max mem: 2500
Train: Epoch[1/5]  [3090/4579]  eta: 0:08:55  Lr: 0.001875  Loss: -0.4801  Acc@1: 56.2500 (51.1384)  Acc@5: 87.5000 (87.2250)  time: 0.3510  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3100/4579]  eta: 0:08:51  Lr: 0.001875  Loss: -0.4927  Acc@1: 62.5000 (51.1770)  Acc@5: 93.7500 (87.2340)  time: 0.3502  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [3110/4579]  eta: 0:08:47  Lr: 0.001875  Loss: 0.4086  Acc@1: 62.5000 (51.2034)  Acc@5: 93.7500 (87.2388)  time: 0.3489  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3120/4579]  eta: 0:08:44  Lr: 0.001875  Loss: -0.3354  Acc@1: 56.2500 (51.2296)  Acc@5: 93.7500 (87.2557)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3130/4579]  eta: 0:08:40  Lr: 0.001875  Loss: 0.0613  Acc@1: 56.2500 (51.2436)  Acc@5: 93.7500 (87.2585)  time: 0.3530  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [3140/4579]  eta: 0:08:36  Lr: 0.001875  Loss: -0.1427  Acc@1: 50.0000 (51.2337)  Acc@5: 87.5000 (87.2553)  time: 0.3532  data: 0.0032  max mem: 2500
Train: Epoch[1/5]  [3150/4579]  eta: 0:08:33  Lr: 0.001875  Loss: 0.4293  Acc@1: 50.0000 (51.2377)  Acc@5: 87.5000 (87.2659)  time: 0.3517  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3160/4579]  eta: 0:08:29  Lr: 0.001875  Loss: 0.1030  Acc@1: 56.2500 (51.2555)  Acc@5: 93.7500 (87.2865)  time: 0.3531  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [3170/4579]  eta: 0:08:26  Lr: 0.001875  Loss: 0.1211  Acc@1: 56.2500 (51.2614)  Acc@5: 93.7500 (87.2832)  time: 0.3521  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [3180/4579]  eta: 0:08:22  Lr: 0.001875  Loss: -0.3095  Acc@1: 56.2500 (51.2732)  Acc@5: 87.5000 (87.2917)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3190/4579]  eta: 0:08:18  Lr: 0.001875  Loss: 0.2484  Acc@1: 56.2500 (51.2966)  Acc@5: 87.5000 (87.3081)  time: 0.3525  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [3200/4579]  eta: 0:08:15  Lr: 0.001875  Loss: -0.4909  Acc@1: 56.2500 (51.3179)  Acc@5: 87.5000 (87.3087)  time: 0.3518  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [3210/4579]  eta: 0:08:11  Lr: 0.001875  Loss: -0.0006  Acc@1: 62.5000 (51.3625)  Acc@5: 87.5000 (87.3209)  time: 0.3524  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [3220/4579]  eta: 0:08:08  Lr: 0.001875  Loss: -0.2154  Acc@1: 68.7500 (51.4087)  Acc@5: 93.7500 (87.3273)  time: 0.3554  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [3230/4579]  eta: 0:08:04  Lr: 0.001875  Loss: -0.0906  Acc@1: 68.7500 (51.4450)  Acc@5: 93.7500 (87.3394)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3240/4579]  eta: 0:08:00  Lr: 0.001875  Loss: -0.2678  Acc@1: 62.5000 (51.4810)  Acc@5: 93.7500 (87.3573)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3250/4579]  eta: 0:07:57  Lr: 0.001875  Loss: 0.1746  Acc@1: 62.5000 (51.5265)  Acc@5: 93.7500 (87.3750)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3260/4579]  eta: 0:07:53  Lr: 0.001875  Loss: -0.1846  Acc@1: 56.2500 (51.5352)  Acc@5: 93.7500 (87.3869)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3270/4579]  eta: 0:07:49  Lr: 0.001875  Loss: -0.1670  Acc@1: 56.2500 (51.5687)  Acc@5: 87.5000 (87.3911)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3280/4579]  eta: 0:07:46  Lr: 0.001875  Loss: 0.2391  Acc@1: 56.2500 (51.5849)  Acc@5: 87.5000 (87.3990)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3290/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.4543  Acc@1: 56.2500 (51.6067)  Acc@5: 87.5000 (87.4031)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3300/4579]  eta: 0:07:38  Lr: 0.001875  Loss: 0.4533  Acc@1: 62.5000 (51.6340)  Acc@5: 87.5000 (87.4110)  time: 0.3546  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [3310/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.0664  Acc@1: 62.5000 (51.6555)  Acc@5: 87.5000 (87.4169)  time: 0.3583  data: 0.0038  max mem: 2500
Train: Epoch[1/5]  [3320/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.0735  Acc@1: 56.2500 (51.6825)  Acc@5: 87.5000 (87.4172)  time: 0.3558  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [3330/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.7654  Acc@1: 56.2500 (51.7131)  Acc@5: 93.7500 (87.4306)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3340/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.1533  Acc@1: 56.2500 (51.7173)  Acc@5: 93.7500 (87.4364)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3350/4579]  eta: 0:07:20  Lr: 0.001875  Loss: -0.3593  Acc@1: 56.2500 (51.7607)  Acc@5: 87.5000 (87.4440)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3360/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.6287  Acc@1: 62.5000 (51.7833)  Acc@5: 93.7500 (87.4591)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3370/4579]  eta: 0:07:13  Lr: 0.001875  Loss: 0.0002  Acc@1: 56.2500 (51.7892)  Acc@5: 87.5000 (87.4611)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3380/4579]  eta: 0:07:09  Lr: 0.001875  Loss: -0.0889  Acc@1: 50.0000 (51.8079)  Acc@5: 87.5000 (87.4667)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3390/4579]  eta: 0:07:06  Lr: 0.001875  Loss: -0.6030  Acc@1: 56.2500 (51.8339)  Acc@5: 87.5000 (87.4668)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3400/4579]  eta: 0:07:02  Lr: 0.001875  Loss: 0.2898  Acc@1: 56.2500 (51.8524)  Acc@5: 93.7500 (87.4816)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/4579]  eta: 0:06:59  Lr: 0.001875  Loss: -0.0840  Acc@1: 56.2500 (51.8653)  Acc@5: 87.5000 (87.4890)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3420/4579]  eta: 0:06:55  Lr: 0.001875  Loss: -0.4302  Acc@1: 62.5000 (51.9037)  Acc@5: 87.5000 (87.4963)  time: 0.3507  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3430/4579]  eta: 0:06:51  Lr: 0.001875  Loss: -0.6776  Acc@1: 62.5000 (51.9491)  Acc@5: 93.7500 (87.5146)  time: 0.3497  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3440/4579]  eta: 0:06:48  Lr: 0.001875  Loss: -0.2452  Acc@1: 56.2500 (51.9453)  Acc@5: 93.7500 (87.5073)  time: 0.3505  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3450/4579]  eta: 0:06:44  Lr: 0.001875  Loss: 0.0865  Acc@1: 56.2500 (51.9704)  Acc@5: 87.5000 (87.5091)  time: 0.3511  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3460/4579]  eta: 0:06:41  Lr: 0.001875  Loss: -0.2681  Acc@1: 56.2500 (51.9774)  Acc@5: 87.5000 (87.5108)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3470/4579]  eta: 0:06:37  Lr: 0.001875  Loss: 0.4953  Acc@1: 56.2500 (51.9897)  Acc@5: 87.5000 (87.5252)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3480/4579]  eta: 0:06:33  Lr: 0.001875  Loss: 0.1400  Acc@1: 50.0000 (51.9912)  Acc@5: 87.5000 (87.5090)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3490/4579]  eta: 0:06:30  Lr: 0.001875  Loss: -0.4394  Acc@1: 56.2500 (52.0177)  Acc@5: 87.5000 (87.5143)  time: 0.3574  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3500/4579]  eta: 0:06:26  Lr: 0.001875  Loss: 0.0556  Acc@1: 56.2500 (52.0333)  Acc@5: 87.5000 (87.5196)  time: 0.3576  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3510/4579]  eta: 0:06:23  Lr: 0.001875  Loss: -0.1141  Acc@1: 50.0000 (52.0382)  Acc@5: 87.5000 (87.5267)  time: 0.3543  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3520/4579]  eta: 0:06:19  Lr: 0.001875  Loss: 0.0467  Acc@1: 62.5000 (52.0662)  Acc@5: 87.5000 (87.5320)  time: 0.3543  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3530/4579]  eta: 0:06:15  Lr: 0.001875  Loss: 0.0411  Acc@1: 62.5000 (52.0869)  Acc@5: 87.5000 (87.5389)  time: 0.3521  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3540/4579]  eta: 0:06:12  Lr: 0.001875  Loss: -0.3092  Acc@1: 56.2500 (52.1022)  Acc@5: 87.5000 (87.5406)  time: 0.3505  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3550/4579]  eta: 0:06:08  Lr: 0.001875  Loss: 0.3085  Acc@1: 56.2500 (52.1279)  Acc@5: 87.5000 (87.5475)  time: 0.3515  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3560/4579]  eta: 0:06:05  Lr: 0.001875  Loss: -0.1653  Acc@1: 56.2500 (52.1395)  Acc@5: 87.5000 (87.5562)  time: 0.3524  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [3570/4579]  eta: 0:06:01  Lr: 0.001875  Loss: 0.6537  Acc@1: 56.2500 (52.1510)  Acc@5: 87.5000 (87.5490)  time: 0.3523  data: 0.0032  max mem: 2500
Train: Epoch[1/5]  [3580/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.5193  Acc@1: 50.0000 (52.1625)  Acc@5: 87.5000 (87.5559)  time: 0.3519  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [3590/4579]  eta: 0:05:54  Lr: 0.001875  Loss: -0.4830  Acc@1: 56.2500 (52.1738)  Acc@5: 87.5000 (87.5557)  time: 0.3501  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3600/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.1531  Acc@1: 56.2500 (52.1990)  Acc@5: 87.5000 (87.5590)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3610/4579]  eta: 0:05:47  Lr: 0.001875  Loss: -0.0588  Acc@1: 62.5000 (52.2224)  Acc@5: 93.7500 (87.5675)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3620/4579]  eta: 0:05:43  Lr: 0.001875  Loss: 0.4070  Acc@1: 56.2500 (52.2249)  Acc@5: 93.7500 (87.5759)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3630/4579]  eta: 0:05:39  Lr: 0.001875  Loss: 0.1197  Acc@1: 56.2500 (52.2360)  Acc@5: 93.7500 (87.5861)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3640/4579]  eta: 0:05:36  Lr: 0.001875  Loss: 0.0011  Acc@1: 62.5000 (52.2607)  Acc@5: 93.7500 (87.5927)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3650/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.2619  Acc@1: 56.2500 (52.2870)  Acc@5: 87.5000 (87.6027)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3660/4579]  eta: 0:05:28  Lr: 0.001875  Loss: -0.0293  Acc@1: 56.2500 (52.3184)  Acc@5: 93.7500 (87.6161)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3670/4579]  eta: 0:05:25  Lr: 0.001875  Loss: 0.7777  Acc@1: 62.5000 (52.3376)  Acc@5: 93.7500 (87.6226)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3680/4579]  eta: 0:05:21  Lr: 0.001875  Loss: -0.3063  Acc@1: 62.5000 (52.3635)  Acc@5: 93.7500 (87.6392)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3690/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.3598  Acc@1: 62.5000 (52.3808)  Acc@5: 93.7500 (87.6558)  time: 0.3537  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [3700/4579]  eta: 0:05:14  Lr: 0.001875  Loss: 0.0916  Acc@1: 56.2500 (52.3896)  Acc@5: 93.7500 (87.6638)  time: 0.3528  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3710/4579]  eta: 0:05:10  Lr: 0.001875  Loss: 0.2801  Acc@1: 56.2500 (52.4016)  Acc@5: 87.5000 (87.6701)  time: 0.3526  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3720/4579]  eta: 0:05:07  Lr: 0.001875  Loss: -0.2131  Acc@1: 50.0000 (52.3952)  Acc@5: 87.5000 (87.6764)  time: 0.3528  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3730/4579]  eta: 0:05:03  Lr: 0.001875  Loss: 0.0885  Acc@1: 50.0000 (52.4089)  Acc@5: 93.7500 (87.6843)  time: 0.3533  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3740/4579]  eta: 0:05:00  Lr: 0.001875  Loss: -0.0788  Acc@1: 62.5000 (52.4308)  Acc@5: 93.7500 (87.6938)  time: 0.3546  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [3750/4579]  eta: 0:04:56  Lr: 0.001875  Loss: 0.2342  Acc@1: 56.2500 (52.4344)  Acc@5: 87.5000 (87.6983)  time: 0.3540  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3760/4579]  eta: 0:04:53  Lr: 0.001875  Loss: -0.1633  Acc@1: 56.2500 (52.4528)  Acc@5: 87.5000 (87.7077)  time: 0.3563  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [3770/4579]  eta: 0:04:49  Lr: 0.001875  Loss: -0.1342  Acc@1: 56.2500 (52.4678)  Acc@5: 87.5000 (87.7121)  time: 0.3648  data: 0.0037  max mem: 2500
Train: Epoch[1/5]  [3780/4579]  eta: 0:04:45  Lr: 0.001875  Loss: -0.1608  Acc@1: 56.2500 (52.4861)  Acc@5: 93.7500 (87.7298)  time: 0.3672  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [3790/4579]  eta: 0:04:42  Lr: 0.001875  Loss: -0.1095  Acc@1: 62.5000 (52.5043)  Acc@5: 93.7500 (87.7374)  time: 0.3660  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3800/4579]  eta: 0:04:38  Lr: 0.001875  Loss: -0.1309  Acc@1: 56.2500 (52.5207)  Acc@5: 93.7500 (87.7401)  time: 0.3615  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [3810/4579]  eta: 0:04:35  Lr: 0.001875  Loss: 0.2084  Acc@1: 56.2500 (52.5518)  Acc@5: 87.5000 (87.7411)  time: 0.3555  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3820/4579]  eta: 0:04:31  Lr: 0.001875  Loss: -0.3642  Acc@1: 56.2500 (52.5615)  Acc@5: 87.5000 (87.7503)  time: 0.3555  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [3830/4579]  eta: 0:04:28  Lr: 0.001875  Loss: -0.0692  Acc@1: 56.2500 (52.5777)  Acc@5: 87.5000 (87.7578)  time: 0.3547  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3840/4579]  eta: 0:04:24  Lr: 0.001875  Loss: -0.4013  Acc@1: 62.5000 (52.6084)  Acc@5: 87.5000 (87.7587)  time: 0.3548  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [3850/4579]  eta: 0:04:20  Lr: 0.001875  Loss: 0.9122  Acc@1: 56.2500 (52.6178)  Acc@5: 87.5000 (87.7613)  time: 0.3544  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3860/4579]  eta: 0:04:17  Lr: 0.001875  Loss: -0.2322  Acc@1: 56.2500 (52.6402)  Acc@5: 87.5000 (87.7622)  time: 0.3552  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:13  Lr: 0.001875  Loss: 0.0123  Acc@1: 56.2500 (52.6479)  Acc@5: 87.5000 (87.7696)  time: 0.3580  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:10  Lr: 0.001875  Loss: -0.1692  Acc@1: 56.2500 (52.6701)  Acc@5: 87.5000 (87.7705)  time: 0.3565  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [3890/4579]  eta: 0:04:06  Lr: 0.001875  Loss: -0.1745  Acc@1: 56.2500 (52.6793)  Acc@5: 87.5000 (87.7731)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3900/4579]  eta: 0:04:02  Lr: 0.001875  Loss: -0.2147  Acc@1: 56.2500 (52.6884)  Acc@5: 93.7500 (87.7820)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3910/4579]  eta: 0:03:59  Lr: 0.001875  Loss: -0.2352  Acc@1: 62.5000 (52.7119)  Acc@5: 93.7500 (87.7892)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3920/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.0545  Acc@1: 56.2500 (52.7130)  Acc@5: 87.5000 (87.7837)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3930/4579]  eta: 0:03:52  Lr: 0.001875  Loss: 0.1572  Acc@1: 56.2500 (52.7108)  Acc@5: 87.5000 (87.7719)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3940/4579]  eta: 0:03:48  Lr: 0.001875  Loss: -0.0648  Acc@1: 56.2500 (52.7246)  Acc@5: 87.5000 (87.7823)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3950/4579]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7323  Acc@1: 50.0000 (52.7287)  Acc@5: 87.5000 (87.7816)  time: 0.3580  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3960/4579]  eta: 0:03:41  Lr: 0.001875  Loss: -0.2297  Acc@1: 56.2500 (52.7534)  Acc@5: 93.7500 (87.7998)  time: 0.3650  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3970/4579]  eta: 0:03:37  Lr: 0.001875  Loss: -0.0159  Acc@1: 62.5000 (52.7795)  Acc@5: 93.7500 (87.8022)  time: 0.3634  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3980/4579]  eta: 0:03:34  Lr: 0.001875  Loss: 0.3440  Acc@1: 62.5000 (52.8008)  Acc@5: 93.7500 (87.8171)  time: 0.3556  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3990/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 0.2188  Acc@1: 56.2500 (52.8063)  Acc@5: 93.7500 (87.8226)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4000/4579]  eta: 0:03:27  Lr: 0.001875  Loss: -0.1105  Acc@1: 56.2500 (52.8384)  Acc@5: 87.5000 (87.8374)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 0.3481  Acc@1: 56.2500 (52.8531)  Acc@5: 87.5000 (87.8381)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.4398  Acc@1: 56.2500 (52.8817)  Acc@5: 87.5000 (87.8451)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:16  Lr: 0.001875  Loss: -0.3397  Acc@1: 56.2500 (52.8901)  Acc@5: 93.7500 (87.8535)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:12  Lr: 0.001875  Loss: 0.4732  Acc@1: 56.2500 (52.9031)  Acc@5: 93.7500 (87.8588)  time: 0.3494  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 0.2421  Acc@1: 56.2500 (52.9175)  Acc@5: 87.5000 (87.8672)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4060/4579]  eta: 0:03:05  Lr: 0.001875  Loss: 0.5150  Acc@1: 56.2500 (52.9288)  Acc@5: 87.5000 (87.8663)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4070/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.3391  Acc@1: 62.5000 (52.9461)  Acc@5: 87.5000 (87.8731)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4080/4579]  eta: 0:02:58  Lr: 0.001875  Loss: 0.2977  Acc@1: 62.5000 (52.9619)  Acc@5: 87.5000 (87.8767)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4090/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.0861  Acc@1: 56.2500 (52.9791)  Acc@5: 87.5000 (87.8819)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4100/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.0636  Acc@1: 56.2500 (52.9901)  Acc@5: 93.7500 (87.8978)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4110/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.0625  Acc@1: 62.5000 (53.0041)  Acc@5: 93.7500 (87.9014)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4120/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.1619  Acc@1: 56.2500 (53.0120)  Acc@5: 87.5000 (87.9034)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4130/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.5778  Acc@1: 62.5000 (53.0380)  Acc@5: 87.5000 (87.9145)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4140/4579]  eta: 0:02:36  Lr: 0.001875  Loss: -0.3413  Acc@1: 62.5000 (53.0639)  Acc@5: 93.7500 (87.9211)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1397  Acc@1: 68.7500 (53.0941)  Acc@5: 93.7500 (87.9261)  time: 0.3558  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.3650  Acc@1: 62.5000 (53.1047)  Acc@5: 93.7500 (87.9266)  time: 0.3562  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:26  Lr: 0.001875  Loss: 0.0746  Acc@1: 56.2500 (53.1123)  Acc@5: 87.5000 (87.9256)  time: 0.3576  data: 0.0035  max mem: 2500
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:22  Lr: 0.001875  Loss: -0.0972  Acc@1: 56.2500 (53.1257)  Acc@5: 87.5000 (87.9335)  time: 0.3595  data: 0.0052  max mem: 2500
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:19  Lr: 0.001875  Loss: 0.2289  Acc@1: 62.5000 (53.1481)  Acc@5: 87.5000 (87.9369)  time: 0.3595  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:15  Lr: 0.001875  Loss: 0.0720  Acc@1: 56.2500 (53.1495)  Acc@5: 87.5000 (87.9300)  time: 0.3583  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:11  Lr: 0.001875  Loss: 0.9715  Acc@1: 56.2500 (53.1628)  Acc@5: 87.5000 (87.9289)  time: 0.3579  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.1744  Acc@1: 62.5000 (53.1879)  Acc@5: 87.5000 (87.9353)  time: 0.3580  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:04  Lr: 0.001875  Loss: -0.2374  Acc@1: 62.5000 (53.1966)  Acc@5: 93.7500 (87.9417)  time: 0.3581  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [4240/4579]  eta: 0:02:01  Lr: 0.001875  Loss: 0.2088  Acc@1: 56.2500 (53.2156)  Acc@5: 93.7500 (87.9451)  time: 0.3579  data: 0.0036  max mem: 2500
Train: Epoch[1/5]  [4250/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 0.1079  Acc@1: 56.2500 (53.2228)  Acc@5: 87.5000 (87.9484)  time: 0.3580  data: 0.0037  max mem: 2500
Train: Epoch[1/5]  [4260/4579]  eta: 0:01:53  Lr: 0.001875  Loss: -0.2904  Acc@1: 62.5000 (53.2504)  Acc@5: 87.5000 (87.9415)  time: 0.3581  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [4270/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.5278  Acc@1: 62.5000 (53.2735)  Acc@5: 87.5000 (87.9536)  time: 0.3581  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [4280/4579]  eta: 0:01:46  Lr: 0.001875  Loss: -0.4176  Acc@1: 62.5000 (53.3009)  Acc@5: 93.7500 (87.9730)  time: 0.3590  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:43  Lr: 0.001875  Loss: -0.1002  Acc@1: 56.2500 (53.3165)  Acc@5: 100.0000 (87.9850)  time: 0.3585  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:39  Lr: 0.001875  Loss: -0.6473  Acc@1: 62.5000 (53.3408)  Acc@5: 93.7500 (87.9912)  time: 0.3578  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:36  Lr: 0.001875  Loss: -0.5010  Acc@1: 62.5000 (53.3635)  Acc@5: 87.5000 (87.9987)  time: 0.3583  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:32  Lr: 0.001875  Loss: 0.4699  Acc@1: 62.5000 (53.3832)  Acc@5: 87.5000 (88.0005)  time: 0.3571  data: 0.0033  max mem: 2500
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:28  Lr: 0.001875  Loss: 0.1657  Acc@1: 62.5000 (53.3985)  Acc@5: 93.7500 (88.0109)  time: 0.3563  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:25  Lr: 0.001875  Loss: -0.5608  Acc@1: 62.5000 (53.4137)  Acc@5: 93.7500 (88.0169)  time: 0.3584  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0399  Acc@1: 68.7500 (53.4417)  Acc@5: 93.7500 (88.0257)  time: 0.3569  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:18  Lr: 0.001875  Loss: 0.2120  Acc@1: 68.7500 (53.4625)  Acc@5: 93.7500 (88.0317)  time: 0.3546  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2210  Acc@1: 56.2500 (53.4660)  Acc@5: 93.7500 (88.0391)  time: 0.3569  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:11  Lr: 0.001875  Loss: -0.3856  Acc@1: 56.2500 (53.4738)  Acc@5: 93.7500 (88.0435)  time: 0.3572  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6167  Acc@1: 56.2500 (53.4944)  Acc@5: 93.7500 (88.0551)  time: 0.3582  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:03  Lr: 0.001875  Loss: 0.0876  Acc@1: 62.5000 (53.5191)  Acc@5: 93.7500 (88.0595)  time: 0.3592  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [4410/4579]  eta: 0:01:00  Lr: 0.001875  Loss: -0.0378  Acc@1: 62.5000 (53.5465)  Acc@5: 93.7500 (88.0682)  time: 0.3587  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [4420/4579]  eta: 0:00:56  Lr: 0.001875  Loss: -0.0934  Acc@1: 62.5000 (53.5767)  Acc@5: 93.7500 (88.0782)  time: 0.3569  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [4430/4579]  eta: 0:00:53  Lr: 0.001875  Loss: 0.3142  Acc@1: 62.5000 (53.5869)  Acc@5: 93.7500 (88.0825)  time: 0.3559  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1055  Acc@1: 62.5000 (53.6112)  Acc@5: 93.7500 (88.0855)  time: 0.3566  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:46  Lr: 0.001875  Loss: 0.2093  Acc@1: 62.5000 (53.6298)  Acc@5: 93.7500 (88.1010)  time: 0.3583  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0893  Acc@1: 56.2500 (53.6315)  Acc@5: 87.5000 (88.0884)  time: 0.3584  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5728  Acc@1: 56.2500 (53.6331)  Acc@5: 93.7500 (88.1025)  time: 0.3550  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:35  Lr: 0.001875  Loss: -0.5070  Acc@1: 56.2500 (53.6613)  Acc@5: 93.7500 (88.1123)  time: 0.3552  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.4456  Acc@1: 62.5000 (53.6740)  Acc@5: 87.5000 (88.1137)  time: 0.3565  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0272  Acc@1: 62.5000 (53.6867)  Acc@5: 87.5000 (88.1193)  time: 0.3592  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0422  Acc@1: 62.5000 (53.6951)  Acc@5: 87.5000 (88.1235)  time: 0.3592  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:21  Lr: 0.001875  Loss: -0.2416  Acc@1: 62.5000 (53.7174)  Acc@5: 93.7500 (88.1276)  time: 0.3590  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3261  Acc@1: 62.5000 (53.7271)  Acc@5: 93.7500 (88.1331)  time: 0.3592  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0203  Acc@1: 56.2500 (53.7409)  Acc@5: 87.5000 (88.1372)  time: 0.3589  data: 0.0049  max mem: 2500
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.3837  Acc@1: 62.5000 (53.7684)  Acc@5: 87.5000 (88.1372)  time: 0.3606  data: 0.0058  max mem: 2500
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.4634  Acc@1: 62.5000 (53.7862)  Acc@5: 87.5000 (88.1413)  time: 0.3621  data: 0.0042  max mem: 2500
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.1304  Acc@1: 62.5000 (53.8080)  Acc@5: 93.7500 (88.1495)  time: 0.3663  data: 0.0046  max mem: 2500
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.8106  Acc@1: 56.2500 (53.8051)  Acc@5: 87.5000 (88.1472)  time: 0.3634  data: 0.0034  max mem: 2500
Train: Epoch[1/5] Total time: 0:27:17 (0.3577 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73209, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 73225, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 73241, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 73177, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.8106  Acc@1: 56.2500 (53.8051)  Acc@5: 87.5000 (88.1472)
Train: Epoch[2/5]  [   0/4579]  eta: 1:43:38  Lr: 0.001875  Loss: -0.2540  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 1.3581  data: 0.9217  max mem: 2500
Train: Epoch[2/5]  [  10/4579]  eta: 0:34:27  Lr: 0.001875  Loss: -0.4390  Acc@1: 62.5000 (63.0682)  Acc@5: 93.7500 (89.7727)  time: 0.4526  data: 0.0851  max mem: 2500
Train: Epoch[2/5]  [  20/4579]  eta: 0:30:54  Lr: 0.001875  Loss: -0.5233  Acc@1: 62.5000 (66.3690)  Acc@5: 87.5000 (90.1786)  time: 0.3591  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [  30/4579]  eta: 0:29:34  Lr: 0.001875  Loss: 0.5993  Acc@1: 62.5000 (63.7097)  Acc@5: 87.5000 (89.9194)  time: 0.3557  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [  40/4579]  eta: 0:28:51  Lr: 0.001875  Loss: 0.3573  Acc@1: 56.2500 (62.9573)  Acc@5: 87.5000 (89.6341)  time: 0.3551  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [  50/4579]  eta: 0:28:24  Lr: 0.001875  Loss: -0.1145  Acc@1: 56.2500 (62.5000)  Acc@5: 93.7500 (90.0735)  time: 0.3554  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [  60/4579]  eta: 0:28:07  Lr: 0.001875  Loss: -0.2983  Acc@1: 62.5000 (62.2951)  Acc@5: 93.7500 (90.2664)  time: 0.3566  data: 0.0043  max mem: 2500
Train: Epoch[2/5]  [  70/4579]  eta: 0:27:50  Lr: 0.001875  Loss: -0.2878  Acc@1: 62.5000 (61.9718)  Acc@5: 93.7500 (90.5810)  time: 0.3553  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [  80/4579]  eta: 0:27:39  Lr: 0.001875  Loss: 0.7830  Acc@1: 62.5000 (61.5741)  Acc@5: 87.5000 (90.1235)  time: 0.3552  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [  90/4579]  eta: 0:27:28  Lr: 0.001875  Loss: -0.0789  Acc@1: 62.5000 (62.1566)  Acc@5: 93.7500 (90.5220)  time: 0.3560  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [ 100/4579]  eta: 0:27:20  Lr: 0.001875  Loss: -0.3680  Acc@1: 68.7500 (62.6856)  Acc@5: 93.7500 (90.6559)  time: 0.3557  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 110/4579]  eta: 0:27:13  Lr: 0.001875  Loss: -0.0684  Acc@1: 62.5000 (62.2748)  Acc@5: 93.7500 (90.5968)  time: 0.3570  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 120/4579]  eta: 0:27:06  Lr: 0.001875  Loss: 0.3944  Acc@1: 56.2500 (61.9318)  Acc@5: 87.5000 (90.3409)  time: 0.3570  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 130/4579]  eta: 0:26:59  Lr: 0.001875  Loss: -0.0093  Acc@1: 56.2500 (61.6889)  Acc@5: 87.5000 (90.2672)  time: 0.3561  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 140/4579]  eta: 0:26:52  Lr: 0.001875  Loss: -0.2623  Acc@1: 56.2500 (61.3032)  Acc@5: 93.7500 (90.2482)  time: 0.3551  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 150/4579]  eta: 0:26:46  Lr: 0.001875  Loss: -0.2181  Acc@1: 56.2500 (61.2169)  Acc@5: 93.7500 (90.4387)  time: 0.3550  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 160/4579]  eta: 0:26:41  Lr: 0.001875  Loss: -0.0367  Acc@1: 56.2500 (61.1025)  Acc@5: 93.7500 (90.6832)  time: 0.3553  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 170/4579]  eta: 0:26:36  Lr: 0.001875  Loss: 0.0533  Acc@1: 56.2500 (60.6725)  Acc@5: 93.7500 (90.5702)  time: 0.3571  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [ 180/4579]  eta: 0:26:31  Lr: 0.001875  Loss: 0.2935  Acc@1: 56.2500 (60.8425)  Acc@5: 87.5000 (90.6423)  time: 0.3580  data: 0.0040  max mem: 2500
Train: Epoch[2/5]  [ 190/4579]  eta: 0:26:27  Lr: 0.001875  Loss: -0.1261  Acc@1: 62.5000 (60.7657)  Acc@5: 93.7500 (90.6414)  time: 0.3571  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [ 200/4579]  eta: 0:26:22  Lr: 0.001875  Loss: -0.1416  Acc@1: 62.5000 (60.7276)  Acc@5: 93.7500 (90.6716)  time: 0.3569  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 210/4579]  eta: 0:26:18  Lr: 0.001875  Loss: 0.0984  Acc@1: 62.5000 (60.9597)  Acc@5: 93.7500 (90.6694)  time: 0.3574  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 220/4579]  eta: 0:26:13  Lr: 0.001875  Loss: 0.0351  Acc@1: 68.7500 (61.1425)  Acc@5: 87.5000 (90.6391)  time: 0.3571  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 230/4579]  eta: 0:26:08  Lr: 0.001875  Loss: -0.2437  Acc@1: 68.7500 (61.2013)  Acc@5: 93.7500 (90.8009)  time: 0.3558  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 240/4579]  eta: 0:26:05  Lr: 0.001875  Loss: -0.5454  Acc@1: 68.7500 (61.5664)  Acc@5: 93.7500 (90.8195)  time: 0.3573  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 250/4579]  eta: 0:26:01  Lr: 0.001875  Loss: 0.0670  Acc@1: 62.5000 (61.5289)  Acc@5: 93.7500 (90.7869)  time: 0.3589  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 260/4579]  eta: 0:25:57  Lr: 0.001875  Loss: -0.3187  Acc@1: 62.5000 (61.6858)  Acc@5: 93.7500 (90.9483)  time: 0.3583  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 270/4579]  eta: 0:25:53  Lr: 0.001875  Loss: -0.2079  Acc@1: 62.5000 (61.6467)  Acc@5: 93.7500 (90.9594)  time: 0.3590  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 280/4579]  eta: 0:25:50  Lr: 0.001875  Loss: -0.1685  Acc@1: 68.7500 (61.8327)  Acc@5: 93.7500 (90.9698)  time: 0.3629  data: 0.0046  max mem: 2500
Train: Epoch[2/5]  [ 290/4579]  eta: 0:25:47  Lr: 0.001875  Loss: -0.0266  Acc@1: 62.5000 (61.7698)  Acc@5: 87.5000 (90.8935)  time: 0.3645  data: 0.0062  max mem: 2500
Train: Epoch[2/5]  [ 300/4579]  eta: 0:25:43  Lr: 0.001875  Loss: -0.3670  Acc@1: 62.5000 (61.8563)  Acc@5: 87.5000 (90.8846)  time: 0.3609  data: 0.0038  max mem: 2500
Train: Epoch[2/5]  [ 310/4579]  eta: 0:25:41  Lr: 0.001875  Loss: -0.0863  Acc@1: 62.5000 (61.9976)  Acc@5: 93.7500 (90.8762)  time: 0.3646  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [ 320/4579]  eta: 0:25:36  Lr: 0.001875  Loss: -0.2081  Acc@1: 62.5000 (61.9743)  Acc@5: 93.7500 (90.9073)  time: 0.3609  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 330/4579]  eta: 0:25:30  Lr: 0.001875  Loss: -0.2342  Acc@1: 62.5000 (61.9335)  Acc@5: 93.7500 (90.8421)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 340/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 0.0604  Acc@1: 62.5000 (61.7669)  Acc@5: 87.5000 (90.7808)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 350/4579]  eta: 0:25:20  Lr: 0.001875  Loss: -0.1158  Acc@1: 56.2500 (61.7343)  Acc@5: 87.5000 (90.7764)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 360/4579]  eta: 0:25:15  Lr: 0.001875  Loss: 0.1936  Acc@1: 56.2500 (61.7036)  Acc@5: 93.7500 (90.8414)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 370/4579]  eta: 0:25:10  Lr: 0.001875  Loss: 0.1615  Acc@1: 62.5000 (61.7251)  Acc@5: 93.7500 (90.7682)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 380/4579]  eta: 0:25:05  Lr: 0.001875  Loss: 0.2623  Acc@1: 62.5000 (61.6798)  Acc@5: 93.7500 (90.7972)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 390/4579]  eta: 0:25:00  Lr: 0.001875  Loss: 0.2977  Acc@1: 56.2500 (61.5569)  Acc@5: 87.5000 (90.6809)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 400/4579]  eta: 0:24:55  Lr: 0.001875  Loss: -0.7478  Acc@1: 62.5000 (61.5960)  Acc@5: 87.5000 (90.7263)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 410/4579]  eta: 0:24:50  Lr: 0.001875  Loss: -0.2935  Acc@1: 62.5000 (61.7092)  Acc@5: 93.7500 (90.6934)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 420/4579]  eta: 0:24:46  Lr: 0.001875  Loss: -0.3074  Acc@1: 56.2500 (61.6835)  Acc@5: 87.5000 (90.6473)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 430/4579]  eta: 0:24:41  Lr: 0.001875  Loss: 0.0895  Acc@1: 56.2500 (61.5139)  Acc@5: 93.7500 (90.6903)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 440/4579]  eta: 0:24:37  Lr: 0.001875  Loss: -0.1755  Acc@1: 56.2500 (61.4796)  Acc@5: 93.7500 (90.6888)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 450/4579]  eta: 0:24:33  Lr: 0.001875  Loss: -0.0150  Acc@1: 62.5000 (61.4052)  Acc@5: 87.5000 (90.6042)  time: 0.3555  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 460/4579]  eta: 0:24:30  Lr: 0.001875  Loss: -0.3321  Acc@1: 62.5000 (61.4561)  Acc@5: 87.5000 (90.5640)  time: 0.3591  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [ 470/4579]  eta: 0:24:27  Lr: 0.001875  Loss: 0.5109  Acc@1: 68.7500 (61.4915)  Acc@5: 87.5000 (90.5122)  time: 0.3595  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [ 480/4579]  eta: 0:24:23  Lr: 0.001875  Loss: -0.6775  Acc@1: 62.5000 (61.5255)  Acc@5: 87.5000 (90.5275)  time: 0.3583  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 490/4579]  eta: 0:24:19  Lr: 0.001875  Loss: -0.1864  Acc@1: 62.5000 (61.5835)  Acc@5: 87.5000 (90.5295)  time: 0.3558  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 500/4579]  eta: 0:24:16  Lr: 0.001875  Loss: -0.3630  Acc@1: 62.5000 (61.5519)  Acc@5: 93.7500 (90.5564)  time: 0.3551  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 510/4579]  eta: 0:24:12  Lr: 0.001875  Loss: 0.0876  Acc@1: 62.5000 (61.5582)  Acc@5: 93.7500 (90.5944)  time: 0.3557  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 520/4579]  eta: 0:24:08  Lr: 0.001875  Loss: 0.3244  Acc@1: 62.5000 (61.6123)  Acc@5: 87.5000 (90.5590)  time: 0.3550  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 530/4579]  eta: 0:24:04  Lr: 0.001875  Loss: 0.2127  Acc@1: 62.5000 (61.5937)  Acc@5: 87.5000 (90.4190)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 540/4579]  eta: 0:24:00  Lr: 0.001875  Loss: -0.3274  Acc@1: 62.5000 (61.5527)  Acc@5: 87.5000 (90.4228)  time: 0.3528  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 550/4579]  eta: 0:23:57  Lr: 0.001875  Loss: -0.3174  Acc@1: 62.5000 (61.6493)  Acc@5: 93.7500 (90.4605)  time: 0.3582  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 560/4579]  eta: 0:23:54  Lr: 0.001875  Loss: 0.1808  Acc@1: 62.5000 (61.5530)  Acc@5: 93.7500 (90.4523)  time: 0.3590  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 570/4579]  eta: 0:23:50  Lr: 0.001875  Loss: -0.2066  Acc@1: 56.2500 (61.5696)  Acc@5: 93.7500 (90.4882)  time: 0.3584  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [ 580/4579]  eta: 0:23:47  Lr: 0.001875  Loss: 0.0561  Acc@1: 56.2500 (61.5211)  Acc@5: 93.7500 (90.4690)  time: 0.3582  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 590/4579]  eta: 0:23:43  Lr: 0.001875  Loss: 0.1654  Acc@1: 56.2500 (61.3896)  Acc@5: 87.5000 (90.4399)  time: 0.3529  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 600/4579]  eta: 0:23:39  Lr: 0.001875  Loss: 0.6185  Acc@1: 56.2500 (61.3561)  Acc@5: 87.5000 (90.3910)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 610/4579]  eta: 0:23:35  Lr: 0.001875  Loss: -0.7347  Acc@1: 62.5000 (61.4669)  Acc@5: 93.7500 (90.4153)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 620/4579]  eta: 0:23:31  Lr: 0.001875  Loss: 0.0596  Acc@1: 68.7500 (61.5036)  Acc@5: 93.7500 (90.5093)  time: 0.3535  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 630/4579]  eta: 0:23:28  Lr: 0.001875  Loss: -0.4963  Acc@1: 68.7500 (61.4303)  Acc@5: 93.7500 (90.5507)  time: 0.3560  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [ 640/4579]  eta: 0:23:24  Lr: 0.001875  Loss: -0.4216  Acc@1: 62.5000 (61.4860)  Acc@5: 93.7500 (90.5616)  time: 0.3538  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 650/4579]  eta: 0:23:20  Lr: 0.001875  Loss: -0.1202  Acc@1: 62.5000 (61.5495)  Acc@5: 93.7500 (90.5914)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 660/4579]  eta: 0:23:16  Lr: 0.001875  Loss: 0.4976  Acc@1: 62.5000 (61.4977)  Acc@5: 87.5000 (90.5541)  time: 0.3524  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 670/4579]  eta: 0:23:12  Lr: 0.001875  Loss: 0.1537  Acc@1: 68.7500 (61.5779)  Acc@5: 87.5000 (90.5272)  time: 0.3526  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 680/4579]  eta: 0:23:08  Lr: 0.001875  Loss: -0.4546  Acc@1: 68.7500 (61.6648)  Acc@5: 87.5000 (90.5286)  time: 0.3528  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [ 690/4579]  eta: 0:23:05  Lr: 0.001875  Loss: -0.7457  Acc@1: 68.7500 (61.7402)  Acc@5: 93.7500 (90.5662)  time: 0.3527  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 700/4579]  eta: 0:23:01  Lr: 0.001875  Loss: -0.5477  Acc@1: 68.7500 (61.8313)  Acc@5: 93.7500 (90.6027)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 710/4579]  eta: 0:22:57  Lr: 0.001875  Loss: 0.3136  Acc@1: 62.5000 (61.8407)  Acc@5: 93.7500 (90.6030)  time: 0.3522  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 720/4579]  eta: 0:22:53  Lr: 0.001875  Loss: -0.2065  Acc@1: 56.2500 (61.7892)  Acc@5: 93.7500 (90.6033)  time: 0.3525  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 730/4579]  eta: 0:22:50  Lr: 0.001875  Loss: 0.0602  Acc@1: 56.2500 (61.7562)  Acc@5: 87.5000 (90.5694)  time: 0.3540  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [ 740/4579]  eta: 0:22:46  Lr: 0.001875  Loss: -0.6069  Acc@1: 56.2500 (61.6650)  Acc@5: 87.5000 (90.5449)  time: 0.3530  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [ 750/4579]  eta: 0:22:42  Lr: 0.001875  Loss: 0.2072  Acc@1: 56.2500 (61.6262)  Acc@5: 87.5000 (90.5210)  time: 0.3535  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 760/4579]  eta: 0:22:39  Lr: 0.001875  Loss: -0.6684  Acc@1: 62.5000 (61.6212)  Acc@5: 93.7500 (90.5141)  time: 0.3544  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 770/4579]  eta: 0:22:35  Lr: 0.001875  Loss: 0.6449  Acc@1: 56.2500 (61.5516)  Acc@5: 87.5000 (90.4507)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 780/4579]  eta: 0:22:31  Lr: 0.001875  Loss: -0.1586  Acc@1: 56.2500 (61.5397)  Acc@5: 87.5000 (90.4449)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 790/4579]  eta: 0:22:27  Lr: 0.001875  Loss: -0.3000  Acc@1: 62.5000 (61.5044)  Acc@5: 87.5000 (90.4235)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 800/4579]  eta: 0:22:24  Lr: 0.001875  Loss: -0.5195  Acc@1: 56.2500 (61.4856)  Acc@5: 87.5000 (90.4494)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 810/4579]  eta: 0:22:20  Lr: 0.001875  Loss: 0.1204  Acc@1: 56.2500 (61.4365)  Acc@5: 87.5000 (90.3977)  time: 0.3536  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 820/4579]  eta: 0:22:16  Lr: 0.001875  Loss: -0.4643  Acc@1: 56.2500 (61.4342)  Acc@5: 87.5000 (90.4309)  time: 0.3529  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 830/4579]  eta: 0:22:12  Lr: 0.001875  Loss: 0.0733  Acc@1: 62.5000 (61.4471)  Acc@5: 87.5000 (90.3655)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 840/4579]  eta: 0:22:08  Lr: 0.001875  Loss: 0.6869  Acc@1: 56.2500 (61.4150)  Acc@5: 87.5000 (90.3537)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 850/4579]  eta: 0:22:05  Lr: 0.001875  Loss: 0.2471  Acc@1: 56.2500 (61.4424)  Acc@5: 93.7500 (90.3569)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 860/4579]  eta: 0:22:01  Lr: 0.001875  Loss: 0.1155  Acc@1: 62.5000 (61.4257)  Acc@5: 93.7500 (90.3600)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 870/4579]  eta: 0:21:57  Lr: 0.001875  Loss: 0.0016  Acc@1: 62.5000 (61.4595)  Acc@5: 87.5000 (90.3272)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 880/4579]  eta: 0:21:53  Lr: 0.001875  Loss: -0.0874  Acc@1: 62.5000 (61.4784)  Acc@5: 87.5000 (90.3519)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 890/4579]  eta: 0:21:49  Lr: 0.001875  Loss: -0.0045  Acc@1: 62.5000 (61.4198)  Acc@5: 93.7500 (90.3409)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 900/4579]  eta: 0:21:45  Lr: 0.001875  Loss: -0.3539  Acc@1: 56.2500 (61.4248)  Acc@5: 93.7500 (90.3510)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 910/4579]  eta: 0:21:41  Lr: 0.001875  Loss: -0.2298  Acc@1: 62.5000 (61.4572)  Acc@5: 87.5000 (90.3403)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 920/4579]  eta: 0:21:37  Lr: 0.001875  Loss: -0.1032  Acc@1: 62.5000 (61.4685)  Acc@5: 93.7500 (90.3773)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 930/4579]  eta: 0:21:33  Lr: 0.001875  Loss: -0.2024  Acc@1: 62.5000 (61.5199)  Acc@5: 93.7500 (90.3733)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 940/4579]  eta: 0:21:29  Lr: 0.001875  Loss: 0.3454  Acc@1: 62.5000 (61.5701)  Acc@5: 87.5000 (90.3494)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 950/4579]  eta: 0:21:25  Lr: 0.001875  Loss: -0.3176  Acc@1: 68.7500 (61.6785)  Acc@5: 93.7500 (90.3851)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 960/4579]  eta: 0:21:21  Lr: 0.001875  Loss: 0.0271  Acc@1: 62.5000 (61.6350)  Acc@5: 93.7500 (90.4136)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 970/4579]  eta: 0:21:18  Lr: 0.001875  Loss: -0.5423  Acc@1: 56.2500 (61.6568)  Acc@5: 87.5000 (90.3901)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 980/4579]  eta: 0:21:14  Lr: 0.001875  Loss: -0.1201  Acc@1: 62.5000 (61.6845)  Acc@5: 93.7500 (90.4243)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 990/4579]  eta: 0:21:11  Lr: 0.001875  Loss: 0.7696  Acc@1: 62.5000 (61.6612)  Acc@5: 93.7500 (90.3885)  time: 0.3549  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1000/4579]  eta: 0:21:07  Lr: 0.001875  Loss: 0.2891  Acc@1: 62.5000 (61.6384)  Acc@5: 87.5000 (90.3846)  time: 0.3559  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1010/4579]  eta: 0:21:04  Lr: 0.001875  Loss: -0.3906  Acc@1: 62.5000 (61.6716)  Acc@5: 93.7500 (90.3994)  time: 0.3592  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1020/4579]  eta: 0:21:00  Lr: 0.001875  Loss: -0.1758  Acc@1: 62.5000 (61.6858)  Acc@5: 93.7500 (90.4077)  time: 0.3590  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1030/4579]  eta: 0:20:57  Lr: 0.001875  Loss: -0.2174  Acc@1: 62.5000 (61.7180)  Acc@5: 93.7500 (90.4159)  time: 0.3570  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [1040/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.1374  Acc@1: 62.5000 (61.7435)  Acc@5: 93.7500 (90.4179)  time: 0.3605  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [1050/4579]  eta: 0:20:50  Lr: 0.001875  Loss: 0.2545  Acc@1: 62.5000 (61.7745)  Acc@5: 93.7500 (90.4198)  time: 0.3603  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1060/4579]  eta: 0:20:47  Lr: 0.001875  Loss: -0.5545  Acc@1: 62.5000 (61.7813)  Acc@5: 93.7500 (90.4159)  time: 0.3566  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1070/4579]  eta: 0:20:43  Lr: 0.001875  Loss: 0.1786  Acc@1: 56.2500 (61.7705)  Acc@5: 93.7500 (90.4178)  time: 0.3581  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1080/4579]  eta: 0:20:40  Lr: 0.001875  Loss: 0.0811  Acc@1: 56.2500 (61.7426)  Acc@5: 93.7500 (90.4082)  time: 0.3571  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1090/4579]  eta: 0:20:36  Lr: 0.001875  Loss: -0.2208  Acc@1: 56.2500 (61.7610)  Acc@5: 87.5000 (90.4044)  time: 0.3571  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1100/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.0818  Acc@1: 62.5000 (61.8074)  Acc@5: 93.7500 (90.4008)  time: 0.3622  data: 0.0044  max mem: 2500
Train: Epoch[2/5]  [1110/4579]  eta: 0:20:30  Lr: 0.001875  Loss: -0.5041  Acc@1: 68.7500 (61.8474)  Acc@5: 93.7500 (90.4197)  time: 0.3605  data: 0.0048  max mem: 2500
Train: Epoch[2/5]  [1120/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.2635  Acc@1: 62.5000 (61.8365)  Acc@5: 87.5000 (90.3936)  time: 0.3575  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1130/4579]  eta: 0:20:23  Lr: 0.001875  Loss: 0.3512  Acc@1: 56.2500 (61.8148)  Acc@5: 87.5000 (90.3570)  time: 0.3568  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1140/4579]  eta: 0:20:19  Lr: 0.001875  Loss: -0.2868  Acc@1: 56.2500 (61.8098)  Acc@5: 87.5000 (90.3648)  time: 0.3573  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1150/4579]  eta: 0:20:16  Lr: 0.001875  Loss: -0.1110  Acc@1: 62.5000 (61.8484)  Acc@5: 93.7500 (90.3616)  time: 0.3579  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [1160/4579]  eta: 0:20:12  Lr: 0.001875  Loss: 0.0808  Acc@1: 62.5000 (61.8271)  Acc@5: 87.5000 (90.3424)  time: 0.3570  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1170/4579]  eta: 0:20:09  Lr: 0.001875  Loss: 0.1092  Acc@1: 56.2500 (61.7901)  Acc@5: 87.5000 (90.3555)  time: 0.3576  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1180/4579]  eta: 0:20:06  Lr: 0.001875  Loss: 0.0717  Acc@1: 56.2500 (61.7750)  Acc@5: 93.7500 (90.3419)  time: 0.3577  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1190/4579]  eta: 0:20:02  Lr: 0.001875  Loss: -0.1789  Acc@1: 62.5000 (61.8440)  Acc@5: 87.5000 (90.3442)  time: 0.3582  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1200/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 0.5937  Acc@1: 62.5000 (61.8547)  Acc@5: 87.5000 (90.3414)  time: 0.3584  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1210/4579]  eta: 0:19:55  Lr: 0.001875  Loss: -0.1977  Acc@1: 56.2500 (61.7929)  Acc@5: 93.7500 (90.3437)  time: 0.3573  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [1220/4579]  eta: 0:19:52  Lr: 0.001875  Loss: 0.3134  Acc@1: 56.2500 (61.7578)  Acc@5: 93.7500 (90.3614)  time: 0.3548  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1230/4579]  eta: 0:19:48  Lr: 0.001875  Loss: -0.5495  Acc@1: 62.5000 (61.7994)  Acc@5: 93.7500 (90.3635)  time: 0.3570  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [1240/4579]  eta: 0:19:45  Lr: 0.001875  Loss: -0.2706  Acc@1: 62.5000 (61.8251)  Acc@5: 93.7500 (90.3807)  time: 0.3584  data: 0.0036  max mem: 2500
Train: Epoch[2/5]  [1250/4579]  eta: 0:19:41  Lr: 0.001875  Loss: -0.1773  Acc@1: 62.5000 (61.8056)  Acc@5: 93.7500 (90.3977)  time: 0.3571  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1260/4579]  eta: 0:19:38  Lr: 0.001875  Loss: 0.5304  Acc@1: 62.5000 (61.7714)  Acc@5: 93.7500 (90.3995)  time: 0.3557  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1270/4579]  eta: 0:19:34  Lr: 0.001875  Loss: 0.1932  Acc@1: 62.5000 (61.7821)  Acc@5: 93.7500 (90.4062)  time: 0.3594  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [1280/4579]  eta: 0:19:31  Lr: 0.001875  Loss: -0.1790  Acc@1: 62.5000 (61.7681)  Acc@5: 93.7500 (90.4176)  time: 0.3669  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [1290/4579]  eta: 0:19:28  Lr: 0.001875  Loss: -0.3586  Acc@1: 56.2500 (61.7787)  Acc@5: 93.7500 (90.4338)  time: 0.3658  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [1300/4579]  eta: 0:19:24  Lr: 0.001875  Loss: -0.4891  Acc@1: 68.7500 (61.8659)  Acc@5: 93.7500 (90.4737)  time: 0.3658  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [1310/4579]  eta: 0:19:21  Lr: 0.001875  Loss: -0.1286  Acc@1: 68.7500 (61.8755)  Acc@5: 93.7500 (90.4701)  time: 0.3640  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [1320/4579]  eta: 0:19:17  Lr: 0.001875  Loss: 0.2032  Acc@1: 62.5000 (61.9322)  Acc@5: 93.7500 (90.4712)  time: 0.3571  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1330/4579]  eta: 0:19:14  Lr: 0.001875  Loss: 0.3200  Acc@1: 56.2500 (61.8708)  Acc@5: 93.7500 (90.4865)  time: 0.3555  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1340/4579]  eta: 0:19:10  Lr: 0.001875  Loss: 0.2731  Acc@1: 62.5000 (61.9174)  Acc@5: 93.7500 (90.4922)  time: 0.3557  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1350/4579]  eta: 0:19:07  Lr: 0.001875  Loss: -0.1373  Acc@1: 62.5000 (61.8847)  Acc@5: 93.7500 (90.5024)  time: 0.3559  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1360/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.5153  Acc@1: 62.5000 (61.8892)  Acc@5: 93.7500 (90.5079)  time: 0.3562  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1370/4579]  eta: 0:19:00  Lr: 0.001875  Loss: 0.2116  Acc@1: 56.2500 (61.8435)  Acc@5: 93.7500 (90.5042)  time: 0.3572  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1380/4579]  eta: 0:18:56  Lr: 0.001875  Loss: 0.0121  Acc@1: 62.5000 (61.8302)  Acc@5: 87.5000 (90.5096)  time: 0.3566  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1390/4579]  eta: 0:18:53  Lr: 0.001875  Loss: 0.4157  Acc@1: 62.5000 (61.8889)  Acc@5: 93.7500 (90.5374)  time: 0.3546  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1400/4579]  eta: 0:18:49  Lr: 0.001875  Loss: -0.1564  Acc@1: 68.7500 (61.8933)  Acc@5: 93.7500 (90.5425)  time: 0.3600  data: 0.0037  max mem: 2500
Train: Epoch[2/5]  [1410/4579]  eta: 0:18:46  Lr: 0.001875  Loss: 0.6384  Acc@1: 62.5000 (61.8799)  Acc@5: 87.5000 (90.5165)  time: 0.3617  data: 0.0039  max mem: 2500
Train: Epoch[2/5]  [1420/4579]  eta: 0:18:42  Lr: 0.001875  Loss: 0.1282  Acc@1: 62.5000 (61.8622)  Acc@5: 87.5000 (90.5128)  time: 0.3597  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [1430/4579]  eta: 0:18:39  Lr: 0.001875  Loss: 0.3812  Acc@1: 62.5000 (61.8623)  Acc@5: 93.7500 (90.5180)  time: 0.3625  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [1440/4579]  eta: 0:18:36  Lr: 0.001875  Loss: 0.0476  Acc@1: 62.5000 (61.8537)  Acc@5: 87.5000 (90.5014)  time: 0.3594  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [1450/4579]  eta: 0:18:32  Lr: 0.001875  Loss: -0.2500  Acc@1: 62.5000 (61.8151)  Acc@5: 87.5000 (90.4979)  time: 0.3556  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1460/4579]  eta: 0:18:29  Lr: 0.001875  Loss: -0.0639  Acc@1: 56.2500 (61.8241)  Acc@5: 93.7500 (90.4988)  time: 0.3599  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1470/4579]  eta: 0:18:25  Lr: 0.001875  Loss: 0.1974  Acc@1: 56.2500 (61.8032)  Acc@5: 87.5000 (90.4869)  time: 0.3610  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [1480/4579]  eta: 0:18:22  Lr: 0.001875  Loss: -0.3285  Acc@1: 56.2500 (61.7910)  Acc@5: 87.5000 (90.4625)  time: 0.3576  data: 0.0039  max mem: 2500
Train: Epoch[2/5]  [1490/4579]  eta: 0:18:18  Lr: 0.001875  Loss: -0.1726  Acc@1: 62.5000 (61.8042)  Acc@5: 93.7500 (90.4636)  time: 0.3569  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [1500/4579]  eta: 0:18:14  Lr: 0.001875  Loss: -0.3822  Acc@1: 62.5000 (61.8005)  Acc@5: 93.7500 (90.4772)  time: 0.3552  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1510/4579]  eta: 0:18:11  Lr: 0.001875  Loss: -0.5026  Acc@1: 62.5000 (61.8216)  Acc@5: 93.7500 (90.4988)  time: 0.3570  data: 0.0048  max mem: 2500
Train: Epoch[2/5]  [1520/4579]  eta: 0:18:08  Lr: 0.001875  Loss: 0.1467  Acc@1: 62.5000 (61.8261)  Acc@5: 93.7500 (90.5038)  time: 0.3599  data: 0.0050  max mem: 2500
Train: Epoch[2/5]  [1530/4579]  eta: 0:18:04  Lr: 0.001875  Loss: -0.1223  Acc@1: 62.5000 (61.8427)  Acc@5: 93.7500 (90.5046)  time: 0.3582  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1540/4579]  eta: 0:18:00  Lr: 0.001875  Loss: -0.4124  Acc@1: 62.5000 (61.8470)  Acc@5: 93.7500 (90.5216)  time: 0.3566  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1550/4579]  eta: 0:17:57  Lr: 0.001875  Loss: -0.1938  Acc@1: 62.5000 (61.8956)  Acc@5: 93.7500 (90.5263)  time: 0.3560  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1560/4579]  eta: 0:17:54  Lr: 0.001875  Loss: 0.0180  Acc@1: 62.5000 (61.8754)  Acc@5: 93.7500 (90.5269)  time: 0.3616  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [1570/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.2432  Acc@1: 62.5000 (61.8794)  Acc@5: 87.5000 (90.5156)  time: 0.3604  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1580/4579]  eta: 0:17:46  Lr: 0.001875  Loss: 0.4157  Acc@1: 62.5000 (61.8793)  Acc@5: 87.5000 (90.5321)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1590/4579]  eta: 0:17:43  Lr: 0.001875  Loss: -0.4967  Acc@1: 62.5000 (61.8990)  Acc@5: 93.7500 (90.5366)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1600/4579]  eta: 0:17:39  Lr: 0.001875  Loss: -0.5069  Acc@1: 62.5000 (61.9066)  Acc@5: 93.7500 (90.5489)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1610/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.3348  Acc@1: 62.5000 (61.8754)  Acc@5: 93.7500 (90.5377)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1620/4579]  eta: 0:17:31  Lr: 0.001875  Loss: -0.0683  Acc@1: 56.2500 (61.8715)  Acc@5: 93.7500 (90.5498)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1630/4579]  eta: 0:17:28  Lr: 0.001875  Loss: -0.2063  Acc@1: 62.5000 (61.8792)  Acc@5: 93.7500 (90.5656)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1640/4579]  eta: 0:17:24  Lr: 0.001875  Loss: -0.0535  Acc@1: 62.5000 (61.9059)  Acc@5: 93.7500 (90.5736)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1650/4579]  eta: 0:17:20  Lr: 0.001875  Loss: -0.2331  Acc@1: 62.5000 (61.9246)  Acc@5: 87.5000 (90.5777)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1660/4579]  eta: 0:17:17  Lr: 0.001875  Loss: 0.0064  Acc@1: 62.5000 (61.9732)  Acc@5: 93.7500 (90.5968)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1670/4579]  eta: 0:17:13  Lr: 0.001875  Loss: -0.1872  Acc@1: 68.7500 (61.9913)  Acc@5: 93.7500 (90.6044)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1680/4579]  eta: 0:17:09  Lr: 0.001875  Loss: 0.0936  Acc@1: 62.5000 (61.9460)  Acc@5: 93.7500 (90.5934)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1690/4579]  eta: 0:17:05  Lr: 0.001875  Loss: -0.5183  Acc@1: 62.5000 (61.9641)  Acc@5: 93.7500 (90.5936)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1700/4579]  eta: 0:17:02  Lr: 0.001875  Loss: -0.5208  Acc@1: 62.5000 (61.9452)  Acc@5: 87.5000 (90.5754)  time: 0.3536  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1710/4579]  eta: 0:16:58  Lr: 0.001875  Loss: -0.2464  Acc@1: 62.5000 (61.9557)  Acc@5: 87.5000 (90.5830)  time: 0.3562  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [1720/4579]  eta: 0:16:55  Lr: 0.001875  Loss: -0.0752  Acc@1: 62.5000 (61.9553)  Acc@5: 93.7500 (90.5978)  time: 0.3570  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [1730/4579]  eta: 0:16:51  Lr: 0.001875  Loss: -0.1565  Acc@1: 62.5000 (61.9765)  Acc@5: 93.7500 (90.5979)  time: 0.3555  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1740/4579]  eta: 0:16:48  Lr: 0.001875  Loss: -0.7322  Acc@1: 62.5000 (62.0190)  Acc@5: 93.7500 (90.6088)  time: 0.3562  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1750/4579]  eta: 0:16:44  Lr: 0.001875  Loss: -0.5459  Acc@1: 68.7500 (62.0467)  Acc@5: 93.7500 (90.6161)  time: 0.3571  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1760/4579]  eta: 0:16:41  Lr: 0.001875  Loss: 0.0731  Acc@1: 62.5000 (62.0706)  Acc@5: 93.7500 (90.6303)  time: 0.3582  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1770/4579]  eta: 0:16:37  Lr: 0.001875  Loss: 0.4619  Acc@1: 62.5000 (62.0624)  Acc@5: 93.7500 (90.5950)  time: 0.3608  data: 0.0032  max mem: 2500
Train: Epoch[2/5]  [1780/4579]  eta: 0:16:34  Lr: 0.001875  Loss: -0.6702  Acc@1: 56.2500 (62.0543)  Acc@5: 87.5000 (90.6127)  time: 0.3590  data: 0.0047  max mem: 2500
Train: Epoch[2/5]  [1790/4579]  eta: 0:16:30  Lr: 0.001875  Loss: -0.2928  Acc@1: 62.5000 (62.0603)  Acc@5: 93.7500 (90.6267)  time: 0.3554  data: 0.0039  max mem: 2500
Train: Epoch[2/5]  [1800/4579]  eta: 0:16:27  Lr: 0.001875  Loss: -0.3404  Acc@1: 62.5000 (62.0350)  Acc@5: 93.7500 (90.6406)  time: 0.3553  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1810/4579]  eta: 0:16:23  Lr: 0.001875  Loss: -0.2936  Acc@1: 56.2500 (62.0375)  Acc@5: 93.7500 (90.5991)  time: 0.3664  data: 0.0037  max mem: 2500
Train: Epoch[2/5]  [1820/4579]  eta: 0:16:20  Lr: 0.001875  Loss: -0.1811  Acc@1: 68.7500 (62.0813)  Acc@5: 93.7500 (90.6164)  time: 0.3676  data: 0.0040  max mem: 2500
Train: Epoch[2/5]  [1830/4579]  eta: 0:16:17  Lr: 0.001875  Loss: -0.3401  Acc@1: 68.7500 (62.0733)  Acc@5: 93.7500 (90.6165)  time: 0.3615  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1840/4579]  eta: 0:16:13  Lr: 0.001875  Loss: -0.2818  Acc@1: 62.5000 (62.0858)  Acc@5: 93.7500 (90.6233)  time: 0.3634  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1850/4579]  eta: 0:16:10  Lr: 0.001875  Loss: 0.0781  Acc@1: 62.5000 (62.0610)  Acc@5: 93.7500 (90.6267)  time: 0.3585  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1860/4579]  eta: 0:16:06  Lr: 0.001875  Loss: -0.0949  Acc@1: 56.2500 (62.0365)  Acc@5: 93.7500 (90.6233)  time: 0.3551  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1870/4579]  eta: 0:16:02  Lr: 0.001875  Loss: -0.2377  Acc@1: 56.2500 (62.0390)  Acc@5: 93.7500 (90.6233)  time: 0.3547  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1880/4579]  eta: 0:15:59  Lr: 0.001875  Loss: -0.0566  Acc@1: 62.5000 (62.0581)  Acc@5: 93.7500 (90.6400)  time: 0.3554  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1890/4579]  eta: 0:15:55  Lr: 0.001875  Loss: -0.1556  Acc@1: 68.7500 (62.0670)  Acc@5: 93.7500 (90.6300)  time: 0.3568  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [1900/4579]  eta: 0:15:52  Lr: 0.001875  Loss: 0.3395  Acc@1: 62.5000 (62.0562)  Acc@5: 93.7500 (90.6332)  time: 0.3572  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [1910/4579]  eta: 0:15:48  Lr: 0.001875  Loss: 0.1885  Acc@1: 62.5000 (62.0454)  Acc@5: 93.7500 (90.6299)  time: 0.3567  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1920/4579]  eta: 0:15:45  Lr: 0.001875  Loss: -0.1667  Acc@1: 62.5000 (62.0510)  Acc@5: 87.5000 (90.6234)  time: 0.3582  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1930/4579]  eta: 0:15:41  Lr: 0.001875  Loss: -0.3807  Acc@1: 62.5000 (62.0404)  Acc@5: 93.7500 (90.6266)  time: 0.3616  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1940/4579]  eta: 0:15:38  Lr: 0.001875  Loss: 0.0275  Acc@1: 56.2500 (62.0170)  Acc@5: 87.5000 (90.6105)  time: 0.3546  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1950/4579]  eta: 0:15:34  Lr: 0.001875  Loss: -0.7135  Acc@1: 56.2500 (62.0195)  Acc@5: 87.5000 (90.6138)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1960/4579]  eta: 0:15:30  Lr: 0.001875  Loss: -0.4853  Acc@1: 62.5000 (62.0219)  Acc@5: 93.7500 (90.6266)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1970/4579]  eta: 0:15:27  Lr: 0.001875  Loss: 0.1610  Acc@1: 62.5000 (62.0307)  Acc@5: 93.7500 (90.6266)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1980/4579]  eta: 0:15:23  Lr: 0.001875  Loss: 0.1182  Acc@1: 62.5000 (62.0268)  Acc@5: 87.5000 (90.6171)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1990/4579]  eta: 0:15:19  Lr: 0.001875  Loss: -0.2445  Acc@1: 62.5000 (62.0480)  Acc@5: 93.7500 (90.6234)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2000/4579]  eta: 0:15:16  Lr: 0.001875  Loss: -0.3924  Acc@1: 62.5000 (62.0471)  Acc@5: 93.7500 (90.6234)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2010/4579]  eta: 0:15:12  Lr: 0.001875  Loss: -0.0437  Acc@1: 56.2500 (62.0462)  Acc@5: 93.7500 (90.6266)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2020/4579]  eta: 0:15:08  Lr: 0.001875  Loss: -0.4027  Acc@1: 68.7500 (62.0670)  Acc@5: 93.7500 (90.6420)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2030/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 0.7084  Acc@1: 62.5000 (62.0415)  Acc@5: 93.7500 (90.6235)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2040/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.0652  Acc@1: 56.2500 (62.0284)  Acc@5: 87.5000 (90.6051)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2050/4579]  eta: 0:14:57  Lr: 0.001875  Loss: -0.6212  Acc@1: 56.2500 (62.0002)  Acc@5: 87.5000 (90.6204)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2060/4579]  eta: 0:14:54  Lr: 0.001875  Loss: 0.1575  Acc@1: 62.5000 (62.0148)  Acc@5: 87.5000 (90.6174)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2070/4579]  eta: 0:14:50  Lr: 0.001875  Loss: -0.4310  Acc@1: 62.5000 (62.0202)  Acc@5: 87.5000 (90.6205)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2080/4579]  eta: 0:14:46  Lr: 0.001875  Loss: 0.2013  Acc@1: 62.5000 (62.0315)  Acc@5: 93.7500 (90.6295)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2090/4579]  eta: 0:14:43  Lr: 0.001875  Loss: -0.6051  Acc@1: 68.7500 (62.0487)  Acc@5: 93.7500 (90.6325)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2100/4579]  eta: 0:14:39  Lr: 0.001875  Loss: -0.5335  Acc@1: 68.7500 (62.0657)  Acc@5: 87.5000 (90.6235)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2110/4579]  eta: 0:14:36  Lr: 0.001875  Loss: -0.4882  Acc@1: 68.7500 (62.0914)  Acc@5: 93.7500 (90.6383)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2120/4579]  eta: 0:14:32  Lr: 0.001875  Loss: -0.7312  Acc@1: 68.7500 (62.1258)  Acc@5: 93.7500 (90.6648)  time: 0.3560  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [2130/4579]  eta: 0:14:29  Lr: 0.001875  Loss: 0.2908  Acc@1: 62.5000 (62.1246)  Acc@5: 93.7500 (90.6646)  time: 0.3555  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [2140/4579]  eta: 0:14:25  Lr: 0.001875  Loss: -0.1206  Acc@1: 62.5000 (62.1030)  Acc@5: 87.5000 (90.6557)  time: 0.3554  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2150/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.8375  Acc@1: 56.2500 (62.0903)  Acc@5: 87.5000 (90.6468)  time: 0.3572  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2160/4579]  eta: 0:14:18  Lr: 0.001875  Loss: 0.0591  Acc@1: 62.5000 (62.0951)  Acc@5: 87.5000 (90.6554)  time: 0.3568  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2170/4579]  eta: 0:14:14  Lr: 0.001875  Loss: 0.1383  Acc@1: 56.2500 (62.0653)  Acc@5: 87.5000 (90.6495)  time: 0.3548  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2180/4579]  eta: 0:14:11  Lr: 0.001875  Loss: -0.5184  Acc@1: 56.2500 (62.0415)  Acc@5: 87.5000 (90.6551)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2190/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.2000  Acc@1: 62.5000 (62.0664)  Acc@5: 93.7500 (90.6692)  time: 0.3584  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2200/4579]  eta: 0:14:04  Lr: 0.001875  Loss: -0.2267  Acc@1: 68.7500 (62.0797)  Acc@5: 93.7500 (90.6605)  time: 0.3605  data: 0.0037  max mem: 2500
Train: Epoch[2/5]  [2210/4579]  eta: 0:14:00  Lr: 0.001875  Loss: -0.2414  Acc@1: 68.7500 (62.1014)  Acc@5: 93.7500 (90.6745)  time: 0.3577  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [2220/4579]  eta: 0:13:57  Lr: 0.001875  Loss: 0.2084  Acc@1: 62.5000 (62.0835)  Acc@5: 93.7500 (90.6517)  time: 0.3560  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2230/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.4512  Acc@1: 56.2500 (62.0714)  Acc@5: 87.5000 (90.6432)  time: 0.3555  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2240/4579]  eta: 0:13:50  Lr: 0.001875  Loss: 0.3527  Acc@1: 56.2500 (62.0426)  Acc@5: 87.5000 (90.6292)  time: 0.3540  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2250/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.4543  Acc@1: 56.2500 (62.0308)  Acc@5: 87.5000 (90.6208)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2260/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.1678  Acc@1: 62.5000 (62.0301)  Acc@5: 87.5000 (90.6153)  time: 0.3560  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2270/4579]  eta: 0:13:39  Lr: 0.001875  Loss: -0.3424  Acc@1: 62.5000 (62.0266)  Acc@5: 93.7500 (90.6154)  time: 0.3565  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2280/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.3146  Acc@1: 62.5000 (62.0342)  Acc@5: 93.7500 (90.6236)  time: 0.3565  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2290/4579]  eta: 0:13:32  Lr: 0.001875  Loss: -0.5096  Acc@1: 62.5000 (62.0444)  Acc@5: 93.7500 (90.6345)  time: 0.3563  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2300/4579]  eta: 0:13:28  Lr: 0.001875  Loss: -0.7004  Acc@1: 62.5000 (62.0437)  Acc@5: 93.7500 (90.6236)  time: 0.3552  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2310/4579]  eta: 0:13:25  Lr: 0.001875  Loss: -0.6191  Acc@1: 56.2500 (62.0484)  Acc@5: 93.7500 (90.6426)  time: 0.3557  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2320/4579]  eta: 0:13:21  Lr: 0.001875  Loss: -0.2562  Acc@1: 62.5000 (62.0692)  Acc@5: 93.7500 (90.6533)  time: 0.3540  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2330/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.3539  Acc@1: 62.5000 (62.0630)  Acc@5: 93.7500 (90.6451)  time: 0.3528  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2340/4579]  eta: 0:13:14  Lr: 0.001875  Loss: 0.5648  Acc@1: 56.2500 (62.0435)  Acc@5: 93.7500 (90.6530)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2350/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.2515  Acc@1: 62.5000 (62.0560)  Acc@5: 93.7500 (90.6503)  time: 0.3552  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2360/4579]  eta: 0:13:07  Lr: 0.001875  Loss: -0.8127  Acc@1: 62.5000 (62.0712)  Acc@5: 93.7500 (90.6793)  time: 0.3554  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2370/4579]  eta: 0:13:04  Lr: 0.001875  Loss: 0.2740  Acc@1: 62.5000 (62.0993)  Acc@5: 93.7500 (90.6843)  time: 0.3556  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2380/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.2850  Acc@1: 62.5000 (62.1010)  Acc@5: 87.5000 (90.6762)  time: 0.3563  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2390/4579]  eta: 0:12:56  Lr: 0.001875  Loss: -0.6149  Acc@1: 62.5000 (62.1001)  Acc@5: 87.5000 (90.6551)  time: 0.3535  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2400/4579]  eta: 0:12:53  Lr: 0.001875  Loss: -0.3816  Acc@1: 62.5000 (62.1304)  Acc@5: 87.5000 (90.6653)  time: 0.3578  data: 0.0029  max mem: 2500
Train: Epoch[2/5]  [2410/4579]  eta: 0:12:49  Lr: 0.001875  Loss: 0.1133  Acc@1: 62.5000 (62.1008)  Acc@5: 93.7500 (90.6678)  time: 0.3594  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [2420/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.6296  Acc@1: 62.5000 (62.1205)  Acc@5: 93.7500 (90.6831)  time: 0.3554  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2430/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.3858  Acc@1: 62.5000 (62.1169)  Acc@5: 93.7500 (90.6906)  time: 0.3546  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2440/4579]  eta: 0:12:39  Lr: 0.001875  Loss: 0.3475  Acc@1: 62.5000 (62.1031)  Acc@5: 93.7500 (90.6903)  time: 0.3632  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [2450/4579]  eta: 0:12:35  Lr: 0.001875  Loss: 0.1847  Acc@1: 62.5000 (62.1124)  Acc@5: 87.5000 (90.6926)  time: 0.3655  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [2460/4579]  eta: 0:12:32  Lr: 0.001875  Loss: -0.6078  Acc@1: 68.7500 (62.1343)  Acc@5: 93.7500 (90.6923)  time: 0.3620  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2470/4579]  eta: 0:12:28  Lr: 0.001875  Loss: -0.1295  Acc@1: 68.7500 (62.1459)  Acc@5: 87.5000 (90.6743)  time: 0.3652  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [2480/4579]  eta: 0:12:25  Lr: 0.001875  Loss: -0.1598  Acc@1: 62.5000 (62.1448)  Acc@5: 87.5000 (90.6766)  time: 0.3585  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2490/4579]  eta: 0:12:21  Lr: 0.001875  Loss: -0.3379  Acc@1: 62.5000 (62.1588)  Acc@5: 93.7500 (90.6840)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2500/4579]  eta: 0:12:18  Lr: 0.001875  Loss: -0.0841  Acc@1: 62.5000 (62.1651)  Acc@5: 93.7500 (90.6862)  time: 0.3547  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2510/4579]  eta: 0:12:14  Lr: 0.001875  Loss: 0.1576  Acc@1: 56.2500 (62.1590)  Acc@5: 93.7500 (90.6934)  time: 0.3555  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2520/4579]  eta: 0:12:11  Lr: 0.001875  Loss: -0.0410  Acc@1: 62.5000 (62.1604)  Acc@5: 93.7500 (90.6981)  time: 0.3530  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2530/4579]  eta: 0:12:07  Lr: 0.001875  Loss: -0.2546  Acc@1: 62.5000 (62.1493)  Acc@5: 93.7500 (90.6954)  time: 0.3529  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2540/4579]  eta: 0:12:04  Lr: 0.001875  Loss: -0.1650  Acc@1: 62.5000 (62.1532)  Acc@5: 87.5000 (90.6828)  time: 0.3542  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2550/4579]  eta: 0:12:00  Lr: 0.001875  Loss: 0.5353  Acc@1: 62.5000 (62.1472)  Acc@5: 87.5000 (90.6752)  time: 0.3557  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2560/4579]  eta: 0:11:56  Lr: 0.001875  Loss: -0.0161  Acc@1: 62.5000 (62.1266)  Acc@5: 87.5000 (90.6799)  time: 0.3538  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2570/4579]  eta: 0:11:53  Lr: 0.001875  Loss: -0.2704  Acc@1: 62.5000 (62.1329)  Acc@5: 93.7500 (90.6919)  time: 0.3538  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2580/4579]  eta: 0:11:49  Lr: 0.001875  Loss: -0.0328  Acc@1: 62.5000 (62.1416)  Acc@5: 93.7500 (90.7110)  time: 0.3553  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2590/4579]  eta: 0:11:46  Lr: 0.001875  Loss: -0.1541  Acc@1: 68.7500 (62.1695)  Acc@5: 93.7500 (90.7251)  time: 0.3556  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2600/4579]  eta: 0:11:42  Lr: 0.001875  Loss: -0.0801  Acc@1: 68.7500 (62.1660)  Acc@5: 93.7500 (90.7223)  time: 0.3545  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2610/4579]  eta: 0:11:39  Lr: 0.001875  Loss: -0.2498  Acc@1: 62.5000 (62.1745)  Acc@5: 93.7500 (90.7267)  time: 0.3539  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2620/4579]  eta: 0:11:35  Lr: 0.001875  Loss: 0.2304  Acc@1: 62.5000 (62.1805)  Acc@5: 93.7500 (90.7287)  time: 0.3534  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2630/4579]  eta: 0:11:32  Lr: 0.001875  Loss: 0.0622  Acc@1: 62.5000 (62.1746)  Acc@5: 93.7500 (90.7331)  time: 0.3532  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2640/4579]  eta: 0:11:28  Lr: 0.001875  Loss: -0.3566  Acc@1: 62.5000 (62.1829)  Acc@5: 93.7500 (90.7445)  time: 0.3536  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2650/4579]  eta: 0:11:24  Lr: 0.001875  Loss: -0.6067  Acc@1: 62.5000 (62.1959)  Acc@5: 93.7500 (90.7535)  time: 0.3571  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2660/4579]  eta: 0:11:21  Lr: 0.001875  Loss: 0.0276  Acc@1: 62.5000 (62.1853)  Acc@5: 93.7500 (90.7624)  time: 0.3588  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2670/4579]  eta: 0:11:17  Lr: 0.001875  Loss: -0.1408  Acc@1: 62.5000 (62.1818)  Acc@5: 93.7500 (90.7595)  time: 0.3549  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2680/4579]  eta: 0:11:14  Lr: 0.001875  Loss: 0.1095  Acc@1: 62.5000 (62.1666)  Acc@5: 87.5000 (90.7567)  time: 0.3554  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2690/4579]  eta: 0:11:10  Lr: 0.001875  Loss: 0.1128  Acc@1: 56.2500 (62.1539)  Acc@5: 87.5000 (90.7469)  time: 0.3563  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [2700/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.1749  Acc@1: 62.5000 (62.1691)  Acc@5: 87.5000 (90.7465)  time: 0.3544  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [2710/4579]  eta: 0:11:03  Lr: 0.001875  Loss: 0.0228  Acc@1: 62.5000 (62.1657)  Acc@5: 93.7500 (90.7576)  time: 0.3543  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [2720/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.2353  Acc@1: 62.5000 (62.1715)  Acc@5: 93.7500 (90.7479)  time: 0.3559  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2730/4579]  eta: 0:10:56  Lr: 0.001875  Loss: 0.0381  Acc@1: 62.5000 (62.1750)  Acc@5: 93.7500 (90.7589)  time: 0.3543  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2740/4579]  eta: 0:10:52  Lr: 0.001875  Loss: -0.1580  Acc@1: 62.5000 (62.1580)  Acc@5: 93.7500 (90.7356)  time: 0.3537  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2750/4579]  eta: 0:10:49  Lr: 0.001875  Loss: 0.5996  Acc@1: 56.2500 (62.1501)  Acc@5: 87.5000 (90.7352)  time: 0.3551  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2760/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.8896  Acc@1: 62.5000 (62.1740)  Acc@5: 93.7500 (90.7438)  time: 0.3562  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2770/4579]  eta: 0:10:42  Lr: 0.001875  Loss: 0.0935  Acc@1: 62.5000 (62.1527)  Acc@5: 87.5000 (90.7366)  time: 0.3618  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2780/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 0.2317  Acc@1: 62.5000 (62.1517)  Acc@5: 87.5000 (90.7340)  time: 0.3566  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2790/4579]  eta: 0:10:35  Lr: 0.001875  Loss: -0.0701  Acc@1: 62.5000 (62.1439)  Acc@5: 93.7500 (90.7448)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2800/4579]  eta: 0:10:31  Lr: 0.001875  Loss: -0.3424  Acc@1: 62.5000 (62.1452)  Acc@5: 93.7500 (90.7600)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2810/4579]  eta: 0:10:28  Lr: 0.001875  Loss: -0.6087  Acc@1: 62.5000 (62.1643)  Acc@5: 93.7500 (90.7773)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2820/4579]  eta: 0:10:24  Lr: 0.001875  Loss: -0.2164  Acc@1: 62.5000 (62.1699)  Acc@5: 93.7500 (90.7790)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2830/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.2659  Acc@1: 68.7500 (62.1821)  Acc@5: 93.7500 (90.7873)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2840/4579]  eta: 0:10:17  Lr: 0.001875  Loss: -0.4131  Acc@1: 62.5000 (62.1832)  Acc@5: 93.7500 (90.7713)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2850/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.5474  Acc@1: 62.5000 (62.1997)  Acc@5: 87.5000 (90.7752)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2860/4579]  eta: 0:10:10  Lr: 0.001875  Loss: 0.1976  Acc@1: 68.7500 (62.2160)  Acc@5: 93.7500 (90.7637)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2870/4579]  eta: 0:10:06  Lr: 0.001875  Loss: 0.4254  Acc@1: 68.7500 (62.2257)  Acc@5: 93.7500 (90.7654)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2880/4579]  eta: 0:10:02  Lr: 0.001875  Loss: 0.0065  Acc@1: 62.5000 (62.2267)  Acc@5: 93.7500 (90.7671)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2890/4579]  eta: 0:09:59  Lr: 0.001875  Loss: -0.4373  Acc@1: 56.2500 (62.2125)  Acc@5: 93.7500 (90.7666)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2900/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.1793  Acc@1: 62.5000 (62.2242)  Acc@5: 87.5000 (90.7618)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2910/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.3912  Acc@1: 62.5000 (62.2187)  Acc@5: 100.0000 (90.7785)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2920/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.0731  Acc@1: 62.5000 (62.2197)  Acc@5: 93.7500 (90.7823)  time: 0.3551  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [2930/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.1991  Acc@1: 68.7500 (62.2335)  Acc@5: 93.7500 (90.7860)  time: 0.3583  data: 0.0039  max mem: 2500
Train: Epoch[2/5]  [2940/4579]  eta: 0:09:41  Lr: 0.001875  Loss: 0.1519  Acc@1: 56.2500 (62.2195)  Acc@5: 93.7500 (90.7876)  time: 0.3583  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2950/4579]  eta: 0:09:37  Lr: 0.001875  Loss: 0.1433  Acc@1: 56.2500 (62.2120)  Acc@5: 87.5000 (90.7849)  time: 0.3563  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [2960/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.4911  Acc@1: 56.2500 (62.2045)  Acc@5: 87.5000 (90.7844)  time: 0.3558  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [2970/4579]  eta: 0:09:30  Lr: 0.001875  Loss: -0.8473  Acc@1: 62.5000 (62.2181)  Acc@5: 93.7500 (90.7859)  time: 0.3588  data: 0.0042  max mem: 2500
Train: Epoch[2/5]  [2980/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.2366  Acc@1: 62.5000 (62.2044)  Acc@5: 93.7500 (90.7917)  time: 0.3603  data: 0.0055  max mem: 2500
Train: Epoch[2/5]  [2990/4579]  eta: 0:09:23  Lr: 0.001875  Loss: -0.4159  Acc@1: 62.5000 (62.2075)  Acc@5: 93.7500 (90.7974)  time: 0.3578  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [3000/4579]  eta: 0:09:20  Lr: 0.001875  Loss: -0.5117  Acc@1: 68.7500 (62.2230)  Acc@5: 93.7500 (90.7968)  time: 0.3583  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [3010/4579]  eta: 0:09:16  Lr: 0.001875  Loss: -0.2259  Acc@1: 62.5000 (62.2136)  Acc@5: 87.5000 (90.7983)  time: 0.3588  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [3020/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.5191  Acc@1: 56.2500 (62.2042)  Acc@5: 93.7500 (90.7977)  time: 0.3550  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3030/4579]  eta: 0:09:09  Lr: 0.001875  Loss: -0.1940  Acc@1: 62.5000 (62.2258)  Acc@5: 93.7500 (90.7992)  time: 0.3543  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3040/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.5454  Acc@1: 62.5000 (62.2328)  Acc@5: 93.7500 (90.8028)  time: 0.3548  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3050/4579]  eta: 0:09:02  Lr: 0.001875  Loss: 0.0974  Acc@1: 62.5000 (62.2398)  Acc@5: 87.5000 (90.8104)  time: 0.3554  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3060/4579]  eta: 0:08:59  Lr: 0.001875  Loss: -0.5891  Acc@1: 62.5000 (62.2591)  Acc@5: 93.7500 (90.8200)  time: 0.3558  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3070/4579]  eta: 0:08:55  Lr: 0.001875  Loss: -1.0179  Acc@1: 62.5000 (62.2680)  Acc@5: 93.7500 (90.8214)  time: 0.3583  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3080/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.2957  Acc@1: 62.5000 (62.2748)  Acc@5: 87.5000 (90.8167)  time: 0.3639  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3090/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -0.2396  Acc@1: 62.5000 (62.2796)  Acc@5: 87.5000 (90.8161)  time: 0.3688  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [3100/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.3952  Acc@1: 62.5000 (62.2723)  Acc@5: 93.7500 (90.8175)  time: 0.3705  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [3110/4579]  eta: 0:08:41  Lr: 0.001875  Loss: -0.0632  Acc@1: 56.2500 (62.2730)  Acc@5: 87.5000 (90.8149)  time: 0.3613  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [3120/4579]  eta: 0:08:37  Lr: 0.001875  Loss: -0.1239  Acc@1: 62.5000 (62.2717)  Acc@5: 87.5000 (90.8162)  time: 0.3565  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3130/4579]  eta: 0:08:34  Lr: 0.001875  Loss: -0.4410  Acc@1: 62.5000 (62.2824)  Acc@5: 93.7500 (90.8156)  time: 0.3566  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3140/4579]  eta: 0:08:30  Lr: 0.001875  Loss: -0.2758  Acc@1: 68.7500 (62.2931)  Acc@5: 93.7500 (90.8210)  time: 0.3545  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3150/4579]  eta: 0:08:27  Lr: 0.001875  Loss: 0.2096  Acc@1: 62.5000 (62.2917)  Acc@5: 87.5000 (90.8184)  time: 0.3568  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3160/4579]  eta: 0:08:23  Lr: 0.001875  Loss: -0.7229  Acc@1: 62.5000 (62.3062)  Acc@5: 87.5000 (90.8217)  time: 0.3566  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3170/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.1598  Acc@1: 68.7500 (62.3226)  Acc@5: 93.7500 (90.8231)  time: 0.3548  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3180/4579]  eta: 0:08:16  Lr: 0.001875  Loss: 0.6980  Acc@1: 68.7500 (62.3133)  Acc@5: 93.7500 (90.8284)  time: 0.3571  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [3190/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.3953  Acc@1: 62.5000 (62.3218)  Acc@5: 93.7500 (90.8316)  time: 0.3605  data: 0.0039  max mem: 2500
Train: Epoch[2/5]  [3200/4579]  eta: 0:08:09  Lr: 0.001875  Loss: -0.4933  Acc@1: 62.5000 (62.3477)  Acc@5: 93.7500 (90.8329)  time: 0.3578  data: 0.0029  max mem: 2500
Train: Epoch[2/5]  [3210/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.6496  Acc@1: 62.5000 (62.3521)  Acc@5: 93.7500 (90.8342)  time: 0.3555  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3220/4579]  eta: 0:08:02  Lr: 0.001875  Loss: -0.2067  Acc@1: 62.5000 (62.3603)  Acc@5: 93.7500 (90.8433)  time: 0.3517  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3230/4579]  eta: 0:07:58  Lr: 0.001875  Loss: -0.0202  Acc@1: 62.5000 (62.3414)  Acc@5: 93.7500 (90.8542)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3240/4579]  eta: 0:07:55  Lr: 0.001875  Loss: 0.2349  Acc@1: 62.5000 (62.3496)  Acc@5: 93.7500 (90.8497)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3250/4579]  eta: 0:07:51  Lr: 0.001875  Loss: -0.1422  Acc@1: 62.5000 (62.3462)  Acc@5: 93.7500 (90.8470)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3260/4579]  eta: 0:07:48  Lr: 0.001875  Loss: -0.2973  Acc@1: 56.2500 (62.3371)  Acc@5: 87.5000 (90.8349)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3270/4579]  eta: 0:07:44  Lr: 0.001875  Loss: -0.1983  Acc@1: 62.5000 (62.3357)  Acc@5: 87.5000 (90.8342)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3280/4579]  eta: 0:07:41  Lr: 0.001875  Loss: -0.1482  Acc@1: 62.5000 (62.3362)  Acc@5: 87.5000 (90.8355)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3290/4579]  eta: 0:07:37  Lr: 0.001875  Loss: -0.0036  Acc@1: 62.5000 (62.3557)  Acc@5: 93.7500 (90.8443)  time: 0.3617  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3300/4579]  eta: 0:07:34  Lr: 0.001875  Loss: -0.3286  Acc@1: 62.5000 (62.3637)  Acc@5: 93.7500 (90.8569)  time: 0.3651  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [3310/4579]  eta: 0:07:30  Lr: 0.001875  Loss: 0.4214  Acc@1: 68.7500 (62.3716)  Acc@5: 93.7500 (90.8543)  time: 0.3609  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [3320/4579]  eta: 0:07:26  Lr: 0.001875  Loss: -0.7082  Acc@1: 62.5000 (62.3871)  Acc@5: 93.7500 (90.8631)  time: 0.3519  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3330/4579]  eta: 0:07:23  Lr: 0.001875  Loss: -0.4446  Acc@1: 62.5000 (62.3874)  Acc@5: 93.7500 (90.8661)  time: 0.3474  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3340/4579]  eta: 0:07:19  Lr: 0.001875  Loss: -0.3705  Acc@1: 62.5000 (62.3878)  Acc@5: 87.5000 (90.8654)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3350/4579]  eta: 0:07:16  Lr: 0.001875  Loss: 0.1666  Acc@1: 62.5000 (62.3806)  Acc@5: 93.7500 (90.8647)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:12  Lr: 0.001875  Loss: 0.0737  Acc@1: 56.2500 (62.3735)  Acc@5: 87.5000 (90.8509)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3370/4579]  eta: 0:07:09  Lr: 0.001875  Loss: 0.1496  Acc@1: 56.2500 (62.3758)  Acc@5: 87.5000 (90.8503)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3380/4579]  eta: 0:07:05  Lr: 0.001875  Loss: -0.5614  Acc@1: 56.2500 (62.3688)  Acc@5: 87.5000 (90.8348)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3390/4579]  eta: 0:07:01  Lr: 0.001875  Loss: 0.3036  Acc@1: 56.2500 (62.3618)  Acc@5: 87.5000 (90.8213)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3400/4579]  eta: 0:06:58  Lr: 0.001875  Loss: 0.3793  Acc@1: 56.2500 (62.3603)  Acc@5: 87.5000 (90.8170)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3410/4579]  eta: 0:06:54  Lr: 0.001875  Loss: -0.3473  Acc@1: 62.5000 (62.3498)  Acc@5: 87.5000 (90.8146)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3420/4579]  eta: 0:06:51  Lr: 0.001875  Loss: -0.3650  Acc@1: 62.5000 (62.3648)  Acc@5: 87.5000 (90.8177)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3430/4579]  eta: 0:06:47  Lr: 0.001875  Loss: 0.0870  Acc@1: 68.7500 (62.3634)  Acc@5: 87.5000 (90.8099)  time: 0.3565  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [3440/4579]  eta: 0:06:44  Lr: 0.001875  Loss: -0.1690  Acc@1: 62.5000 (62.3565)  Acc@5: 87.5000 (90.8021)  time: 0.3581  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [3450/4579]  eta: 0:06:40  Lr: 0.001875  Loss: -0.3115  Acc@1: 62.5000 (62.3624)  Acc@5: 87.5000 (90.8034)  time: 0.3564  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3460/4579]  eta: 0:06:36  Lr: 0.001875  Loss: -0.1976  Acc@1: 62.5000 (62.3646)  Acc@5: 87.5000 (90.8047)  time: 0.3535  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3470/4579]  eta: 0:06:33  Lr: 0.001875  Loss: 0.3936  Acc@1: 56.2500 (62.3397)  Acc@5: 87.5000 (90.7970)  time: 0.3559  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3480/4579]  eta: 0:06:29  Lr: 0.001875  Loss: -0.2344  Acc@1: 56.2500 (62.3240)  Acc@5: 87.5000 (90.7893)  time: 0.3559  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3490/4579]  eta: 0:06:26  Lr: 0.001875  Loss: -0.4498  Acc@1: 62.5000 (62.3353)  Acc@5: 87.5000 (90.7888)  time: 0.3548  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3500/4579]  eta: 0:06:22  Lr: 0.001875  Loss: 0.1413  Acc@1: 62.5000 (62.3197)  Acc@5: 87.5000 (90.7794)  time: 0.3554  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3510/4579]  eta: 0:06:19  Lr: 0.001875  Loss: 0.2224  Acc@1: 62.5000 (62.3202)  Acc@5: 87.5000 (90.7808)  time: 0.3563  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:15  Lr: 0.001875  Loss: 0.2158  Acc@1: 62.5000 (62.3189)  Acc@5: 93.7500 (90.7803)  time: 0.3549  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:12  Lr: 0.001875  Loss: -0.4110  Acc@1: 56.2500 (62.3195)  Acc@5: 93.7500 (90.7834)  time: 0.3539  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3540/4579]  eta: 0:06:08  Lr: 0.001875  Loss: -0.0597  Acc@1: 62.5000 (62.3429)  Acc@5: 93.7500 (90.7865)  time: 0.3560  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [3550/4579]  eta: 0:06:05  Lr: 0.001875  Loss: -0.3396  Acc@1: 62.5000 (62.3416)  Acc@5: 87.5000 (90.7896)  time: 0.3553  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3560/4579]  eta: 0:06:01  Lr: 0.001875  Loss: -0.1607  Acc@1: 62.5000 (62.3596)  Acc@5: 93.7500 (90.7926)  time: 0.3551  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [3570/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.2810  Acc@1: 68.7500 (62.3757)  Acc@5: 93.7500 (90.7904)  time: 0.3572  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [3580/4579]  eta: 0:05:54  Lr: 0.001875  Loss: -0.0602  Acc@1: 68.7500 (62.3900)  Acc@5: 93.7500 (90.7934)  time: 0.3666  data: 0.0036  max mem: 2500
Train: Epoch[2/5]  [3590/4579]  eta: 0:05:50  Lr: 0.001875  Loss: 0.1403  Acc@1: 62.5000 (62.3869)  Acc@5: 87.5000 (90.7877)  time: 0.3691  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [3600/4579]  eta: 0:05:47  Lr: 0.001875  Loss: 0.2127  Acc@1: 56.2500 (62.3611)  Acc@5: 87.5000 (90.7908)  time: 0.3660  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3610/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.4606  Acc@1: 62.5000 (62.3719)  Acc@5: 93.7500 (90.7920)  time: 0.3625  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3620/4579]  eta: 0:05:40  Lr: 0.001875  Loss: -0.0787  Acc@1: 62.5000 (62.3688)  Acc@5: 93.7500 (90.8002)  time: 0.3565  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3630/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.2117  Acc@1: 62.5000 (62.3726)  Acc@5: 93.7500 (90.8049)  time: 0.3567  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3640/4579]  eta: 0:05:33  Lr: 0.001875  Loss: -0.5178  Acc@1: 62.5000 (62.3850)  Acc@5: 93.7500 (90.8078)  time: 0.3575  data: 0.0038  max mem: 2500
Train: Epoch[2/5]  [3650/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.4015  Acc@1: 68.7500 (62.3973)  Acc@5: 93.7500 (90.8176)  time: 0.3575  data: 0.0032  max mem: 2500
Train: Epoch[2/5]  [3660/4579]  eta: 0:05:26  Lr: 0.001875  Loss: 0.7937  Acc@1: 62.5000 (62.3907)  Acc@5: 87.5000 (90.8000)  time: 0.3565  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.1791  Acc@1: 62.5000 (62.3774)  Acc@5: 87.5000 (90.7961)  time: 0.3566  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:19  Lr: 0.001875  Loss: -0.3147  Acc@1: 62.5000 (62.3794)  Acc@5: 87.5000 (90.7939)  time: 0.3589  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.1785  Acc@1: 62.5000 (62.3849)  Acc@5: 87.5000 (90.7986)  time: 0.3586  data: 0.0046  max mem: 2500
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:12  Lr: 0.001875  Loss: -0.5425  Acc@1: 62.5000 (62.3784)  Acc@5: 93.7500 (90.7981)  time: 0.3556  data: 0.0037  max mem: 2500
Train: Epoch[2/5]  [3710/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.2596  Acc@1: 56.2500 (62.3737)  Acc@5: 93.7500 (90.8010)  time: 0.3563  data: 0.0032  max mem: 2500
Train: Epoch[2/5]  [3720/4579]  eta: 0:05:04  Lr: 0.001875  Loss: 0.0532  Acc@1: 62.5000 (62.3723)  Acc@5: 93.7500 (90.8056)  time: 0.3569  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [3730/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.1798  Acc@1: 62.5000 (62.3727)  Acc@5: 93.7500 (90.8084)  time: 0.3565  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3740/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.4541  Acc@1: 62.5000 (62.3764)  Acc@5: 93.7500 (90.8029)  time: 0.3575  data: 0.0039  max mem: 2500
Train: Epoch[2/5]  [3750/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.2454  Acc@1: 68.7500 (62.3884)  Acc@5: 93.7500 (90.8141)  time: 0.3617  data: 0.0037  max mem: 2500
Train: Epoch[2/5]  [3760/4579]  eta: 0:04:50  Lr: 0.001875  Loss: 0.1803  Acc@1: 68.7500 (62.3953)  Acc@5: 93.7500 (90.8169)  time: 0.3574  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3770/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.3436  Acc@1: 68.7500 (62.4055)  Acc@5: 93.7500 (90.8280)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3780/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.2981  Acc@1: 62.5000 (62.3975)  Acc@5: 93.7500 (90.8325)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3790/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.2432  Acc@1: 62.5000 (62.4077)  Acc@5: 93.7500 (90.8418)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3800/4579]  eta: 0:04:36  Lr: 0.001875  Loss: 0.0618  Acc@1: 62.5000 (62.3931)  Acc@5: 93.7500 (90.8494)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3810/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.4748  Acc@1: 56.2500 (62.3868)  Acc@5: 93.7500 (90.8407)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.1509  Acc@1: 62.5000 (62.4002)  Acc@5: 87.5000 (90.8434)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:25  Lr: 0.001875  Loss: -0.1339  Acc@1: 68.7500 (62.4086)  Acc@5: 87.5000 (90.8379)  time: 0.3542  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:22  Lr: 0.001875  Loss: -0.0063  Acc@1: 62.5000 (62.4007)  Acc@5: 87.5000 (90.8341)  time: 0.3625  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:18  Lr: 0.001875  Loss: 0.0979  Acc@1: 62.5000 (62.4156)  Acc@5: 93.7500 (90.8352)  time: 0.3635  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 0.1935  Acc@1: 68.7500 (62.4304)  Acc@5: 87.5000 (90.8265)  time: 0.3558  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:11  Lr: 0.001875  Loss: -0.0161  Acc@1: 68.7500 (62.4499)  Acc@5: 87.5000 (90.8325)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.0969  Acc@1: 68.7500 (62.4646)  Acc@5: 93.7500 (90.8416)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3890/4579]  eta: 0:04:04  Lr: 0.001875  Loss: -0.1932  Acc@1: 68.7500 (62.4711)  Acc@5: 93.7500 (90.8330)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3900/4579]  eta: 0:04:00  Lr: 0.001875  Loss: -0.3647  Acc@1: 62.5000 (62.4551)  Acc@5: 87.5000 (90.8357)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3910/4579]  eta: 0:03:57  Lr: 0.001875  Loss: -0.1027  Acc@1: 62.5000 (62.4616)  Acc@5: 93.7500 (90.8319)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3920/4579]  eta: 0:03:53  Lr: 0.001875  Loss: -0.1908  Acc@1: 62.5000 (62.4617)  Acc@5: 87.5000 (90.8346)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3930/4579]  eta: 0:03:50  Lr: 0.001875  Loss: -0.3494  Acc@1: 62.5000 (62.4618)  Acc@5: 87.5000 (90.8325)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3940/4579]  eta: 0:03:46  Lr: 0.001875  Loss: -0.4955  Acc@1: 62.5000 (62.4794)  Acc@5: 87.5000 (90.8367)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3950/4579]  eta: 0:03:43  Lr: 0.001875  Loss: -0.1697  Acc@1: 62.5000 (62.4810)  Acc@5: 93.7500 (90.8346)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3960/4579]  eta: 0:03:39  Lr: 0.001875  Loss: -0.0734  Acc@1: 62.5000 (62.4826)  Acc@5: 87.5000 (90.8246)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.6248  Acc@1: 62.5000 (62.4984)  Acc@5: 87.5000 (90.8335)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:32  Lr: 0.001875  Loss: -0.6153  Acc@1: 62.5000 (62.4953)  Acc@5: 93.7500 (90.8346)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:28  Lr: 0.001875  Loss: -0.2066  Acc@1: 56.2500 (62.4843)  Acc@5: 87.5000 (90.8341)  time: 0.3564  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:25  Lr: 0.001875  Loss: -0.7908  Acc@1: 56.2500 (62.4938)  Acc@5: 93.7500 (90.8492)  time: 0.3582  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:21  Lr: 0.001875  Loss: 0.0015  Acc@1: 62.5000 (62.5047)  Acc@5: 93.7500 (90.8517)  time: 0.3597  data: 0.0036  max mem: 2500
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:18  Lr: 0.001875  Loss: 0.2295  Acc@1: 62.5000 (62.4938)  Acc@5: 93.7500 (90.8558)  time: 0.3602  data: 0.0037  max mem: 2500
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:14  Lr: 0.001875  Loss: -0.0904  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (90.8583)  time: 0.3564  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:11  Lr: 0.001875  Loss: -0.3315  Acc@1: 62.5000 (62.5062)  Acc@5: 87.5000 (90.8609)  time: 0.3572  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:07  Lr: 0.001875  Loss: -0.3105  Acc@1: 62.5000 (62.5108)  Acc@5: 93.7500 (90.8603)  time: 0.3584  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [4060/4579]  eta: 0:03:04  Lr: 0.001875  Loss: -0.1457  Acc@1: 62.5000 (62.5108)  Acc@5: 93.7500 (90.8643)  time: 0.3571  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4070/4579]  eta: 0:03:00  Lr: 0.001875  Loss: -0.1118  Acc@1: 62.5000 (62.5138)  Acc@5: 93.7500 (90.8745)  time: 0.3585  data: 0.0036  max mem: 2500
Train: Epoch[2/5]  [4080/4579]  eta: 0:02:57  Lr: 0.001875  Loss: -0.2965  Acc@1: 62.5000 (62.5138)  Acc@5: 93.7500 (90.8785)  time: 0.3575  data: 0.0029  max mem: 2500
Train: Epoch[2/5]  [4090/4579]  eta: 0:02:53  Lr: 0.001875  Loss: -0.0001  Acc@1: 62.5000 (62.5137)  Acc@5: 87.5000 (90.8778)  time: 0.3564  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [4100/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 0.1981  Acc@1: 62.5000 (62.5152)  Acc@5: 87.5000 (90.8757)  time: 0.3573  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [4110/4579]  eta: 0:02:46  Lr: 0.001875  Loss: -0.2831  Acc@1: 62.5000 (62.5365)  Acc@5: 93.7500 (90.8857)  time: 0.3549  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4120/4579]  eta: 0:02:42  Lr: 0.001875  Loss: -0.7381  Acc@1: 62.5000 (62.5394)  Acc@5: 93.7500 (90.8927)  time: 0.3555  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:39  Lr: 0.001875  Loss: 0.1644  Acc@1: 62.5000 (62.5287)  Acc@5: 93.7500 (90.8996)  time: 0.3585  data: 0.0040  max mem: 2500
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:35  Lr: 0.001875  Loss: -0.1636  Acc@1: 62.5000 (62.5423)  Acc@5: 93.7500 (90.9020)  time: 0.3584  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:32  Lr: 0.001875  Loss: -0.2807  Acc@1: 56.2500 (62.5316)  Acc@5: 93.7500 (90.8983)  time: 0.3570  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:28  Lr: 0.001875  Loss: -0.5841  Acc@1: 56.2500 (62.5451)  Acc@5: 93.7500 (90.9006)  time: 0.3578  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.3406  Acc@1: 62.5000 (62.5480)  Acc@5: 93.7500 (90.9045)  time: 0.3570  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:21  Lr: 0.001875  Loss: -0.2322  Acc@1: 62.5000 (62.5598)  Acc@5: 93.7500 (90.9083)  time: 0.3548  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:18  Lr: 0.001875  Loss: -0.3425  Acc@1: 62.5000 (62.5656)  Acc@5: 93.7500 (90.9076)  time: 0.3545  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:14  Lr: 0.001875  Loss: -0.0756  Acc@1: 62.5000 (62.5580)  Acc@5: 87.5000 (90.9054)  time: 0.3541  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:10  Lr: 0.001875  Loss: 0.0016  Acc@1: 56.2500 (62.5401)  Acc@5: 87.5000 (90.8988)  time: 0.3548  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:07  Lr: 0.001875  Loss: -0.2048  Acc@1: 62.5000 (62.5503)  Acc@5: 93.7500 (90.9041)  time: 0.3585  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:03  Lr: 0.001875  Loss: -0.3715  Acc@1: 68.7500 (62.5739)  Acc@5: 93.7500 (90.9079)  time: 0.3672  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [4240/4579]  eta: 0:02:00  Lr: 0.001875  Loss: -0.1977  Acc@1: 68.7500 (62.5766)  Acc@5: 93.7500 (90.9087)  time: 0.3704  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [4250/4579]  eta: 0:01:56  Lr: 0.001875  Loss: 0.2235  Acc@1: 62.5000 (62.5691)  Acc@5: 87.5000 (90.9080)  time: 0.3703  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [4260/4579]  eta: 0:01:53  Lr: 0.001875  Loss: -0.1549  Acc@1: 56.2500 (62.5660)  Acc@5: 87.5000 (90.9030)  time: 0.3629  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4270/4579]  eta: 0:01:49  Lr: 0.001875  Loss: -0.0171  Acc@1: 62.5000 (62.5600)  Acc@5: 93.7500 (90.9082)  time: 0.3540  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:46  Lr: 0.001875  Loss: -0.3856  Acc@1: 62.5000 (62.5540)  Acc@5: 93.7500 (90.9031)  time: 0.3569  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:42  Lr: 0.001875  Loss: -0.4606  Acc@1: 62.5000 (62.5422)  Acc@5: 87.5000 (90.9010)  time: 0.3559  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:39  Lr: 0.001875  Loss: -0.2323  Acc@1: 68.7500 (62.5436)  Acc@5: 87.5000 (90.8931)  time: 0.3544  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:35  Lr: 0.001875  Loss: -0.4339  Acc@1: 62.5000 (62.5348)  Acc@5: 87.5000 (90.8881)  time: 0.3558  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:31  Lr: 0.001875  Loss: -0.4452  Acc@1: 56.2500 (62.5289)  Acc@5: 87.5000 (90.8875)  time: 0.3570  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:28  Lr: 0.001875  Loss: -0.0630  Acc@1: 56.2500 (62.5260)  Acc@5: 87.5000 (90.8826)  time: 0.3582  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6256  Acc@1: 62.5000 (62.5403)  Acc@5: 93.7500 (90.8849)  time: 0.3575  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2677  Acc@1: 62.5000 (62.5445)  Acc@5: 93.7500 (90.8857)  time: 0.3585  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:17  Lr: 0.001875  Loss: -0.1179  Acc@1: 62.5000 (62.5358)  Acc@5: 87.5000 (90.8808)  time: 0.3587  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:14  Lr: 0.001875  Loss: 0.1239  Acc@1: 62.5000 (62.5500)  Acc@5: 93.7500 (90.8874)  time: 0.3583  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.2433  Acc@1: 62.5000 (62.5357)  Acc@5: 93.7500 (90.8939)  time: 0.3616  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1202  Acc@1: 62.5000 (62.5342)  Acc@5: 93.7500 (90.8976)  time: 0.3650  data: 0.0039  max mem: 2500
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4764  Acc@1: 62.5000 (62.5369)  Acc@5: 93.7500 (90.9026)  time: 0.3628  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [4410/4579]  eta: 0:01:00  Lr: 0.001875  Loss: -0.2593  Acc@1: 62.5000 (62.5368)  Acc@5: 93.7500 (90.9034)  time: 0.3587  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4420/4579]  eta: 0:00:56  Lr: 0.001875  Loss: -0.5556  Acc@1: 62.5000 (62.5382)  Acc@5: 93.7500 (90.9141)  time: 0.3579  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0806  Acc@1: 62.5000 (62.5409)  Acc@5: 93.7500 (90.9149)  time: 0.3587  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6790  Acc@1: 62.5000 (62.5535)  Acc@5: 93.7500 (90.9184)  time: 0.3600  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4102  Acc@1: 62.5000 (62.5534)  Acc@5: 93.7500 (90.9164)  time: 0.3593  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:42  Lr: 0.001875  Loss: -0.3941  Acc@1: 68.7500 (62.5743)  Acc@5: 93.7500 (90.9241)  time: 0.3573  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.6558  Acc@1: 68.7500 (62.5797)  Acc@5: 93.7500 (90.9332)  time: 0.3584  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:35  Lr: 0.001875  Loss: -0.1765  Acc@1: 68.7500 (62.5921)  Acc@5: 93.7500 (90.9381)  time: 0.3610  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2652  Acc@1: 68.7500 (62.6030)  Acc@5: 93.7500 (90.9346)  time: 0.3613  data: 0.0048  max mem: 2500
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:28  Lr: 0.001875  Loss: -0.2598  Acc@1: 62.5000 (62.6028)  Acc@5: 87.5000 (90.9242)  time: 0.3633  data: 0.0059  max mem: 2500
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.2144  Acc@1: 62.5000 (62.6122)  Acc@5: 87.5000 (90.9263)  time: 0.3639  data: 0.0053  max mem: 2500
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.1261  Acc@1: 62.5000 (62.6203)  Acc@5: 93.7500 (90.9312)  time: 0.3618  data: 0.0037  max mem: 2500
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2986  Acc@1: 62.5000 (62.6255)  Acc@5: 87.5000 (90.9209)  time: 0.3659  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.1185  Acc@1: 62.5000 (62.6308)  Acc@5: 87.5000 (90.9202)  time: 0.3606  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.4182  Acc@1: 68.7500 (62.6442)  Acc@5: 87.5000 (90.9196)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.4441  Acc@1: 62.5000 (62.6425)  Acc@5: 87.5000 (90.9203)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.2007  Acc@1: 62.5000 (62.6477)  Acc@5: 93.7500 (90.9224)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1915  Acc@1: 62.5000 (62.6493)  Acc@5: 93.7500 (90.9237)  time: 0.3405  data: 0.0008  max mem: 2500
Train: Epoch[2/5] Total time: 0:27:07 (0.3554 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 146466, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 146482, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 146498, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 146434, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1915  Acc@1: 62.5000 (62.6493)  Acc@5: 93.7500 (90.9237)
Train: Epoch[3/5]  [   0/4579]  eta: 0:49:41  Lr: 0.001875  Loss: 0.3335  Acc@1: 56.2500 (56.2500)  Acc@5: 81.2500 (81.2500)  time: 0.6511  data: 0.3013  max mem: 2500
Train: Epoch[3/5]  [  10/4579]  eta: 0:28:31  Lr: 0.001875  Loss: -0.3265  Acc@1: 62.5000 (67.0455)  Acc@5: 93.7500 (93.1818)  time: 0.3746  data: 0.0279  max mem: 2500
Train: Epoch[3/5]  [  20/4579]  eta: 0:27:27  Lr: 0.001875  Loss: -0.0480  Acc@1: 62.5000 (65.7738)  Acc@5: 87.5000 (89.5833)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  30/4579]  eta: 0:27:04  Lr: 0.001875  Loss: 0.3375  Acc@1: 62.5000 (66.3306)  Acc@5: 87.5000 (90.5242)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  40/4579]  eta: 0:26:48  Lr: 0.001875  Loss: -0.7860  Acc@1: 62.5000 (66.3110)  Acc@5: 93.7500 (91.0061)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  50/4579]  eta: 0:26:37  Lr: 0.001875  Loss: -0.0725  Acc@1: 56.2500 (63.8480)  Acc@5: 93.7500 (90.4412)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  60/4579]  eta: 0:26:28  Lr: 0.001875  Loss: -0.1055  Acc@1: 62.5000 (64.6516)  Acc@5: 93.7500 (91.2910)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  70/4579]  eta: 0:26:21  Lr: 0.001875  Loss: -0.2121  Acc@1: 68.7500 (64.1725)  Acc@5: 93.7500 (91.0211)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  80/4579]  eta: 0:26:14  Lr: 0.001875  Loss: -0.6973  Acc@1: 62.5000 (64.3519)  Acc@5: 93.7500 (91.2809)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  90/4579]  eta: 0:26:12  Lr: 0.001875  Loss: -0.3607  Acc@1: 62.5000 (64.2857)  Acc@5: 93.7500 (91.4148)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 100/4579]  eta: 0:26:13  Lr: 0.001875  Loss: -0.5685  Acc@1: 62.5000 (64.2946)  Acc@5: 93.7500 (91.6460)  time: 0.3565  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [ 110/4579]  eta: 0:26:13  Lr: 0.001875  Loss: -0.3877  Acc@1: 68.7500 (64.6396)  Acc@5: 93.7500 (91.7230)  time: 0.3599  data: 0.0044  max mem: 2500
Train: Epoch[3/5]  [ 120/4579]  eta: 0:26:13  Lr: 0.001875  Loss: 0.0322  Acc@1: 68.7500 (64.8244)  Acc@5: 93.7500 (91.8388)  time: 0.3603  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [ 130/4579]  eta: 0:26:13  Lr: 0.001875  Loss: -0.3998  Acc@1: 62.5000 (64.8855)  Acc@5: 93.7500 (91.9847)  time: 0.3619  data: 0.0046  max mem: 2500
Train: Epoch[3/5]  [ 140/4579]  eta: 0:26:11  Lr: 0.001875  Loss: -0.1957  Acc@1: 62.5000 (64.9379)  Acc@5: 93.7500 (92.1099)  time: 0.3622  data: 0.0045  max mem: 2500
Train: Epoch[3/5]  [ 150/4579]  eta: 0:26:10  Lr: 0.001875  Loss: -0.4811  Acc@1: 68.7500 (64.9834)  Acc@5: 93.7500 (92.1358)  time: 0.3613  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [ 160/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 0.0491  Acc@1: 68.7500 (65.1398)  Acc@5: 93.7500 (92.0031)  time: 0.3621  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [ 170/4579]  eta: 0:26:07  Lr: 0.001875  Loss: -0.3805  Acc@1: 68.7500 (65.2412)  Acc@5: 93.7500 (91.9956)  time: 0.3616  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 180/4579]  eta: 0:26:06  Lr: 0.001875  Loss: -0.4060  Acc@1: 62.5000 (65.3660)  Acc@5: 93.7500 (92.0580)  time: 0.3635  data: 0.0044  max mem: 2500
Train: Epoch[3/5]  [ 190/4579]  eta: 0:26:05  Lr: 0.001875  Loss: -0.4321  Acc@1: 62.5000 (65.2814)  Acc@5: 93.7500 (91.7866)  time: 0.3686  data: 0.0055  max mem: 2500
Train: Epoch[3/5]  [ 200/4579]  eta: 0:26:03  Lr: 0.001875  Loss: -0.6509  Acc@1: 62.5000 (65.2052)  Acc@5: 93.7500 (92.0709)  time: 0.3658  data: 0.0039  max mem: 2500
Train: Epoch[3/5]  [ 210/4579]  eta: 0:26:01  Lr: 0.001875  Loss: -0.5044  Acc@1: 68.7500 (65.4028)  Acc@5: 93.7500 (92.1209)  time: 0.3628  data: 0.0047  max mem: 2500
Train: Epoch[3/5]  [ 220/4579]  eta: 0:25:59  Lr: 0.001875  Loss: 0.0115  Acc@1: 68.7500 (65.3281)  Acc@5: 93.7500 (92.1097)  time: 0.3652  data: 0.0043  max mem: 2500
Train: Epoch[3/5]  [ 230/4579]  eta: 0:25:56  Lr: 0.001875  Loss: -0.6215  Acc@1: 62.5000 (65.2597)  Acc@5: 93.7500 (92.1537)  time: 0.3633  data: 0.0039  max mem: 2500
Train: Epoch[3/5]  [ 240/4579]  eta: 0:25:53  Lr: 0.001875  Loss: -0.5170  Acc@1: 68.7500 (65.3786)  Acc@5: 93.7500 (92.1162)  time: 0.3601  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [ 250/4579]  eta: 0:25:49  Lr: 0.001875  Loss: -0.3128  Acc@1: 62.5000 (65.3386)  Acc@5: 93.7500 (92.1066)  time: 0.3598  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [ 260/4579]  eta: 0:25:46  Lr: 0.001875  Loss: -0.6218  Acc@1: 62.5000 (65.3017)  Acc@5: 93.7500 (92.1695)  time: 0.3602  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 270/4579]  eta: 0:25:43  Lr: 0.001875  Loss: 0.1167  Acc@1: 62.5000 (65.1753)  Acc@5: 93.7500 (92.2279)  time: 0.3603  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 280/4579]  eta: 0:25:41  Lr: 0.001875  Loss: -0.3030  Acc@1: 62.5000 (65.0801)  Acc@5: 93.7500 (92.2375)  time: 0.3633  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [ 290/4579]  eta: 0:25:38  Lr: 0.001875  Loss: -0.3399  Acc@1: 62.5000 (64.9485)  Acc@5: 93.7500 (92.3754)  time: 0.3652  data: 0.0052  max mem: 2500
Train: Epoch[3/5]  [ 300/4579]  eta: 0:25:35  Lr: 0.001875  Loss: -0.3337  Acc@1: 62.5000 (64.8671)  Acc@5: 93.7500 (92.2965)  time: 0.3639  data: 0.0079  max mem: 2500
Train: Epoch[3/5]  [ 310/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 0.1196  Acc@1: 62.5000 (64.7307)  Acc@5: 87.5000 (92.2629)  time: 0.3680  data: 0.0100  max mem: 2500
Train: Epoch[3/5]  [ 320/4579]  eta: 0:25:31  Lr: 0.001875  Loss: -0.0282  Acc@1: 62.5000 (64.6612)  Acc@5: 93.7500 (92.2897)  time: 0.3698  data: 0.0101  max mem: 2500
Train: Epoch[3/5]  [ 330/4579]  eta: 0:25:28  Lr: 0.001875  Loss: -0.1720  Acc@1: 62.5000 (64.5770)  Acc@5: 93.7500 (92.1828)  time: 0.3657  data: 0.0072  max mem: 2500
Train: Epoch[3/5]  [ 340/4579]  eta: 0:25:26  Lr: 0.001875  Loss: 0.1324  Acc@1: 62.5000 (64.4978)  Acc@5: 93.7500 (92.1921)  time: 0.3684  data: 0.0045  max mem: 2500
Train: Epoch[3/5]  [ 350/4579]  eta: 0:25:23  Lr: 0.001875  Loss: -0.1690  Acc@1: 62.5000 (64.3697)  Acc@5: 87.5000 (92.1118)  time: 0.3703  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [ 360/4579]  eta: 0:25:21  Lr: 0.001875  Loss: -0.1267  Acc@1: 62.5000 (64.3698)  Acc@5: 87.5000 (92.0706)  time: 0.3703  data: 0.0046  max mem: 2500
Train: Epoch[3/5]  [ 370/4579]  eta: 0:25:17  Lr: 0.001875  Loss: -0.1288  Acc@1: 56.2500 (64.2183)  Acc@5: 87.5000 (92.0317)  time: 0.3638  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [ 380/4579]  eta: 0:25:13  Lr: 0.001875  Loss: -0.3451  Acc@1: 62.5000 (64.3701)  Acc@5: 93.7500 (92.0440)  time: 0.3588  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 390/4579]  eta: 0:25:10  Lr: 0.001875  Loss: -0.5827  Acc@1: 68.7500 (64.4182)  Acc@5: 93.7500 (91.9917)  time: 0.3605  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [ 400/4579]  eta: 0:25:07  Lr: 0.001875  Loss: 0.2388  Acc@1: 68.7500 (64.4327)  Acc@5: 93.7500 (92.0200)  time: 0.3625  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [ 410/4579]  eta: 0:25:03  Lr: 0.001875  Loss: -0.4573  Acc@1: 68.7500 (64.5073)  Acc@5: 93.7500 (92.0773)  time: 0.3636  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [ 420/4579]  eta: 0:25:00  Lr: 0.001875  Loss: -0.1957  Acc@1: 68.7500 (64.5338)  Acc@5: 93.7500 (92.1170)  time: 0.3660  data: 0.0086  max mem: 2500
Train: Epoch[3/5]  [ 430/4579]  eta: 0:24:57  Lr: 0.001875  Loss: -0.2552  Acc@1: 68.7500 (64.4722)  Acc@5: 93.7500 (92.1404)  time: 0.3691  data: 0.0109  max mem: 2500
Train: Epoch[3/5]  [ 440/4579]  eta: 0:24:55  Lr: 0.001875  Loss: -0.2058  Acc@1: 68.7500 (64.4416)  Acc@5: 93.7500 (92.0918)  time: 0.3686  data: 0.0095  max mem: 2500
Train: Epoch[3/5]  [ 450/4579]  eta: 0:24:51  Lr: 0.001875  Loss: -0.4842  Acc@1: 68.7500 (64.5094)  Acc@5: 93.7500 (92.0316)  time: 0.3652  data: 0.0058  max mem: 2500
Train: Epoch[3/5]  [ 460/4579]  eta: 0:24:48  Lr: 0.001875  Loss: 0.0977  Acc@1: 62.5000 (64.4252)  Acc@5: 87.5000 (92.0282)  time: 0.3623  data: 0.0049  max mem: 2500
Train: Epoch[3/5]  [ 470/4579]  eta: 0:24:44  Lr: 0.001875  Loss: 0.0825  Acc@1: 62.5000 (64.3710)  Acc@5: 93.7500 (92.0249)  time: 0.3630  data: 0.0073  max mem: 2500
Train: Epoch[3/5]  [ 480/4579]  eta: 0:24:40  Lr: 0.001875  Loss: -0.1479  Acc@1: 62.5000 (64.4491)  Acc@5: 87.5000 (91.9828)  time: 0.3620  data: 0.0060  max mem: 2500
Train: Epoch[3/5]  [ 490/4579]  eta: 0:24:37  Lr: 0.001875  Loss: 0.1673  Acc@1: 68.7500 (64.4857)  Acc@5: 93.7500 (92.0443)  time: 0.3619  data: 0.0058  max mem: 2500
Train: Epoch[3/5]  [ 500/4579]  eta: 0:24:33  Lr: 0.001875  Loss: -0.1520  Acc@1: 62.5000 (64.4586)  Acc@5: 93.7500 (92.0659)  time: 0.3606  data: 0.0042  max mem: 2500
Train: Epoch[3/5]  [ 510/4579]  eta: 0:24:29  Lr: 0.001875  Loss: 0.1140  Acc@1: 62.5000 (64.3958)  Acc@5: 93.7500 (92.0988)  time: 0.3574  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [ 520/4579]  eta: 0:24:25  Lr: 0.001875  Loss: 0.2488  Acc@1: 62.5000 (64.3954)  Acc@5: 93.7500 (92.0585)  time: 0.3583  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [ 530/4579]  eta: 0:24:22  Lr: 0.001875  Loss: -0.1131  Acc@1: 62.5000 (64.3715)  Acc@5: 93.7500 (92.0904)  time: 0.3622  data: 0.0043  max mem: 2500
Train: Epoch[3/5]  [ 540/4579]  eta: 0:24:18  Lr: 0.001875  Loss: -0.0816  Acc@1: 62.5000 (64.4755)  Acc@5: 93.7500 (92.1326)  time: 0.3614  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [ 550/4579]  eta: 0:24:15  Lr: 0.001875  Loss: -0.2169  Acc@1: 62.5000 (64.4283)  Acc@5: 93.7500 (92.1053)  time: 0.3610  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [ 560/4579]  eta: 0:24:11  Lr: 0.001875  Loss: -0.6565  Acc@1: 62.5000 (64.3939)  Acc@5: 87.5000 (92.0455)  time: 0.3600  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 570/4579]  eta: 0:24:06  Lr: 0.001875  Loss: -0.6213  Acc@1: 62.5000 (64.3936)  Acc@5: 93.7500 (92.0753)  time: 0.3523  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 580/4579]  eta: 0:24:02  Lr: 0.001875  Loss: -0.1831  Acc@1: 62.5000 (64.2965)  Acc@5: 93.7500 (92.0396)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 590/4579]  eta: 0:23:57  Lr: 0.001875  Loss: -0.4485  Acc@1: 62.5000 (64.3084)  Acc@5: 93.7500 (92.0262)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 600/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 0.2990  Acc@1: 62.5000 (64.2991)  Acc@5: 93.7500 (92.0133)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 610/4579]  eta: 0:23:48  Lr: 0.001875  Loss: -0.1407  Acc@1: 62.5000 (64.2390)  Acc@5: 93.7500 (91.9804)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 620/4579]  eta: 0:23:44  Lr: 0.001875  Loss: 0.2141  Acc@1: 62.5000 (64.1606)  Acc@5: 93.7500 (91.9686)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 630/4579]  eta: 0:23:40  Lr: 0.001875  Loss: -0.1012  Acc@1: 68.7500 (64.2135)  Acc@5: 93.7500 (92.0166)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 640/4579]  eta: 0:23:37  Lr: 0.001875  Loss: -0.4753  Acc@1: 68.7500 (64.1576)  Acc@5: 93.7500 (91.9949)  time: 0.3639  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [ 650/4579]  eta: 0:23:34  Lr: 0.001875  Loss: -0.3781  Acc@1: 68.7500 (64.1801)  Acc@5: 93.7500 (91.9547)  time: 0.3731  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [ 660/4579]  eta: 0:23:31  Lr: 0.001875  Loss: -0.4901  Acc@1: 68.7500 (64.2776)  Acc@5: 93.7500 (91.9724)  time: 0.3683  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [ 670/4579]  eta: 0:23:27  Lr: 0.001875  Loss: -0.2836  Acc@1: 68.7500 (64.2884)  Acc@5: 93.7500 (91.9244)  time: 0.3582  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 680/4579]  eta: 0:23:22  Lr: 0.001875  Loss: -0.3801  Acc@1: 68.7500 (64.3722)  Acc@5: 93.7500 (91.9512)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 690/4579]  eta: 0:23:18  Lr: 0.001875  Loss: -0.4444  Acc@1: 68.7500 (64.3452)  Acc@5: 93.7500 (91.9682)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 700/4579]  eta: 0:23:14  Lr: 0.001875  Loss: -0.5023  Acc@1: 62.5000 (64.3723)  Acc@5: 93.7500 (91.9668)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 710/4579]  eta: 0:23:10  Lr: 0.001875  Loss: -0.2263  Acc@1: 68.7500 (64.3987)  Acc@5: 93.7500 (91.9743)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 720/4579]  eta: 0:23:05  Lr: 0.001875  Loss: -0.1399  Acc@1: 68.7500 (64.3897)  Acc@5: 93.7500 (92.0163)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 730/4579]  eta: 0:23:01  Lr: 0.001875  Loss: 0.0067  Acc@1: 62.5000 (64.3382)  Acc@5: 93.7500 (92.0315)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 740/4579]  eta: 0:22:57  Lr: 0.001875  Loss: -0.2426  Acc@1: 62.5000 (64.3978)  Acc@5: 93.7500 (92.0631)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 750/4579]  eta: 0:22:53  Lr: 0.001875  Loss: -0.0212  Acc@1: 62.5000 (64.3725)  Acc@5: 93.7500 (92.0523)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 760/4579]  eta: 0:22:48  Lr: 0.001875  Loss: -0.2632  Acc@1: 56.2500 (64.3150)  Acc@5: 93.7500 (92.0253)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 770/4579]  eta: 0:22:44  Lr: 0.001875  Loss: -0.3591  Acc@1: 62.5000 (64.3158)  Acc@5: 93.7500 (92.0233)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 780/4579]  eta: 0:22:40  Lr: 0.001875  Loss: -0.4660  Acc@1: 62.5000 (64.2606)  Acc@5: 93.7500 (92.0375)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 790/4579]  eta: 0:22:36  Lr: 0.001875  Loss: -0.2879  Acc@1: 62.5000 (64.2541)  Acc@5: 93.7500 (92.0591)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 800/4579]  eta: 0:22:33  Lr: 0.001875  Loss: -0.2109  Acc@1: 62.5000 (64.2556)  Acc@5: 93.7500 (92.0412)  time: 0.3580  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 810/4579]  eta: 0:22:29  Lr: 0.001875  Loss: -0.4489  Acc@1: 62.5000 (64.2109)  Acc@5: 93.7500 (92.0469)  time: 0.3603  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [ 820/4579]  eta: 0:22:26  Lr: 0.001875  Loss: -0.2469  Acc@1: 56.2500 (64.1519)  Acc@5: 93.7500 (92.1057)  time: 0.3556  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 830/4579]  eta: 0:22:22  Lr: 0.001875  Loss: 0.2537  Acc@1: 68.7500 (64.1922)  Acc@5: 93.7500 (92.1330)  time: 0.3587  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [ 840/4579]  eta: 0:22:19  Lr: 0.001875  Loss: 0.0486  Acc@1: 68.7500 (64.1350)  Acc@5: 93.7500 (92.1225)  time: 0.3619  data: 0.0039  max mem: 2500
Train: Epoch[3/5]  [ 850/4579]  eta: 0:22:15  Lr: 0.001875  Loss: -0.4173  Acc@1: 62.5000 (64.1818)  Acc@5: 93.7500 (92.1269)  time: 0.3619  data: 0.0044  max mem: 2500
Train: Epoch[3/5]  [ 860/4579]  eta: 0:22:12  Lr: 0.001875  Loss: -0.1715  Acc@1: 68.7500 (64.2059)  Acc@5: 93.7500 (92.1312)  time: 0.3612  data: 0.0052  max mem: 2500
Train: Epoch[3/5]  [ 870/4579]  eta: 0:22:08  Lr: 0.001875  Loss: -0.0069  Acc@1: 68.7500 (64.1648)  Acc@5: 93.7500 (92.0852)  time: 0.3581  data: 0.0031  max mem: 2500
Train: Epoch[3/5]  [ 880/4579]  eta: 0:22:05  Lr: 0.001875  Loss: -0.4503  Acc@1: 62.5000 (64.1813)  Acc@5: 93.7500 (92.0616)  time: 0.3644  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [ 890/4579]  eta: 0:22:02  Lr: 0.001875  Loss: 0.0500  Acc@1: 62.5000 (64.2186)  Acc@5: 93.7500 (92.0805)  time: 0.3660  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 900/4579]  eta: 0:21:59  Lr: 0.001875  Loss: -0.4123  Acc@1: 68.7500 (64.2966)  Acc@5: 93.7500 (92.0921)  time: 0.3661  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [ 910/4579]  eta: 0:21:55  Lr: 0.001875  Loss: -0.5915  Acc@1: 62.5000 (64.2357)  Acc@5: 93.7500 (92.0760)  time: 0.3663  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [ 920/4579]  eta: 0:21:52  Lr: 0.001875  Loss: -0.5152  Acc@1: 62.5000 (64.1694)  Acc@5: 87.5000 (92.0535)  time: 0.3592  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [ 930/4579]  eta: 0:21:48  Lr: 0.001875  Loss: -0.5218  Acc@1: 62.5000 (64.1447)  Acc@5: 93.7500 (92.0650)  time: 0.3577  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [ 940/4579]  eta: 0:21:44  Lr: 0.001875  Loss: 0.0614  Acc@1: 56.2500 (64.0874)  Acc@5: 87.5000 (92.0032)  time: 0.3567  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [ 950/4579]  eta: 0:21:41  Lr: 0.001875  Loss: -0.0281  Acc@1: 56.2500 (64.0576)  Acc@5: 87.5000 (91.9887)  time: 0.3557  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 960/4579]  eta: 0:21:37  Lr: 0.001875  Loss: 0.0083  Acc@1: 62.5000 (64.0414)  Acc@5: 93.7500 (92.0135)  time: 0.3579  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 970/4579]  eta: 0:21:33  Lr: 0.001875  Loss: -0.0902  Acc@1: 68.7500 (64.0641)  Acc@5: 93.7500 (92.0636)  time: 0.3573  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [ 980/4579]  eta: 0:21:30  Lr: 0.001875  Loss: -0.2562  Acc@1: 62.5000 (64.0800)  Acc@5: 93.7500 (92.0298)  time: 0.3539  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 990/4579]  eta: 0:21:26  Lr: 0.001875  Loss: -0.5067  Acc@1: 62.5000 (64.0515)  Acc@5: 93.7500 (92.0535)  time: 0.3543  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1000/4579]  eta: 0:21:22  Lr: 0.001875  Loss: -0.3577  Acc@1: 62.5000 (64.0172)  Acc@5: 93.7500 (92.0080)  time: 0.3551  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [1010/4579]  eta: 0:21:19  Lr: 0.001875  Loss: -0.5697  Acc@1: 56.2500 (63.9960)  Acc@5: 87.5000 (91.9943)  time: 0.3577  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1020/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.1412  Acc@1: 56.2500 (63.9447)  Acc@5: 93.7500 (92.0115)  time: 0.3538  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1030/4579]  eta: 0:21:11  Lr: 0.001875  Loss: -0.2649  Acc@1: 62.5000 (63.9670)  Acc@5: 93.7500 (92.0162)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1040/4579]  eta: 0:21:07  Lr: 0.001875  Loss: -0.0146  Acc@1: 62.5000 (63.9649)  Acc@5: 93.7500 (92.0149)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1050/4579]  eta: 0:21:03  Lr: 0.001875  Loss: -0.1738  Acc@1: 62.5000 (63.9629)  Acc@5: 93.7500 (92.0255)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1060/4579]  eta: 0:20:59  Lr: 0.001875  Loss: -0.5216  Acc@1: 62.5000 (64.0080)  Acc@5: 93.7500 (92.0535)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1070/4579]  eta: 0:20:55  Lr: 0.001875  Loss: 0.2423  Acc@1: 68.7500 (64.0698)  Acc@5: 93.7500 (92.0635)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1080/4579]  eta: 0:20:51  Lr: 0.001875  Loss: 0.0018  Acc@1: 62.5000 (64.0321)  Acc@5: 93.7500 (92.0617)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1090/4579]  eta: 0:20:47  Lr: 0.001875  Loss: -0.8240  Acc@1: 62.5000 (64.0639)  Acc@5: 93.7500 (92.0715)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1100/4579]  eta: 0:20:43  Lr: 0.001875  Loss: -0.2105  Acc@1: 68.7500 (64.0895)  Acc@5: 93.7500 (92.1038)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1110/4579]  eta: 0:20:39  Lr: 0.001875  Loss: 0.1154  Acc@1: 62.5000 (64.0470)  Acc@5: 93.7500 (92.1073)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1120/4579]  eta: 0:20:35  Lr: 0.001875  Loss: -0.3416  Acc@1: 62.5000 (64.0611)  Acc@5: 93.7500 (92.0718)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1130/4579]  eta: 0:20:32  Lr: 0.001875  Loss: -0.2544  Acc@1: 62.5000 (64.0584)  Acc@5: 93.7500 (92.0756)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1140/4579]  eta: 0:20:28  Lr: 0.001875  Loss: -0.7312  Acc@1: 62.5000 (64.0940)  Acc@5: 93.7500 (92.0903)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1150/4579]  eta: 0:20:24  Lr: 0.001875  Loss: -0.6089  Acc@1: 62.5000 (64.0910)  Acc@5: 93.7500 (92.0884)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1160/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.2844  Acc@1: 62.5000 (64.0396)  Acc@5: 93.7500 (92.0973)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1170/4579]  eta: 0:20:16  Lr: 0.001875  Loss: -0.5272  Acc@1: 56.2500 (64.0265)  Acc@5: 93.7500 (92.0954)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1180/4579]  eta: 0:20:12  Lr: 0.001875  Loss: -0.4944  Acc@1: 62.5000 (64.0453)  Acc@5: 93.7500 (92.1041)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1190/4579]  eta: 0:20:08  Lr: 0.001875  Loss: -0.2055  Acc@1: 62.5000 (64.0481)  Acc@5: 93.7500 (92.1127)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1200/4579]  eta: 0:20:05  Lr: 0.001875  Loss: -0.4090  Acc@1: 56.2500 (64.0404)  Acc@5: 93.7500 (92.1211)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1210/4579]  eta: 0:20:01  Lr: 0.001875  Loss: -0.7775  Acc@1: 56.2500 (64.0328)  Acc@5: 93.7500 (92.1140)  time: 0.3522  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1220/4579]  eta: 0:19:57  Lr: 0.001875  Loss: 0.1324  Acc@1: 68.7500 (64.0254)  Acc@5: 87.5000 (92.0762)  time: 0.3552  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [1230/4579]  eta: 0:19:54  Lr: 0.001875  Loss: -0.1459  Acc@1: 68.7500 (64.0435)  Acc@5: 87.5000 (92.0390)  time: 0.3550  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [1240/4579]  eta: 0:19:50  Lr: 0.001875  Loss: -0.3306  Acc@1: 62.5000 (64.0260)  Acc@5: 93.7500 (92.0377)  time: 0.3537  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1250/4579]  eta: 0:19:46  Lr: 0.001875  Loss: -0.4309  Acc@1: 62.5000 (64.0488)  Acc@5: 93.7500 (92.0364)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1260/4579]  eta: 0:19:43  Lr: 0.001875  Loss: 0.0700  Acc@1: 62.5000 (64.0464)  Acc@5: 93.7500 (92.0202)  time: 0.3545  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1270/4579]  eta: 0:19:39  Lr: 0.001875  Loss: 0.0192  Acc@1: 62.5000 (64.0391)  Acc@5: 93.7500 (92.0092)  time: 0.3586  data: 0.0038  max mem: 2500
Train: Epoch[3/5]  [1280/4579]  eta: 0:19:36  Lr: 0.001875  Loss: -0.1844  Acc@1: 68.7500 (64.0759)  Acc@5: 87.5000 (91.9887)  time: 0.3576  data: 0.0044  max mem: 2500
Train: Epoch[3/5]  [1290/4579]  eta: 0:19:32  Lr: 0.001875  Loss: 0.1110  Acc@1: 68.7500 (64.0976)  Acc@5: 87.5000 (91.9684)  time: 0.3560  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [1300/4579]  eta: 0:19:29  Lr: 0.001875  Loss: 0.1601  Acc@1: 62.5000 (64.0661)  Acc@5: 87.5000 (91.9581)  time: 0.3550  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1310/4579]  eta: 0:19:25  Lr: 0.001875  Loss: 0.5371  Acc@1: 62.5000 (64.0208)  Acc@5: 93.7500 (91.9575)  time: 0.3536  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1320/4579]  eta: 0:19:21  Lr: 0.001875  Loss: -0.2425  Acc@1: 56.2500 (63.9762)  Acc@5: 87.5000 (91.9285)  time: 0.3551  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1330/4579]  eta: 0:19:18  Lr: 0.001875  Loss: -0.5250  Acc@1: 62.5000 (63.9604)  Acc@5: 93.7500 (91.9562)  time: 0.3548  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [1340/4579]  eta: 0:19:14  Lr: 0.001875  Loss: -0.3214  Acc@1: 62.5000 (63.9355)  Acc@5: 93.7500 (91.9743)  time: 0.3531  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1350/4579]  eta: 0:19:10  Lr: 0.001875  Loss: -0.1887  Acc@1: 62.5000 (63.9573)  Acc@5: 93.7500 (92.0013)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1360/4579]  eta: 0:19:07  Lr: 0.001875  Loss: 0.1011  Acc@1: 62.5000 (63.9557)  Acc@5: 93.7500 (91.9866)  time: 0.3529  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1370/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.2682  Acc@1: 62.5000 (63.9998)  Acc@5: 87.5000 (91.9675)  time: 0.3544  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1380/4579]  eta: 0:19:00  Lr: 0.001875  Loss: -0.1948  Acc@1: 68.7500 (64.0387)  Acc@5: 93.7500 (91.9940)  time: 0.3554  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1390/4579]  eta: 0:18:56  Lr: 0.001875  Loss: -0.1991  Acc@1: 62.5000 (64.0322)  Acc@5: 93.7500 (91.9887)  time: 0.3550  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [1400/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.1346  Acc@1: 62.5000 (64.0079)  Acc@5: 87.5000 (91.9477)  time: 0.3538  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [1410/4579]  eta: 0:18:49  Lr: 0.001875  Loss: -0.0420  Acc@1: 62.5000 (64.0060)  Acc@5: 87.5000 (91.9295)  time: 0.3551  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1420/4579]  eta: 0:18:45  Lr: 0.001875  Loss: -0.0278  Acc@1: 62.5000 (63.9866)  Acc@5: 87.5000 (91.9247)  time: 0.3541  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1430/4579]  eta: 0:18:42  Lr: 0.001875  Loss: -0.4335  Acc@1: 62.5000 (64.0068)  Acc@5: 93.7500 (91.9244)  time: 0.3543  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1440/4579]  eta: 0:18:38  Lr: 0.001875  Loss: 0.1122  Acc@1: 62.5000 (64.0224)  Acc@5: 93.7500 (91.9067)  time: 0.3550  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1450/4579]  eta: 0:18:35  Lr: 0.001875  Loss: -0.0011  Acc@1: 62.5000 (64.0248)  Acc@5: 87.5000 (91.8978)  time: 0.3594  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1460/4579]  eta: 0:18:31  Lr: 0.001875  Loss: -0.6047  Acc@1: 62.5000 (64.0015)  Acc@5: 93.7500 (91.9105)  time: 0.3613  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [1470/4579]  eta: 0:18:27  Lr: 0.001875  Loss: -0.5052  Acc@1: 62.5000 (63.9913)  Acc@5: 93.7500 (91.8975)  time: 0.3575  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [1480/4579]  eta: 0:18:24  Lr: 0.001875  Loss: -0.1032  Acc@1: 62.5000 (63.9939)  Acc@5: 93.7500 (91.9142)  time: 0.3598  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [1490/4579]  eta: 0:18:20  Lr: 0.001875  Loss: -0.3121  Acc@1: 62.5000 (64.0132)  Acc@5: 93.7500 (91.9140)  time: 0.3582  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [1500/4579]  eta: 0:18:17  Lr: 0.001875  Loss: -0.2887  Acc@1: 62.5000 (64.0115)  Acc@5: 93.7500 (91.9262)  time: 0.3540  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1510/4579]  eta: 0:18:13  Lr: 0.001875  Loss: -0.0997  Acc@1: 56.2500 (63.9725)  Acc@5: 93.7500 (91.9259)  time: 0.3533  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1520/4579]  eta: 0:18:10  Lr: 0.001875  Loss: -0.8357  Acc@1: 68.7500 (64.0450)  Acc@5: 93.7500 (91.9214)  time: 0.3558  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1530/4579]  eta: 0:18:06  Lr: 0.001875  Loss: -0.2030  Acc@1: 68.7500 (64.0554)  Acc@5: 93.7500 (91.9252)  time: 0.3569  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [1540/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.1688  Acc@1: 62.5000 (64.0493)  Acc@5: 87.5000 (91.8965)  time: 0.3566  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1550/4579]  eta: 0:17:59  Lr: 0.001875  Loss: -0.2838  Acc@1: 62.5000 (64.0675)  Acc@5: 93.7500 (91.9165)  time: 0.3554  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1560/4579]  eta: 0:17:55  Lr: 0.001875  Loss: -0.7498  Acc@1: 62.5000 (64.0975)  Acc@5: 93.7500 (91.9323)  time: 0.3547  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1570/4579]  eta: 0:17:52  Lr: 0.001875  Loss: 0.0469  Acc@1: 68.7500 (64.1073)  Acc@5: 93.7500 (91.9279)  time: 0.3572  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1580/4579]  eta: 0:17:48  Lr: 0.001875  Loss: 0.1536  Acc@1: 62.5000 (64.0694)  Acc@5: 93.7500 (91.9236)  time: 0.3588  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1590/4579]  eta: 0:17:45  Lr: 0.001875  Loss: -0.3485  Acc@1: 56.2500 (64.0635)  Acc@5: 93.7500 (91.9312)  time: 0.3644  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1600/4579]  eta: 0:17:42  Lr: 0.001875  Loss: -0.1915  Acc@1: 62.5000 (64.0498)  Acc@5: 93.7500 (91.9113)  time: 0.3694  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1610/4579]  eta: 0:17:38  Lr: 0.001875  Loss: -0.3290  Acc@1: 62.5000 (64.0208)  Acc@5: 87.5000 (91.8917)  time: 0.3731  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [1620/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.1528  Acc@1: 62.5000 (64.0345)  Acc@5: 93.7500 (91.8993)  time: 0.3705  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [1630/4579]  eta: 0:17:31  Lr: 0.001875  Loss: 0.1309  Acc@1: 62.5000 (64.0405)  Acc@5: 93.7500 (91.8761)  time: 0.3589  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1640/4579]  eta: 0:17:28  Lr: 0.001875  Loss: -0.2297  Acc@1: 62.5000 (64.0615)  Acc@5: 93.7500 (91.8761)  time: 0.3568  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1650/4579]  eta: 0:17:24  Lr: 0.001875  Loss: -0.1547  Acc@1: 62.5000 (64.0597)  Acc@5: 93.7500 (91.8799)  time: 0.3565  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [1660/4579]  eta: 0:17:21  Lr: 0.001875  Loss: -0.0874  Acc@1: 68.7500 (64.0766)  Acc@5: 93.7500 (91.8724)  time: 0.3570  data: 0.0047  max mem: 2500
Train: Epoch[3/5]  [1670/4579]  eta: 0:17:17  Lr: 0.001875  Loss: -0.0729  Acc@1: 68.7500 (64.0747)  Acc@5: 87.5000 (91.8612)  time: 0.3590  data: 0.0059  max mem: 2500
Train: Epoch[3/5]  [1680/4579]  eta: 0:17:14  Lr: 0.001875  Loss: -0.6661  Acc@1: 68.7500 (64.0988)  Acc@5: 93.7500 (91.8575)  time: 0.3565  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [1690/4579]  eta: 0:17:10  Lr: 0.001875  Loss: -0.2986  Acc@1: 62.5000 (64.0782)  Acc@5: 93.7500 (91.8687)  time: 0.3540  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1700/4579]  eta: 0:17:06  Lr: 0.001875  Loss: -1.0886  Acc@1: 62.5000 (64.0763)  Acc@5: 93.7500 (91.8798)  time: 0.3559  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1710/4579]  eta: 0:17:03  Lr: 0.001875  Loss: -0.8489  Acc@1: 62.5000 (64.1072)  Acc@5: 93.7500 (91.8761)  time: 0.3610  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [1720/4579]  eta: 0:16:59  Lr: 0.001875  Loss: 0.2381  Acc@1: 68.7500 (64.0834)  Acc@5: 93.7500 (91.8725)  time: 0.3588  data: 0.0040  max mem: 2500
Train: Epoch[3/5]  [1730/4579]  eta: 0:16:56  Lr: 0.001875  Loss: 0.0498  Acc@1: 56.2500 (64.0598)  Acc@5: 93.7500 (91.8725)  time: 0.3570  data: 0.0038  max mem: 2500
Train: Epoch[3/5]  [1740/4579]  eta: 0:16:52  Lr: 0.001875  Loss: -0.2471  Acc@1: 62.5000 (64.0760)  Acc@5: 87.5000 (91.8474)  time: 0.3583  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1750/4579]  eta: 0:16:49  Lr: 0.001875  Loss: -0.3932  Acc@1: 62.5000 (64.0598)  Acc@5: 87.5000 (91.8547)  time: 0.3569  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1760/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.2567  Acc@1: 62.5000 (64.0794)  Acc@5: 93.7500 (91.8512)  time: 0.3585  data: 0.0043  max mem: 2500
Train: Epoch[3/5]  [1770/4579]  eta: 0:16:42  Lr: 0.001875  Loss: -0.1880  Acc@1: 62.5000 (64.0810)  Acc@5: 93.7500 (91.8584)  time: 0.3571  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [1780/4579]  eta: 0:16:38  Lr: 0.001875  Loss: 0.4029  Acc@1: 62.5000 (64.0862)  Acc@5: 93.7500 (91.8550)  time: 0.3532  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1790/4579]  eta: 0:16:35  Lr: 0.001875  Loss: -0.0611  Acc@1: 62.5000 (64.1087)  Acc@5: 93.7500 (91.8586)  time: 0.3582  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [1800/4579]  eta: 0:16:31  Lr: 0.001875  Loss: -0.3693  Acc@1: 62.5000 (64.0859)  Acc@5: 93.7500 (91.8587)  time: 0.3634  data: 0.0046  max mem: 2500
Train: Epoch[3/5]  [1810/4579]  eta: 0:16:28  Lr: 0.001875  Loss: -0.0788  Acc@1: 62.5000 (64.0944)  Acc@5: 93.7500 (91.8588)  time: 0.3625  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [1820/4579]  eta: 0:16:24  Lr: 0.001875  Loss: 0.2866  Acc@1: 62.5000 (64.0616)  Acc@5: 93.7500 (91.8589)  time: 0.3616  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1830/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.6358  Acc@1: 62.5000 (64.1077)  Acc@5: 93.7500 (91.8521)  time: 0.3628  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1840/4579]  eta: 0:16:17  Lr: 0.001875  Loss: 0.0908  Acc@1: 56.2500 (64.0684)  Acc@5: 87.5000 (91.8183)  time: 0.3635  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1850/4579]  eta: 0:16:14  Lr: 0.001875  Loss: 0.0213  Acc@1: 56.2500 (64.0836)  Acc@5: 93.7500 (91.8254)  time: 0.3616  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1860/4579]  eta: 0:16:10  Lr: 0.001875  Loss: -0.2817  Acc@1: 68.7500 (64.1188)  Acc@5: 93.7500 (91.8189)  time: 0.3610  data: 0.0059  max mem: 2500
Train: Epoch[3/5]  [1870/4579]  eta: 0:16:07  Lr: 0.001875  Loss: -0.4425  Acc@1: 62.5000 (64.1134)  Acc@5: 87.5000 (91.7958)  time: 0.3657  data: 0.0073  max mem: 2500
Train: Epoch[3/5]  [1880/4579]  eta: 0:16:03  Lr: 0.001875  Loss: 0.1354  Acc@1: 62.5000 (64.1182)  Acc@5: 93.7500 (91.7963)  time: 0.3663  data: 0.0060  max mem: 2500
Train: Epoch[3/5]  [1890/4579]  eta: 0:16:00  Lr: 0.001875  Loss: -0.3523  Acc@1: 62.5000 (64.1030)  Acc@5: 93.7500 (91.8066)  time: 0.3607  data: 0.0053  max mem: 2500
Train: Epoch[3/5]  [1900/4579]  eta: 0:15:56  Lr: 0.001875  Loss: 0.0426  Acc@1: 62.5000 (64.0880)  Acc@5: 93.7500 (91.8135)  time: 0.3579  data: 0.0038  max mem: 2500
Train: Epoch[3/5]  [1910/4579]  eta: 0:15:53  Lr: 0.001875  Loss: -0.2590  Acc@1: 62.5000 (64.0960)  Acc@5: 93.7500 (91.8204)  time: 0.3629  data: 0.0049  max mem: 2500
Train: Epoch[3/5]  [1920/4579]  eta: 0:15:49  Lr: 0.001875  Loss: -0.1640  Acc@1: 68.7500 (64.1072)  Acc@5: 93.7500 (91.8174)  time: 0.3748  data: 0.0049  max mem: 2500
Train: Epoch[3/5]  [1930/4579]  eta: 0:15:46  Lr: 0.001875  Loss: 0.1512  Acc@1: 68.7500 (64.1248)  Acc@5: 93.7500 (91.8048)  time: 0.3708  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [1940/4579]  eta: 0:15:42  Lr: 0.001875  Loss: -0.4473  Acc@1: 68.7500 (64.1293)  Acc@5: 93.7500 (91.8019)  time: 0.3538  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1950/4579]  eta: 0:15:39  Lr: 0.001875  Loss: -0.3185  Acc@1: 68.7500 (64.1210)  Acc@5: 93.7500 (91.7991)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1960/4579]  eta: 0:15:35  Lr: 0.001875  Loss: 0.3186  Acc@1: 62.5000 (64.1063)  Acc@5: 87.5000 (91.7835)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1970/4579]  eta: 0:15:31  Lr: 0.001875  Loss: -0.0655  Acc@1: 62.5000 (64.0950)  Acc@5: 87.5000 (91.7935)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1980/4579]  eta: 0:15:27  Lr: 0.001875  Loss: -0.5811  Acc@1: 62.5000 (64.1027)  Acc@5: 93.7500 (91.8097)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1990/4579]  eta: 0:15:24  Lr: 0.001875  Loss: -0.1641  Acc@1: 62.5000 (64.0884)  Acc@5: 93.7500 (91.8163)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2000/4579]  eta: 0:15:20  Lr: 0.001875  Loss: 1.0210  Acc@1: 62.5000 (64.0867)  Acc@5: 93.7500 (91.8103)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2010/4579]  eta: 0:15:16  Lr: 0.001875  Loss: -0.2628  Acc@1: 68.7500 (64.0819)  Acc@5: 93.7500 (91.8013)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2020/4579]  eta: 0:15:13  Lr: 0.001875  Loss: -0.3340  Acc@1: 62.5000 (64.0648)  Acc@5: 93.7500 (91.8110)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2030/4579]  eta: 0:15:09  Lr: 0.001875  Loss: -0.1493  Acc@1: 62.5000 (64.0417)  Acc@5: 93.7500 (91.8051)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2040/4579]  eta: 0:15:05  Lr: 0.001875  Loss: -0.2802  Acc@1: 62.5000 (64.0434)  Acc@5: 93.7500 (91.8024)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2050/4579]  eta: 0:15:02  Lr: 0.001875  Loss: -0.8031  Acc@1: 62.5000 (64.0450)  Acc@5: 93.7500 (91.8028)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2060/4579]  eta: 0:14:58  Lr: 0.001875  Loss: -0.4250  Acc@1: 62.5000 (64.0496)  Acc@5: 93.7500 (91.7940)  time: 0.3518  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2070/4579]  eta: 0:14:55  Lr: 0.001875  Loss: -0.2633  Acc@1: 68.7500 (64.0814)  Acc@5: 93.7500 (91.7974)  time: 0.3622  data: 0.0045  max mem: 2500
Train: Epoch[3/5]  [2080/4579]  eta: 0:14:51  Lr: 0.001875  Loss: -0.0047  Acc@1: 62.5000 (64.0768)  Acc@5: 87.5000 (91.7828)  time: 0.3637  data: 0.0053  max mem: 2500
Train: Epoch[3/5]  [2090/4579]  eta: 0:14:48  Lr: 0.001875  Loss: 0.0556  Acc@1: 62.5000 (64.0931)  Acc@5: 93.7500 (91.7922)  time: 0.3627  data: 0.0050  max mem: 2500
Train: Epoch[3/5]  [2100/4579]  eta: 0:14:44  Lr: 0.001875  Loss: -0.5294  Acc@1: 62.5000 (64.0975)  Acc@5: 93.7500 (91.7837)  time: 0.3609  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [2110/4579]  eta: 0:14:41  Lr: 0.001875  Loss: -0.2206  Acc@1: 62.5000 (64.1047)  Acc@5: 93.7500 (91.7871)  time: 0.3633  data: 0.0050  max mem: 2500
Train: Epoch[3/5]  [2120/4579]  eta: 0:14:37  Lr: 0.001875  Loss: -0.3108  Acc@1: 62.5000 (64.1001)  Acc@5: 93.7500 (91.7727)  time: 0.3686  data: 0.0075  max mem: 2500
Train: Epoch[3/5]  [2130/4579]  eta: 0:14:34  Lr: 0.001875  Loss: -0.2391  Acc@1: 62.5000 (64.0779)  Acc@5: 87.5000 (91.7527)  time: 0.3629  data: 0.0053  max mem: 2500
Train: Epoch[3/5]  [2140/4579]  eta: 0:14:30  Lr: 0.001875  Loss: -0.7793  Acc@1: 56.2500 (64.0822)  Acc@5: 87.5000 (91.7533)  time: 0.3609  data: 0.0048  max mem: 2500
Train: Epoch[3/5]  [2150/4579]  eta: 0:14:27  Lr: 0.001875  Loss: 0.0995  Acc@1: 62.5000 (64.0719)  Acc@5: 93.7500 (91.7655)  time: 0.3615  data: 0.0063  max mem: 2500
Train: Epoch[3/5]  [2160/4579]  eta: 0:14:23  Lr: 0.001875  Loss: -0.1393  Acc@1: 56.2500 (64.0531)  Acc@5: 93.7500 (91.7660)  time: 0.3591  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [2170/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.3599  Acc@1: 62.5000 (64.0661)  Acc@5: 93.7500 (91.7751)  time: 0.3613  data: 0.0043  max mem: 2500
Train: Epoch[3/5]  [2180/4579]  eta: 0:14:16  Lr: 0.001875  Loss: -0.1396  Acc@1: 62.5000 (64.0532)  Acc@5: 87.5000 (91.7469)  time: 0.3615  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [2190/4579]  eta: 0:14:12  Lr: 0.001875  Loss: -0.5386  Acc@1: 62.5000 (64.0575)  Acc@5: 87.5000 (91.7361)  time: 0.3614  data: 0.0042  max mem: 2500
Train: Epoch[3/5]  [2200/4579]  eta: 0:14:09  Lr: 0.001875  Loss: 0.0900  Acc@1: 62.5000 (64.0448)  Acc@5: 87.5000 (91.7083)  time: 0.3611  data: 0.0049  max mem: 2500
Train: Epoch[3/5]  [2210/4579]  eta: 0:14:06  Lr: 0.001875  Loss: -0.5420  Acc@1: 62.5000 (64.0576)  Acc@5: 93.7500 (91.7204)  time: 0.3665  data: 0.0071  max mem: 2500
Train: Epoch[3/5]  [2220/4579]  eta: 0:14:02  Lr: 0.001875  Loss: -0.2974  Acc@1: 68.7500 (64.1040)  Acc@5: 93.7500 (91.7267)  time: 0.3672  data: 0.0062  max mem: 2500
Train: Epoch[3/5]  [2230/4579]  eta: 0:13:58  Lr: 0.001875  Loss: -0.5207  Acc@1: 68.7500 (64.0968)  Acc@5: 93.7500 (91.7246)  time: 0.3631  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [2240/4579]  eta: 0:13:55  Lr: 0.001875  Loss: 0.5365  Acc@1: 62.5000 (64.0953)  Acc@5: 93.7500 (91.7364)  time: 0.3652  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [2250/4579]  eta: 0:13:51  Lr: 0.001875  Loss: -0.0636  Acc@1: 62.5000 (64.0937)  Acc@5: 93.7500 (91.7287)  time: 0.3639  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [2260/4579]  eta: 0:13:48  Lr: 0.001875  Loss: -0.6336  Acc@1: 62.5000 (64.0977)  Acc@5: 93.7500 (91.7321)  time: 0.3602  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [2270/4579]  eta: 0:13:44  Lr: 0.001875  Loss: -0.1026  Acc@1: 62.5000 (64.0825)  Acc@5: 93.7500 (91.7300)  time: 0.3641  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2280/4579]  eta: 0:13:41  Lr: 0.001875  Loss: 0.0038  Acc@1: 62.5000 (64.0700)  Acc@5: 87.5000 (91.7169)  time: 0.3681  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2290/4579]  eta: 0:13:38  Lr: 0.001875  Loss: 0.0021  Acc@1: 62.5000 (64.0605)  Acc@5: 93.7500 (91.7203)  time: 0.3703  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2300/4579]  eta: 0:13:34  Lr: 0.001875  Loss: -0.6573  Acc@1: 68.7500 (64.0754)  Acc@5: 87.5000 (91.7047)  time: 0.3672  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [2310/4579]  eta: 0:13:31  Lr: 0.001875  Loss: -0.7493  Acc@1: 68.7500 (64.0767)  Acc@5: 87.5000 (91.7054)  time: 0.3625  data: 0.0040  max mem: 2500
Train: Epoch[3/5]  [2320/4579]  eta: 0:13:27  Lr: 0.001875  Loss: -0.2386  Acc@1: 62.5000 (64.0618)  Acc@5: 87.5000 (91.7035)  time: 0.3651  data: 0.0058  max mem: 2500
Train: Epoch[3/5]  [2330/4579]  eta: 0:13:23  Lr: 0.001875  Loss: -0.2368  Acc@1: 62.5000 (64.0578)  Acc@5: 87.5000 (91.6962)  time: 0.3612  data: 0.0045  max mem: 2500
Train: Epoch[3/5]  [2340/4579]  eta: 0:13:20  Lr: 0.001875  Loss: -0.5537  Acc@1: 68.7500 (64.0779)  Acc@5: 87.5000 (91.6782)  time: 0.3583  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [2350/4579]  eta: 0:13:16  Lr: 0.001875  Loss: 0.5065  Acc@1: 68.7500 (64.0951)  Acc@5: 93.7500 (91.6870)  time: 0.3592  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [2360/4579]  eta: 0:13:13  Lr: 0.001875  Loss: 0.5566  Acc@1: 68.7500 (64.0963)  Acc@5: 93.7500 (91.6799)  time: 0.3630  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [2370/4579]  eta: 0:13:09  Lr: 0.001875  Loss: -0.0688  Acc@1: 68.7500 (64.1343)  Acc@5: 87.5000 (91.6834)  time: 0.3619  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [2380/4579]  eta: 0:13:06  Lr: 0.001875  Loss: 0.2134  Acc@1: 68.7500 (64.1143)  Acc@5: 87.5000 (91.6684)  time: 0.3601  data: 0.0044  max mem: 2500
Train: Epoch[3/5]  [2390/4579]  eta: 0:13:02  Lr: 0.001875  Loss: -0.5114  Acc@1: 62.5000 (64.1128)  Acc@5: 87.5000 (91.6614)  time: 0.3631  data: 0.0052  max mem: 2500
Train: Epoch[3/5]  [2400/4579]  eta: 0:12:59  Lr: 0.001875  Loss: -0.1607  Acc@1: 62.5000 (64.1165)  Acc@5: 93.7500 (91.6701)  time: 0.3640  data: 0.0048  max mem: 2500
Train: Epoch[3/5]  [2410/4579]  eta: 0:12:55  Lr: 0.001875  Loss: -0.0719  Acc@1: 62.5000 (64.1098)  Acc@5: 93.7500 (91.6839)  time: 0.3652  data: 0.0050  max mem: 2500
Train: Epoch[3/5]  [2420/4579]  eta: 0:12:52  Lr: 0.001875  Loss: 0.2332  Acc@1: 62.5000 (64.1006)  Acc@5: 93.7500 (91.6796)  time: 0.3652  data: 0.0031  max mem: 2500
Train: Epoch[3/5]  [2430/4579]  eta: 0:12:48  Lr: 0.001875  Loss: -0.1620  Acc@1: 62.5000 (64.1068)  Acc@5: 87.5000 (91.6804)  time: 0.3651  data: 0.0056  max mem: 2500
Train: Epoch[3/5]  [2440/4579]  eta: 0:12:45  Lr: 0.001875  Loss: 0.0230  Acc@1: 68.7500 (64.1182)  Acc@5: 87.5000 (91.6812)  time: 0.3641  data: 0.0075  max mem: 2500
Train: Epoch[3/5]  [2450/4579]  eta: 0:12:41  Lr: 0.001875  Loss: -0.0231  Acc@1: 68.7500 (64.1345)  Acc@5: 93.7500 (91.6820)  time: 0.3613  data: 0.0050  max mem: 2500
Train: Epoch[3/5]  [2460/4579]  eta: 0:12:38  Lr: 0.001875  Loss: -0.4011  Acc@1: 62.5000 (64.1228)  Acc@5: 93.7500 (91.6853)  time: 0.3619  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [2470/4579]  eta: 0:12:34  Lr: 0.001875  Loss: -0.1334  Acc@1: 62.5000 (64.1162)  Acc@5: 93.7500 (91.6810)  time: 0.3637  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [2480/4579]  eta: 0:12:31  Lr: 0.001875  Loss: 0.1313  Acc@1: 62.5000 (64.1274)  Acc@5: 87.5000 (91.6717)  time: 0.3652  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [2490/4579]  eta: 0:12:27  Lr: 0.001875  Loss: -0.3966  Acc@1: 62.5000 (64.1359)  Acc@5: 93.7500 (91.6725)  time: 0.3588  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2500/4579]  eta: 0:12:23  Lr: 0.001875  Loss: 0.2107  Acc@1: 62.5000 (64.1244)  Acc@5: 93.7500 (91.6658)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2510/4579]  eta: 0:12:20  Lr: 0.001875  Loss: 0.0224  Acc@1: 62.5000 (64.1253)  Acc@5: 93.7500 (91.6692)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2520/4579]  eta: 0:12:16  Lr: 0.001875  Loss: 0.0688  Acc@1: 62.5000 (64.1412)  Acc@5: 93.7500 (91.6774)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2530/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.2317  Acc@1: 68.7500 (64.1446)  Acc@5: 87.5000 (91.6733)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2540/4579]  eta: 0:12:09  Lr: 0.001875  Loss: 0.6058  Acc@1: 68.7500 (64.1406)  Acc@5: 87.5000 (91.6716)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2550/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.0887  Acc@1: 62.5000 (64.1195)  Acc@5: 87.5000 (91.6577)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2560/4579]  eta: 0:12:01  Lr: 0.001875  Loss: -0.2652  Acc@1: 62.5000 (64.1229)  Acc@5: 87.5000 (91.6537)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2570/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.2908  Acc@1: 68.7500 (64.1336)  Acc@5: 93.7500 (91.6667)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2580/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.3209  Acc@1: 68.7500 (64.1273)  Acc@5: 93.7500 (91.6554)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2590/4579]  eta: 0:11:50  Lr: 0.001875  Loss: -0.1933  Acc@1: 62.5000 (64.1234)  Acc@5: 87.5000 (91.6562)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2600/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.8347  Acc@1: 68.7500 (64.1580)  Acc@5: 93.7500 (91.6643)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2610/4579]  eta: 0:11:43  Lr: 0.001875  Loss: 0.4452  Acc@1: 68.7500 (64.1493)  Acc@5: 93.7500 (91.6723)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2620/4579]  eta: 0:11:39  Lr: 0.001875  Loss: -0.3888  Acc@1: 62.5000 (64.1764)  Acc@5: 93.7500 (91.6754)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2630/4579]  eta: 0:11:36  Lr: 0.001875  Loss: -0.4042  Acc@1: 75.0000 (64.2009)  Acc@5: 93.7500 (91.6762)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2640/4579]  eta: 0:11:32  Lr: 0.001875  Loss: -0.3036  Acc@1: 62.5000 (64.1850)  Acc@5: 93.7500 (91.6580)  time: 0.3591  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [2650/4579]  eta: 0:11:29  Lr: 0.001875  Loss: 0.4665  Acc@1: 62.5000 (64.1880)  Acc@5: 87.5000 (91.6565)  time: 0.3671  data: 0.0057  max mem: 2500
Train: Epoch[3/5]  [2660/4579]  eta: 0:11:25  Lr: 0.001875  Loss: -0.3576  Acc@1: 62.5000 (64.1747)  Acc@5: 93.7500 (91.6596)  time: 0.3647  data: 0.0043  max mem: 2500
Train: Epoch[3/5]  [2670/4579]  eta: 0:11:22  Lr: 0.001875  Loss: -0.6633  Acc@1: 62.5000 (64.1988)  Acc@5: 93.7500 (91.6698)  time: 0.3617  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [2680/4579]  eta: 0:11:18  Lr: 0.001875  Loss: 0.0612  Acc@1: 62.5000 (64.1831)  Acc@5: 93.7500 (91.6682)  time: 0.3620  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [2690/4579]  eta: 0:11:15  Lr: 0.001875  Loss: -0.8372  Acc@1: 62.5000 (64.1931)  Acc@5: 93.7500 (91.6829)  time: 0.3642  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [2700/4579]  eta: 0:11:11  Lr: 0.001875  Loss: -0.2438  Acc@1: 62.5000 (64.2100)  Acc@5: 93.7500 (91.6790)  time: 0.3654  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [2710/4579]  eta: 0:11:08  Lr: 0.001875  Loss: -0.4838  Acc@1: 62.5000 (64.2014)  Acc@5: 93.7500 (91.6751)  time: 0.3670  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [2720/4579]  eta: 0:11:04  Lr: 0.001875  Loss: -0.2343  Acc@1: 62.5000 (64.2020)  Acc@5: 93.7500 (91.6896)  time: 0.3657  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [2730/4579]  eta: 0:11:01  Lr: 0.001875  Loss: -0.1577  Acc@1: 62.5000 (64.1981)  Acc@5: 93.7500 (91.6926)  time: 0.3636  data: 0.0051  max mem: 2500
Train: Epoch[3/5]  [2740/4579]  eta: 0:10:57  Lr: 0.001875  Loss: -0.4851  Acc@1: 62.5000 (64.1942)  Acc@5: 93.7500 (91.6841)  time: 0.3639  data: 0.0068  max mem: 2500
Train: Epoch[3/5]  [2750/4579]  eta: 0:10:53  Lr: 0.001875  Loss: 0.0697  Acc@1: 62.5000 (64.1948)  Acc@5: 87.5000 (91.6780)  time: 0.3630  data: 0.0051  max mem: 2500
Train: Epoch[3/5]  [2760/4579]  eta: 0:10:50  Lr: 0.001875  Loss: 0.1166  Acc@1: 62.5000 (64.1864)  Acc@5: 87.5000 (91.6742)  time: 0.3638  data: 0.0038  max mem: 2500
Train: Epoch[3/5]  [2770/4579]  eta: 0:10:46  Lr: 0.001875  Loss: -0.1333  Acc@1: 68.7500 (64.1871)  Acc@5: 87.5000 (91.6614)  time: 0.3631  data: 0.0040  max mem: 2500
Train: Epoch[3/5]  [2780/4579]  eta: 0:10:43  Lr: 0.001875  Loss: -0.0890  Acc@1: 62.5000 (64.1810)  Acc@5: 87.5000 (91.6622)  time: 0.3685  data: 0.0084  max mem: 2500
Train: Epoch[3/5]  [2790/4579]  eta: 0:10:39  Lr: 0.001875  Loss: 0.0791  Acc@1: 56.2500 (64.1773)  Acc@5: 93.7500 (91.6540)  time: 0.3683  data: 0.0063  max mem: 2500
Train: Epoch[3/5]  [2800/4579]  eta: 0:10:36  Lr: 0.001875  Loss: -0.2022  Acc@1: 62.5000 (64.1869)  Acc@5: 93.7500 (91.6592)  time: 0.3607  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2810/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.4939  Acc@1: 68.7500 (64.1987)  Acc@5: 93.7500 (91.6667)  time: 0.3647  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2820/4579]  eta: 0:10:29  Lr: 0.001875  Loss: -0.2743  Acc@1: 62.5000 (64.1993)  Acc@5: 93.7500 (91.6608)  time: 0.3662  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [2830/4579]  eta: 0:10:25  Lr: 0.001875  Loss: 0.4343  Acc@1: 68.7500 (64.2088)  Acc@5: 93.7500 (91.6571)  time: 0.3626  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [2840/4579]  eta: 0:10:22  Lr: 0.001875  Loss: -0.7698  Acc@1: 68.7500 (64.2269)  Acc@5: 93.7500 (91.6579)  time: 0.3651  data: 0.0055  max mem: 2500
Train: Epoch[3/5]  [2850/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.3829  Acc@1: 68.7500 (64.2384)  Acc@5: 87.5000 (91.6542)  time: 0.3659  data: 0.0058  max mem: 2500
Train: Epoch[3/5]  [2860/4579]  eta: 0:10:15  Lr: 0.001875  Loss: -0.4218  Acc@1: 68.7500 (64.2476)  Acc@5: 93.7500 (91.6638)  time: 0.3634  data: 0.0040  max mem: 2500
Train: Epoch[3/5]  [2870/4579]  eta: 0:10:11  Lr: 0.001875  Loss: -0.2199  Acc@1: 68.7500 (64.2546)  Acc@5: 93.7500 (91.6688)  time: 0.3616  data: 0.0031  max mem: 2500
Train: Epoch[3/5]  [2880/4579]  eta: 0:10:07  Lr: 0.001875  Loss: -0.3173  Acc@1: 62.5000 (64.2572)  Acc@5: 93.7500 (91.6565)  time: 0.3605  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [2890/4579]  eta: 0:10:04  Lr: 0.001875  Loss: -0.3209  Acc@1: 62.5000 (64.2576)  Acc@5: 93.7500 (91.6551)  time: 0.3638  data: 0.0043  max mem: 2500
Train: Epoch[3/5]  [2900/4579]  eta: 0:10:00  Lr: 0.001875  Loss: -0.1825  Acc@1: 62.5000 (64.2602)  Acc@5: 93.7500 (91.6559)  time: 0.3675  data: 0.0053  max mem: 2500
Train: Epoch[3/5]  [2910/4579]  eta: 0:09:57  Lr: 0.001875  Loss: -0.1434  Acc@1: 62.5000 (64.2369)  Acc@5: 93.7500 (91.6545)  time: 0.3641  data: 0.0052  max mem: 2500
Train: Epoch[3/5]  [2920/4579]  eta: 0:09:53  Lr: 0.001875  Loss: 0.0139  Acc@1: 56.2500 (64.2310)  Acc@5: 87.5000 (91.6510)  time: 0.3593  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [2930/4579]  eta: 0:09:50  Lr: 0.001875  Loss: -0.4610  Acc@1: 56.2500 (64.2102)  Acc@5: 93.7500 (91.6517)  time: 0.3575  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2940/4579]  eta: 0:09:46  Lr: 0.001875  Loss: -0.2181  Acc@1: 62.5000 (64.2341)  Acc@5: 93.7500 (91.6440)  time: 0.3592  data: 0.0048  max mem: 2500
Train: Epoch[3/5]  [2950/4579]  eta: 0:09:43  Lr: 0.001875  Loss: -0.3046  Acc@1: 68.7500 (64.2579)  Acc@5: 93.7500 (91.6533)  time: 0.3593  data: 0.0047  max mem: 2500
Train: Epoch[3/5]  [2960/4579]  eta: 0:09:39  Lr: 0.001875  Loss: 0.0207  Acc@1: 68.7500 (64.2583)  Acc@5: 93.7500 (91.6603)  time: 0.3588  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [2970/4579]  eta: 0:09:35  Lr: 0.001875  Loss: -0.1175  Acc@1: 62.5000 (64.2671)  Acc@5: 93.7500 (91.6547)  time: 0.3602  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [2980/4579]  eta: 0:09:32  Lr: 0.001875  Loss: 0.1029  Acc@1: 68.7500 (64.2674)  Acc@5: 93.7500 (91.6576)  time: 0.3615  data: 0.0039  max mem: 2500
Train: Epoch[3/5]  [2990/4579]  eta: 0:09:28  Lr: 0.001875  Loss: 0.0610  Acc@1: 62.5000 (64.2720)  Acc@5: 93.7500 (91.6604)  time: 0.3612  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [3000/4579]  eta: 0:09:25  Lr: 0.001875  Loss: 0.6682  Acc@1: 68.7500 (64.2807)  Acc@5: 93.7500 (91.6653)  time: 0.3619  data: 0.0050  max mem: 2500
Train: Epoch[3/5]  [3010/4579]  eta: 0:09:21  Lr: 0.001875  Loss: 0.6760  Acc@1: 68.7500 (64.2851)  Acc@5: 93.7500 (91.6597)  time: 0.3670  data: 0.0049  max mem: 2500
Train: Epoch[3/5]  [3020/4579]  eta: 0:09:18  Lr: 0.001875  Loss: -0.9908  Acc@1: 68.7500 (64.2896)  Acc@5: 93.7500 (91.6729)  time: 0.3711  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3030/4579]  eta: 0:09:14  Lr: 0.001875  Loss: 0.1994  Acc@1: 62.5000 (64.2837)  Acc@5: 93.7500 (91.6653)  time: 0.3708  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [3040/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.3502  Acc@1: 62.5000 (64.2819)  Acc@5: 87.5000 (91.6639)  time: 0.3699  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [3050/4579]  eta: 0:09:07  Lr: 0.001875  Loss: 0.0984  Acc@1: 56.2500 (64.2617)  Acc@5: 93.7500 (91.6626)  time: 0.3658  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [3060/4579]  eta: 0:09:04  Lr: 0.001875  Loss: -0.4268  Acc@1: 56.2500 (64.2396)  Acc@5: 93.7500 (91.6592)  time: 0.3628  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [3070/4579]  eta: 0:09:00  Lr: 0.001875  Loss: 0.4609  Acc@1: 62.5000 (64.2523)  Acc@5: 93.7500 (91.6558)  time: 0.3597  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [3080/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.2846  Acc@1: 75.0000 (64.2912)  Acc@5: 93.7500 (91.6646)  time: 0.3573  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [3090/4579]  eta: 0:08:53  Lr: 0.001875  Loss: -0.9009  Acc@1: 68.7500 (64.2854)  Acc@5: 93.7500 (91.6694)  time: 0.3604  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [3100/4579]  eta: 0:08:49  Lr: 0.001875  Loss: -0.2839  Acc@1: 62.5000 (64.2676)  Acc@5: 93.7500 (91.6720)  time: 0.3608  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [3110/4579]  eta: 0:08:46  Lr: 0.001875  Loss: -0.5498  Acc@1: 62.5000 (64.2760)  Acc@5: 93.7500 (91.6827)  time: 0.3626  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [3120/4579]  eta: 0:08:42  Lr: 0.001875  Loss: -0.7688  Acc@1: 68.7500 (64.2723)  Acc@5: 93.7500 (91.6814)  time: 0.3632  data: 0.0054  max mem: 2500
Train: Epoch[3/5]  [3130/4579]  eta: 0:08:39  Lr: 0.001875  Loss: 0.2305  Acc@1: 62.5000 (64.2626)  Acc@5: 93.7500 (91.6920)  time: 0.3608  data: 0.0047  max mem: 2500
Train: Epoch[3/5]  [3140/4579]  eta: 0:08:35  Lr: 0.001875  Loss: -0.7241  Acc@1: 62.5000 (64.2749)  Acc@5: 93.7500 (91.6806)  time: 0.3618  data: 0.0042  max mem: 2500
Train: Epoch[3/5]  [3150/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.3122  Acc@1: 68.7500 (64.2693)  Acc@5: 93.7500 (91.6872)  time: 0.3629  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [3160/4579]  eta: 0:08:28  Lr: 0.001875  Loss: -0.1138  Acc@1: 68.7500 (64.2815)  Acc@5: 93.7500 (91.6957)  time: 0.3607  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [3170/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.6747  Acc@1: 62.5000 (64.2640)  Acc@5: 93.7500 (91.6883)  time: 0.3606  data: 0.0049  max mem: 2500
Train: Epoch[3/5]  [3180/4579]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5778  Acc@1: 62.5000 (64.2722)  Acc@5: 93.7500 (91.6909)  time: 0.3608  data: 0.0038  max mem: 2500
Train: Epoch[3/5]  [3190/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.7438  Acc@1: 68.7500 (64.2941)  Acc@5: 93.7500 (91.6954)  time: 0.3615  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [3200/4579]  eta: 0:08:14  Lr: 0.001875  Loss: -0.5929  Acc@1: 68.7500 (64.2924)  Acc@5: 93.7500 (91.7018)  time: 0.3673  data: 0.0089  max mem: 2500
Train: Epoch[3/5]  [3210/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.1541  Acc@1: 62.5000 (64.2868)  Acc@5: 93.7500 (91.6985)  time: 0.3691  data: 0.0109  max mem: 2500
Train: Epoch[3/5]  [3220/4579]  eta: 0:08:07  Lr: 0.001875  Loss: -0.5252  Acc@1: 68.7500 (64.2929)  Acc@5: 93.7500 (91.7029)  time: 0.3643  data: 0.0056  max mem: 2500
Train: Epoch[3/5]  [3230/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.2776  Acc@1: 68.7500 (64.2970)  Acc@5: 93.7500 (91.7092)  time: 0.3623  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [3240/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.1757  Acc@1: 62.5000 (64.3031)  Acc@5: 93.7500 (91.7039)  time: 0.3630  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [3250/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.2779  Acc@1: 68.7500 (64.3206)  Acc@5: 93.7500 (91.7141)  time: 0.3631  data: 0.0050  max mem: 2500
Train: Epoch[3/5]  [3260/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.4585  Acc@1: 62.5000 (64.3054)  Acc@5: 93.7500 (91.7146)  time: 0.3631  data: 0.0045  max mem: 2500
Train: Epoch[3/5]  [3270/4579]  eta: 0:07:49  Lr: 0.001875  Loss: -0.0986  Acc@1: 62.5000 (64.3076)  Acc@5: 93.7500 (91.7113)  time: 0.3604  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3280/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.4397  Acc@1: 62.5000 (64.3116)  Acc@5: 87.5000 (91.7117)  time: 0.3588  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3290/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.0478  Acc@1: 68.7500 (64.3175)  Acc@5: 93.7500 (91.7046)  time: 0.3593  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [3300/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.2949  Acc@1: 68.7500 (64.3252)  Acc@5: 93.7500 (91.7071)  time: 0.3600  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [3310/4579]  eta: 0:07:34  Lr: 0.001875  Loss: -0.3906  Acc@1: 62.5000 (64.2970)  Acc@5: 93.7500 (91.6925)  time: 0.3608  data: 0.0040  max mem: 2500
Train: Epoch[3/5]  [3320/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.3774  Acc@1: 62.5000 (64.3048)  Acc@5: 93.7500 (91.6968)  time: 0.3636  data: 0.0061  max mem: 2500
Train: Epoch[3/5]  [3330/4579]  eta: 0:07:27  Lr: 0.001875  Loss: -0.0561  Acc@1: 68.7500 (64.3031)  Acc@5: 93.7500 (91.6917)  time: 0.3648  data: 0.0053  max mem: 2500
Train: Epoch[3/5]  [3340/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.0046  Acc@1: 68.7500 (64.3183)  Acc@5: 87.5000 (91.6885)  time: 0.3618  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3350/4579]  eta: 0:07:20  Lr: 0.001875  Loss: 0.0202  Acc@1: 68.7500 (64.3129)  Acc@5: 93.7500 (91.6928)  time: 0.3611  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3360/4579]  eta: 0:07:17  Lr: 0.001875  Loss: 0.1212  Acc@1: 68.7500 (64.3038)  Acc@5: 93.7500 (91.6784)  time: 0.3620  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [3370/4579]  eta: 0:07:13  Lr: 0.001875  Loss: -0.2244  Acc@1: 68.7500 (64.3207)  Acc@5: 87.5000 (91.6809)  time: 0.3640  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3380/4579]  eta: 0:07:09  Lr: 0.001875  Loss: 0.0861  Acc@1: 62.5000 (64.3042)  Acc@5: 93.7500 (91.6852)  time: 0.3558  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3390/4579]  eta: 0:07:06  Lr: 0.001875  Loss: -0.0332  Acc@1: 62.5000 (64.3118)  Acc@5: 93.7500 (91.6839)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3400/4579]  eta: 0:07:02  Lr: 0.001875  Loss: -0.2445  Acc@1: 62.5000 (64.3175)  Acc@5: 93.7500 (91.6826)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3410/4579]  eta: 0:06:58  Lr: 0.001875  Loss: -0.1503  Acc@1: 62.5000 (64.3103)  Acc@5: 93.7500 (91.6758)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3420/4579]  eta: 0:06:55  Lr: 0.001875  Loss: -0.1623  Acc@1: 62.5000 (64.3233)  Acc@5: 93.7500 (91.6819)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3430/4579]  eta: 0:06:51  Lr: 0.001875  Loss: -0.3014  Acc@1: 68.7500 (64.3344)  Acc@5: 93.7500 (91.6843)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3440/4579]  eta: 0:06:48  Lr: 0.001875  Loss: 0.0224  Acc@1: 68.7500 (64.3381)  Acc@5: 93.7500 (91.6903)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3450/4579]  eta: 0:06:44  Lr: 0.001875  Loss: -0.4176  Acc@1: 62.5000 (64.3419)  Acc@5: 93.7500 (91.6981)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3460/4579]  eta: 0:06:40  Lr: 0.001875  Loss: -0.4450  Acc@1: 68.7500 (64.3564)  Acc@5: 93.7500 (91.6986)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3470/4579]  eta: 0:06:37  Lr: 0.001875  Loss: -0.1386  Acc@1: 62.5000 (64.3402)  Acc@5: 87.5000 (91.6847)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3480/4579]  eta: 0:06:33  Lr: 0.001875  Loss: -0.5331  Acc@1: 62.5000 (64.3511)  Acc@5: 93.7500 (91.6942)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3490/4579]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6626  Acc@1: 68.7500 (64.3601)  Acc@5: 93.7500 (91.6893)  time: 0.3535  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3500/4579]  eta: 0:06:26  Lr: 0.001875  Loss: 0.1017  Acc@1: 62.5000 (64.3441)  Acc@5: 87.5000 (91.6774)  time: 0.3601  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [3510/4579]  eta: 0:06:22  Lr: 0.001875  Loss: -0.2929  Acc@1: 68.7500 (64.3673)  Acc@5: 93.7500 (91.6886)  time: 0.3631  data: 0.0057  max mem: 2500
Train: Epoch[3/5]  [3520/4579]  eta: 0:06:19  Lr: 0.001875  Loss: -0.2892  Acc@1: 68.7500 (64.3780)  Acc@5: 93.7500 (91.6945)  time: 0.3629  data: 0.0062  max mem: 2500
Train: Epoch[3/5]  [3530/4579]  eta: 0:06:15  Lr: 0.001875  Loss: -0.3850  Acc@1: 62.5000 (64.3709)  Acc@5: 93.7500 (91.6897)  time: 0.3608  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [3540/4579]  eta: 0:06:12  Lr: 0.001875  Loss: -0.0104  Acc@1: 68.7500 (64.3745)  Acc@5: 93.7500 (91.6920)  time: 0.3617  data: 0.0046  max mem: 2500
Train: Epoch[3/5]  [3550/4579]  eta: 0:06:08  Lr: 0.001875  Loss: 0.1832  Acc@1: 62.5000 (64.3657)  Acc@5: 93.7500 (91.6907)  time: 0.3567  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [3560/4579]  eta: 0:06:05  Lr: 0.001875  Loss: -0.2138  Acc@1: 62.5000 (64.3692)  Acc@5: 93.7500 (91.6930)  time: 0.3558  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3570/4579]  eta: 0:06:01  Lr: 0.001875  Loss: 0.0400  Acc@1: 62.5000 (64.3570)  Acc@5: 93.7500 (91.6883)  time: 0.3650  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [3580/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.1267  Acc@1: 62.5000 (64.3623)  Acc@5: 93.7500 (91.7010)  time: 0.3706  data: 0.0047  max mem: 2500
Train: Epoch[3/5]  [3590/4579]  eta: 0:05:54  Lr: 0.001875  Loss: -0.0764  Acc@1: 68.7500 (64.3693)  Acc@5: 93.7500 (91.7137)  time: 0.3754  data: 0.0055  max mem: 2500
Train: Epoch[3/5]  [3600/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.0981  Acc@1: 68.7500 (64.3762)  Acc@5: 93.7500 (91.7141)  time: 0.3701  data: 0.0044  max mem: 2500
Train: Epoch[3/5]  [3610/4579]  eta: 0:05:47  Lr: 0.001875  Loss: 0.2680  Acc@1: 62.5000 (64.3831)  Acc@5: 93.7500 (91.7215)  time: 0.3613  data: 0.0040  max mem: 2500
Train: Epoch[3/5]  [3620/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.0007  Acc@1: 62.5000 (64.3831)  Acc@5: 93.7500 (91.7271)  time: 0.3660  data: 0.0085  max mem: 2500
Train: Epoch[3/5]  [3630/4579]  eta: 0:05:40  Lr: 0.001875  Loss: -0.6191  Acc@1: 62.5000 (64.3900)  Acc@5: 93.7500 (91.7223)  time: 0.3645  data: 0.0064  max mem: 2500
Train: Epoch[3/5]  [3640/4579]  eta: 0:05:36  Lr: 0.001875  Loss: 0.8081  Acc@1: 62.5000 (64.3865)  Acc@5: 87.5000 (91.7227)  time: 0.3604  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [3650/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.2977  Acc@1: 62.5000 (64.3694)  Acc@5: 87.5000 (91.7163)  time: 0.3628  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [3660/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.7156  Acc@1: 62.5000 (64.3711)  Acc@5: 87.5000 (91.7099)  time: 0.3630  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3670/4579]  eta: 0:05:25  Lr: 0.001875  Loss: 0.3773  Acc@1: 62.5000 (64.3558)  Acc@5: 87.5000 (91.7053)  time: 0.3593  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3680/4579]  eta: 0:05:22  Lr: 0.001875  Loss: 0.0749  Acc@1: 62.5000 (64.3677)  Acc@5: 93.7500 (91.7125)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3690/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.4205  Acc@1: 75.0000 (64.3880)  Acc@5: 93.7500 (91.7197)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:14  Lr: 0.001875  Loss: -0.0080  Acc@1: 68.7500 (64.3981)  Acc@5: 93.7500 (91.7218)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3710/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.7693  Acc@1: 62.5000 (64.3964)  Acc@5: 93.7500 (91.7138)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3720/4579]  eta: 0:05:07  Lr: 0.001875  Loss: -0.3568  Acc@1: 62.5000 (64.3947)  Acc@5: 93.7500 (91.7092)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3730/4579]  eta: 0:05:04  Lr: 0.001875  Loss: -0.5730  Acc@1: 62.5000 (64.4030)  Acc@5: 93.7500 (91.7180)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3740/4579]  eta: 0:05:00  Lr: 0.001875  Loss: 0.4402  Acc@1: 62.5000 (64.3862)  Acc@5: 93.7500 (91.7068)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3750/4579]  eta: 0:04:56  Lr: 0.001875  Loss: -0.8053  Acc@1: 62.5000 (64.4128)  Acc@5: 87.5000 (91.7072)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3760/4579]  eta: 0:04:53  Lr: 0.001875  Loss: -0.4411  Acc@1: 68.7500 (64.4077)  Acc@5: 93.7500 (91.7010)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3770/4579]  eta: 0:04:49  Lr: 0.001875  Loss: -0.2673  Acc@1: 62.5000 (64.4126)  Acc@5: 93.7500 (91.7081)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3780/4579]  eta: 0:04:46  Lr: 0.001875  Loss: -0.1566  Acc@1: 62.5000 (64.4043)  Acc@5: 93.7500 (91.7036)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3790/4579]  eta: 0:04:42  Lr: 0.001875  Loss: 0.0474  Acc@1: 62.5000 (64.4058)  Acc@5: 87.5000 (91.6908)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3800/4579]  eta: 0:04:38  Lr: 0.001875  Loss: -0.5129  Acc@1: 68.7500 (64.4140)  Acc@5: 93.7500 (91.6913)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3810/4579]  eta: 0:04:35  Lr: 0.001875  Loss: -0.4181  Acc@1: 68.7500 (64.4122)  Acc@5: 93.7500 (91.6967)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3820/4579]  eta: 0:04:31  Lr: 0.001875  Loss: 0.1160  Acc@1: 68.7500 (64.4203)  Acc@5: 93.7500 (91.6890)  time: 0.3534  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3830/4579]  eta: 0:04:28  Lr: 0.001875  Loss: -0.4487  Acc@1: 68.7500 (64.4349)  Acc@5: 93.7500 (91.7042)  time: 0.3553  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3840/4579]  eta: 0:04:24  Lr: 0.001875  Loss: -0.2332  Acc@1: 56.2500 (64.4119)  Acc@5: 93.7500 (91.7063)  time: 0.3559  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [3850/4579]  eta: 0:04:20  Lr: 0.001875  Loss: -0.1752  Acc@1: 56.2500 (64.4135)  Acc@5: 93.7500 (91.7083)  time: 0.3564  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:17  Lr: 0.001875  Loss: 0.5261  Acc@1: 62.5000 (64.4198)  Acc@5: 93.7500 (91.7071)  time: 0.3582  data: 0.0045  max mem: 2500
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:13  Lr: 0.001875  Loss: 0.0177  Acc@1: 62.5000 (64.4100)  Acc@5: 93.7500 (91.7027)  time: 0.3578  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:10  Lr: 0.001875  Loss: -0.3865  Acc@1: 62.5000 (64.4099)  Acc@5: 93.7500 (91.7064)  time: 0.3542  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3890/4579]  eta: 0:04:06  Lr: 0.001875  Loss: -0.9902  Acc@1: 62.5000 (64.4179)  Acc@5: 93.7500 (91.7052)  time: 0.3539  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3900/4579]  eta: 0:04:03  Lr: 0.001875  Loss: -0.5950  Acc@1: 68.7500 (64.4402)  Acc@5: 93.7500 (91.7105)  time: 0.3556  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [3910/4579]  eta: 0:03:59  Lr: 0.001875  Loss: 0.4940  Acc@1: 68.7500 (64.4416)  Acc@5: 93.7500 (91.7077)  time: 0.3562  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3920/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.4500  Acc@1: 68.7500 (64.4447)  Acc@5: 93.7500 (91.7081)  time: 0.3621  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3930/4579]  eta: 0:03:52  Lr: 0.001875  Loss: 0.1207  Acc@1: 68.7500 (64.4540)  Acc@5: 93.7500 (91.7069)  time: 0.3631  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [3940/4579]  eta: 0:03:48  Lr: 0.001875  Loss: -0.4541  Acc@1: 68.7500 (64.4586)  Acc@5: 93.7500 (91.7058)  time: 0.3626  data: 0.0039  max mem: 2500
Train: Epoch[3/5]  [3950/4579]  eta: 0:03:45  Lr: 0.001875  Loss: -0.6707  Acc@1: 68.7500 (64.4742)  Acc@5: 93.7500 (91.7094)  time: 0.3605  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [3960/4579]  eta: 0:03:41  Lr: 0.001875  Loss: 0.1212  Acc@1: 62.5000 (64.4645)  Acc@5: 93.7500 (91.7114)  time: 0.3551  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [3970/4579]  eta: 0:03:38  Lr: 0.001875  Loss: -0.1744  Acc@1: 62.5000 (64.4642)  Acc@5: 93.7500 (91.7181)  time: 0.3580  data: 0.0039  max mem: 2500
Train: Epoch[3/5]  [3980/4579]  eta: 0:03:34  Lr: 0.001875  Loss: -0.5652  Acc@1: 68.7500 (64.4687)  Acc@5: 93.7500 (91.7200)  time: 0.3581  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [3990/4579]  eta: 0:03:30  Lr: 0.001875  Loss: -0.2537  Acc@1: 62.5000 (64.4560)  Acc@5: 93.7500 (91.7142)  time: 0.3551  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [4000/4579]  eta: 0:03:27  Lr: 0.001875  Loss: 0.2661  Acc@1: 62.5000 (64.4558)  Acc@5: 87.5000 (91.7083)  time: 0.3551  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:23  Lr: 0.001875  Loss: -0.0101  Acc@1: 68.7500 (64.4571)  Acc@5: 93.7500 (91.7134)  time: 0.3595  data: 0.0049  max mem: 2500
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:20  Lr: 0.001875  Loss: -0.1215  Acc@1: 68.7500 (64.4678)  Acc@5: 93.7500 (91.7169)  time: 0.3605  data: 0.0042  max mem: 2500
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:16  Lr: 0.001875  Loss: 0.4246  Acc@1: 62.5000 (64.4521)  Acc@5: 93.7500 (91.7189)  time: 0.3568  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:12  Lr: 0.001875  Loss: -0.4095  Acc@1: 56.2500 (64.4565)  Acc@5: 93.7500 (91.7223)  time: 0.3589  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:09  Lr: 0.001875  Loss: -0.1073  Acc@1: 68.7500 (64.4640)  Acc@5: 93.7500 (91.7274)  time: 0.3617  data: 0.0054  max mem: 2500
Train: Epoch[3/5]  [4060/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.2111  Acc@1: 68.7500 (64.4669)  Acc@5: 93.7500 (91.7293)  time: 0.3547  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [4070/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 0.1235  Acc@1: 56.2500 (64.4406)  Acc@5: 93.7500 (91.7296)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4080/4579]  eta: 0:02:58  Lr: 0.001875  Loss: -0.1137  Acc@1: 56.2500 (64.4419)  Acc@5: 93.7500 (91.7315)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4090/4579]  eta: 0:02:55  Lr: 0.001875  Loss: -0.0742  Acc@1: 68.7500 (64.4433)  Acc@5: 93.7500 (91.7319)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4100/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.1221  Acc@1: 68.7500 (64.4446)  Acc@5: 93.7500 (91.7322)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4110/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.0410  Acc@1: 68.7500 (64.4506)  Acc@5: 93.7500 (91.7234)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4120/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.4368  Acc@1: 68.7500 (64.4610)  Acc@5: 93.7500 (91.7299)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4130/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.3171  Acc@1: 68.7500 (64.4547)  Acc@5: 93.7500 (91.7257)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4140/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.0927  Acc@1: 68.7500 (64.4560)  Acc@5: 93.7500 (91.7245)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.7088  Acc@1: 68.7500 (64.4619)  Acc@5: 87.5000 (91.7234)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.1556  Acc@1: 68.7500 (64.4737)  Acc@5: 93.7500 (91.7267)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0089  Acc@1: 68.7500 (64.4705)  Acc@5: 93.7500 (91.7301)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:22  Lr: 0.001875  Loss: -0.4373  Acc@1: 68.7500 (64.4792)  Acc@5: 93.7500 (91.7334)  time: 0.3532  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.5436  Acc@1: 68.7500 (64.4879)  Acc@5: 93.7500 (91.7338)  time: 0.3615  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:15  Lr: 0.001875  Loss: -0.4677  Acc@1: 68.7500 (64.4802)  Acc@5: 93.7500 (91.7282)  time: 0.3668  data: 0.0040  max mem: 2500
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:12  Lr: 0.001875  Loss: 0.2716  Acc@1: 62.5000 (64.4710)  Acc@5: 93.7500 (91.7211)  time: 0.3626  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.0054  Acc@1: 62.5000 (64.4723)  Acc@5: 93.7500 (91.7289)  time: 0.3575  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:04  Lr: 0.001875  Loss: -0.4814  Acc@1: 68.7500 (64.4809)  Acc@5: 93.7500 (91.7395)  time: 0.3545  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [4240/4579]  eta: 0:02:01  Lr: 0.001875  Loss: 0.3905  Acc@1: 68.7500 (64.4866)  Acc@5: 93.7500 (91.7369)  time: 0.3533  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [4250/4579]  eta: 0:01:57  Lr: 0.001875  Loss: -0.1313  Acc@1: 62.5000 (64.4804)  Acc@5: 93.7500 (91.7402)  time: 0.3506  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4260/4579]  eta: 0:01:54  Lr: 0.001875  Loss: -0.5786  Acc@1: 62.5000 (64.4787)  Acc@5: 93.7500 (91.7420)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4270/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.0228  Acc@1: 62.5000 (64.4770)  Acc@5: 93.7500 (91.7350)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4280/4579]  eta: 0:01:46  Lr: 0.001875  Loss: -0.0071  Acc@1: 62.5000 (64.4768)  Acc@5: 87.5000 (91.7265)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:43  Lr: 0.001875  Loss: -0.7187  Acc@1: 68.7500 (64.4823)  Acc@5: 87.5000 (91.7312)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:39  Lr: 0.001875  Loss: -0.4948  Acc@1: 68.7500 (64.4981)  Acc@5: 93.7500 (91.7388)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 0.0848  Acc@1: 68.7500 (64.4978)  Acc@5: 93.7500 (91.7435)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:32  Lr: 0.001875  Loss: -0.1722  Acc@1: 62.5000 (64.4975)  Acc@5: 87.5000 (91.7366)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:29  Lr: 0.001875  Loss: -0.2290  Acc@1: 62.5000 (64.4987)  Acc@5: 93.7500 (91.7412)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:25  Lr: 0.001875  Loss: 0.1585  Acc@1: 68.7500 (64.4969)  Acc@5: 93.7500 (91.7459)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2952  Acc@1: 56.2500 (64.4722)  Acc@5: 93.7500 (91.7476)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:18  Lr: 0.001875  Loss: -0.3634  Acc@1: 56.2500 (64.4749)  Acc@5: 93.7500 (91.7421)  time: 0.3539  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4593  Acc@1: 62.5000 (64.4504)  Acc@5: 87.5000 (91.7367)  time: 0.3527  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0652  Acc@1: 62.5000 (64.4445)  Acc@5: 87.5000 (91.7370)  time: 0.3532  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1394  Acc@1: 62.5000 (64.4529)  Acc@5: 93.7500 (91.7374)  time: 0.3551  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:03  Lr: 0.001875  Loss: -0.2082  Acc@1: 62.5000 (64.4555)  Acc@5: 93.7500 (91.7391)  time: 0.3595  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [4410/4579]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6277  Acc@1: 62.5000 (64.4497)  Acc@5: 93.7500 (91.7323)  time: 0.3592  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [4420/4579]  eta: 0:00:56  Lr: 0.001875  Loss: -0.4378  Acc@1: 56.2500 (64.4410)  Acc@5: 87.5000 (91.7341)  time: 0.3568  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [4430/4579]  eta: 0:00:53  Lr: 0.001875  Loss: -0.2596  Acc@1: 62.5000 (64.4409)  Acc@5: 93.7500 (91.7344)  time: 0.3557  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1347  Acc@1: 68.7500 (64.4478)  Acc@5: 93.7500 (91.7319)  time: 0.3544  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:46  Lr: 0.001875  Loss: 0.3163  Acc@1: 68.7500 (64.4546)  Acc@5: 87.5000 (91.7322)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:42  Lr: 0.001875  Loss: -0.2478  Acc@1: 68.7500 (64.4614)  Acc@5: 93.7500 (91.7353)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5341  Acc@1: 68.7500 (64.4780)  Acc@5: 93.7500 (91.7440)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6630  Acc@1: 68.7500 (64.4820)  Acc@5: 93.7500 (91.7457)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.3415  Acc@1: 62.5000 (64.4720)  Acc@5: 93.7500 (91.7432)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6335  Acc@1: 62.5000 (64.4676)  Acc@5: 87.5000 (91.7421)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3496  Acc@1: 62.5000 (64.4702)  Acc@5: 87.5000 (91.7396)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7667  Acc@1: 68.7500 (64.4783)  Acc@5: 87.5000 (91.7399)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2434  Acc@1: 68.7500 (64.4932)  Acc@5: 93.7500 (91.7485)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.5951  Acc@1: 68.7500 (64.5053)  Acc@5: 93.7500 (91.7474)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.1136  Acc@1: 62.5000 (64.4954)  Acc@5: 87.5000 (91.7395)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1036  Acc@1: 62.5000 (64.4924)  Acc@5: 87.5000 (91.7384)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.4668  Acc@1: 62.5000 (64.4840)  Acc@5: 93.7500 (91.7414)  time: 0.3556  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7162  Acc@1: 68.7500 (64.4867)  Acc@5: 93.7500 (91.7428)  time: 0.3509  data: 0.0024  max mem: 2500
Train: Epoch[3/5] Total time: 0:27:16 (0.3574 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 219723, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 219739, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 219755, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 219691, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.7162  Acc@1: 68.7500 (64.4867)  Acc@5: 93.7500 (91.7428)
Train: Epoch[4/5]  [   0/4579]  eta: 1:11:39  Lr: 0.001875  Loss: -0.3160  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.9390  data: 0.5895  max mem: 2500
Train: Epoch[4/5]  [  10/4579]  eta: 0:31:44  Lr: 0.001875  Loss: 0.0399  Acc@1: 68.7500 (67.0455)  Acc@5: 93.7500 (95.4545)  time: 0.4167  data: 0.0573  max mem: 2500
Train: Epoch[4/5]  [  20/4579]  eta: 0:29:35  Lr: 0.001875  Loss: -0.6607  Acc@1: 68.7500 (66.3690)  Acc@5: 93.7500 (94.0476)  time: 0.3619  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [  30/4579]  eta: 0:28:37  Lr: 0.001875  Loss: -0.1826  Acc@1: 68.7500 (67.3387)  Acc@5: 93.7500 (94.1532)  time: 0.3560  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [  40/4579]  eta: 0:28:06  Lr: 0.001875  Loss: 0.2263  Acc@1: 68.7500 (66.3110)  Acc@5: 93.7500 (92.8354)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [  50/4579]  eta: 0:27:43  Lr: 0.001875  Loss: -0.6735  Acc@1: 62.5000 (66.6667)  Acc@5: 93.7500 (93.3824)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  60/4579]  eta: 0:27:24  Lr: 0.001875  Loss: 0.1231  Acc@1: 68.7500 (66.8033)  Acc@5: 93.7500 (92.8279)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  70/4579]  eta: 0:27:10  Lr: 0.001875  Loss: -0.6108  Acc@1: 68.7500 (66.8134)  Acc@5: 87.5000 (92.3415)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  80/4579]  eta: 0:26:58  Lr: 0.001875  Loss: 0.3976  Acc@1: 68.7500 (66.5895)  Acc@5: 93.7500 (92.2840)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  90/4579]  eta: 0:26:49  Lr: 0.001875  Loss: -0.0442  Acc@1: 62.5000 (66.1401)  Acc@5: 93.7500 (92.2390)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 100/4579]  eta: 0:26:40  Lr: 0.001875  Loss: 0.1167  Acc@1: 62.5000 (66.5223)  Acc@5: 93.7500 (92.0792)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 110/4579]  eta: 0:26:35  Lr: 0.001875  Loss: 0.0437  Acc@1: 68.7500 (66.6104)  Acc@5: 87.5000 (91.8919)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 120/4579]  eta: 0:26:31  Lr: 0.001875  Loss: -0.2310  Acc@1: 62.5000 (66.1674)  Acc@5: 93.7500 (91.9938)  time: 0.3555  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 130/4579]  eta: 0:26:30  Lr: 0.001875  Loss: -0.6627  Acc@1: 62.5000 (66.4122)  Acc@5: 93.7500 (92.2233)  time: 0.3609  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 140/4579]  eta: 0:26:25  Lr: 0.001875  Loss: -0.2173  Acc@1: 68.7500 (66.1348)  Acc@5: 93.7500 (92.3759)  time: 0.3584  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 150/4579]  eta: 0:26:18  Lr: 0.001875  Loss: -0.3969  Acc@1: 62.5000 (66.0596)  Acc@5: 93.7500 (92.3427)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 160/4579]  eta: 0:26:12  Lr: 0.001875  Loss: -0.2160  Acc@1: 68.7500 (66.1102)  Acc@5: 93.7500 (92.2360)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 170/4579]  eta: 0:26:06  Lr: 0.001875  Loss: -0.0495  Acc@1: 68.7500 (65.7895)  Acc@5: 87.5000 (92.0687)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 180/4579]  eta: 0:26:01  Lr: 0.001875  Loss: -0.3348  Acc@1: 62.5000 (65.8494)  Acc@5: 93.7500 (92.1271)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 190/4579]  eta: 0:25:56  Lr: 0.001875  Loss: -0.0641  Acc@1: 68.7500 (65.9686)  Acc@5: 93.7500 (92.0484)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 200/4579]  eta: 0:25:50  Lr: 0.001875  Loss: 0.1013  Acc@1: 68.7500 (66.0448)  Acc@5: 93.7500 (92.0398)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 210/4579]  eta: 0:25:45  Lr: 0.001875  Loss: -0.2256  Acc@1: 68.7500 (66.1730)  Acc@5: 93.7500 (92.2690)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 220/4579]  eta: 0:25:40  Lr: 0.001875  Loss: 0.6837  Acc@1: 68.7500 (66.1482)  Acc@5: 93.7500 (92.1946)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 230/4579]  eta: 0:25:35  Lr: 0.001875  Loss: -0.2264  Acc@1: 62.5000 (65.9903)  Acc@5: 93.7500 (92.2890)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 240/4579]  eta: 0:25:30  Lr: 0.001875  Loss: -0.1217  Acc@1: 62.5000 (66.2085)  Acc@5: 93.7500 (92.4274)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 250/4579]  eta: 0:25:26  Lr: 0.001875  Loss: 0.4677  Acc@1: 68.7500 (66.0359)  Acc@5: 93.7500 (92.3556)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 260/4579]  eta: 0:25:23  Lr: 0.001875  Loss: -0.4545  Acc@1: 68.7500 (66.1638)  Acc@5: 93.7500 (92.4090)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 270/4579]  eta: 0:25:20  Lr: 0.001875  Loss: 0.7951  Acc@1: 62.5000 (65.8672)  Acc@5: 93.7500 (92.2740)  time: 0.3553  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 280/4579]  eta: 0:25:18  Lr: 0.001875  Loss: -0.6803  Acc@1: 62.5000 (66.0810)  Acc@5: 87.5000 (92.2598)  time: 0.3589  data: 0.0036  max mem: 2500
Train: Epoch[4/5]  [ 290/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 0.1742  Acc@1: 68.7500 (66.0438)  Acc@5: 93.7500 (92.2251)  time: 0.3572  data: 0.0036  max mem: 2500
Train: Epoch[4/5]  [ 300/4579]  eta: 0:25:10  Lr: 0.001875  Loss: -0.0146  Acc@1: 68.7500 (66.0299)  Acc@5: 93.7500 (92.2135)  time: 0.3529  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 310/4579]  eta: 0:25:07  Lr: 0.001875  Loss: -0.1955  Acc@1: 62.5000 (65.9767)  Acc@5: 93.7500 (92.1021)  time: 0.3537  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 320/4579]  eta: 0:25:05  Lr: 0.001875  Loss: -0.0598  Acc@1: 62.5000 (66.1215)  Acc@5: 87.5000 (92.0171)  time: 0.3599  data: 0.0033  max mem: 2500
Train: Epoch[4/5]  [ 330/4579]  eta: 0:25:02  Lr: 0.001875  Loss: 0.0091  Acc@1: 62.5000 (65.9743)  Acc@5: 87.5000 (91.7485)  time: 0.3613  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [ 340/4579]  eta: 0:24:59  Lr: 0.001875  Loss: -0.2466  Acc@1: 62.5000 (66.0374)  Acc@5: 87.5000 (91.7339)  time: 0.3589  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 350/4579]  eta: 0:24:57  Lr: 0.001875  Loss: -0.5342  Acc@1: 68.7500 (66.1681)  Acc@5: 93.7500 (91.8447)  time: 0.3616  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [ 360/4579]  eta: 0:24:54  Lr: 0.001875  Loss: -0.1886  Acc@1: 68.7500 (66.2050)  Acc@5: 93.7500 (91.7763)  time: 0.3591  data: 0.0044  max mem: 2500
Train: Epoch[4/5]  [ 370/4579]  eta: 0:24:50  Lr: 0.001875  Loss: -0.0876  Acc@1: 62.5000 (66.1557)  Acc@5: 87.5000 (91.6947)  time: 0.3539  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 380/4579]  eta: 0:24:46  Lr: 0.001875  Loss: -0.1048  Acc@1: 68.7500 (66.1745)  Acc@5: 87.5000 (91.6995)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 390/4579]  eta: 0:24:42  Lr: 0.001875  Loss: -0.5081  Acc@1: 68.7500 (66.1125)  Acc@5: 87.5000 (91.5761)  time: 0.3514  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 400/4579]  eta: 0:24:39  Lr: 0.001875  Loss: -0.0264  Acc@1: 62.5000 (66.0380)  Acc@5: 87.5000 (91.5991)  time: 0.3532  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 410/4579]  eta: 0:24:35  Lr: 0.001875  Loss: -0.1240  Acc@1: 68.7500 (66.1648)  Acc@5: 93.7500 (91.6515)  time: 0.3533  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 420/4579]  eta: 0:24:31  Lr: 0.001875  Loss: -0.5075  Acc@1: 68.7500 (66.2262)  Acc@5: 93.7500 (91.7607)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 430/4579]  eta: 0:24:27  Lr: 0.001875  Loss: -0.2756  Acc@1: 68.7500 (66.2993)  Acc@5: 93.7500 (91.8213)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 440/4579]  eta: 0:24:23  Lr: 0.001875  Loss: -0.5705  Acc@1: 68.7500 (66.3974)  Acc@5: 93.7500 (91.9076)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 450/4579]  eta: 0:24:19  Lr: 0.001875  Loss: -0.0646  Acc@1: 68.7500 (66.2417)  Acc@5: 93.7500 (91.8376)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 460/4579]  eta: 0:24:15  Lr: 0.001875  Loss: -0.3647  Acc@1: 62.5000 (66.2148)  Acc@5: 87.5000 (91.8791)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 470/4579]  eta: 0:24:11  Lr: 0.001875  Loss: 0.2992  Acc@1: 56.2500 (65.9766)  Acc@5: 87.5000 (91.7330)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 480/4579]  eta: 0:24:07  Lr: 0.001875  Loss: -0.0583  Acc@1: 62.5000 (65.9563)  Acc@5: 87.5000 (91.6580)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 490/4579]  eta: 0:24:03  Lr: 0.001875  Loss: 0.1092  Acc@1: 56.2500 (65.7077)  Acc@5: 93.7500 (91.6752)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 500/4579]  eta: 0:23:59  Lr: 0.001875  Loss: -0.3224  Acc@1: 56.2500 (65.5689)  Acc@5: 93.7500 (91.6791)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 510/4579]  eta: 0:23:56  Lr: 0.001875  Loss: -0.4506  Acc@1: 56.2500 (65.4599)  Acc@5: 93.7500 (91.6463)  time: 0.3565  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [ 520/4579]  eta: 0:23:53  Lr: 0.001875  Loss: -0.1876  Acc@1: 62.5000 (65.5230)  Acc@5: 93.7500 (91.7466)  time: 0.3559  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [ 530/4579]  eta: 0:23:49  Lr: 0.001875  Loss: -0.7816  Acc@1: 62.5000 (65.4896)  Acc@5: 93.7500 (91.7255)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 540/4579]  eta: 0:23:45  Lr: 0.001875  Loss: -0.6956  Acc@1: 62.5000 (65.5152)  Acc@5: 87.5000 (91.7167)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 550/4579]  eta: 0:23:41  Lr: 0.001875  Loss: -0.6773  Acc@1: 62.5000 (65.5059)  Acc@5: 93.7500 (91.7309)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 560/4579]  eta: 0:23:37  Lr: 0.001875  Loss: -0.5178  Acc@1: 62.5000 (65.5080)  Acc@5: 93.7500 (91.7669)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 570/4579]  eta: 0:23:33  Lr: 0.001875  Loss: -0.0091  Acc@1: 62.5000 (65.4444)  Acc@5: 93.7500 (91.7141)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 580/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.3010  Acc@1: 62.5000 (65.4367)  Acc@5: 93.7500 (91.7491)  time: 0.3526  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 590/4579]  eta: 0:23:27  Lr: 0.001875  Loss: -0.3181  Acc@1: 62.5000 (65.4294)  Acc@5: 93.7500 (91.7195)  time: 0.3599  data: 0.0037  max mem: 2500
Train: Epoch[4/5]  [ 600/4579]  eta: 0:23:23  Lr: 0.001875  Loss: -0.6901  Acc@1: 62.5000 (65.3598)  Acc@5: 93.7500 (91.7637)  time: 0.3589  data: 0.0039  max mem: 2500
Train: Epoch[4/5]  [ 610/4579]  eta: 0:23:19  Lr: 0.001875  Loss: -0.1493  Acc@1: 62.5000 (65.3642)  Acc@5: 93.7500 (91.7962)  time: 0.3520  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 620/4579]  eta: 0:23:16  Lr: 0.001875  Loss: -0.1891  Acc@1: 68.7500 (65.3281)  Acc@5: 93.7500 (91.7371)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 630/4579]  eta: 0:23:12  Lr: 0.001875  Loss: -0.5564  Acc@1: 68.7500 (65.3823)  Acc@5: 93.7500 (91.7789)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 640/4579]  eta: 0:23:08  Lr: 0.001875  Loss: -0.2072  Acc@1: 68.7500 (65.3569)  Acc@5: 93.7500 (91.7902)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 650/4579]  eta: 0:23:04  Lr: 0.001875  Loss: -0.2880  Acc@1: 62.5000 (65.3802)  Acc@5: 93.7500 (91.7915)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 660/4579]  eta: 0:23:01  Lr: 0.001875  Loss: -0.1310  Acc@1: 62.5000 (65.3461)  Acc@5: 93.7500 (91.8022)  time: 0.3540  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 670/4579]  eta: 0:22:58  Lr: 0.001875  Loss: 0.0414  Acc@1: 62.5000 (65.3316)  Acc@5: 93.7500 (91.8219)  time: 0.3605  data: 0.0033  max mem: 2500
Train: Epoch[4/5]  [ 680/4579]  eta: 0:22:54  Lr: 0.001875  Loss: 0.3257  Acc@1: 56.2500 (65.2441)  Acc@5: 93.7500 (91.8135)  time: 0.3561  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [ 690/4579]  eta: 0:22:50  Lr: 0.001875  Loss: -0.4553  Acc@1: 68.7500 (65.2587)  Acc@5: 93.7500 (91.8144)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 700/4579]  eta: 0:22:46  Lr: 0.001875  Loss: -0.0882  Acc@1: 62.5000 (65.1926)  Acc@5: 93.7500 (91.8598)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 710/4579]  eta: 0:22:42  Lr: 0.001875  Loss: 0.2990  Acc@1: 62.5000 (65.2250)  Acc@5: 93.7500 (91.8513)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 720/4579]  eta: 0:22:39  Lr: 0.001875  Loss: -0.7473  Acc@1: 62.5000 (65.2653)  Acc@5: 93.7500 (91.8603)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 730/4579]  eta: 0:22:35  Lr: 0.001875  Loss: 0.2953  Acc@1: 62.5000 (65.2702)  Acc@5: 93.7500 (91.9118)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 740/4579]  eta: 0:22:31  Lr: 0.001875  Loss: -0.4545  Acc@1: 62.5000 (65.3087)  Acc@5: 100.0000 (91.9787)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 750/4579]  eta: 0:22:27  Lr: 0.001875  Loss: 0.3599  Acc@1: 62.5000 (65.2879)  Acc@5: 93.7500 (91.9857)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 760/4579]  eta: 0:22:23  Lr: 0.001875  Loss: 0.1340  Acc@1: 62.5000 (65.3417)  Acc@5: 93.7500 (92.0171)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 770/4579]  eta: 0:22:19  Lr: 0.001875  Loss: -0.4592  Acc@1: 62.5000 (65.3210)  Acc@5: 93.7500 (91.9990)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 780/4579]  eta: 0:22:16  Lr: 0.001875  Loss: 0.3316  Acc@1: 68.7500 (65.2929)  Acc@5: 87.5000 (91.9734)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 790/4579]  eta: 0:22:12  Lr: 0.001875  Loss: -0.2755  Acc@1: 68.7500 (65.3524)  Acc@5: 87.5000 (91.9564)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 800/4579]  eta: 0:22:08  Lr: 0.001875  Loss: -0.2900  Acc@1: 62.5000 (65.3402)  Acc@5: 93.7500 (91.9164)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 810/4579]  eta: 0:22:05  Lr: 0.001875  Loss: -0.4478  Acc@1: 62.5000 (65.3052)  Acc@5: 87.5000 (91.8850)  time: 0.3551  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [ 820/4579]  eta: 0:22:02  Lr: 0.001875  Loss: -0.5235  Acc@1: 68.7500 (65.3928)  Acc@5: 93.7500 (91.8925)  time: 0.3546  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [ 830/4579]  eta: 0:21:58  Lr: 0.001875  Loss: -0.1716  Acc@1: 68.7500 (65.3881)  Acc@5: 93.7500 (91.8848)  time: 0.3538  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 840/4579]  eta: 0:21:55  Lr: 0.001875  Loss: -0.9097  Acc@1: 68.7500 (65.4578)  Acc@5: 93.7500 (91.8921)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 850/4579]  eta: 0:21:51  Lr: 0.001875  Loss: -0.2028  Acc@1: 62.5000 (65.4230)  Acc@5: 93.7500 (91.8772)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 860/4579]  eta: 0:21:48  Lr: 0.001875  Loss: -0.3476  Acc@1: 68.7500 (65.4980)  Acc@5: 93.7500 (91.9280)  time: 0.3557  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 870/4579]  eta: 0:21:45  Lr: 0.001875  Loss: -0.0821  Acc@1: 68.7500 (65.5712)  Acc@5: 93.7500 (91.9346)  time: 0.3596  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 880/4579]  eta: 0:21:42  Lr: 0.001875  Loss: -0.3396  Acc@1: 68.7500 (65.5576)  Acc@5: 87.5000 (91.8913)  time: 0.3612  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [ 890/4579]  eta: 0:21:39  Lr: 0.001875  Loss: 0.2166  Acc@1: 62.5000 (65.5584)  Acc@5: 93.7500 (91.8981)  time: 0.3620  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [ 900/4579]  eta: 0:21:35  Lr: 0.001875  Loss: 0.1191  Acc@1: 75.0000 (65.6423)  Acc@5: 93.7500 (91.9395)  time: 0.3590  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [ 910/4579]  eta: 0:21:32  Lr: 0.001875  Loss: -0.6357  Acc@1: 75.0000 (65.7245)  Acc@5: 93.7500 (91.9868)  time: 0.3550  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 920/4579]  eta: 0:21:28  Lr: 0.001875  Loss: -0.1791  Acc@1: 62.5000 (65.6895)  Acc@5: 93.7500 (91.9856)  time: 0.3544  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 930/4579]  eta: 0:21:25  Lr: 0.001875  Loss: -0.3616  Acc@1: 62.5000 (65.6082)  Acc@5: 93.7500 (91.9777)  time: 0.3522  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 940/4579]  eta: 0:21:21  Lr: 0.001875  Loss: -0.5313  Acc@1: 62.5000 (65.6482)  Acc@5: 93.7500 (91.9899)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 950/4579]  eta: 0:21:18  Lr: 0.001875  Loss: 0.0768  Acc@1: 68.7500 (65.6414)  Acc@5: 93.7500 (92.0150)  time: 0.3517  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 960/4579]  eta: 0:21:14  Lr: 0.001875  Loss: -0.0262  Acc@1: 68.7500 (65.6478)  Acc@5: 93.7500 (92.0200)  time: 0.3538  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 970/4579]  eta: 0:21:11  Lr: 0.001875  Loss: -0.0113  Acc@1: 68.7500 (65.6411)  Acc@5: 93.7500 (92.0057)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 980/4579]  eta: 0:21:07  Lr: 0.001875  Loss: -0.3967  Acc@1: 62.5000 (65.6091)  Acc@5: 93.7500 (91.9788)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 990/4579]  eta: 0:21:03  Lr: 0.001875  Loss: -0.5197  Acc@1: 62.5000 (65.6282)  Acc@5: 87.5000 (91.9778)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1000/4579]  eta: 0:21:00  Lr: 0.001875  Loss: 0.1575  Acc@1: 68.7500 (65.6031)  Acc@5: 87.5000 (91.9331)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1010/4579]  eta: 0:20:56  Lr: 0.001875  Loss: 0.0092  Acc@1: 62.5000 (65.5725)  Acc@5: 87.5000 (91.9139)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1020/4579]  eta: 0:20:52  Lr: 0.001875  Loss: -0.2130  Acc@1: 62.5000 (65.5791)  Acc@5: 87.5000 (91.9197)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1030/4579]  eta: 0:20:49  Lr: 0.001875  Loss: -0.3621  Acc@1: 68.7500 (65.6583)  Acc@5: 93.7500 (91.9435)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1040/4579]  eta: 0:20:45  Lr: 0.001875  Loss: -0.0513  Acc@1: 62.5000 (65.6040)  Acc@5: 93.7500 (91.9368)  time: 0.3524  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1050/4579]  eta: 0:20:42  Lr: 0.001875  Loss: 0.3618  Acc@1: 56.2500 (65.5804)  Acc@5: 93.7500 (91.9184)  time: 0.3529  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1060/4579]  eta: 0:20:38  Lr: 0.001875  Loss: -0.2407  Acc@1: 62.5000 (65.5396)  Acc@5: 93.7500 (91.9357)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1070/4579]  eta: 0:20:34  Lr: 0.001875  Loss: -0.2893  Acc@1: 62.5000 (65.5462)  Acc@5: 93.7500 (91.9409)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1080/4579]  eta: 0:20:31  Lr: 0.001875  Loss: -0.2424  Acc@1: 62.5000 (65.5123)  Acc@5: 93.7500 (91.9692)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1090/4579]  eta: 0:20:27  Lr: 0.001875  Loss: -0.4044  Acc@1: 56.2500 (65.4331)  Acc@5: 93.7500 (91.9455)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1100/4579]  eta: 0:20:23  Lr: 0.001875  Loss: -0.4549  Acc@1: 56.2500 (65.3951)  Acc@5: 93.7500 (91.9902)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1110/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.3295  Acc@1: 62.5000 (65.3690)  Acc@5: 93.7500 (91.9779)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1120/4579]  eta: 0:20:16  Lr: 0.001875  Loss: 0.0491  Acc@1: 62.5000 (65.3490)  Acc@5: 93.7500 (92.0049)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1130/4579]  eta: 0:20:12  Lr: 0.001875  Loss: -0.1307  Acc@1: 62.5000 (65.3404)  Acc@5: 93.7500 (92.0148)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1140/4579]  eta: 0:20:08  Lr: 0.001875  Loss: -0.1182  Acc@1: 62.5000 (65.3265)  Acc@5: 93.7500 (92.0081)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1150/4579]  eta: 0:20:05  Lr: 0.001875  Loss: -0.4207  Acc@1: 62.5000 (65.3182)  Acc@5: 93.7500 (92.0124)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1160/4579]  eta: 0:20:01  Lr: 0.001875  Loss: 0.2484  Acc@1: 62.5000 (65.2885)  Acc@5: 93.7500 (92.0058)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1170/4579]  eta: 0:19:58  Lr: 0.001875  Loss: -0.3482  Acc@1: 62.5000 (65.2594)  Acc@5: 93.7500 (91.9940)  time: 0.3506  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1180/4579]  eta: 0:19:54  Lr: 0.001875  Loss: 0.0489  Acc@1: 62.5000 (65.2466)  Acc@5: 93.7500 (91.9983)  time: 0.3506  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1190/4579]  eta: 0:19:50  Lr: 0.001875  Loss: -0.1221  Acc@1: 62.5000 (65.3075)  Acc@5: 93.7500 (92.0130)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1200/4579]  eta: 0:19:47  Lr: 0.001875  Loss: -0.3302  Acc@1: 68.7500 (65.3414)  Acc@5: 93.7500 (92.0379)  time: 0.3507  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1210/4579]  eta: 0:19:43  Lr: 0.001875  Loss: -0.3555  Acc@1: 68.7500 (65.3437)  Acc@5: 93.7500 (92.0417)  time: 0.3516  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1220/4579]  eta: 0:19:40  Lr: 0.001875  Loss: -0.4825  Acc@1: 56.2500 (65.3102)  Acc@5: 93.7500 (92.0250)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1230/4579]  eta: 0:19:37  Lr: 0.001875  Loss: -0.8314  Acc@1: 62.5000 (65.3432)  Acc@5: 87.5000 (92.0390)  time: 0.3531  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1240/4579]  eta: 0:19:33  Lr: 0.001875  Loss: 0.0934  Acc@1: 68.7500 (65.3354)  Acc@5: 93.7500 (92.0427)  time: 0.3541  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1250/4579]  eta: 0:19:30  Lr: 0.001875  Loss: -0.0474  Acc@1: 62.5000 (65.3327)  Acc@5: 93.7500 (92.0663)  time: 0.3530  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1260/4579]  eta: 0:19:26  Lr: 0.001875  Loss: 0.0402  Acc@1: 68.7500 (65.3747)  Acc@5: 93.7500 (92.0797)  time: 0.3517  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1270/4579]  eta: 0:19:23  Lr: 0.001875  Loss: -0.1543  Acc@1: 68.7500 (65.4160)  Acc@5: 93.7500 (92.0830)  time: 0.3511  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1280/4579]  eta: 0:19:19  Lr: 0.001875  Loss: 0.6381  Acc@1: 62.5000 (65.4079)  Acc@5: 93.7500 (92.0765)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1290/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.1995  Acc@1: 62.5000 (65.4192)  Acc@5: 87.5000 (92.0556)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1300/4579]  eta: 0:19:12  Lr: 0.001875  Loss: -0.2377  Acc@1: 68.7500 (65.4400)  Acc@5: 87.5000 (92.0542)  time: 0.3530  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1310/4579]  eta: 0:19:09  Lr: 0.001875  Loss: -0.4520  Acc@1: 68.7500 (65.4510)  Acc@5: 93.7500 (92.0481)  time: 0.3577  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1320/4579]  eta: 0:19:05  Lr: 0.001875  Loss: -0.5734  Acc@1: 68.7500 (65.4712)  Acc@5: 93.7500 (92.0704)  time: 0.3547  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1330/4579]  eta: 0:19:02  Lr: 0.001875  Loss: -0.0186  Acc@1: 68.7500 (65.4724)  Acc@5: 93.7500 (92.0689)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1340/4579]  eta: 0:18:58  Lr: 0.001875  Loss: 0.1225  Acc@1: 62.5000 (65.4316)  Acc@5: 87.5000 (92.0442)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1350/4579]  eta: 0:18:54  Lr: 0.001875  Loss: -0.2950  Acc@1: 68.7500 (65.4654)  Acc@5: 93.7500 (92.0661)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1360/4579]  eta: 0:18:51  Lr: 0.001875  Loss: -0.2215  Acc@1: 68.7500 (65.4574)  Acc@5: 93.7500 (92.0509)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1370/4579]  eta: 0:18:47  Lr: 0.001875  Loss: -0.0188  Acc@1: 62.5000 (65.4404)  Acc@5: 87.5000 (92.0405)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1380/4579]  eta: 0:18:43  Lr: 0.001875  Loss: -0.6467  Acc@1: 62.5000 (65.4372)  Acc@5: 93.7500 (92.0483)  time: 0.3457  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1390/4579]  eta: 0:18:40  Lr: 0.001875  Loss: -0.3370  Acc@1: 62.5000 (65.4206)  Acc@5: 93.7500 (92.0381)  time: 0.3470  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1400/4579]  eta: 0:18:36  Lr: 0.001875  Loss: 0.3708  Acc@1: 62.5000 (65.4086)  Acc@5: 87.5000 (92.0414)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1410/4579]  eta: 0:18:33  Lr: 0.001875  Loss: -0.1504  Acc@1: 62.5000 (65.4102)  Acc@5: 93.7500 (92.0535)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1420/4579]  eta: 0:18:29  Lr: 0.001875  Loss: -0.2983  Acc@1: 62.5000 (65.3501)  Acc@5: 93.7500 (92.0127)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1430/4579]  eta: 0:18:26  Lr: 0.001875  Loss: -0.5644  Acc@1: 68.7500 (65.3913)  Acc@5: 93.7500 (92.0379)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1440/4579]  eta: 0:18:22  Lr: 0.001875  Loss: -0.3257  Acc@1: 68.7500 (65.4407)  Acc@5: 93.7500 (92.0498)  time: 0.3552  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1450/4579]  eta: 0:18:19  Lr: 0.001875  Loss: 0.2109  Acc@1: 62.5000 (65.4075)  Acc@5: 87.5000 (91.9969)  time: 0.3567  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1460/4579]  eta: 0:18:15  Lr: 0.001875  Loss: -0.5945  Acc@1: 68.7500 (65.4689)  Acc@5: 87.5000 (92.0132)  time: 0.3541  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1470/4579]  eta: 0:18:12  Lr: 0.001875  Loss: 0.0363  Acc@1: 68.7500 (65.4572)  Acc@5: 93.7500 (91.9867)  time: 0.3519  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1480/4579]  eta: 0:18:08  Lr: 0.001875  Loss: -0.6034  Acc@1: 62.5000 (65.4161)  Acc@5: 93.7500 (92.0029)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1490/4579]  eta: 0:18:05  Lr: 0.001875  Loss: -0.7670  Acc@1: 68.7500 (65.4259)  Acc@5: 93.7500 (91.9936)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1500/4579]  eta: 0:18:01  Lr: 0.001875  Loss: -0.2527  Acc@1: 68.7500 (65.4106)  Acc@5: 93.7500 (91.9970)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1510/4579]  eta: 0:17:58  Lr: 0.001875  Loss: -0.0503  Acc@1: 62.5000 (65.4037)  Acc@5: 93.7500 (91.9796)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1520/4579]  eta: 0:17:54  Lr: 0.001875  Loss: -0.1402  Acc@1: 62.5000 (65.3805)  Acc@5: 93.7500 (91.9707)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1530/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.4309  Acc@1: 56.2500 (65.3535)  Acc@5: 93.7500 (91.9660)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1540/4579]  eta: 0:17:47  Lr: 0.001875  Loss: -0.7178  Acc@1: 68.7500 (65.3999)  Acc@5: 93.7500 (92.0019)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1550/4579]  eta: 0:17:43  Lr: 0.001875  Loss: 0.3940  Acc@1: 68.7500 (65.3772)  Acc@5: 93.7500 (91.9971)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1560/4579]  eta: 0:17:40  Lr: 0.001875  Loss: 0.4135  Acc@1: 62.5000 (65.3467)  Acc@5: 87.5000 (91.9763)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1570/4579]  eta: 0:17:36  Lr: 0.001875  Loss: -0.0879  Acc@1: 56.2500 (65.3405)  Acc@5: 93.7500 (91.9796)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1580/4579]  eta: 0:17:32  Lr: 0.001875  Loss: -0.9019  Acc@1: 75.0000 (65.3977)  Acc@5: 93.7500 (92.0066)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1590/4579]  eta: 0:17:29  Lr: 0.001875  Loss: -0.1057  Acc@1: 68.7500 (65.3755)  Acc@5: 93.7500 (91.9862)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1600/4579]  eta: 0:17:25  Lr: 0.001875  Loss: -0.2412  Acc@1: 62.5000 (65.3537)  Acc@5: 87.5000 (91.9660)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1610/4579]  eta: 0:17:22  Lr: 0.001875  Loss: -0.0812  Acc@1: 68.7500 (65.3942)  Acc@5: 87.5000 (91.9770)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1620/4579]  eta: 0:17:18  Lr: 0.001875  Loss: -0.6789  Acc@1: 68.7500 (65.3879)  Acc@5: 93.7500 (91.9648)  time: 0.3526  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1630/4579]  eta: 0:17:15  Lr: 0.001875  Loss: 0.3217  Acc@1: 68.7500 (65.4008)  Acc@5: 93.7500 (91.9528)  time: 0.3529  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1640/4579]  eta: 0:17:12  Lr: 0.001875  Loss: -0.6387  Acc@1: 68.7500 (65.3679)  Acc@5: 93.7500 (91.9257)  time: 0.3538  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1650/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.4754  Acc@1: 62.5000 (65.3619)  Acc@5: 93.7500 (91.9329)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1660/4579]  eta: 0:17:05  Lr: 0.001875  Loss: 0.1346  Acc@1: 68.7500 (65.3597)  Acc@5: 93.7500 (91.9250)  time: 0.3514  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1670/4579]  eta: 0:17:01  Lr: 0.001875  Loss: 0.2508  Acc@1: 62.5000 (65.3613)  Acc@5: 93.7500 (91.9285)  time: 0.3505  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1680/4579]  eta: 0:16:58  Lr: 0.001875  Loss: 0.3091  Acc@1: 62.5000 (65.3034)  Acc@5: 93.7500 (91.9282)  time: 0.3534  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1690/4579]  eta: 0:16:54  Lr: 0.001875  Loss: -0.9630  Acc@1: 62.5000 (65.3090)  Acc@5: 93.7500 (91.9094)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1700/4579]  eta: 0:16:50  Lr: 0.001875  Loss: -0.5161  Acc@1: 68.7500 (65.3476)  Acc@5: 93.7500 (91.9092)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1710/4579]  eta: 0:16:47  Lr: 0.001875  Loss: -0.1883  Acc@1: 75.0000 (65.3930)  Acc@5: 93.7500 (91.9236)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1720/4579]  eta: 0:16:43  Lr: 0.001875  Loss: 0.1977  Acc@1: 68.7500 (65.4343)  Acc@5: 93.7500 (91.9306)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1730/4579]  eta: 0:16:40  Lr: 0.001875  Loss: -0.3169  Acc@1: 75.0000 (65.4932)  Acc@5: 93.7500 (91.9375)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1740/4579]  eta: 0:16:36  Lr: 0.001875  Loss: 0.0231  Acc@1: 68.7500 (65.5119)  Acc@5: 93.7500 (91.9407)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1750/4579]  eta: 0:16:32  Lr: 0.001875  Loss: -0.4709  Acc@1: 62.5000 (65.4947)  Acc@5: 93.7500 (91.9368)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1760/4579]  eta: 0:16:29  Lr: 0.001875  Loss: 0.0368  Acc@1: 62.5000 (65.4990)  Acc@5: 93.7500 (91.9399)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1770/4579]  eta: 0:16:25  Lr: 0.001875  Loss: 0.0268  Acc@1: 68.7500 (65.5138)  Acc@5: 93.7500 (91.9466)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1780/4579]  eta: 0:16:22  Lr: 0.001875  Loss: -0.1553  Acc@1: 68.7500 (65.5355)  Acc@5: 93.7500 (91.9427)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1790/4579]  eta: 0:16:18  Lr: 0.001875  Loss: 0.2081  Acc@1: 62.5000 (65.5290)  Acc@5: 93.7500 (91.9424)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1800/4579]  eta: 0:16:15  Lr: 0.001875  Loss: -0.0124  Acc@1: 62.5000 (65.5226)  Acc@5: 93.7500 (91.9350)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1810/4579]  eta: 0:16:11  Lr: 0.001875  Loss: 0.0187  Acc@1: 62.5000 (65.5128)  Acc@5: 93.7500 (91.9313)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1820/4579]  eta: 0:16:08  Lr: 0.001875  Loss: 0.7830  Acc@1: 62.5000 (65.4860)  Acc@5: 93.7500 (91.9104)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1830/4579]  eta: 0:16:04  Lr: 0.001875  Loss: -0.0007  Acc@1: 62.5000 (65.4833)  Acc@5: 93.7500 (91.9102)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1840/4579]  eta: 0:16:01  Lr: 0.001875  Loss: 0.0841  Acc@1: 62.5000 (65.4773)  Acc@5: 93.7500 (91.9202)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1850/4579]  eta: 0:15:57  Lr: 0.001875  Loss: -0.1441  Acc@1: 62.5000 (65.4849)  Acc@5: 93.7500 (91.9368)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1860/4579]  eta: 0:15:54  Lr: 0.001875  Loss: -0.2141  Acc@1: 68.7500 (65.5159)  Acc@5: 93.7500 (91.9432)  time: 0.3546  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1870/4579]  eta: 0:15:50  Lr: 0.001875  Loss: -0.3517  Acc@1: 68.7500 (65.5131)  Acc@5: 93.7500 (91.9462)  time: 0.3593  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1880/4579]  eta: 0:15:47  Lr: 0.001875  Loss: -0.7422  Acc@1: 62.5000 (65.5004)  Acc@5: 93.7500 (91.9624)  time: 0.3589  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1890/4579]  eta: 0:15:43  Lr: 0.001875  Loss: -0.1191  Acc@1: 62.5000 (65.4812)  Acc@5: 93.7500 (91.9718)  time: 0.3546  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1900/4579]  eta: 0:15:40  Lr: 0.001875  Loss: -0.0993  Acc@1: 62.5000 (65.4787)  Acc@5: 93.7500 (91.9713)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1910/4579]  eta: 0:15:36  Lr: 0.001875  Loss: -0.4801  Acc@1: 62.5000 (65.4533)  Acc@5: 93.7500 (91.9708)  time: 0.3530  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1920/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.4404  Acc@1: 62.5000 (65.4412)  Acc@5: 93.7500 (91.9671)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1930/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.4795  Acc@1: 62.5000 (65.4389)  Acc@5: 93.7500 (91.9795)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1940/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 0.1368  Acc@1: 62.5000 (65.4334)  Acc@5: 93.7500 (91.9693)  time: 0.3541  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1950/4579]  eta: 0:15:22  Lr: 0.001875  Loss: 0.1498  Acc@1: 62.5000 (65.4344)  Acc@5: 87.5000 (91.9689)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1960/4579]  eta: 0:15:19  Lr: 0.001875  Loss: -0.0652  Acc@1: 68.7500 (65.4386)  Acc@5: 87.5000 (91.9524)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1970/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 0.0222  Acc@1: 62.5000 (65.4268)  Acc@5: 93.7500 (91.9552)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1980/4579]  eta: 0:15:12  Lr: 0.001875  Loss: -0.6428  Acc@1: 62.5000 (65.4152)  Acc@5: 93.7500 (91.9548)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1990/4579]  eta: 0:15:08  Lr: 0.001875  Loss: -0.5422  Acc@1: 68.7500 (65.4257)  Acc@5: 87.5000 (91.9419)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2000/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 0.1948  Acc@1: 68.7500 (65.4267)  Acc@5: 87.5000 (91.9322)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2010/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.3810  Acc@1: 68.7500 (65.4214)  Acc@5: 93.7500 (91.9412)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2020/4579]  eta: 0:14:58  Lr: 0.001875  Loss: -0.5396  Acc@1: 62.5000 (65.3884)  Acc@5: 93.7500 (91.9316)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2030/4579]  eta: 0:14:54  Lr: 0.001875  Loss: -0.5893  Acc@1: 62.5000 (65.3957)  Acc@5: 93.7500 (91.9221)  time: 0.3451  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2040/4579]  eta: 0:14:50  Lr: 0.001875  Loss: -0.5333  Acc@1: 68.7500 (65.4305)  Acc@5: 93.7500 (91.9249)  time: 0.3451  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2050/4579]  eta: 0:14:47  Lr: 0.001875  Loss: 0.0422  Acc@1: 75.0000 (65.4315)  Acc@5: 93.7500 (91.9247)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2060/4579]  eta: 0:14:43  Lr: 0.001875  Loss: -0.5800  Acc@1: 62.5000 (65.4264)  Acc@5: 93.7500 (91.9214)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2070/4579]  eta: 0:14:40  Lr: 0.001875  Loss: -0.1770  Acc@1: 62.5000 (65.4364)  Acc@5: 93.7500 (91.9272)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2080/4579]  eta: 0:14:36  Lr: 0.001875  Loss: 0.1882  Acc@1: 68.7500 (65.4493)  Acc@5: 87.5000 (91.9149)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2090/4579]  eta: 0:14:33  Lr: 0.001875  Loss: -0.1711  Acc@1: 68.7500 (65.4352)  Acc@5: 87.5000 (91.9267)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2100/4579]  eta: 0:14:29  Lr: 0.001875  Loss: 0.8318  Acc@1: 62.5000 (65.4212)  Acc@5: 93.7500 (91.9384)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2110/4579]  eta: 0:14:26  Lr: 0.001875  Loss: -0.4783  Acc@1: 62.5000 (65.4074)  Acc@5: 93.7500 (91.9114)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2120/4579]  eta: 0:14:22  Lr: 0.001875  Loss: -0.5204  Acc@1: 62.5000 (65.4438)  Acc@5: 93.7500 (91.9201)  time: 0.3538  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2130/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.2068  Acc@1: 75.0000 (65.4446)  Acc@5: 93.7500 (91.9169)  time: 0.3534  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2140/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.7531  Acc@1: 68.7500 (65.4571)  Acc@5: 87.5000 (91.9080)  time: 0.3514  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2150/4579]  eta: 0:14:12  Lr: 0.001875  Loss: -0.1775  Acc@1: 68.7500 (65.4725)  Acc@5: 87.5000 (91.8962)  time: 0.3517  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2160/4579]  eta: 0:14:08  Lr: 0.001875  Loss: -0.0938  Acc@1: 68.7500 (65.4847)  Acc@5: 93.7500 (91.9077)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2170/4579]  eta: 0:14:05  Lr: 0.001875  Loss: -0.0732  Acc@1: 62.5000 (65.4652)  Acc@5: 93.7500 (91.9018)  time: 0.3514  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2180/4579]  eta: 0:14:01  Lr: 0.001875  Loss: 0.1494  Acc@1: 62.5000 (65.4631)  Acc@5: 87.5000 (91.8931)  time: 0.3517  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2190/4579]  eta: 0:13:58  Lr: 0.001875  Loss: -0.1376  Acc@1: 62.5000 (65.4667)  Acc@5: 93.7500 (91.9044)  time: 0.3506  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2200/4579]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6889  Acc@1: 62.5000 (65.4617)  Acc@5: 93.7500 (91.8900)  time: 0.3520  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2210/4579]  eta: 0:13:51  Lr: 0.001875  Loss: -0.0922  Acc@1: 68.7500 (65.4964)  Acc@5: 93.7500 (91.8985)  time: 0.3533  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2220/4579]  eta: 0:13:47  Lr: 0.001875  Loss: -0.6872  Acc@1: 75.0000 (65.5307)  Acc@5: 93.7500 (91.9040)  time: 0.3542  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2230/4579]  eta: 0:13:44  Lr: 0.001875  Loss: -0.5798  Acc@1: 68.7500 (65.5227)  Acc@5: 93.7500 (91.9011)  time: 0.3568  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2240/4579]  eta: 0:13:40  Lr: 0.001875  Loss: -0.4751  Acc@1: 62.5000 (65.5120)  Acc@5: 93.7500 (91.9009)  time: 0.3535  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2250/4579]  eta: 0:13:37  Lr: 0.001875  Loss: -0.5177  Acc@1: 62.5000 (65.4765)  Acc@5: 93.7500 (91.9064)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2260/4579]  eta: 0:13:33  Lr: 0.001875  Loss: -0.2362  Acc@1: 62.5000 (65.4716)  Acc@5: 93.7500 (91.9090)  time: 0.3507  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2270/4579]  eta: 0:13:30  Lr: 0.001875  Loss: -0.2322  Acc@1: 68.7500 (65.4778)  Acc@5: 93.7500 (91.9199)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2280/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.3552  Acc@1: 68.7500 (65.4976)  Acc@5: 93.7500 (91.9334)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2290/4579]  eta: 0:13:23  Lr: 0.001875  Loss: -0.3548  Acc@1: 68.7500 (65.5118)  Acc@5: 93.7500 (91.9358)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2300/4579]  eta: 0:13:19  Lr: 0.001875  Loss: -0.3050  Acc@1: 68.7500 (65.5068)  Acc@5: 93.7500 (91.9410)  time: 0.3524  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2310/4579]  eta: 0:13:16  Lr: 0.001875  Loss: -0.3424  Acc@1: 62.5000 (65.4938)  Acc@5: 93.7500 (91.9380)  time: 0.3514  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2320/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.5576  Acc@1: 68.7500 (65.5267)  Acc@5: 93.7500 (91.9458)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2330/4579]  eta: 0:13:09  Lr: 0.001875  Loss: -0.6472  Acc@1: 62.5000 (65.5191)  Acc@5: 93.7500 (91.9375)  time: 0.3524  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2340/4579]  eta: 0:13:05  Lr: 0.001875  Loss: -0.4077  Acc@1: 62.5000 (65.5169)  Acc@5: 87.5000 (91.9345)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2350/4579]  eta: 0:13:02  Lr: 0.001875  Loss: 0.4836  Acc@1: 68.7500 (65.5120)  Acc@5: 93.7500 (91.9396)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2360/4579]  eta: 0:12:58  Lr: 0.001875  Loss: 0.1575  Acc@1: 62.5000 (65.5019)  Acc@5: 93.7500 (91.9473)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2370/4579]  eta: 0:12:55  Lr: 0.001875  Loss: -0.5398  Acc@1: 62.5000 (65.4998)  Acc@5: 93.7500 (91.9391)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2380/4579]  eta: 0:12:51  Lr: 0.001875  Loss: -0.6289  Acc@1: 68.7500 (65.5187)  Acc@5: 87.5000 (91.9388)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2390/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.1957  Acc@1: 68.7500 (65.5296)  Acc@5: 93.7500 (91.9437)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2400/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.5170  Acc@1: 68.7500 (65.5534)  Acc@5: 93.7500 (91.9435)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2410/4579]  eta: 0:12:40  Lr: 0.001875  Loss: 0.0693  Acc@1: 68.7500 (65.5563)  Acc@5: 87.5000 (91.9302)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2420/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.1400  Acc@1: 68.7500 (65.5927)  Acc@5: 93.7500 (91.9352)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2430/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.5792  Acc@1: 75.0000 (65.6160)  Acc@5: 93.7500 (91.9298)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2440/4579]  eta: 0:12:30  Lr: 0.001875  Loss: -0.2224  Acc@1: 68.7500 (65.5981)  Acc@5: 87.5000 (91.9295)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2450/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.3682  Acc@1: 68.7500 (65.6186)  Acc@5: 93.7500 (91.9446)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2460/4579]  eta: 0:12:23  Lr: 0.001875  Loss: -0.2526  Acc@1: 68.7500 (65.6161)  Acc@5: 93.7500 (91.9520)  time: 0.3474  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2470/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.8559  Acc@1: 62.5000 (65.6288)  Acc@5: 93.7500 (91.9542)  time: 0.3515  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2480/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.7272  Acc@1: 62.5000 (65.6212)  Acc@5: 93.7500 (91.9564)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2490/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.6183  Acc@1: 68.7500 (65.6413)  Acc@5: 93.7500 (91.9636)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2500/4579]  eta: 0:12:09  Lr: 0.001875  Loss: -0.2831  Acc@1: 68.7500 (65.6412)  Acc@5: 93.7500 (91.9632)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2510/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.3425  Acc@1: 62.5000 (65.6287)  Acc@5: 93.7500 (91.9604)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2520/4579]  eta: 0:12:02  Lr: 0.001875  Loss: 0.4569  Acc@1: 62.5000 (65.6188)  Acc@5: 93.7500 (91.9452)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2530/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 0.3915  Acc@1: 62.5000 (65.5917)  Acc@5: 93.7500 (91.9474)  time: 0.3527  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2540/4579]  eta: 0:11:55  Lr: 0.001875  Loss: 0.0144  Acc@1: 62.5000 (65.5893)  Acc@5: 93.7500 (91.9421)  time: 0.3541  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2550/4579]  eta: 0:11:51  Lr: 0.001875  Loss: -0.3851  Acc@1: 68.7500 (65.6066)  Acc@5: 93.7500 (91.9443)  time: 0.3530  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2560/4579]  eta: 0:11:48  Lr: 0.001875  Loss: -0.5718  Acc@1: 68.7500 (65.6189)  Acc@5: 93.7500 (91.9538)  time: 0.3522  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2570/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.2291  Acc@1: 68.7500 (65.6165)  Acc@5: 93.7500 (91.9584)  time: 0.3524  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2580/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.7785  Acc@1: 68.7500 (65.6311)  Acc@5: 93.7500 (91.9605)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2590/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.4212  Acc@1: 68.7500 (65.6576)  Acc@5: 93.7500 (91.9650)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2600/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.3226  Acc@1: 68.7500 (65.6550)  Acc@5: 93.7500 (91.9622)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2610/4579]  eta: 0:11:30  Lr: 0.001875  Loss: -0.6253  Acc@1: 62.5000 (65.6453)  Acc@5: 87.5000 (91.9619)  time: 0.3530  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2620/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 0.4922  Acc@1: 56.2500 (65.6143)  Acc@5: 93.7500 (91.9616)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2630/4579]  eta: 0:11:23  Lr: 0.001875  Loss: -0.0635  Acc@1: 62.5000 (65.6286)  Acc@5: 93.7500 (91.9731)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2640/4579]  eta: 0:11:20  Lr: 0.001875  Loss: -0.6862  Acc@1: 68.7500 (65.6380)  Acc@5: 93.7500 (91.9775)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2650/4579]  eta: 0:11:16  Lr: 0.001875  Loss: -0.2015  Acc@1: 75.0000 (65.6663)  Acc@5: 93.7500 (91.9912)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2660/4579]  eta: 0:11:13  Lr: 0.001875  Loss: -0.2852  Acc@1: 68.7500 (65.6638)  Acc@5: 93.7500 (91.9884)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2670/4579]  eta: 0:11:09  Lr: 0.001875  Loss: -0.0786  Acc@1: 68.7500 (65.6613)  Acc@5: 93.7500 (91.9974)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2680/4579]  eta: 0:11:05  Lr: 0.001875  Loss: -0.4416  Acc@1: 62.5000 (65.6355)  Acc@5: 93.7500 (92.0132)  time: 0.3471  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2690/4579]  eta: 0:11:02  Lr: 0.001875  Loss: -0.3391  Acc@1: 56.2500 (65.6215)  Acc@5: 93.7500 (92.0081)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2700/4579]  eta: 0:10:58  Lr: 0.001875  Loss: -0.3618  Acc@1: 62.5000 (65.6238)  Acc@5: 93.7500 (92.0099)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2710/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.2440  Acc@1: 62.5000 (65.6308)  Acc@5: 93.7500 (92.0071)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2720/4579]  eta: 0:10:51  Lr: 0.001875  Loss: 0.2245  Acc@1: 62.5000 (65.6147)  Acc@5: 93.7500 (91.9882)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2730/4579]  eta: 0:10:48  Lr: 0.001875  Loss: -0.6245  Acc@1: 56.2500 (65.5895)  Acc@5: 87.5000 (91.9832)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2740/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.2504  Acc@1: 68.7500 (65.6079)  Acc@5: 93.7500 (91.9874)  time: 0.3454  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2750/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 0.0427  Acc@1: 68.7500 (65.6057)  Acc@5: 93.7500 (91.9779)  time: 0.3459  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2760/4579]  eta: 0:10:37  Lr: 0.001875  Loss: 0.0142  Acc@1: 68.7500 (65.6171)  Acc@5: 93.7500 (91.9889)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2770/4579]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4930  Acc@1: 68.7500 (65.6239)  Acc@5: 93.7500 (91.9997)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2780/4579]  eta: 0:10:30  Lr: 0.001875  Loss: -0.3795  Acc@1: 68.7500 (65.6464)  Acc@5: 93.7500 (91.9993)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2790/4579]  eta: 0:10:27  Lr: 0.001875  Loss: -0.6356  Acc@1: 62.5000 (65.6373)  Acc@5: 93.7500 (91.9921)  time: 0.3512  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2800/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.2868  Acc@1: 62.5000 (65.6440)  Acc@5: 93.7500 (91.9962)  time: 0.3517  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2810/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.1044  Acc@1: 62.5000 (65.6417)  Acc@5: 93.7500 (91.9868)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2820/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.1018  Acc@1: 62.5000 (65.6416)  Acc@5: 93.7500 (91.9887)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2830/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.5139  Acc@1: 62.5000 (65.6327)  Acc@5: 87.5000 (91.9728)  time: 0.3514  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2840/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.4449  Acc@1: 68.7500 (65.6437)  Acc@5: 87.5000 (91.9703)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2850/4579]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5995  Acc@1: 68.7500 (65.6568)  Acc@5: 93.7500 (91.9897)  time: 0.3520  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2860/4579]  eta: 0:10:02  Lr: 0.001875  Loss: -0.0284  Acc@1: 68.7500 (65.6326)  Acc@5: 93.7500 (91.9871)  time: 0.3528  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2870/4579]  eta: 0:09:59  Lr: 0.001875  Loss: 0.3204  Acc@1: 62.5000 (65.6239)  Acc@5: 87.5000 (91.9823)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2880/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.2555  Acc@1: 62.5000 (65.6348)  Acc@5: 87.5000 (91.9820)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2890/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.8463  Acc@1: 68.7500 (65.6369)  Acc@5: 93.7500 (91.9902)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.0866  Acc@1: 68.7500 (65.6519)  Acc@5: 93.7500 (91.9920)  time: 0.3521  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2910/4579]  eta: 0:09:45  Lr: 0.001875  Loss: 0.4527  Acc@1: 68.7500 (65.6712)  Acc@5: 93.7500 (91.9937)  time: 0.3526  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5863  Acc@1: 75.0000 (65.6753)  Acc@5: 93.7500 (91.9933)  time: 0.3553  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2930/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.0717  Acc@1: 62.5000 (65.6538)  Acc@5: 93.7500 (91.9993)  time: 0.3583  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.1237  Acc@1: 62.5000 (65.6579)  Acc@5: 93.7500 (91.9925)  time: 0.3553  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [2950/4579]  eta: 0:09:31  Lr: 0.001875  Loss: -0.6295  Acc@1: 62.5000 (65.6557)  Acc@5: 93.7500 (92.0006)  time: 0.3530  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.8189  Acc@1: 68.7500 (65.6683)  Acc@5: 93.7500 (92.0086)  time: 0.3512  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2970/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.4008  Acc@1: 68.7500 (65.6723)  Acc@5: 93.7500 (92.0019)  time: 0.3499  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: -0.7734  Acc@1: 62.5000 (65.6764)  Acc@5: 87.5000 (91.9972)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2990/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.8017  Acc@1: 62.5000 (65.6783)  Acc@5: 93.7500 (92.0010)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3000/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.4742  Acc@1: 68.7500 (65.6844)  Acc@5: 93.7500 (92.0027)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3010/4579]  eta: 0:09:10  Lr: 0.001875  Loss: 0.2454  Acc@1: 68.7500 (65.6862)  Acc@5: 93.7500 (92.0064)  time: 0.3515  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3020/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.4904  Acc@1: 68.7500 (65.6922)  Acc@5: 93.7500 (92.0163)  time: 0.3515  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3030/4579]  eta: 0:09:03  Lr: 0.001875  Loss: 0.1907  Acc@1: 62.5000 (65.6941)  Acc@5: 93.7500 (92.0097)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3040/4579]  eta: 0:08:59  Lr: 0.001875  Loss: 0.2049  Acc@1: 68.7500 (65.7000)  Acc@5: 93.7500 (92.0113)  time: 0.3506  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3050/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.9353  Acc@1: 68.7500 (65.7080)  Acc@5: 93.7500 (92.0108)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3060/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.7025  Acc@1: 68.7500 (65.7159)  Acc@5: 93.7500 (92.0145)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3070/4579]  eta: 0:08:49  Lr: 0.001875  Loss: 0.0258  Acc@1: 62.5000 (65.7115)  Acc@5: 93.7500 (92.0099)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3080/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.1526  Acc@1: 62.5000 (65.7112)  Acc@5: 87.5000 (92.0054)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3090/4579]  eta: 0:08:42  Lr: 0.001875  Loss: 0.2866  Acc@1: 68.7500 (65.7170)  Acc@5: 93.7500 (92.0091)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3100/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.0416  Acc@1: 62.5000 (65.7086)  Acc@5: 93.7500 (92.0147)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3110/4579]  eta: 0:08:35  Lr: 0.001875  Loss: -0.8979  Acc@1: 62.5000 (65.7224)  Acc@5: 93.7500 (92.0203)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3120/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.4834  Acc@1: 75.0000 (65.7321)  Acc@5: 93.7500 (92.0198)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3130/4579]  eta: 0:08:28  Lr: 0.001875  Loss: -0.6208  Acc@1: 75.0000 (65.7538)  Acc@5: 93.7500 (92.0273)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3140/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.5669  Acc@1: 68.7500 (65.7494)  Acc@5: 93.7500 (92.0268)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3150/4579]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3041  Acc@1: 62.5000 (65.7450)  Acc@5: 93.7500 (92.0204)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3160/4579]  eta: 0:08:17  Lr: 0.001875  Loss: 0.0074  Acc@1: 62.5000 (65.7387)  Acc@5: 93.7500 (92.0140)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3170/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.0160  Acc@1: 62.5000 (65.7304)  Acc@5: 87.5000 (92.0116)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3180/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.6789  Acc@1: 62.5000 (65.7242)  Acc@5: 87.5000 (92.0072)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3190/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.8261  Acc@1: 68.7500 (65.7396)  Acc@5: 93.7500 (92.0166)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3200/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.7762  Acc@1: 62.5000 (65.7334)  Acc@5: 93.7500 (92.0103)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3210/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.3958  Acc@1: 62.5000 (65.7272)  Acc@5: 87.5000 (92.0040)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3220/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 0.1640  Acc@1: 68.7500 (65.7288)  Acc@5: 93.7500 (91.9978)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3230/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.4333  Acc@1: 68.7500 (65.7227)  Acc@5: 93.7500 (91.9994)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.5665  Acc@1: 62.5000 (65.7012)  Acc@5: 87.5000 (91.9778)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3250/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.0939  Acc@1: 68.7500 (65.7163)  Acc@5: 87.5000 (91.9813)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 0.1089  Acc@1: 68.7500 (65.6930)  Acc@5: 93.7500 (91.9714)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3270/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.1237  Acc@1: 62.5000 (65.6890)  Acc@5: 87.5000 (91.9673)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.1994  Acc@1: 62.5000 (65.6888)  Acc@5: 93.7500 (91.9670)  time: 0.3501  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3290/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.0256  Acc@1: 68.7500 (65.6867)  Acc@5: 93.7500 (91.9629)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.1671  Acc@1: 68.7500 (65.6903)  Acc@5: 87.5000 (91.9589)  time: 0.3524  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3310/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.0950  Acc@1: 68.7500 (65.6826)  Acc@5: 93.7500 (91.9624)  time: 0.3531  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.3603  Acc@1: 62.5000 (65.6768)  Acc@5: 93.7500 (91.9659)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3330/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.0488  Acc@1: 62.5000 (65.6804)  Acc@5: 93.7500 (91.9581)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.2392  Acc@1: 62.5000 (65.6839)  Acc@5: 93.7500 (91.9672)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3350/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.4366  Acc@1: 62.5000 (65.6819)  Acc@5: 93.7500 (91.9670)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.1032  Acc@1: 62.5000 (65.6985)  Acc@5: 93.7500 (91.9648)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3370/4579]  eta: 0:07:03  Lr: 0.001875  Loss: 0.4764  Acc@1: 68.7500 (65.6853)  Acc@5: 93.7500 (91.9664)  time: 0.3540  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.6213  Acc@1: 68.7500 (65.6814)  Acc@5: 93.7500 (91.9680)  time: 0.3545  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3390/4579]  eta: 0:06:56  Lr: 0.001875  Loss: 0.1367  Acc@1: 68.7500 (65.6904)  Acc@5: 93.7500 (91.9751)  time: 0.3531  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.0025  Acc@1: 68.7500 (65.6810)  Acc@5: 93.7500 (91.9766)  time: 0.3546  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3410/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.4811  Acc@1: 62.5000 (65.6754)  Acc@5: 93.7500 (91.9910)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3420/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.3398  Acc@1: 62.5000 (65.6771)  Acc@5: 93.7500 (92.0016)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3430/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.2544  Acc@1: 68.7500 (65.6715)  Acc@5: 93.7500 (91.9958)  time: 0.3511  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3440/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.3185  Acc@1: 68.7500 (65.6713)  Acc@5: 87.5000 (91.9936)  time: 0.3521  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3450/4579]  eta: 0:06:35  Lr: 0.001875  Loss: 0.0778  Acc@1: 62.5000 (65.6567)  Acc@5: 87.5000 (91.9915)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3460/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.4750  Acc@1: 62.5000 (65.6512)  Acc@5: 87.5000 (91.9893)  time: 0.3519  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3470/4579]  eta: 0:06:28  Lr: 0.001875  Loss: 0.2654  Acc@1: 62.5000 (65.6457)  Acc@5: 93.7500 (91.9908)  time: 0.3518  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3480/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.5025  Acc@1: 68.7500 (65.6582)  Acc@5: 93.7500 (91.9940)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3490/4579]  eta: 0:06:21  Lr: 0.001875  Loss: 0.3948  Acc@1: 68.7500 (65.6635)  Acc@5: 93.7500 (91.9991)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3500/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.2266  Acc@1: 68.7500 (65.6884)  Acc@5: 93.7500 (92.0023)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3510/4579]  eta: 0:06:14  Lr: 0.001875  Loss: -0.1241  Acc@1: 68.7500 (65.6989)  Acc@5: 93.7500 (92.0037)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3520/4579]  eta: 0:06:11  Lr: 0.001875  Loss: -0.5972  Acc@1: 68.7500 (65.7040)  Acc@5: 93.7500 (92.0087)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3530/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.5934  Acc@1: 62.5000 (65.7091)  Acc@5: 93.7500 (92.0154)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3540/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.0380  Acc@1: 62.5000 (65.7053)  Acc@5: 93.7500 (92.0114)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3550/4579]  eta: 0:06:00  Lr: 0.001875  Loss: -0.5619  Acc@1: 68.7500 (65.7068)  Acc@5: 93.7500 (92.0199)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3560/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.3314  Acc@1: 68.7500 (65.7013)  Acc@5: 93.7500 (92.0194)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3570/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.2673  Acc@1: 62.5000 (65.7011)  Acc@5: 87.5000 (92.0173)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3580/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.5865  Acc@1: 62.5000 (65.7044)  Acc@5: 93.7500 (92.0239)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3590/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.5035  Acc@1: 68.7500 (65.7251)  Acc@5: 93.7500 (92.0287)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3600/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.1871  Acc@1: 62.5000 (65.7092)  Acc@5: 93.7500 (92.0335)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3610/4579]  eta: 0:05:39  Lr: 0.001875  Loss: -0.4788  Acc@1: 62.5000 (65.7020)  Acc@5: 93.7500 (92.0261)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3620/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.8706  Acc@1: 68.7500 (65.7122)  Acc@5: 93.7500 (92.0326)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3630/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.7958  Acc@1: 68.7500 (65.7205)  Acc@5: 93.7500 (92.0390)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3640/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.2187  Acc@1: 68.7500 (65.7374)  Acc@5: 93.7500 (92.0472)  time: 0.3471  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3650/4579]  eta: 0:05:25  Lr: 0.001875  Loss: 0.2213  Acc@1: 68.7500 (65.7234)  Acc@5: 93.7500 (92.0416)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3660/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.1832  Acc@1: 62.5000 (65.7317)  Acc@5: 93.7500 (92.0428)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: 0.0635  Acc@1: 62.5000 (65.7348)  Acc@5: 93.7500 (92.0441)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3680/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.6431  Acc@1: 62.5000 (65.7447)  Acc@5: 93.7500 (92.0419)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.1980  Acc@1: 62.5000 (65.7427)  Acc@5: 93.7500 (92.0465)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3700/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.2882  Acc@1: 62.5000 (65.7491)  Acc@5: 93.7500 (92.0511)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: 0.1858  Acc@1: 68.7500 (65.7471)  Acc@5: 93.7500 (92.0456)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3720/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.0906  Acc@1: 68.7500 (65.7602)  Acc@5: 87.5000 (92.0401)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.3149  Acc@1: 62.5000 (65.7431)  Acc@5: 93.7500 (92.0380)  time: 0.3535  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3740/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.7474  Acc@1: 56.2500 (65.7411)  Acc@5: 93.7500 (92.0359)  time: 0.3519  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.2001  Acc@1: 62.5000 (65.7325)  Acc@5: 93.7500 (92.0421)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3760/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.0905  Acc@1: 62.5000 (65.7255)  Acc@5: 93.7500 (92.0334)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.1611  Acc@1: 62.5000 (65.7269)  Acc@5: 87.5000 (92.0346)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3780/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.5085  Acc@1: 68.7500 (65.7184)  Acc@5: 93.7500 (92.0408)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.0727  Acc@1: 68.7500 (65.7198)  Acc@5: 93.7500 (92.0453)  time: 0.3552  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3800/4579]  eta: 0:04:33  Lr: 0.001875  Loss: 0.6240  Acc@1: 68.7500 (65.7294)  Acc@5: 93.7500 (92.0498)  time: 0.3544  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.7332  Acc@1: 75.0000 (65.7488)  Acc@5: 93.7500 (92.0510)  time: 0.3548  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3820/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.2478  Acc@1: 75.0000 (65.7649)  Acc@5: 93.7500 (92.0472)  time: 0.3529  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: -0.4467  Acc@1: 68.7500 (65.7531)  Acc@5: 87.5000 (92.0419)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3840/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.5019  Acc@1: 68.7500 (65.7527)  Acc@5: 87.5000 (92.0398)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: -0.5985  Acc@1: 68.7500 (65.7703)  Acc@5: 93.7500 (92.0459)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3860/4579]  eta: 0:04:12  Lr: 0.001875  Loss: -0.1180  Acc@1: 68.7500 (65.7602)  Acc@5: 93.7500 (92.0341)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: 0.1584  Acc@1: 62.5000 (65.7711)  Acc@5: 87.5000 (92.0224)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3880/4579]  eta: 0:04:05  Lr: 0.001875  Loss: 0.4987  Acc@1: 68.7500 (65.7772)  Acc@5: 93.7500 (92.0156)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.1737  Acc@1: 68.7500 (65.7784)  Acc@5: 93.7500 (92.0120)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3900/4579]  eta: 0:03:57  Lr: 0.001875  Loss: -0.1691  Acc@1: 68.7500 (65.7748)  Acc@5: 87.5000 (92.0117)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.2875  Acc@1: 68.7500 (65.7952)  Acc@5: 87.5000 (92.0081)  time: 0.3522  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3920/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.6848  Acc@1: 68.7500 (65.7995)  Acc@5: 87.5000 (92.0094)  time: 0.3543  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: -0.5322  Acc@1: 68.7500 (65.7991)  Acc@5: 93.7500 (92.0074)  time: 0.3514  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3940/4579]  eta: 0:03:43  Lr: 0.001875  Loss: -0.7856  Acc@1: 62.5000 (65.7955)  Acc@5: 93.7500 (92.0071)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: 0.2351  Acc@1: 62.5000 (65.7903)  Acc@5: 93.7500 (91.9925)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3960/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.3140  Acc@1: 62.5000 (65.7930)  Acc@5: 93.7500 (91.9970)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -0.0576  Acc@1: 68.7500 (65.8036)  Acc@5: 93.7500 (91.9998)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3980/4579]  eta: 0:03:29  Lr: 0.001875  Loss: 0.1856  Acc@1: 68.7500 (65.8110)  Acc@5: 93.7500 (92.0011)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.3495  Acc@1: 62.5000 (65.7886)  Acc@5: 93.7500 (91.9976)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4000/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.1182  Acc@1: 56.2500 (65.7836)  Acc@5: 93.7500 (91.9973)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.2088  Acc@1: 62.5000 (65.7816)  Acc@5: 93.7500 (91.9986)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4020/4579]  eta: 0:03:15  Lr: 0.001875  Loss: -0.4693  Acc@1: 68.7500 (65.7812)  Acc@5: 93.7500 (91.9983)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: -0.4262  Acc@1: 68.7500 (65.7963)  Acc@5: 93.7500 (91.9980)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4040/4579]  eta: 0:03:08  Lr: 0.001875  Loss: 0.1074  Acc@1: 68.7500 (65.7851)  Acc@5: 93.7500 (91.9976)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.3171  Acc@1: 62.5000 (65.7862)  Acc@5: 93.7500 (92.0020)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4060/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.1517  Acc@1: 62.5000 (65.7858)  Acc@5: 93.7500 (91.9955)  time: 0.3522  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: 0.1586  Acc@1: 62.5000 (65.7793)  Acc@5: 87.5000 (91.9860)  time: 0.3522  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4080/4579]  eta: 0:02:54  Lr: 0.001875  Loss: 0.4305  Acc@1: 68.7500 (65.7850)  Acc@5: 93.7500 (91.9980)  time: 0.3553  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.1864  Acc@1: 68.7500 (65.7953)  Acc@5: 93.7500 (92.0007)  time: 0.3562  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.4220  Acc@1: 62.5000 (65.7980)  Acc@5: 93.7500 (92.0035)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.3142  Acc@1: 62.5000 (65.7976)  Acc@5: 87.5000 (91.9895)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.9809  Acc@1: 68.7500 (65.8047)  Acc@5: 87.5000 (91.9907)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: 0.0477  Acc@1: 68.7500 (65.8073)  Acc@5: 87.5000 (91.9844)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.4376  Acc@1: 68.7500 (65.8099)  Acc@5: 93.7500 (91.9826)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.0967  Acc@1: 68.7500 (65.8094)  Acc@5: 93.7500 (91.9808)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0942  Acc@1: 62.5000 (65.8075)  Acc@5: 93.7500 (91.9791)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: -0.3112  Acc@1: 62.5000 (65.8011)  Acc@5: 93.7500 (91.9818)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.4448  Acc@1: 68.7500 (65.8111)  Acc@5: 93.7500 (91.9876)  time: 0.3536  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: -0.4662  Acc@1: 68.7500 (65.8017)  Acc@5: 93.7500 (91.9888)  time: 0.3554  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.2965  Acc@1: 62.5000 (65.7983)  Acc@5: 93.7500 (91.9870)  time: 0.3528  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: -0.4057  Acc@1: 62.5000 (65.7920)  Acc@5: 87.5000 (91.9823)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: 0.1875  Acc@1: 62.5000 (65.7842)  Acc@5: 87.5000 (91.9776)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.3987  Acc@1: 62.5000 (65.7808)  Acc@5: 93.7500 (91.9803)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: 0.0345  Acc@1: 62.5000 (65.7761)  Acc@5: 93.7500 (91.9771)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.2719  Acc@1: 62.5000 (65.7683)  Acc@5: 93.7500 (91.9813)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.3375  Acc@1: 62.5000 (65.7621)  Acc@5: 93.7500 (91.9854)  time: 0.3450  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: -0.3005  Acc@1: 62.5000 (65.7604)  Acc@5: 93.7500 (91.9852)  time: 0.3452  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: -0.4836  Acc@1: 62.5000 (65.7498)  Acc@5: 93.7500 (91.9849)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.1697  Acc@1: 62.5000 (65.7466)  Acc@5: 87.5000 (91.9745)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: 0.2219  Acc@1: 68.7500 (65.7522)  Acc@5: 87.5000 (91.9699)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.2529  Acc@1: 62.5000 (65.7490)  Acc@5: 87.5000 (91.9668)  time: 0.3531  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3385  Acc@1: 62.5000 (65.7501)  Acc@5: 87.5000 (91.9622)  time: 0.3549  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: 0.4733  Acc@1: 62.5000 (65.7441)  Acc@5: 87.5000 (91.9548)  time: 0.3569  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.2228  Acc@1: 62.5000 (65.7308)  Acc@5: 87.5000 (91.9546)  time: 0.3572  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2014  Acc@1: 62.5000 (65.7363)  Acc@5: 93.7500 (91.9602)  time: 0.3515  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1851  Acc@1: 68.7500 (65.7418)  Acc@5: 93.7500 (91.9629)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4247  Acc@1: 68.7500 (65.7330)  Acc@5: 93.7500 (91.9569)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.5743  Acc@1: 68.7500 (65.7413)  Acc@5: 93.7500 (91.9567)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4882  Acc@1: 68.7500 (65.7439)  Acc@5: 93.7500 (91.9594)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.7566  Acc@1: 68.7500 (65.7450)  Acc@5: 93.7500 (91.9592)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.0651  Acc@1: 68.7500 (65.7391)  Acc@5: 87.5000 (91.9534)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.3521  Acc@1: 68.7500 (65.7402)  Acc@5: 87.5000 (91.9532)  time: 0.3493  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1121  Acc@1: 68.7500 (65.7385)  Acc@5: 93.7500 (91.9516)  time: 0.3560  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0445  Acc@1: 62.5000 (65.7327)  Acc@5: 93.7500 (91.9500)  time: 0.3594  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0677  Acc@1: 62.5000 (65.7268)  Acc@5: 87.5000 (91.9456)  time: 0.3553  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.3262  Acc@1: 68.7500 (65.7490)  Acc@5: 93.7500 (91.9525)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.4335  Acc@1: 68.7500 (65.7417)  Acc@5: 93.7500 (91.9551)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6705  Acc@1: 68.7500 (65.7568)  Acc@5: 93.7500 (91.9549)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2259  Acc@1: 75.0000 (65.7732)  Acc@5: 87.5000 (91.9506)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3218  Acc@1: 68.7500 (65.7882)  Acc@5: 87.5000 (91.9518)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3815  Acc@1: 68.7500 (65.7920)  Acc@5: 93.7500 (91.9585)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.2465  Acc@1: 68.7500 (65.7943)  Acc@5: 93.7500 (91.9542)  time: 0.3549  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2283  Acc@1: 62.5000 (65.7954)  Acc@5: 93.7500 (91.9499)  time: 0.3523  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.4501  Acc@1: 68.7500 (65.8060)  Acc@5: 93.7500 (91.9539)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.1154  Acc@1: 68.7500 (65.8152)  Acc@5: 93.7500 (91.9509)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.1941  Acc@1: 68.7500 (65.8230)  Acc@5: 93.7500 (91.9521)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.4226  Acc@1: 62.5000 (65.8116)  Acc@5: 93.7500 (91.9547)  time: 0.3514  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1106  Acc@1: 62.5000 (65.8149)  Acc@5: 88.8889 (91.9489)  time: 0.3441  data: 0.0020  max mem: 2500
Train: Epoch[4/5] Total time: 0:26:45 (0.3506 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 292980, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 292996, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 293012, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 292948, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1106  Acc@1: 62.5000 (65.8149)  Acc@5: 88.8889 (91.9489)
Train: Epoch[5/5]  [   0/4579]  eta: 0:46:16  Lr: 0.001875  Loss: -0.1549  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 0.6063  data: 0.2632  max mem: 2500
Train: Epoch[5/5]  [  10/4579]  eta: 0:28:01  Lr: 0.001875  Loss: -0.4953  Acc@1: 62.5000 (60.7955)  Acc@5: 87.5000 (89.2045)  time: 0.3680  data: 0.0243  max mem: 2500
Train: Epoch[5/5]  [  20/4579]  eta: 0:27:05  Lr: 0.001875  Loss: 0.2085  Acc@1: 62.5000 (60.4167)  Acc@5: 93.7500 (89.8810)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  30/4579]  eta: 0:26:44  Lr: 0.001875  Loss: -0.5584  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (90.3226)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [  40/4579]  eta: 0:26:31  Lr: 0.001875  Loss: -0.5197  Acc@1: 68.7500 (65.7012)  Acc@5: 93.7500 (91.1585)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  50/4579]  eta: 0:26:22  Lr: 0.001875  Loss: -0.5622  Acc@1: 68.7500 (66.0539)  Acc@5: 93.7500 (91.6667)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  60/4579]  eta: 0:26:15  Lr: 0.001875  Loss: 0.1746  Acc@1: 68.7500 (66.4959)  Acc@5: 93.7500 (91.3934)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  70/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 0.2230  Acc@1: 68.7500 (65.9331)  Acc@5: 87.5000 (91.2852)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  80/4579]  eta: 0:26:06  Lr: 0.001875  Loss: -0.3144  Acc@1: 68.7500 (66.2809)  Acc@5: 93.7500 (91.5895)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [  90/4579]  eta: 0:26:04  Lr: 0.001875  Loss: -0.1351  Acc@1: 68.7500 (66.0027)  Acc@5: 93.7500 (91.4835)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 100/4579]  eta: 0:26:02  Lr: 0.001875  Loss: -0.0483  Acc@1: 68.7500 (66.2129)  Acc@5: 93.7500 (91.6460)  time: 0.3512  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 110/4579]  eta: 0:25:59  Lr: 0.001875  Loss: -0.7015  Acc@1: 68.7500 (66.4977)  Acc@5: 93.7500 (91.8919)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 120/4579]  eta: 0:25:56  Lr: 0.001875  Loss: -0.4359  Acc@1: 68.7500 (65.8058)  Acc@5: 93.7500 (91.6839)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 130/4579]  eta: 0:25:53  Lr: 0.001875  Loss: -0.1996  Acc@1: 56.2500 (65.2195)  Acc@5: 87.5000 (91.5076)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 140/4579]  eta: 0:25:50  Lr: 0.001875  Loss: -0.0127  Acc@1: 62.5000 (65.2482)  Acc@5: 93.7500 (91.5780)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 150/4579]  eta: 0:25:47  Lr: 0.001875  Loss: 0.2920  Acc@1: 62.5000 (64.9007)  Acc@5: 93.7500 (91.6391)  time: 0.3516  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 160/4579]  eta: 0:25:44  Lr: 0.001875  Loss: -0.2586  Acc@1: 62.5000 (64.9457)  Acc@5: 93.7500 (91.6537)  time: 0.3512  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [ 170/4579]  eta: 0:25:42  Lr: 0.001875  Loss: -0.4704  Acc@1: 68.7500 (65.2778)  Acc@5: 93.7500 (91.7032)  time: 0.3539  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 180/4579]  eta: 0:25:41  Lr: 0.001875  Loss: -0.0782  Acc@1: 68.7500 (65.0207)  Acc@5: 93.7500 (91.6091)  time: 0.3567  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 190/4579]  eta: 0:25:38  Lr: 0.001875  Loss: 0.6236  Acc@1: 56.2500 (64.9215)  Acc@5: 93.7500 (91.5903)  time: 0.3548  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 200/4579]  eta: 0:25:36  Lr: 0.001875  Loss: -0.0529  Acc@1: 62.5000 (64.8632)  Acc@5: 93.7500 (91.4179)  time: 0.3546  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 210/4579]  eta: 0:25:32  Lr: 0.001875  Loss: -0.0024  Acc@1: 62.5000 (64.7216)  Acc@5: 93.7500 (91.5877)  time: 0.3541  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 220/4579]  eta: 0:25:29  Lr: 0.001875  Loss: -0.4231  Acc@1: 62.5000 (64.6493)  Acc@5: 93.7500 (91.6007)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 230/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 0.2466  Acc@1: 68.7500 (64.7998)  Acc@5: 93.7500 (91.5855)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 240/4579]  eta: 0:25:22  Lr: 0.001875  Loss: -0.4201  Acc@1: 68.7500 (65.1193)  Acc@5: 93.7500 (91.7272)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 250/4579]  eta: 0:25:19  Lr: 0.001875  Loss: -0.3615  Acc@1: 68.7500 (65.3137)  Acc@5: 93.7500 (91.8576)  time: 0.3526  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 260/4579]  eta: 0:25:15  Lr: 0.001875  Loss: -0.5050  Acc@1: 68.7500 (65.3496)  Acc@5: 93.7500 (91.8343)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 270/4579]  eta: 0:25:11  Lr: 0.001875  Loss: -0.6967  Acc@1: 62.5000 (65.4982)  Acc@5: 93.7500 (91.8819)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 280/4579]  eta: 0:25:08  Lr: 0.001875  Loss: -0.3298  Acc@1: 62.5000 (65.4804)  Acc@5: 93.7500 (91.7927)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 290/4579]  eta: 0:25:04  Lr: 0.001875  Loss: -0.5569  Acc@1: 62.5000 (65.5498)  Acc@5: 93.7500 (91.8600)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 300/4579]  eta: 0:25:01  Lr: 0.001875  Loss: -0.3012  Acc@1: 68.7500 (65.8223)  Acc@5: 93.7500 (92.0058)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 310/4579]  eta: 0:24:57  Lr: 0.001875  Loss: -0.3822  Acc@1: 68.7500 (65.7958)  Acc@5: 93.7500 (91.9212)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 320/4579]  eta: 0:24:53  Lr: 0.001875  Loss: -0.0286  Acc@1: 68.7500 (65.8879)  Acc@5: 87.5000 (91.7835)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 330/4579]  eta: 0:24:50  Lr: 0.001875  Loss: 0.3533  Acc@1: 68.7500 (65.9177)  Acc@5: 93.7500 (91.7674)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 340/4579]  eta: 0:24:46  Lr: 0.001875  Loss: -0.8342  Acc@1: 68.7500 (65.7808)  Acc@5: 87.5000 (91.6239)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 350/4579]  eta: 0:24:42  Lr: 0.001875  Loss: -0.0516  Acc@1: 68.7500 (65.8120)  Acc@5: 87.5000 (91.6311)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 360/4579]  eta: 0:24:38  Lr: 0.001875  Loss: -0.4288  Acc@1: 68.7500 (65.8587)  Acc@5: 93.7500 (91.5686)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 370/4579]  eta: 0:24:35  Lr: 0.001875  Loss: -0.3973  Acc@1: 62.5000 (65.6334)  Acc@5: 87.5000 (91.5431)  time: 0.3513  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 380/4579]  eta: 0:24:31  Lr: 0.001875  Loss: 0.0120  Acc@1: 56.2500 (65.6332)  Acc@5: 93.7500 (91.5682)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 390/4579]  eta: 0:24:28  Lr: 0.001875  Loss: 0.0134  Acc@1: 62.5000 (65.5371)  Acc@5: 93.7500 (91.5921)  time: 0.3468  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 400/4579]  eta: 0:24:24  Lr: 0.001875  Loss: -1.0064  Acc@1: 62.5000 (65.6328)  Acc@5: 93.7500 (91.6147)  time: 0.3478  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [ 410/4579]  eta: 0:24:20  Lr: 0.001875  Loss: -0.2161  Acc@1: 68.7500 (65.7999)  Acc@5: 93.7500 (91.5602)  time: 0.3465  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 420/4579]  eta: 0:24:16  Lr: 0.001875  Loss: -0.5156  Acc@1: 68.7500 (65.7215)  Acc@5: 87.5000 (91.4935)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 430/4579]  eta: 0:24:12  Lr: 0.001875  Loss: -0.5818  Acc@1: 68.7500 (65.8933)  Acc@5: 93.7500 (91.4733)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 440/4579]  eta: 0:24:08  Lr: 0.001875  Loss: -0.0619  Acc@1: 68.7500 (65.8588)  Acc@5: 93.7500 (91.4824)  time: 0.3455  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 450/4579]  eta: 0:24:04  Lr: 0.001875  Loss: -0.5039  Acc@1: 68.7500 (66.0338)  Acc@5: 93.7500 (91.5327)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 460/4579]  eta: 0:24:00  Lr: 0.001875  Loss: -0.5080  Acc@1: 75.0000 (66.1198)  Acc@5: 93.7500 (91.5130)  time: 0.3453  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 470/4579]  eta: 0:23:57  Lr: 0.001875  Loss: -0.3864  Acc@1: 62.5000 (66.0430)  Acc@5: 93.7500 (91.5074)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 480/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 0.0894  Acc@1: 62.5000 (66.0083)  Acc@5: 93.7500 (91.5800)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 490/4579]  eta: 0:23:50  Lr: 0.001875  Loss: 0.0780  Acc@1: 68.7500 (65.9751)  Acc@5: 93.7500 (91.6242)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 500/4579]  eta: 0:23:46  Lr: 0.001875  Loss: -0.2849  Acc@1: 68.7500 (65.9681)  Acc@5: 93.7500 (91.5918)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 510/4579]  eta: 0:23:43  Lr: 0.001875  Loss: -0.1972  Acc@1: 62.5000 (65.8023)  Acc@5: 87.5000 (91.5607)  time: 0.3525  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 520/4579]  eta: 0:23:40  Lr: 0.001875  Loss: -0.3326  Acc@1: 62.5000 (65.7750)  Acc@5: 93.7500 (91.5547)  time: 0.3523  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 530/4579]  eta: 0:23:36  Lr: 0.001875  Loss: 0.1127  Acc@1: 62.5000 (65.7250)  Acc@5: 93.7500 (91.5843)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 540/4579]  eta: 0:23:33  Lr: 0.001875  Loss: -0.2407  Acc@1: 62.5000 (65.6192)  Acc@5: 87.5000 (91.5319)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 550/4579]  eta: 0:23:29  Lr: 0.001875  Loss: -0.5223  Acc@1: 62.5000 (65.6307)  Acc@5: 93.7500 (91.5835)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 560/4579]  eta: 0:23:26  Lr: 0.001875  Loss: -0.4932  Acc@1: 68.7500 (65.6863)  Acc@5: 93.7500 (91.5775)  time: 0.3517  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 570/4579]  eta: 0:23:23  Lr: 0.001875  Loss: -0.4692  Acc@1: 68.7500 (65.6414)  Acc@5: 87.5000 (91.5718)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 580/4579]  eta: 0:23:19  Lr: 0.001875  Loss: -0.4293  Acc@1: 62.5000 (65.5336)  Acc@5: 87.5000 (91.5555)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 590/4579]  eta: 0:23:16  Lr: 0.001875  Loss: -0.2832  Acc@1: 62.5000 (65.4188)  Acc@5: 93.7500 (91.5609)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 600/4579]  eta: 0:23:12  Lr: 0.001875  Loss: -0.5037  Acc@1: 62.5000 (65.4534)  Acc@5: 93.7500 (91.5037)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 610/4579]  eta: 0:23:09  Lr: 0.001875  Loss: -0.3735  Acc@1: 62.5000 (65.4562)  Acc@5: 93.7500 (91.5200)  time: 0.3528  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 620/4579]  eta: 0:23:06  Lr: 0.001875  Loss: -0.7082  Acc@1: 62.5000 (65.5193)  Acc@5: 93.7500 (91.5258)  time: 0.3555  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 630/4579]  eta: 0:23:03  Lr: 0.001875  Loss: -0.2602  Acc@1: 68.7500 (65.5210)  Acc@5: 93.7500 (91.5115)  time: 0.3538  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 640/4579]  eta: 0:23:00  Lr: 0.001875  Loss: 0.2284  Acc@1: 68.7500 (65.6494)  Acc@5: 93.7500 (91.5367)  time: 0.3557  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 650/4579]  eta: 0:22:56  Lr: 0.001875  Loss: -0.3324  Acc@1: 75.0000 (65.7066)  Acc@5: 93.7500 (91.5899)  time: 0.3545  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 660/4579]  eta: 0:22:53  Lr: 0.001875  Loss: -0.5324  Acc@1: 62.5000 (65.6959)  Acc@5: 93.7500 (91.5658)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 670/4579]  eta: 0:22:49  Lr: 0.001875  Loss: -0.1498  Acc@1: 62.5000 (65.7507)  Acc@5: 93.7500 (91.5984)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 680/4579]  eta: 0:22:46  Lr: 0.001875  Loss: -0.4862  Acc@1: 62.5000 (65.6571)  Acc@5: 93.7500 (91.5106)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 690/4579]  eta: 0:22:42  Lr: 0.001875  Loss: -0.0634  Acc@1: 62.5000 (65.6024)  Acc@5: 87.5000 (91.4707)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 700/4579]  eta: 0:22:38  Lr: 0.001875  Loss: 0.0349  Acc@1: 62.5000 (65.6116)  Acc@5: 87.5000 (91.4319)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 710/4579]  eta: 0:22:35  Lr: 0.001875  Loss: -0.5643  Acc@1: 62.5000 (65.5854)  Acc@5: 93.7500 (91.4557)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 720/4579]  eta: 0:22:32  Lr: 0.001875  Loss: -0.0023  Acc@1: 62.5000 (65.5600)  Acc@5: 93.7500 (91.4875)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 730/4579]  eta: 0:22:28  Lr: 0.001875  Loss: -0.1291  Acc@1: 68.7500 (65.6293)  Acc@5: 93.7500 (91.4586)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 740/4579]  eta: 0:22:25  Lr: 0.001875  Loss: -0.5835  Acc@1: 68.7500 (65.7051)  Acc@5: 93.7500 (91.4895)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 750/4579]  eta: 0:22:21  Lr: 0.001875  Loss: -0.0131  Acc@1: 68.7500 (65.7457)  Acc@5: 93.7500 (91.5113)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 760/4579]  eta: 0:22:18  Lr: 0.001875  Loss: 0.1463  Acc@1: 68.7500 (65.7687)  Acc@5: 93.7500 (91.5325)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 770/4579]  eta: 0:22:14  Lr: 0.001875  Loss: -0.5702  Acc@1: 68.7500 (65.7750)  Acc@5: 93.7500 (91.5451)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 780/4579]  eta: 0:22:11  Lr: 0.001875  Loss: 0.1415  Acc@1: 68.7500 (65.8451)  Acc@5: 93.7500 (91.5493)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 790/4579]  eta: 0:22:07  Lr: 0.001875  Loss: -0.1673  Acc@1: 68.7500 (65.7870)  Acc@5: 93.7500 (91.5455)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 800/4579]  eta: 0:22:04  Lr: 0.001875  Loss: 0.2968  Acc@1: 56.2500 (65.7615)  Acc@5: 93.7500 (91.6042)  time: 0.3562  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 810/4579]  eta: 0:22:01  Lr: 0.001875  Loss: -0.2860  Acc@1: 62.5000 (65.7213)  Acc@5: 93.7500 (91.5922)  time: 0.3540  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 820/4579]  eta: 0:21:57  Lr: 0.001875  Loss: -0.9283  Acc@1: 68.7500 (65.7887)  Acc@5: 93.7500 (91.5804)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 830/4579]  eta: 0:21:53  Lr: 0.001875  Loss: -0.4433  Acc@1: 68.7500 (65.8093)  Acc@5: 93.7500 (91.5839)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 840/4579]  eta: 0:21:50  Lr: 0.001875  Loss: -0.8025  Acc@1: 68.7500 (65.8368)  Acc@5: 93.7500 (91.5800)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 850/4579]  eta: 0:21:46  Lr: 0.001875  Loss: -0.3878  Acc@1: 62.5000 (65.8196)  Acc@5: 93.7500 (91.6202)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 860/4579]  eta: 0:21:43  Lr: 0.001875  Loss: -0.4180  Acc@1: 62.5000 (65.8174)  Acc@5: 93.7500 (91.6521)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 870/4579]  eta: 0:21:39  Lr: 0.001875  Loss: -0.1884  Acc@1: 56.2500 (65.7290)  Acc@5: 93.7500 (91.6475)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 880/4579]  eta: 0:21:36  Lr: 0.001875  Loss: 0.5307  Acc@1: 56.2500 (65.6711)  Acc@5: 87.5000 (91.6005)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 890/4579]  eta: 0:21:32  Lr: 0.001875  Loss: -0.6967  Acc@1: 62.5000 (65.6987)  Acc@5: 87.5000 (91.6105)  time: 0.3494  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 900/4579]  eta: 0:21:28  Lr: 0.001875  Loss: 0.5308  Acc@1: 62.5000 (65.6215)  Acc@5: 87.5000 (91.5719)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 910/4579]  eta: 0:21:25  Lr: 0.001875  Loss: -0.4678  Acc@1: 68.7500 (65.6970)  Acc@5: 93.7500 (91.6026)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 920/4579]  eta: 0:21:21  Lr: 0.001875  Loss: -0.3136  Acc@1: 68.7500 (65.6827)  Acc@5: 93.7500 (91.5852)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 930/4579]  eta: 0:21:18  Lr: 0.001875  Loss: -0.4245  Acc@1: 68.7500 (65.7693)  Acc@5: 93.7500 (91.6219)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 940/4579]  eta: 0:21:14  Lr: 0.001875  Loss: 0.1195  Acc@1: 68.7500 (65.7744)  Acc@5: 93.7500 (91.5980)  time: 0.3514  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 950/4579]  eta: 0:21:11  Lr: 0.001875  Loss: 0.3810  Acc@1: 68.7500 (65.7334)  Acc@5: 87.5000 (91.5878)  time: 0.3525  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 960/4579]  eta: 0:21:07  Lr: 0.001875  Loss: -0.8491  Acc@1: 68.7500 (65.7778)  Acc@5: 93.7500 (91.6103)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 970/4579]  eta: 0:21:04  Lr: 0.001875  Loss: -0.6180  Acc@1: 62.5000 (65.7376)  Acc@5: 93.7500 (91.5808)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 980/4579]  eta: 0:21:00  Lr: 0.001875  Loss: -0.5451  Acc@1: 62.5000 (65.7556)  Acc@5: 93.7500 (91.6093)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 990/4579]  eta: 0:20:57  Lr: 0.001875  Loss: -0.0348  Acc@1: 68.7500 (65.7228)  Acc@5: 93.7500 (91.6183)  time: 0.3548  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1000/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.4209  Acc@1: 62.5000 (65.7030)  Acc@5: 93.7500 (91.6021)  time: 0.3563  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1010/4579]  eta: 0:20:50  Lr: 0.001875  Loss: -0.2162  Acc@1: 62.5000 (65.7270)  Acc@5: 93.7500 (91.6110)  time: 0.3548  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1020/4579]  eta: 0:20:47  Lr: 0.001875  Loss: -0.4264  Acc@1: 62.5000 (65.7076)  Acc@5: 93.7500 (91.6197)  time: 0.3538  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1030/4579]  eta: 0:20:43  Lr: 0.001875  Loss: -0.0200  Acc@1: 62.5000 (65.7311)  Acc@5: 87.5000 (91.5919)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1040/4579]  eta: 0:20:40  Lr: 0.001875  Loss: 0.0794  Acc@1: 68.7500 (65.7000)  Acc@5: 93.7500 (91.5886)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1050/4579]  eta: 0:20:36  Lr: 0.001875  Loss: -0.7550  Acc@1: 68.7500 (65.7231)  Acc@5: 93.7500 (91.5854)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1060/4579]  eta: 0:20:33  Lr: 0.001875  Loss: 0.0996  Acc@1: 68.7500 (65.7575)  Acc@5: 93.7500 (91.5999)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1070/4579]  eta: 0:20:30  Lr: 0.001875  Loss: -0.4798  Acc@1: 75.0000 (65.8322)  Acc@5: 93.7500 (91.6317)  time: 0.3553  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1080/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.1322  Acc@1: 75.0000 (65.9054)  Acc@5: 93.7500 (91.6339)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1090/4579]  eta: 0:20:22  Lr: 0.001875  Loss: -0.4969  Acc@1: 68.7500 (65.8799)  Acc@5: 93.7500 (91.6247)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1100/4579]  eta: 0:20:19  Lr: 0.001875  Loss: -0.4622  Acc@1: 62.5000 (65.8890)  Acc@5: 93.7500 (91.6213)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1110/4579]  eta: 0:20:15  Lr: 0.001875  Loss: -0.1504  Acc@1: 68.7500 (65.9878)  Acc@5: 93.7500 (91.6742)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1120/4579]  eta: 0:20:11  Lr: 0.001875  Loss: -0.5408  Acc@1: 68.7500 (66.0125)  Acc@5: 93.7500 (91.6927)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1130/4579]  eta: 0:20:08  Lr: 0.001875  Loss: -0.0766  Acc@1: 62.5000 (65.9704)  Acc@5: 93.7500 (91.7053)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1140/4579]  eta: 0:20:04  Lr: 0.001875  Loss: -0.3676  Acc@1: 68.7500 (66.0221)  Acc@5: 93.7500 (91.7233)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1150/4579]  eta: 0:20:01  Lr: 0.001875  Loss: -0.6082  Acc@1: 68.7500 (66.0078)  Acc@5: 93.7500 (91.7300)  time: 0.3539  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1160/4579]  eta: 0:19:58  Lr: 0.001875  Loss: 0.0129  Acc@1: 62.5000 (65.9345)  Acc@5: 93.7500 (91.6882)  time: 0.3558  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1170/4579]  eta: 0:19:54  Lr: 0.001875  Loss: -0.3775  Acc@1: 62.5000 (65.9159)  Acc@5: 87.5000 (91.6951)  time: 0.3539  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1180/4579]  eta: 0:19:51  Lr: 0.001875  Loss: -0.3704  Acc@1: 68.7500 (65.9452)  Acc@5: 93.7500 (91.6967)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1190/4579]  eta: 0:19:47  Lr: 0.001875  Loss: 0.0191  Acc@1: 62.5000 (65.9110)  Acc@5: 93.7500 (91.7139)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1200/4579]  eta: 0:19:43  Lr: 0.001875  Loss: -0.2693  Acc@1: 62.5000 (65.9346)  Acc@5: 93.7500 (91.7152)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1210/4579]  eta: 0:19:40  Lr: 0.001875  Loss: 0.2664  Acc@1: 62.5000 (65.9321)  Acc@5: 93.7500 (91.7217)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1220/4579]  eta: 0:19:36  Lr: 0.001875  Loss: -0.4315  Acc@1: 62.5000 (65.9296)  Acc@5: 93.7500 (91.6871)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1230/4579]  eta: 0:19:33  Lr: 0.001875  Loss: -0.0972  Acc@1: 62.5000 (65.9525)  Acc@5: 93.7500 (91.7191)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1240/4579]  eta: 0:19:29  Lr: 0.001875  Loss: -0.6267  Acc@1: 68.7500 (65.9851)  Acc@5: 100.0000 (91.7506)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1250/4579]  eta: 0:19:25  Lr: 0.001875  Loss: -0.6876  Acc@1: 62.5000 (65.9422)  Acc@5: 93.7500 (91.7266)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1260/4579]  eta: 0:19:22  Lr: 0.001875  Loss: -0.5547  Acc@1: 68.7500 (65.9645)  Acc@5: 93.7500 (91.7476)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1270/4579]  eta: 0:19:18  Lr: 0.001875  Loss: -0.4378  Acc@1: 68.7500 (65.9717)  Acc@5: 93.7500 (91.7683)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1280/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.4611  Acc@1: 68.7500 (65.9397)  Acc@5: 93.7500 (91.7545)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1290/4579]  eta: 0:19:11  Lr: 0.001875  Loss: -0.1762  Acc@1: 68.7500 (66.0002)  Acc@5: 93.7500 (91.7893)  time: 0.3523  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1300/4579]  eta: 0:19:08  Lr: 0.001875  Loss: 0.5691  Acc@1: 75.0000 (66.0309)  Acc@5: 93.7500 (91.8044)  time: 0.3520  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1310/4579]  eta: 0:19:04  Lr: 0.001875  Loss: -0.7443  Acc@1: 75.0000 (66.0946)  Acc@5: 93.7500 (91.8097)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1320/4579]  eta: 0:19:01  Lr: 0.001875  Loss: -0.2155  Acc@1: 62.5000 (66.0768)  Acc@5: 93.7500 (91.8055)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1330/4579]  eta: 0:18:58  Lr: 0.001875  Loss: -0.2159  Acc@1: 62.5000 (66.0781)  Acc@5: 93.7500 (91.8201)  time: 0.3554  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1340/4579]  eta: 0:18:54  Lr: 0.001875  Loss: -0.2769  Acc@1: 62.5000 (66.0608)  Acc@5: 93.7500 (91.8251)  time: 0.3556  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1350/4579]  eta: 0:18:51  Lr: 0.001875  Loss: -0.1384  Acc@1: 62.5000 (66.0575)  Acc@5: 93.7500 (91.8209)  time: 0.3531  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1360/4579]  eta: 0:18:47  Lr: 0.001875  Loss: -0.9948  Acc@1: 62.5000 (66.0865)  Acc@5: 93.7500 (91.8442)  time: 0.3524  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1370/4579]  eta: 0:18:44  Lr: 0.001875  Loss: -0.1882  Acc@1: 62.5000 (66.0649)  Acc@5: 93.7500 (91.8308)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1380/4579]  eta: 0:18:40  Lr: 0.001875  Loss: -0.5375  Acc@1: 62.5000 (66.0889)  Acc@5: 93.7500 (91.8492)  time: 0.3531  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [1390/4579]  eta: 0:18:37  Lr: 0.001875  Loss: -0.5825  Acc@1: 62.5000 (66.0676)  Acc@5: 93.7500 (91.8584)  time: 0.3517  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1400/4579]  eta: 0:18:33  Lr: 0.001875  Loss: -0.3986  Acc@1: 62.5000 (66.0956)  Acc@5: 93.7500 (91.8630)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1410/4579]  eta: 0:18:30  Lr: 0.001875  Loss: -0.2092  Acc@1: 62.5000 (66.0790)  Acc@5: 93.7500 (91.8542)  time: 0.3550  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1420/4579]  eta: 0:18:26  Lr: 0.001875  Loss: -0.1518  Acc@1: 62.5000 (66.0626)  Acc@5: 87.5000 (91.8323)  time: 0.3530  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1430/4579]  eta: 0:18:23  Lr: 0.001875  Loss: -0.3592  Acc@1: 62.5000 (66.0596)  Acc@5: 93.7500 (91.8326)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1440/4579]  eta: 0:18:19  Lr: 0.001875  Loss: -0.4581  Acc@1: 68.7500 (66.0826)  Acc@5: 93.7500 (91.8459)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1450/4579]  eta: 0:18:16  Lr: 0.001875  Loss: -0.5581  Acc@1: 68.7500 (66.0967)  Acc@5: 93.7500 (91.8418)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1460/4579]  eta: 0:18:12  Lr: 0.001875  Loss: -0.1288  Acc@1: 62.5000 (66.0806)  Acc@5: 87.5000 (91.8335)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1470/4579]  eta: 0:18:09  Lr: 0.001875  Loss: -0.3696  Acc@1: 62.5000 (66.0478)  Acc@5: 87.5000 (91.8125)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1480/4579]  eta: 0:18:05  Lr: 0.001875  Loss: -0.7378  Acc@1: 75.0000 (66.1293)  Acc@5: 93.7500 (91.8256)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1490/4579]  eta: 0:18:01  Lr: 0.001875  Loss: -0.6501  Acc@1: 75.0000 (66.1259)  Acc@5: 93.7500 (91.8260)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1500/4579]  eta: 0:17:58  Lr: 0.001875  Loss: -0.4677  Acc@1: 62.5000 (66.1434)  Acc@5: 93.7500 (91.8429)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1510/4579]  eta: 0:17:54  Lr: 0.001875  Loss: -0.5410  Acc@1: 62.5000 (66.1317)  Acc@5: 93.7500 (91.8473)  time: 0.3475  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1520/4579]  eta: 0:17:51  Lr: 0.001875  Loss: -0.0347  Acc@1: 62.5000 (66.1448)  Acc@5: 93.7500 (91.8557)  time: 0.3469  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1530/4579]  eta: 0:17:47  Lr: 0.001875  Loss: -0.0858  Acc@1: 62.5000 (66.1169)  Acc@5: 93.7500 (91.8517)  time: 0.3467  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1540/4579]  eta: 0:17:44  Lr: 0.001875  Loss: -0.6181  Acc@1: 68.7500 (66.1543)  Acc@5: 93.7500 (91.8640)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1550/4579]  eta: 0:17:40  Lr: 0.001875  Loss: -0.3178  Acc@1: 68.7500 (66.1630)  Acc@5: 93.7500 (91.8641)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1560/4579]  eta: 0:17:36  Lr: 0.001875  Loss: 0.0056  Acc@1: 62.5000 (66.1235)  Acc@5: 87.5000 (91.8442)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1570/4579]  eta: 0:17:33  Lr: 0.001875  Loss: 0.0877  Acc@1: 62.5000 (66.0964)  Acc@5: 87.5000 (91.8444)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1580/4579]  eta: 0:17:29  Lr: 0.001875  Loss: -0.0122  Acc@1: 62.5000 (66.0974)  Acc@5: 93.7500 (91.8525)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1590/4579]  eta: 0:17:26  Lr: 0.001875  Loss: -0.0525  Acc@1: 62.5000 (66.0473)  Acc@5: 93.7500 (91.8605)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1600/4579]  eta: 0:17:23  Lr: 0.001875  Loss: 0.2528  Acc@1: 62.5000 (66.0251)  Acc@5: 93.7500 (91.8293)  time: 0.3515  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1610/4579]  eta: 0:17:19  Lr: 0.001875  Loss: -0.3422  Acc@1: 68.7500 (66.0459)  Acc@5: 93.7500 (91.8529)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1620/4579]  eta: 0:17:16  Lr: 0.001875  Loss: -0.3258  Acc@1: 62.5000 (66.0356)  Acc@5: 93.7500 (91.8530)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1630/4579]  eta: 0:17:12  Lr: 0.001875  Loss: 0.1069  Acc@1: 62.5000 (66.0178)  Acc@5: 87.5000 (91.8340)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1640/4579]  eta: 0:17:09  Lr: 0.001875  Loss: -0.3729  Acc@1: 62.5000 (66.0230)  Acc@5: 93.7500 (91.8381)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1650/4579]  eta: 0:17:05  Lr: 0.001875  Loss: -0.6990  Acc@1: 68.7500 (66.0547)  Acc@5: 93.7500 (91.8534)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1660/4579]  eta: 0:17:02  Lr: 0.001875  Loss: 0.1301  Acc@1: 68.7500 (66.0446)  Acc@5: 93.7500 (91.8460)  time: 0.3530  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1670/4579]  eta: 0:16:58  Lr: 0.001875  Loss: -0.1933  Acc@1: 68.7500 (66.0682)  Acc@5: 93.7500 (91.8312)  time: 0.3539  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1680/4579]  eta: 0:16:55  Lr: 0.001875  Loss: -0.4519  Acc@1: 68.7500 (66.0730)  Acc@5: 93.7500 (91.8427)  time: 0.3556  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1690/4579]  eta: 0:16:51  Lr: 0.001875  Loss: -0.1421  Acc@1: 68.7500 (66.0556)  Acc@5: 93.7500 (91.8465)  time: 0.3540  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1700/4579]  eta: 0:16:48  Lr: 0.001875  Loss: -0.4482  Acc@1: 68.7500 (66.0751)  Acc@5: 93.7500 (91.8577)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1710/4579]  eta: 0:16:44  Lr: 0.001875  Loss: -0.4616  Acc@1: 68.7500 (66.0834)  Acc@5: 93.7500 (91.8651)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1720/4579]  eta: 0:16:41  Lr: 0.001875  Loss: -0.1672  Acc@1: 62.5000 (66.0844)  Acc@5: 93.7500 (91.8725)  time: 0.3520  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1730/4579]  eta: 0:16:37  Lr: 0.001875  Loss: 0.2555  Acc@1: 56.2500 (66.0456)  Acc@5: 87.5000 (91.8653)  time: 0.3535  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1740/4579]  eta: 0:16:34  Lr: 0.001875  Loss: -0.2234  Acc@1: 62.5000 (66.0432)  Acc@5: 87.5000 (91.8545)  time: 0.3542  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1750/4579]  eta: 0:16:30  Lr: 0.001875  Loss: -0.4335  Acc@1: 62.5000 (66.0194)  Acc@5: 87.5000 (91.8475)  time: 0.3531  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1760/4579]  eta: 0:16:27  Lr: 0.001875  Loss: -0.3282  Acc@1: 68.7500 (66.0207)  Acc@5: 93.7500 (91.8512)  time: 0.3517  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1770/4579]  eta: 0:16:23  Lr: 0.001875  Loss: -0.5443  Acc@1: 68.7500 (66.0291)  Acc@5: 93.7500 (91.8619)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1780/4579]  eta: 0:16:20  Lr: 0.001875  Loss: -0.3292  Acc@1: 68.7500 (66.0830)  Acc@5: 93.7500 (91.8796)  time: 0.3585  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1790/4579]  eta: 0:16:17  Lr: 0.001875  Loss: -0.3055  Acc@1: 68.7500 (66.0734)  Acc@5: 93.7500 (91.8795)  time: 0.3573  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1800/4579]  eta: 0:16:13  Lr: 0.001875  Loss: 0.0802  Acc@1: 62.5000 (66.0709)  Acc@5: 93.7500 (91.8969)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1810/4579]  eta: 0:16:10  Lr: 0.001875  Loss: -0.4441  Acc@1: 62.5000 (66.0616)  Acc@5: 93.7500 (91.8898)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1820/4579]  eta: 0:16:06  Lr: 0.001875  Loss: -0.1963  Acc@1: 68.7500 (66.0901)  Acc@5: 93.7500 (91.9069)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1830/4579]  eta: 0:16:03  Lr: 0.001875  Loss: -0.1255  Acc@1: 68.7500 (66.1012)  Acc@5: 93.7500 (91.9067)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1840/4579]  eta: 0:15:59  Lr: 0.001875  Loss: -0.4931  Acc@1: 68.7500 (66.1190)  Acc@5: 93.7500 (91.9168)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1850/4579]  eta: 0:15:56  Lr: 0.001875  Loss: -0.3309  Acc@1: 68.7500 (66.1028)  Acc@5: 93.7500 (91.9064)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1860/4579]  eta: 0:15:52  Lr: 0.001875  Loss: -0.4484  Acc@1: 62.5000 (66.1304)  Acc@5: 93.7500 (91.9163)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1870/4579]  eta: 0:15:49  Lr: 0.001875  Loss: -0.3321  Acc@1: 75.0000 (66.1745)  Acc@5: 93.7500 (91.9294)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1880/4579]  eta: 0:15:45  Lr: 0.001875  Loss: -0.6835  Acc@1: 75.0000 (66.1849)  Acc@5: 93.7500 (91.9358)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1890/4579]  eta: 0:15:41  Lr: 0.001875  Loss: -0.1609  Acc@1: 68.7500 (66.1885)  Acc@5: 93.7500 (91.9322)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1900/4579]  eta: 0:15:38  Lr: 0.001875  Loss: -0.3396  Acc@1: 68.7500 (66.1888)  Acc@5: 93.7500 (91.9385)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1910/4579]  eta: 0:15:34  Lr: 0.001875  Loss: -0.4849  Acc@1: 68.7500 (66.2121)  Acc@5: 87.5000 (91.9218)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1920/4579]  eta: 0:15:31  Lr: 0.001875  Loss: 0.2822  Acc@1: 68.7500 (66.2253)  Acc@5: 87.5000 (91.9150)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1930/4579]  eta: 0:15:27  Lr: 0.001875  Loss: -0.4662  Acc@1: 68.7500 (66.2416)  Acc@5: 93.7500 (91.9278)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1940/4579]  eta: 0:15:24  Lr: 0.001875  Loss: -0.2970  Acc@1: 68.7500 (66.2416)  Acc@5: 93.7500 (91.9436)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1950/4579]  eta: 0:15:20  Lr: 0.001875  Loss: -0.3995  Acc@1: 68.7500 (66.2257)  Acc@5: 93.7500 (91.9432)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1960/4579]  eta: 0:15:17  Lr: 0.001875  Loss: -0.0959  Acc@1: 68.7500 (66.2513)  Acc@5: 93.7500 (91.9493)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1970/4579]  eta: 0:15:13  Lr: 0.001875  Loss: -0.5688  Acc@1: 68.7500 (66.2449)  Acc@5: 93.7500 (91.9647)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/4579]  eta: 0:15:10  Lr: 0.001875  Loss: -0.3943  Acc@1: 62.5000 (66.2386)  Acc@5: 93.7500 (91.9674)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1990/4579]  eta: 0:15:06  Lr: 0.001875  Loss: -0.6045  Acc@1: 62.5000 (66.2481)  Acc@5: 93.7500 (91.9733)  time: 0.3514  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2000/4579]  eta: 0:15:03  Lr: 0.001875  Loss: -0.3398  Acc@1: 68.7500 (66.2481)  Acc@5: 93.7500 (91.9821)  time: 0.3524  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2010/4579]  eta: 0:14:59  Lr: 0.001875  Loss: -0.0701  Acc@1: 68.7500 (66.2792)  Acc@5: 93.7500 (91.9909)  time: 0.3527  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2020/4579]  eta: 0:14:56  Lr: 0.001875  Loss: -0.7656  Acc@1: 68.7500 (66.2791)  Acc@5: 93.7500 (92.0027)  time: 0.3509  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2030/4579]  eta: 0:14:52  Lr: 0.001875  Loss: -0.2836  Acc@1: 68.7500 (66.2974)  Acc@5: 93.7500 (92.0021)  time: 0.3531  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2040/4579]  eta: 0:14:49  Lr: 0.001875  Loss: 0.0877  Acc@1: 68.7500 (66.3186)  Acc@5: 93.7500 (92.0198)  time: 0.3535  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2050/4579]  eta: 0:14:45  Lr: 0.001875  Loss: -0.6755  Acc@1: 62.5000 (66.3061)  Acc@5: 93.7500 (92.0283)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2060/4579]  eta: 0:14:42  Lr: 0.001875  Loss: -0.4986  Acc@1: 62.5000 (66.3179)  Acc@5: 93.7500 (92.0306)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2070/4579]  eta: 0:14:38  Lr: 0.001875  Loss: -0.5362  Acc@1: 68.7500 (66.3478)  Acc@5: 93.7500 (92.0238)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2080/4579]  eta: 0:14:35  Lr: 0.001875  Loss: -0.2855  Acc@1: 68.7500 (66.3563)  Acc@5: 93.7500 (92.0321)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2090/4579]  eta: 0:14:31  Lr: 0.001875  Loss: -0.7567  Acc@1: 68.7500 (66.3737)  Acc@5: 93.7500 (92.0343)  time: 0.3514  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2100/4579]  eta: 0:14:28  Lr: 0.001875  Loss: -0.2871  Acc@1: 68.7500 (66.3940)  Acc@5: 100.0000 (92.0603)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2110/4579]  eta: 0:14:24  Lr: 0.001875  Loss: 0.7018  Acc@1: 62.5000 (66.3696)  Acc@5: 93.7500 (92.0446)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2120/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.5323  Acc@1: 62.5000 (66.3838)  Acc@5: 93.7500 (92.0497)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2130/4579]  eta: 0:14:17  Lr: 0.001875  Loss: 0.2848  Acc@1: 68.7500 (66.3597)  Acc@5: 93.7500 (92.0607)  time: 0.3535  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2140/4579]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5403  Acc@1: 68.7500 (66.3533)  Acc@5: 93.7500 (92.0481)  time: 0.3536  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2150/4579]  eta: 0:14:10  Lr: 0.001875  Loss: -0.1194  Acc@1: 68.7500 (66.3500)  Acc@5: 93.7500 (92.0560)  time: 0.3525  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2160/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.7449  Acc@1: 68.7500 (66.3640)  Acc@5: 93.7500 (92.0668)  time: 0.3588  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2170/4579]  eta: 0:14:03  Lr: 0.001875  Loss: 0.0209  Acc@1: 68.7500 (66.3749)  Acc@5: 93.7500 (92.0659)  time: 0.3566  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2180/4579]  eta: 0:14:00  Lr: 0.001875  Loss: -0.1378  Acc@1: 62.5000 (66.3572)  Acc@5: 93.7500 (92.0736)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2190/4579]  eta: 0:13:56  Lr: 0.001875  Loss: 0.1329  Acc@1: 62.5000 (66.3453)  Acc@5: 93.7500 (92.0841)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2200/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.2301  Acc@1: 62.5000 (66.3448)  Acc@5: 93.7500 (92.0860)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2210/4579]  eta: 0:13:49  Lr: 0.001875  Loss: -0.4445  Acc@1: 62.5000 (66.3275)  Acc@5: 93.7500 (92.0794)  time: 0.3514  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2220/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.3223  Acc@1: 62.5000 (66.3187)  Acc@5: 93.7500 (92.0785)  time: 0.3521  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [2230/4579]  eta: 0:13:42  Lr: 0.001875  Loss: -0.4873  Acc@1: 62.5000 (66.3100)  Acc@5: 87.5000 (92.0635)  time: 0.3532  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2240/4579]  eta: 0:13:39  Lr: 0.001875  Loss: -0.5575  Acc@1: 62.5000 (66.3125)  Acc@5: 87.5000 (92.0683)  time: 0.3534  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2250/4579]  eta: 0:13:35  Lr: 0.001875  Loss: 0.7449  Acc@1: 68.7500 (66.2928)  Acc@5: 87.5000 (92.0480)  time: 0.3510  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2260/4579]  eta: 0:13:32  Lr: 0.001875  Loss: -0.6204  Acc@1: 68.7500 (66.3009)  Acc@5: 93.7500 (92.0500)  time: 0.3513  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2270/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.1392  Acc@1: 68.7500 (66.2924)  Acc@5: 93.7500 (92.0520)  time: 0.3517  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2280/4579]  eta: 0:13:25  Lr: 0.001875  Loss: -0.1188  Acc@1: 62.5000 (66.2949)  Acc@5: 93.7500 (92.0567)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2290/4579]  eta: 0:13:22  Lr: 0.001875  Loss: 0.0799  Acc@1: 62.5000 (66.2784)  Acc@5: 93.7500 (92.0613)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2300/4579]  eta: 0:13:18  Lr: 0.001875  Loss: 0.1840  Acc@1: 56.2500 (66.2674)  Acc@5: 93.7500 (92.0578)  time: 0.3528  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2310/4579]  eta: 0:13:14  Lr: 0.001875  Loss: -0.7505  Acc@1: 68.7500 (66.2781)  Acc@5: 93.7500 (92.0624)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2320/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.8182  Acc@1: 68.7500 (66.2888)  Acc@5: 93.7500 (92.0670)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2330/4579]  eta: 0:13:07  Lr: 0.001875  Loss: -0.5229  Acc@1: 62.5000 (66.2886)  Acc@5: 93.7500 (92.0742)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2340/4579]  eta: 0:13:04  Lr: 0.001875  Loss: 0.2200  Acc@1: 68.7500 (66.3125)  Acc@5: 93.7500 (92.0760)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2350/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.7161  Acc@1: 68.7500 (66.3175)  Acc@5: 93.7500 (92.0752)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2360/4579]  eta: 0:12:57  Lr: 0.001875  Loss: -0.6352  Acc@1: 68.7500 (66.3358)  Acc@5: 93.7500 (92.0770)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2370/4579]  eta: 0:12:53  Lr: 0.001875  Loss: -0.2321  Acc@1: 75.0000 (66.3591)  Acc@5: 93.7500 (92.0656)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2380/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -0.7059  Acc@1: 68.7500 (66.3534)  Acc@5: 87.5000 (92.0569)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2390/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.5306  Acc@1: 68.7500 (66.3478)  Acc@5: 93.7500 (92.0640)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2400/4579]  eta: 0:12:43  Lr: 0.001875  Loss: -0.4983  Acc@1: 68.7500 (66.3526)  Acc@5: 93.7500 (92.0606)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2410/4579]  eta: 0:12:39  Lr: 0.001875  Loss: -0.6607  Acc@1: 68.7500 (66.3547)  Acc@5: 93.7500 (92.0598)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2420/4579]  eta: 0:12:36  Lr: 0.001875  Loss: -0.8189  Acc@1: 68.7500 (66.3646)  Acc@5: 93.7500 (92.0591)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2430/4579]  eta: 0:12:32  Lr: 0.001875  Loss: -0.5882  Acc@1: 68.7500 (66.3873)  Acc@5: 93.7500 (92.0660)  time: 0.3463  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2440/4579]  eta: 0:12:29  Lr: 0.001875  Loss: -0.6054  Acc@1: 68.7500 (66.4098)  Acc@5: 93.7500 (92.0729)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2450/4579]  eta: 0:12:25  Lr: 0.001875  Loss: -0.3581  Acc@1: 62.5000 (66.3632)  Acc@5: 93.7500 (92.0645)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2460/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.5392  Acc@1: 56.2500 (66.3729)  Acc@5: 93.7500 (92.0764)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2470/4579]  eta: 0:12:18  Lr: 0.001875  Loss: -0.3137  Acc@1: 68.7500 (66.3825)  Acc@5: 93.7500 (92.0832)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2480/4579]  eta: 0:12:15  Lr: 0.001875  Loss: -0.8864  Acc@1: 62.5000 (66.3845)  Acc@5: 93.7500 (92.0949)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2490/4579]  eta: 0:12:11  Lr: 0.001875  Loss: -0.2450  Acc@1: 68.7500 (66.3940)  Acc@5: 93.7500 (92.0940)  time: 0.3526  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2500/4579]  eta: 0:12:08  Lr: 0.001875  Loss: -0.4319  Acc@1: 68.7500 (66.4059)  Acc@5: 93.7500 (92.0957)  time: 0.3537  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2510/4579]  eta: 0:12:04  Lr: 0.001875  Loss: 0.3686  Acc@1: 68.7500 (66.4028)  Acc@5: 93.7500 (92.0973)  time: 0.3531  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [2520/4579]  eta: 0:12:01  Lr: 0.001875  Loss: -0.0908  Acc@1: 68.7500 (66.4245)  Acc@5: 93.7500 (92.1038)  time: 0.3523  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2530/4579]  eta: 0:11:57  Lr: 0.001875  Loss: -0.1468  Acc@1: 68.7500 (66.4090)  Acc@5: 93.7500 (92.1005)  time: 0.3508  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2540/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.1843  Acc@1: 68.7500 (66.4158)  Acc@5: 93.7500 (92.0971)  time: 0.3508  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2550/4579]  eta: 0:11:50  Lr: 0.001875  Loss: -0.1180  Acc@1: 68.7500 (66.4249)  Acc@5: 93.7500 (92.0962)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2560/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.3566  Acc@1: 62.5000 (66.4267)  Acc@5: 93.7500 (92.1051)  time: 0.3510  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2570/4579]  eta: 0:11:43  Lr: 0.001875  Loss: -0.4429  Acc@1: 62.5000 (66.4163)  Acc@5: 93.7500 (92.1067)  time: 0.3504  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2580/4579]  eta: 0:11:40  Lr: 0.001875  Loss: -0.6005  Acc@1: 68.7500 (66.4302)  Acc@5: 93.7500 (92.1130)  time: 0.3536  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2590/4579]  eta: 0:11:36  Lr: 0.001875  Loss: -0.4661  Acc@1: 62.5000 (66.4078)  Acc@5: 87.5000 (92.0880)  time: 0.3572  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2600/4579]  eta: 0:11:33  Lr: 0.001875  Loss: -0.3155  Acc@1: 62.5000 (66.3951)  Acc@5: 87.5000 (92.0800)  time: 0.3575  data: 0.0027  max mem: 2500
Train: Epoch[5/5]  [2610/4579]  eta: 0:11:29  Lr: 0.001875  Loss: -0.0118  Acc@1: 62.5000 (66.3970)  Acc@5: 93.7500 (92.0888)  time: 0.3598  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2620/4579]  eta: 0:11:26  Lr: 0.001875  Loss: -0.6805  Acc@1: 68.7500 (66.3916)  Acc@5: 93.7500 (92.0784)  time: 0.3544  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2630/4579]  eta: 0:11:22  Lr: 0.001875  Loss: -0.6575  Acc@1: 68.7500 (66.4030)  Acc@5: 93.7500 (92.0990)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2640/4579]  eta: 0:11:19  Lr: 0.001875  Loss: -0.1913  Acc@1: 68.7500 (66.4190)  Acc@5: 93.7500 (92.1053)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2650/4579]  eta: 0:11:15  Lr: 0.001875  Loss: -0.1443  Acc@1: 68.7500 (66.4348)  Acc@5: 93.7500 (92.1115)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2660/4579]  eta: 0:11:12  Lr: 0.001875  Loss: -0.3116  Acc@1: 68.7500 (66.4318)  Acc@5: 87.5000 (92.0988)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2670/4579]  eta: 0:11:08  Lr: 0.001875  Loss: -0.9477  Acc@1: 68.7500 (66.4475)  Acc@5: 93.7500 (92.1050)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2680/4579]  eta: 0:11:05  Lr: 0.001875  Loss: -0.3770  Acc@1: 62.5000 (66.4304)  Acc@5: 93.7500 (92.1042)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2690/4579]  eta: 0:11:01  Lr: 0.001875  Loss: 0.2414  Acc@1: 62.5000 (66.4391)  Acc@5: 93.7500 (92.0987)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2700/4579]  eta: 0:10:58  Lr: 0.001875  Loss: -0.4042  Acc@1: 68.7500 (66.4245)  Acc@5: 93.7500 (92.0909)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2710/4579]  eta: 0:10:54  Lr: 0.001875  Loss: -0.1151  Acc@1: 62.5000 (66.4284)  Acc@5: 93.7500 (92.1039)  time: 0.3520  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2720/4579]  eta: 0:10:51  Lr: 0.001875  Loss: -0.1778  Acc@1: 68.7500 (66.4576)  Acc@5: 93.7500 (92.1123)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2730/4579]  eta: 0:10:47  Lr: 0.001875  Loss: -0.2646  Acc@1: 68.7500 (66.4592)  Acc@5: 93.7500 (92.1137)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2740/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.6632  Acc@1: 68.7500 (66.4835)  Acc@5: 93.7500 (92.1242)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2750/4579]  eta: 0:10:40  Lr: 0.001875  Loss: -0.2734  Acc@1: 75.0000 (66.5008)  Acc@5: 87.5000 (92.1051)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2760/4579]  eta: 0:10:37  Lr: 0.001875  Loss: -0.5595  Acc@1: 68.7500 (66.4841)  Acc@5: 87.5000 (92.1043)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2770/4579]  eta: 0:10:33  Lr: 0.001875  Loss: -0.7354  Acc@1: 62.5000 (66.4855)  Acc@5: 93.7500 (92.1102)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2780/4579]  eta: 0:10:30  Lr: 0.001875  Loss: -0.3654  Acc@1: 68.7500 (66.4779)  Acc@5: 93.7500 (92.1094)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2790/4579]  eta: 0:10:26  Lr: 0.001875  Loss: 0.1536  Acc@1: 62.5000 (66.4748)  Acc@5: 93.7500 (92.1108)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2800/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.2585  Acc@1: 62.5000 (66.4718)  Acc@5: 93.7500 (92.1077)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2810/4579]  eta: 0:10:19  Lr: 0.001875  Loss: 0.3413  Acc@1: 62.5000 (66.4643)  Acc@5: 93.7500 (92.1047)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2820/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.1835  Acc@1: 68.7500 (66.4879)  Acc@5: 93.7500 (92.1194)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2830/4579]  eta: 0:10:12  Lr: 0.001875  Loss: -0.0292  Acc@1: 68.7500 (66.4959)  Acc@5: 93.7500 (92.1273)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2840/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.4954  Acc@1: 62.5000 (66.4863)  Acc@5: 93.7500 (92.1331)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2850/4579]  eta: 0:10:05  Lr: 0.001875  Loss: -0.7465  Acc@1: 62.5000 (66.4833)  Acc@5: 93.7500 (92.1365)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2860/4579]  eta: 0:10:02  Lr: 0.001875  Loss: -0.4938  Acc@1: 68.7500 (66.4846)  Acc@5: 93.7500 (92.1400)  time: 0.3540  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2870/4579]  eta: 0:09:58  Lr: 0.001875  Loss: -0.0841  Acc@1: 68.7500 (66.4838)  Acc@5: 93.7500 (92.1347)  time: 0.3555  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2880/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.1273  Acc@1: 62.5000 (66.4678)  Acc@5: 87.5000 (92.1316)  time: 0.3540  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2890/4579]  eta: 0:09:51  Lr: 0.001875  Loss: -0.4785  Acc@1: 62.5000 (66.4800)  Acc@5: 93.7500 (92.1329)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.5757  Acc@1: 75.0000 (66.5115)  Acc@5: 93.7500 (92.1406)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2910/4579]  eta: 0:09:44  Lr: 0.001875  Loss: -0.6237  Acc@1: 68.7500 (66.5171)  Acc@5: 93.7500 (92.1462)  time: 0.3517  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5258  Acc@1: 68.7500 (66.5183)  Acc@5: 93.7500 (92.1602)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2930/4579]  eta: 0:09:37  Lr: 0.001875  Loss: -0.6390  Acc@1: 68.7500 (66.5174)  Acc@5: 93.7500 (92.1571)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.0320  Acc@1: 62.5000 (66.5080)  Acc@5: 93.7500 (92.1562)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2950/4579]  eta: 0:09:30  Lr: 0.001875  Loss: -0.2238  Acc@1: 62.5000 (66.5008)  Acc@5: 93.7500 (92.1573)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: 0.6239  Acc@1: 62.5000 (66.4788)  Acc@5: 87.5000 (92.1374)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2970/4579]  eta: 0:09:23  Lr: 0.001875  Loss: -0.2373  Acc@1: 62.5000 (66.4822)  Acc@5: 87.5000 (92.1428)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: 0.1072  Acc@1: 62.5000 (66.4836)  Acc@5: 93.7500 (92.1482)  time: 0.3548  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2990/4579]  eta: 0:09:16  Lr: 0.001875  Loss: -0.1106  Acc@1: 62.5000 (66.4640)  Acc@5: 93.7500 (92.1410)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3000/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.1760  Acc@1: 62.5000 (66.4591)  Acc@5: 93.7500 (92.1360)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3010/4579]  eta: 0:09:09  Lr: 0.001875  Loss: -0.5430  Acc@1: 62.5000 (66.4480)  Acc@5: 93.7500 (92.1289)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3020/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.4622  Acc@1: 68.7500 (66.4577)  Acc@5: 93.7500 (92.1322)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3030/4579]  eta: 0:09:02  Lr: 0.001875  Loss: -0.0685  Acc@1: 62.5000 (66.4323)  Acc@5: 93.7500 (92.1272)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3040/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.2269  Acc@1: 62.5000 (66.4070)  Acc@5: 93.7500 (92.1222)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3050/4579]  eta: 0:08:55  Lr: 0.001875  Loss: -0.0653  Acc@1: 56.2500 (66.3901)  Acc@5: 93.7500 (92.1214)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3060/4579]  eta: 0:08:51  Lr: 0.001875  Loss: -0.1872  Acc@1: 62.5000 (66.3958)  Acc@5: 93.7500 (92.1288)  time: 0.3455  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3070/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -0.4635  Acc@1: 68.7500 (66.3953)  Acc@5: 93.7500 (92.1219)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3080/4579]  eta: 0:08:44  Lr: 0.001875  Loss: 0.3243  Acc@1: 68.7500 (66.4050)  Acc@5: 87.5000 (92.1190)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3090/4579]  eta: 0:08:41  Lr: 0.001875  Loss: -0.3651  Acc@1: 68.7500 (66.4025)  Acc@5: 93.7500 (92.1142)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3100/4579]  eta: 0:08:37  Lr: 0.001875  Loss: -0.1288  Acc@1: 68.7500 (66.3939)  Acc@5: 93.7500 (92.1034)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3110/4579]  eta: 0:08:34  Lr: 0.001875  Loss: 0.2129  Acc@1: 62.5000 (66.3794)  Acc@5: 93.7500 (92.1066)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3120/4579]  eta: 0:08:30  Lr: 0.001875  Loss: 0.0987  Acc@1: 62.5000 (66.3790)  Acc@5: 93.7500 (92.1059)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3130/4579]  eta: 0:08:27  Lr: 0.001875  Loss: 0.0452  Acc@1: 62.5000 (66.3766)  Acc@5: 93.7500 (92.1052)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3140/4579]  eta: 0:08:23  Lr: 0.001875  Loss: -0.3564  Acc@1: 62.5000 (66.3801)  Acc@5: 93.7500 (92.1004)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3150/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.4851  Acc@1: 68.7500 (66.3797)  Acc@5: 87.5000 (92.0918)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3160/4579]  eta: 0:08:16  Lr: 0.001875  Loss: -0.4744  Acc@1: 68.7500 (66.3793)  Acc@5: 93.7500 (92.0891)  time: 0.3522  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3170/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.3022  Acc@1: 62.5000 (66.3690)  Acc@5: 93.7500 (92.0885)  time: 0.3537  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3180/4579]  eta: 0:08:09  Lr: 0.001875  Loss: -0.0765  Acc@1: 62.5000 (66.3805)  Acc@5: 93.7500 (92.0898)  time: 0.3538  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3190/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.3918  Acc@1: 62.5000 (66.3761)  Acc@5: 93.7500 (92.0871)  time: 0.3539  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3200/4579]  eta: 0:08:02  Lr: 0.001875  Loss: -0.0603  Acc@1: 62.5000 (66.3816)  Acc@5: 93.7500 (92.0982)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3210/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6794  Acc@1: 68.7500 (66.3909)  Acc@5: 93.7500 (92.1072)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3220/4579]  eta: 0:07:55  Lr: 0.001875  Loss: -0.6924  Acc@1: 68.7500 (66.4021)  Acc@5: 93.7500 (92.1026)  time: 0.3528  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [3230/4579]  eta: 0:07:52  Lr: 0.001875  Loss: 0.2333  Acc@1: 68.7500 (66.3920)  Acc@5: 93.7500 (92.1058)  time: 0.3565  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [3240/4579]  eta: 0:07:48  Lr: 0.001875  Loss: -0.0010  Acc@1: 56.2500 (66.3838)  Acc@5: 93.7500 (92.1089)  time: 0.3534  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3250/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.3047  Acc@1: 62.5000 (66.3757)  Acc@5: 93.7500 (92.1063)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3260/4579]  eta: 0:07:41  Lr: 0.001875  Loss: -0.2382  Acc@1: 62.5000 (66.3581)  Acc@5: 93.7500 (92.1036)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3270/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.4381  Acc@1: 62.5000 (66.3826)  Acc@5: 93.7500 (92.1106)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3280/4579]  eta: 0:07:34  Lr: 0.001875  Loss: -0.3771  Acc@1: 68.7500 (66.3898)  Acc@5: 93.7500 (92.1137)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3290/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.4472  Acc@1: 68.7500 (66.4027)  Acc@5: 93.7500 (92.1244)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3300/4579]  eta: 0:07:27  Lr: 0.001875  Loss: -0.6007  Acc@1: 75.0000 (66.4231)  Acc@5: 93.7500 (92.1350)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3310/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.1736  Acc@1: 75.0000 (66.4225)  Acc@5: 93.7500 (92.1285)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3320/4579]  eta: 0:07:20  Lr: 0.001875  Loss: -0.4552  Acc@1: 68.7500 (66.4164)  Acc@5: 93.7500 (92.1390)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3330/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.3970  Acc@1: 68.7500 (66.4140)  Acc@5: 93.7500 (92.1364)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/4579]  eta: 0:07:13  Lr: 0.001875  Loss: -0.6639  Acc@1: 68.7500 (66.4116)  Acc@5: 93.7500 (92.1375)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3350/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.8158  Acc@1: 68.7500 (66.4391)  Acc@5: 93.7500 (92.1404)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3360/4579]  eta: 0:07:06  Lr: 0.001875  Loss: -0.4761  Acc@1: 75.0000 (66.4311)  Acc@5: 93.7500 (92.1378)  time: 0.3539  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3370/4579]  eta: 0:07:03  Lr: 0.001875  Loss: -0.1699  Acc@1: 62.5000 (66.4139)  Acc@5: 87.5000 (92.1333)  time: 0.3545  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3380/4579]  eta: 0:06:59  Lr: 0.001875  Loss: -0.1548  Acc@1: 68.7500 (66.4190)  Acc@5: 87.5000 (92.1325)  time: 0.3582  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [3390/4579]  eta: 0:06:56  Lr: 0.001875  Loss: -0.6536  Acc@1: 68.7500 (66.4111)  Acc@5: 93.7500 (92.1354)  time: 0.3577  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [3400/4579]  eta: 0:06:52  Lr: 0.001875  Loss: -0.2620  Acc@1: 68.7500 (66.4180)  Acc@5: 93.7500 (92.1383)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3410/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.0456  Acc@1: 68.7500 (66.4266)  Acc@5: 93.7500 (92.1486)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3420/4579]  eta: 0:06:45  Lr: 0.001875  Loss: 0.2195  Acc@1: 62.5000 (66.4097)  Acc@5: 93.7500 (92.1459)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3430/4579]  eta: 0:06:42  Lr: 0.001875  Loss: 0.0873  Acc@1: 68.7500 (66.4129)  Acc@5: 93.7500 (92.1506)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3440/4579]  eta: 0:06:38  Lr: 0.001875  Loss: -0.4618  Acc@1: 68.7500 (66.4087)  Acc@5: 87.5000 (92.1407)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3450/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.1607  Acc@1: 62.5000 (66.4137)  Acc@5: 93.7500 (92.1454)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3460/4579]  eta: 0:06:31  Lr: 0.001875  Loss: -0.6430  Acc@1: 62.5000 (66.4151)  Acc@5: 93.7500 (92.1464)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3470/4579]  eta: 0:06:28  Lr: 0.001875  Loss: 0.1741  Acc@1: 68.7500 (66.4128)  Acc@5: 93.7500 (92.1510)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3480/4579]  eta: 0:06:24  Lr: 0.001875  Loss: -0.3248  Acc@1: 68.7500 (66.4177)  Acc@5: 93.7500 (92.1574)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3490/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.2859  Acc@1: 68.7500 (66.4405)  Acc@5: 93.7500 (92.1620)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3500/4579]  eta: 0:06:17  Lr: 0.001875  Loss: 0.3281  Acc@1: 68.7500 (66.4346)  Acc@5: 93.7500 (92.1612)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3510/4579]  eta: 0:06:14  Lr: 0.001875  Loss: 0.4757  Acc@1: 62.5000 (66.4323)  Acc@5: 87.5000 (92.1426)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3520/4579]  eta: 0:06:10  Lr: 0.001875  Loss: 0.0762  Acc@1: 68.7500 (66.4264)  Acc@5: 87.5000 (92.1223)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3530/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.4441  Acc@1: 68.7500 (66.4330)  Acc@5: 87.5000 (92.1233)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3540/4579]  eta: 0:06:03  Lr: 0.001875  Loss: -0.5990  Acc@1: 68.7500 (66.4325)  Acc@5: 93.7500 (92.1138)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3550/4579]  eta: 0:06:00  Lr: 0.001875  Loss: 0.1595  Acc@1: 62.5000 (66.4126)  Acc@5: 87.5000 (92.1026)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3560/4579]  eta: 0:05:56  Lr: 0.001875  Loss: -0.1232  Acc@1: 62.5000 (66.3964)  Acc@5: 87.5000 (92.1002)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3570/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.3122  Acc@1: 62.5000 (66.4030)  Acc@5: 93.7500 (92.0961)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3580/4579]  eta: 0:05:49  Lr: 0.001875  Loss: -0.4019  Acc@1: 62.5000 (66.3991)  Acc@5: 93.7500 (92.1024)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3590/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.1634  Acc@1: 62.5000 (66.3986)  Acc@5: 93.7500 (92.0983)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3600/4579]  eta: 0:05:42  Lr: 0.001875  Loss: -0.1495  Acc@1: 68.7500 (66.4086)  Acc@5: 93.7500 (92.1029)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3610/4579]  eta: 0:05:39  Lr: 0.001875  Loss: -0.3030  Acc@1: 68.7500 (66.4030)  Acc@5: 93.7500 (92.0988)  time: 0.3519  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3620/4579]  eta: 0:05:35  Lr: 0.001875  Loss: -0.5831  Acc@1: 62.5000 (66.4095)  Acc@5: 93.7500 (92.0982)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3630/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.0623  Acc@1: 62.5000 (66.4159)  Acc@5: 93.7500 (92.0976)  time: 0.3511  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3640/4579]  eta: 0:05:28  Lr: 0.001875  Loss: -0.7907  Acc@1: 62.5000 (66.4052)  Acc@5: 93.7500 (92.1021)  time: 0.3509  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3650/4579]  eta: 0:05:25  Lr: 0.001875  Loss: -0.0996  Acc@1: 56.2500 (66.3911)  Acc@5: 93.7500 (92.1015)  time: 0.3530  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3660/4579]  eta: 0:05:21  Lr: 0.001875  Loss: -0.0788  Acc@1: 62.5000 (66.3924)  Acc@5: 93.7500 (92.1043)  time: 0.3532  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.4382  Acc@1: 68.7500 (66.4005)  Acc@5: 93.7500 (92.1071)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3680/4579]  eta: 0:05:14  Lr: 0.001875  Loss: -0.3876  Acc@1: 68.7500 (66.4086)  Acc@5: 93.7500 (92.1132)  time: 0.3531  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.0703  Acc@1: 68.7500 (66.4098)  Acc@5: 93.7500 (92.1126)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3700/4579]  eta: 0:05:07  Lr: 0.001875  Loss: -0.0011  Acc@1: 68.7500 (66.4212)  Acc@5: 93.7500 (92.1136)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: -0.5162  Acc@1: 68.7500 (66.4174)  Acc@5: 93.7500 (92.1113)  time: 0.3518  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [3720/4579]  eta: 0:05:00  Lr: 0.001875  Loss: -0.0353  Acc@1: 68.7500 (66.4220)  Acc@5: 93.7500 (92.1140)  time: 0.3513  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.1956  Acc@1: 68.7500 (66.4282)  Acc@5: 93.7500 (92.1134)  time: 0.3526  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3740/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 0.0701  Acc@1: 68.7500 (66.4395)  Acc@5: 93.7500 (92.1127)  time: 0.3542  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.2882  Acc@1: 68.7500 (66.4489)  Acc@5: 93.7500 (92.1071)  time: 0.3516  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3760/4579]  eta: 0:04:46  Lr: 0.001875  Loss: -0.0811  Acc@1: 68.7500 (66.4434)  Acc@5: 93.7500 (92.1048)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.5511  Acc@1: 62.5000 (66.4446)  Acc@5: 93.7500 (92.1059)  time: 0.3537  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3780/4579]  eta: 0:04:39  Lr: 0.001875  Loss: -0.5471  Acc@1: 68.7500 (66.4490)  Acc@5: 93.7500 (92.1003)  time: 0.3517  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.4126  Acc@1: 68.7500 (66.4518)  Acc@5: 93.7500 (92.1014)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3800/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.6919  Acc@1: 68.7500 (66.4710)  Acc@5: 93.7500 (92.1057)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.1448  Acc@1: 68.7500 (66.4721)  Acc@5: 93.7500 (92.1084)  time: 0.3484  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3820/4579]  eta: 0:04:25  Lr: 0.001875  Loss: -0.0654  Acc@1: 68.7500 (66.4731)  Acc@5: 93.7500 (92.1029)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 0.1416  Acc@1: 68.7500 (66.4725)  Acc@5: 93.7500 (92.1039)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3840/4579]  eta: 0:04:18  Lr: 0.001875  Loss: -0.1962  Acc@1: 62.5000 (66.4752)  Acc@5: 93.7500 (92.1017)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: -0.2970  Acc@1: 62.5000 (66.4697)  Acc@5: 93.7500 (92.1076)  time: 0.3480  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [3860/4579]  eta: 0:04:11  Lr: 0.001875  Loss: -0.2899  Acc@1: 62.5000 (66.4757)  Acc@5: 93.7500 (92.1053)  time: 0.3479  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.4517  Acc@1: 75.0000 (66.4928)  Acc@5: 93.7500 (92.1144)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3880/4579]  eta: 0:04:04  Lr: 0.001875  Loss: -0.6343  Acc@1: 68.7500 (66.4986)  Acc@5: 93.7500 (92.1170)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.7103  Acc@1: 68.7500 (66.5076)  Acc@5: 93.7500 (92.1228)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3900/4579]  eta: 0:03:57  Lr: 0.001875  Loss: -0.4811  Acc@1: 68.7500 (66.5214)  Acc@5: 93.7500 (92.1318)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.0810  Acc@1: 68.7500 (66.5159)  Acc@5: 93.7500 (92.1296)  time: 0.3532  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3920/4579]  eta: 0:03:50  Lr: 0.001875  Loss: -0.1847  Acc@1: 62.5000 (66.5200)  Acc@5: 93.7500 (92.1305)  time: 0.3533  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: -0.1126  Acc@1: 68.7500 (66.5289)  Acc@5: 93.7500 (92.1362)  time: 0.3572  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3940/4579]  eta: 0:03:43  Lr: 0.001875  Loss: -0.1085  Acc@1: 68.7500 (66.5218)  Acc@5: 93.7500 (92.1356)  time: 0.3575  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.6764  Acc@1: 68.7500 (66.5259)  Acc@5: 93.7500 (92.1302)  time: 0.3514  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3960/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.2950  Acc@1: 68.7500 (66.5236)  Acc@5: 93.7500 (92.1216)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -0.7782  Acc@1: 62.5000 (66.5213)  Acc@5: 93.7500 (92.1242)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3980/4579]  eta: 0:03:29  Lr: 0.001875  Loss: 0.2106  Acc@1: 75.0000 (66.5364)  Acc@5: 93.7500 (92.1220)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: 0.2322  Acc@1: 68.7500 (66.5278)  Acc@5: 93.7500 (92.1229)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4000/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4473  Acc@1: 62.5000 (66.5209)  Acc@5: 87.5000 (92.1098)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.3035  Acc@1: 68.7500 (66.5373)  Acc@5: 87.5000 (92.1154)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4020/4579]  eta: 0:03:15  Lr: 0.001875  Loss: -0.1682  Acc@1: 68.7500 (66.5459)  Acc@5: 93.7500 (92.1133)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: 0.1017  Acc@1: 62.5000 (66.5328)  Acc@5: 93.7500 (92.1158)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4040/4579]  eta: 0:03:08  Lr: 0.001875  Loss: -0.4831  Acc@1: 62.5000 (66.5259)  Acc@5: 93.7500 (92.1136)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.7636  Acc@1: 68.7500 (66.5407)  Acc@5: 93.7500 (92.1192)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4060/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.2690  Acc@1: 68.7500 (66.5446)  Acc@5: 93.7500 (92.1202)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: -0.5110  Acc@1: 68.7500 (66.5438)  Acc@5: 93.7500 (92.1272)  time: 0.3470  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4080/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.4528  Acc@1: 68.7500 (66.5615)  Acc@5: 93.7500 (92.1358)  time: 0.3476  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.2357  Acc@1: 68.7500 (66.5500)  Acc@5: 93.7500 (92.1214)  time: 0.3472  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: 0.1638  Acc@1: 62.5000 (66.5432)  Acc@5: 87.5000 (92.1178)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.0290  Acc@1: 62.5000 (66.5486)  Acc@5: 93.7500 (92.1157)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.3596  Acc@1: 68.7500 (66.5509)  Acc@5: 93.7500 (92.1136)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.2508  Acc@1: 68.7500 (66.5592)  Acc@5: 93.7500 (92.1190)  time: 0.3474  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.5856  Acc@1: 68.7500 (66.5766)  Acc@5: 93.7500 (92.1215)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.2338  Acc@1: 68.7500 (66.5834)  Acc@5: 93.7500 (92.1254)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.3815  Acc@1: 68.7500 (66.5886)  Acc@5: 93.7500 (92.1248)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: 0.0973  Acc@1: 68.7500 (66.5788)  Acc@5: 93.7500 (92.1212)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: 0.6135  Acc@1: 62.5000 (66.5541)  Acc@5: 87.5000 (92.1116)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: 0.1263  Acc@1: 62.5000 (66.5593)  Acc@5: 87.5000 (92.1081)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.7341  Acc@1: 68.7500 (66.5645)  Acc@5: 93.7500 (92.1179)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: -0.2990  Acc@1: 68.7500 (66.5563)  Acc@5: 93.7500 (92.1114)  time: 0.3546  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: 0.0167  Acc@1: 68.7500 (66.5615)  Acc@5: 87.5000 (92.1064)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.2575  Acc@1: 75.0000 (66.5889)  Acc@5: 93.7500 (92.1133)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: -0.1341  Acc@1: 68.7500 (66.5836)  Acc@5: 93.7500 (92.1142)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4473  Acc@1: 68.7500 (66.5829)  Acc@5: 93.7500 (92.1210)  time: 0.3498  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8828  Acc@1: 68.7500 (66.5997)  Acc@5: 93.7500 (92.1277)  time: 0.3492  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: -0.8061  Acc@1: 68.7500 (66.6120)  Acc@5: 93.7500 (92.1271)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: 0.4773  Acc@1: 68.7500 (66.6156)  Acc@5: 93.7500 (92.1251)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.3250  Acc@1: 68.7500 (66.6162)  Acc@5: 93.7500 (92.1260)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.5723  Acc@1: 68.7500 (66.6139)  Acc@5: 93.7500 (92.1239)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0907  Acc@1: 62.5000 (66.5942)  Acc@5: 87.5000 (92.1088)  time: 0.3512  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3119  Acc@1: 62.5000 (66.5861)  Acc@5: 87.5000 (92.1112)  time: 0.3515  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.5666  Acc@1: 68.7500 (66.6085)  Acc@5: 93.7500 (92.1092)  time: 0.3516  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.1193  Acc@1: 68.7500 (66.6019)  Acc@5: 93.7500 (92.1044)  time: 0.3522  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8618  Acc@1: 68.7500 (66.6197)  Acc@5: 93.7500 (92.1067)  time: 0.3517  data: 0.0023  max mem: 2500
Train: Epoch[5/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.6831  Acc@1: 68.7500 (66.6232)  Acc@5: 93.7500 (92.1033)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.2684  Acc@1: 68.7500 (66.6338)  Acc@5: 93.7500 (92.1114)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.4225  Acc@1: 75.0000 (66.6514)  Acc@5: 100.0000 (92.1165)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.1129  Acc@1: 68.7500 (66.6434)  Acc@5: 93.7500 (92.1202)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.1420  Acc@1: 62.5000 (66.6397)  Acc@5: 93.7500 (92.1168)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.3320  Acc@1: 62.5000 (66.6246)  Acc@5: 87.5000 (92.1106)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: 0.1368  Acc@1: 62.5000 (66.6266)  Acc@5: 93.7500 (92.1186)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0387  Acc@1: 68.7500 (66.6399)  Acc@5: 93.7500 (92.1251)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2062  Acc@1: 68.7500 (66.6460)  Acc@5: 93.7500 (92.1273)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.2130  Acc@1: 68.7500 (66.6564)  Acc@5: 93.7500 (92.1268)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.4041  Acc@1: 68.7500 (66.6653)  Acc@5: 93.7500 (92.1304)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.3589  Acc@1: 75.0000 (66.6783)  Acc@5: 93.7500 (92.1256)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4442  Acc@1: 75.0000 (66.6969)  Acc@5: 93.7500 (92.1335)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.4180  Acc@1: 68.7500 (66.6889)  Acc@5: 93.7500 (92.1315)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5575  Acc@1: 68.7500 (66.6921)  Acc@5: 93.7500 (92.1281)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5274  Acc@1: 68.7500 (66.6856)  Acc@5: 93.7500 (92.1303)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0715  Acc@1: 68.7500 (66.6971)  Acc@5: 93.7500 (92.1270)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8016  Acc@1: 62.5000 (66.6906)  Acc@5: 87.5000 (92.1168)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.3546  Acc@1: 62.5000 (66.6731)  Acc@5: 87.5000 (92.1066)  time: 0.3550  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 0.8108  Acc@1: 62.5000 (66.6667)  Acc@5: 87.5000 (92.1034)  time: 0.3544  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.6883  Acc@1: 62.5000 (66.6740)  Acc@5: 87.5000 (92.0988)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.3822  Acc@1: 68.7500 (66.6799)  Acc@5: 87.5000 (92.0942)  time: 0.3480  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4836  Acc@1: 68.7500 (66.6803)  Acc@5: 93.7500 (92.0909)  time: 0.3398  data: 0.0011  max mem: 2500
Train: Epoch[5/5] Total time: 0:26:43 (0.3502 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4836  Acc@1: 68.7500 (66.6803)  Acc@5: 93.7500 (92.0909)
Test: [Task 1]  [   0/1627]  eta: 0:15:54  Loss: 1.0121 (1.0121)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5865  data: 0.3705  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:41  Loss: 0.8778 (0.8292)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.1591)  time: 0.2480  data: 0.0340  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:12  Loss: 0.8666 (0.8145)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.6190)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:00  Loss: 0.8560 (0.8238)  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (97.9839)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:54  Loss: 0.8891 (0.8389)  Acc@1: 81.2500 (85.2134)  Acc@5: 100.0000 (97.5610)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:48  Loss: 0.8332 (0.8111)  Acc@1: 81.2500 (85.7843)  Acc@5: 100.0000 (97.7941)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:44  Loss: 0.7903 (0.8249)  Acc@1: 87.5000 (85.4508)  Acc@5: 100.0000 (97.6434)  time: 0.2131  data: 0.0003  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:40  Loss: 0.7903 (0.8201)  Acc@1: 87.5000 (85.6514)  Acc@5: 100.0000 (97.7993)  time: 0.2134  data: 0.0003  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:37  Loss: 0.6439 (0.8027)  Acc@1: 87.5000 (86.1883)  Acc@5: 100.0000 (97.9938)  time: 0.2134  data: 0.0003  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:34  Loss: 0.8054 (0.8172)  Acc@1: 87.5000 (85.6456)  Acc@5: 100.0000 (97.8709)  time: 0.2134  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:31  Loss: 0.8667 (0.8382)  Acc@1: 81.2500 (85.1485)  Acc@5: 100.0000 (97.7723)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:29  Loss: 0.7562 (0.8273)  Acc@1: 87.5000 (85.3604)  Acc@5: 100.0000 (97.9167)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:26  Loss: 0.7046 (0.8263)  Acc@1: 87.5000 (85.4855)  Acc@5: 100.0000 (97.8306)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:24  Loss: 0.8443 (0.8298)  Acc@1: 87.5000 (85.4485)  Acc@5: 100.0000 (97.8053)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:21  Loss: 0.8037 (0.8247)  Acc@1: 81.2500 (85.5496)  Acc@5: 100.0000 (97.7837)  time: 0.2150  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:19  Loss: 0.5927 (0.8109)  Acc@1: 93.7500 (85.8858)  Acc@5: 100.0000 (97.8477)  time: 0.2153  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:17  Loss: 0.6011 (0.8062)  Acc@1: 87.5000 (86.0637)  Acc@5: 100.0000 (97.8261)  time: 0.2158  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:15  Loss: 0.6814 (0.7988)  Acc@1: 87.5000 (86.2573)  Acc@5: 100.0000 (97.9167)  time: 0.2160  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:12  Loss: 0.7947 (0.8098)  Acc@1: 87.5000 (86.1533)  Acc@5: 100.0000 (97.8936)  time: 0.2148  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:10  Loss: 0.8259 (0.8087)  Acc@1: 87.5000 (86.0929)  Acc@5: 100.0000 (97.8730)  time: 0.2147  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:08  Loss: 0.7586 (0.8092)  Acc@1: 87.5000 (86.1940)  Acc@5: 100.0000 (97.8545)  time: 0.2146  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:06  Loss: 0.7586 (0.8090)  Acc@1: 87.5000 (86.3152)  Acc@5: 100.0000 (97.8081)  time: 0.2155  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:03  Loss: 0.6831 (0.8120)  Acc@1: 81.2500 (86.1991)  Acc@5: 100.0000 (97.7658)  time: 0.2161  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:01  Loss: 0.7381 (0.8053)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.8084)  time: 0.2150  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:04:59  Loss: 0.7381 (0.8012)  Acc@1: 87.5000 (86.4886)  Acc@5: 100.0000 (97.8734)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:04:57  Loss: 0.7344 (0.8069)  Acc@1: 87.5000 (86.5040)  Acc@5: 100.0000 (97.8088)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:55  Loss: 0.7964 (0.8066)  Acc@1: 87.5000 (86.5421)  Acc@5: 100.0000 (97.7730)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:53  Loss: 0.6149 (0.8015)  Acc@1: 87.5000 (86.6006)  Acc@5: 100.0000 (97.8321)  time: 0.2175  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:51  Loss: 0.6923 (0.8035)  Acc@1: 87.5000 (86.4991)  Acc@5: 100.0000 (97.7980)  time: 0.2200  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:49  Loss: 0.7609 (0.8029)  Acc@1: 87.5000 (86.5765)  Acc@5: 100.0000 (97.7878)  time: 0.2184  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:46  Loss: 0.6710 (0.8003)  Acc@1: 87.5000 (86.5864)  Acc@5: 100.0000 (97.8198)  time: 0.2165  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:45  Loss: 0.6910 (0.8011)  Acc@1: 87.5000 (86.7162)  Acc@5: 100.0000 (97.8497)  time: 0.2199  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:42  Loss: 0.7629 (0.7994)  Acc@1: 93.7500 (86.8575)  Acc@5: 100.0000 (97.8388)  time: 0.2194  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:40  Loss: 0.7239 (0.7981)  Acc@1: 93.7500 (86.8769)  Acc@5: 100.0000 (97.8474)  time: 0.2154  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:38  Loss: 0.6643 (0.7977)  Acc@1: 87.5000 (87.0235)  Acc@5: 100.0000 (97.8556)  time: 0.2168  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:36  Loss: 0.6810 (0.7975)  Acc@1: 87.5000 (86.9836)  Acc@5: 100.0000 (97.8632)  time: 0.2175  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:34  Loss: 0.7047 (0.7961)  Acc@1: 87.5000 (86.8940)  Acc@5: 100.0000 (97.8878)  time: 0.2163  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 0.7047 (0.7958)  Acc@1: 87.5000 (86.9609)  Acc@5: 100.0000 (97.8774)  time: 0.2159  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:29  Loss: 0.7324 (0.7947)  Acc@1: 87.5000 (86.9915)  Acc@5: 100.0000 (97.8675)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:27  Loss: 0.7833 (0.7965)  Acc@1: 87.5000 (86.9725)  Acc@5: 100.0000 (97.8740)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:25  Loss: 0.8050 (0.7975)  Acc@1: 87.5000 (87.0324)  Acc@5: 100.0000 (97.8959)  time: 0.2167  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:23  Loss: 0.7443 (0.7987)  Acc@1: 87.5000 (87.0438)  Acc@5: 100.0000 (97.8558)  time: 0.2171  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:21  Loss: 0.6135 (0.7972)  Acc@1: 93.7500 (87.0992)  Acc@5: 100.0000 (97.8622)  time: 0.2166  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:19  Loss: 0.6027 (0.7955)  Acc@1: 93.7500 (87.0650)  Acc@5: 100.0000 (97.8828)  time: 0.2193  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:16  Loss: 0.7254 (0.7950)  Acc@1: 87.5000 (87.0323)  Acc@5: 100.0000 (97.9025)  time: 0.2185  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:14  Loss: 0.8129 (0.7975)  Acc@1: 87.5000 (86.9180)  Acc@5: 100.0000 (97.8381)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 0.8126 (0.7968)  Acc@1: 87.5000 (86.9441)  Acc@5: 100.0000 (97.8715)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:10  Loss: 0.6191 (0.7937)  Acc@1: 93.7500 (87.0090)  Acc@5: 100.0000 (97.8901)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:08  Loss: 0.6921 (0.7973)  Acc@1: 87.5000 (86.9153)  Acc@5: 100.0000 (97.8560)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 0.7766 (0.7976)  Acc@1: 81.2500 (86.8635)  Acc@5: 100.0000 (97.8615)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 0.7280 (0.7995)  Acc@1: 87.5000 (86.8263)  Acc@5: 100.0000 (97.8293)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:01  Loss: 0.8510 (0.8041)  Acc@1: 87.5000 (86.8151)  Acc@5: 100.0000 (97.8107)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 0.8692 (0.8119)  Acc@1: 81.2500 (86.7202)  Acc@5: 100.0000 (97.7447)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:57  Loss: 0.8145 (0.8086)  Acc@1: 87.5000 (86.7938)  Acc@5: 100.0000 (97.7637)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 0.7160 (0.8083)  Acc@1: 87.5000 (86.8068)  Acc@5: 100.0000 (97.7472)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 0.8845 (0.8103)  Acc@1: 87.5000 (86.7854)  Acc@5: 93.7500 (97.7087)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 0.9266 (0.8128)  Acc@1: 87.5000 (86.7424)  Acc@5: 93.7500 (97.6939)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:48  Loss: 0.7592 (0.8107)  Acc@1: 87.5000 (86.7776)  Acc@5: 100.0000 (97.6795)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:46  Loss: 0.7592 (0.8110)  Acc@1: 87.5000 (86.7577)  Acc@5: 100.0000 (97.7087)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:43  Loss: 0.7498 (0.8094)  Acc@1: 87.5000 (86.7915)  Acc@5: 100.0000 (97.7263)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 0.6773 (0.8108)  Acc@1: 87.5000 (86.7512)  Acc@5: 100.0000 (97.7433)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 0.8782 (0.8102)  Acc@1: 87.5000 (86.7942)  Acc@5: 100.0000 (97.7291)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 0.8782 (0.8117)  Acc@1: 87.5000 (86.7653)  Acc@5: 100.0000 (97.7053)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 0.6840 (0.8118)  Acc@1: 87.5000 (86.7571)  Acc@5: 100.0000 (97.7021)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 0.6458 (0.8122)  Acc@1: 81.2500 (86.7102)  Acc@5: 100.0000 (97.6892)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:30  Loss: 0.7387 (0.8117)  Acc@1: 81.2500 (86.6935)  Acc@5: 100.0000 (97.7151)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 0.7375 (0.8108)  Acc@1: 87.5000 (86.6774)  Acc@5: 100.0000 (97.7402)  time: 0.2172  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 0.7375 (0.8108)  Acc@1: 87.5000 (86.6710)  Acc@5: 100.0000 (97.7180)  time: 0.2174  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 0.7870 (0.8103)  Acc@1: 87.5000 (86.6832)  Acc@5: 100.0000 (97.7148)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 0.7516 (0.8086)  Acc@1: 87.5000 (86.7493)  Acc@5: 100.0000 (97.7207)  time: 0.2170  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 0.6734 (0.8087)  Acc@1: 87.5000 (86.7511)  Acc@5: 100.0000 (97.7086)  time: 0.2162  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 0.6734 (0.8066)  Acc@1: 87.5000 (86.8319)  Acc@5: 100.0000 (97.7233)  time: 0.2165  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 0.6832 (0.8049)  Acc@1: 93.7500 (86.8499)  Acc@5: 100.0000 (97.7202)  time: 0.2172  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 0.7542 (0.8056)  Acc@1: 87.5000 (86.8075)  Acc@5: 100.0000 (97.7086)  time: 0.2181  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 0.8310 (0.8076)  Acc@1: 81.2500 (86.7831)  Acc@5: 100.0000 (97.6889)  time: 0.2197  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 0.8339 (0.8065)  Acc@1: 87.5000 (86.7926)  Acc@5: 100.0000 (97.7114)  time: 0.2194  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 0.8713 (0.8096)  Acc@1: 81.2500 (86.7362)  Acc@5: 100.0000 (97.6511)  time: 0.2179  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 0.6913 (0.8063)  Acc@1: 87.5000 (86.7947)  Acc@5: 93.7500 (97.6573)  time: 0.2212  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:03  Loss: 0.5435 (0.8044)  Acc@1: 93.7500 (86.8918)  Acc@5: 100.0000 (97.6633)  time: 0.2212  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 0.6088 (0.8062)  Acc@1: 87.5000 (86.8837)  Acc@5: 100.0000 (97.6454)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 0.7766 (0.8045)  Acc@1: 87.5000 (86.9382)  Acc@5: 100.0000 (97.6748)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 0.6779 (0.8040)  Acc@1: 87.5000 (86.9528)  Acc@5: 100.0000 (97.6726)  time: 0.2174  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 0.6491 (0.8029)  Acc@1: 87.5000 (86.9976)  Acc@5: 100.0000 (97.6629)  time: 0.2178  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 0.5892 (0.8025)  Acc@1: 93.7500 (86.9961)  Acc@5: 100.0000 (97.6685)  time: 0.2168  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:50  Loss: 0.5325 (0.8004)  Acc@1: 93.7500 (87.0392)  Acc@5: 100.0000 (97.6888)  time: 0.2166  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:48  Loss: 0.6680 (0.8009)  Acc@1: 87.5000 (87.0373)  Acc@5: 100.0000 (97.6939)  time: 0.2164  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 0.6867 (0.8001)  Acc@1: 87.5000 (87.0572)  Acc@5: 100.0000 (97.6989)  time: 0.2168  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 0.6288 (0.7986)  Acc@1: 87.5000 (87.0838)  Acc@5: 100.0000 (97.6966)  time: 0.2172  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 0.7021 (0.7996)  Acc@1: 87.5000 (87.0673)  Acc@5: 100.0000 (97.7086)  time: 0.2198  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 0.8066 (0.8016)  Acc@1: 87.5000 (87.0511)  Acc@5: 100.0000 (97.6992)  time: 0.2191  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:37  Loss: 0.8066 (0.8014)  Acc@1: 87.5000 (87.0422)  Acc@5: 100.0000 (97.6831)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:35  Loss: 0.7838 (0.8027)  Acc@1: 87.5000 (86.9855)  Acc@5: 100.0000 (97.6468)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 0.7606 (0.8020)  Acc@1: 87.5000 (87.0114)  Acc@5: 100.0000 (97.6384)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 0.7663 (0.8018)  Acc@1: 87.5000 (86.9831)  Acc@5: 100.0000 (97.6504)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 0.7558 (0.8005)  Acc@1: 87.5000 (87.0151)  Acc@5: 100.0000 (97.6554)  time: 0.2150  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 0.7670 (0.8006)  Acc@1: 87.5000 (87.0334)  Acc@5: 100.0000 (97.6735)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 0.7670 (0.7999)  Acc@1: 87.5000 (87.0057)  Acc@5: 100.0000 (97.6847)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:22  Loss: 0.6016 (0.7987)  Acc@1: 87.5000 (87.0173)  Acc@5: 100.0000 (97.6957)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 0.7065 (0.7989)  Acc@1: 87.5000 (87.0222)  Acc@5: 100.0000 (97.6809)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 0.8901 (0.8014)  Acc@1: 87.5000 (86.9955)  Acc@5: 93.7500 (97.6539)  time: 0.2167  data: 0.0004  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 0.9680 (0.8019)  Acc@1: 87.5000 (86.9880)  Acc@5: 93.7500 (97.6461)  time: 0.2196  data: 0.0011  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 0.8779 (0.8020)  Acc@1: 87.5000 (86.9931)  Acc@5: 100.0000 (97.6447)  time: 0.2186  data: 0.0014  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 0.7825 (0.8025)  Acc@1: 87.5000 (86.9613)  Acc@5: 100.0000 (97.6432)  time: 0.2190  data: 0.0013  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.6874 (0.8006)  Acc@1: 87.5000 (87.0029)  Acc@5: 100.0000 (97.6540)  time: 0.2210  data: 0.0013  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:07  Loss: 0.5684 (0.8000)  Acc@1: 87.5000 (86.9957)  Acc@5: 100.0000 (97.6705)  time: 0.2181  data: 0.0008  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.6511 (0.7982)  Acc@1: 87.5000 (87.0243)  Acc@5: 100.0000 (97.6808)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 0.7307 (0.7985)  Acc@1: 87.5000 (87.0111)  Acc@5: 100.0000 (97.6732)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 0.7467 (0.7987)  Acc@1: 87.5000 (86.9981)  Acc@5: 100.0000 (97.6774)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 0.7467 (0.7998)  Acc@1: 87.5000 (86.9796)  Acc@5: 100.0000 (97.6700)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 0.7478 (0.7996)  Acc@1: 81.2500 (86.9730)  Acc@5: 100.0000 (97.6799)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 0.7336 (0.7986)  Acc@1: 87.5000 (86.9948)  Acc@5: 100.0000 (97.6896)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 0.7138 (0.7990)  Acc@1: 87.5000 (86.9824)  Acc@5: 100.0000 (97.6879)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 0.7138 (0.7998)  Acc@1: 87.5000 (86.9982)  Acc@5: 100.0000 (97.6862)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 0.7785 (0.7996)  Acc@1: 87.5000 (87.0082)  Acc@5: 100.0000 (97.6790)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 0.9568 (0.8012)  Acc@1: 81.2500 (86.9687)  Acc@5: 100.0000 (97.6775)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 1.0373 (0.8027)  Acc@1: 81.2500 (86.9353)  Acc@5: 100.0000 (97.6705)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 0.8463 (0.8016)  Acc@1: 87.5000 (86.9724)  Acc@5: 100.0000 (97.6744)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 0.7357 (0.8006)  Acc@1: 93.7500 (86.9930)  Acc@5: 100.0000 (97.6836)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 0.7524 (0.8008)  Acc@1: 87.5000 (86.9972)  Acc@5: 100.0000 (97.6926)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 0.8114 (0.8011)  Acc@1: 81.2500 (86.9752)  Acc@5: 100.0000 (97.7068)  time: 0.2146  data: 0.0002  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 0.8464 (0.8018)  Acc@1: 81.2500 (86.9588)  Acc@5: 100.0000 (97.6894)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.7759 (0.8021)  Acc@1: 87.5000 (86.9478)  Acc@5: 100.0000 (97.6827)  time: 0.2143  data: 0.0002  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 0.6478 (0.8010)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.7017)  time: 0.2143  data: 0.0002  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 0.7021 (0.8017)  Acc@1: 81.2500 (86.8958)  Acc@5: 100.0000 (97.7153)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 0.7426 (0.8016)  Acc@1: 81.2500 (86.8856)  Acc@5: 100.0000 (97.7135)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 0.8619 (0.8017)  Acc@1: 87.5000 (86.8955)  Acc@5: 100.0000 (97.7168)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 0.8572 (0.8016)  Acc@1: 87.5000 (86.9102)  Acc@5: 100.0000 (97.7102)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 0.7428 (0.8017)  Acc@1: 87.5000 (86.9148)  Acc@5: 100.0000 (97.6937)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 0.6451 (0.8000)  Acc@1: 87.5000 (86.9340)  Acc@5: 100.0000 (97.7069)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 0.6451 (0.8004)  Acc@1: 81.2500 (86.9094)  Acc@5: 100.0000 (97.7004)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 0.8911 (0.8000)  Acc@1: 87.5000 (86.9331)  Acc@5: 100.0000 (97.6989)  time: 0.2155  data: 0.0010  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.6036 (0.7985)  Acc@1: 87.5000 (86.9565)  Acc@5: 100.0000 (97.6974)  time: 0.2166  data: 0.0012  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.4973 (0.7973)  Acc@1: 87.5000 (86.9890)  Acc@5: 100.0000 (97.6911)  time: 0.2169  data: 0.0009  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.5424 (0.7972)  Acc@1: 87.5000 (86.9882)  Acc@5: 100.0000 (97.6850)  time: 0.2173  data: 0.0013  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 0.8084 (0.7975)  Acc@1: 87.5000 (86.9733)  Acc@5: 100.0000 (97.6930)  time: 0.2168  data: 0.0011  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 0.7365 (0.7970)  Acc@1: 87.5000 (86.9911)  Acc@5: 100.0000 (97.6962)  time: 0.2203  data: 0.0006  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.6839 (0.7968)  Acc@1: 93.7500 (86.9994)  Acc@5: 100.0000 (97.7039)  time: 0.2198  data: 0.0006  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.6839 (0.7960)  Acc@1: 87.5000 (87.0031)  Acc@5: 100.0000 (97.7161)  time: 0.2176  data: 0.0008  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 0.7558 (0.7962)  Acc@1: 87.5000 (86.9750)  Acc@5: 100.0000 (97.7100)  time: 0.2174  data: 0.0006  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 0.8210 (0.7957)  Acc@1: 81.2500 (86.9833)  Acc@5: 100.0000 (97.7175)  time: 0.2170  data: 0.0007  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 0.7136 (0.7959)  Acc@1: 87.5000 (86.9557)  Acc@5: 100.0000 (97.7115)  time: 0.2180  data: 0.0015  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 0.6888 (0.7956)  Acc@1: 81.2500 (86.9640)  Acc@5: 100.0000 (97.7188)  time: 0.2170  data: 0.0014  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.6888 (0.7951)  Acc@1: 87.5000 (86.9678)  Acc@5: 100.0000 (97.7261)  time: 0.2161  data: 0.0007  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 0.8459 (0.7971)  Acc@1: 87.5000 (86.9278)  Acc@5: 100.0000 (97.7027)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 0.9536 (0.7970)  Acc@1: 81.2500 (86.9231)  Acc@5: 100.0000 (97.7099)  time: 0.2167  data: 0.0007  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 0.8674 (0.7978)  Acc@1: 87.5000 (86.9228)  Acc@5: 100.0000 (97.7085)  time: 0.2165  data: 0.0007  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 0.8674 (0.7980)  Acc@1: 87.5000 (86.9139)  Acc@5: 100.0000 (97.7113)  time: 0.2164  data: 0.0009  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 0.7291 (0.7979)  Acc@1: 87.5000 (86.9349)  Acc@5: 100.0000 (97.7141)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 0.7291 (0.7978)  Acc@1: 87.5000 (86.9472)  Acc@5: 100.0000 (97.7085)  time: 0.2167  data: 0.0006  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 0.7828 (0.7984)  Acc@1: 87.5000 (86.9425)  Acc@5: 100.0000 (97.7071)  time: 0.2169  data: 0.0006  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.7828 (0.7986)  Acc@1: 87.5000 (86.9462)  Acc@5: 100.0000 (97.7015)  time: 0.2175  data: 0.0010  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.6526 (0.7987)  Acc@1: 87.5000 (86.9540)  Acc@5: 100.0000 (97.7043)  time: 0.2177  data: 0.0010  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.6055 (0.7976)  Acc@1: 87.5000 (86.9699)  Acc@5: 100.0000 (97.7112)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.6742 (0.7973)  Acc@1: 87.5000 (86.9815)  Acc@5: 100.0000 (97.7139)  time: 0.2171  data: 0.0010  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.6794 (0.7963)  Acc@1: 87.5000 (87.0011)  Acc@5: 100.0000 (97.7206)  time: 0.2190  data: 0.0013  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.6137 (0.7959)  Acc@1: 87.5000 (87.0003)  Acc@5: 100.0000 (97.7313)  time: 0.2220  data: 0.0014  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.5961 (0.7950)  Acc@1: 87.5000 (87.0275)  Acc@5: 100.0000 (97.7378)  time: 0.2201  data: 0.0013  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.5961 (0.7950)  Acc@1: 93.7500 (87.0385)  Acc@5: 100.0000 (97.7323)  time: 0.2183  data: 0.0010  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.6903 (0.7952)  Acc@1: 87.5000 (87.0454)  Acc@5: 100.0000 (97.7269)  time: 0.2214  data: 0.0013  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.7679 (0.7955)  Acc@1: 87.5000 (87.0325)  Acc@5: 100.0000 (97.7294)  time: 0.2203  data: 0.0012  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 0.8034 (0.7964)  Acc@1: 87.5000 (87.0003)  Acc@5: 100.0000 (97.7280)  time: 0.2170  data: 0.0008  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.7532 (0.7961)  Acc@1: 87.5000 (87.0112)  Acc@5: 100.0000 (97.7343)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.6615 (0.7951)  Acc@1: 87.5000 (87.0450)  Acc@5: 100.0000 (97.7406)  time: 0.2166  data: 0.0006  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.6719 (0.7947)  Acc@1: 87.5000 (87.0582)  Acc@5: 100.0000 (97.7336)  time: 0.2171  data: 0.0006  max mem: 2500
Test: [Task 1] Total time: 0:05:52 (0.2166 s / it)
* Acc@1 87.058 Acc@5 97.734 loss 0.795
{0: {0: 0, 1: 26032, 2: 0, 3: 0, 4: 0, 5: 0, 6: 26032, 7: 0, 8: 26032, 9: 0, 10: 0, 11: 0, 12: 26032, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task1]	Acc@1: 87.0582	Acc@5: 97.7336	Loss: 0.7947
Train: Epoch[1/5]  [   0/3750]  eta: 0:54:46  Lr: 0.001875  Loss: 2.2308  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  time: 0.8765  data: 0.5013  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:24:53  Lr: 0.001875  Loss: 1.8498  Acc@1: 25.0000 (23.8636)  Acc@5: 62.5000 (62.5000)  time: 0.3994  data: 0.0463  max mem: 2500
Train: Epoch[1/5]  [  20/3750]  eta: 0:23:23  Lr: 0.001875  Loss: 1.9495  Acc@1: 25.0000 (25.5952)  Acc@5: 68.7500 (65.7738)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:49  Lr: 0.001875  Loss: 1.6989  Acc@1: 31.2500 (30.2419)  Acc@5: 75.0000 (70.5645)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:28  Lr: 0.001875  Loss: 1.7600  Acc@1: 43.7500 (34.4512)  Acc@5: 81.2500 (74.2378)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [  50/3750]  eta: 0:22:17  Lr: 0.001875  Loss: 1.4700  Acc@1: 50.0000 (37.5000)  Acc@5: 87.5000 (76.7157)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [  60/3750]  eta: 0:22:07  Lr: 0.001875  Loss: 1.3203  Acc@1: 50.0000 (39.5492)  Acc@5: 87.5000 (78.9959)  time: 0.3515  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [  70/3750]  eta: 0:22:00  Lr: 0.001875  Loss: 1.6408  Acc@1: 50.0000 (40.9331)  Acc@5: 87.5000 (80.3697)  time: 0.3524  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:55  Lr: 0.001875  Loss: 0.7262  Acc@1: 50.0000 (42.4383)  Acc@5: 93.7500 (81.8673)  time: 0.3547  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:48  Lr: 0.001875  Loss: 1.1451  Acc@1: 56.2500 (44.0247)  Acc@5: 93.7500 (82.8984)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:42  Lr: 0.001875  Loss: 0.7377  Acc@1: 62.5000 (45.9158)  Acc@5: 93.7500 (83.9109)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:37  Lr: 0.001875  Loss: 1.0330  Acc@1: 62.5000 (47.5225)  Acc@5: 93.7500 (84.5721)  time: 0.3521  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:33  Lr: 0.001875  Loss: 0.6974  Acc@1: 62.5000 (48.8120)  Acc@5: 93.7500 (85.1240)  time: 0.3535  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:29  Lr: 0.001875  Loss: 0.7921  Acc@1: 62.5000 (49.7137)  Acc@5: 93.7500 (85.9256)  time: 0.3550  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:24  Lr: 0.001875  Loss: 0.5205  Acc@1: 62.5000 (50.9309)  Acc@5: 93.7500 (86.5248)  time: 0.3524  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:18  Lr: 0.001875  Loss: 0.8418  Acc@1: 62.5000 (51.6142)  Acc@5: 93.7500 (86.9205)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:13  Lr: 0.001875  Loss: 0.4760  Acc@1: 62.5000 (52.3292)  Acc@5: 93.7500 (87.3835)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 170/3750]  eta: 0:21:08  Lr: 0.001875  Loss: 0.7884  Acc@1: 62.5000 (52.8874)  Acc@5: 93.7500 (87.6096)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 180/3750]  eta: 0:21:03  Lr: 0.001875  Loss: 0.4353  Acc@1: 68.7500 (53.7293)  Acc@5: 93.7500 (87.9144)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:58  Lr: 0.001875  Loss: 0.6174  Acc@1: 68.7500 (54.2212)  Acc@5: 93.7500 (88.1872)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:54  Lr: 0.001875  Loss: 0.2466  Acc@1: 62.5000 (54.8197)  Acc@5: 93.7500 (88.4950)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:49  Lr: 0.001875  Loss: 0.2384  Acc@1: 68.7500 (55.3021)  Acc@5: 93.7500 (88.7441)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:45  Lr: 0.001875  Loss: 0.4042  Acc@1: 68.7500 (55.7127)  Acc@5: 93.7500 (88.8575)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:40  Lr: 0.001875  Loss: 0.3506  Acc@1: 62.5000 (56.1147)  Acc@5: 87.5000 (88.9610)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:36  Lr: 0.001875  Loss: 0.4906  Acc@1: 62.5000 (56.3797)  Acc@5: 93.7500 (89.1338)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:32  Lr: 0.001875  Loss: 0.2102  Acc@1: 62.5000 (56.8476)  Acc@5: 93.7500 (89.2679)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:29  Lr: 0.001875  Loss: 0.0463  Acc@1: 68.7500 (57.3276)  Acc@5: 93.7500 (89.4875)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.0360  Acc@1: 68.7500 (57.7260)  Acc@5: 93.7500 (89.6910)  time: 0.3526  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:23  Lr: 0.001875  Loss: 0.2768  Acc@1: 68.7500 (57.8069)  Acc@5: 93.7500 (89.8132)  time: 0.3594  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:20  Lr: 0.001875  Loss: 0.0258  Acc@1: 68.7500 (58.2045)  Acc@5: 93.7500 (89.9270)  time: 0.3602  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.0114  Acc@1: 68.7500 (58.5548)  Acc@5: 93.7500 (89.9917)  time: 0.3586  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.3967  Acc@1: 68.7500 (58.8625)  Acc@5: 93.7500 (90.1326)  time: 0.3597  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.0464  Acc@1: 68.7500 (59.2484)  Acc@5: 93.7500 (90.2843)  time: 0.3543  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 330/3750]  eta: 0:20:08  Lr: 0.001875  Loss: 0.0298  Acc@1: 68.7500 (59.4033)  Acc@5: 93.7500 (90.4079)  time: 0.3551  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 340/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.2247  Acc@1: 68.7500 (59.6957)  Acc@5: 93.7500 (90.4142)  time: 0.3524  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 350/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.0032  Acc@1: 68.7500 (59.9537)  Acc@5: 93.7500 (90.4915)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:55  Lr: 0.001875  Loss: 0.4618  Acc@1: 75.0000 (60.3359)  Acc@5: 93.7500 (90.5298)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:51  Lr: 0.001875  Loss: 0.1055  Acc@1: 75.0000 (60.6469)  Acc@5: 93.7500 (90.5829)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.5895  Acc@1: 75.0000 (60.9580)  Acc@5: 93.7500 (90.6496)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.7308  Acc@1: 68.7500 (61.2212)  Acc@5: 93.7500 (90.6809)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.0781  Acc@1: 68.7500 (61.4557)  Acc@5: 93.7500 (90.7263)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.2166  Acc@1: 68.7500 (61.6028)  Acc@5: 93.7500 (90.8759)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.3019  Acc@1: 68.7500 (61.7874)  Acc@5: 93.7500 (90.9887)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.4470  Acc@1: 68.7500 (61.9925)  Acc@5: 93.7500 (91.0818)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.3972  Acc@1: 68.7500 (62.2166)  Acc@5: 93.7500 (91.1423)  time: 0.3520  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.6631  Acc@1: 68.7500 (62.4307)  Acc@5: 93.7500 (91.2694)  time: 0.3536  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.1699  Acc@1: 68.7500 (62.6085)  Acc@5: 93.7500 (91.2825)  time: 0.3581  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.1744  Acc@1: 68.7500 (62.7389)  Acc@5: 87.5000 (91.2420)  time: 0.3600  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.0519  Acc@1: 75.0000 (63.0068)  Acc@5: 93.7500 (91.3591)  time: 0.3618  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [ 490/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.0491  Acc@1: 75.0000 (63.0728)  Acc@5: 93.7500 (91.4460)  time: 0.3609  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [ 500/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.7746  Acc@1: 68.7500 (63.0988)  Acc@5: 93.7500 (91.5294)  time: 0.3530  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 510/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.5403  Acc@1: 68.7500 (63.2339)  Acc@5: 93.7500 (91.5484)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.5220  Acc@1: 68.7500 (63.4477)  Acc@5: 93.7500 (91.6027)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.5700  Acc@1: 75.0000 (63.6653)  Acc@5: 100.0000 (91.7137)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.1806  Acc@1: 75.0000 (63.8632)  Acc@5: 100.0000 (91.7860)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.6034  Acc@1: 68.7500 (63.8498)  Acc@5: 93.7500 (91.7877)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.7067  Acc@1: 68.7500 (63.9817)  Acc@5: 93.7500 (91.8338)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.6605  Acc@1: 68.7500 (64.1419)  Acc@5: 93.7500 (91.8345)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.1866  Acc@1: 75.0000 (64.2319)  Acc@5: 93.7500 (91.8460)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.4808  Acc@1: 75.0000 (64.4459)  Acc@5: 93.7500 (91.8676)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.6907  Acc@1: 75.0000 (64.5695)  Acc@5: 93.7500 (91.9093)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.7753  Acc@1: 68.7500 (64.6072)  Acc@5: 93.7500 (91.9394)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.5947  Acc@1: 62.5000 (64.5934)  Acc@5: 93.7500 (91.9585)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.4988  Acc@1: 68.7500 (64.7385)  Acc@5: 93.7500 (91.9671)  time: 0.3516  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.3417  Acc@1: 75.0000 (64.6743)  Acc@5: 93.7500 (91.9462)  time: 0.3548  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.3908  Acc@1: 75.0000 (64.8041)  Acc@5: 93.7500 (91.9547)  time: 0.3611  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.5168  Acc@1: 75.0000 (65.0151)  Acc@5: 93.7500 (92.0102)  time: 0.3643  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 670/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.7541  Acc@1: 75.0000 (65.1080)  Acc@5: 100.0000 (92.0734)  time: 0.3638  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 680/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.5438  Acc@1: 75.0000 (65.2349)  Acc@5: 93.7500 (92.0980)  time: 0.3604  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.4152  Acc@1: 68.7500 (65.3130)  Acc@5: 93.7500 (92.0948)  time: 0.3572  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.8201  Acc@1: 68.7500 (65.3887)  Acc@5: 93.7500 (92.1273)  time: 0.3549  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.5251  Acc@1: 75.0000 (65.5679)  Acc@5: 93.7500 (92.1853)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.6092  Acc@1: 75.0000 (65.6033)  Acc@5: 93.7500 (92.2070)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -1.0500  Acc@1: 68.7500 (65.7148)  Acc@5: 93.7500 (92.2367)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.6086  Acc@1: 75.0000 (65.8401)  Acc@5: 93.7500 (92.2908)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.7683  Acc@1: 75.0000 (65.9204)  Acc@5: 93.7500 (92.3352)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -1.1279  Acc@1: 75.0000 (66.0069)  Acc@5: 93.7500 (92.3456)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.6700  Acc@1: 75.0000 (66.1235)  Acc@5: 93.7500 (92.4043)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.1562  Acc@1: 75.0000 (66.2212)  Acc@5: 93.7500 (92.4376)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -1.0290  Acc@1: 68.7500 (66.2611)  Acc@5: 93.7500 (92.4384)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -1.0883  Acc@1: 68.7500 (66.3936)  Acc@5: 93.7500 (92.4703)  time: 0.3451  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.4685  Acc@1: 75.0000 (66.4843)  Acc@5: 93.7500 (92.4861)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -1.1193  Acc@1: 75.0000 (66.6261)  Acc@5: 93.7500 (92.5396)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.7449  Acc@1: 75.0000 (66.6591)  Acc@5: 93.7500 (92.5692)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 840/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.6170  Acc@1: 68.7500 (66.7435)  Acc@5: 93.7500 (92.5981)  time: 0.3455  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.7273  Acc@1: 68.7500 (66.8625)  Acc@5: 100.0000 (92.6557)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.7246  Acc@1: 75.0000 (66.9643)  Acc@5: 93.7500 (92.6684)  time: 0.3536  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.4161  Acc@1: 75.0000 (67.0135)  Acc@5: 93.7500 (92.6952)  time: 0.3543  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -1.0261  Acc@1: 75.0000 (67.1112)  Acc@5: 93.7500 (92.7284)  time: 0.3558  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.7325  Acc@1: 68.7500 (67.1787)  Acc@5: 93.7500 (92.7680)  time: 0.3558  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.4831  Acc@1: 75.0000 (67.2655)  Acc@5: 93.7500 (92.7719)  time: 0.3570  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -1.1300  Acc@1: 81.2500 (67.4122)  Acc@5: 93.7500 (92.8032)  time: 0.3605  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.5393  Acc@1: 75.0000 (67.4878)  Acc@5: 93.7500 (92.8407)  time: 0.3569  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.7499  Acc@1: 75.0000 (67.5550)  Acc@5: 93.7500 (92.8773)  time: 0.3529  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.8917  Acc@1: 75.0000 (67.6541)  Acc@5: 93.7500 (92.8733)  time: 0.3539  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.2872  Acc@1: 75.0000 (67.7182)  Acc@5: 93.7500 (92.9154)  time: 0.3543  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.6775  Acc@1: 75.0000 (67.8590)  Acc@5: 93.7500 (92.9370)  time: 0.3536  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.6798  Acc@1: 75.0000 (67.8811)  Acc@5: 93.7500 (92.9454)  time: 0.3535  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.6655  Acc@1: 68.7500 (67.9345)  Acc@5: 93.7500 (92.9855)  time: 0.3572  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -1.0089  Acc@1: 68.7500 (67.9932)  Acc@5: 93.7500 (93.0121)  time: 0.3583  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1000/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.6146  Acc@1: 75.0000 (68.0195)  Acc@5: 93.7500 (92.9945)  time: 0.3597  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1010/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.8893  Acc@1: 68.7500 (68.0082)  Acc@5: 93.7500 (93.0020)  time: 0.3606  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1020/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7045  Acc@1: 75.0000 (68.0766)  Acc@5: 93.7500 (93.0399)  time: 0.3544  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.8655  Acc@1: 75.0000 (68.1620)  Acc@5: 100.0000 (93.0589)  time: 0.3514  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.7128  Acc@1: 75.0000 (68.2097)  Acc@5: 93.7500 (93.0776)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.9069  Acc@1: 75.0000 (68.2624)  Acc@5: 100.0000 (93.1078)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.6160  Acc@1: 75.0000 (68.2964)  Acc@5: 100.0000 (93.1433)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.9512  Acc@1: 75.0000 (68.3532)  Acc@5: 93.7500 (93.1548)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -1.1511  Acc@1: 68.7500 (68.3742)  Acc@5: 93.7500 (93.1718)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -1.2180  Acc@1: 68.7500 (68.4464)  Acc@5: 100.0000 (93.2000)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.6550  Acc@1: 68.7500 (68.4775)  Acc@5: 100.0000 (93.2221)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.7668  Acc@1: 75.0000 (68.5644)  Acc@5: 93.7500 (93.2606)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.4406  Acc@1: 75.0000 (68.6775)  Acc@5: 100.0000 (93.2817)  time: 0.3494  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.8131  Acc@1: 75.0000 (68.7389)  Acc@5: 100.0000 (93.3190)  time: 0.3501  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.6857  Acc@1: 75.0000 (68.7993)  Acc@5: 100.0000 (93.3447)  time: 0.3535  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.6245  Acc@1: 75.0000 (68.8260)  Acc@5: 100.0000 (93.3808)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.7487  Acc@1: 75.0000 (68.8630)  Acc@5: 93.7500 (93.3839)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.7257  Acc@1: 75.0000 (68.9208)  Acc@5: 93.7500 (93.3977)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1180/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.6514  Acc@1: 75.0000 (69.0040)  Acc@5: 93.7500 (93.4166)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1190/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.2078  Acc@1: 75.0000 (69.0544)  Acc@5: 93.7500 (93.4299)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.4693  Acc@1: 75.0000 (69.1195)  Acc@5: 100.0000 (93.4534)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.6178  Acc@1: 68.7500 (69.1422)  Acc@5: 93.7500 (93.4403)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.9985  Acc@1: 75.0000 (69.2107)  Acc@5: 93.7500 (93.4480)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.7808  Acc@1: 75.0000 (69.2222)  Acc@5: 93.7500 (93.4454)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.8161  Acc@1: 75.0000 (69.2637)  Acc@5: 93.7500 (93.4629)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:38  Lr: 0.001875  Loss: 0.0822  Acc@1: 68.7500 (69.2546)  Acc@5: 93.7500 (93.4702)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.6631  Acc@1: 75.0000 (69.3150)  Acc@5: 93.7500 (93.4923)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.8109  Acc@1: 81.2500 (69.3696)  Acc@5: 93.7500 (93.4992)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -1.0846  Acc@1: 75.0000 (69.4331)  Acc@5: 93.7500 (93.5109)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.5617  Acc@1: 75.0000 (69.4810)  Acc@5: 93.7500 (93.5321)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.3575  Acc@1: 75.0000 (69.5427)  Acc@5: 93.7500 (93.5530)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.7372  Acc@1: 81.2500 (69.6129)  Acc@5: 93.7500 (93.5736)  time: 0.3460  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.8100  Acc@1: 75.0000 (69.6631)  Acc@5: 93.7500 (93.5891)  time: 0.3473  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.1261  Acc@1: 75.0000 (69.7079)  Acc@5: 93.7500 (93.5903)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.9954  Acc@1: 75.0000 (69.7008)  Acc@5: 93.7500 (93.6009)  time: 0.3506  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1350/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.5301  Acc@1: 75.0000 (69.7354)  Acc@5: 93.7500 (93.5973)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.6464  Acc@1: 75.0000 (69.7878)  Acc@5: 100.0000 (93.6260)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.6955  Acc@1: 75.0000 (69.8395)  Acc@5: 100.0000 (93.6451)  time: 0.3497  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.6554  Acc@1: 75.0000 (69.8452)  Acc@5: 93.7500 (93.6685)  time: 0.3488  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.6635  Acc@1: 75.0000 (69.8643)  Acc@5: 93.7500 (93.6736)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -1.1348  Acc@1: 75.0000 (69.8831)  Acc@5: 93.7500 (93.6786)  time: 0.3491  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.8554  Acc@1: 75.0000 (69.9238)  Acc@5: 93.7500 (93.6880)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.2499  Acc@1: 75.0000 (69.9156)  Acc@5: 93.7500 (93.6884)  time: 0.3491  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.9114  Acc@1: 75.0000 (69.9642)  Acc@5: 93.7500 (93.7107)  time: 0.3491  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.5822  Acc@1: 75.0000 (69.9558)  Acc@5: 93.7500 (93.7283)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.9730  Acc@1: 68.7500 (69.9991)  Acc@5: 100.0000 (93.7457)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.7605  Acc@1: 75.0000 (70.0505)  Acc@5: 100.0000 (93.7628)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.8892  Acc@1: 75.0000 (70.1139)  Acc@5: 100.0000 (93.7882)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.7544  Acc@1: 81.2500 (70.1553)  Acc@5: 100.0000 (93.8049)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.4456  Acc@1: 81.2500 (70.2255)  Acc@5: 100.0000 (93.8296)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.5272  Acc@1: 81.2500 (70.2781)  Acc@5: 93.7500 (93.8374)  time: 0.3493  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.7730  Acc@1: 81.2500 (70.3301)  Acc@5: 93.7500 (93.8493)  time: 0.3523  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1520/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.6266  Acc@1: 75.0000 (70.3690)  Acc@5: 93.7500 (93.8609)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.2915  Acc@1: 75.0000 (70.3992)  Acc@5: 93.7500 (93.8684)  time: 0.3530  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -1.1144  Acc@1: 75.0000 (70.4250)  Acc@5: 93.7500 (93.8879)  time: 0.3552  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.4885  Acc@1: 75.0000 (70.4747)  Acc@5: 93.7500 (93.8991)  time: 0.3518  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -1.0124  Acc@1: 75.0000 (70.5357)  Acc@5: 93.7500 (93.9102)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -1.2940  Acc@1: 75.0000 (70.5880)  Acc@5: 93.7500 (93.9211)  time: 0.3491  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.6822  Acc@1: 75.0000 (70.5803)  Acc@5: 93.7500 (93.9160)  time: 0.3500  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -1.0130  Acc@1: 75.0000 (70.6356)  Acc@5: 93.7500 (93.9346)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.5805  Acc@1: 75.0000 (70.6512)  Acc@5: 93.7500 (93.9491)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.5706  Acc@1: 68.7500 (70.6665)  Acc@5: 93.7500 (93.9595)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.3763  Acc@1: 68.7500 (70.6585)  Acc@5: 93.7500 (93.9582)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.0368  Acc@1: 68.7500 (70.6928)  Acc@5: 93.7500 (93.9761)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.7459  Acc@1: 75.0000 (70.7305)  Acc@5: 100.0000 (93.9861)  time: 0.3484  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.9958  Acc@1: 75.0000 (70.7639)  Acc@5: 100.0000 (93.9998)  time: 0.3495  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.9410  Acc@1: 75.0000 (70.7894)  Acc@5: 100.0000 (94.0172)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.8506  Acc@1: 75.0000 (70.8296)  Acc@5: 100.0000 (94.0268)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -1.0241  Acc@1: 75.0000 (70.8470)  Acc@5: 93.7500 (94.0400)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.9980  Acc@1: 75.0000 (70.8604)  Acc@5: 93.7500 (94.0605)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.5705  Acc@1: 81.2500 (70.9252)  Acc@5: 93.7500 (94.0660)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.9714  Acc@1: 81.2500 (70.9928)  Acc@5: 100.0000 (94.0824)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.6679  Acc@1: 75.0000 (71.0270)  Acc@5: 100.0000 (94.0950)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.4485  Acc@1: 75.0000 (71.0680)  Acc@5: 100.0000 (94.1219)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -1.0223  Acc@1: 81.2500 (71.1193)  Acc@5: 100.0000 (94.1269)  time: 0.3514  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.8098  Acc@1: 81.2500 (71.1879)  Acc@5: 93.7500 (94.1284)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -1.0972  Acc@1: 81.2500 (71.1811)  Acc@5: 93.7500 (94.1475)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.7437  Acc@1: 75.0000 (71.1992)  Acc@5: 93.7500 (94.1417)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -1.0631  Acc@1: 75.0000 (71.2381)  Acc@5: 93.7500 (94.1571)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.5194  Acc@1: 75.0000 (71.2730)  Acc@5: 100.0000 (94.1757)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.9690  Acc@1: 81.2500 (71.3388)  Acc@5: 100.0000 (94.1907)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -1.1975  Acc@1: 81.2500 (71.3694)  Acc@5: 93.7500 (94.1883)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.7199  Acc@1: 75.0000 (71.3962)  Acc@5: 93.7500 (94.1928)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -1.0282  Acc@1: 75.0000 (71.4261)  Acc@5: 93.7500 (94.1937)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -0.9439  Acc@1: 75.0000 (71.4693)  Acc@5: 100.0000 (94.2117)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -1.0153  Acc@1: 75.0000 (71.4850)  Acc@5: 100.0000 (94.2160)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.4444  Acc@1: 68.7500 (71.4871)  Acc@5: 93.7500 (94.2034)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -0.8574  Acc@1: 75.0000 (71.5159)  Acc@5: 93.7500 (94.2177)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.9827  Acc@1: 75.0000 (71.5444)  Acc@5: 100.0000 (94.2251)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.4024  Acc@1: 75.0000 (71.5627)  Acc@5: 93.7500 (94.2259)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -1.0205  Acc@1: 81.2500 (71.6268)  Acc@5: 100.0000 (94.2366)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -1.0453  Acc@1: 81.2500 (71.6248)  Acc@5: 100.0000 (94.2406)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.0843  Acc@1: 75.0000 (71.6326)  Acc@5: 93.7500 (94.2380)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.5733  Acc@1: 75.0000 (71.6371)  Acc@5: 93.7500 (94.2484)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.9882  Acc@1: 75.0000 (71.6609)  Acc@5: 93.7500 (94.2459)  time: 0.3486  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -1.0928  Acc@1: 75.0000 (71.6684)  Acc@5: 93.7500 (94.2594)  time: 0.3501  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.6784  Acc@1: 75.0000 (71.6790)  Acc@5: 93.7500 (94.2568)  time: 0.3498  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.7049  Acc@1: 81.2500 (71.7371)  Acc@5: 93.7500 (94.2764)  time: 0.3498  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.5964  Acc@1: 81.2500 (71.7693)  Acc@5: 100.0000 (94.2674)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -0.6261  Acc@1: 75.0000 (71.7573)  Acc@5: 93.7500 (94.2680)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.6155  Acc@1: 75.0000 (71.8016)  Acc@5: 93.7500 (94.2685)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -0.5862  Acc@1: 81.2500 (71.8424)  Acc@5: 93.7500 (94.2628)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -1.1676  Acc@1: 81.2500 (71.8827)  Acc@5: 93.7500 (94.2695)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2030/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.4869  Acc@1: 75.0000 (71.8827)  Acc@5: 93.7500 (94.2670)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.4384  Acc@1: 75.0000 (71.9225)  Acc@5: 93.7500 (94.2736)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -1.1907  Acc@1: 75.0000 (71.9466)  Acc@5: 93.7500 (94.2863)  time: 0.3516  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.8392  Acc@1: 75.0000 (71.9311)  Acc@5: 93.7500 (94.2928)  time: 0.3516  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7058  Acc@1: 75.0000 (71.9520)  Acc@5: 93.7500 (94.2962)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.8300  Acc@1: 75.0000 (71.9696)  Acc@5: 100.0000 (94.3206)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.8387  Acc@1: 75.0000 (71.9751)  Acc@5: 100.0000 (94.3209)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -1.0106  Acc@1: 75.0000 (72.0014)  Acc@5: 93.7500 (94.3271)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.8945  Acc@1: 81.2500 (72.0304)  Acc@5: 93.7500 (94.3273)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.1512  Acc@1: 75.0000 (72.0356)  Acc@5: 93.7500 (94.3305)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.9454  Acc@1: 81.2500 (72.0730)  Acc@5: 93.7500 (94.3307)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.8599  Acc@1: 75.0000 (72.0983)  Acc@5: 93.7500 (94.3251)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -1.1485  Acc@1: 75.0000 (72.1060)  Acc@5: 93.7500 (94.3340)  time: 0.3513  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.7647  Acc@1: 75.0000 (72.1339)  Acc@5: 100.0000 (94.3516)  time: 0.3519  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -1.0975  Acc@1: 81.2500 (72.1471)  Acc@5: 100.0000 (94.3632)  time: 0.3523  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.7732  Acc@1: 75.0000 (72.1630)  Acc@5: 100.0000 (94.3776)  time: 0.3502  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -1.2847  Acc@1: 75.0000 (72.1902)  Acc@5: 100.0000 (94.3918)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2200/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.8445  Acc@1: 81.2500 (72.2342)  Acc@5: 100.0000 (94.4060)  time: 0.3495  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.7949  Acc@1: 81.2500 (72.2806)  Acc@5: 100.0000 (94.4143)  time: 0.3490  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.8352  Acc@1: 81.2500 (72.3126)  Acc@5: 100.0000 (94.4310)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.8129  Acc@1: 75.0000 (72.3218)  Acc@5: 100.0000 (94.4392)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.7451  Acc@1: 75.0000 (72.3505)  Acc@5: 93.7500 (94.4444)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.9057  Acc@1: 81.2500 (72.4012)  Acc@5: 93.7500 (94.4580)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.6293  Acc@1: 81.2500 (72.4016)  Acc@5: 100.0000 (94.4659)  time: 0.3487  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.6781  Acc@1: 75.0000 (72.4323)  Acc@5: 93.7500 (94.4766)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.7492  Acc@1: 75.0000 (72.4463)  Acc@5: 93.7500 (94.4761)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.8516  Acc@1: 81.2500 (72.4875)  Acc@5: 93.7500 (94.4811)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -1.1335  Acc@1: 81.2500 (72.5147)  Acc@5: 93.7500 (94.4915)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -1.0040  Acc@1: 81.2500 (72.5471)  Acc@5: 100.0000 (94.5018)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -1.0904  Acc@1: 81.2500 (72.5738)  Acc@5: 100.0000 (94.5121)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.6828  Acc@1: 81.2500 (72.6271)  Acc@5: 100.0000 (94.5302)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.7680  Acc@1: 81.2500 (72.6479)  Acc@5: 100.0000 (94.5376)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.8608  Acc@1: 81.2500 (72.6792)  Acc@5: 93.7500 (94.5396)  time: 0.3509  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.9284  Acc@1: 81.2500 (72.7234)  Acc@5: 93.7500 (94.5442)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.9831  Acc@1: 81.2500 (72.7462)  Acc@5: 100.0000 (94.5566)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6264  Acc@1: 75.0000 (72.7583)  Acc@5: 93.7500 (94.5506)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.8603  Acc@1: 81.2500 (72.7938)  Acc@5: 93.7500 (94.5551)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.9821  Acc@1: 81.2500 (72.8160)  Acc@5: 100.0000 (94.5622)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.8955  Acc@1: 75.0000 (72.8510)  Acc@5: 100.0000 (94.5743)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:45  Lr: 0.001875  Loss: 0.3705  Acc@1: 75.0000 (72.8289)  Acc@5: 100.0000 (94.5684)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -1.1835  Acc@1: 75.0000 (72.8584)  Acc@5: 100.0000 (94.5856)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:38  Lr: 0.001875  Loss: 0.0674  Acc@1: 81.2500 (72.8646)  Acc@5: 100.0000 (94.5873)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.8629  Acc@1: 81.2500 (72.9039)  Acc@5: 93.7500 (94.5966)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:31  Lr: 0.001875  Loss: 0.2401  Acc@1: 75.0000 (72.8896)  Acc@5: 100.0000 (94.6033)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.8369  Acc@1: 75.0000 (72.9158)  Acc@5: 100.0000 (94.6150)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.8506  Acc@1: 81.2500 (72.9570)  Acc@5: 100.0000 (94.6166)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.5383  Acc@1: 81.2500 (72.9827)  Acc@5: 93.7500 (94.6257)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.3737  Acc@1: 81.2500 (73.0058)  Acc@5: 100.0000 (94.6371)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.0111  Acc@1: 75.0000 (73.0137)  Acc@5: 100.0000 (94.6510)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.7821  Acc@1: 75.0000 (73.0291)  Acc@5: 100.0000 (94.6574)  time: 0.3496  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.6944  Acc@1: 75.0000 (73.0443)  Acc@5: 93.7500 (94.6563)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -1.0930  Acc@1: 75.0000 (73.0741)  Acc@5: 93.7500 (94.6601)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.9254  Acc@1: 81.2500 (73.0939)  Acc@5: 93.7500 (94.6541)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.6413  Acc@1: 81.2500 (73.1257)  Acc@5: 93.7500 (94.6627)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.8160  Acc@1: 75.0000 (73.1306)  Acc@5: 100.0000 (94.6616)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.8888  Acc@1: 75.0000 (73.1354)  Acc@5: 93.7500 (94.6629)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -1.0450  Acc@1: 81.2500 (73.1595)  Acc@5: 93.7500 (94.6618)  time: 0.3531  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.9117  Acc@1: 81.2500 (73.1882)  Acc@5: 100.0000 (94.6727)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.5334  Acc@1: 75.0000 (73.1951)  Acc@5: 100.0000 (94.6812)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.8110  Acc@1: 75.0000 (73.2068)  Acc@5: 100.0000 (94.6871)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.3276  Acc@1: 75.0000 (73.2184)  Acc@5: 100.0000 (94.6860)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.4676  Acc@1: 75.0000 (73.2227)  Acc@5: 93.7500 (94.6729)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.2629  Acc@1: 75.0000 (73.2436)  Acc@5: 93.7500 (94.6836)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -1.2377  Acc@1: 81.2500 (73.2596)  Acc@5: 100.0000 (94.6895)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8737  Acc@1: 75.0000 (73.2778)  Acc@5: 100.0000 (94.6977)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.7325  Acc@1: 75.0000 (73.2819)  Acc@5: 93.7500 (94.7011)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.3668  Acc@1: 75.0000 (73.3092)  Acc@5: 100.0000 (94.7139)  time: 0.3531  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.9551  Acc@1: 75.0000 (73.3247)  Acc@5: 100.0000 (94.7242)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.6383  Acc@1: 75.0000 (73.3263)  Acc@5: 100.0000 (94.7298)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.7296  Acc@1: 75.0000 (73.3347)  Acc@5: 93.7500 (94.7285)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6320  Acc@1: 81.2500 (73.3431)  Acc@5: 93.7500 (94.7386)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.8951  Acc@1: 81.2500 (73.3628)  Acc@5: 93.7500 (94.7396)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.8669  Acc@1: 81.2500 (73.3960)  Acc@5: 100.0000 (94.7519)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -1.1373  Acc@1: 81.2500 (73.4222)  Acc@5: 100.0000 (94.7596)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.6191  Acc@1: 75.0000 (73.4279)  Acc@5: 93.7500 (94.7492)  time: 0.3530  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.5894  Acc@1: 75.0000 (73.4268)  Acc@5: 93.7500 (94.7523)  time: 0.3541  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.8937  Acc@1: 75.0000 (73.4459)  Acc@5: 93.7500 (94.7510)  time: 0.3522  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -0.9304  Acc@1: 81.2500 (73.4782)  Acc@5: 93.7500 (94.7541)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -1.1054  Acc@1: 81.2500 (73.4948)  Acc@5: 93.7500 (94.7528)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.6778  Acc@1: 81.2500 (73.4957)  Acc@5: 93.7500 (94.7558)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.9367  Acc@1: 75.0000 (73.4966)  Acc@5: 93.7500 (94.7589)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -1.2628  Acc@1: 75.0000 (73.5062)  Acc@5: 93.7500 (94.7642)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.6210  Acc@1: 75.0000 (73.5334)  Acc@5: 93.7500 (94.7562)  time: 0.3531  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -1.0099  Acc@1: 81.2500 (73.5735)  Acc@5: 93.7500 (94.7658)  time: 0.3561  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.7947  Acc@1: 81.2500 (73.5959)  Acc@5: 100.0000 (94.7732)  time: 0.3539  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -1.1708  Acc@1: 81.2500 (73.6246)  Acc@5: 100.0000 (94.7740)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.7083  Acc@1: 81.2500 (73.6315)  Acc@5: 100.0000 (94.7769)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.7023  Acc@1: 81.2500 (73.6535)  Acc@5: 100.0000 (94.7884)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -1.0449  Acc@1: 87.5000 (73.6925)  Acc@5: 100.0000 (94.7999)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.9696  Acc@1: 87.5000 (73.7248)  Acc@5: 100.0000 (94.8027)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.2958  Acc@1: 81.2500 (73.7483)  Acc@5: 93.7500 (94.8013)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.8935  Acc@1: 81.2500 (73.7547)  Acc@5: 93.7500 (94.8041)  time: 0.3514  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.0201  Acc@1: 81.2500 (73.7716)  Acc@5: 93.7500 (94.8047)  time: 0.3515  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.5956  Acc@1: 81.2500 (73.7736)  Acc@5: 100.0000 (94.8159)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.9908  Acc@1: 81.2500 (73.7883)  Acc@5: 100.0000 (94.8229)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.3704  Acc@1: 75.0000 (73.7965)  Acc@5: 100.0000 (94.8172)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.0424  Acc@1: 75.0000 (73.8236)  Acc@5: 93.7500 (94.8220)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -1.1876  Acc@1: 75.0000 (73.8275)  Acc@5: 100.0000 (94.8226)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.7850  Acc@1: 75.0000 (73.8397)  Acc@5: 100.0000 (94.8252)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.7023  Acc@1: 75.0000 (73.8435)  Acc@5: 100.0000 (94.8299)  time: 0.3467  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.8301  Acc@1: 75.0000 (73.8432)  Acc@5: 100.0000 (94.8326)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.1053  Acc@1: 75.0000 (73.8696)  Acc@5: 100.0000 (94.8454)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.8730  Acc@1: 75.0000 (73.8692)  Acc@5: 93.7500 (94.8398)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.9710  Acc@1: 81.2500 (73.8995)  Acc@5: 93.7500 (94.8485)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.5574  Acc@1: 81.2500 (73.9153)  Acc@5: 100.0000 (94.8612)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.1532  Acc@1: 81.2500 (73.9431)  Acc@5: 100.0000 (94.8596)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.7369  Acc@1: 81.2500 (73.9506)  Acc@5: 100.0000 (94.8702)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.8585  Acc@1: 81.2500 (73.9701)  Acc@5: 100.0000 (94.8827)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -1.2219  Acc@1: 81.2500 (73.9875)  Acc@5: 100.0000 (94.8891)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.7219  Acc@1: 81.2500 (74.0107)  Acc@5: 100.0000 (94.8975)  time: 0.3520  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.5079  Acc@1: 75.0000 (74.0159)  Acc@5: 100.0000 (94.9018)  time: 0.3505  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.8471  Acc@1: 81.2500 (74.0409)  Acc@5: 93.7500 (94.9061)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.5628  Acc@1: 81.2500 (74.0400)  Acc@5: 93.7500 (94.9064)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7760  Acc@1: 75.0000 (74.0371)  Acc@5: 93.7500 (94.9087)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.2238  Acc@1: 75.0000 (74.0559)  Acc@5: 100.0000 (94.9208)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.8682  Acc@1: 75.0000 (74.0549)  Acc@5: 100.0000 (94.9289)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.3933  Acc@1: 68.7500 (74.0540)  Acc@5: 93.7500 (94.9271)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -1.3848  Acc@1: 75.0000 (74.0687)  Acc@5: 93.7500 (94.9332)  time: 0.3486  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.5744  Acc@1: 81.2500 (74.0988)  Acc@5: 93.7500 (94.9334)  time: 0.3502  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.8319  Acc@1: 75.0000 (74.0900)  Acc@5: 93.7500 (94.9395)  time: 0.3521  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.5075  Acc@1: 68.7500 (74.0928)  Acc@5: 93.7500 (94.9396)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4761  Acc@1: 81.2500 (74.1206)  Acc@5: 93.7500 (94.9437)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.9515  Acc@1: 81.2500 (74.1445)  Acc@5: 100.0000 (94.9516)  time: 0.3521  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.9625  Acc@1: 81.2500 (74.1720)  Acc@5: 100.0000 (94.9594)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -1.0222  Acc@1: 87.5000 (74.1841)  Acc@5: 100.0000 (94.9633)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.8894  Acc@1: 81.2500 (74.2018)  Acc@5: 100.0000 (94.9730)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.0744  Acc@1: 81.2500 (74.2176)  Acc@5: 100.0000 (94.9749)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.8569  Acc@1: 81.2500 (74.2427)  Acc@5: 93.7500 (94.9693)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.5348  Acc@1: 81.2500 (74.2544)  Acc@5: 93.7500 (94.9713)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4495  Acc@1: 81.2500 (74.2529)  Acc@5: 100.0000 (94.9752)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.9906  Acc@1: 81.2500 (74.2795)  Acc@5: 100.0000 (94.9790)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.9896  Acc@1: 81.2500 (74.2854)  Acc@5: 93.7500 (94.9753)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.0655  Acc@1: 81.2500 (74.2931)  Acc@5: 93.7500 (94.9735)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.8063  Acc@1: 81.2500 (74.3194)  Acc@5: 93.7500 (94.9773)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.3403  Acc@1: 81.2500 (74.3344)  Acc@5: 100.0000 (94.9885)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.7555  Acc@1: 81.2500 (74.3567)  Acc@5: 100.0000 (94.9867)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.1682  Acc@1: 81.2500 (74.3770)  Acc@5: 93.7500 (94.9904)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.5127  Acc@1: 81.2500 (74.3899)  Acc@5: 93.7500 (94.9941)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9630  Acc@1: 75.0000 (74.4027)  Acc@5: 93.7500 (94.9978)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -1.0068  Acc@1: 81.2500 (74.4209)  Acc@5: 100.0000 (95.0088)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.6767  Acc@1: 81.2500 (74.4262)  Acc@5: 100.0000 (95.0179)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.8237  Acc@1: 75.0000 (74.4388)  Acc@5: 100.0000 (95.0214)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6551  Acc@1: 81.2500 (74.4621)  Acc@5: 100.0000 (95.0232)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9249  Acc@1: 75.0000 (74.4582)  Acc@5: 100.0000 (95.0249)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -1.1737  Acc@1: 75.0000 (74.4724)  Acc@5: 100.0000 (95.0321)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.9444  Acc@1: 81.2500 (74.4829)  Acc@5: 93.7500 (95.0266)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.2604  Acc@1: 81.2500 (74.4933)  Acc@5: 93.7500 (95.0229)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0176  Acc@1: 81.2500 (74.5091)  Acc@5: 100.0000 (95.0318)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -1.2070  Acc@1: 81.2500 (74.5265)  Acc@5: 100.0000 (95.0388)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8667  Acc@1: 81.2500 (74.5474)  Acc@5: 100.0000 (95.0440)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1733  Acc@1: 81.2500 (74.5363)  Acc@5: 100.0000 (95.0457)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.8499  Acc@1: 75.0000 (74.5534)  Acc@5: 100.0000 (95.0544)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.6051  Acc@1: 75.0000 (74.5529)  Acc@5: 100.0000 (95.0560)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.2493  Acc@1: 75.0000 (74.5630)  Acc@5: 100.0000 (95.0611)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.2353  Acc@1: 87.5000 (74.6080)  Acc@5: 100.0000 (95.0732)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.5841  Acc@1: 87.5000 (74.6213)  Acc@5: 100.0000 (95.0747)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -1.1915  Acc@1: 87.5000 (74.6589)  Acc@5: 100.0000 (95.0797)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.3448  Acc@1: 81.2500 (74.6737)  Acc@5: 100.0000 (95.0847)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.2593  Acc@1: 81.2500 (74.6936)  Acc@5: 100.0000 (95.0948)  time: 0.3513  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.7053  Acc@1: 81.2500 (74.6979)  Acc@5: 100.0000 (95.0963)  time: 0.3514  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7590  Acc@1: 81.2500 (74.6988)  Acc@5: 100.0000 (95.0978)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.8862  Acc@1: 75.0000 (74.6945)  Acc@5: 93.7500 (95.0924)  time: 0.3524  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.1824  Acc@1: 75.0000 (74.7124)  Acc@5: 93.7500 (95.1024)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.9143  Acc@1: 75.0000 (74.7012)  Acc@5: 100.0000 (95.1038)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0571  Acc@1: 68.7500 (74.6987)  Acc@5: 93.7500 (95.1035)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3243  Acc@1: 81.2500 (74.7080)  Acc@5: 93.7500 (95.0998)  time: 0.3506  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7573  Acc@1: 81.2500 (74.7138)  Acc@5: 93.7500 (95.0996)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8055  Acc@1: 81.2500 (74.7349)  Acc@5: 100.0000 (95.1010)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.7133  Acc@1: 81.2500 (74.7457)  Acc@5: 100.0000 (95.1125)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0765  Acc@1: 75.0000 (74.7564)  Acc@5: 100.0000 (95.1038)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.1876  Acc@1: 81.2500 (74.7688)  Acc@5: 93.7500 (95.1119)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6317  Acc@1: 75.0000 (74.7728)  Acc@5: 100.0000 (95.1099)  time: 0.3519  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3350  Acc@1: 81.2500 (74.7883)  Acc@5: 100.0000 (95.1167)  time: 0.3544  data: 0.0022  max mem: 2500
Train: Epoch[1/5] Total time: 0:21:51 (0.3498 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 59984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.3350  Acc@1: 81.2500 (74.7883)  Acc@5: 100.0000 (95.1167)
Train: Epoch[2/5]  [   0/3750]  eta: 0:39:56  Lr: 0.001875  Loss: -1.1138  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6390  data: 0.2868  max mem: 2500
Train: Epoch[2/5]  [  10/3750]  eta: 0:23:34  Lr: 0.001875  Loss: -0.9381  Acc@1: 81.2500 (79.5455)  Acc@5: 93.7500 (96.0227)  time: 0.3783  data: 0.0268  max mem: 2500
Train: Epoch[2/5]  [  20/3750]  eta: 0:22:51  Lr: 0.001875  Loss: -0.9870  Acc@1: 81.2500 (80.9524)  Acc@5: 100.0000 (97.0238)  time: 0.3542  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:25  Lr: 0.001875  Loss: -1.0144  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (96.5726)  time: 0.3525  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:09  Lr: 0.001875  Loss: -0.9718  Acc@1: 81.2500 (80.6402)  Acc@5: 93.7500 (96.3415)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [  50/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -0.5949  Acc@1: 81.2500 (79.4118)  Acc@5: 93.7500 (95.8333)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:52  Lr: 0.001875  Loss: -0.8118  Acc@1: 75.0000 (78.5861)  Acc@5: 93.7500 (95.7992)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.9373  Acc@1: 75.0000 (79.1373)  Acc@5: 93.7500 (95.7746)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.9141  Acc@1: 81.2500 (79.0123)  Acc@5: 100.0000 (95.9877)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.9578  Acc@1: 81.2500 (79.3269)  Acc@5: 93.7500 (95.8104)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:29  Lr: 0.001875  Loss: -0.6535  Acc@1: 81.2500 (79.8267)  Acc@5: 93.7500 (95.9158)  time: 0.3513  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -0.4685  Acc@1: 81.2500 (79.4482)  Acc@5: 93.7500 (95.8896)  time: 0.3504  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.8842  Acc@1: 75.0000 (79.1322)  Acc@5: 93.7500 (95.8678)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -1.0493  Acc@1: 75.0000 (78.9122)  Acc@5: 93.7500 (95.9924)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.6410  Acc@1: 75.0000 (78.2358)  Acc@5: 100.0000 (95.9220)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -0.7285  Acc@1: 75.0000 (78.3113)  Acc@5: 100.0000 (95.9851)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.9113  Acc@1: 81.2500 (78.5326)  Acc@5: 100.0000 (96.0792)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.9120  Acc@1: 81.2500 (78.9108)  Acc@5: 100.0000 (96.0161)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -1.0968  Acc@1: 81.2500 (79.0401)  Acc@5: 93.7500 (95.9254)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -1.0578  Acc@1: 87.5000 (79.4175)  Acc@5: 100.0000 (96.0406)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -1.2016  Acc@1: 81.2500 (79.3843)  Acc@5: 100.0000 (96.1132)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -1.1580  Acc@1: 81.2500 (79.4135)  Acc@5: 100.0000 (96.0604)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -1.1824  Acc@1: 81.2500 (79.4400)  Acc@5: 93.7500 (96.0690)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.9190  Acc@1: 81.2500 (79.4102)  Acc@5: 93.7500 (96.1039)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -1.1210  Acc@1: 81.2500 (79.4346)  Acc@5: 100.0000 (96.0840)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.7642  Acc@1: 81.2500 (79.4821)  Acc@5: 100.0000 (96.1653)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.7467  Acc@1: 75.0000 (79.4301)  Acc@5: 100.0000 (96.0967)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -1.2253  Acc@1: 75.0000 (79.4050)  Acc@5: 93.7500 (96.0332)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.8987  Acc@1: 75.0000 (79.3149)  Acc@5: 100.0000 (96.1077)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.6957  Acc@1: 75.0000 (79.2741)  Acc@5: 100.0000 (96.1340)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -1.2909  Acc@1: 81.2500 (79.2774)  Acc@5: 100.0000 (96.1794)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -1.1100  Acc@1: 81.2500 (79.3207)  Acc@5: 100.0000 (96.2219)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 320/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.3214  Acc@1: 75.0000 (79.1083)  Acc@5: 100.0000 (96.1838)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -1.0604  Acc@1: 75.0000 (79.0597)  Acc@5: 93.7500 (96.0725)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.7314  Acc@1: 75.0000 (79.0689)  Acc@5: 93.7500 (96.0594)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.9792  Acc@1: 81.2500 (78.9530)  Acc@5: 93.7500 (96.0470)  time: 0.3472  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.6452  Acc@1: 75.0000 (78.7569)  Acc@5: 93.7500 (96.0353)  time: 0.3479  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -1.2555  Acc@1: 68.7500 (78.6220)  Acc@5: 100.0000 (96.0916)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -1.2175  Acc@1: 81.2500 (78.6909)  Acc@5: 100.0000 (96.0958)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -1.2850  Acc@1: 87.5000 (78.9003)  Acc@5: 100.0000 (96.0997)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -1.1541  Acc@1: 87.5000 (78.9589)  Acc@5: 100.0000 (96.1035)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.6709  Acc@1: 81.2500 (78.9994)  Acc@5: 100.0000 (96.1223)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.9155  Acc@1: 81.2500 (79.0083)  Acc@5: 100.0000 (96.1550)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.5576  Acc@1: 81.2500 (79.0603)  Acc@5: 100.0000 (96.1572)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -1.1531  Acc@1: 81.2500 (79.1383)  Acc@5: 93.7500 (96.1451)  time: 0.3509  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.7865  Acc@1: 81.2500 (79.1297)  Acc@5: 93.7500 (96.1059)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -1.2942  Acc@1: 81.2500 (79.2570)  Acc@5: 93.7500 (96.1226)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -1.0383  Acc@1: 81.2500 (79.2728)  Acc@5: 100.0000 (96.1120)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.7715  Acc@1: 81.2500 (79.2879)  Acc@5: 100.0000 (96.1538)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 490/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.5930  Acc@1: 81.2500 (79.2643)  Acc@5: 100.0000 (96.1176)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -1.3899  Acc@1: 81.2500 (79.3663)  Acc@5: 100.0000 (96.1203)  time: 0.3528  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.4455  Acc@1: 81.2500 (79.2564)  Acc@5: 93.7500 (96.0739)  time: 0.3531  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.9078  Acc@1: 81.2500 (79.3066)  Acc@5: 93.7500 (96.1012)  time: 0.3531  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.2600  Acc@1: 81.2500 (79.2608)  Acc@5: 100.0000 (96.0923)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -1.2810  Acc@1: 75.0000 (79.2976)  Acc@5: 93.7500 (96.1067)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -0.4937  Acc@1: 81.2500 (79.2877)  Acc@5: 100.0000 (96.1093)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.5617  Acc@1: 81.2500 (79.3672)  Acc@5: 100.0000 (96.1007)  time: 0.3509  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -1.2233  Acc@1: 81.2500 (79.3673)  Acc@5: 100.0000 (96.0924)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.8219  Acc@1: 75.0000 (79.3029)  Acc@5: 100.0000 (96.0843)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -1.1819  Acc@1: 75.0000 (79.2830)  Acc@5: 100.0000 (96.0871)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.8487  Acc@1: 81.2500 (79.3053)  Acc@5: 100.0000 (96.1002)  time: 0.3500  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -1.1664  Acc@1: 75.0000 (79.2349)  Acc@5: 93.7500 (96.1129)  time: 0.3518  data: 0.0029  max mem: 2500
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -1.0225  Acc@1: 75.0000 (79.2170)  Acc@5: 100.0000 (96.1353)  time: 0.3509  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.8941  Acc@1: 75.0000 (79.1700)  Acc@5: 100.0000 (96.1173)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -1.0892  Acc@1: 75.0000 (79.2024)  Acc@5: 100.0000 (96.1486)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -1.0328  Acc@1: 81.2500 (79.2339)  Acc@5: 100.0000 (96.1502)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 660/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.9564  Acc@1: 87.5000 (79.3400)  Acc@5: 100.0000 (96.1517)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -1.2215  Acc@1: 87.5000 (79.3778)  Acc@5: 100.0000 (96.1904)  time: 0.3531  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.4846  Acc@1: 75.0000 (79.3043)  Acc@5: 100.0000 (96.1546)  time: 0.3545  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.5095  Acc@1: 75.0000 (79.2963)  Acc@5: 93.7500 (96.1198)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -1.2647  Acc@1: 81.2500 (79.3955)  Acc@5: 100.0000 (96.1484)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.8858  Acc@1: 87.5000 (79.4568)  Acc@5: 100.0000 (96.1674)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.7252  Acc@1: 81.2500 (79.4643)  Acc@5: 100.0000 (96.1598)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.9251  Acc@1: 81.2500 (79.4802)  Acc@5: 100.0000 (96.1611)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.8897  Acc@1: 75.0000 (79.4366)  Acc@5: 93.7500 (96.1201)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.7690  Acc@1: 75.0000 (79.4358)  Acc@5: 93.7500 (96.1385)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.7538  Acc@1: 81.2500 (79.4432)  Acc@5: 100.0000 (96.1399)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -0.8869  Acc@1: 81.2500 (79.3774)  Acc@5: 100.0000 (96.1414)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -1.0793  Acc@1: 75.0000 (79.4254)  Acc@5: 100.0000 (96.1428)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -1.0130  Acc@1: 81.2500 (79.4327)  Acc@5: 100.0000 (96.1599)  time: 0.3456  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.8868  Acc@1: 81.2500 (79.4554)  Acc@5: 100.0000 (96.1767)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.7395  Acc@1: 81.2500 (79.4467)  Acc@5: 100.0000 (96.1467)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.8725  Acc@1: 81.2500 (79.4458)  Acc@5: 93.7500 (96.1404)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 830/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.7686  Acc@1: 81.2500 (79.4149)  Acc@5: 100.0000 (96.1267)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -1.0433  Acc@1: 81.2500 (79.4218)  Acc@5: 93.7500 (96.1356)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -1.0742  Acc@1: 81.2500 (79.4139)  Acc@5: 100.0000 (96.1442)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:49  Lr: 0.001875  Loss: 0.0400  Acc@1: 75.0000 (79.3627)  Acc@5: 100.0000 (96.1382)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -1.0354  Acc@1: 81.2500 (79.4059)  Acc@5: 100.0000 (96.1754)  time: 0.3497  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.9321  Acc@1: 81.2500 (79.4197)  Acc@5: 100.0000 (96.1975)  time: 0.3506  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -1.1709  Acc@1: 81.2500 (79.4402)  Acc@5: 100.0000 (96.1841)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.5907  Acc@1: 75.0000 (79.3216)  Acc@5: 93.7500 (96.1917)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.8502  Acc@1: 68.7500 (79.2741)  Acc@5: 100.0000 (96.2061)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -1.1858  Acc@1: 75.0000 (79.2345)  Acc@5: 100.0000 (96.2269)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -1.1117  Acc@1: 75.0000 (79.2293)  Acc@5: 93.7500 (96.2137)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.8386  Acc@1: 75.0000 (79.1844)  Acc@5: 93.7500 (96.2141)  time: 0.3503  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -1.3292  Acc@1: 81.2500 (79.2324)  Acc@5: 93.7500 (96.1948)  time: 0.3505  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -1.4042  Acc@1: 81.2500 (79.2794)  Acc@5: 93.7500 (96.2019)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -1.2090  Acc@1: 81.2500 (79.3061)  Acc@5: 100.0000 (96.2152)  time: 0.3504  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.8079  Acc@1: 81.2500 (79.3451)  Acc@5: 100.0000 (96.2029)  time: 0.3490  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.5500  Acc@1: 81.2500 (79.3264)  Acc@5: 93.7500 (96.2033)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1000/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -1.3755  Acc@1: 81.2500 (79.3581)  Acc@5: 100.0000 (96.2038)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.8901  Acc@1: 81.2500 (79.3769)  Acc@5: 100.0000 (96.1919)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.9351  Acc@1: 81.2500 (79.3524)  Acc@5: 93.7500 (96.2047)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -1.1158  Acc@1: 81.2500 (79.3465)  Acc@5: 100.0000 (96.2051)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.3777  Acc@1: 81.2500 (79.3468)  Acc@5: 93.7500 (96.1695)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.9372  Acc@1: 81.2500 (79.3589)  Acc@5: 93.7500 (96.1882)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -1.1041  Acc@1: 81.2500 (79.3827)  Acc@5: 93.7500 (96.1652)  time: 0.3506  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.7439  Acc@1: 81.2500 (79.3417)  Acc@5: 93.7500 (96.1543)  time: 0.3525  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.8493  Acc@1: 75.0000 (79.3074)  Acc@5: 93.7500 (96.1494)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.4773  Acc@1: 75.0000 (79.2621)  Acc@5: 100.0000 (96.1503)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.8324  Acc@1: 75.0000 (79.2518)  Acc@5: 93.7500 (96.1172)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.7724  Acc@1: 75.0000 (79.2248)  Acc@5: 93.7500 (96.1127)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -1.0197  Acc@1: 75.0000 (79.2484)  Acc@5: 93.7500 (96.1307)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.8837  Acc@1: 87.5000 (79.2882)  Acc@5: 100.0000 (96.1207)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -1.1657  Acc@1: 81.2500 (79.2835)  Acc@5: 93.7500 (96.1273)  time: 0.3509  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -1.1988  Acc@1: 81.2500 (79.3658)  Acc@5: 100.0000 (96.1392)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -1.2742  Acc@1: 87.5000 (79.3820)  Acc@5: 100.0000 (96.1456)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1170/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.8689  Acc@1: 81.2500 (79.4086)  Acc@5: 93.7500 (96.1411)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.7331  Acc@1: 81.2500 (79.3872)  Acc@5: 93.7500 (96.1473)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.8683  Acc@1: 75.0000 (79.3713)  Acc@5: 100.0000 (96.1482)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.9976  Acc@1: 75.0000 (79.3922)  Acc@5: 100.0000 (96.1595)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.9858  Acc@1: 81.2500 (79.3714)  Acc@5: 100.0000 (96.1654)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -1.2386  Acc@1: 81.2500 (79.4021)  Acc@5: 93.7500 (96.1712)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -1.2984  Acc@1: 81.2500 (79.4121)  Acc@5: 100.0000 (96.1921)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.6893  Acc@1: 81.2500 (79.4067)  Acc@5: 100.0000 (96.1926)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -1.4688  Acc@1: 81.2500 (79.4215)  Acc@5: 100.0000 (96.2030)  time: 0.3497  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -1.1058  Acc@1: 75.0000 (79.4062)  Acc@5: 100.0000 (96.2282)  time: 0.3505  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.4916  Acc@1: 75.0000 (79.3666)  Acc@5: 100.0000 (96.2333)  time: 0.3507  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -1.1154  Acc@1: 75.0000 (79.3813)  Acc@5: 100.0000 (96.2334)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -1.2370  Acc@1: 81.2500 (79.4249)  Acc@5: 100.0000 (96.2432)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.9721  Acc@1: 81.2500 (79.4293)  Acc@5: 93.7500 (96.2337)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.8144  Acc@1: 75.0000 (79.4003)  Acc@5: 93.7500 (96.2386)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.7539  Acc@1: 75.0000 (79.4048)  Acc@5: 100.0000 (96.2434)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.6887  Acc@1: 81.2500 (79.4187)  Acc@5: 100.0000 (96.2481)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1340/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.9892  Acc@1: 87.5000 (79.4603)  Acc@5: 100.0000 (96.2668)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.8803  Acc@1: 87.5000 (79.4828)  Acc@5: 100.0000 (96.2713)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6290  Acc@1: 81.2500 (79.4682)  Acc@5: 93.7500 (96.2757)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.9822  Acc@1: 75.0000 (79.4675)  Acc@5: 93.7500 (96.2710)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.4248  Acc@1: 75.0000 (79.4216)  Acc@5: 93.7500 (96.2527)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.8970  Acc@1: 75.0000 (79.4393)  Acc@5: 93.7500 (96.2572)  time: 0.3449  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.3401  Acc@1: 81.2500 (79.4299)  Acc@5: 100.0000 (96.2616)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -1.3177  Acc@1: 81.2500 (79.5004)  Acc@5: 100.0000 (96.2792)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -1.4101  Acc@1: 87.5000 (79.5171)  Acc@5: 100.0000 (96.2834)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.9560  Acc@1: 81.2500 (79.5510)  Acc@5: 100.0000 (96.3007)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.9611  Acc@1: 81.2500 (79.5715)  Acc@5: 100.0000 (96.2960)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.8507  Acc@1: 81.2500 (79.5960)  Acc@5: 100.0000 (96.3043)  time: 0.3488  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -1.0007  Acc@1: 81.2500 (79.5859)  Acc@5: 100.0000 (96.3210)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.7717  Acc@1: 75.0000 (79.6057)  Acc@5: 100.0000 (96.3248)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.6126  Acc@1: 75.0000 (79.5831)  Acc@5: 93.7500 (96.3074)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -1.1381  Acc@1: 75.0000 (79.6026)  Acc@5: 93.7500 (96.3028)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -1.2294  Acc@1: 81.2500 (79.6386)  Acc@5: 93.7500 (96.2941)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1510/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.8413  Acc@1: 81.2500 (79.6575)  Acc@5: 93.7500 (96.2938)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.6307  Acc@1: 81.2500 (79.6639)  Acc@5: 93.7500 (96.2853)  time: 0.3528  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -1.2950  Acc@1: 81.2500 (79.6620)  Acc@5: 93.7500 (96.2769)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -1.1168  Acc@1: 81.2500 (79.6763)  Acc@5: 93.7500 (96.2687)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.8145  Acc@1: 81.2500 (79.6663)  Acc@5: 93.7500 (96.2645)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.9522  Acc@1: 75.0000 (79.6645)  Acc@5: 100.0000 (96.2724)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.8495  Acc@1: 81.2500 (79.6825)  Acc@5: 100.0000 (96.2683)  time: 0.3495  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -1.1231  Acc@1: 81.2500 (79.6885)  Acc@5: 100.0000 (96.2761)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.3779  Acc@1: 81.2500 (79.6983)  Acc@5: 93.7500 (96.2720)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.7194  Acc@1: 81.2500 (79.7041)  Acc@5: 93.7500 (96.2758)  time: 0.3480  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -1.3280  Acc@1: 87.5000 (79.7331)  Acc@5: 100.0000 (96.2834)  time: 0.3533  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -1.0121  Acc@1: 87.5000 (79.7424)  Acc@5: 100.0000 (96.2832)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.4427  Acc@1: 75.0000 (79.6789)  Acc@5: 93.7500 (96.2638)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -1.1650  Acc@1: 75.0000 (79.6923)  Acc@5: 93.7500 (96.2637)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.8679  Acc@1: 81.2500 (79.6941)  Acc@5: 93.7500 (96.2561)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.5946  Acc@1: 81.2500 (79.6997)  Acc@5: 93.7500 (96.2635)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.9967  Acc@1: 81.2500 (79.7165)  Acc@5: 100.0000 (96.2635)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -1.1185  Acc@1: 81.2500 (79.7145)  Acc@5: 93.7500 (96.2671)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.9917  Acc@1: 75.0000 (79.7124)  Acc@5: 100.0000 (96.2633)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.8007  Acc@1: 75.0000 (79.7288)  Acc@5: 93.7500 (96.2559)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.8925  Acc@1: 81.2500 (79.7268)  Acc@5: 93.7500 (96.2558)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.5401  Acc@1: 81.2500 (79.7102)  Acc@5: 93.7500 (96.2594)  time: 0.3460  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.9631  Acc@1: 81.2500 (79.7227)  Acc@5: 93.7500 (96.2522)  time: 0.3457  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.9233  Acc@1: 81.2500 (79.7171)  Acc@5: 93.7500 (96.2342)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -1.1358  Acc@1: 81.2500 (79.7187)  Acc@5: 100.0000 (96.2450)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.4279  Acc@1: 81.2500 (79.7132)  Acc@5: 100.0000 (96.2379)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -1.1562  Acc@1: 75.0000 (79.6972)  Acc@5: 93.7500 (96.2380)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.5220  Acc@1: 81.2500 (79.7059)  Acc@5: 93.7500 (96.2416)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -1.0867  Acc@1: 81.2500 (79.7320)  Acc@5: 100.0000 (96.2486)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.7130  Acc@1: 81.2500 (79.7300)  Acc@5: 100.0000 (96.2486)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -1.2028  Acc@1: 81.2500 (79.7557)  Acc@5: 100.0000 (96.2624)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.7308  Acc@1: 87.5000 (79.7776)  Acc@5: 100.0000 (96.2727)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -1.1656  Acc@1: 81.2500 (79.7549)  Acc@5: 100.0000 (96.2520)  time: 0.3502  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -1.0682  Acc@1: 75.0000 (79.7698)  Acc@5: 93.7500 (96.2452)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -1.1688  Acc@1: 81.2500 (79.7778)  Acc@5: 93.7500 (96.2250)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1860/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.3670  Acc@1: 81.2500 (79.7656)  Acc@5: 93.7500 (96.2151)  time: 0.3498  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.7805  Acc@1: 75.0000 (79.7468)  Acc@5: 93.7500 (96.1919)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -1.1031  Acc@1: 75.0000 (79.7315)  Acc@5: 93.7500 (96.1855)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.7651  Acc@1: 75.0000 (79.7197)  Acc@5: 93.7500 (96.1859)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.3260  Acc@1: 81.2500 (79.7015)  Acc@5: 100.0000 (96.1895)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.4569  Acc@1: 75.0000 (79.6736)  Acc@5: 100.0000 (96.1833)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.6136  Acc@1: 75.0000 (79.6753)  Acc@5: 93.7500 (96.1869)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.5669  Acc@1: 81.2500 (79.6640)  Acc@5: 93.7500 (96.1775)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -1.1090  Acc@1: 81.2500 (79.6883)  Acc@5: 93.7500 (96.1875)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.6185  Acc@1: 81.2500 (79.7027)  Acc@5: 100.0000 (96.1879)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.8117  Acc@1: 81.2500 (79.7106)  Acc@5: 100.0000 (96.1850)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.9399  Acc@1: 75.0000 (79.6772)  Acc@5: 100.0000 (96.1885)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.8458  Acc@1: 87.5000 (79.7135)  Acc@5: 100.0000 (96.1951)  time: 0.3532  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.7138  Acc@1: 87.5000 (79.7338)  Acc@5: 100.0000 (96.1891)  time: 0.3512  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.7627  Acc@1: 81.2500 (79.7351)  Acc@5: 100.0000 (96.2019)  time: 0.3547  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.8772  Acc@1: 81.2500 (79.7333)  Acc@5: 100.0000 (96.2084)  time: 0.3546  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.9604  Acc@1: 81.2500 (79.7347)  Acc@5: 100.0000 (96.2086)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -1.0897  Acc@1: 81.2500 (79.7606)  Acc@5: 93.7500 (96.2088)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -1.1735  Acc@1: 81.2500 (79.7740)  Acc@5: 100.0000 (96.2120)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.5373  Acc@1: 81.2500 (79.7538)  Acc@5: 93.7500 (96.1939)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -1.1369  Acc@1: 75.0000 (79.7550)  Acc@5: 93.7500 (96.1972)  time: 0.3491  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -0.6510  Acc@1: 81.2500 (79.7682)  Acc@5: 100.0000 (96.1945)  time: 0.3507  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -1.4063  Acc@1: 81.2500 (79.7784)  Acc@5: 100.0000 (96.2007)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.9436  Acc@1: 87.5000 (79.7854)  Acc@5: 93.7500 (96.1920)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.7577  Acc@1: 81.2500 (79.7626)  Acc@5: 93.7500 (96.1893)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.7356  Acc@1: 81.2500 (79.7756)  Acc@5: 93.7500 (96.1896)  time: 0.3497  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -1.2324  Acc@1: 87.5000 (79.7914)  Acc@5: 100.0000 (96.1987)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.6577  Acc@1: 81.2500 (79.7982)  Acc@5: 100.0000 (96.2019)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.7685  Acc@1: 81.2500 (79.7992)  Acc@5: 100.0000 (96.2050)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.8566  Acc@1: 81.2500 (79.8204)  Acc@5: 93.7500 (96.1994)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.9348  Acc@1: 81.2500 (79.8068)  Acc@5: 93.7500 (96.2026)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.8252  Acc@1: 81.2500 (79.8307)  Acc@5: 93.7500 (96.2057)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.4110  Acc@1: 81.2500 (79.8258)  Acc@5: 100.0000 (96.2030)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.7966  Acc@1: 75.0000 (79.8152)  Acc@5: 100.0000 (96.1947)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -1.2145  Acc@1: 81.2500 (79.8160)  Acc@5: 93.7500 (96.1949)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -1.0141  Acc@1: 81.2500 (79.8055)  Acc@5: 93.7500 (96.1923)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.5516  Acc@1: 81.2500 (79.8064)  Acc@5: 93.7500 (96.1898)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -1.0682  Acc@1: 81.2500 (79.8297)  Acc@5: 100.0000 (96.1900)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.9716  Acc@1: 81.2500 (79.8221)  Acc@5: 100.0000 (96.1987)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.7757  Acc@1: 75.0000 (79.8118)  Acc@5: 100.0000 (96.1961)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.5966  Acc@1: 75.0000 (79.8071)  Acc@5: 100.0000 (96.2019)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.5506  Acc@1: 81.2500 (79.8244)  Acc@5: 100.0000 (96.1994)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.4930  Acc@1: 81.2500 (79.8142)  Acc@5: 100.0000 (96.2051)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -1.0937  Acc@1: 81.2500 (79.8123)  Acc@5: 93.7500 (96.2025)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -1.1871  Acc@1: 81.2500 (79.8158)  Acc@5: 93.7500 (96.2109)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -0.6033  Acc@1: 81.2500 (79.8166)  Acc@5: 100.0000 (96.2138)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.4739  Acc@1: 75.0000 (79.7905)  Acc@5: 93.7500 (96.2058)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.8637  Acc@1: 75.0000 (79.7699)  Acc@5: 93.7500 (96.2007)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.9333  Acc@1: 81.2500 (79.7736)  Acc@5: 93.7500 (96.2009)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.9050  Acc@1: 81.2500 (79.7560)  Acc@5: 93.7500 (96.1931)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.8375  Acc@1: 81.2500 (79.7570)  Acc@5: 100.0000 (96.1960)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -1.1553  Acc@1: 81.2500 (79.7527)  Acc@5: 100.0000 (96.1936)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -1.0464  Acc@1: 81.2500 (79.7590)  Acc@5: 93.7500 (96.1991)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.4367  Acc@1: 81.2500 (79.7496)  Acc@5: 100.0000 (96.2071)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.8840  Acc@1: 81.2500 (79.7636)  Acc@5: 100.0000 (96.2099)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.5881  Acc@1: 81.2500 (79.7750)  Acc@5: 100.0000 (96.2153)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -0.7658  Acc@1: 81.2500 (79.7888)  Acc@5: 100.0000 (96.2180)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.6248  Acc@1: 81.2500 (79.7717)  Acc@5: 100.0000 (96.2207)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.8974  Acc@1: 81.2500 (79.7752)  Acc@5: 100.0000 (96.2362)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.8657  Acc@1: 75.0000 (79.7634)  Acc@5: 100.0000 (96.2413)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.8168  Acc@1: 81.2500 (79.7796)  Acc@5: 100.0000 (96.2414)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.9564  Acc@1: 81.2500 (79.7931)  Acc@5: 93.7500 (96.2439)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -1.1957  Acc@1: 81.2500 (79.7939)  Acc@5: 100.0000 (96.2440)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -1.1589  Acc@1: 81.2500 (79.8073)  Acc@5: 100.0000 (96.2515)  time: 0.3530  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.8931  Acc@1: 81.2500 (79.8206)  Acc@5: 100.0000 (96.2590)  time: 0.3543  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.7716  Acc@1: 81.2500 (79.8138)  Acc@5: 100.0000 (96.2515)  time: 0.3548  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -1.3066  Acc@1: 75.0000 (79.7922)  Acc@5: 100.0000 (96.2465)  time: 0.3575  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.9678  Acc@1: 75.0000 (79.7955)  Acc@5: 93.7500 (96.2441)  time: 0.3534  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -1.1106  Acc@1: 81.2500 (79.8062)  Acc@5: 93.7500 (96.2367)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -1.2314  Acc@1: 87.5000 (79.8265)  Acc@5: 93.7500 (96.2392)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -1.0326  Acc@1: 87.5000 (79.8419)  Acc@5: 100.0000 (96.2441)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.8455  Acc@1: 87.5000 (79.8400)  Acc@5: 100.0000 (96.2466)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -1.1280  Acc@1: 81.2500 (79.8431)  Acc@5: 93.7500 (96.2490)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.9074  Acc@1: 81.2500 (79.8389)  Acc@5: 100.0000 (96.2539)  time: 0.3510  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -1.2850  Acc@1: 81.2500 (79.8443)  Acc@5: 100.0000 (96.2538)  time: 0.3503  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.9802  Acc@1: 81.2500 (79.8521)  Acc@5: 93.7500 (96.2490)  time: 0.3507  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6070  Acc@1: 81.2500 (79.8574)  Acc@5: 93.7500 (96.2490)  time: 0.3529  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.7961  Acc@1: 81.2500 (79.8651)  Acc@5: 93.7500 (96.2490)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.5231  Acc@1: 81.2500 (79.8727)  Acc@5: 93.7500 (96.2443)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.9657  Acc@1: 81.2500 (79.8614)  Acc@5: 100.0000 (96.2514)  time: 0.3508  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.6108  Acc@1: 81.2500 (79.8595)  Acc@5: 100.0000 (96.2514)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.9395  Acc@1: 81.2500 (79.8460)  Acc@5: 93.7500 (96.2467)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.7142  Acc@1: 81.2500 (79.8419)  Acc@5: 100.0000 (96.2537)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -1.2034  Acc@1: 81.2500 (79.8472)  Acc@5: 100.0000 (96.2537)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.5859  Acc@1: 81.2500 (79.8362)  Acc@5: 100.0000 (96.2491)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -1.1300  Acc@1: 81.2500 (79.8299)  Acc@5: 93.7500 (96.2468)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -1.1953  Acc@1: 81.2500 (79.8351)  Acc@5: 100.0000 (96.2537)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.6480  Acc@1: 81.2500 (79.8448)  Acc@5: 93.7500 (96.2445)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.5322  Acc@1: 81.2500 (79.8522)  Acc@5: 93.7500 (96.2445)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -1.0998  Acc@1: 81.2500 (79.8619)  Acc@5: 93.7500 (96.2423)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.7642  Acc@1: 81.2500 (79.8578)  Acc@5: 93.7500 (96.2446)  time: 0.3513  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.6029  Acc@1: 81.2500 (79.8538)  Acc@5: 100.0000 (96.2491)  time: 0.3538  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -1.0462  Acc@1: 75.0000 (79.8409)  Acc@5: 100.0000 (96.2446)  time: 0.3528  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -1.0215  Acc@1: 81.2500 (79.8482)  Acc@5: 93.7500 (96.2424)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.4329  Acc@1: 81.2500 (79.8487)  Acc@5: 93.7500 (96.2402)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.9567  Acc@1: 81.2500 (79.8493)  Acc@5: 100.0000 (96.2447)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.9923  Acc@1: 75.0000 (79.8321)  Acc@5: 100.0000 (96.2403)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.8237  Acc@1: 75.0000 (79.8150)  Acc@5: 93.7500 (96.2447)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -1.0826  Acc@1: 81.2500 (79.8266)  Acc@5: 100.0000 (96.2513)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.6413  Acc@1: 81.2500 (79.8360)  Acc@5: 100.0000 (96.2513)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -1.2774  Acc@1: 81.2500 (79.8388)  Acc@5: 93.7500 (96.2513)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -1.2950  Acc@1: 87.5000 (79.8742)  Acc@5: 93.7500 (96.2557)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -1.1346  Acc@1: 87.5000 (79.8724)  Acc@5: 100.0000 (96.2600)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.6787  Acc@1: 81.2500 (79.8750)  Acc@5: 93.7500 (96.2535)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -1.2196  Acc@1: 81.2500 (79.8819)  Acc@5: 100.0000 (96.2599)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.6558  Acc@1: 81.2500 (79.8802)  Acc@5: 100.0000 (96.2534)  time: 0.3541  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.9489  Acc@1: 81.2500 (79.8934)  Acc@5: 93.7500 (96.2470)  time: 0.3542  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.3441  Acc@1: 81.2500 (79.8810)  Acc@5: 93.7500 (96.2406)  time: 0.3537  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.7281  Acc@1: 81.2500 (79.8835)  Acc@5: 93.7500 (96.2428)  time: 0.3498  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.1560  Acc@1: 81.2500 (79.8966)  Acc@5: 100.0000 (96.2492)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.8320  Acc@1: 81.2500 (79.8949)  Acc@5: 100.0000 (96.2534)  time: 0.3517  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.1191  Acc@1: 81.2500 (79.8973)  Acc@5: 100.0000 (96.2513)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.7330  Acc@1: 81.2500 (79.8809)  Acc@5: 100.0000 (96.2575)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.2521  Acc@1: 81.2500 (79.8813)  Acc@5: 100.0000 (96.2596)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -1.0518  Acc@1: 81.2500 (79.8921)  Acc@5: 100.0000 (96.2575)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -1.3448  Acc@1: 87.5000 (79.9132)  Acc@5: 100.0000 (96.2616)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.7160  Acc@1: 81.2500 (79.9135)  Acc@5: 100.0000 (96.2616)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.8941  Acc@1: 81.2500 (79.9262)  Acc@5: 100.0000 (96.2636)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.9706  Acc@1: 81.2500 (79.9161)  Acc@5: 100.0000 (96.2656)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.5074  Acc@1: 81.2500 (79.9349)  Acc@5: 93.7500 (96.2594)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -1.0847  Acc@1: 87.5000 (79.9330)  Acc@5: 93.7500 (96.2635)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -1.2935  Acc@1: 81.2500 (79.9495)  Acc@5: 93.7500 (96.2573)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -1.3310  Acc@1: 87.5000 (79.9578)  Acc@5: 93.7500 (96.2553)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.7868  Acc@1: 87.5000 (79.9741)  Acc@5: 93.7500 (96.2593)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.1553  Acc@1: 87.5000 (79.9762)  Acc@5: 100.0000 (96.2613)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.8244  Acc@1: 87.5000 (80.0024)  Acc@5: 100.0000 (96.2653)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.6753  Acc@1: 81.2500 (80.0024)  Acc@5: 100.0000 (96.2632)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -1.1325  Acc@1: 81.2500 (79.9964)  Acc@5: 93.7500 (96.2532)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -1.1265  Acc@1: 81.2500 (80.0004)  Acc@5: 93.7500 (96.2532)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -1.0033  Acc@1: 81.2500 (79.9964)  Acc@5: 93.7500 (96.2512)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.9253  Acc@1: 81.2500 (80.0024)  Acc@5: 100.0000 (96.2591)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.0910  Acc@1: 81.2500 (80.0102)  Acc@5: 100.0000 (96.2689)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -1.0183  Acc@1: 81.2500 (80.0083)  Acc@5: 100.0000 (96.2767)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.9937  Acc@1: 81.2500 (80.0200)  Acc@5: 100.0000 (96.2766)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -1.1790  Acc@1: 81.2500 (80.0277)  Acc@5: 100.0000 (96.2785)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.6841  Acc@1: 81.2500 (80.0335)  Acc@5: 93.7500 (96.2745)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -1.0054  Acc@1: 81.2500 (80.0431)  Acc@5: 100.0000 (96.2803)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.9600  Acc@1: 81.2500 (80.0391)  Acc@5: 100.0000 (96.2802)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.3973  Acc@1: 75.0000 (80.0255)  Acc@5: 93.7500 (96.2704)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.8749  Acc@1: 75.0000 (80.0158)  Acc@5: 93.7500 (96.2704)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.6225  Acc@1: 75.0000 (80.0023)  Acc@5: 93.7500 (96.2588)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -1.2038  Acc@1: 75.0000 (79.9870)  Acc@5: 93.7500 (96.2492)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -1.0043  Acc@1: 75.0000 (79.9680)  Acc@5: 93.7500 (96.2511)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.0053  Acc@1: 75.0000 (79.9643)  Acc@5: 100.0000 (96.2492)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -1.0824  Acc@1: 81.2500 (79.9625)  Acc@5: 100.0000 (96.2473)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.4707  Acc@1: 81.2500 (79.9740)  Acc@5: 100.0000 (96.2511)  time: 0.3498  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.9245  Acc@1: 75.0000 (79.9496)  Acc@5: 100.0000 (96.2474)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.8860  Acc@1: 75.0000 (79.9497)  Acc@5: 93.7500 (96.2492)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.6755  Acc@1: 81.2500 (79.9424)  Acc@5: 93.7500 (96.2455)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6207  Acc@1: 81.2500 (79.9426)  Acc@5: 93.7500 (96.2511)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -1.2289  Acc@1: 81.2500 (79.9557)  Acc@5: 100.0000 (96.2548)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.0618  Acc@1: 81.2500 (79.9485)  Acc@5: 93.7500 (96.2530)  time: 0.3494  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.7421  Acc@1: 81.2500 (79.9542)  Acc@5: 93.7500 (96.2474)  time: 0.3498  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6863  Acc@1: 81.2500 (79.9395)  Acc@5: 93.7500 (96.2456)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.9608  Acc@1: 75.0000 (79.9269)  Acc@5: 93.7500 (96.2401)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.4762  Acc@1: 75.0000 (79.9289)  Acc@5: 100.0000 (96.2438)  time: 0.3516  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.5650  Acc@1: 81.2500 (79.9291)  Acc@5: 100.0000 (96.2493)  time: 0.3535  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.9633  Acc@1: 81.2500 (79.9293)  Acc@5: 100.0000 (96.2547)  time: 0.3520  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.2411  Acc@1: 81.2500 (79.9422)  Acc@5: 100.0000 (96.2584)  time: 0.3490  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -1.0559  Acc@1: 87.5000 (79.9460)  Acc@5: 100.0000 (96.2638)  time: 0.3505  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.1415  Acc@1: 81.2500 (79.9570)  Acc@5: 100.0000 (96.2691)  time: 0.3511  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -1.0000  Acc@1: 81.2500 (79.9607)  Acc@5: 100.0000 (96.2655)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.9524  Acc@1: 81.2500 (79.9609)  Acc@5: 93.7500 (96.2601)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.2571  Acc@1: 81.2500 (79.9807)  Acc@5: 100.0000 (96.2654)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0026  Acc@1: 87.5000 (79.9843)  Acc@5: 100.0000 (96.2600)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.8782  Acc@1: 81.2500 (79.9932)  Acc@5: 93.7500 (96.2617)  time: 0.3492  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6258  Acc@1: 81.2500 (79.9755)  Acc@5: 93.7500 (96.2617)  time: 0.3494  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -1.2524  Acc@1: 75.0000 (79.9720)  Acc@5: 93.7500 (96.2617)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2327  Acc@1: 81.2500 (79.9809)  Acc@5: 100.0000 (96.2669)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -1.3367  Acc@1: 81.2500 (79.9845)  Acc@5: 100.0000 (96.2651)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1116  Acc@1: 81.2500 (79.9863)  Acc@5: 100.0000 (96.2651)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.7806  Acc@1: 81.2500 (79.9846)  Acc@5: 100.0000 (96.2686)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.9883  Acc@1: 81.2500 (79.9969)  Acc@5: 100.0000 (96.2650)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.7034  Acc@1: 81.2500 (79.9951)  Acc@5: 100.0000 (96.2667)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.0824  Acc@1: 81.2500 (79.9899)  Acc@5: 100.0000 (96.2719)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.6630  Acc@1: 81.2500 (80.0003)  Acc@5: 100.0000 (96.2753)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8289  Acc@1: 81.2500 (80.0021)  Acc@5: 93.7500 (96.2735)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7242  Acc@1: 81.2500 (79.9935)  Acc@5: 100.0000 (96.2769)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.8696  Acc@1: 75.0000 (79.9849)  Acc@5: 100.0000 (96.2785)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.0110  Acc@1: 75.0000 (79.9832)  Acc@5: 93.7500 (96.2801)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.2552  Acc@1: 75.0000 (79.9696)  Acc@5: 93.7500 (96.2800)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7357  Acc@1: 75.0000 (79.9731)  Acc@5: 93.7500 (96.2783)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9344  Acc@1: 81.2500 (79.9749)  Acc@5: 100.0000 (96.2833)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -1.3639  Acc@1: 81.2500 (79.9902)  Acc@5: 100.0000 (96.2849)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9574  Acc@1: 81.2500 (79.9801)  Acc@5: 93.7500 (96.2747)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.7110  Acc@1: 75.0000 (79.9683)  Acc@5: 93.7500 (96.2763)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7368  Acc@1: 75.0000 (79.9684)  Acc@5: 100.0000 (96.2812)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.9679  Acc@1: 81.2500 (79.9869)  Acc@5: 100.0000 (96.2879)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7613  Acc@1: 81.2500 (79.9886)  Acc@5: 100.0000 (96.2911)  time: 0.3474  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.2195  Acc@1: 81.2500 (79.9967)  Acc@5: 100.0000 (96.2900)  time: 0.3503  data: 0.0018  max mem: 2500
Train: Epoch[2/5] Total time: 0:21:49 (0.3491 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 119984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.2195  Acc@1: 81.2500 (79.9967)  Acc@5: 100.0000 (96.2900)
Train: Epoch[3/5]  [   0/3750]  eta: 0:53:38  Lr: 0.001875  Loss: -0.7723  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8582  data: 0.5118  max mem: 2500
Train: Epoch[3/5]  [  10/3750]  eta: 0:24:33  Lr: 0.001875  Loss: -1.4221  Acc@1: 81.2500 (80.1136)  Acc@5: 93.7500 (94.8864)  time: 0.3940  data: 0.0475  max mem: 2500
Train: Epoch[3/5]  [  20/3750]  eta: 0:23:07  Lr: 0.001875  Loss: -0.7136  Acc@1: 81.2500 (80.9524)  Acc@5: 93.7500 (94.3452)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:38  Lr: 0.001875  Loss: -1.0996  Acc@1: 81.2500 (81.0484)  Acc@5: 93.7500 (94.9597)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:22  Lr: 0.001875  Loss: -1.2062  Acc@1: 81.2500 (80.7927)  Acc@5: 100.0000 (95.5793)  time: 0.3513  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [  50/3750]  eta: 0:22:10  Lr: 0.001875  Loss: -0.7211  Acc@1: 81.2500 (81.6176)  Acc@5: 100.0000 (95.8333)  time: 0.3512  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [  60/3750]  eta: 0:22:00  Lr: 0.001875  Loss: -0.9989  Acc@1: 87.5000 (81.9672)  Acc@5: 100.0000 (95.6967)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -1.4148  Acc@1: 87.5000 (83.0106)  Acc@5: 93.7500 (95.8627)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.8680  Acc@1: 81.2500 (82.4846)  Acc@5: 100.0000 (95.9105)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.9724  Acc@1: 75.0000 (82.4176)  Acc@5: 100.0000 (96.2225)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.7991  Acc@1: 81.2500 (82.6114)  Acc@5: 100.0000 (96.2871)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -1.1268  Acc@1: 87.5000 (82.9392)  Acc@5: 100.0000 (96.4527)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -1.2565  Acc@1: 87.5000 (82.7996)  Acc@5: 100.0000 (96.5909)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -0.8549  Acc@1: 81.2500 (82.8721)  Acc@5: 100.0000 (96.5649)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -1.2243  Acc@1: 81.2500 (82.7571)  Acc@5: 100.0000 (96.6312)  time: 0.3484  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.9593  Acc@1: 81.2500 (82.7401)  Acc@5: 100.0000 (96.5232)  time: 0.3484  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -1.1005  Acc@1: 81.2500 (82.7252)  Acc@5: 93.7500 (96.5450)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.2554  Acc@1: 81.2500 (82.4196)  Acc@5: 93.7500 (96.3816)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.8471  Acc@1: 81.2500 (82.6312)  Acc@5: 93.7500 (96.4779)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.8281  Acc@1: 87.5000 (82.5262)  Acc@5: 93.7500 (96.3678)  time: 0.3535  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.9502  Acc@1: 81.2500 (82.3694)  Acc@5: 93.7500 (96.4552)  time: 0.3530  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.5134  Acc@1: 75.0000 (82.1386)  Acc@5: 93.7500 (96.3566)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -1.1859  Acc@1: 81.2500 (82.1267)  Acc@5: 93.7500 (96.2952)  time: 0.3546  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.9283  Acc@1: 75.0000 (81.7911)  Acc@5: 93.7500 (96.1580)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -1.2034  Acc@1: 75.0000 (81.7168)  Acc@5: 93.7500 (96.1618)  time: 0.3506  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -1.0745  Acc@1: 81.2500 (81.8227)  Acc@5: 100.0000 (96.1653)  time: 0.3505  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -1.0881  Acc@1: 87.5000 (81.9684)  Acc@5: 100.0000 (96.2883)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.4647  Acc@1: 81.2500 (81.9188)  Acc@5: 100.0000 (96.2869)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -1.0931  Acc@1: 81.2500 (81.8728)  Acc@5: 100.0000 (96.3301)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.8935  Acc@1: 81.2500 (81.8943)  Acc@5: 100.0000 (96.3918)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -1.0983  Acc@1: 87.5000 (81.8937)  Acc@5: 100.0000 (96.4286)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -1.1339  Acc@1: 87.5000 (81.9333)  Acc@5: 100.0000 (96.4630)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 320/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -1.4158  Acc@1: 81.2500 (81.9120)  Acc@5: 93.7500 (96.3785)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 330/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.6039  Acc@1: 75.0000 (81.7221)  Acc@5: 93.7500 (96.3180)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -1.3018  Acc@1: 75.0000 (81.7999)  Acc@5: 93.7500 (96.3160)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -1.1340  Acc@1: 81.2500 (81.6952)  Acc@5: 100.0000 (96.3319)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.7856  Acc@1: 81.2500 (81.7348)  Acc@5: 100.0000 (96.3470)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -1.1210  Acc@1: 81.2500 (81.7722)  Acc@5: 100.0000 (96.3780)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.8159  Acc@1: 81.2500 (81.6273)  Acc@5: 100.0000 (96.3911)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.8507  Acc@1: 75.0000 (81.5857)  Acc@5: 93.7500 (96.2756)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.9399  Acc@1: 75.0000 (81.5150)  Acc@5: 93.7500 (96.2594)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.7298  Acc@1: 75.0000 (81.4173)  Acc@5: 93.7500 (96.2591)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.7201  Acc@1: 81.2500 (81.2797)  Acc@5: 93.7500 (96.2589)  time: 0.3550  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.7609  Acc@1: 81.2500 (81.3805)  Acc@5: 93.7500 (96.2587)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -1.1025  Acc@1: 81.2500 (81.4201)  Acc@5: 100.0000 (96.2727)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.9033  Acc@1: 81.2500 (81.4717)  Acc@5: 100.0000 (96.3276)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -0.9382  Acc@1: 87.5000 (81.5483)  Acc@5: 100.0000 (96.3124)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -1.2644  Acc@1: 81.2500 (81.4756)  Acc@5: 100.0000 (96.3508)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.8707  Acc@1: 81.2500 (81.5229)  Acc@5: 100.0000 (96.3747)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 490/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -1.2448  Acc@1: 87.5000 (81.6955)  Acc@5: 93.7500 (96.3722)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.7750  Acc@1: 81.2500 (81.6617)  Acc@5: 93.7500 (96.3573)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.9284  Acc@1: 81.2500 (81.5802)  Acc@5: 93.7500 (96.3674)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.9587  Acc@1: 81.2500 (81.4779)  Acc@5: 93.7500 (96.3052)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.6072  Acc@1: 81.2500 (81.4854)  Acc@5: 93.7500 (96.3041)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -1.2285  Acc@1: 81.2500 (81.4464)  Acc@5: 93.7500 (96.2916)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.9719  Acc@1: 81.2500 (81.4315)  Acc@5: 93.7500 (96.2795)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -1.0954  Acc@1: 75.0000 (81.3948)  Acc@5: 93.7500 (96.2455)  time: 0.3455  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.5984  Acc@1: 81.2500 (81.4032)  Acc@5: 100.0000 (96.2675)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -1.1149  Acc@1: 81.2500 (81.3361)  Acc@5: 100.0000 (96.2457)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -1.0616  Acc@1: 81.2500 (81.3346)  Acc@5: 100.0000 (96.2775)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.5266  Acc@1: 81.2500 (81.2916)  Acc@5: 100.0000 (96.2978)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.8881  Acc@1: 75.0000 (81.2398)  Acc@5: 100.0000 (96.3380)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -1.3277  Acc@1: 81.2500 (81.2601)  Acc@5: 100.0000 (96.3567)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.9691  Acc@1: 87.5000 (81.2995)  Acc@5: 100.0000 (96.3649)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.8518  Acc@1: 81.2500 (81.2988)  Acc@5: 93.7500 (96.3241)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -1.1453  Acc@1: 81.2500 (81.2692)  Acc@5: 100.0000 (96.3326)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 660/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.8784  Acc@1: 81.2500 (81.3162)  Acc@5: 100.0000 (96.3597)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.9316  Acc@1: 87.5000 (81.2966)  Acc@5: 100.0000 (96.3767)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -1.1311  Acc@1: 75.0000 (81.2408)  Acc@5: 100.0000 (96.3748)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -1.0764  Acc@1: 81.2500 (81.2319)  Acc@5: 100.0000 (96.3911)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -1.4160  Acc@1: 81.2500 (81.2767)  Acc@5: 100.0000 (96.3534)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.8775  Acc@1: 81.2500 (81.1973)  Acc@5: 100.0000 (96.3344)  time: 0.3480  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.6445  Acc@1: 75.0000 (81.1720)  Acc@5: 100.0000 (96.3159)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -1.1709  Acc@1: 81.2500 (81.1303)  Acc@5: 100.0000 (96.3150)  time: 0.3513  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.8397  Acc@1: 81.2500 (81.0729)  Acc@5: 93.7500 (96.2972)  time: 0.3525  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -1.2779  Acc@1: 81.2500 (81.1834)  Acc@5: 100.0000 (96.3382)  time: 0.3537  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -1.2239  Acc@1: 87.5000 (81.1925)  Acc@5: 100.0000 (96.3617)  time: 0.3528  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -1.0014  Acc@1: 81.2500 (81.2095)  Acc@5: 100.0000 (96.3765)  time: 0.3511  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -1.2049  Acc@1: 81.2500 (81.2900)  Acc@5: 100.0000 (96.3908)  time: 0.3497  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.6459  Acc@1: 81.2500 (81.2895)  Acc@5: 100.0000 (96.3812)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -1.1969  Acc@1: 81.2500 (81.2656)  Acc@5: 93.7500 (96.3639)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.6366  Acc@1: 81.2500 (81.2731)  Acc@5: 93.7500 (96.3702)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -1.0224  Acc@1: 81.2500 (81.2652)  Acc@5: 93.7500 (96.3688)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 830/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.7831  Acc@1: 75.0000 (81.2124)  Acc@5: 100.0000 (96.4049)  time: 0.3502  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.4401  Acc@1: 75.0000 (81.1608)  Acc@5: 100.0000 (96.4031)  time: 0.3498  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.6610  Acc@1: 81.2500 (81.1766)  Acc@5: 100.0000 (96.4160)  time: 0.3490  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.9598  Acc@1: 81.2500 (81.1484)  Acc@5: 93.7500 (96.4141)  time: 0.3494  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.7944  Acc@1: 81.2500 (81.1352)  Acc@5: 93.7500 (96.4122)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.8864  Acc@1: 75.0000 (81.0868)  Acc@5: 100.0000 (96.4245)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.8185  Acc@1: 75.0000 (81.0466)  Acc@5: 100.0000 (96.4226)  time: 0.3544  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.2460  Acc@1: 75.0000 (81.0280)  Acc@5: 100.0000 (96.4484)  time: 0.3537  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -1.1149  Acc@1: 81.2500 (81.0510)  Acc@5: 100.0000 (96.4599)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -1.2028  Acc@1: 81.2500 (81.0803)  Acc@5: 100.0000 (96.4712)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -1.4214  Acc@1: 81.2500 (81.0553)  Acc@5: 100.0000 (96.4823)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.9530  Acc@1: 81.2500 (81.0507)  Acc@5: 100.0000 (96.4798)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.8365  Acc@1: 81.2500 (81.0660)  Acc@5: 93.7500 (96.4511)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.8405  Acc@1: 81.2500 (81.0939)  Acc@5: 93.7500 (96.4425)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -1.3146  Acc@1: 81.2500 (81.0891)  Acc@5: 100.0000 (96.4470)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -1.2505  Acc@1: 81.2500 (81.0461)  Acc@5: 100.0000 (96.4513)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.9411  Acc@1: 81.2500 (81.0734)  Acc@5: 100.0000 (96.4493)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1000/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.9685  Acc@1: 87.5000 (81.0564)  Acc@5: 93.7500 (96.4286)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.8677  Acc@1: 81.2500 (81.0460)  Acc@5: 93.7500 (96.4144)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.4824  Acc@1: 81.2500 (81.0602)  Acc@5: 100.0000 (96.4251)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -1.0781  Acc@1: 81.2500 (81.0742)  Acc@5: 93.7500 (96.4173)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.9064  Acc@1: 81.2500 (81.0579)  Acc@5: 93.7500 (96.4037)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.8620  Acc@1: 81.2500 (81.0419)  Acc@5: 93.7500 (96.3903)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -1.1664  Acc@1: 81.2500 (81.0144)  Acc@5: 100.0000 (96.4126)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.9695  Acc@1: 81.2500 (81.0282)  Acc@5: 100.0000 (96.4052)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -1.0800  Acc@1: 81.2500 (81.0476)  Acc@5: 93.7500 (96.4154)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -1.1115  Acc@1: 81.2500 (81.0438)  Acc@5: 100.0000 (96.4138)  time: 0.3500  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -1.0907  Acc@1: 81.2500 (81.0627)  Acc@5: 100.0000 (96.4180)  time: 0.3484  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -1.0073  Acc@1: 81.2500 (81.0419)  Acc@5: 100.0000 (96.4334)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5986  Acc@1: 81.2500 (81.0660)  Acc@5: 100.0000 (96.4373)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.6469  Acc@1: 81.2500 (81.0897)  Acc@5: 100.0000 (96.4467)  time: 0.3501  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.9394  Acc@1: 81.2500 (81.0802)  Acc@5: 100.0000 (96.4614)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -1.2917  Acc@1: 75.0000 (81.0545)  Acc@5: 100.0000 (96.4705)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -1.2146  Acc@1: 75.0000 (81.0724)  Acc@5: 100.0000 (96.4632)  time: 0.3491  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1170/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.5432  Acc@1: 81.2500 (81.0685)  Acc@5: 93.7500 (96.4347)  time: 0.3500  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -1.1614  Acc@1: 81.2500 (81.0701)  Acc@5: 100.0000 (96.4543)  time: 0.3505  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -1.2649  Acc@1: 81.2500 (81.0821)  Acc@5: 100.0000 (96.4421)  time: 0.3505  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -1.2316  Acc@1: 87.5000 (81.1251)  Acc@5: 93.7500 (96.4457)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.8902  Acc@1: 87.5000 (81.1158)  Acc@5: 100.0000 (96.4595)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -1.3524  Acc@1: 87.5000 (81.1630)  Acc@5: 100.0000 (96.4732)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -1.1342  Acc@1: 81.2500 (81.1383)  Acc@5: 100.0000 (96.4764)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -1.1791  Acc@1: 75.0000 (81.1342)  Acc@5: 93.7500 (96.4595)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.9742  Acc@1: 75.0000 (81.1001)  Acc@5: 93.7500 (96.4528)  time: 0.3499  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -1.0786  Acc@1: 81.2500 (81.1063)  Acc@5: 100.0000 (96.4661)  time: 0.3494  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -1.2042  Acc@1: 81.2500 (81.0926)  Acc@5: 100.0000 (96.4546)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -1.2177  Acc@1: 81.2500 (81.0890)  Acc@5: 100.0000 (96.4530)  time: 0.3549  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.9343  Acc@1: 81.2500 (81.0999)  Acc@5: 100.0000 (96.4562)  time: 0.3534  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -1.1187  Acc@1: 81.2500 (81.0867)  Acc@5: 100.0000 (96.4643)  time: 0.3525  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.7483  Acc@1: 87.5000 (81.1213)  Acc@5: 100.0000 (96.4769)  time: 0.3525  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.6061  Acc@1: 87.5000 (81.1128)  Acc@5: 100.0000 (96.4705)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.8294  Acc@1: 81.2500 (81.1138)  Acc@5: 100.0000 (96.4782)  time: 0.3472  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1340/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -1.1240  Acc@1: 81.2500 (81.1475)  Acc@5: 100.0000 (96.4765)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.6762  Acc@1: 87.5000 (81.1806)  Acc@5: 93.7500 (96.4702)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.5509  Acc@1: 81.2500 (81.1719)  Acc@5: 93.7500 (96.4686)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.7350  Acc@1: 87.5000 (81.2181)  Acc@5: 100.0000 (96.4761)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.6952  Acc@1: 81.2500 (81.2274)  Acc@5: 100.0000 (96.4790)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -1.1307  Acc@1: 81.2500 (81.2320)  Acc@5: 100.0000 (96.4908)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -1.0078  Acc@1: 75.0000 (81.1875)  Acc@5: 100.0000 (96.4891)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.9707  Acc@1: 75.0000 (81.1968)  Acc@5: 93.7500 (96.4918)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.8495  Acc@1: 87.5000 (81.2192)  Acc@5: 93.7500 (96.4901)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.7327  Acc@1: 87.5000 (81.2456)  Acc@5: 93.7500 (96.4797)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -1.1172  Acc@1: 87.5000 (81.2500)  Acc@5: 93.7500 (96.4825)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.6502  Acc@1: 75.0000 (81.2457)  Acc@5: 100.0000 (96.4895)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9721  Acc@1: 81.2500 (81.2757)  Acc@5: 100.0000 (96.4921)  time: 0.3486  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.1465  Acc@1: 81.2500 (81.2585)  Acc@5: 100.0000 (96.4990)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -1.1435  Acc@1: 81.2500 (81.2584)  Acc@5: 100.0000 (96.5184)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -1.0552  Acc@1: 81.2500 (81.2584)  Acc@5: 100.0000 (96.5208)  time: 0.3569  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.9804  Acc@1: 81.2500 (81.2750)  Acc@5: 100.0000 (96.5148)  time: 0.3552  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -1.3493  Acc@1: 81.2500 (81.2790)  Acc@5: 100.0000 (96.5172)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.7838  Acc@1: 81.2500 (81.2788)  Acc@5: 100.0000 (96.5237)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.6357  Acc@1: 81.2500 (81.2949)  Acc@5: 93.7500 (96.5219)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.7802  Acc@1: 81.2500 (81.3189)  Acc@5: 100.0000 (96.5323)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -1.2302  Acc@1: 81.2500 (81.3387)  Acc@5: 100.0000 (96.5184)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.9880  Acc@1: 81.2500 (81.3181)  Acc@5: 93.7500 (96.5127)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.6784  Acc@1: 81.2500 (81.3256)  Acc@5: 93.7500 (96.5110)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.8812  Acc@1: 81.2500 (81.3330)  Acc@5: 100.0000 (96.5133)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.4749  Acc@1: 81.2500 (81.3207)  Acc@5: 100.0000 (96.5156)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.9655  Acc@1: 81.2500 (81.3242)  Acc@5: 93.7500 (96.5139)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -1.2026  Acc@1: 81.2500 (81.3392)  Acc@5: 93.7500 (96.5006)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.7608  Acc@1: 81.2500 (81.3541)  Acc@5: 100.0000 (96.5145)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.6726  Acc@1: 81.2500 (81.3343)  Acc@5: 100.0000 (96.4899)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -1.1501  Acc@1: 81.2500 (81.3338)  Acc@5: 93.7500 (96.4960)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -1.1844  Acc@1: 81.2500 (81.3409)  Acc@5: 100.0000 (96.4945)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.7685  Acc@1: 81.2500 (81.3215)  Acc@5: 100.0000 (96.4931)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.9603  Acc@1: 81.2500 (81.3248)  Acc@5: 100.0000 (96.4954)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -1.1994  Acc@1: 81.2500 (81.3504)  Acc@5: 100.0000 (96.5051)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1690/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.9297  Acc@1: 81.2500 (81.3683)  Acc@5: 100.0000 (96.4999)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.7868  Acc@1: 81.2500 (81.3823)  Acc@5: 93.7500 (96.4800)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.6849  Acc@1: 87.5000 (81.4071)  Acc@5: 93.7500 (96.4714)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -1.3975  Acc@1: 87.5000 (81.4171)  Acc@5: 100.0000 (96.4737)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.9201  Acc@1: 81.2500 (81.4053)  Acc@5: 100.0000 (96.4796)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.4543  Acc@1: 81.2500 (81.4008)  Acc@5: 100.0000 (96.4783)  time: 0.3512  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.7712  Acc@1: 75.0000 (81.3714)  Acc@5: 93.7500 (96.4770)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.9132  Acc@1: 81.2500 (81.3955)  Acc@5: 93.7500 (96.4686)  time: 0.3508  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -1.1571  Acc@1: 87.5000 (81.4159)  Acc@5: 100.0000 (96.4744)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.5788  Acc@1: 81.2500 (81.3834)  Acc@5: 93.7500 (96.4592)  time: 0.3513  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.4867  Acc@1: 81.2500 (81.4140)  Acc@5: 93.7500 (96.4580)  time: 0.3522  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.4237  Acc@1: 87.5000 (81.4166)  Acc@5: 100.0000 (96.4638)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.7893  Acc@1: 81.2500 (81.4122)  Acc@5: 100.0000 (96.4626)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.8174  Acc@1: 81.2500 (81.4250)  Acc@5: 100.0000 (96.4717)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -1.1147  Acc@1: 81.2500 (81.4207)  Acc@5: 100.0000 (96.4842)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -1.0780  Acc@1: 81.2500 (81.4130)  Acc@5: 93.7500 (96.4727)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -1.2468  Acc@1: 81.2500 (81.4425)  Acc@5: 100.0000 (96.4884)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.8996  Acc@1: 87.5000 (81.4280)  Acc@5: 100.0000 (96.4770)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.9925  Acc@1: 81.2500 (81.4237)  Acc@5: 93.7500 (96.4858)  time: 0.3524  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.9969  Acc@1: 81.2500 (81.4128)  Acc@5: 100.0000 (96.4779)  time: 0.3531  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.7310  Acc@1: 81.2500 (81.4252)  Acc@5: 93.7500 (96.4734)  time: 0.3541  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.4965  Acc@1: 81.2500 (81.3914)  Acc@5: 93.7500 (96.4690)  time: 0.3541  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.9804  Acc@1: 81.2500 (81.3906)  Acc@5: 93.7500 (96.4744)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -1.1367  Acc@1: 75.0000 (81.3834)  Acc@5: 100.0000 (96.4732)  time: 0.3502  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.9774  Acc@1: 81.2500 (81.3859)  Acc@5: 100.0000 (96.4785)  time: 0.3495  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -1.2700  Acc@1: 81.2500 (81.3852)  Acc@5: 100.0000 (96.4741)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.0978  Acc@1: 81.2500 (81.4038)  Acc@5: 100.0000 (96.4698)  time: 0.3526  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -1.1385  Acc@1: 81.2500 (81.3998)  Acc@5: 93.7500 (96.4623)  time: 0.3523  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.7992  Acc@1: 81.2500 (81.3832)  Acc@5: 93.7500 (96.4612)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.4425  Acc@1: 81.2500 (81.3730)  Acc@5: 93.7500 (96.4570)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.9813  Acc@1: 81.2500 (81.3913)  Acc@5: 93.7500 (96.4496)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -1.2648  Acc@1: 81.2500 (81.4030)  Acc@5: 93.7500 (96.4518)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -1.0966  Acc@1: 81.2500 (81.3743)  Acc@5: 100.0000 (96.4539)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -1.0550  Acc@1: 81.2500 (81.3737)  Acc@5: 93.7500 (96.4436)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.9331  Acc@1: 81.2500 (81.3916)  Acc@5: 100.0000 (96.4580)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -0.8738  Acc@1: 81.2500 (81.3847)  Acc@5: 100.0000 (96.4539)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.4434  Acc@1: 81.2500 (81.3932)  Acc@5: 100.0000 (96.4621)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.9361  Acc@1: 87.5000 (81.4077)  Acc@5: 100.0000 (96.4671)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.9294  Acc@1: 81.2500 (81.4069)  Acc@5: 100.0000 (96.4631)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -1.1056  Acc@1: 81.2500 (81.3972)  Acc@5: 93.7500 (96.4620)  time: 0.3561  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.9068  Acc@1: 81.2500 (81.4084)  Acc@5: 93.7500 (96.4610)  time: 0.3553  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.6201  Acc@1: 81.2500 (81.3958)  Acc@5: 93.7500 (96.4570)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.6567  Acc@1: 75.0000 (81.3832)  Acc@5: 93.7500 (96.4531)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -1.3587  Acc@1: 81.2500 (81.3855)  Acc@5: 100.0000 (96.4551)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.4982  Acc@1: 87.5000 (81.3878)  Acc@5: 100.0000 (96.4541)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.7356  Acc@1: 81.2500 (81.3668)  Acc@5: 93.7500 (96.4473)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.8383  Acc@1: 81.2500 (81.3749)  Acc@5: 100.0000 (96.4551)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.6158  Acc@1: 81.2500 (81.3859)  Acc@5: 100.0000 (96.4513)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.9306  Acc@1: 87.5000 (81.3997)  Acc@5: 100.0000 (96.4561)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -1.1663  Acc@1: 87.5000 (81.4133)  Acc@5: 100.0000 (96.4609)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -1.0041  Acc@1: 81.2500 (81.4126)  Acc@5: 100.0000 (96.4571)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2200/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -1.2548  Acc@1: 81.2500 (81.4090)  Acc@5: 93.7500 (96.4505)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.7563  Acc@1: 81.2500 (81.3913)  Acc@5: 93.7500 (96.4467)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.5928  Acc@1: 81.2500 (81.3963)  Acc@5: 93.7500 (96.4515)  time: 0.3501  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -1.4044  Acc@1: 81.2500 (81.4041)  Acc@5: 100.0000 (96.4590)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.4924  Acc@1: 81.2500 (81.3755)  Acc@5: 100.0000 (96.4553)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.7748  Acc@1: 75.0000 (81.3583)  Acc@5: 100.0000 (96.4544)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -1.3677  Acc@1: 81.2500 (81.3606)  Acc@5: 100.0000 (96.4673)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.8226  Acc@1: 87.5000 (81.3656)  Acc@5: 100.0000 (96.4718)  time: 0.3541  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.7630  Acc@1: 81.2500 (81.3459)  Acc@5: 100.0000 (96.4654)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -1.2012  Acc@1: 81.2500 (81.3537)  Acc@5: 100.0000 (96.4726)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.5728  Acc@1: 81.2500 (81.3396)  Acc@5: 100.0000 (96.4716)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.9490  Acc@1: 81.2500 (81.3420)  Acc@5: 93.7500 (96.4707)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -1.0484  Acc@1: 81.2500 (81.3308)  Acc@5: 93.7500 (96.4670)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -1.1794  Acc@1: 81.2500 (81.3224)  Acc@5: 93.7500 (96.4554)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.8170  Acc@1: 81.2500 (81.3248)  Acc@5: 93.7500 (96.4518)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -1.3153  Acc@1: 81.2500 (81.3165)  Acc@5: 100.0000 (96.4563)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -1.1204  Acc@1: 87.5000 (81.3427)  Acc@5: 100.0000 (96.4634)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2370/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.9403  Acc@1: 87.5000 (81.3554)  Acc@5: 100.0000 (96.4730)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.5388  Acc@1: 81.2500 (81.3497)  Acc@5: 100.0000 (96.4694)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -1.0006  Acc@1: 81.2500 (81.3624)  Acc@5: 100.0000 (96.4738)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.6814  Acc@1: 81.2500 (81.3541)  Acc@5: 100.0000 (96.4780)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.9956  Acc@1: 81.2500 (81.3304)  Acc@5: 100.0000 (96.4745)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -1.3133  Acc@1: 81.2500 (81.3378)  Acc@5: 100.0000 (96.4761)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.9668  Acc@1: 81.2500 (81.3220)  Acc@5: 100.0000 (96.4701)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.9570  Acc@1: 75.0000 (81.2910)  Acc@5: 93.7500 (96.4589)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -1.0967  Acc@1: 75.0000 (81.2806)  Acc@5: 93.7500 (96.4479)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.3948  Acc@1: 81.2500 (81.2754)  Acc@5: 93.7500 (96.4395)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.7780  Acc@1: 81.2500 (81.2677)  Acc@5: 93.7500 (96.4362)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.8228  Acc@1: 81.2500 (81.2576)  Acc@5: 93.7500 (96.4304)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -1.0146  Acc@1: 75.0000 (81.2525)  Acc@5: 93.7500 (96.4296)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -1.0554  Acc@1: 81.2500 (81.2575)  Acc@5: 100.0000 (96.4364)  time: 0.3490  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -1.1690  Acc@1: 81.2500 (81.2749)  Acc@5: 100.0000 (96.4332)  time: 0.3503  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.5841  Acc@1: 87.5000 (81.2921)  Acc@5: 93.7500 (96.4300)  time: 0.3500  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -1.1181  Acc@1: 87.5000 (81.3167)  Acc@5: 93.7500 (96.4317)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.8281  Acc@1: 81.2500 (81.3066)  Acc@5: 93.7500 (96.4187)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.9961  Acc@1: 75.0000 (81.2843)  Acc@5: 100.0000 (96.4303)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.9216  Acc@1: 75.0000 (81.2671)  Acc@5: 100.0000 (96.4296)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.8129  Acc@1: 75.0000 (81.2670)  Acc@5: 100.0000 (96.4338)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -1.0081  Acc@1: 81.2500 (81.2766)  Acc@5: 93.7500 (96.4282)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.7404  Acc@1: 81.2500 (81.2789)  Acc@5: 100.0000 (96.4372)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -1.2665  Acc@1: 81.2500 (81.2860)  Acc@5: 100.0000 (96.4389)  time: 0.3531  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -1.0324  Acc@1: 81.2500 (81.2931)  Acc@5: 100.0000 (96.4429)  time: 0.3523  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -1.0287  Acc@1: 87.5000 (81.3048)  Acc@5: 100.0000 (96.4446)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -1.2327  Acc@1: 81.2500 (81.2928)  Acc@5: 93.7500 (96.4343)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6829  Acc@1: 81.2500 (81.2950)  Acc@5: 93.7500 (96.4384)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.1464  Acc@1: 81.2500 (81.3089)  Acc@5: 100.0000 (96.4400)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.2826  Acc@1: 87.5000 (81.3181)  Acc@5: 100.0000 (96.4370)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8886  Acc@1: 81.2500 (81.3108)  Acc@5: 100.0000 (96.4363)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -1.2590  Acc@1: 81.2500 (81.3293)  Acc@5: 100.0000 (96.4379)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.0366  Acc@1: 87.5000 (81.3429)  Acc@5: 100.0000 (96.4442)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -1.3163  Acc@1: 87.5000 (81.3518)  Acc@5: 100.0000 (96.4365)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.5504  Acc@1: 81.2500 (81.3514)  Acc@5: 100.0000 (96.4381)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -1.0285  Acc@1: 81.2500 (81.3511)  Acc@5: 100.0000 (96.4443)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.9659  Acc@1: 81.2500 (81.3713)  Acc@5: 100.0000 (96.4436)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -1.0684  Acc@1: 81.2500 (81.3800)  Acc@5: 100.0000 (96.4475)  time: 0.3558  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.9939  Acc@1: 81.2500 (81.3750)  Acc@5: 100.0000 (96.4490)  time: 0.3545  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.7179  Acc@1: 81.2500 (81.3881)  Acc@5: 100.0000 (96.4551)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.7590  Acc@1: 87.5000 (81.3944)  Acc@5: 100.0000 (96.4566)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.9513  Acc@1: 81.2500 (81.4006)  Acc@5: 100.0000 (96.4649)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.7790  Acc@1: 81.2500 (81.3956)  Acc@5: 100.0000 (96.4551)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -1.0737  Acc@1: 81.2500 (81.3928)  Acc@5: 93.7500 (96.4455)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.6686  Acc@1: 75.0000 (81.3745)  Acc@5: 93.7500 (96.4381)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -1.2152  Acc@1: 81.2500 (81.3807)  Acc@5: 93.7500 (96.4419)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.6502  Acc@1: 81.2500 (81.3714)  Acc@5: 93.7500 (96.4324)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.9199  Acc@1: 81.2500 (81.3622)  Acc@5: 93.7500 (96.4251)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -1.2025  Acc@1: 81.2500 (81.3750)  Acc@5: 100.0000 (96.4333)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.8221  Acc@1: 81.2500 (81.3723)  Acc@5: 100.0000 (96.4304)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -1.0950  Acc@1: 81.2500 (81.3828)  Acc@5: 100.0000 (96.4385)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.7696  Acc@1: 81.2500 (81.3823)  Acc@5: 100.0000 (96.4400)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -1.1704  Acc@1: 81.2500 (81.3905)  Acc@5: 100.0000 (96.4415)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.8776  Acc@1: 81.2500 (81.3965)  Acc@5: 100.0000 (96.4517)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.8478  Acc@1: 81.2500 (81.4024)  Acc@5: 100.0000 (96.4595)  time: 0.3483  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -1.0318  Acc@1: 81.2500 (81.4041)  Acc@5: 100.0000 (96.4524)  time: 0.3498  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.4959  Acc@1: 81.2500 (81.4078)  Acc@5: 100.0000 (96.4581)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.5854  Acc@1: 81.2500 (81.4136)  Acc@5: 100.0000 (96.4595)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.9812  Acc@1: 81.2500 (81.4258)  Acc@5: 100.0000 (96.4652)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.8358  Acc@1: 81.2500 (81.4231)  Acc@5: 100.0000 (96.4602)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.8164  Acc@1: 81.2500 (81.4141)  Acc@5: 93.7500 (96.4574)  time: 0.3516  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.9863  Acc@1: 81.2500 (81.4051)  Acc@5: 100.0000 (96.4588)  time: 0.3521  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.1662  Acc@1: 81.2500 (81.3963)  Acc@5: 100.0000 (96.4560)  time: 0.3515  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -1.1509  Acc@1: 81.2500 (81.3958)  Acc@5: 100.0000 (96.4658)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -1.0307  Acc@1: 81.2500 (81.3953)  Acc@5: 100.0000 (96.4630)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -1.0334  Acc@1: 81.2500 (81.3886)  Acc@5: 93.7500 (96.4561)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.8808  Acc@1: 75.0000 (81.3675)  Acc@5: 93.7500 (96.4595)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -1.1047  Acc@1: 75.0000 (81.3651)  Acc@5: 93.7500 (96.4568)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.7860  Acc@1: 81.2500 (81.3565)  Acc@5: 93.7500 (96.4520)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.6442  Acc@1: 81.2500 (81.3603)  Acc@5: 100.0000 (96.4574)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -1.1016  Acc@1: 87.5000 (81.3741)  Acc@5: 100.0000 (96.4629)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.4902  Acc@1: 81.2500 (81.3656)  Acc@5: 100.0000 (96.4642)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -1.3855  Acc@1: 81.2500 (81.3673)  Acc@5: 100.0000 (96.4635)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.1679  Acc@1: 81.2500 (81.3790)  Acc@5: 100.0000 (96.4649)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.8122  Acc@1: 81.2500 (81.3766)  Acc@5: 93.7500 (96.4581)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.6117  Acc@1: 75.0000 (81.3621)  Acc@5: 93.7500 (96.4595)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.8258  Acc@1: 81.2500 (81.3658)  Acc@5: 93.7500 (96.4568)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -1.1478  Acc@1: 81.2500 (81.3654)  Acc@5: 93.7500 (96.4522)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.7395  Acc@1: 81.2500 (81.3631)  Acc@5: 100.0000 (96.4614)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.9834  Acc@1: 81.2500 (81.3607)  Acc@5: 100.0000 (96.4627)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.2229  Acc@1: 81.2500 (81.3702)  Acc@5: 100.0000 (96.4700)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -1.4450  Acc@1: 87.5000 (81.3718)  Acc@5: 100.0000 (96.4732)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.7033  Acc@1: 81.2500 (81.3754)  Acc@5: 100.0000 (96.4725)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -1.0141  Acc@1: 81.2500 (81.3593)  Acc@5: 93.7500 (96.4640)  time: 0.3496  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.8502  Acc@1: 81.2500 (81.3551)  Acc@5: 93.7500 (96.4653)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.9646  Acc@1: 75.0000 (81.3334)  Acc@5: 100.0000 (96.4627)  time: 0.3507  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.9077  Acc@1: 75.0000 (81.3235)  Acc@5: 100.0000 (96.4678)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.7399  Acc@1: 81.2500 (81.3175)  Acc@5: 100.0000 (96.4691)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -1.0302  Acc@1: 81.2500 (81.3211)  Acc@5: 100.0000 (96.4722)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.9174  Acc@1: 81.2500 (81.3056)  Acc@5: 100.0000 (96.4677)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -1.1197  Acc@1: 75.0000 (81.2978)  Acc@5: 93.7500 (96.4651)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.0265  Acc@1: 81.2500 (81.2843)  Acc@5: 93.7500 (96.4569)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.9338  Acc@1: 81.2500 (81.2709)  Acc@5: 93.7500 (96.4543)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -1.0738  Acc@1: 81.2500 (81.2784)  Acc@5: 100.0000 (96.4575)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.0963  Acc@1: 81.2500 (81.2821)  Acc@5: 100.0000 (96.4531)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -1.0416  Acc@1: 81.2500 (81.2745)  Acc@5: 100.0000 (96.4581)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.1439  Acc@1: 81.2500 (81.2706)  Acc@5: 100.0000 (96.4631)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.9893  Acc@1: 81.2500 (81.2687)  Acc@5: 100.0000 (96.4644)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6585  Acc@1: 81.2500 (81.2369)  Acc@5: 100.0000 (96.4619)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.9567  Acc@1: 81.2500 (81.2463)  Acc@5: 100.0000 (96.4668)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.1903  Acc@1: 81.2500 (81.2444)  Acc@5: 100.0000 (96.4606)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -1.0920  Acc@1: 81.2500 (81.2518)  Acc@5: 93.7500 (96.4637)  time: 0.3500  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.2710  Acc@1: 81.2500 (81.2463)  Acc@5: 100.0000 (96.4631)  time: 0.3499  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.9912  Acc@1: 81.2500 (81.2408)  Acc@5: 93.7500 (96.4606)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.8464  Acc@1: 81.2500 (81.2372)  Acc@5: 100.0000 (96.4600)  time: 0.3529  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4821  Acc@1: 75.0000 (81.2317)  Acc@5: 100.0000 (96.4630)  time: 0.3524  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.3898  Acc@1: 87.5000 (81.2354)  Acc@5: 100.0000 (96.4624)  time: 0.3520  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.1213  Acc@1: 87.5000 (81.2318)  Acc@5: 100.0000 (96.4672)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.9763  Acc@1: 75.0000 (81.2065)  Acc@5: 100.0000 (96.4666)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8381  Acc@1: 75.0000 (81.2067)  Acc@5: 100.0000 (96.4696)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.8770  Acc@1: 81.2500 (81.2086)  Acc@5: 100.0000 (96.4726)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.8822  Acc@1: 81.2500 (81.2195)  Acc@5: 93.7500 (96.4665)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.1282  Acc@1: 81.2500 (81.2214)  Acc@5: 100.0000 (96.4695)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9742  Acc@1: 81.2500 (81.2179)  Acc@5: 100.0000 (96.4760)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.9857  Acc@1: 81.2500 (81.2197)  Acc@5: 100.0000 (96.4754)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8503  Acc@1: 81.2500 (81.2305)  Acc@5: 100.0000 (96.4765)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1998  Acc@1: 81.2500 (81.2181)  Acc@5: 100.0000 (96.4741)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2030  Acc@1: 81.2500 (81.2147)  Acc@5: 100.0000 (96.4752)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.7154  Acc@1: 81.2500 (81.2271)  Acc@5: 100.0000 (96.4711)  time: 0.3460  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1756  Acc@1: 81.2500 (81.2167)  Acc@5: 100.0000 (96.4757)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.1142  Acc@1: 81.2500 (81.2255)  Acc@5: 100.0000 (96.4838)  time: 0.3462  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.8492  Acc@1: 81.2500 (81.2325)  Acc@5: 100.0000 (96.4849)  time: 0.3491  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.2042  Acc@1: 81.2500 (81.2274)  Acc@5: 100.0000 (96.4860)  time: 0.3494  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.9900  Acc@1: 87.5000 (81.2344)  Acc@5: 100.0000 (96.4906)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.7658  Acc@1: 81.2500 (81.2396)  Acc@5: 100.0000 (96.4882)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.1671  Acc@1: 81.2500 (81.2448)  Acc@5: 100.0000 (96.4927)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9544  Acc@1: 81.2500 (81.2483)  Acc@5: 100.0000 (96.4937)  time: 0.3502  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.2053  Acc@1: 87.5000 (81.2654)  Acc@5: 100.0000 (96.4982)  time: 0.3499  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7202  Acc@1: 87.5000 (81.2757)  Acc@5: 100.0000 (96.4975)  time: 0.3524  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.2322  Acc@1: 81.2500 (81.2671)  Acc@5: 100.0000 (96.4969)  time: 0.3525  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8950  Acc@1: 81.2500 (81.2687)  Acc@5: 100.0000 (96.4979)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.1229  Acc@1: 81.2500 (81.2789)  Acc@5: 93.7500 (96.4972)  time: 0.3537  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9814  Acc@1: 81.2500 (81.2771)  Acc@5: 93.7500 (96.4949)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -1.2286  Acc@1: 81.2500 (81.2888)  Acc@5: 100.0000 (96.4959)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.0093  Acc@1: 81.2500 (81.2938)  Acc@5: 100.0000 (96.4986)  time: 0.3486  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0859  Acc@1: 81.2500 (81.3071)  Acc@5: 100.0000 (96.5046)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.9796  Acc@1: 87.5000 (81.3237)  Acc@5: 100.0000 (96.5090)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7736  Acc@1: 87.5000 (81.3352)  Acc@5: 100.0000 (96.5133)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6983  Acc@1: 81.2500 (81.3267)  Acc@5: 100.0000 (96.5133)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[3/5] Total time: 0:21:49 (0.3492 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 179984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6983  Acc@1: 81.2500 (81.3267)  Acc@5: 100.0000 (96.5133)
Train: Epoch[4/5]  [   0/3750]  eta: 0:46:10  Lr: 0.001875  Loss: -0.5121  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7387  data: 0.3872  max mem: 2500
Train: Epoch[4/5]  [  10/3750]  eta: 0:23:56  Lr: 0.001875  Loss: -1.1111  Acc@1: 81.2500 (77.2727)  Acc@5: 100.0000 (96.0227)  time: 0.3842  data: 0.0357  max mem: 2500
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:51  Lr: 0.001875  Loss: -0.6084  Acc@1: 81.2500 (78.5714)  Acc@5: 100.0000 (96.1310)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:22  Lr: 0.001875  Loss: -0.7787  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (96.5726)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:04  Lr: 0.001875  Loss: -0.6822  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.6463)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  50/3750]  eta: 0:21:52  Lr: 0.001875  Loss: -1.1962  Acc@1: 81.2500 (80.3922)  Acc@5: 100.0000 (96.5686)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:43  Lr: 0.001875  Loss: -1.0123  Acc@1: 81.2500 (80.7377)  Acc@5: 100.0000 (96.6189)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -1.3448  Acc@1: 81.2500 (80.8979)  Acc@5: 100.0000 (96.6549)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:29  Lr: 0.001875  Loss: -1.1432  Acc@1: 81.2500 (81.3272)  Acc@5: 100.0000 (96.6821)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -1.3025  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.6346)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -1.3393  Acc@1: 81.2500 (81.3738)  Acc@5: 100.0000 (96.7822)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -1.3013  Acc@1: 81.2500 (81.4752)  Acc@5: 100.0000 (96.9595)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.2593  Acc@1: 87.5000 (81.5083)  Acc@5: 100.0000 (96.9525)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -1.1421  Acc@1: 81.2500 (81.3454)  Acc@5: 100.0000 (96.9943)  time: 0.3502  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 140/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -1.3936  Acc@1: 87.5000 (81.7376)  Acc@5: 100.0000 (97.1188)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 150/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -1.1367  Acc@1: 87.5000 (81.7881)  Acc@5: 100.0000 (97.1440)  time: 0.3528  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 160/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -1.0666  Acc@1: 81.2500 (81.9488)  Acc@5: 100.0000 (97.1273)  time: 0.3545  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -1.0491  Acc@1: 87.5000 (81.9810)  Acc@5: 100.0000 (97.1491)  time: 0.3561  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -1.2747  Acc@1: 81.2500 (81.9406)  Acc@5: 100.0000 (97.0649)  time: 0.3555  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.8430  Acc@1: 81.2500 (81.8390)  Acc@5: 93.7500 (97.0223)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -1.0928  Acc@1: 87.5000 (82.0585)  Acc@5: 100.0000 (97.0149)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.5648  Acc@1: 87.5000 (82.1979)  Acc@5: 100.0000 (97.0379)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.7655  Acc@1: 81.2500 (82.2964)  Acc@5: 100.0000 (97.0305)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -1.0811  Acc@1: 81.2500 (82.1970)  Acc@5: 100.0000 (97.0509)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -1.1577  Acc@1: 81.2500 (82.2095)  Acc@5: 100.0000 (97.0954)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.7002  Acc@1: 81.2500 (82.2460)  Acc@5: 100.0000 (97.1116)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.8428  Acc@1: 81.2500 (82.1839)  Acc@5: 100.0000 (97.0546)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.5735  Acc@1: 81.2500 (82.0111)  Acc@5: 93.7500 (97.0018)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.9200  Acc@1: 81.2500 (82.0285)  Acc@5: 100.0000 (96.9751)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -1.1378  Acc@1: 81.2500 (81.9158)  Acc@5: 100.0000 (96.9287)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -1.1056  Acc@1: 81.2500 (82.1013)  Acc@5: 100.0000 (96.9269)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.7142  Acc@1: 81.2500 (82.1744)  Acc@5: 100.0000 (96.9252)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 320/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -1.1295  Acc@1: 81.2500 (82.1651)  Acc@5: 100.0000 (96.8847)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -1.1316  Acc@1: 87.5000 (82.3829)  Acc@5: 100.0000 (96.9411)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -1.0343  Acc@1: 87.5000 (82.4230)  Acc@5: 100.0000 (96.8842)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.7345  Acc@1: 81.2500 (82.3540)  Acc@5: 93.7500 (96.8483)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -1.3960  Acc@1: 81.2500 (82.3061)  Acc@5: 100.0000 (96.8663)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.9785  Acc@1: 87.5000 (82.4292)  Acc@5: 100.0000 (96.8666)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.9915  Acc@1: 81.2500 (82.3655)  Acc@5: 100.0000 (96.8996)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.7811  Acc@1: 81.2500 (82.2251)  Acc@5: 100.0000 (96.8830)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -1.0052  Acc@1: 81.2500 (82.3099)  Acc@5: 93.7500 (96.8516)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.7047  Acc@1: 81.2500 (82.3297)  Acc@5: 100.0000 (96.8826)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.9070  Acc@1: 81.2500 (82.3634)  Acc@5: 100.0000 (96.8973)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.8402  Acc@1: 81.2500 (82.4101)  Acc@5: 93.7500 (96.8532)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -1.2746  Acc@1: 87.5000 (82.4972)  Acc@5: 100.0000 (96.8821)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -1.0488  Acc@1: 81.2500 (82.4002)  Acc@5: 100.0000 (96.8126)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.6556  Acc@1: 81.2500 (82.3617)  Acc@5: 93.7500 (96.8140)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -1.1419  Acc@1: 81.2500 (82.3514)  Acc@5: 93.7500 (96.8153)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -1.2012  Acc@1: 87.5000 (82.3415)  Acc@5: 93.7500 (96.7775)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 490/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -1.1651  Acc@1: 87.5000 (82.4338)  Acc@5: 93.7500 (96.7923)  time: 0.3554  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.7735  Acc@1: 81.2500 (82.3852)  Acc@5: 93.7500 (96.7565)  time: 0.3557  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.7754  Acc@1: 87.5000 (82.5342)  Acc@5: 93.7500 (96.7833)  time: 0.3519  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -1.2687  Acc@1: 87.5000 (82.4136)  Acc@5: 100.0000 (96.7490)  time: 0.3530  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -1.1200  Acc@1: 81.2500 (82.3799)  Acc@5: 93.7500 (96.7514)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -1.0055  Acc@1: 81.2500 (82.3013)  Acc@5: 93.7500 (96.7075)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.9168  Acc@1: 81.2500 (82.3616)  Acc@5: 93.7500 (96.7105)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.6271  Acc@1: 81.2500 (82.3641)  Acc@5: 100.0000 (96.7023)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.5997  Acc@1: 81.2500 (82.3227)  Acc@5: 100.0000 (96.7053)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -1.3147  Acc@1: 81.2500 (82.3365)  Acc@5: 100.0000 (96.7083)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.9347  Acc@1: 87.5000 (82.3710)  Acc@5: 100.0000 (96.7111)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.8041  Acc@1: 81.2500 (82.4147)  Acc@5: 100.0000 (96.7346)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -1.0946  Acc@1: 81.2500 (82.3445)  Acc@5: 100.0000 (96.7369)  time: 0.3514  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.7589  Acc@1: 81.2500 (82.2967)  Acc@5: 100.0000 (96.7492)  time: 0.3530  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -1.0794  Acc@1: 81.2500 (82.3990)  Acc@5: 100.0000 (96.7611)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -1.2131  Acc@1: 87.5000 (82.4005)  Acc@5: 100.0000 (96.7921)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.4572  Acc@1: 81.2500 (82.3733)  Acc@5: 100.0000 (96.8030)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 660/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -1.4443  Acc@1: 81.2500 (82.3846)  Acc@5: 100.0000 (96.8135)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.8474  Acc@1: 81.2500 (82.3118)  Acc@5: 100.0000 (96.7865)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -1.0326  Acc@1: 81.2500 (82.2228)  Acc@5: 93.7500 (96.7603)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.5877  Acc@1: 81.2500 (82.1816)  Acc@5: 93.7500 (96.7619)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -1.2112  Acc@1: 81.2500 (82.1772)  Acc@5: 100.0000 (96.7546)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -1.0971  Acc@1: 81.2500 (82.1554)  Acc@5: 93.7500 (96.7475)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -1.1722  Acc@1: 81.2500 (82.1602)  Acc@5: 93.7500 (96.7406)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -0.8927  Acc@1: 81.2500 (82.1563)  Acc@5: 93.7500 (96.6912)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -1.3397  Acc@1: 87.5000 (82.1694)  Acc@5: 93.7500 (96.7021)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.7449  Acc@1: 81.2500 (82.1488)  Acc@5: 100.0000 (96.7044)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -1.3085  Acc@1: 81.2500 (82.1534)  Acc@5: 100.0000 (96.7148)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.9908  Acc@1: 81.2500 (82.1093)  Acc@5: 100.0000 (96.7250)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -1.1031  Acc@1: 81.2500 (82.1303)  Acc@5: 100.0000 (96.7190)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.7830  Acc@1: 81.2500 (82.1192)  Acc@5: 100.0000 (96.7130)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -1.1699  Acc@1: 81.2500 (82.0927)  Acc@5: 93.7500 (96.6994)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.9323  Acc@1: 81.2500 (82.0438)  Acc@5: 100.0000 (96.7093)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -1.0931  Acc@1: 81.2500 (82.0874)  Acc@5: 100.0000 (96.7113)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 830/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -1.0783  Acc@1: 81.2500 (82.0548)  Acc@5: 100.0000 (96.7359)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.9955  Acc@1: 81.2500 (82.0155)  Acc@5: 100.0000 (96.7524)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.9513  Acc@1: 75.0000 (81.9697)  Acc@5: 100.0000 (96.7318)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -1.0294  Acc@1: 81.2500 (81.9614)  Acc@5: 93.7500 (96.7044)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -1.0905  Acc@1: 81.2500 (82.0034)  Acc@5: 93.7500 (96.6992)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -1.0522  Acc@1: 81.2500 (82.0233)  Acc@5: 93.7500 (96.6799)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.5878  Acc@1: 81.2500 (82.0426)  Acc@5: 93.7500 (96.6821)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.6950  Acc@1: 81.2500 (82.0963)  Acc@5: 100.0000 (96.6912)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.9530  Acc@1: 81.2500 (82.0733)  Acc@5: 100.0000 (96.6863)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -1.2745  Acc@1: 81.2500 (82.0575)  Acc@5: 93.7500 (96.6748)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.9569  Acc@1: 81.2500 (82.0757)  Acc@5: 93.7500 (96.6568)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.7206  Acc@1: 81.2500 (82.0337)  Acc@5: 93.7500 (96.6326)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -1.1951  Acc@1: 81.2500 (82.0321)  Acc@5: 100.0000 (96.6483)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.8722  Acc@1: 87.5000 (82.0695)  Acc@5: 100.0000 (96.6571)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -1.1710  Acc@1: 87.5000 (82.1125)  Acc@5: 100.0000 (96.6787)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -1.1091  Acc@1: 81.2500 (82.0973)  Acc@5: 100.0000 (96.6807)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.8720  Acc@1: 81.2500 (82.0636)  Acc@5: 100.0000 (96.6826)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1000/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.5883  Acc@1: 81.2500 (82.0430)  Acc@5: 100.0000 (96.6846)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -1.1175  Acc@1: 87.5000 (82.0660)  Acc@5: 100.0000 (96.6864)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -1.0658  Acc@1: 87.5000 (82.1009)  Acc@5: 100.0000 (96.6822)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.5470  Acc@1: 87.5000 (82.0987)  Acc@5: 100.0000 (96.6962)  time: 0.3506  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -1.3867  Acc@1: 81.2500 (82.0785)  Acc@5: 100.0000 (96.7159)  time: 0.3535  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -1.3091  Acc@1: 81.2500 (82.1182)  Acc@5: 100.0000 (96.7115)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.6912  Acc@1: 87.5000 (82.1336)  Acc@5: 100.0000 (96.7130)  time: 0.3527  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.8502  Acc@1: 81.2500 (82.1545)  Acc@5: 100.0000 (96.7262)  time: 0.3570  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -1.1281  Acc@1: 81.2500 (82.1404)  Acc@5: 100.0000 (96.7333)  time: 0.3539  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.9558  Acc@1: 81.2500 (82.1036)  Acc@5: 100.0000 (96.7175)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.7651  Acc@1: 75.0000 (82.0447)  Acc@5: 93.7500 (96.7075)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -1.2418  Acc@1: 75.0000 (82.0320)  Acc@5: 93.7500 (96.7034)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.7802  Acc@1: 81.2500 (82.0306)  Acc@5: 100.0000 (96.7050)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -1.2966  Acc@1: 87.5000 (82.0568)  Acc@5: 100.0000 (96.7230)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.9965  Acc@1: 87.5000 (82.0662)  Acc@5: 100.0000 (96.7353)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.9838  Acc@1: 81.2500 (82.0862)  Acc@5: 100.0000 (96.7420)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -1.2877  Acc@1: 87.5000 (82.1167)  Acc@5: 100.0000 (96.7593)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1170/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -1.2081  Acc@1: 87.5000 (82.1200)  Acc@5: 100.0000 (96.7602)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -1.1758  Acc@1: 87.5000 (82.1338)  Acc@5: 100.0000 (96.7612)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.7876  Acc@1: 81.2500 (82.0791)  Acc@5: 100.0000 (96.7569)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -1.4338  Acc@1: 81.2500 (82.0670)  Acc@5: 100.0000 (96.7787)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.8167  Acc@1: 81.2500 (82.1016)  Acc@5: 100.0000 (96.7898)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.8461  Acc@1: 81.2500 (82.0946)  Acc@5: 100.0000 (96.8008)  time: 0.3514  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.7390  Acc@1: 81.2500 (82.0573)  Acc@5: 100.0000 (96.7861)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.7205  Acc@1: 81.2500 (82.0608)  Acc@5: 100.0000 (96.7818)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.8218  Acc@1: 81.2500 (82.0244)  Acc@5: 100.0000 (96.7826)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -1.3391  Acc@1: 81.2500 (82.0827)  Acc@5: 100.0000 (96.7932)  time: 0.3549  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -1.3330  Acc@1: 81.2500 (82.0515)  Acc@5: 100.0000 (96.7889)  time: 0.3538  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.8533  Acc@1: 81.2500 (82.0550)  Acc@5: 100.0000 (96.7896)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -1.1224  Acc@1: 81.2500 (82.0536)  Acc@5: 93.7500 (96.7709)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.8324  Acc@1: 81.2500 (82.0667)  Acc@5: 100.0000 (96.7765)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.6173  Acc@1: 87.5000 (82.0891)  Acc@5: 100.0000 (96.7820)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.7513  Acc@1: 87.5000 (82.0732)  Acc@5: 100.0000 (96.7827)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.7599  Acc@1: 81.2500 (82.0577)  Acc@5: 93.7500 (96.7693)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1340/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -1.0941  Acc@1: 81.2500 (82.0610)  Acc@5: 93.7500 (96.7748)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.5427  Acc@1: 87.5000 (82.0735)  Acc@5: 100.0000 (96.7848)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.8843  Acc@1: 87.5000 (82.0996)  Acc@5: 100.0000 (96.7855)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7782  Acc@1: 81.2500 (82.0569)  Acc@5: 93.7500 (96.7724)  time: 0.3450  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -1.0199  Acc@1: 81.2500 (82.0420)  Acc@5: 100.0000 (96.7732)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -1.2038  Acc@1: 81.2500 (82.0318)  Acc@5: 93.7500 (96.7604)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -1.0715  Acc@1: 81.2500 (82.0218)  Acc@5: 93.7500 (96.7523)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.6962  Acc@1: 81.2500 (82.0252)  Acc@5: 93.7500 (96.7355)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.9459  Acc@1: 81.2500 (81.9977)  Acc@5: 100.0000 (96.7409)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -1.1926  Acc@1: 81.2500 (81.9575)  Acc@5: 100.0000 (96.7287)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -1.2136  Acc@1: 81.2500 (81.9570)  Acc@5: 100.0000 (96.7254)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.4475  Acc@1: 81.2500 (81.9564)  Acc@5: 100.0000 (96.7221)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.9114  Acc@1: 81.2500 (81.9559)  Acc@5: 100.0000 (96.7274)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -1.1135  Acc@1: 81.2500 (81.9596)  Acc@5: 100.0000 (96.7242)  time: 0.3515  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.9615  Acc@1: 81.2500 (81.9379)  Acc@5: 93.7500 (96.7041)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -1.2719  Acc@1: 81.2500 (81.9458)  Acc@5: 93.7500 (96.7052)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -1.1682  Acc@1: 81.2500 (81.9329)  Acc@5: 100.0000 (96.7189)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.8323  Acc@1: 81.2500 (81.9325)  Acc@5: 100.0000 (96.7282)  time: 0.3491  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -1.0801  Acc@1: 81.2500 (81.9486)  Acc@5: 100.0000 (96.7250)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -1.1764  Acc@1: 87.5000 (81.9889)  Acc@5: 100.0000 (96.7301)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.9992  Acc@1: 87.5000 (81.9517)  Acc@5: 100.0000 (96.7189)  time: 0.3505  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.7033  Acc@1: 81.2500 (81.9592)  Acc@5: 100.0000 (96.7279)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -1.2929  Acc@1: 81.2500 (81.9587)  Acc@5: 100.0000 (96.7209)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.6435  Acc@1: 81.2500 (81.9343)  Acc@5: 100.0000 (96.7377)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.8994  Acc@1: 81.2500 (81.9379)  Acc@5: 100.0000 (96.7505)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.7751  Acc@1: 81.2500 (81.9610)  Acc@5: 100.0000 (96.7591)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -1.0182  Acc@1: 81.2500 (81.9800)  Acc@5: 100.0000 (96.7637)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.9284  Acc@1: 81.2500 (81.9522)  Acc@5: 100.0000 (96.7567)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -1.0149  Acc@1: 81.2500 (81.9671)  Acc@5: 93.7500 (96.7574)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -1.2938  Acc@1: 81.2500 (81.9742)  Acc@5: 100.0000 (96.7543)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.4625  Acc@1: 87.5000 (81.9813)  Acc@5: 100.0000 (96.7512)  time: 0.3533  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -1.2874  Acc@1: 87.5000 (81.9995)  Acc@5: 100.0000 (96.7671)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -1.0263  Acc@1: 81.2500 (82.0214)  Acc@5: 100.0000 (96.7753)  time: 0.3558  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.6604  Acc@1: 81.2500 (82.0242)  Acc@5: 93.7500 (96.7684)  time: 0.3563  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1680/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -1.1436  Acc@1: 81.2500 (82.0382)  Acc@5: 93.7500 (96.7690)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.5681  Acc@1: 81.2500 (82.0077)  Acc@5: 100.0000 (96.7734)  time: 0.3480  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -1.2905  Acc@1: 75.0000 (82.0216)  Acc@5: 100.0000 (96.7776)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.8383  Acc@1: 81.2500 (82.0098)  Acc@5: 100.0000 (96.7709)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.9349  Acc@1: 75.0000 (82.0054)  Acc@5: 100.0000 (96.7824)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.7639  Acc@1: 81.2500 (82.0046)  Acc@5: 100.0000 (96.7902)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.7231  Acc@1: 81.2500 (81.9823)  Acc@5: 93.7500 (96.7799)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -0.7681  Acc@1: 81.2500 (81.9817)  Acc@5: 93.7500 (96.7768)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -1.0524  Acc@1: 87.5000 (82.0095)  Acc@5: 93.7500 (96.7703)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -1.2927  Acc@1: 87.5000 (82.0264)  Acc@5: 100.0000 (96.7815)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.9934  Acc@1: 87.5000 (82.0185)  Acc@5: 100.0000 (96.7785)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -1.1461  Acc@1: 75.0000 (82.0003)  Acc@5: 100.0000 (96.7790)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.8804  Acc@1: 75.0000 (81.9684)  Acc@5: 93.7500 (96.7692)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.3549  Acc@1: 75.0000 (81.9782)  Acc@5: 100.0000 (96.7766)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.7968  Acc@1: 81.2500 (81.9708)  Acc@5: 100.0000 (96.7738)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -0.7287  Acc@1: 81.2500 (81.9771)  Acc@5: 100.0000 (96.7811)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.8885  Acc@1: 81.2500 (81.9663)  Acc@5: 93.7500 (96.7613)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.3002  Acc@1: 75.0000 (81.9489)  Acc@5: 93.7500 (96.7585)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -1.0591  Acc@1: 81.2500 (81.9452)  Acc@5: 93.7500 (96.7524)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -1.1594  Acc@1: 81.2500 (81.9715)  Acc@5: 93.7500 (96.7531)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.8594  Acc@1: 81.2500 (81.9411)  Acc@5: 100.0000 (96.7504)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -1.1114  Acc@1: 81.2500 (81.9342)  Acc@5: 93.7500 (96.7478)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -1.1031  Acc@1: 81.2500 (81.9306)  Acc@5: 93.7500 (96.7418)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -1.0325  Acc@1: 81.2500 (81.9041)  Acc@5: 93.7500 (96.7393)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -1.0115  Acc@1: 81.2500 (81.9267)  Acc@5: 93.7500 (96.7367)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -0.6843  Acc@1: 87.5000 (81.9394)  Acc@5: 100.0000 (96.7472)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.8871  Acc@1: 81.2500 (81.9262)  Acc@5: 100.0000 (96.7478)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -0.7721  Acc@1: 81.2500 (81.9259)  Acc@5: 100.0000 (96.7581)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -1.0037  Acc@1: 87.5000 (81.9416)  Acc@5: 100.0000 (96.7650)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.6438  Acc@1: 81.2500 (81.9381)  Acc@5: 100.0000 (96.7656)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -1.2006  Acc@1: 81.2500 (81.9567)  Acc@5: 100.0000 (96.7725)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.5694  Acc@1: 87.5000 (81.9846)  Acc@5: 100.0000 (96.7761)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -1.1587  Acc@1: 81.2500 (81.9653)  Acc@5: 100.0000 (96.7704)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.7500  Acc@1: 81.2500 (81.9586)  Acc@5: 100.0000 (96.7740)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.9688  Acc@1: 81.2500 (81.9644)  Acc@5: 100.0000 (96.7807)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2030/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -1.2122  Acc@1: 81.2500 (81.9762)  Acc@5: 100.0000 (96.7811)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.7950  Acc@1: 75.0000 (81.9421)  Acc@5: 93.7500 (96.7724)  time: 0.3488  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.7168  Acc@1: 75.0000 (81.9387)  Acc@5: 93.7500 (96.7668)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -1.1170  Acc@1: 81.2500 (81.9293)  Acc@5: 100.0000 (96.7643)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -1.2065  Acc@1: 81.2500 (81.9230)  Acc@5: 100.0000 (96.7709)  time: 0.3522  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -1.0163  Acc@1: 81.2500 (81.9107)  Acc@5: 100.0000 (96.7684)  time: 0.3538  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.4917  Acc@1: 81.2500 (81.8986)  Acc@5: 100.0000 (96.7719)  time: 0.3517  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.3354  Acc@1: 81.2500 (81.8896)  Acc@5: 100.0000 (96.7753)  time: 0.3543  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -1.2053  Acc@1: 81.2500 (81.9073)  Acc@5: 100.0000 (96.7847)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -1.2144  Acc@1: 81.2500 (81.8953)  Acc@5: 100.0000 (96.7940)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.7431  Acc@1: 75.0000 (81.8600)  Acc@5: 100.0000 (96.7855)  time: 0.3489  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -1.3302  Acc@1: 75.0000 (81.8718)  Acc@5: 93.7500 (96.7772)  time: 0.3495  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -1.1920  Acc@1: 81.2500 (81.8805)  Acc@5: 100.0000 (96.7835)  time: 0.3488  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.9165  Acc@1: 81.2500 (81.8747)  Acc@5: 100.0000 (96.7897)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.9192  Acc@1: 81.2500 (81.8718)  Acc@5: 100.0000 (96.7987)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.5214  Acc@1: 81.2500 (81.8804)  Acc@5: 100.0000 (96.8019)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -1.2006  Acc@1: 87.5000 (81.8918)  Acc@5: 100.0000 (96.8108)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2200/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.9780  Acc@1: 81.2500 (81.8832)  Acc@5: 100.0000 (96.8054)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.8510  Acc@1: 81.2500 (81.8832)  Acc@5: 100.0000 (96.8114)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.6333  Acc@1: 81.2500 (81.8860)  Acc@5: 100.0000 (96.8061)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -1.2595  Acc@1: 81.2500 (81.8971)  Acc@5: 93.7500 (96.8008)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -1.3992  Acc@1: 81.2500 (81.8998)  Acc@5: 93.7500 (96.7955)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -1.2849  Acc@1: 81.2500 (81.9108)  Acc@5: 100.0000 (96.8014)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -1.1954  Acc@1: 81.2500 (81.8996)  Acc@5: 100.0000 (96.7990)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.7218  Acc@1: 75.0000 (81.8747)  Acc@5: 93.7500 (96.7966)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.8313  Acc@1: 75.0000 (81.8857)  Acc@5: 93.7500 (96.7942)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.9398  Acc@1: 75.0000 (81.8638)  Acc@5: 93.7500 (96.7945)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -1.0845  Acc@1: 81.2500 (81.8584)  Acc@5: 93.7500 (96.7894)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -0.9812  Acc@1: 81.2500 (81.8423)  Acc@5: 93.7500 (96.7898)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -1.1819  Acc@1: 81.2500 (81.8559)  Acc@5: 100.0000 (96.7848)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.7366  Acc@1: 81.2500 (81.8506)  Acc@5: 100.0000 (96.7879)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.9625  Acc@1: 81.2500 (81.8587)  Acc@5: 100.0000 (96.7936)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.6131  Acc@1: 81.2500 (81.8508)  Acc@5: 100.0000 (96.7966)  time: 0.3536  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.5232  Acc@1: 81.2500 (81.8562)  Acc@5: 100.0000 (96.7943)  time: 0.3526  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -1.1841  Acc@1: 81.2500 (81.8616)  Acc@5: 100.0000 (96.7999)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -1.1526  Acc@1: 81.2500 (81.8642)  Acc@5: 100.0000 (96.8002)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.6061  Acc@1: 81.2500 (81.8695)  Acc@5: 100.0000 (96.8031)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -1.1243  Acc@1: 81.2500 (81.8669)  Acc@5: 100.0000 (96.8060)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -1.0562  Acc@1: 75.0000 (81.8566)  Acc@5: 93.7500 (96.7908)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -1.0947  Acc@1: 81.2500 (81.8644)  Acc@5: 93.7500 (96.7937)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.8632  Acc@1: 81.2500 (81.8593)  Acc@5: 100.0000 (96.7914)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -1.1963  Acc@1: 81.2500 (81.8747)  Acc@5: 100.0000 (96.7943)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -1.0430  Acc@1: 81.2500 (81.8824)  Acc@5: 100.0000 (96.7896)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -1.0481  Acc@1: 87.5000 (81.9052)  Acc@5: 100.0000 (96.7950)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -1.1899  Acc@1: 87.5000 (81.9329)  Acc@5: 100.0000 (96.8004)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -1.3205  Acc@1: 87.5000 (81.9528)  Acc@5: 100.0000 (96.8032)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.9285  Acc@1: 81.2500 (81.9500)  Acc@5: 100.0000 (96.8035)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.9927  Acc@1: 81.2500 (81.9522)  Acc@5: 100.0000 (96.8038)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -1.3847  Acc@1: 81.2500 (81.9619)  Acc@5: 100.0000 (96.8066)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.9528  Acc@1: 81.2500 (81.9466)  Acc@5: 100.0000 (96.8068)  time: 0.3475  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.9944  Acc@1: 81.2500 (81.9562)  Acc@5: 100.0000 (96.8096)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -1.1596  Acc@1: 81.2500 (81.9485)  Acc@5: 93.7500 (96.7951)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.7525  Acc@1: 81.2500 (81.9581)  Acc@5: 93.7500 (96.7905)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.8787  Acc@1: 81.2500 (81.9406)  Acc@5: 100.0000 (96.7957)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -1.1935  Acc@1: 81.2500 (81.9453)  Acc@5: 100.0000 (96.7984)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.9222  Acc@1: 81.2500 (81.9547)  Acc@5: 100.0000 (96.8011)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -1.0726  Acc@1: 81.2500 (81.9447)  Acc@5: 100.0000 (96.7966)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.6538  Acc@1: 81.2500 (81.9589)  Acc@5: 100.0000 (96.7969)  time: 0.3545  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.9701  Acc@1: 81.2500 (81.9490)  Acc@5: 93.7500 (96.7948)  time: 0.3543  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -1.0119  Acc@1: 75.0000 (81.9010)  Acc@5: 93.7500 (96.7903)  time: 0.3550  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -1.4092  Acc@1: 81.2500 (81.9056)  Acc@5: 93.7500 (96.7859)  time: 0.3529  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6251  Acc@1: 81.2500 (81.9126)  Acc@5: 93.7500 (96.7886)  time: 0.3486  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.8567  Acc@1: 81.2500 (81.9148)  Acc@5: 100.0000 (96.7913)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.1409  Acc@1: 81.2500 (81.9241)  Acc@5: 100.0000 (96.7963)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -1.0552  Acc@1: 87.5000 (81.9379)  Acc@5: 100.0000 (96.8036)  time: 0.3486  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.8764  Acc@1: 87.5000 (81.9447)  Acc@5: 100.0000 (96.8086)  time: 0.3489  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.8518  Acc@1: 87.5000 (81.9537)  Acc@5: 100.0000 (96.8088)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -1.2353  Acc@1: 87.5000 (81.9720)  Acc@5: 100.0000 (96.8114)  time: 0.3491  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.6673  Acc@1: 87.5000 (81.9923)  Acc@5: 100.0000 (96.8116)  time: 0.3522  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.6846  Acc@1: 87.5000 (81.9827)  Acc@5: 100.0000 (96.8072)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -1.2132  Acc@1: 75.0000 (81.9617)  Acc@5: 100.0000 (96.8075)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.8239  Acc@1: 75.0000 (81.9546)  Acc@5: 100.0000 (96.8100)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -1.2289  Acc@1: 81.2500 (81.9429)  Acc@5: 100.0000 (96.8103)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -1.0761  Acc@1: 81.2500 (81.9585)  Acc@5: 100.0000 (96.8150)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -1.1323  Acc@1: 81.2500 (81.9650)  Acc@5: 100.0000 (96.8152)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -1.2536  Acc@1: 81.2500 (81.9759)  Acc@5: 100.0000 (96.8177)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -1.3443  Acc@1: 81.2500 (81.9711)  Acc@5: 100.0000 (96.8157)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -1.4103  Acc@1: 81.2500 (81.9908)  Acc@5: 100.0000 (96.8226)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.5540  Acc@1: 87.5000 (81.9904)  Acc@5: 100.0000 (96.8227)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.6728  Acc@1: 81.2500 (81.9966)  Acc@5: 100.0000 (96.8229)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.6414  Acc@1: 87.5000 (82.0094)  Acc@5: 100.0000 (96.8187)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -1.1869  Acc@1: 87.5000 (82.0090)  Acc@5: 93.7500 (96.8211)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.9733  Acc@1: 81.2500 (82.0217)  Acc@5: 100.0000 (96.8169)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.8450  Acc@1: 81.2500 (82.0299)  Acc@5: 100.0000 (96.8106)  time: 0.3498  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.9119  Acc@1: 81.2500 (82.0185)  Acc@5: 93.7500 (96.8042)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.6997  Acc@1: 81.2500 (82.0158)  Acc@5: 100.0000 (96.8045)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.9329  Acc@1: 81.2500 (82.0261)  Acc@5: 100.0000 (96.8091)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.7058  Acc@1: 81.2500 (82.0084)  Acc@5: 93.7500 (96.8007)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -1.3583  Acc@1: 75.0000 (81.9843)  Acc@5: 93.7500 (96.8031)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.9327  Acc@1: 75.0000 (81.9668)  Acc@5: 100.0000 (96.8012)  time: 0.3505  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -1.4353  Acc@1: 75.0000 (81.9643)  Acc@5: 100.0000 (96.8078)  time: 0.3531  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -1.2762  Acc@1: 81.2500 (81.9725)  Acc@5: 100.0000 (96.8102)  time: 0.3542  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.1681  Acc@1: 87.5000 (81.9807)  Acc@5: 100.0000 (96.8146)  time: 0.3541  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.8268  Acc@1: 81.2500 (81.9719)  Acc@5: 100.0000 (96.8191)  time: 0.3565  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.0042  Acc@1: 81.2500 (81.9779)  Acc@5: 93.7500 (96.8150)  time: 0.3529  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -1.0303  Acc@1: 81.2500 (81.9691)  Acc@5: 100.0000 (96.8236)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.8772  Acc@1: 81.2500 (81.9730)  Acc@5: 100.0000 (96.8238)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.4725  Acc@1: 75.0000 (81.9623)  Acc@5: 100.0000 (96.8240)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.5908  Acc@1: 75.0000 (81.9640)  Acc@5: 100.0000 (96.8179)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.8904  Acc@1: 81.2500 (81.9638)  Acc@5: 100.0000 (96.8140)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.9072  Acc@1: 81.2500 (81.9552)  Acc@5: 100.0000 (96.8224)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.8552  Acc@1: 75.0000 (81.9549)  Acc@5: 100.0000 (96.8205)  time: 0.3549  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.3783  Acc@1: 81.2500 (81.9506)  Acc@5: 100.0000 (96.8248)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.8748  Acc@1: 87.5000 (81.9667)  Acc@5: 100.0000 (96.8270)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.9112  Acc@1: 87.5000 (81.9766)  Acc@5: 100.0000 (96.8251)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.8097  Acc@1: 87.5000 (81.9864)  Acc@5: 100.0000 (96.8294)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -1.0024  Acc@1: 87.5000 (81.9840)  Acc@5: 100.0000 (96.8315)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.2073  Acc@1: 87.5000 (81.9998)  Acc@5: 100.0000 (96.8377)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.3222  Acc@1: 87.5000 (82.0114)  Acc@5: 100.0000 (96.8459)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.9323  Acc@1: 81.2500 (82.0110)  Acc@5: 100.0000 (96.8460)  time: 0.3527  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.7616  Acc@1: 81.2500 (82.0125)  Acc@5: 100.0000 (96.8461)  time: 0.3526  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.8443  Acc@1: 81.2500 (81.9962)  Acc@5: 100.0000 (96.8382)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.7602  Acc@1: 81.2500 (82.0037)  Acc@5: 100.0000 (96.8403)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -1.2150  Acc@1: 87.5000 (82.0073)  Acc@5: 100.0000 (96.8384)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4426  Acc@1: 81.2500 (81.9832)  Acc@5: 100.0000 (96.8366)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.9633  Acc@1: 81.2500 (81.9986)  Acc@5: 100.0000 (96.8406)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -1.2419  Acc@1: 87.5000 (82.0178)  Acc@5: 100.0000 (96.8446)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.6789  Acc@1: 87.5000 (82.0291)  Acc@5: 100.0000 (96.8389)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -1.0465  Acc@1: 87.5000 (82.0364)  Acc@5: 100.0000 (96.8429)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.7909  Acc@1: 81.2500 (82.0262)  Acc@5: 100.0000 (96.8313)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.8837  Acc@1: 81.2500 (82.0334)  Acc@5: 93.7500 (96.8334)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -1.0540  Acc@1: 81.2500 (82.0233)  Acc@5: 100.0000 (96.8316)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.9337  Acc@1: 81.2500 (82.0228)  Acc@5: 93.7500 (96.8298)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -1.0265  Acc@1: 81.2500 (82.0224)  Acc@5: 93.7500 (96.8300)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.4993  Acc@1: 81.2500 (82.0124)  Acc@5: 100.0000 (96.8301)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -1.0504  Acc@1: 81.2500 (82.0215)  Acc@5: 100.0000 (96.8340)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.9053  Acc@1: 81.2500 (82.0172)  Acc@5: 100.0000 (96.8323)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -1.3793  Acc@1: 81.2500 (82.0111)  Acc@5: 93.7500 (96.8286)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.0596  Acc@1: 81.2500 (82.0164)  Acc@5: 100.0000 (96.8269)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -1.0846  Acc@1: 87.5000 (82.0310)  Acc@5: 100.0000 (96.8308)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.2793  Acc@1: 81.2500 (82.0268)  Acc@5: 100.0000 (96.8234)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.7317  Acc@1: 81.2500 (82.0189)  Acc@5: 93.7500 (96.8236)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.2467  Acc@1: 81.2500 (82.0259)  Acc@5: 100.0000 (96.8274)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -1.2846  Acc@1: 81.2500 (82.0329)  Acc@5: 100.0000 (96.8294)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.1850  Acc@1: 81.2500 (82.0417)  Acc@5: 100.0000 (96.8351)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8798  Acc@1: 81.2500 (82.0467)  Acc@5: 100.0000 (96.8334)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.2045  Acc@1: 81.2500 (82.0462)  Acc@5: 100.0000 (96.8427)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.9704  Acc@1: 87.5000 (82.0567)  Acc@5: 100.0000 (96.8465)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.4363  Acc@1: 87.5000 (82.0379)  Acc@5: 100.0000 (96.8466)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -1.0021  Acc@1: 75.0000 (82.0228)  Acc@5: 93.7500 (96.8449)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.7928  Acc@1: 75.0000 (82.0114)  Acc@5: 93.7500 (96.8449)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.3180  Acc@1: 81.2500 (82.0238)  Acc@5: 93.7500 (96.8450)  time: 0.3490  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.5556  Acc@1: 87.5000 (82.0342)  Acc@5: 100.0000 (96.8469)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.1327  Acc@1: 87.5000 (82.0446)  Acc@5: 100.0000 (96.8470)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.8214  Acc@1: 87.5000 (82.0531)  Acc@5: 100.0000 (96.8453)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.1655  Acc@1: 81.2500 (82.0508)  Acc@5: 100.0000 (96.8418)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.7542  Acc@1: 81.2500 (82.0628)  Acc@5: 100.0000 (96.8490)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0665  Acc@1: 81.2500 (82.0587)  Acc@5: 100.0000 (96.8509)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.7758  Acc@1: 81.2500 (82.0528)  Acc@5: 100.0000 (96.8474)  time: 0.3529  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -1.1023  Acc@1: 81.2500 (82.0577)  Acc@5: 100.0000 (96.8493)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.8211  Acc@1: 87.5000 (82.0660)  Acc@5: 100.0000 (96.8529)  time: 0.3550  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2918  Acc@1: 81.2500 (82.0619)  Acc@5: 100.0000 (96.8529)  time: 0.3555  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.4511  Acc@1: 81.2500 (82.0596)  Acc@5: 93.7500 (96.8512)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6195  Acc@1: 81.2500 (82.0538)  Acc@5: 100.0000 (96.8548)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.2705  Acc@1: 81.2500 (82.0568)  Acc@5: 100.0000 (96.8514)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0136  Acc@1: 81.2500 (82.0563)  Acc@5: 93.7500 (96.8514)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.8961  Acc@1: 81.2500 (82.0611)  Acc@5: 100.0000 (96.8515)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8085  Acc@1: 81.2500 (82.0571)  Acc@5: 100.0000 (96.8498)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.2250  Acc@1: 87.5000 (82.0652)  Acc@5: 100.0000 (96.8516)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.0034  Acc@1: 87.5000 (82.0750)  Acc@5: 100.0000 (96.8569)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.8213  Acc@1: 81.2500 (82.0711)  Acc@5: 100.0000 (96.8535)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.0934  Acc@1: 81.2500 (82.0671)  Acc@5: 93.7500 (96.8484)  time: 0.3493  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5763  Acc@1: 81.2500 (82.0580)  Acc@5: 93.7500 (96.8468)  time: 0.3488  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.1503  Acc@1: 81.2500 (82.0524)  Acc@5: 100.0000 (96.8468)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -1.2154  Acc@1: 81.2500 (82.0434)  Acc@5: 100.0000 (96.8452)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6254  Acc@1: 81.2500 (82.0412)  Acc@5: 100.0000 (96.8402)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6783  Acc@1: 81.2500 (82.0272)  Acc@5: 93.7500 (96.8301)  time: 0.3514  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5064  Acc@1: 81.2500 (82.0336)  Acc@5: 100.0000 (96.8336)  time: 0.3486  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0144  Acc@1: 87.5000 (82.0416)  Acc@5: 100.0000 (96.8337)  time: 0.3488  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.2749  Acc@1: 87.5000 (82.0462)  Acc@5: 100.0000 (96.8305)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.0373  Acc@1: 87.5000 (82.0608)  Acc@5: 100.0000 (96.8356)  time: 0.3546  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -1.0170  Acc@1: 81.2500 (82.0519)  Acc@5: 100.0000 (96.8357)  time: 0.3547  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9534  Acc@1: 81.2500 (82.0483)  Acc@5: 100.0000 (96.8333)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[4/5] Total time: 0:21:48 (0.3490 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 239984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.9534  Acc@1: 81.2500 (82.0483)  Acc@5: 100.0000 (96.8333)
Train: Epoch[5/5]  [   0/3750]  eta: 0:40:41  Lr: 0.001875  Loss: -0.9451  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6510  data: 0.3014  max mem: 2500
Train: Epoch[5/5]  [  10/3750]  eta: 0:23:18  Lr: 0.001875  Loss: -0.9500  Acc@1: 75.0000 (77.8409)  Acc@5: 93.7500 (95.4545)  time: 0.3739  data: 0.0277  max mem: 2500
Train: Epoch[5/5]  [  20/3750]  eta: 0:22:27  Lr: 0.001875  Loss: -1.2968  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (97.0238)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:06  Lr: 0.001875  Loss: -1.0512  Acc@1: 87.5000 (81.0484)  Acc@5: 100.0000 (96.3710)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  40/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -0.9035  Acc@1: 87.5000 (82.0122)  Acc@5: 93.7500 (96.6463)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  50/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -0.7014  Acc@1: 81.2500 (81.4951)  Acc@5: 100.0000 (96.6912)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.9655  Acc@1: 75.0000 (81.0451)  Acc@5: 93.7500 (96.5164)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:31  Lr: 0.001875  Loss: -1.1218  Acc@1: 81.2500 (81.3380)  Acc@5: 100.0000 (96.7430)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:25  Lr: 0.001875  Loss: -1.4240  Acc@1: 87.5000 (81.5586)  Acc@5: 100.0000 (96.9907)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.7027  Acc@1: 81.2500 (81.4560)  Acc@5: 100.0000 (96.9780)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -1.2529  Acc@1: 81.2500 (81.9926)  Acc@5: 100.0000 (96.9059)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.7272  Acc@1: 81.2500 (81.4752)  Acc@5: 100.0000 (96.9032)  time: 0.3461  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -1.2593  Acc@1: 75.0000 (81.6116)  Acc@5: 100.0000 (96.9525)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.9256  Acc@1: 81.2500 (81.5840)  Acc@5: 100.0000 (96.9466)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 140/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -1.5061  Acc@1: 81.2500 (82.0479)  Acc@5: 100.0000 (96.9858)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 150/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -1.1646  Acc@1: 81.2500 (81.9950)  Acc@5: 100.0000 (97.0199)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 160/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -1.5162  Acc@1: 87.5000 (82.2981)  Acc@5: 100.0000 (97.0497)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -1.0008  Acc@1: 87.5000 (82.2368)  Acc@5: 100.0000 (97.0760)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -1.0856  Acc@1: 81.2500 (82.1823)  Acc@5: 100.0000 (97.0994)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -1.0701  Acc@1: 81.2500 (82.1990)  Acc@5: 100.0000 (97.1859)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.7307  Acc@1: 81.2500 (82.0585)  Acc@5: 100.0000 (97.1393)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.8028  Acc@1: 81.2500 (82.0498)  Acc@5: 93.7500 (97.1268)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.7846  Acc@1: 81.2500 (81.9005)  Acc@5: 93.7500 (96.9457)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -1.2039  Acc@1: 81.2500 (81.8994)  Acc@5: 100.0000 (96.9968)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -0.9830  Acc@1: 75.0000 (81.7427)  Acc@5: 100.0000 (96.9398)  time: 0.3495  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.7868  Acc@1: 81.2500 (81.8227)  Acc@5: 100.0000 (96.9871)  time: 0.3503  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -1.1804  Acc@1: 81.2500 (81.8487)  Acc@5: 100.0000 (97.0785)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.8836  Acc@1: 81.2500 (81.9419)  Acc@5: 100.0000 (97.0710)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.6728  Acc@1: 81.2500 (81.9395)  Acc@5: 100.0000 (97.0641)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -1.0906  Acc@1: 81.2500 (81.9802)  Acc@5: 100.0000 (97.0361)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.5941  Acc@1: 81.2500 (81.9975)  Acc@5: 100.0000 (97.0100)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -1.2888  Acc@1: 81.2500 (81.8931)  Acc@5: 100.0000 (96.9855)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 320/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -1.0042  Acc@1: 81.2500 (81.8341)  Acc@5: 100.0000 (97.0016)  time: 0.3539  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.7914  Acc@1: 81.2500 (81.8353)  Acc@5: 100.0000 (97.0355)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -1.1328  Acc@1: 81.2500 (81.7632)  Acc@5: 100.0000 (97.0491)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.9187  Acc@1: 81.2500 (81.6417)  Acc@5: 100.0000 (97.0442)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -1.0336  Acc@1: 81.2500 (81.5789)  Acc@5: 100.0000 (97.0048)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.6230  Acc@1: 81.2500 (81.5701)  Acc@5: 100.0000 (97.0182)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.7013  Acc@1: 81.2500 (81.5781)  Acc@5: 100.0000 (97.0472)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.3768  Acc@1: 81.2500 (81.5857)  Acc@5: 100.0000 (97.0109)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -1.2613  Acc@1: 87.5000 (81.6864)  Acc@5: 100.0000 (96.9919)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -1.1539  Acc@1: 87.5000 (81.7518)  Acc@5: 100.0000 (97.0043)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.9040  Acc@1: 87.5000 (81.8884)  Acc@5: 100.0000 (97.0606)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.7228  Acc@1: 81.2500 (81.8590)  Acc@5: 100.0000 (97.0708)  time: 0.3480  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -1.0703  Acc@1: 81.2500 (81.7744)  Acc@5: 100.0000 (96.9955)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -1.0594  Acc@1: 81.2500 (81.7905)  Acc@5: 93.7500 (96.9651)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -1.0109  Acc@1: 81.2500 (81.8330)  Acc@5: 93.7500 (96.9496)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.7750  Acc@1: 81.2500 (81.8737)  Acc@5: 93.7500 (96.9347)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -1.0888  Acc@1: 81.2500 (81.9517)  Acc@5: 100.0000 (96.9205)  time: 0.3482  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.5023  Acc@1: 81.2500 (81.9628)  Acc@5: 100.0000 (96.9577)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.7651  Acc@1: 81.2500 (81.8239)  Acc@5: 100.0000 (96.9686)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.8729  Acc@1: 81.2500 (81.8860)  Acc@5: 100.0000 (96.9912)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -1.5489  Acc@1: 87.5000 (81.9338)  Acc@5: 100.0000 (96.9770)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.7870  Acc@1: 87.5000 (81.9680)  Acc@5: 100.0000 (96.9986)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -1.3680  Acc@1: 81.2500 (82.0009)  Acc@5: 100.0000 (97.0079)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.7702  Acc@1: 81.2500 (81.8966)  Acc@5: 93.7500 (96.9374)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -1.3362  Acc@1: 81.2500 (81.8627)  Acc@5: 93.7500 (96.9140)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.5310  Acc@1: 75.0000 (81.7754)  Acc@5: 93.7500 (96.9243)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.9682  Acc@1: 75.0000 (81.7556)  Acc@5: 100.0000 (96.9234)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.7881  Acc@1: 81.2500 (81.8316)  Acc@5: 93.7500 (96.9120)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -1.0790  Acc@1: 81.2500 (81.7596)  Acc@5: 100.0000 (96.9322)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.7366  Acc@1: 75.0000 (81.7921)  Acc@5: 100.0000 (96.9517)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -1.0788  Acc@1: 81.2500 (81.7733)  Acc@5: 100.0000 (96.9706)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -1.0090  Acc@1: 81.2500 (81.7849)  Acc@5: 100.0000 (96.9592)  time: 0.3515  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -1.2590  Acc@1: 87.5000 (81.8253)  Acc@5: 93.7500 (96.9579)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.5570  Acc@1: 87.5000 (81.8260)  Acc@5: 100.0000 (96.9662)  time: 0.3529  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -1.0408  Acc@1: 81.2500 (81.8741)  Acc@5: 100.0000 (96.9554)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -1.3178  Acc@1: 81.2500 (81.9020)  Acc@5: 100.0000 (96.9355)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -1.1092  Acc@1: 81.2500 (81.8649)  Acc@5: 93.7500 (96.9163)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -1.1069  Acc@1: 81.2500 (81.8741)  Acc@5: 100.0000 (96.9428)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -1.0411  Acc@1: 75.0000 (81.7760)  Acc@5: 100.0000 (96.9240)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.5675  Acc@1: 81.2500 (81.7598)  Acc@5: 93.7500 (96.9058)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -1.2456  Acc@1: 87.5000 (81.8221)  Acc@5: 100.0000 (96.9227)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -1.3073  Acc@1: 87.5000 (81.8399)  Acc@5: 100.0000 (96.9049)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.9516  Acc@1: 87.5000 (81.8742)  Acc@5: 100.0000 (96.9383)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.7084  Acc@1: 81.2500 (81.8575)  Acc@5: 100.0000 (96.9541)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -0.9519  Acc@1: 81.2500 (81.9152)  Acc@5: 100.0000 (96.9694)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -1.2587  Acc@1: 81.2500 (81.9147)  Acc@5: 100.0000 (96.9763)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -0.9317  Acc@1: 81.2500 (81.8982)  Acc@5: 100.0000 (96.9910)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.7255  Acc@1: 81.2500 (81.9216)  Acc@5: 100.0000 (96.9975)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -1.2084  Acc@1: 75.0000 (81.8352)  Acc@5: 100.0000 (96.9959)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.6658  Acc@1: 75.0000 (81.7895)  Acc@5: 100.0000 (97.0022)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 820/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.9021  Acc@1: 81.2500 (81.7981)  Acc@5: 100.0000 (97.0006)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 830/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.7750  Acc@1: 81.2500 (81.8366)  Acc@5: 100.0000 (97.0141)  time: 0.3459  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -1.0918  Acc@1: 87.5000 (81.8445)  Acc@5: 100.0000 (97.0125)  time: 0.3463  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -1.4317  Acc@1: 87.5000 (81.8669)  Acc@5: 100.0000 (97.0035)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -1.0638  Acc@1: 81.2500 (81.9033)  Acc@5: 100.0000 (97.0166)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -1.2602  Acc@1: 87.5000 (81.9747)  Acc@5: 100.0000 (97.0077)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.7756  Acc@1: 81.2500 (81.9594)  Acc@5: 93.7500 (96.9991)  time: 0.3499  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.8346  Acc@1: 81.2500 (81.9725)  Acc@5: 93.7500 (96.9837)  time: 0.3505  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.9936  Acc@1: 81.2500 (81.9575)  Acc@5: 93.7500 (96.9686)  time: 0.3506  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.4984  Acc@1: 81.2500 (81.9429)  Acc@5: 93.7500 (96.9196)  time: 0.3505  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -1.3302  Acc@1: 81.2500 (81.9693)  Acc@5: 93.7500 (96.9259)  time: 0.3499  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -1.1397  Acc@1: 81.2500 (81.9952)  Acc@5: 100.0000 (96.9253)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.9178  Acc@1: 81.2500 (81.9806)  Acc@5: 100.0000 (96.9447)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -1.1246  Acc@1: 81.2500 (81.9598)  Acc@5: 100.0000 (96.9769)  time: 0.3502  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.8857  Acc@1: 81.2500 (81.9329)  Acc@5: 100.0000 (96.9888)  time: 0.3497  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.6997  Acc@1: 75.0000 (81.8872)  Acc@5: 100.0000 (96.9683)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -1.2699  Acc@1: 75.0000 (81.8807)  Acc@5: 93.7500 (96.9546)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7414  Acc@1: 81.2500 (81.8870)  Acc@5: 100.0000 (96.9475)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1000/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -1.1106  Acc@1: 81.2500 (81.9118)  Acc@5: 100.0000 (96.9530)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.8789  Acc@1: 81.2500 (81.8867)  Acc@5: 100.0000 (96.9585)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -1.0129  Acc@1: 81.2500 (81.9234)  Acc@5: 100.0000 (96.9638)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.9831  Acc@1: 81.2500 (81.8865)  Acc@5: 100.0000 (96.9690)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.6203  Acc@1: 75.0000 (81.8024)  Acc@5: 93.7500 (96.9200)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -1.1941  Acc@1: 75.0000 (81.8030)  Acc@5: 93.7500 (96.9255)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -1.0571  Acc@1: 81.2500 (81.8155)  Acc@5: 100.0000 (96.9545)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.5928  Acc@1: 81.2500 (81.8277)  Acc@5: 100.0000 (96.9421)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -1.3229  Acc@1: 81.2500 (81.8513)  Acc@5: 93.7500 (96.9299)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.9191  Acc@1: 81.2500 (81.8057)  Acc@5: 93.7500 (96.9065)  time: 0.3545  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.7569  Acc@1: 75.0000 (81.8006)  Acc@5: 100.0000 (96.9176)  time: 0.3522  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -1.0662  Acc@1: 81.2500 (81.7901)  Acc@5: 100.0000 (96.9284)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.4371  Acc@1: 81.2500 (81.8075)  Acc@5: 100.0000 (96.9335)  time: 0.3490  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -1.0788  Acc@1: 81.2500 (81.7916)  Acc@5: 100.0000 (96.9330)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.4697  Acc@1: 81.2500 (81.7923)  Acc@5: 100.0000 (96.9380)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -1.1137  Acc@1: 87.5000 (81.8473)  Acc@5: 100.0000 (96.9592)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -1.3227  Acc@1: 87.5000 (81.8691)  Acc@5: 100.0000 (96.9584)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1170/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -1.2339  Acc@1: 81.2500 (81.8691)  Acc@5: 100.0000 (96.9684)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -1.1586  Acc@1: 81.2500 (81.9115)  Acc@5: 100.0000 (96.9729)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.8635  Acc@1: 81.2500 (81.8902)  Acc@5: 100.0000 (96.9668)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -1.1602  Acc@1: 81.2500 (81.9161)  Acc@5: 100.0000 (96.9713)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.8999  Acc@1: 81.2500 (81.8900)  Acc@5: 100.0000 (96.9447)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -1.2639  Acc@1: 81.2500 (81.8745)  Acc@5: 93.7500 (96.9441)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -1.2623  Acc@1: 87.5000 (81.9151)  Acc@5: 100.0000 (96.9537)  time: 0.3474  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -1.0954  Acc@1: 87.5000 (81.8946)  Acc@5: 100.0000 (96.9581)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -1.2031  Acc@1: 81.2500 (81.9295)  Acc@5: 100.0000 (96.9524)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -1.3211  Acc@1: 87.5000 (81.9191)  Acc@5: 100.0000 (96.9568)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.8006  Acc@1: 81.2500 (81.9237)  Acc@5: 100.0000 (96.9414)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.9771  Acc@1: 81.2500 (81.9672)  Acc@5: 100.0000 (96.9604)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -1.0164  Acc@1: 87.5000 (81.9520)  Acc@5: 100.0000 (96.9500)  time: 0.3554  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5762  Acc@1: 81.2500 (81.9322)  Acc@5: 100.0000 (96.9495)  time: 0.3547  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.9706  Acc@1: 81.2500 (81.9413)  Acc@5: 100.0000 (96.9489)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.9876  Acc@1: 81.2500 (81.9644)  Acc@5: 100.0000 (96.9531)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -1.2563  Acc@1: 87.5000 (81.9872)  Acc@5: 100.0000 (96.9572)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1340/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -1.1769  Acc@1: 87.5000 (82.0237)  Acc@5: 100.0000 (96.9612)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -1.2735  Acc@1: 87.5000 (82.0272)  Acc@5: 100.0000 (96.9652)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.3960  Acc@1: 81.2500 (82.0123)  Acc@5: 100.0000 (96.9783)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -1.0768  Acc@1: 81.2500 (82.0478)  Acc@5: 100.0000 (96.9776)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -1.0969  Acc@1: 81.2500 (82.0103)  Acc@5: 100.0000 (96.9723)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -1.0385  Acc@1: 81.2500 (82.0363)  Acc@5: 100.0000 (96.9896)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.5759  Acc@1: 81.2500 (82.0173)  Acc@5: 100.0000 (96.9843)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -1.1466  Acc@1: 81.2500 (82.0163)  Acc@5: 100.0000 (96.9924)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.5891  Acc@1: 75.0000 (82.0109)  Acc@5: 100.0000 (97.0048)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -1.2670  Acc@1: 81.2500 (82.0231)  Acc@5: 100.0000 (97.0082)  time: 0.3515  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -1.1317  Acc@1: 81.2500 (82.0134)  Acc@5: 100.0000 (97.0116)  time: 0.3514  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -1.2859  Acc@1: 81.2500 (82.0296)  Acc@5: 100.0000 (97.0236)  time: 0.3523  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.8899  Acc@1: 81.2500 (82.0329)  Acc@5: 100.0000 (97.0226)  time: 0.3526  data: 0.0023  max mem: 2500
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -1.4501  Acc@1: 81.2500 (82.0530)  Acc@5: 100.0000 (97.0258)  time: 0.3488  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.7079  Acc@1: 81.2500 (82.0518)  Acc@5: 100.0000 (97.0375)  time: 0.3480  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -0.9455  Acc@1: 81.2500 (82.0381)  Acc@5: 100.0000 (97.0322)  time: 0.3492  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -1.0621  Acc@1: 81.2500 (82.0328)  Acc@5: 100.0000 (97.0353)  time: 0.3481  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.8357  Acc@1: 81.2500 (81.9863)  Acc@5: 100.0000 (97.0136)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.8891  Acc@1: 75.0000 (81.9609)  Acc@5: 93.7500 (96.9880)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.6303  Acc@1: 81.2500 (81.9603)  Acc@5: 100.0000 (96.9995)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.8846  Acc@1: 81.2500 (81.9800)  Acc@5: 100.0000 (96.9987)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.6940  Acc@1: 87.5000 (82.0197)  Acc@5: 93.7500 (96.9858)  time: 0.3483  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -1.1454  Acc@1: 87.5000 (82.0267)  Acc@5: 100.0000 (96.9891)  time: 0.3471  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.6040  Acc@1: 81.2500 (82.0337)  Acc@5: 100.0000 (96.9884)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -1.1815  Acc@1: 81.2500 (82.0406)  Acc@5: 100.0000 (96.9877)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -1.3303  Acc@1: 81.2500 (82.0317)  Acc@5: 100.0000 (96.9870)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.9631  Acc@1: 81.2500 (82.0073)  Acc@5: 93.7500 (96.9745)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.9476  Acc@1: 81.2500 (81.9871)  Acc@5: 100.0000 (96.9856)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.8584  Acc@1: 81.2500 (82.0019)  Acc@5: 100.0000 (97.0003)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.7767  Acc@1: 81.2500 (81.9934)  Acc@5: 100.0000 (97.0110)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.8308  Acc@1: 81.2500 (81.9965)  Acc@5: 100.0000 (97.0102)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -1.2993  Acc@1: 81.2500 (82.0147)  Acc@5: 100.0000 (97.0094)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -1.0393  Acc@1: 81.2500 (82.0101)  Acc@5: 100.0000 (96.9973)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.9803  Acc@1: 81.2500 (82.0130)  Acc@5: 93.7500 (96.9816)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.3852  Acc@1: 87.5000 (82.0345)  Acc@5: 93.7500 (96.9810)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.2760  Acc@1: 87.5000 (82.0299)  Acc@5: 100.0000 (96.9766)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.7799  Acc@1: 75.0000 (81.9922)  Acc@5: 93.7500 (96.9577)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -1.1721  Acc@1: 81.2500 (82.0354)  Acc@5: 93.7500 (96.9572)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -1.1879  Acc@1: 87.5000 (82.0526)  Acc@5: 100.0000 (96.9640)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.7539  Acc@1: 81.2500 (82.0479)  Acc@5: 93.7500 (96.9490)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.8926  Acc@1: 81.2500 (82.0613)  Acc@5: 93.7500 (96.9378)  time: 0.3504  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -1.1783  Acc@1: 87.5000 (82.0817)  Acc@5: 100.0000 (96.9446)  time: 0.3498  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.9434  Acc@1: 87.5000 (82.0769)  Acc@5: 100.0000 (96.9371)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.8128  Acc@1: 81.2500 (82.0687)  Acc@5: 93.7500 (96.9297)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -1.0229  Acc@1: 81.2500 (82.0817)  Acc@5: 93.7500 (96.9294)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -1.0243  Acc@1: 87.5000 (82.1015)  Acc@5: 100.0000 (96.9326)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.8763  Acc@1: 87.5000 (82.1106)  Acc@5: 100.0000 (96.9392)  time: 0.3534  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.1978  Acc@1: 87.5000 (82.1197)  Acc@5: 100.0000 (96.9423)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.8224  Acc@1: 87.5000 (82.1286)  Acc@5: 100.0000 (96.9488)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -1.0153  Acc@1: 81.2500 (82.1238)  Acc@5: 100.0000 (96.9620)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -1.3432  Acc@1: 81.2500 (82.1225)  Acc@5: 100.0000 (96.9582)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.5314  Acc@1: 81.2500 (82.0941)  Acc@5: 100.0000 (96.9577)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -0.8603  Acc@1: 81.2500 (82.0930)  Acc@5: 100.0000 (96.9438)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -1.0307  Acc@1: 81.2500 (82.0651)  Acc@5: 93.7500 (96.9335)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.7569  Acc@1: 81.2500 (82.0508)  Acc@5: 93.7500 (96.9331)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -1.1195  Acc@1: 81.2500 (82.0598)  Acc@5: 93.7500 (96.9295)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.3561  Acc@1: 81.2500 (82.0588)  Acc@5: 93.7500 (96.9292)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.8259  Acc@1: 81.2500 (82.0742)  Acc@5: 93.7500 (96.9257)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -1.2057  Acc@1: 87.5000 (82.0829)  Acc@5: 100.0000 (96.9352)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -1.0331  Acc@1: 81.2500 (82.0753)  Acc@5: 100.0000 (96.9349)  time: 0.3482  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -1.0994  Acc@1: 81.2500 (82.0969)  Acc@5: 100.0000 (96.9378)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -1.0970  Acc@1: 81.2500 (82.0989)  Acc@5: 100.0000 (96.9407)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -1.0968  Acc@1: 81.2500 (82.1169)  Acc@5: 93.7500 (96.9340)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -1.0395  Acc@1: 81.2500 (82.1188)  Acc@5: 93.7500 (96.9178)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -1.0896  Acc@1: 81.2500 (82.1239)  Acc@5: 93.7500 (96.9271)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.9178  Acc@1: 87.5000 (82.1101)  Acc@5: 100.0000 (96.9268)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -1.1908  Acc@1: 81.2500 (82.1121)  Acc@5: 100.0000 (96.9265)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.8931  Acc@1: 81.2500 (82.1016)  Acc@5: 100.0000 (96.9356)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.7946  Acc@1: 81.2500 (82.1190)  Acc@5: 100.0000 (96.9477)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2030/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -1.1323  Acc@1: 87.5000 (82.1240)  Acc@5: 100.0000 (96.9504)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -1.1022  Acc@1: 87.5000 (82.1442)  Acc@5: 100.0000 (96.9592)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -1.0283  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (96.9405)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.8408  Acc@1: 81.2500 (82.1537)  Acc@5: 93.7500 (96.9372)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.9554  Acc@1: 87.5000 (82.1795)  Acc@5: 93.7500 (96.9278)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.4579  Acc@1: 81.2500 (82.1570)  Acc@5: 100.0000 (96.9306)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -1.2674  Acc@1: 75.0000 (82.1377)  Acc@5: 100.0000 (96.9333)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.8564  Acc@1: 75.0000 (82.1186)  Acc@5: 100.0000 (96.9390)  time: 0.3493  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.6709  Acc@1: 81.2500 (82.1293)  Acc@5: 100.0000 (96.9298)  time: 0.3489  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -1.1893  Acc@1: 87.5000 (82.1429)  Acc@5: 93.7500 (96.9236)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.8232  Acc@1: 87.5000 (82.1563)  Acc@5: 100.0000 (96.9322)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.8749  Acc@1: 81.2500 (82.1462)  Acc@5: 100.0000 (96.9290)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.7962  Acc@1: 81.2500 (82.1391)  Acc@5: 100.0000 (96.9258)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.7653  Acc@1: 81.2500 (82.1466)  Acc@5: 100.0000 (96.9256)  time: 0.3524  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -1.0705  Acc@1: 87.5000 (82.1626)  Acc@5: 100.0000 (96.9340)  time: 0.3536  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.8178  Acc@1: 75.0000 (82.1441)  Acc@5: 100.0000 (96.9194)  time: 0.3520  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -1.1636  Acc@1: 81.2500 (82.1543)  Acc@5: 93.7500 (96.9249)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2200/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.8293  Acc@1: 87.5000 (82.1615)  Acc@5: 100.0000 (96.9190)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.8419  Acc@1: 81.2500 (82.1517)  Acc@5: 100.0000 (96.9245)  time: 0.3489  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -1.0558  Acc@1: 81.2500 (82.1561)  Acc@5: 100.0000 (96.9186)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -1.1810  Acc@1: 81.2500 (82.1661)  Acc@5: 93.7500 (96.9156)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -1.2937  Acc@1: 87.5000 (82.1787)  Acc@5: 100.0000 (96.9238)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -1.2366  Acc@1: 87.5000 (82.1940)  Acc@5: 100.0000 (96.9236)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.1891  Acc@1: 87.5000 (82.1926)  Acc@5: 100.0000 (96.9178)  time: 0.3508  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -1.1884  Acc@1: 81.2500 (82.1857)  Acc@5: 100.0000 (96.9259)  time: 0.3503  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.5478  Acc@1: 81.2500 (82.1843)  Acc@5: 100.0000 (96.9230)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.5766  Acc@1: 81.2500 (82.1803)  Acc@5: 100.0000 (96.9227)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -1.0966  Acc@1: 81.2500 (82.1871)  Acc@5: 100.0000 (96.9280)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -1.1282  Acc@1: 81.2500 (82.1830)  Acc@5: 100.0000 (96.9277)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.9876  Acc@1: 81.2500 (82.2059)  Acc@5: 100.0000 (96.9248)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -1.1572  Acc@1: 81.2500 (82.2099)  Acc@5: 100.0000 (96.9326)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -1.1531  Acc@1: 87.5000 (82.2271)  Acc@5: 100.0000 (96.9324)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.6170  Acc@1: 87.5000 (82.2177)  Acc@5: 93.7500 (96.9268)  time: 0.3452  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.7164  Acc@1: 87.5000 (82.2374)  Acc@5: 100.0000 (96.9293)  time: 0.3455  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.4424  Acc@1: 87.5000 (82.2411)  Acc@5: 100.0000 (96.9317)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -1.3598  Acc@1: 81.2500 (82.2344)  Acc@5: 100.0000 (96.9314)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -1.3048  Acc@1: 81.2500 (82.2224)  Acc@5: 100.0000 (96.9207)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.4649  Acc@1: 81.2500 (82.2183)  Acc@5: 100.0000 (96.9310)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -1.1952  Acc@1: 81.2500 (82.2040)  Acc@5: 100.0000 (96.9307)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -1.1108  Acc@1: 81.2500 (82.2052)  Acc@5: 100.0000 (96.9305)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.6281  Acc@1: 81.2500 (82.1987)  Acc@5: 100.0000 (96.9303)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.5000  Acc@1: 81.2500 (82.2050)  Acc@5: 93.7500 (96.9224)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -1.1169  Acc@1: 81.2500 (82.2088)  Acc@5: 93.7500 (96.9069)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -1.4864  Acc@1: 81.2500 (82.2024)  Acc@5: 93.7500 (96.9118)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -1.2291  Acc@1: 81.2500 (82.2213)  Acc@5: 100.0000 (96.9142)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.9276  Acc@1: 87.5000 (82.2325)  Acc@5: 100.0000 (96.9191)  time: 0.3503  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.3649  Acc@1: 81.2500 (82.2110)  Acc@5: 100.0000 (96.9114)  time: 0.3509  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.9763  Acc@1: 81.2500 (82.2196)  Acc@5: 93.7500 (96.9112)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -1.2392  Acc@1: 87.5000 (82.2282)  Acc@5: 100.0000 (96.9161)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.8490  Acc@1: 81.2500 (82.2243)  Acc@5: 100.0000 (96.9109)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -1.2427  Acc@1: 81.2500 (82.2279)  Acc@5: 100.0000 (96.9034)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -1.0103  Acc@1: 81.2500 (82.2216)  Acc@5: 100.0000 (96.9033)  time: 0.3490  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -1.2195  Acc@1: 81.2500 (82.2447)  Acc@5: 100.0000 (96.9032)  time: 0.3489  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -1.2596  Acc@1: 87.5000 (82.2433)  Acc@5: 100.0000 (96.9079)  time: 0.3505  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.8730  Acc@1: 81.2500 (82.2248)  Acc@5: 100.0000 (96.9030)  time: 0.3551  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -1.1590  Acc@1: 81.2500 (82.2404)  Acc@5: 93.7500 (96.9004)  time: 0.3548  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.9717  Acc@1: 81.2500 (82.2438)  Acc@5: 93.7500 (96.9027)  time: 0.3526  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.7491  Acc@1: 81.2500 (82.2088)  Acc@5: 100.0000 (96.8954)  time: 0.3518  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -1.2030  Acc@1: 81.2500 (82.2195)  Acc@5: 93.7500 (96.8906)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -1.2545  Acc@1: 81.2500 (82.2277)  Acc@5: 100.0000 (96.8977)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.7271  Acc@1: 87.5000 (82.2382)  Acc@5: 100.0000 (96.9023)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.8993  Acc@1: 81.2500 (82.2274)  Acc@5: 100.0000 (96.9069)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.9477  Acc@1: 81.2500 (82.2119)  Acc@5: 100.0000 (96.9092)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -1.1074  Acc@1: 81.2500 (82.2200)  Acc@5: 100.0000 (96.9114)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -1.2135  Acc@1: 81.2500 (82.2047)  Acc@5: 93.7500 (96.9066)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.9653  Acc@1: 81.2500 (82.2175)  Acc@5: 93.7500 (96.8995)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.2413  Acc@1: 87.5000 (82.2185)  Acc@5: 100.0000 (96.8947)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -1.0577  Acc@1: 87.5000 (82.2288)  Acc@5: 93.7500 (96.8877)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -1.1769  Acc@1: 87.5000 (82.2206)  Acc@5: 93.7500 (96.8854)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -1.3306  Acc@1: 81.2500 (82.2170)  Acc@5: 100.0000 (96.8853)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -1.1294  Acc@1: 87.5000 (82.2364)  Acc@5: 100.0000 (96.8876)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.7550  Acc@1: 81.2500 (82.2442)  Acc@5: 100.0000 (96.8921)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -1.2124  Acc@1: 81.2500 (82.2587)  Acc@5: 100.0000 (96.8989)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -1.0203  Acc@1: 87.5000 (82.2573)  Acc@5: 100.0000 (96.8942)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -1.2363  Acc@1: 81.2500 (82.2582)  Acc@5: 93.7500 (96.8942)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.7817  Acc@1: 81.2500 (82.2546)  Acc@5: 100.0000 (96.8941)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.9723  Acc@1: 81.2500 (82.2487)  Acc@5: 100.0000 (96.8940)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.8351  Acc@1: 81.2500 (82.2385)  Acc@5: 100.0000 (96.8962)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.9407  Acc@1: 81.2500 (82.2416)  Acc@5: 100.0000 (96.9006)  time: 0.3461  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -1.3197  Acc@1: 81.2500 (82.2293)  Acc@5: 100.0000 (96.9049)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -1.1471  Acc@1: 75.0000 (82.2346)  Acc@5: 100.0000 (96.9048)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -1.1336  Acc@1: 81.2500 (82.2356)  Acc@5: 100.0000 (96.9091)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.7887  Acc@1: 81.2500 (82.2343)  Acc@5: 100.0000 (96.9156)  time: 0.3479  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.9812  Acc@1: 81.2500 (82.2265)  Acc@5: 100.0000 (96.9198)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -1.1004  Acc@1: 81.2500 (82.2209)  Acc@5: 100.0000 (96.9153)  time: 0.3498  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.4134  Acc@1: 81.2500 (82.2219)  Acc@5: 93.7500 (96.9108)  time: 0.3520  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -1.1678  Acc@1: 81.2500 (82.2164)  Acc@5: 100.0000 (96.9063)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.8800  Acc@1: 81.2500 (82.2260)  Acc@5: 93.7500 (96.8998)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -1.1054  Acc@1: 81.2500 (82.2312)  Acc@5: 93.7500 (96.8954)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.9627  Acc@1: 81.2500 (82.2407)  Acc@5: 93.7500 (96.8910)  time: 0.3493  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -1.1766  Acc@1: 87.5000 (82.2330)  Acc@5: 93.7500 (96.8889)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -1.3562  Acc@1: 81.2500 (82.2403)  Acc@5: 100.0000 (96.8952)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -1.3096  Acc@1: 87.5000 (82.2560)  Acc@5: 100.0000 (96.8951)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.8814  Acc@1: 87.5000 (82.2611)  Acc@5: 100.0000 (96.8993)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -1.3412  Acc@1: 81.2500 (82.2598)  Acc@5: 100.0000 (96.8887)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.5514  Acc@1: 81.2500 (82.2606)  Acc@5: 93.7500 (96.8844)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.6610  Acc@1: 81.2500 (82.2593)  Acc@5: 100.0000 (96.8802)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -1.1191  Acc@1: 87.5000 (82.2767)  Acc@5: 100.0000 (96.8823)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -1.2732  Acc@1: 87.5000 (82.2754)  Acc@5: 100.0000 (96.8823)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.7723  Acc@1: 81.2500 (82.2762)  Acc@5: 93.7500 (96.8802)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -1.2857  Acc@1: 81.2500 (82.2851)  Acc@5: 93.7500 (96.8802)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -1.1876  Acc@1: 87.5000 (82.3023)  Acc@5: 100.0000 (96.8842)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -1.3529  Acc@1: 87.5000 (82.3029)  Acc@5: 100.0000 (96.8904)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.6214  Acc@1: 75.0000 (82.2954)  Acc@5: 100.0000 (96.8903)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.9795  Acc@1: 75.0000 (82.2839)  Acc@5: 100.0000 (96.8821)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -1.1522  Acc@1: 81.2500 (82.2947)  Acc@5: 100.0000 (96.8821)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.9056  Acc@1: 81.2500 (82.2954)  Acc@5: 100.0000 (96.8801)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.0569  Acc@1: 81.2500 (82.3041)  Acc@5: 100.0000 (96.8800)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7854  Acc@1: 87.5000 (82.3208)  Acc@5: 100.0000 (96.8820)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.6961  Acc@1: 81.2500 (82.3154)  Acc@5: 100.0000 (96.8840)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -1.0082  Acc@1: 81.2500 (82.3239)  Acc@5: 93.7500 (96.8780)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.8850  Acc@1: 81.2500 (82.3205)  Acc@5: 93.7500 (96.8820)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -1.1224  Acc@1: 81.2500 (82.3211)  Acc@5: 100.0000 (96.8819)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.6598  Acc@1: 81.2500 (82.3039)  Acc@5: 93.7500 (96.8701)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.6855  Acc@1: 81.2500 (82.3183)  Acc@5: 93.7500 (96.8701)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.7884  Acc@1: 81.2500 (82.3169)  Acc@5: 100.0000 (96.8642)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.3071  Acc@1: 81.2500 (82.3233)  Acc@5: 100.0000 (96.8681)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.8704  Acc@1: 87.5000 (82.3239)  Acc@5: 100.0000 (96.8682)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -1.3665  Acc@1: 81.2500 (82.3322)  Acc@5: 100.0000 (96.8760)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.8384  Acc@1: 87.5000 (82.3366)  Acc@5: 100.0000 (96.8721)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -1.3964  Acc@1: 87.5000 (82.3468)  Acc@5: 100.0000 (96.8760)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -1.1135  Acc@1: 87.5000 (82.3492)  Acc@5: 100.0000 (96.8779)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -1.3215  Acc@1: 81.2500 (82.3593)  Acc@5: 100.0000 (96.8817)  time: 0.3490  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -1.2398  Acc@1: 87.5000 (82.3635)  Acc@5: 100.0000 (96.8836)  time: 0.3486  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.6321  Acc@1: 81.2500 (82.3659)  Acc@5: 100.0000 (96.8817)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -1.0158  Acc@1: 81.2500 (82.3739)  Acc@5: 100.0000 (96.8798)  time: 0.3514  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.1931  Acc@1: 81.2500 (82.3838)  Acc@5: 100.0000 (96.8816)  time: 0.3520  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.8319  Acc@1: 81.2500 (82.3822)  Acc@5: 100.0000 (96.8892)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.3477  Acc@1: 81.2500 (82.3883)  Acc@5: 100.0000 (96.8948)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -1.0920  Acc@1: 81.2500 (82.3773)  Acc@5: 100.0000 (96.8854)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.7237  Acc@1: 81.2500 (82.3702)  Acc@5: 93.7500 (96.8872)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -1.4290  Acc@1: 81.2500 (82.3762)  Acc@5: 100.0000 (96.8928)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.1301  Acc@1: 87.5000 (82.3840)  Acc@5: 100.0000 (96.8964)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -1.2572  Acc@1: 81.2500 (82.3806)  Acc@5: 100.0000 (96.8945)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.8024  Acc@1: 81.2500 (82.3865)  Acc@5: 100.0000 (96.8908)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.8822  Acc@1: 81.2500 (82.3850)  Acc@5: 100.0000 (96.8926)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.0189  Acc@1: 81.2500 (82.3780)  Acc@5: 100.0000 (96.8925)  time: 0.3518  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.9088  Acc@1: 81.2500 (82.4059)  Acc@5: 100.0000 (96.8998)  time: 0.3526  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9457  Acc@1: 87.5000 (82.3989)  Acc@5: 100.0000 (96.9052)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -1.3193  Acc@1: 87.5000 (82.4156)  Acc@5: 100.0000 (96.9015)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.3964  Acc@1: 81.2500 (82.3958)  Acc@5: 100.0000 (96.9014)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.0734  Acc@1: 75.0000 (82.3925)  Acc@5: 100.0000 (96.9050)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7761  Acc@1: 81.2500 (82.3910)  Acc@5: 100.0000 (96.9031)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9747  Acc@1: 81.2500 (82.3895)  Acc@5: 93.7500 (96.9012)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9612  Acc@1: 81.2500 (82.3970)  Acc@5: 100.0000 (96.9047)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.3069  Acc@1: 81.2500 (82.3865)  Acc@5: 100.0000 (96.8974)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.9474  Acc@1: 81.2500 (82.3904)  Acc@5: 100.0000 (96.9010)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9885  Acc@1: 87.5000 (82.4104)  Acc@5: 100.0000 (96.9062)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -1.2737  Acc@1: 81.2500 (82.4017)  Acc@5: 100.0000 (96.9097)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.9229  Acc@1: 81.2500 (82.4056)  Acc@5: 100.0000 (96.9114)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -1.1228  Acc@1: 81.2500 (82.4165)  Acc@5: 100.0000 (96.9095)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.1041  Acc@1: 87.5000 (82.4132)  Acc@5: 100.0000 (96.9147)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.8388  Acc@1: 81.2500 (82.4064)  Acc@5: 100.0000 (96.9128)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.9395  Acc@1: 81.2500 (82.4224)  Acc@5: 93.7500 (96.9127)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.0680  Acc@1: 81.2500 (82.4209)  Acc@5: 93.7500 (96.9091)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0156  Acc@1: 81.2500 (82.4211)  Acc@5: 93.7500 (96.9021)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -1.2463  Acc@1: 81.2500 (82.4196)  Acc@5: 93.7500 (96.9020)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.3627  Acc@1: 87.5000 (82.4337)  Acc@5: 100.0000 (96.9088)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.3405  Acc@1: 87.5000 (82.4373)  Acc@5: 100.0000 (96.9088)  time: 0.3553  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.0053  Acc@1: 87.5000 (82.4548)  Acc@5: 100.0000 (96.9121)  time: 0.3540  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -1.1505  Acc@1: 87.5000 (82.4704)  Acc@5: 100.0000 (96.9120)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.0369  Acc@1: 81.2500 (82.4533)  Acc@5: 93.7500 (96.9050)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.3610  Acc@1: 81.2500 (82.4517)  Acc@5: 93.7500 (96.9067)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.8437  Acc@1: 81.2500 (82.4553)  Acc@5: 100.0000 (96.9049)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -1.0682  Acc@1: 81.2500 (82.4571)  Acc@5: 100.0000 (96.9082)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.2840  Acc@1: 87.5000 (82.4725)  Acc@5: 100.0000 (96.9098)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6010  Acc@1: 87.5000 (82.4641)  Acc@5: 100.0000 (96.9131)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6819  Acc@1: 81.2500 (82.4625)  Acc@5: 100.0000 (96.9062)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.0607  Acc@1: 75.0000 (82.4390)  Acc@5: 93.7500 (96.9045)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.3745  Acc@1: 75.0000 (82.4358)  Acc@5: 100.0000 (96.9078)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.2484  Acc@1: 81.2500 (82.4243)  Acc@5: 100.0000 (96.9060)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6518  Acc@1: 81.2500 (82.4145)  Acc@5: 100.0000 (96.9076)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.3375  Acc@1: 81.2500 (82.4183)  Acc@5: 100.0000 (96.9083)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[5/5] Total time: 0:21:47 (0.3487 s / it)
{0: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.3375  Acc@1: 81.2500 (82.4183)  Acc@5: 100.0000 (96.9083)
Test: [Task 1]  [   0/1627]  eta: 0:18:53  Loss: 1.1903 (1.1903)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6968  data: 0.4813  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:59  Loss: 1.1800 (1.0813)  Acc@1: 68.7500 (69.3182)  Acc@5: 100.0000 (96.5909)  time: 0.2596  data: 0.0444  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:23  Loss: 1.0832 (1.0516)  Acc@1: 68.7500 (71.1310)  Acc@5: 100.0000 (95.8333)  time: 0.2156  data: 0.0009  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:08  Loss: 1.0336 (1.0517)  Acc@1: 75.0000 (71.9758)  Acc@5: 100.0000 (95.9677)  time: 0.2152  data: 0.0010  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 1.1101 (1.0748)  Acc@1: 68.7500 (70.8841)  Acc@5: 100.0000 (95.7317)  time: 0.2144  data: 0.0006  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:54  Loss: 1.1032 (1.0502)  Acc@1: 68.7500 (72.0588)  Acc@5: 100.0000 (95.9559)  time: 0.2149  data: 0.0006  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:49  Loss: 1.1276 (1.0720)  Acc@1: 75.0000 (71.3115)  Acc@5: 100.0000 (95.6967)  time: 0.2158  data: 0.0007  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:45  Loss: 1.0174 (1.0636)  Acc@1: 68.7500 (71.8310)  Acc@5: 93.7500 (95.8627)  time: 0.2155  data: 0.0012  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:42  Loss: 0.8564 (1.0524)  Acc@1: 75.0000 (72.1451)  Acc@5: 100.0000 (96.0648)  time: 0.2154  data: 0.0011  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:39  Loss: 0.9936 (1.0656)  Acc@1: 68.7500 (71.4973)  Acc@5: 100.0000 (96.0852)  time: 0.2152  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:36  Loss: 1.0863 (1.0840)  Acc@1: 68.7500 (71.1634)  Acc@5: 93.7500 (95.9777)  time: 0.2156  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:33  Loss: 0.9743 (1.0721)  Acc@1: 68.7500 (71.3964)  Acc@5: 100.0000 (96.1712)  time: 0.2165  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:31  Loss: 0.9743 (1.0702)  Acc@1: 68.7500 (71.5909)  Acc@5: 93.7500 (95.9711)  time: 0.2188  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:28  Loss: 1.0711 (1.0726)  Acc@1: 68.7500 (71.4218)  Acc@5: 93.7500 (95.8969)  time: 0.2174  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:25  Loss: 1.0068 (1.0677)  Acc@1: 68.7500 (71.4539)  Acc@5: 93.7500 (95.9220)  time: 0.2150  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:23  Loss: 0.7926 (1.0501)  Acc@1: 75.0000 (71.8957)  Acc@5: 100.0000 (95.9851)  time: 0.2182  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:21  Loss: 0.8081 (1.0454)  Acc@1: 75.0000 (72.2050)  Acc@5: 100.0000 (95.9627)  time: 0.2192  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:19  Loss: 0.8777 (1.0367)  Acc@1: 75.0000 (72.3319)  Acc@5: 100.0000 (96.1257)  time: 0.2168  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:16  Loss: 1.0912 (1.0474)  Acc@1: 68.7500 (72.0304)  Acc@5: 100.0000 (96.0290)  time: 0.2160  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:14  Loss: 1.0912 (1.0450)  Acc@1: 68.7500 (72.1204)  Acc@5: 93.7500 (96.0406)  time: 0.2156  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:11  Loss: 1.0070 (1.0432)  Acc@1: 75.0000 (72.3570)  Acc@5: 100.0000 (96.0821)  time: 0.2150  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:09  Loss: 1.0070 (1.0418)  Acc@1: 75.0000 (72.5711)  Acc@5: 100.0000 (96.0012)  time: 0.2151  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:06  Loss: 0.8858 (1.0444)  Acc@1: 75.0000 (72.5962)  Acc@5: 100.0000 (96.0124)  time: 0.2154  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:04  Loss: 0.8858 (1.0364)  Acc@1: 75.0000 (72.9167)  Acc@5: 100.0000 (96.0498)  time: 0.2156  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:02  Loss: 0.9421 (1.0331)  Acc@1: 75.0000 (72.8994)  Acc@5: 93.7500 (96.0581)  time: 0.2155  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:00  Loss: 0.9464 (1.0384)  Acc@1: 75.0000 (72.9084)  Acc@5: 93.7500 (95.9910)  time: 0.2161  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:57  Loss: 0.9467 (1.0381)  Acc@1: 75.0000 (72.9646)  Acc@5: 93.7500 (95.9052)  time: 0.2163  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:55  Loss: 0.8909 (1.0316)  Acc@1: 75.0000 (73.0627)  Acc@5: 100.0000 (96.0101)  time: 0.2154  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:53  Loss: 0.8466 (1.0330)  Acc@1: 75.0000 (73.1094)  Acc@5: 100.0000 (95.9520)  time: 0.2155  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:50  Loss: 1.0438 (1.0335)  Acc@1: 75.0000 (73.0455)  Acc@5: 100.0000 (95.9622)  time: 0.2156  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:48  Loss: 1.0149 (1.0321)  Acc@1: 75.0000 (73.0066)  Acc@5: 100.0000 (95.9510)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:46  Loss: 0.9088 (1.0340)  Acc@1: 75.0000 (73.0105)  Acc@5: 100.0000 (96.0209)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:43  Loss: 0.9954 (1.0320)  Acc@1: 75.0000 (72.9945)  Acc@5: 100.0000 (96.0475)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:41  Loss: 0.9624 (1.0306)  Acc@1: 75.0000 (73.0740)  Acc@5: 100.0000 (96.0725)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:39  Loss: 0.9346 (1.0305)  Acc@1: 75.0000 (73.1855)  Acc@5: 100.0000 (96.1144)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:37  Loss: 0.9392 (1.0294)  Acc@1: 81.2500 (73.2372)  Acc@5: 100.0000 (96.0826)  time: 0.2141  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:34  Loss: 0.9968 (1.0286)  Acc@1: 81.2500 (73.3553)  Acc@5: 93.7500 (96.0873)  time: 0.2152  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:32  Loss: 0.9822 (1.0279)  Acc@1: 75.0000 (73.2480)  Acc@5: 100.0000 (96.1085)  time: 0.2151  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:30  Loss: 0.9497 (1.0268)  Acc@1: 68.7500 (73.1791)  Acc@5: 93.7500 (96.0958)  time: 0.2141  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:28  Loss: 0.9672 (1.0281)  Acc@1: 68.7500 (73.1618)  Acc@5: 93.7500 (96.0678)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:25  Loss: 1.0171 (1.0292)  Acc@1: 75.0000 (73.0985)  Acc@5: 93.7500 (96.0567)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:23  Loss: 0.9790 (1.0306)  Acc@1: 68.7500 (73.0535)  Acc@5: 93.7500 (95.9854)  time: 0.2130  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:21  Loss: 0.9790 (1.0301)  Acc@1: 68.7500 (73.0701)  Acc@5: 93.7500 (96.0214)  time: 0.2132  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:19  Loss: 0.9062 (1.0288)  Acc@1: 75.0000 (73.0568)  Acc@5: 100.0000 (96.0267)  time: 0.2131  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:16  Loss: 1.0199 (1.0282)  Acc@1: 68.7500 (73.1293)  Acc@5: 100.0000 (96.0743)  time: 0.2129  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:14  Loss: 1.1082 (1.0317)  Acc@1: 68.7500 (72.9767)  Acc@5: 93.7500 (96.0227)  time: 0.2129  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 0.9965 (1.0310)  Acc@1: 68.7500 (72.9799)  Acc@5: 93.7500 (96.0412)  time: 0.2133  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:10  Loss: 0.8838 (1.0279)  Acc@1: 75.0000 (73.1157)  Acc@5: 100.0000 (96.0855)  time: 0.2133  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:07  Loss: 1.0317 (1.0321)  Acc@1: 68.7500 (73.0120)  Acc@5: 100.0000 (96.0499)  time: 0.2130  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 1.0317 (1.0321)  Acc@1: 68.7500 (73.0015)  Acc@5: 93.7500 (96.0412)  time: 0.2131  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 0.9340 (1.0331)  Acc@1: 75.0000 (73.0165)  Acc@5: 93.7500 (96.0205)  time: 0.2133  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:01  Loss: 1.0025 (1.0387)  Acc@1: 75.0000 (72.9330)  Acc@5: 93.7500 (95.9760)  time: 0.2134  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:03:58  Loss: 1.1245 (1.0465)  Acc@1: 68.7500 (72.7927)  Acc@5: 93.7500 (95.9213)  time: 0.2141  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:56  Loss: 0.9867 (1.0423)  Acc@1: 75.0000 (72.9755)  Acc@5: 100.0000 (95.9628)  time: 0.2147  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 0.9800 (1.0420)  Acc@1: 75.0000 (72.9898)  Acc@5: 93.7500 (95.9335)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 1.1800 (1.0443)  Acc@1: 68.7500 (72.9242)  Acc@5: 93.7500 (95.9165)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 1.1988 (1.0467)  Acc@1: 68.7500 (72.8275)  Acc@5: 93.7500 (95.9225)  time: 0.2165  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:48  Loss: 1.0056 (1.0453)  Acc@1: 68.7500 (72.8875)  Acc@5: 93.7500 (95.9063)  time: 0.2168  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:45  Loss: 0.9930 (1.0456)  Acc@1: 68.7500 (72.8270)  Acc@5: 93.7500 (95.9122)  time: 0.2148  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:43  Loss: 1.0508 (1.0450)  Acc@1: 68.7500 (72.7792)  Acc@5: 100.0000 (95.9391)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 1.0035 (1.0465)  Acc@1: 68.7500 (72.7433)  Acc@5: 100.0000 (95.9339)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 1.0543 (1.0460)  Acc@1: 75.0000 (72.7496)  Acc@5: 93.7500 (95.9288)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 1.0805 (1.0476)  Acc@1: 68.7500 (72.6852)  Acc@5: 93.7500 (95.8937)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 0.9028 (1.0482)  Acc@1: 75.0000 (72.7120)  Acc@5: 93.7500 (95.9093)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:32  Loss: 0.8980 (1.0483)  Acc@1: 75.0000 (72.7574)  Acc@5: 93.7500 (95.8756)  time: 0.2160  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:30  Loss: 0.9314 (1.0479)  Acc@1: 75.0000 (72.7823)  Acc@5: 100.0000 (95.9197)  time: 0.2170  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 0.9314 (1.0471)  Acc@1: 75.0000 (72.8253)  Acc@5: 100.0000 (95.9342)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 1.0572 (1.0469)  Acc@1: 75.0000 (72.8577)  Acc@5: 100.0000 (95.9296)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 1.0121 (1.0463)  Acc@1: 75.0000 (72.8616)  Acc@5: 100.0000 (95.9251)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 0.9890 (1.0443)  Acc@1: 75.0000 (72.9468)  Acc@5: 100.0000 (95.9569)  time: 0.2155  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 1.0515 (1.0445)  Acc@1: 75.0000 (72.9583)  Acc@5: 100.0000 (95.9611)  time: 0.2160  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:17  Loss: 1.0183 (1.0424)  Acc@1: 75.0000 (73.0046)  Acc@5: 100.0000 (95.9652)  time: 0.2183  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 0.9105 (1.0407)  Acc@1: 75.0000 (73.0322)  Acc@5: 100.0000 (95.9778)  time: 0.2187  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 0.9715 (1.0415)  Acc@1: 75.0000 (72.9822)  Acc@5: 100.0000 (95.9901)  time: 0.2173  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 1.0527 (1.0432)  Acc@1: 68.7500 (72.9420)  Acc@5: 93.7500 (95.9683)  time: 0.2164  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 1.0527 (1.0419)  Acc@1: 75.0000 (73.0027)  Acc@5: 100.0000 (96.0053)  time: 0.2176  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 1.1663 (1.0451)  Acc@1: 68.7500 (72.9057)  Acc@5: 100.0000 (95.9511)  time: 0.2194  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 0.9075 (1.0412)  Acc@1: 75.0000 (73.0383)  Acc@5: 93.7500 (95.9711)  time: 0.2184  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:02  Loss: 0.8069 (1.0390)  Acc@1: 81.2500 (73.0954)  Acc@5: 100.0000 (95.9987)  time: 0.2161  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 0.8285 (1.0406)  Acc@1: 75.0000 (73.1195)  Acc@5: 100.0000 (95.9861)  time: 0.2152  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 0.9831 (1.0390)  Acc@1: 75.0000 (73.1586)  Acc@5: 100.0000 (96.0284)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 0.8290 (1.0377)  Acc@1: 81.2500 (73.2506)  Acc@5: 100.0000 (96.0388)  time: 0.2171  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 0.8532 (1.0375)  Acc@1: 75.0000 (73.2262)  Acc@5: 100.0000 (96.0338)  time: 0.2174  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 0.9324 (1.0374)  Acc@1: 75.0000 (73.2250)  Acc@5: 100.0000 (96.0514)  time: 0.2159  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:50  Loss: 0.8575 (1.0349)  Acc@1: 75.0000 (73.2982)  Acc@5: 100.0000 (96.0910)  time: 0.2155  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 0.8599 (1.0356)  Acc@1: 75.0000 (73.2888)  Acc@5: 100.0000 (96.1075)  time: 0.2154  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 0.8953 (1.0347)  Acc@1: 75.0000 (73.3087)  Acc@5: 100.0000 (96.1310)  time: 0.2150  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 0.8771 (1.0330)  Acc@1: 75.0000 (73.3496)  Acc@5: 100.0000 (96.1323)  time: 0.2154  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 0.9411 (1.0347)  Acc@1: 68.7500 (73.3187)  Acc@5: 100.0000 (96.1478)  time: 0.2150  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 1.0523 (1.0369)  Acc@1: 68.7500 (73.2393)  Acc@5: 100.0000 (96.1560)  time: 0.2160  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:37  Loss: 1.0523 (1.0375)  Acc@1: 62.5000 (73.1964)  Acc@5: 100.0000 (96.1432)  time: 0.2171  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 1.0874 (1.0383)  Acc@1: 68.7500 (73.2025)  Acc@5: 93.7500 (96.1169)  time: 0.2167  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 1.0011 (1.0384)  Acc@1: 68.7500 (73.1678)  Acc@5: 93.7500 (96.1116)  time: 0.2163  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 1.0090 (1.0387)  Acc@1: 62.5000 (73.1136)  Acc@5: 100.0000 (96.1198)  time: 0.2159  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 1.0090 (1.0376)  Acc@1: 68.7500 (73.1270)  Acc@5: 100.0000 (96.1411)  time: 0.2164  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 1.0722 (1.0378)  Acc@1: 68.7500 (73.0810)  Acc@5: 100.0000 (96.1619)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 1.0096 (1.0369)  Acc@1: 75.0000 (73.0944)  Acc@5: 100.0000 (96.1824)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 0.8306 (1.0356)  Acc@1: 75.0000 (73.1334)  Acc@5: 100.0000 (96.1959)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 0.9449 (1.0358)  Acc@1: 75.0000 (73.1588)  Acc@5: 93.7500 (96.1901)  time: 0.2167  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 1.0874 (1.0386)  Acc@1: 75.0000 (73.1206)  Acc@5: 93.7500 (96.1655)  time: 0.2164  data: 0.0007  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.1400 (1.0392)  Acc@1: 75.0000 (73.1331)  Acc@5: 93.7500 (96.1414)  time: 0.2147  data: 0.0006  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 1.0609 (1.0391)  Acc@1: 75.0000 (73.1639)  Acc@5: 93.7500 (96.1424)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 1.0992 (1.0395)  Acc@1: 75.0000 (73.1513)  Acc@5: 93.7500 (96.1374)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 0.8606 (1.0373)  Acc@1: 75.0000 (73.2117)  Acc@5: 93.7500 (96.1324)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.7862 (1.0364)  Acc@1: 75.0000 (73.1868)  Acc@5: 100.0000 (96.1455)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.8752 (1.0350)  Acc@1: 75.0000 (73.2279)  Acc@5: 100.0000 (96.1703)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 0.9995 (1.0353)  Acc@1: 75.0000 (73.2033)  Acc@5: 100.0000 (96.1652)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.0351 (1.0356)  Acc@1: 68.7500 (73.1793)  Acc@5: 100.0000 (96.1776)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 1.0906 (1.0372)  Acc@1: 68.7500 (73.1441)  Acc@5: 100.0000 (96.1783)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 1.0645 (1.0366)  Acc@1: 68.7500 (73.1382)  Acc@5: 93.7500 (96.1847)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 0.9632 (1.0352)  Acc@1: 75.0000 (73.1721)  Acc@5: 100.0000 (96.1966)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 0.9685 (1.0356)  Acc@1: 81.2500 (73.1942)  Acc@5: 100.0000 (96.1971)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 0.9761 (1.0368)  Acc@1: 75.0000 (73.1545)  Acc@5: 100.0000 (96.1976)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 0.9761 (1.0370)  Acc@1: 68.7500 (73.1432)  Acc@5: 100.0000 (96.1925)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.2057 (1.0386)  Acc@1: 62.5000 (73.0883)  Acc@5: 93.7500 (96.1821)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 1.3099 (1.0401)  Acc@1: 68.7500 (73.0723)  Acc@5: 93.7500 (96.1447)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 1.1282 (1.0390)  Acc@1: 75.0000 (73.1158)  Acc@5: 93.7500 (96.1563)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 0.9354 (1.0380)  Acc@1: 75.0000 (73.1640)  Acc@5: 100.0000 (96.1731)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 1.0332 (1.0385)  Acc@1: 75.0000 (73.1319)  Acc@5: 100.0000 (96.1950)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.1183 (1.0389)  Acc@1: 68.7500 (73.0898)  Acc@5: 100.0000 (96.2164)  time: 0.2151  data: 0.0007  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.1183 (1.0395)  Acc@1: 68.7500 (73.0953)  Acc@5: 100.0000 (96.1959)  time: 0.2150  data: 0.0007  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 0.9521 (1.0398)  Acc@1: 75.0000 (73.0646)  Acc@5: 93.7500 (96.1963)  time: 0.2163  data: 0.0015  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 0.9470 (1.0389)  Acc@1: 75.0000 (73.0702)  Acc@5: 100.0000 (96.2172)  time: 0.2166  data: 0.0015  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 0.9692 (1.0396)  Acc@1: 68.7500 (73.0351)  Acc@5: 100.0000 (96.1972)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 0.9837 (1.0393)  Acc@1: 75.0000 (73.0207)  Acc@5: 93.7500 (96.1775)  time: 0.2161  data: 0.0010  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.1037 (1.0397)  Acc@1: 68.7500 (73.0066)  Acc@5: 93.7500 (96.1831)  time: 0.2158  data: 0.0012  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.1037 (1.0395)  Acc@1: 68.7500 (73.0174)  Acc@5: 100.0000 (96.1786)  time: 0.2156  data: 0.0010  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 0.9935 (1.0398)  Acc@1: 68.7500 (73.0232)  Acc@5: 100.0000 (96.1497)  time: 0.2164  data: 0.0019  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 0.9935 (1.0381)  Acc@1: 75.0000 (73.0874)  Acc@5: 93.7500 (96.1602)  time: 0.2164  data: 0.0015  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 1.0056 (1.0383)  Acc@1: 75.0000 (73.0877)  Acc@5: 93.7500 (96.1367)  time: 0.2148  data: 0.0005  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.0493 (1.0376)  Acc@1: 75.0000 (73.1360)  Acc@5: 93.7500 (96.1328)  time: 0.2152  data: 0.0008  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.8410 (1.0361)  Acc@1: 75.0000 (73.1693)  Acc@5: 93.7500 (96.1337)  time: 0.2164  data: 0.0011  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.7229 (1.0349)  Acc@1: 75.0000 (73.2163)  Acc@5: 100.0000 (96.1298)  time: 0.2175  data: 0.0015  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.8002 (1.0347)  Acc@1: 75.0000 (73.2250)  Acc@5: 100.0000 (96.1260)  time: 0.2171  data: 0.0017  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 0.9851 (1.0353)  Acc@1: 75.0000 (73.2010)  Acc@5: 93.7500 (96.1270)  time: 0.2167  data: 0.0012  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 0.9823 (1.0347)  Acc@1: 75.0000 (73.2189)  Acc@5: 100.0000 (96.1325)  time: 0.2203  data: 0.0011  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.9657 (1.0343)  Acc@1: 75.0000 (73.2228)  Acc@5: 100.0000 (96.1334)  time: 0.2197  data: 0.0012  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.9330 (1.0339)  Acc@1: 75.0000 (73.2175)  Acc@5: 100.0000 (96.1524)  time: 0.2160  data: 0.0008  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.0089 (1.0344)  Acc@1: 75.0000 (73.1852)  Acc@5: 100.0000 (96.1441)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.1135 (1.0340)  Acc@1: 75.0000 (73.2072)  Acc@5: 93.7500 (96.1449)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 1.0076 (1.0340)  Acc@1: 75.0000 (73.2156)  Acc@5: 93.7500 (96.1322)  time: 0.2157  data: 0.0009  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 0.8772 (1.0337)  Acc@1: 75.0000 (73.2282)  Acc@5: 93.7500 (96.1331)  time: 0.2155  data: 0.0008  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.9270 (1.0329)  Acc@1: 75.0000 (73.2275)  Acc@5: 100.0000 (96.1427)  time: 0.2152  data: 0.0006  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.1040 (1.0346)  Acc@1: 68.7500 (73.2224)  Acc@5: 93.7500 (96.1085)  time: 0.2156  data: 0.0006  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1817 (1.0345)  Acc@1: 68.7500 (73.2044)  Acc@5: 93.7500 (96.1008)  time: 0.2163  data: 0.0008  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.0921 (1.0353)  Acc@1: 68.7500 (73.1823)  Acc@5: 93.7500 (96.0846)  time: 0.2166  data: 0.0015  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.0844 (1.0355)  Acc@1: 75.0000 (73.1990)  Acc@5: 93.7500 (96.0900)  time: 0.2171  data: 0.0019  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 0.9808 (1.0352)  Acc@1: 75.0000 (73.1985)  Acc@5: 100.0000 (96.0953)  time: 0.2166  data: 0.0011  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 0.9688 (1.0354)  Acc@1: 68.7500 (73.1811)  Acc@5: 100.0000 (96.0922)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 0.9921 (1.0361)  Acc@1: 68.7500 (73.1682)  Acc@5: 100.0000 (96.0932)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.9921 (1.0360)  Acc@1: 68.7500 (73.1762)  Acc@5: 100.0000 (96.0984)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.8994 (1.0360)  Acc@1: 68.7500 (73.1924)  Acc@5: 100.0000 (96.1036)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.9305 (1.0351)  Acc@1: 75.0000 (73.2166)  Acc@5: 100.0000 (96.1086)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.8689 (1.0346)  Acc@1: 75.0000 (73.2283)  Acc@5: 100.0000 (96.1096)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.8632 (1.0337)  Acc@1: 75.0000 (73.2438)  Acc@5: 100.0000 (96.1226)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.8595 (1.0336)  Acc@1: 75.0000 (73.2592)  Acc@5: 100.0000 (96.1315)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.8410 (1.0327)  Acc@1: 81.2500 (73.3224)  Acc@5: 100.0000 (96.1283)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.8410 (1.0328)  Acc@1: 81.2500 (73.3410)  Acc@5: 100.0000 (96.1211)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.8781 (1.0327)  Acc@1: 75.0000 (73.3515)  Acc@5: 100.0000 (96.1140)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 0.9792 (1.0328)  Acc@1: 68.7500 (73.3422)  Acc@5: 100.0000 (96.1188)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.0310 (1.0341)  Acc@1: 68.7500 (73.2979)  Acc@5: 100.0000 (96.1274)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.1385 (1.0338)  Acc@1: 68.7500 (73.3163)  Acc@5: 100.0000 (96.1204)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.8431 (1.0327)  Acc@1: 75.0000 (73.3614)  Acc@5: 100.0000 (96.1251)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.8544 (1.0321)  Acc@1: 81.2500 (73.3789)  Acc@5: 93.7500 (96.1202)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1] Total time: 0:05:51 (0.2159 s / it)
* Acc@1 73.379 Acc@5 96.120 loss 1.032
Test: [Task 2]  [  0/625]  eta: 0:04:57  Loss: 0.2024 (0.2024)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4760  data: 0.2629  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:25  Loss: 0.2024 (0.2283)  Acc@1: 93.7500 (96.0227)  Acc@5: 100.0000 (99.4318)  time: 0.2371  data: 0.0241  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:16  Loss: 0.1710 (0.2171)  Acc@1: 100.0000 (96.1310)  Acc@5: 100.0000 (99.7024)  time: 0.2131  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:11  Loss: 0.1974 (0.2494)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (99.5968)  time: 0.2132  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:08  Loss: 0.2715 (0.2548)  Acc@1: 93.7500 (94.0549)  Acc@5: 100.0000 (99.6951)  time: 0.2130  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:05  Loss: 0.2748 (0.2679)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.7549)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:02  Loss: 0.2748 (0.2666)  Acc@1: 93.7500 (93.6475)  Acc@5: 100.0000 (99.7951)  time: 0.2131  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:00  Loss: 0.2782 (0.2639)  Acc@1: 93.7500 (93.8380)  Acc@5: 100.0000 (99.8239)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:01:58  Loss: 0.2699 (0.2687)  Acc@1: 93.7500 (93.6728)  Acc@5: 100.0000 (99.6914)  time: 0.2150  data: 0.0010  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:01:55  Loss: 0.2086 (0.2613)  Acc@1: 93.7500 (93.8874)  Acc@5: 100.0000 (99.7253)  time: 0.2150  data: 0.0013  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:53  Loss: 0.2046 (0.2587)  Acc@1: 93.7500 (93.9356)  Acc@5: 100.0000 (99.7525)  time: 0.2156  data: 0.0011  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:51  Loss: 0.1935 (0.2590)  Acc@1: 93.7500 (94.0878)  Acc@5: 100.0000 (99.7748)  time: 0.2157  data: 0.0009  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:49  Loss: 0.1907 (0.2593)  Acc@1: 93.7500 (94.1116)  Acc@5: 100.0000 (99.6901)  time: 0.2150  data: 0.0005  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:46  Loss: 0.2397 (0.2593)  Acc@1: 93.7500 (94.1317)  Acc@5: 100.0000 (99.7137)  time: 0.2149  data: 0.0005  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:44  Loss: 0.2156 (0.2614)  Acc@1: 93.7500 (94.2376)  Acc@5: 100.0000 (99.6454)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:42  Loss: 0.2058 (0.2661)  Acc@1: 93.7500 (94.1225)  Acc@5: 100.0000 (99.6275)  time: 0.2153  data: 0.0006  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:40  Loss: 0.3145 (0.2704)  Acc@1: 93.7500 (93.9829)  Acc@5: 100.0000 (99.5342)  time: 0.2155  data: 0.0007  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:38  Loss: 0.2719 (0.2717)  Acc@1: 93.7500 (93.8231)  Acc@5: 100.0000 (99.5249)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:36  Loss: 0.2719 (0.2718)  Acc@1: 93.7500 (93.8536)  Acc@5: 100.0000 (99.5511)  time: 0.2161  data: 0.0010  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:33  Loss: 0.2714 (0.2738)  Acc@1: 93.7500 (93.8154)  Acc@5: 100.0000 (99.5419)  time: 0.2167  data: 0.0010  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:31  Loss: 0.2124 (0.2710)  Acc@1: 93.7500 (93.7811)  Acc@5: 100.0000 (99.5647)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:29  Loss: 0.2015 (0.2727)  Acc@1: 93.7500 (93.6315)  Acc@5: 100.0000 (99.5853)  time: 0.2160  data: 0.0006  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:27  Loss: 0.2011 (0.2701)  Acc@1: 93.7500 (93.7783)  Acc@5: 100.0000 (99.6041)  time: 0.2151  data: 0.0006  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 0.1574 (0.2677)  Acc@1: 100.0000 (93.9123)  Acc@5: 100.0000 (99.6212)  time: 0.2140  data: 0.0005  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.2384 (0.2674)  Acc@1: 93.7500 (93.9834)  Acc@5: 100.0000 (99.6369)  time: 0.2148  data: 0.0007  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:20  Loss: 0.2651 (0.2698)  Acc@1: 93.7500 (93.9243)  Acc@5: 100.0000 (99.6016)  time: 0.2153  data: 0.0010  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:18  Loss: 0.2670 (0.2716)  Acc@1: 93.7500 (93.8458)  Acc@5: 100.0000 (99.5929)  time: 0.2161  data: 0.0011  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:16  Loss: 0.2895 (0.2733)  Acc@1: 93.7500 (93.7731)  Acc@5: 100.0000 (99.5618)  time: 0.2175  data: 0.0014  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 0.3194 (0.2754)  Acc@1: 93.7500 (93.6388)  Acc@5: 100.0000 (99.5552)  time: 0.2171  data: 0.0012  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.2647 (0.2769)  Acc@1: 93.7500 (93.6641)  Acc@5: 100.0000 (99.5704)  time: 0.2158  data: 0.0010  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.2516 (0.2767)  Acc@1: 93.7500 (93.6254)  Acc@5: 100.0000 (99.5847)  time: 0.2172  data: 0.0010  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.2516 (0.2778)  Acc@1: 93.7500 (93.6093)  Acc@5: 100.0000 (99.5378)  time: 0.2173  data: 0.0008  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:05  Loss: 0.1242 (0.2717)  Acc@1: 100.0000 (93.7889)  Acc@5: 100.0000 (99.5522)  time: 0.2156  data: 0.0006  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 0.0952 (0.2674)  Acc@1: 100.0000 (93.9388)  Acc@5: 100.0000 (99.5657)  time: 0.2153  data: 0.0011  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.0952 (0.2618)  Acc@1: 100.0000 (94.0982)  Acc@5: 100.0000 (99.5784)  time: 0.2162  data: 0.0013  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.0752 (0.2580)  Acc@1: 100.0000 (94.1774)  Acc@5: 100.0000 (99.5905)  time: 0.2158  data: 0.0007  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.1668 (0.2587)  Acc@1: 93.7500 (94.1309)  Acc@5: 100.0000 (99.5845)  time: 0.2158  data: 0.0008  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.1834 (0.2562)  Acc@1: 93.7500 (94.1880)  Acc@5: 100.0000 (99.5957)  time: 0.2169  data: 0.0010  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:52  Loss: 0.2572 (0.2608)  Acc@1: 93.7500 (94.0125)  Acc@5: 100.0000 (99.5407)  time: 0.2164  data: 0.0008  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 0.2823 (0.2611)  Acc@1: 93.7500 (93.9738)  Acc@5: 100.0000 (99.5205)  time: 0.2161  data: 0.0013  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.0933 (0.2576)  Acc@1: 93.7500 (94.0461)  Acc@5: 100.0000 (99.5324)  time: 0.2155  data: 0.0015  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0658 (0.2556)  Acc@1: 100.0000 (94.1150)  Acc@5: 100.0000 (99.5286)  time: 0.2153  data: 0.0008  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.0758 (0.2547)  Acc@1: 100.0000 (94.1360)  Acc@5: 100.0000 (99.5398)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.1152 (0.2518)  Acc@1: 100.0000 (94.2285)  Acc@5: 100.0000 (99.5505)  time: 0.2156  data: 0.0015  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:39  Loss: 0.0722 (0.2478)  Acc@1: 100.0000 (94.3594)  Acc@5: 100.0000 (99.5607)  time: 0.2157  data: 0.0015  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.0674 (0.2442)  Acc@1: 100.0000 (94.4152)  Acc@5: 100.0000 (99.5704)  time: 0.2157  data: 0.0006  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.0921 (0.2413)  Acc@1: 100.0000 (94.4957)  Acc@5: 100.0000 (99.5797)  time: 0.2166  data: 0.0010  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1152 (0.2391)  Acc@1: 100.0000 (94.5993)  Acc@5: 100.0000 (99.5886)  time: 0.2166  data: 0.0016  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1378 (0.2379)  Acc@1: 100.0000 (94.6596)  Acc@5: 100.0000 (99.5972)  time: 0.2159  data: 0.0016  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1353 (0.2360)  Acc@1: 100.0000 (94.7429)  Acc@5: 100.0000 (99.6054)  time: 0.2159  data: 0.0014  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:26  Loss: 0.1139 (0.2334)  Acc@1: 100.0000 (94.8104)  Acc@5: 100.0000 (99.6133)  time: 0.2155  data: 0.0012  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.1298 (0.2345)  Acc@1: 93.7500 (94.7162)  Acc@5: 100.0000 (99.6208)  time: 0.2212  data: 0.0008  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.1913 (0.2345)  Acc@1: 93.7500 (94.7457)  Acc@5: 100.0000 (99.6281)  time: 0.2226  data: 0.0011  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1159 (0.2324)  Acc@1: 100.0000 (94.8329)  Acc@5: 100.0000 (99.6351)  time: 0.2158  data: 0.0008  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1055 (0.2307)  Acc@1: 100.0000 (94.8706)  Acc@5: 100.0000 (99.6419)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0786 (0.2277)  Acc@1: 100.0000 (94.9410)  Acc@5: 100.0000 (99.6484)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0442 (0.2243)  Acc@1: 100.0000 (95.0312)  Acc@5: 100.0000 (99.6546)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0451 (0.2232)  Acc@1: 100.0000 (95.0635)  Acc@5: 100.0000 (99.6607)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.0479 (0.2204)  Acc@1: 100.0000 (95.1377)  Acc@5: 100.0000 (99.6665)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.0738 (0.2191)  Acc@1: 100.0000 (95.1354)  Acc@5: 100.0000 (99.6722)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1646 (0.2188)  Acc@1: 93.7500 (95.1331)  Acc@5: 100.0000 (99.6776)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2751 (0.2209)  Acc@1: 93.7500 (95.0798)  Acc@5: 100.0000 (99.6624)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.2441 (0.2206)  Acc@1: 93.7500 (95.1087)  Acc@5: 100.0000 (99.6679)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2253 (0.2202)  Acc@1: 93.7500 (95.1200)  Acc@5: 100.0000 (99.6700)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2] Total time: 0:02:15 (0.2162 s / it)
* Acc@1 95.120 Acc@5 99.670 loss 0.220
{0: {0: 0, 1: 26032, 2: 0, 3: 0, 4: 0, 5: 0, 6: 26032, 7: 0, 8: 26032, 9: 0, 10: 0, 11: 0, 12: 26032, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 10000, 3: 10000, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 10000, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task2]	Acc@1: 84.2495	Acc@5: 97.8951	Loss: 0.6261	Forgetting: 13.6793	Backward: -13.6793
Train: Epoch[1/5]  [   0/3125]  eta: 0:32:24  Lr: 0.001875  Loss: 2.3114  Acc@1: 12.5000 (12.5000)  Acc@5: 56.2500 (56.2500)  time: 0.6223  data: 0.2612  max mem: 2500
Train: Epoch[1/5]  [  10/3125]  eta: 0:19:13  Lr: 0.001875  Loss: 2.1437  Acc@1: 18.7500 (21.5909)  Acc@5: 75.0000 (65.9091)  time: 0.3703  data: 0.0240  max mem: 2502
Train: Epoch[1/5]  [  20/3125]  eta: 0:18:31  Lr: 0.001875  Loss: 1.9996  Acc@1: 37.5000 (36.0119)  Acc@5: 81.2500 (75.8929)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  30/3125]  eta: 0:18:15  Lr: 0.001875  Loss: 1.7858  Acc@1: 50.0000 (42.1371)  Acc@5: 87.5000 (79.2339)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  40/3125]  eta: 0:18:06  Lr: 0.001875  Loss: 1.3994  Acc@1: 62.5000 (47.7134)  Acc@5: 87.5000 (82.9268)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  50/3125]  eta: 0:17:58  Lr: 0.001875  Loss: 1.1559  Acc@1: 68.7500 (52.6961)  Acc@5: 93.7500 (85.4167)  time: 0.3458  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  60/3125]  eta: 0:17:52  Lr: 0.001875  Loss: 1.4696  Acc@1: 68.7500 (54.3033)  Acc@5: 93.7500 (86.3730)  time: 0.3454  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  70/3125]  eta: 0:17:47  Lr: 0.001875  Loss: 1.3101  Acc@1: 62.5000 (56.5141)  Acc@5: 93.7500 (87.5880)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  80/3125]  eta: 0:17:43  Lr: 0.001875  Loss: 0.8208  Acc@1: 75.0000 (57.8704)  Acc@5: 93.7500 (88.4259)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  90/3125]  eta: 0:17:40  Lr: 0.001875  Loss: 0.8263  Acc@1: 68.7500 (58.9286)  Acc@5: 93.7500 (88.9423)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 100/3125]  eta: 0:17:37  Lr: 0.001875  Loss: 0.7229  Acc@1: 68.7500 (60.7673)  Acc@5: 93.7500 (89.5421)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 110/3125]  eta: 0:17:34  Lr: 0.001875  Loss: 1.0097  Acc@1: 75.0000 (61.8243)  Acc@5: 93.7500 (90.0338)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 120/3125]  eta: 0:17:30  Lr: 0.001875  Loss: 0.6267  Acc@1: 68.7500 (62.4483)  Acc@5: 93.7500 (90.3926)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 130/3125]  eta: 0:17:27  Lr: 0.001875  Loss: 0.7549  Acc@1: 68.7500 (62.8817)  Acc@5: 93.7500 (90.6966)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 140/3125]  eta: 0:17:23  Lr: 0.001875  Loss: 0.6315  Acc@1: 68.7500 (63.6082)  Acc@5: 100.0000 (91.1348)  time: 0.3496  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 150/3125]  eta: 0:17:20  Lr: 0.001875  Loss: 0.0792  Acc@1: 75.0000 (64.4040)  Acc@5: 100.0000 (91.3907)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 160/3125]  eta: 0:17:16  Lr: 0.001875  Loss: 0.3317  Acc@1: 75.0000 (64.8680)  Acc@5: 93.7500 (91.6537)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 170/3125]  eta: 0:17:13  Lr: 0.001875  Loss: 0.3984  Acc@1: 75.0000 (65.4971)  Acc@5: 93.7500 (91.8860)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 180/3125]  eta: 0:17:09  Lr: 0.001875  Loss: 0.8154  Acc@1: 75.0000 (66.1602)  Acc@5: 100.0000 (92.1961)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 190/3125]  eta: 0:17:06  Lr: 0.001875  Loss: 0.3516  Acc@1: 75.0000 (66.3285)  Acc@5: 100.0000 (92.3102)  time: 0.3486  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 200/3125]  eta: 0:17:02  Lr: 0.001875  Loss: 0.4778  Acc@1: 75.0000 (66.8843)  Acc@5: 100.0000 (92.6617)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 210/3125]  eta: 0:16:59  Lr: 0.001875  Loss: 0.1293  Acc@1: 75.0000 (67.4467)  Acc@5: 100.0000 (92.8910)  time: 0.3521  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 220/3125]  eta: 0:16:56  Lr: 0.001875  Loss: 0.4116  Acc@1: 75.0000 (67.9299)  Acc@5: 100.0000 (93.0995)  time: 0.3521  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 230/3125]  eta: 0:16:53  Lr: 0.001875  Loss: 0.0740  Acc@1: 81.2500 (68.4253)  Acc@5: 100.0000 (93.3171)  time: 0.3533  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 240/3125]  eta: 0:16:49  Lr: 0.001875  Loss: 0.2602  Acc@1: 81.2500 (68.8537)  Acc@5: 100.0000 (93.4907)  time: 0.3535  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 250/3125]  eta: 0:16:46  Lr: 0.001875  Loss: 0.4130  Acc@1: 75.0000 (69.0737)  Acc@5: 100.0000 (93.6255)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 260/3125]  eta: 0:16:42  Lr: 0.001875  Loss: 0.1348  Acc@1: 81.2500 (69.5163)  Acc@5: 100.0000 (93.7979)  time: 0.3482  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 270/3125]  eta: 0:16:38  Lr: 0.001875  Loss: 0.2644  Acc@1: 81.2500 (69.7417)  Acc@5: 100.0000 (93.8653)  time: 0.3486  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 280/3125]  eta: 0:16:35  Lr: 0.001875  Loss: 0.3848  Acc@1: 75.0000 (69.8176)  Acc@5: 93.7500 (93.9057)  time: 0.3499  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 290/3125]  eta: 0:16:31  Lr: 0.001875  Loss: 0.1223  Acc@1: 75.0000 (69.9742)  Acc@5: 100.0000 (94.0292)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 300/3125]  eta: 0:16:28  Lr: 0.001875  Loss: 0.1422  Acc@1: 75.0000 (70.2243)  Acc@5: 100.0000 (94.0615)  time: 0.3480  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 310/3125]  eta: 0:16:24  Lr: 0.001875  Loss: 0.4298  Acc@1: 75.0000 (70.3577)  Acc@5: 100.0000 (94.1519)  time: 0.3475  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 320/3125]  eta: 0:16:20  Lr: 0.001875  Loss: 0.1031  Acc@1: 75.0000 (70.5607)  Acc@5: 100.0000 (94.2562)  time: 0.3474  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 330/3125]  eta: 0:16:17  Lr: 0.001875  Loss: 0.7700  Acc@1: 81.2500 (70.9592)  Acc@5: 100.0000 (94.3920)  time: 0.3468  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 340/3125]  eta: 0:16:13  Lr: 0.001875  Loss: -0.3284  Acc@1: 81.2500 (71.0777)  Acc@5: 100.0000 (94.4282)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 350/3125]  eta: 0:16:09  Lr: 0.001875  Loss: 0.0595  Acc@1: 81.2500 (71.3319)  Acc@5: 100.0000 (94.5513)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 360/3125]  eta: 0:16:06  Lr: 0.001875  Loss: 0.3203  Acc@1: 81.2500 (71.6066)  Acc@5: 100.0000 (94.5637)  time: 0.3511  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 370/3125]  eta: 0:16:03  Lr: 0.001875  Loss: 0.3831  Acc@1: 81.2500 (71.7992)  Acc@5: 93.7500 (94.6092)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 380/3125]  eta: 0:15:59  Lr: 0.001875  Loss: -0.2536  Acc@1: 87.5000 (72.1457)  Acc@5: 93.7500 (94.6686)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 390/3125]  eta: 0:15:55  Lr: 0.001875  Loss: 0.3682  Acc@1: 81.2500 (72.2986)  Acc@5: 93.7500 (94.6292)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 400/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.0147  Acc@1: 81.2500 (72.5374)  Acc@5: 93.7500 (94.6540)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 410/3125]  eta: 0:15:48  Lr: 0.001875  Loss: 0.1671  Acc@1: 81.2500 (72.7646)  Acc@5: 100.0000 (94.7232)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 420/3125]  eta: 0:15:44  Lr: 0.001875  Loss: 0.2002  Acc@1: 75.0000 (72.8474)  Acc@5: 100.0000 (94.7595)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 430/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.2267  Acc@1: 75.0000 (73.0858)  Acc@5: 100.0000 (94.8231)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 440/3125]  eta: 0:15:37  Lr: 0.001875  Loss: 0.2945  Acc@1: 75.0000 (73.0017)  Acc@5: 100.0000 (94.8413)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 450/3125]  eta: 0:15:33  Lr: 0.001875  Loss: -0.1798  Acc@1: 75.0000 (73.2123)  Acc@5: 100.0000 (94.9141)  time: 0.3477  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 460/3125]  eta: 0:15:30  Lr: 0.001875  Loss: -0.1146  Acc@1: 81.2500 (73.3189)  Acc@5: 100.0000 (94.9973)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 470/3125]  eta: 0:15:26  Lr: 0.001875  Loss: 0.1397  Acc@1: 75.0000 (73.3944)  Acc@5: 100.0000 (95.0504)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 480/3125]  eta: 0:15:22  Lr: 0.001875  Loss: 0.2111  Acc@1: 75.0000 (73.5057)  Acc@5: 100.0000 (95.1143)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 490/3125]  eta: 0:15:19  Lr: 0.001875  Loss: -0.4081  Acc@1: 75.0000 (73.6889)  Acc@5: 100.0000 (95.1757)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 500/3125]  eta: 0:15:15  Lr: 0.001875  Loss: -0.0896  Acc@1: 81.2500 (73.8149)  Acc@5: 100.0000 (95.2595)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 510/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.5481  Acc@1: 81.2500 (73.9237)  Acc@5: 100.0000 (95.3156)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 520/3125]  eta: 0:15:08  Lr: 0.001875  Loss: -0.3934  Acc@1: 81.2500 (74.0283)  Acc@5: 100.0000 (95.3695)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 530/3125]  eta: 0:15:04  Lr: 0.001875  Loss: 0.0542  Acc@1: 81.2500 (74.1055)  Acc@5: 100.0000 (95.4096)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 540/3125]  eta: 0:15:00  Lr: 0.001875  Loss: 0.0569  Acc@1: 81.2500 (74.1451)  Acc@5: 100.0000 (95.4482)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 550/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.0987  Acc@1: 81.2500 (74.1946)  Acc@5: 93.7500 (95.4515)  time: 0.3463  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 560/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.4773  Acc@1: 81.2500 (74.2981)  Acc@5: 100.0000 (95.4991)  time: 0.3476  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 570/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.4315  Acc@1: 81.2500 (74.3651)  Acc@5: 100.0000 (95.5451)  time: 0.3504  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 580/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.4662  Acc@1: 75.0000 (74.5052)  Acc@5: 100.0000 (95.5895)  time: 0.3507  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 590/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.3302  Acc@1: 75.0000 (74.5453)  Acc@5: 100.0000 (95.6007)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 600/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.0123  Acc@1: 75.0000 (74.6256)  Acc@5: 93.7500 (95.6115)  time: 0.3520  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 610/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.3824  Acc@1: 81.2500 (74.7852)  Acc@5: 100.0000 (95.6526)  time: 0.3509  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 620/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.3142  Acc@1: 81.2500 (74.7484)  Acc@5: 100.0000 (95.6522)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 630/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.2896  Acc@1: 81.2500 (74.8217)  Acc@5: 100.0000 (95.6914)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 640/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.0569  Acc@1: 81.2500 (74.9220)  Acc@5: 100.0000 (95.7293)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 650/3125]  eta: 0:14:23  Lr: 0.001875  Loss: -0.4431  Acc@1: 81.2500 (74.9616)  Acc@5: 100.0000 (95.7565)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 660/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.1398  Acc@1: 75.0000 (74.9811)  Acc@5: 100.0000 (95.7640)  time: 0.3519  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 670/3125]  eta: 0:14:16  Lr: 0.001875  Loss: -0.2890  Acc@1: 81.2500 (75.0931)  Acc@5: 100.0000 (95.7899)  time: 0.3524  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 680/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.4984  Acc@1: 87.5000 (75.1927)  Acc@5: 100.0000 (95.7966)  time: 0.3499  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 690/3125]  eta: 0:14:09  Lr: 0.001875  Loss: -0.2623  Acc@1: 81.2500 (75.2352)  Acc@5: 100.0000 (95.7941)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 700/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.2479  Acc@1: 81.2500 (75.3210)  Acc@5: 100.0000 (95.8096)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 710/3125]  eta: 0:14:02  Lr: 0.001875  Loss: -0.2673  Acc@1: 81.2500 (75.3956)  Acc@5: 100.0000 (95.8245)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 720/3125]  eta: 0:13:59  Lr: 0.001875  Loss: -0.3218  Acc@1: 81.2500 (75.4941)  Acc@5: 100.0000 (95.8391)  time: 0.3529  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 730/3125]  eta: 0:13:55  Lr: 0.001875  Loss: -0.2427  Acc@1: 81.2500 (75.6412)  Acc@5: 100.0000 (95.8618)  time: 0.3542  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 740/3125]  eta: 0:13:52  Lr: 0.001875  Loss: -0.5617  Acc@1: 81.2500 (75.6748)  Acc@5: 100.0000 (95.8924)  time: 0.3525  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 750/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.1603  Acc@1: 81.2500 (75.7490)  Acc@5: 100.0000 (95.9055)  time: 0.3529  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 760/3125]  eta: 0:13:45  Lr: 0.001875  Loss: -0.2648  Acc@1: 81.2500 (75.8131)  Acc@5: 100.0000 (95.8936)  time: 0.3520  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 770/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.1950  Acc@1: 81.2500 (75.8512)  Acc@5: 100.0000 (95.9225)  time: 0.3493  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 780/3125]  eta: 0:13:38  Lr: 0.001875  Loss: -0.4677  Acc@1: 81.2500 (75.9523)  Acc@5: 100.0000 (95.9507)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 790/3125]  eta: 0:13:35  Lr: 0.001875  Loss: -0.1371  Acc@1: 87.5000 (76.0588)  Acc@5: 100.0000 (95.9940)  time: 0.3493  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 800/3125]  eta: 0:13:31  Lr: 0.001875  Loss: -0.5425  Acc@1: 87.5000 (76.1470)  Acc@5: 100.0000 (96.0050)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 810/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.1850  Acc@1: 81.2500 (76.1868)  Acc@5: 100.0000 (96.0234)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 820/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.3058  Acc@1: 75.0000 (76.2028)  Acc@5: 100.0000 (96.0566)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 830/3125]  eta: 0:13:21  Lr: 0.001875  Loss: -0.4912  Acc@1: 81.2500 (76.2184)  Acc@5: 100.0000 (96.0815)  time: 0.3507  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 840/3125]  eta: 0:13:17  Lr: 0.001875  Loss: -0.6332  Acc@1: 81.2500 (76.2708)  Acc@5: 100.0000 (96.0835)  time: 0.3509  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 850/3125]  eta: 0:13:14  Lr: 0.001875  Loss: -0.4740  Acc@1: 81.2500 (76.2926)  Acc@5: 100.0000 (96.0855)  time: 0.3488  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 860/3125]  eta: 0:13:10  Lr: 0.001875  Loss: -0.5268  Acc@1: 75.0000 (76.3139)  Acc@5: 100.0000 (96.0947)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 870/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.4032  Acc@1: 81.2500 (76.3562)  Acc@5: 100.0000 (96.1036)  time: 0.3483  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 880/3125]  eta: 0:13:03  Lr: 0.001875  Loss: -0.3852  Acc@1: 81.2500 (76.3834)  Acc@5: 100.0000 (96.1124)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 890/3125]  eta: 0:13:00  Lr: 0.001875  Loss: -0.1475  Acc@1: 81.2500 (76.3889)  Acc@5: 93.7500 (96.0929)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 900/3125]  eta: 0:12:56  Lr: 0.001875  Loss: -0.2372  Acc@1: 81.2500 (76.4012)  Acc@5: 93.7500 (96.1016)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 910/3125]  eta: 0:12:53  Lr: 0.001875  Loss: -0.6273  Acc@1: 75.0000 (76.3927)  Acc@5: 100.0000 (96.1238)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 920/3125]  eta: 0:12:49  Lr: 0.001875  Loss: -0.3392  Acc@1: 81.2500 (76.4590)  Acc@5: 100.0000 (96.1387)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 930/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.0822  Acc@1: 81.2500 (76.5306)  Acc@5: 100.0000 (96.1600)  time: 0.3518  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 940/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.4713  Acc@1: 81.2500 (76.6073)  Acc@5: 100.0000 (96.1942)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 950/3125]  eta: 0:12:39  Lr: 0.001875  Loss: -0.3890  Acc@1: 81.2500 (76.6299)  Acc@5: 100.0000 (96.2211)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 960/3125]  eta: 0:12:35  Lr: 0.001875  Loss: -0.5569  Acc@1: 81.2500 (76.6975)  Acc@5: 100.0000 (96.2344)  time: 0.3466  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 970/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.4606  Acc@1: 81.2500 (76.7958)  Acc@5: 100.0000 (96.2667)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 980/3125]  eta: 0:12:28  Lr: 0.001875  Loss: -0.4993  Acc@1: 81.2500 (76.8094)  Acc@5: 100.0000 (96.2857)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 990/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.4904  Acc@1: 81.2500 (76.8290)  Acc@5: 100.0000 (96.2790)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1000/3125]  eta: 0:12:21  Lr: 0.001875  Loss: -0.4742  Acc@1: 81.2500 (76.8794)  Acc@5: 93.7500 (96.2725)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1010/3125]  eta: 0:12:18  Lr: 0.001875  Loss: -0.6532  Acc@1: 81.2500 (76.9164)  Acc@5: 100.0000 (96.2970)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1020/3125]  eta: 0:12:14  Lr: 0.001875  Loss: -0.7194  Acc@1: 81.2500 (76.9895)  Acc@5: 100.0000 (96.2965)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1030/3125]  eta: 0:12:11  Lr: 0.001875  Loss: -0.3035  Acc@1: 87.5000 (77.0550)  Acc@5: 100.0000 (96.3021)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1040/3125]  eta: 0:12:07  Lr: 0.001875  Loss: -0.5809  Acc@1: 81.2500 (77.0773)  Acc@5: 100.0000 (96.3196)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1050/3125]  eta: 0:12:04  Lr: 0.001875  Loss: -0.4304  Acc@1: 81.2500 (77.1289)  Acc@5: 100.0000 (96.3368)  time: 0.3453  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1060/3125]  eta: 0:12:00  Lr: 0.001875  Loss: 0.0796  Acc@1: 87.5000 (77.2031)  Acc@5: 100.0000 (96.3478)  time: 0.3451  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1070/3125]  eta: 0:11:56  Lr: 0.001875  Loss: -0.5813  Acc@1: 87.5000 (77.2642)  Acc@5: 100.0000 (96.3702)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1080/3125]  eta: 0:11:53  Lr: 0.001875  Loss: -0.3988  Acc@1: 81.2500 (77.3127)  Acc@5: 100.0000 (96.3980)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1090/3125]  eta: 0:11:49  Lr: 0.001875  Loss: -0.4848  Acc@1: 81.2500 (77.3659)  Acc@5: 100.0000 (96.4196)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1100/3125]  eta: 0:11:46  Lr: 0.001875  Loss: -0.2849  Acc@1: 81.2500 (77.3955)  Acc@5: 100.0000 (96.4294)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1110/3125]  eta: 0:11:42  Lr: 0.001875  Loss: -0.0230  Acc@1: 81.2500 (77.4359)  Acc@5: 100.0000 (96.4278)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1120/3125]  eta: 0:11:39  Lr: 0.001875  Loss: -0.2621  Acc@1: 81.2500 (77.4755)  Acc@5: 100.0000 (96.4429)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1130/3125]  eta: 0:11:35  Lr: 0.001875  Loss: -0.4884  Acc@1: 81.2500 (77.5199)  Acc@5: 100.0000 (96.4302)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1140/3125]  eta: 0:11:32  Lr: 0.001875  Loss: -0.3476  Acc@1: 81.2500 (77.5362)  Acc@5: 100.0000 (96.4450)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1150/3125]  eta: 0:11:28  Lr: 0.001875  Loss: -0.1777  Acc@1: 81.2500 (77.5630)  Acc@5: 100.0000 (96.4596)  time: 0.3492  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1160/3125]  eta: 0:11:25  Lr: 0.001875  Loss: -0.2268  Acc@1: 81.2500 (77.5947)  Acc@5: 100.0000 (96.4686)  time: 0.3508  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [1170/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.4095  Acc@1: 87.5000 (77.6420)  Acc@5: 100.0000 (96.4827)  time: 0.3513  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1180/3125]  eta: 0:11:18  Lr: 0.001875  Loss: -0.6504  Acc@1: 81.2500 (77.6566)  Acc@5: 100.0000 (96.4807)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1190/3125]  eta: 0:11:15  Lr: 0.001875  Loss: -0.6161  Acc@1: 87.5000 (77.7445)  Acc@5: 100.0000 (96.4945)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1200/3125]  eta: 0:11:11  Lr: 0.001875  Loss: -0.6149  Acc@1: 87.5000 (77.7789)  Acc@5: 100.0000 (96.4925)  time: 0.3519  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [1210/3125]  eta: 0:11:08  Lr: 0.001875  Loss: -0.4100  Acc@1: 81.2500 (77.8334)  Acc@5: 100.0000 (96.5008)  time: 0.3512  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [1220/3125]  eta: 0:11:04  Lr: 0.001875  Loss: -0.8788  Acc@1: 87.5000 (77.9023)  Acc@5: 100.0000 (96.5090)  time: 0.3502  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1230/3125]  eta: 0:11:01  Lr: 0.001875  Loss: -0.4815  Acc@1: 87.5000 (77.9346)  Acc@5: 100.0000 (96.5323)  time: 0.3491  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1240/3125]  eta: 0:10:57  Lr: 0.001875  Loss: -0.0371  Acc@1: 81.2500 (77.9512)  Acc@5: 100.0000 (96.5401)  time: 0.3503  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1250/3125]  eta: 0:10:54  Lr: 0.001875  Loss: -0.5775  Acc@1: 81.2500 (77.9776)  Acc@5: 100.0000 (96.5478)  time: 0.3514  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1260/3125]  eta: 0:10:50  Lr: 0.001875  Loss: -0.4995  Acc@1: 87.5000 (78.0630)  Acc@5: 93.7500 (96.5454)  time: 0.3512  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1270/3125]  eta: 0:10:47  Lr: 0.001875  Loss: -0.6324  Acc@1: 87.5000 (78.0980)  Acc@5: 100.0000 (96.5578)  time: 0.3529  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1280/3125]  eta: 0:10:43  Lr: 0.001875  Loss: -0.3741  Acc@1: 81.2500 (78.1323)  Acc@5: 100.0000 (96.5554)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1290/3125]  eta: 0:10:40  Lr: 0.001875  Loss: -0.4737  Acc@1: 81.2500 (78.1807)  Acc@5: 100.0000 (96.5627)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1300/3125]  eta: 0:10:36  Lr: 0.001875  Loss: -0.3497  Acc@1: 81.2500 (78.2043)  Acc@5: 100.0000 (96.5748)  time: 0.3482  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1310/3125]  eta: 0:10:33  Lr: 0.001875  Loss: -0.0882  Acc@1: 87.5000 (78.2561)  Acc@5: 100.0000 (96.5961)  time: 0.3476  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1320/3125]  eta: 0:10:29  Lr: 0.001875  Loss: -0.5346  Acc@1: 87.5000 (78.2882)  Acc@5: 100.0000 (96.6077)  time: 0.3482  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1330/3125]  eta: 0:10:26  Lr: 0.001875  Loss: -0.8028  Acc@1: 87.5000 (78.3715)  Acc@5: 100.0000 (96.6238)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1340/3125]  eta: 0:10:22  Lr: 0.001875  Loss: -0.7816  Acc@1: 87.5000 (78.4070)  Acc@5: 100.0000 (96.6350)  time: 0.3484  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1350/3125]  eta: 0:10:19  Lr: 0.001875  Loss: -0.3051  Acc@1: 81.2500 (78.4234)  Acc@5: 100.0000 (96.6368)  time: 0.3478  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1360/3125]  eta: 0:10:15  Lr: 0.001875  Loss: -0.4928  Acc@1: 81.2500 (78.4258)  Acc@5: 100.0000 (96.6385)  time: 0.3499  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1370/3125]  eta: 0:10:12  Lr: 0.001875  Loss: -0.5385  Acc@1: 87.5000 (78.5057)  Acc@5: 100.0000 (96.6539)  time: 0.3504  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1380/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.5156  Acc@1: 87.5000 (78.5527)  Acc@5: 100.0000 (96.6781)  time: 0.3493  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1390/3125]  eta: 0:10:05  Lr: 0.001875  Loss: -0.0199  Acc@1: 81.2500 (78.5182)  Acc@5: 100.0000 (96.7020)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1400/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.4231  Acc@1: 75.0000 (78.5689)  Acc@5: 100.0000 (96.7032)  time: 0.3526  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1410/3125]  eta: 0:09:58  Lr: 0.001875  Loss: -0.4713  Acc@1: 75.0000 (78.5746)  Acc@5: 100.0000 (96.7089)  time: 0.3516  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.6647  Acc@1: 81.2500 (78.6066)  Acc@5: 100.0000 (96.7145)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1430/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.1050  Acc@1: 81.2500 (78.6032)  Acc@5: 100.0000 (96.7112)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: 0.0108  Acc@1: 81.2500 (78.6216)  Acc@5: 100.0000 (96.7124)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1450/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.4998  Acc@1: 87.5000 (78.6699)  Acc@5: 100.0000 (96.7178)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5289  Acc@1: 87.5000 (78.6875)  Acc@5: 100.0000 (96.7360)  time: 0.3478  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1470/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.3752  Acc@1: 81.2500 (78.7135)  Acc@5: 100.0000 (96.7539)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.7380  Acc@1: 81.2500 (78.7179)  Acc@5: 100.0000 (96.7547)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1490/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.3362  Acc@1: 81.2500 (78.7307)  Acc@5: 100.0000 (96.7513)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1500/3125]  eta: 0:09:26  Lr: 0.001875  Loss: -0.5245  Acc@1: 81.2500 (78.7433)  Acc@5: 93.7500 (96.7480)  time: 0.3448  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1510/3125]  eta: 0:09:23  Lr: 0.001875  Loss: -0.5156  Acc@1: 81.2500 (78.7641)  Acc@5: 93.7500 (96.7406)  time: 0.3447  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1520/3125]  eta: 0:09:19  Lr: 0.001875  Loss: -0.3251  Acc@1: 81.2500 (78.7722)  Acc@5: 93.7500 (96.7373)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1530/3125]  eta: 0:09:16  Lr: 0.001875  Loss: -0.3956  Acc@1: 81.2500 (78.7884)  Acc@5: 100.0000 (96.7464)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1540/3125]  eta: 0:09:12  Lr: 0.001875  Loss: -0.3002  Acc@1: 81.2500 (78.8206)  Acc@5: 100.0000 (96.7432)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1550/3125]  eta: 0:09:09  Lr: 0.001875  Loss: -0.4875  Acc@1: 81.2500 (78.8443)  Acc@5: 100.0000 (96.7602)  time: 0.3448  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1560/3125]  eta: 0:09:05  Lr: 0.001875  Loss: -0.5224  Acc@1: 81.2500 (78.8637)  Acc@5: 100.0000 (96.7649)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1570/3125]  eta: 0:09:02  Lr: 0.001875  Loss: -0.1834  Acc@1: 81.2500 (78.8749)  Acc@5: 100.0000 (96.7775)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1580/3125]  eta: 0:08:58  Lr: 0.001875  Loss: -0.6751  Acc@1: 81.2500 (78.8860)  Acc@5: 100.0000 (96.7821)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1590/3125]  eta: 0:08:55  Lr: 0.001875  Loss: -0.2746  Acc@1: 81.2500 (78.9048)  Acc@5: 100.0000 (96.7905)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1600/3125]  eta: 0:08:51  Lr: 0.001875  Loss: -0.5744  Acc@1: 81.2500 (78.9389)  Acc@5: 100.0000 (96.7833)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1610/3125]  eta: 0:08:48  Lr: 0.001875  Loss: -0.5540  Acc@1: 81.2500 (78.9378)  Acc@5: 100.0000 (96.7877)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1620/3125]  eta: 0:08:44  Lr: 0.001875  Loss: -0.4994  Acc@1: 81.2500 (78.9752)  Acc@5: 100.0000 (96.8037)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1630/3125]  eta: 0:08:41  Lr: 0.001875  Loss: -0.6220  Acc@1: 81.2500 (78.9968)  Acc@5: 100.0000 (96.8156)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1640/3125]  eta: 0:08:37  Lr: 0.001875  Loss: -0.5355  Acc@1: 81.2500 (79.0334)  Acc@5: 100.0000 (96.8160)  time: 0.3485  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1650/3125]  eta: 0:08:34  Lr: 0.001875  Loss: -0.9526  Acc@1: 81.2500 (79.0544)  Acc@5: 100.0000 (96.8315)  time: 0.3485  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1660/3125]  eta: 0:08:30  Lr: 0.001875  Loss: -0.2875  Acc@1: 81.2500 (79.1014)  Acc@5: 100.0000 (96.8355)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1670/3125]  eta: 0:08:27  Lr: 0.001875  Loss: -0.7716  Acc@1: 87.5000 (79.1367)  Acc@5: 100.0000 (96.8432)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1680/3125]  eta: 0:08:23  Lr: 0.001875  Loss: -0.5874  Acc@1: 81.2500 (79.1605)  Acc@5: 100.0000 (96.8546)  time: 0.3524  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1690/3125]  eta: 0:08:20  Lr: 0.001875  Loss: -0.3321  Acc@1: 81.2500 (79.1802)  Acc@5: 100.0000 (96.8695)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1700/3125]  eta: 0:08:17  Lr: 0.001875  Loss: -0.4435  Acc@1: 81.2500 (79.1997)  Acc@5: 100.0000 (96.8805)  time: 0.3521  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1710/3125]  eta: 0:08:13  Lr: 0.001875  Loss: -0.4322  Acc@1: 81.2500 (79.2263)  Acc@5: 100.0000 (96.8732)  time: 0.3531  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1720/3125]  eta: 0:08:10  Lr: 0.001875  Loss: -0.4672  Acc@1: 87.5000 (79.2490)  Acc@5: 100.0000 (96.8804)  time: 0.3528  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1730/3125]  eta: 0:08:06  Lr: 0.001875  Loss: -0.3964  Acc@1: 87.5000 (79.2966)  Acc@5: 100.0000 (96.8840)  time: 0.3528  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1740/3125]  eta: 0:08:03  Lr: 0.001875  Loss: -0.5975  Acc@1: 87.5000 (79.3222)  Acc@5: 100.0000 (96.8876)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1750/3125]  eta: 0:07:59  Lr: 0.001875  Loss: -0.5564  Acc@1: 87.5000 (79.3547)  Acc@5: 100.0000 (96.8946)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1760/3125]  eta: 0:07:56  Lr: 0.001875  Loss: 0.1216  Acc@1: 81.2500 (79.3796)  Acc@5: 100.0000 (96.8945)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1770/3125]  eta: 0:07:52  Lr: 0.001875  Loss: -0.7311  Acc@1: 81.2500 (79.3972)  Acc@5: 100.0000 (96.8909)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1780/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.6589  Acc@1: 81.2500 (79.4111)  Acc@5: 100.0000 (96.8943)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1790/3125]  eta: 0:07:45  Lr: 0.001875  Loss: -0.6059  Acc@1: 81.2500 (79.4249)  Acc@5: 100.0000 (96.9116)  time: 0.3491  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1800/3125]  eta: 0:07:42  Lr: 0.001875  Loss: 0.0534  Acc@1: 81.2500 (79.4628)  Acc@5: 100.0000 (96.9080)  time: 0.3505  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1810/3125]  eta: 0:07:38  Lr: 0.001875  Loss: -0.2833  Acc@1: 87.5000 (79.5141)  Acc@5: 100.0000 (96.9250)  time: 0.3500  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1820/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.3666  Acc@1: 87.5000 (79.5305)  Acc@5: 100.0000 (96.9282)  time: 0.3501  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1830/3125]  eta: 0:07:31  Lr: 0.001875  Loss: -0.2646  Acc@1: 81.2500 (79.5365)  Acc@5: 100.0000 (96.9313)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1840/3125]  eta: 0:07:28  Lr: 0.001875  Loss: -0.5918  Acc@1: 81.2500 (79.5593)  Acc@5: 100.0000 (96.9412)  time: 0.3548  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1850/3125]  eta: 0:07:24  Lr: 0.001875  Loss: -0.4919  Acc@1: 81.2500 (79.5752)  Acc@5: 100.0000 (96.9510)  time: 0.3536  data: 0.0021  max mem: 2502
Train: Epoch[1/5]  [1860/3125]  eta: 0:07:21  Lr: 0.001875  Loss: -0.4049  Acc@1: 81.2500 (79.5943)  Acc@5: 100.0000 (96.9640)  time: 0.3482  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [1870/3125]  eta: 0:07:17  Lr: 0.001875  Loss: -0.3161  Acc@1: 81.2500 (79.5998)  Acc@5: 100.0000 (96.9635)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1880/3125]  eta: 0:07:14  Lr: 0.001875  Loss: -0.3324  Acc@1: 81.2500 (79.6053)  Acc@5: 100.0000 (96.9763)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1890/3125]  eta: 0:07:10  Lr: 0.001875  Loss: -0.2079  Acc@1: 81.2500 (79.6206)  Acc@5: 100.0000 (96.9791)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:07  Lr: 0.001875  Loss: -0.3536  Acc@1: 81.2500 (79.6390)  Acc@5: 100.0000 (96.9786)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1910/3125]  eta: 0:07:03  Lr: 0.001875  Loss: -0.3910  Acc@1: 81.2500 (79.6409)  Acc@5: 100.0000 (96.9878)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1920/3125]  eta: 0:07:00  Lr: 0.001875  Loss: -0.1013  Acc@1: 81.2500 (79.6558)  Acc@5: 100.0000 (96.9775)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1930/3125]  eta: 0:06:56  Lr: 0.001875  Loss: -0.6861  Acc@1: 81.2500 (79.6576)  Acc@5: 93.7500 (96.9705)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1940/3125]  eta: 0:06:53  Lr: 0.001875  Loss: -0.2814  Acc@1: 81.2500 (79.6625)  Acc@5: 100.0000 (96.9700)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1950/3125]  eta: 0:06:49  Lr: 0.001875  Loss: -0.4888  Acc@1: 81.2500 (79.6707)  Acc@5: 100.0000 (96.9695)  time: 0.3463  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1960/3125]  eta: 0:06:46  Lr: 0.001875  Loss: 0.2344  Acc@1: 81.2500 (79.6947)  Acc@5: 100.0000 (96.9754)  time: 0.3475  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1970/3125]  eta: 0:06:42  Lr: 0.001875  Loss: -0.4795  Acc@1: 81.2500 (79.6899)  Acc@5: 100.0000 (96.9844)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1980/3125]  eta: 0:06:39  Lr: 0.001875  Loss: -0.6061  Acc@1: 75.0000 (79.7072)  Acc@5: 100.0000 (96.9838)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1990/3125]  eta: 0:06:35  Lr: 0.001875  Loss: -0.5929  Acc@1: 81.2500 (79.7087)  Acc@5: 100.0000 (96.9864)  time: 0.3526  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2000/3125]  eta: 0:06:32  Lr: 0.001875  Loss: -0.3099  Acc@1: 81.2500 (79.7383)  Acc@5: 100.0000 (96.9859)  time: 0.3501  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.6644  Acc@1: 81.2500 (79.7271)  Acc@5: 100.0000 (96.9822)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2020/3125]  eta: 0:06:25  Lr: 0.001875  Loss: -0.3061  Acc@1: 75.0000 (79.7316)  Acc@5: 100.0000 (96.9910)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.5993  Acc@1: 81.2500 (79.7421)  Acc@5: 100.0000 (96.9904)  time: 0.3491  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2040/3125]  eta: 0:06:18  Lr: 0.001875  Loss: -0.6080  Acc@1: 81.2500 (79.7709)  Acc@5: 100.0000 (97.0021)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: 0.1433  Acc@1: 87.5000 (79.7964)  Acc@5: 100.0000 (97.0076)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:11  Lr: 0.001875  Loss: -0.4732  Acc@1: 81.2500 (79.8126)  Acc@5: 100.0000 (97.0160)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.8082  Acc@1: 81.2500 (79.8346)  Acc@5: 100.0000 (97.0123)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2080/3125]  eta: 0:06:04  Lr: 0.001875  Loss: -0.4277  Acc@1: 87.5000 (79.8564)  Acc@5: 100.0000 (97.0147)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.0864  Acc@1: 81.2500 (79.8661)  Acc@5: 100.0000 (97.0110)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2100/3125]  eta: 0:05:57  Lr: 0.001875  Loss: -0.7394  Acc@1: 81.2500 (79.8876)  Acc@5: 100.0000 (97.0223)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.6292  Acc@1: 81.2500 (79.8940)  Acc@5: 100.0000 (97.0245)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2120/3125]  eta: 0:05:50  Lr: 0.001875  Loss: -0.5530  Acc@1: 87.5000 (79.9240)  Acc@5: 100.0000 (97.0356)  time: 0.3440  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.7743  Acc@1: 87.5000 (79.9478)  Acc@5: 100.0000 (97.0378)  time: 0.3455  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2140/3125]  eta: 0:05:43  Lr: 0.001875  Loss: -0.6969  Acc@1: 87.5000 (79.9918)  Acc@5: 100.0000 (97.0487)  time: 0.3471  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.6056  Acc@1: 87.5000 (79.9831)  Acc@5: 100.0000 (97.0566)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2160/3125]  eta: 0:05:36  Lr: 0.001875  Loss: -0.2167  Acc@1: 75.0000 (79.9861)  Acc@5: 100.0000 (97.0442)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6564  Acc@1: 81.2500 (80.0092)  Acc@5: 100.0000 (97.0492)  time: 0.3535  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2180/3125]  eta: 0:05:29  Lr: 0.001875  Loss: -0.3831  Acc@1: 87.5000 (80.0264)  Acc@5: 100.0000 (97.0455)  time: 0.3532  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.3638  Acc@1: 87.5000 (80.0633)  Acc@5: 100.0000 (97.0476)  time: 0.3514  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2200/3125]  eta: 0:05:22  Lr: 0.001875  Loss: -0.5602  Acc@1: 87.5000 (80.0971)  Acc@5: 100.0000 (97.0525)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.5453  Acc@1: 87.5000 (80.1278)  Acc@5: 100.0000 (97.0545)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:15  Lr: 0.001875  Loss: -0.2815  Acc@1: 81.2500 (80.1356)  Acc@5: 100.0000 (97.0593)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2268  Acc@1: 81.2500 (80.1294)  Acc@5: 100.0000 (97.0557)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:08  Lr: 0.001875  Loss: -0.3743  Acc@1: 81.2500 (80.1344)  Acc@5: 100.0000 (97.0605)  time: 0.3469  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.3226  Acc@1: 81.2500 (80.1533)  Acc@5: 100.0000 (97.0707)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2260/3125]  eta: 0:05:01  Lr: 0.001875  Loss: -0.4675  Acc@1: 87.5000 (80.1664)  Acc@5: 100.0000 (97.0754)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.7008  Acc@1: 81.2500 (80.1712)  Acc@5: 100.0000 (97.0855)  time: 0.3478  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2280/3125]  eta: 0:04:54  Lr: 0.001875  Loss: -0.6894  Acc@1: 81.2500 (80.1869)  Acc@5: 100.0000 (97.0901)  time: 0.3469  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.6137  Acc@1: 87.5000 (80.2188)  Acc@5: 100.0000 (97.0892)  time: 0.3458  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2300/3125]  eta: 0:04:47  Lr: 0.001875  Loss: -0.7153  Acc@1: 87.5000 (80.2559)  Acc@5: 100.0000 (97.0937)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.0428  Acc@1: 81.2500 (80.2494)  Acc@5: 100.0000 (97.0927)  time: 0.3455  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2320/3125]  eta: 0:04:40  Lr: 0.001875  Loss: -0.6712  Acc@1: 81.2500 (80.2590)  Acc@5: 100.0000 (97.0918)  time: 0.3457  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.1302  Acc@1: 87.5000 (80.2847)  Acc@5: 100.0000 (97.0935)  time: 0.3464  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2340/3125]  eta: 0:04:33  Lr: 0.001875  Loss: -0.7597  Acc@1: 87.5000 (80.2996)  Acc@5: 100.0000 (97.0979)  time: 0.3472  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6410  Acc@1: 81.2500 (80.3142)  Acc@5: 100.0000 (97.1023)  time: 0.3502  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:26  Lr: 0.001875  Loss: 0.2167  Acc@1: 81.2500 (80.3261)  Acc@5: 100.0000 (97.1066)  time: 0.3518  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.4765  Acc@1: 81.2500 (80.3379)  Acc@5: 100.0000 (97.1057)  time: 0.3501  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:19  Lr: 0.001875  Loss: -0.1336  Acc@1: 81.2500 (80.3549)  Acc@5: 100.0000 (97.1073)  time: 0.3502  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.5672  Acc@1: 81.2500 (80.3717)  Acc@5: 93.7500 (97.1011)  time: 0.3502  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:12  Lr: 0.001875  Loss: -0.8210  Acc@1: 87.5000 (80.3884)  Acc@5: 100.0000 (97.1106)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.5369  Acc@1: 87.5000 (80.4205)  Acc@5: 100.0000 (97.1174)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:05  Lr: 0.001875  Loss: -0.5277  Acc@1: 87.5000 (80.4342)  Acc@5: 100.0000 (97.1190)  time: 0.3505  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: 0.0310  Acc@1: 81.2500 (80.4170)  Acc@5: 100.0000 (97.1231)  time: 0.3505  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2440/3125]  eta: 0:03:58  Lr: 0.001875  Loss: -0.4163  Acc@1: 81.2500 (80.4307)  Acc@5: 100.0000 (97.1298)  time: 0.3502  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.4609  Acc@1: 81.2500 (80.4315)  Acc@5: 100.0000 (97.1262)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [2460/3125]  eta: 0:03:51  Lr: 0.001875  Loss: -0.2467  Acc@1: 81.2500 (80.4297)  Acc@5: 100.0000 (97.1226)  time: 0.3490  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.4361  Acc@1: 81.2500 (80.4431)  Acc@5: 100.0000 (97.1292)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2480/3125]  eta: 0:03:44  Lr: 0.001875  Loss: -0.5853  Acc@1: 87.5000 (80.4665)  Acc@5: 100.0000 (97.1383)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.5532  Acc@1: 87.5000 (80.4747)  Acc@5: 100.0000 (97.1322)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.0358  Acc@1: 87.5000 (80.4978)  Acc@5: 93.7500 (97.1336)  time: 0.3501  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.8274  Acc@1: 87.5000 (80.5456)  Acc@5: 100.0000 (97.1401)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.9181  Acc@1: 87.5000 (80.5558)  Acc@5: 100.0000 (97.1390)  time: 0.3506  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.3770  Acc@1: 81.2500 (80.5610)  Acc@5: 100.0000 (97.1454)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.4450  Acc@1: 87.5000 (80.5711)  Acc@5: 100.0000 (97.1493)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.6175  Acc@1: 87.5000 (80.5983)  Acc@5: 100.0000 (97.1506)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.5936  Acc@1: 87.5000 (80.6179)  Acc@5: 100.0000 (97.1569)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.5478  Acc@1: 87.5000 (80.6374)  Acc@5: 100.0000 (97.1655)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.8143  Acc@1: 87.5000 (80.6640)  Acc@5: 100.0000 (97.1692)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.4016  Acc@1: 87.5000 (80.6831)  Acc@5: 100.0000 (97.1753)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.4582  Acc@1: 87.5000 (80.7141)  Acc@5: 100.0000 (97.1790)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.2085  Acc@1: 87.5000 (80.7258)  Acc@5: 100.0000 (97.1826)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7047  Acc@1: 87.5000 (80.7421)  Acc@5: 100.0000 (97.1838)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.5728  Acc@1: 81.2500 (80.7464)  Acc@5: 100.0000 (97.1874)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.6995  Acc@1: 87.5000 (80.7601)  Acc@5: 100.0000 (97.1862)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7271  Acc@1: 87.5000 (80.7620)  Acc@5: 100.0000 (97.1803)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.9670  Acc@1: 81.2500 (80.7732)  Acc@5: 100.0000 (97.1815)  time: 0.3547  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.3207  Acc@1: 81.2500 (80.7844)  Acc@5: 100.0000 (97.1921)  time: 0.3529  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.2678  Acc@1: 81.2500 (80.7768)  Acc@5: 100.0000 (97.2025)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.4072  Acc@1: 81.2500 (80.8017)  Acc@5: 100.0000 (97.2013)  time: 0.3523  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.8094  Acc@1: 87.5000 (80.8219)  Acc@5: 100.0000 (97.2094)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.7601  Acc@1: 87.5000 (80.8258)  Acc@5: 100.0000 (97.2104)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.7635  Acc@1: 81.2500 (80.8274)  Acc@5: 100.0000 (97.2161)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.4945  Acc@1: 81.2500 (80.8426)  Acc@5: 100.0000 (97.2194)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5361  Acc@1: 87.5000 (80.8646)  Acc@5: 100.0000 (97.2250)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.6399  Acc@1: 87.5000 (80.8706)  Acc@5: 100.0000 (97.2260)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.7553  Acc@1: 81.2500 (80.8833)  Acc@5: 100.0000 (97.2270)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.3442  Acc@1: 81.2500 (80.9004)  Acc@5: 100.0000 (97.2302)  time: 0.3466  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.5233  Acc@1: 87.5000 (80.9196)  Acc@5: 100.0000 (97.2335)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2790/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.2708  Acc@1: 87.5000 (80.9410)  Acc@5: 100.0000 (97.2299)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.1036  Acc@1: 81.2500 (80.9421)  Acc@5: 100.0000 (97.2354)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2810/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7845  Acc@1: 81.2500 (80.9543)  Acc@5: 100.0000 (97.2385)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7705  Acc@1: 81.2500 (80.9642)  Acc@5: 100.0000 (97.2395)  time: 0.3466  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:42  Lr: 0.001875  Loss: -0.4533  Acc@1: 81.2500 (80.9696)  Acc@5: 100.0000 (97.2426)  time: 0.3478  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: 0.4141  Acc@1: 87.5000 (80.9750)  Acc@5: 100.0000 (97.2391)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:35  Lr: 0.001875  Loss: 0.0791  Acc@1: 81.2500 (80.9913)  Acc@5: 100.0000 (97.2422)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.6364  Acc@1: 87.5000 (81.0119)  Acc@5: 100.0000 (97.2475)  time: 0.3489  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8205  Acc@1: 87.5000 (81.0345)  Acc@5: 100.0000 (97.2505)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.3738  Acc@1: 87.5000 (81.0482)  Acc@5: 100.0000 (97.2557)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4425  Acc@1: 81.2500 (81.0619)  Acc@5: 100.0000 (97.2631)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.7527  Acc@1: 81.2500 (81.0733)  Acc@5: 100.0000 (97.2660)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:14  Lr: 0.001875  Loss: 0.0287  Acc@1: 87.5000 (81.0804)  Acc@5: 100.0000 (97.2647)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5380  Acc@1: 87.5000 (81.1002)  Acc@5: 100.0000 (97.2634)  time: 0.3513  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.8142  Acc@1: 87.5000 (81.1071)  Acc@5: 100.0000 (97.2642)  time: 0.3539  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.2349  Acc@1: 81.2500 (81.1161)  Acc@5: 100.0000 (97.2650)  time: 0.3529  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.4423  Acc@1: 81.2500 (81.1250)  Acc@5: 100.0000 (97.2721)  time: 0.3486  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3926  Acc@1: 81.2500 (81.1297)  Acc@5: 100.0000 (97.2771)  time: 0.3493  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6337  Acc@1: 87.5000 (81.1701)  Acc@5: 100.0000 (97.2800)  time: 0.3505  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.5078  Acc@1: 87.5000 (81.1871)  Acc@5: 100.0000 (97.2807)  time: 0.3501  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4581  Acc@1: 87.5000 (81.1998)  Acc@5: 100.0000 (97.2877)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.4810  Acc@1: 81.2500 (81.2125)  Acc@5: 100.0000 (97.2967)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4206  Acc@1: 81.2500 (81.2168)  Acc@5: 100.0000 (97.2995)  time: 0.3489  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.3223  Acc@1: 81.2500 (81.2231)  Acc@5: 100.0000 (97.3043)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7814  Acc@1: 87.5000 (81.2479)  Acc@5: 100.0000 (97.3091)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5035  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (97.3056)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5587  Acc@1: 87.5000 (81.2746)  Acc@5: 100.0000 (97.3103)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: 0.0835  Acc@1: 87.5000 (81.2704)  Acc@5: 100.0000 (97.3150)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.7272  Acc@1: 87.5000 (81.2887)  Acc@5: 100.0000 (97.3197)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.6283  Acc@1: 87.5000 (81.2926)  Acc@5: 100.0000 (97.3223)  time: 0.3459  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.7163  Acc@1: 81.2500 (81.2945)  Acc@5: 100.0000 (97.3188)  time: 0.3461  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.3351  Acc@1: 81.2500 (81.3024)  Acc@5: 100.0000 (97.3255)  time: 0.3462  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5659  Acc@1: 81.2500 (81.2922)  Acc@5: 100.0000 (97.3260)  time: 0.3481  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.1824  Acc@1: 81.2500 (81.2780)  Acc@5: 100.0000 (97.3346)  time: 0.3499  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3275  Acc@1: 75.0000 (81.2660)  Acc@5: 100.0000 (97.3340)  time: 0.3497  data: 0.0014  max mem: 2502
Train: Epoch[1/5] Total time: 0:18:10 (0.3490 s / it)
{0: {0: 0, 1: 0, 2: 49872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 49888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 49936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.3275  Acc@1: 75.0000 (81.2660)  Acc@5: 100.0000 (97.3340)
Train: Epoch[2/5]  [   0/3125]  eta: 1:01:23  Lr: 0.001875  Loss: -0.6869  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 1.1788  data: 0.8198  max mem: 2502
Train: Epoch[2/5]  [  10/3125]  eta: 0:22:11  Lr: 0.001875  Loss: -0.3574  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (97.7273)  time: 0.4276  data: 0.0754  max mem: 2502
Train: Epoch[2/5]  [  20/3125]  eta: 0:20:16  Lr: 0.001875  Loss: -0.4350  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (98.5119)  time: 0.3523  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [  30/3125]  eta: 0:19:29  Lr: 0.001875  Loss: -0.6062  Acc@1: 81.2500 (82.4597)  Acc@5: 100.0000 (98.1855)  time: 0.3506  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [  40/3125]  eta: 0:19:04  Lr: 0.001875  Loss: -0.7518  Acc@1: 81.2500 (83.2317)  Acc@5: 100.0000 (98.1707)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  50/3125]  eta: 0:18:49  Lr: 0.001875  Loss: -0.2466  Acc@1: 81.2500 (83.0882)  Acc@5: 100.0000 (98.2843)  time: 0.3511  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [  60/3125]  eta: 0:18:37  Lr: 0.001875  Loss: -0.7428  Acc@1: 87.5000 (84.0164)  Acc@5: 100.0000 (98.4631)  time: 0.3515  data: 0.0025  max mem: 2502
Train: Epoch[2/5]  [  70/3125]  eta: 0:18:26  Lr: 0.001875  Loss: -0.5756  Acc@1: 87.5000 (83.6268)  Acc@5: 100.0000 (98.4155)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  80/3125]  eta: 0:18:17  Lr: 0.001875  Loss: -0.2104  Acc@1: 75.0000 (82.4846)  Acc@5: 93.7500 (97.9167)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  90/3125]  eta: 0:18:09  Lr: 0.001875  Loss: -0.6496  Acc@1: 75.0000 (82.8297)  Acc@5: 93.7500 (97.8709)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 100/3125]  eta: 0:18:02  Lr: 0.001875  Loss: -0.1408  Acc@1: 87.5000 (82.6114)  Acc@5: 100.0000 (97.8342)  time: 0.3472  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 110/3125]  eta: 0:17:55  Lr: 0.001875  Loss: -0.3330  Acc@1: 81.2500 (82.8829)  Acc@5: 100.0000 (97.9167)  time: 0.3473  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 120/3125]  eta: 0:17:49  Lr: 0.001875  Loss: -0.5746  Acc@1: 81.2500 (83.1095)  Acc@5: 100.0000 (97.8822)  time: 0.3464  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 130/3125]  eta: 0:17:43  Lr: 0.001875  Loss: -0.7006  Acc@1: 81.2500 (83.1107)  Acc@5: 100.0000 (97.9485)  time: 0.3456  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 140/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.3518  Acc@1: 81.2500 (83.2004)  Acc@5: 100.0000 (98.0496)  time: 0.3455  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 150/3125]  eta: 0:17:32  Lr: 0.001875  Loss: -0.2925  Acc@1: 81.2500 (83.2368)  Acc@5: 100.0000 (98.0960)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 160/3125]  eta: 0:17:27  Lr: 0.001875  Loss: -0.2191  Acc@1: 87.5000 (83.5404)  Acc@5: 100.0000 (98.1366)  time: 0.3451  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 170/3125]  eta: 0:17:22  Lr: 0.001875  Loss: -0.5711  Acc@1: 87.5000 (83.6623)  Acc@5: 100.0000 (98.1360)  time: 0.3468  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 180/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6887  Acc@1: 87.5000 (83.8052)  Acc@5: 100.0000 (98.1354)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 190/3125]  eta: 0:17:14  Lr: 0.001875  Loss: -0.8059  Acc@1: 87.5000 (83.8351)  Acc@5: 100.0000 (98.2003)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 200/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.3621  Acc@1: 81.2500 (83.7376)  Acc@5: 100.0000 (98.1654)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 210/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.4415  Acc@1: 81.2500 (83.9159)  Acc@5: 100.0000 (98.2524)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 220/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.3203  Acc@1: 87.5000 (83.8235)  Acc@5: 100.0000 (98.2466)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 230/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.7523  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (98.2684)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 240/3125]  eta: 0:16:55  Lr: 0.001875  Loss: -0.2590  Acc@1: 81.2500 (83.8434)  Acc@5: 100.0000 (98.2624)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 250/3125]  eta: 0:16:53  Lr: 0.001875  Loss: -0.0943  Acc@1: 81.2500 (83.7151)  Acc@5: 100.0000 (98.2321)  time: 0.3544  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [ 260/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.4604  Acc@1: 81.2500 (83.8362)  Acc@5: 100.0000 (98.2759)  time: 0.3541  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [ 270/3125]  eta: 0:16:46  Lr: 0.001875  Loss: -0.3834  Acc@1: 87.5000 (83.9022)  Acc@5: 100.0000 (98.2703)  time: 0.3528  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 280/3125]  eta: 0:16:42  Lr: 0.001875  Loss: -0.7117  Acc@1: 87.5000 (83.9858)  Acc@5: 100.0000 (98.2429)  time: 0.3535  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 290/3125]  eta: 0:16:38  Lr: 0.001875  Loss: -0.7696  Acc@1: 87.5000 (83.9777)  Acc@5: 100.0000 (98.1959)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 300/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.0393  Acc@1: 81.2500 (83.8870)  Acc@5: 100.0000 (98.1312)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 310/3125]  eta: 0:16:30  Lr: 0.001875  Loss: -0.6354  Acc@1: 81.2500 (83.9027)  Acc@5: 100.0000 (98.1511)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 320/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.6903  Acc@1: 81.2500 (84.0732)  Acc@5: 100.0000 (98.1503)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 330/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.4123  Acc@1: 87.5000 (84.0634)  Acc@5: 100.0000 (98.1495)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 340/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.8384  Acc@1: 87.5000 (84.1642)  Acc@5: 100.0000 (98.1305)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 350/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.2726  Acc@1: 87.5000 (84.2236)  Acc@5: 100.0000 (98.1125)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 360/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.5744  Acc@1: 87.5000 (84.3490)  Acc@5: 100.0000 (98.1129)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 370/3125]  eta: 0:16:07  Lr: 0.001875  Loss: -0.2493  Acc@1: 87.5000 (84.4677)  Acc@5: 100.0000 (98.1637)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 380/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.1241  Acc@1: 87.5000 (84.4160)  Acc@5: 100.0000 (98.1463)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 390/3125]  eta: 0:16:00  Lr: 0.001875  Loss: -0.3101  Acc@1: 81.2500 (84.4309)  Acc@5: 100.0000 (98.1777)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 400/3125]  eta: 0:15:56  Lr: 0.001875  Loss: -0.2836  Acc@1: 87.5000 (84.4763)  Acc@5: 100.0000 (98.1764)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 410/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.2793  Acc@1: 87.5000 (84.5195)  Acc@5: 100.0000 (98.1752)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 420/3125]  eta: 0:15:48  Lr: 0.001875  Loss: -0.3659  Acc@1: 87.5000 (84.5457)  Acc@5: 100.0000 (98.1740)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 430/3125]  eta: 0:15:44  Lr: 0.001875  Loss: -0.0932  Acc@1: 81.2500 (84.4403)  Acc@5: 100.0000 (98.1584)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 440/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.4362  Acc@1: 81.2500 (84.4246)  Acc@5: 100.0000 (98.1576)  time: 0.3453  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 450/3125]  eta: 0:15:37  Lr: 0.001875  Loss: -0.5271  Acc@1: 87.5000 (84.4928)  Acc@5: 100.0000 (98.1569)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 460/3125]  eta: 0:15:33  Lr: 0.001875  Loss: -0.5398  Acc@1: 87.5000 (84.5309)  Acc@5: 100.0000 (98.1562)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 470/3125]  eta: 0:15:30  Lr: 0.001875  Loss: -0.7095  Acc@1: 87.5000 (84.5143)  Acc@5: 100.0000 (98.1157)  time: 0.3496  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 480/3125]  eta: 0:15:27  Lr: 0.001875  Loss: -0.6503  Acc@1: 87.5000 (84.5114)  Acc@5: 100.0000 (98.1159)  time: 0.3528  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 490/3125]  eta: 0:15:23  Lr: 0.001875  Loss: -0.7309  Acc@1: 87.5000 (84.5468)  Acc@5: 100.0000 (98.1415)  time: 0.3536  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 500/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.6669  Acc@1: 87.5000 (84.5434)  Acc@5: 100.0000 (98.1412)  time: 0.3524  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 510/3125]  eta: 0:15:16  Lr: 0.001875  Loss: -0.5344  Acc@1: 87.5000 (84.4912)  Acc@5: 100.0000 (98.1409)  time: 0.3510  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 520/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.7682  Acc@1: 87.5000 (84.5849)  Acc@5: 100.0000 (98.1766)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 530/3125]  eta: 0:15:09  Lr: 0.001875  Loss: -0.6587  Acc@1: 87.5000 (84.5927)  Acc@5: 100.0000 (98.2109)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 540/3125]  eta: 0:15:05  Lr: 0.001875  Loss: -0.6877  Acc@1: 87.5000 (84.6580)  Acc@5: 100.0000 (98.2209)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 550/3125]  eta: 0:15:02  Lr: 0.001875  Loss: -0.5416  Acc@1: 81.2500 (84.6075)  Acc@5: 100.0000 (98.1851)  time: 0.3468  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 560/3125]  eta: 0:14:58  Lr: 0.001875  Loss: -0.2074  Acc@1: 81.2500 (84.6145)  Acc@5: 100.0000 (98.1840)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 570/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.3225  Acc@1: 87.5000 (84.6979)  Acc@5: 100.0000 (98.1721)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 580/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.5934  Acc@1: 87.5000 (84.6493)  Acc@5: 100.0000 (98.1605)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 590/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.1173  Acc@1: 81.2500 (84.6552)  Acc@5: 100.0000 (98.1493)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 600/3125]  eta: 0:14:44  Lr: 0.001875  Loss: -0.6370  Acc@1: 81.2500 (84.6402)  Acc@5: 100.0000 (98.1593)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 610/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.2622  Acc@1: 81.2500 (84.5847)  Acc@5: 100.0000 (98.1588)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 620/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.3919  Acc@1: 81.2500 (84.6216)  Acc@5: 100.0000 (98.1683)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 630/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.8097  Acc@1: 81.2500 (84.6474)  Acc@5: 100.0000 (98.1874)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 640/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5285  Acc@1: 87.5000 (84.6236)  Acc@5: 100.0000 (98.1864)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 650/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.4138  Acc@1: 87.5000 (84.6966)  Acc@5: 100.0000 (98.2143)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 660/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.3225  Acc@1: 87.5000 (84.7485)  Acc@5: 100.0000 (98.2318)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 670/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.8343  Acc@1: 87.5000 (84.8454)  Acc@5: 100.0000 (98.2396)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 680/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.2682  Acc@1: 87.5000 (84.8477)  Acc@5: 100.0000 (98.2379)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 690/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.2885  Acc@1: 87.5000 (84.8951)  Acc@5: 100.0000 (98.2091)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 700/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.3479  Acc@1: 87.5000 (84.9055)  Acc@5: 100.0000 (98.2079)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 710/3125]  eta: 0:14:03  Lr: 0.001875  Loss: -0.2551  Acc@1: 87.5000 (84.8541)  Acc@5: 100.0000 (98.1804)  time: 0.3485  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 720/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.1371  Acc@1: 81.2500 (84.8301)  Acc@5: 100.0000 (98.1709)  time: 0.3511  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [ 730/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.3332  Acc@1: 81.2500 (84.7897)  Acc@5: 100.0000 (98.1703)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 740/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.8326  Acc@1: 81.2500 (84.7335)  Acc@5: 100.0000 (98.1697)  time: 0.3496  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 750/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.8760  Acc@1: 81.2500 (84.7703)  Acc@5: 100.0000 (98.1608)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 760/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.5606  Acc@1: 87.5000 (84.8390)  Acc@5: 100.0000 (98.1685)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 770/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6070  Acc@1: 87.5000 (84.8330)  Acc@5: 100.0000 (98.1761)  time: 0.3505  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 780/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.2041  Acc@1: 81.2500 (84.8351)  Acc@5: 100.0000 (98.1754)  time: 0.3512  data: 0.0024  max mem: 2502
Train: Epoch[2/5]  [ 790/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.1511  Acc@1: 81.2500 (84.7661)  Acc@5: 100.0000 (98.1669)  time: 0.3509  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 800/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.5365  Acc@1: 81.2500 (84.7768)  Acc@5: 100.0000 (98.1820)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 810/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.1615  Acc@1: 87.5000 (84.7719)  Acc@5: 100.0000 (98.1890)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 820/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.3619  Acc@1: 81.2500 (84.7290)  Acc@5: 100.0000 (98.1806)  time: 0.3520  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [ 830/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.3225  Acc@1: 81.2500 (84.7398)  Acc@5: 100.0000 (98.1799)  time: 0.3532  data: 0.0023  max mem: 2502
Train: Epoch[2/5]  [ 840/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.5759  Acc@1: 81.2500 (84.7280)  Acc@5: 100.0000 (98.1793)  time: 0.3539  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [ 850/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6491  Acc@1: 87.5000 (84.7679)  Acc@5: 100.0000 (98.1566)  time: 0.3506  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 860/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.1561  Acc@1: 87.5000 (84.7779)  Acc@5: 100.0000 (98.1417)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 870/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.8177  Acc@1: 87.5000 (84.7948)  Acc@5: 100.0000 (98.1559)  time: 0.3482  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 880/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.5204  Acc@1: 87.5000 (84.7616)  Acc@5: 100.0000 (98.1555)  time: 0.3532  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 890/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.3002  Acc@1: 87.5000 (84.8204)  Acc@5: 100.0000 (98.1692)  time: 0.3551  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 900/3125]  eta: 0:12:58  Lr: 0.001875  Loss: 0.1230  Acc@1: 87.5000 (84.7808)  Acc@5: 100.0000 (98.1548)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 910/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.5911  Acc@1: 81.2500 (84.8175)  Acc@5: 100.0000 (98.1682)  time: 0.3552  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 920/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.8334  Acc@1: 93.7500 (84.8806)  Acc@5: 100.0000 (98.1813)  time: 0.3517  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 930/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.5745  Acc@1: 87.5000 (84.8751)  Acc@5: 100.0000 (98.1807)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 940/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.5504  Acc@1: 87.5000 (84.8565)  Acc@5: 100.0000 (98.1735)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 950/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.5411  Acc@1: 81.2500 (84.8580)  Acc@5: 100.0000 (98.1664)  time: 0.3496  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 960/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.3445  Acc@1: 87.5000 (84.8855)  Acc@5: 100.0000 (98.1595)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 970/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.6999  Acc@1: 87.5000 (84.9060)  Acc@5: 100.0000 (98.1527)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 980/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.5105  Acc@1: 87.5000 (84.9325)  Acc@5: 100.0000 (98.1715)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 990/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.6044  Acc@1: 87.5000 (84.9458)  Acc@5: 100.0000 (98.1710)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1000/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.6376  Acc@1: 87.5000 (84.9588)  Acc@5: 100.0000 (98.1831)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.0437  Acc@1: 87.5000 (84.9530)  Acc@5: 100.0000 (98.1763)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1020/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.5068  Acc@1: 81.2500 (84.9535)  Acc@5: 100.0000 (98.1636)  time: 0.3491  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.5003  Acc@1: 81.2500 (84.9539)  Acc@5: 100.0000 (98.1693)  time: 0.3502  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1040/3125]  eta: 0:12:09  Lr: 0.001875  Loss: -0.5934  Acc@1: 81.2500 (84.9244)  Acc@5: 100.0000 (98.1748)  time: 0.3503  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.5732  Acc@1: 81.2500 (84.9310)  Acc@5: 100.0000 (98.1744)  time: 0.3495  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1060/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.4621  Acc@1: 81.2500 (84.9081)  Acc@5: 100.0000 (98.1798)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.3429  Acc@1: 87.5000 (84.9090)  Acc@5: 100.0000 (98.1851)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1080/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.8458  Acc@1: 87.5000 (84.8809)  Acc@5: 100.0000 (98.1730)  time: 0.3582  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1090/3125]  eta: 0:11:52  Lr: 0.001875  Loss: -0.4426  Acc@1: 81.2500 (84.8992)  Acc@5: 100.0000 (98.1783)  time: 0.3586  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1100/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.0564  Acc@1: 81.2500 (84.8660)  Acc@5: 100.0000 (98.1835)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1110/3125]  eta: 0:11:45  Lr: 0.001875  Loss: -0.6753  Acc@1: 81.2500 (84.8447)  Acc@5: 100.0000 (98.1886)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1120/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.2491  Acc@1: 81.2500 (84.8294)  Acc@5: 100.0000 (98.1769)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1130/3125]  eta: 0:11:38  Lr: 0.001875  Loss: -0.3646  Acc@1: 81.2500 (84.8254)  Acc@5: 100.0000 (98.1819)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1140/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.6270  Acc@1: 81.2500 (84.8050)  Acc@5: 100.0000 (98.1924)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.7668  Acc@1: 81.2500 (84.7958)  Acc@5: 100.0000 (98.1864)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1160/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.4661  Acc@1: 87.5000 (84.8191)  Acc@5: 100.0000 (98.1804)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.1256  Acc@1: 81.2500 (84.8047)  Acc@5: 100.0000 (98.1746)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1180/3125]  eta: 0:11:20  Lr: 0.001875  Loss: 0.2160  Acc@1: 81.2500 (84.7798)  Acc@5: 100.0000 (98.1742)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.5432  Acc@1: 87.5000 (84.8027)  Acc@5: 100.0000 (98.1791)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1200/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.8171  Acc@1: 87.5000 (84.8460)  Acc@5: 100.0000 (98.1890)  time: 0.3470  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.1447  Acc@1: 87.5000 (84.8318)  Acc@5: 100.0000 (98.1885)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1220/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.6841  Acc@1: 87.5000 (84.8434)  Acc@5: 100.0000 (98.1777)  time: 0.3490  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.3210  Acc@1: 87.5000 (84.8548)  Acc@5: 100.0000 (98.1722)  time: 0.3497  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1240/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.7633  Acc@1: 87.5000 (84.8711)  Acc@5: 100.0000 (98.1819)  time: 0.3530  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.6182  Acc@1: 87.5000 (84.9021)  Acc@5: 100.0000 (98.1815)  time: 0.3544  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1260/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.5866  Acc@1: 87.5000 (84.9078)  Acc@5: 100.0000 (98.1909)  time: 0.3541  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.8785  Acc@1: 87.5000 (84.9282)  Acc@5: 100.0000 (98.1953)  time: 0.3519  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1280/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.5926  Acc@1: 87.5000 (84.9336)  Acc@5: 100.0000 (98.1948)  time: 0.3488  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.6744  Acc@1: 87.5000 (84.9196)  Acc@5: 100.0000 (98.1991)  time: 0.3486  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1300/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.8601  Acc@1: 87.5000 (84.9587)  Acc@5: 100.0000 (98.2081)  time: 0.3498  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4281  Acc@1: 87.5000 (84.9447)  Acc@5: 100.0000 (98.2122)  time: 0.3491  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1320/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.6977  Acc@1: 87.5000 (84.9877)  Acc@5: 100.0000 (98.2210)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.2091  Acc@1: 87.5000 (84.9690)  Acc@5: 100.0000 (98.2203)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1340/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.7086  Acc@1: 87.5000 (84.9786)  Acc@5: 100.0000 (98.2289)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.4693  Acc@1: 87.5000 (84.9695)  Acc@5: 100.0000 (98.2282)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1360/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.0830  Acc@1: 87.5000 (84.9651)  Acc@5: 100.0000 (98.2320)  time: 0.3471  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.0067  Acc@1: 81.2500 (84.9380)  Acc@5: 100.0000 (98.2312)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1380/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.6595  Acc@1: 81.2500 (84.9611)  Acc@5: 100.0000 (98.2395)  time: 0.3477  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1390/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5520  Acc@1: 87.5000 (84.9793)  Acc@5: 100.0000 (98.2387)  time: 0.3458  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1400/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.0698  Acc@1: 87.5000 (84.9572)  Acc@5: 100.0000 (98.2156)  time: 0.3461  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.5073  Acc@1: 87.5000 (84.9708)  Acc@5: 100.0000 (98.2061)  time: 0.3477  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.5529  Acc@1: 81.2500 (84.9270)  Acc@5: 100.0000 (98.2011)  time: 0.3463  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.1566  Acc@1: 81.2500 (84.9231)  Acc@5: 100.0000 (98.2093)  time: 0.3453  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.4769  Acc@1: 81.2500 (84.9063)  Acc@5: 100.0000 (98.2044)  time: 0.3458  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.8101  Acc@1: 87.5000 (84.9113)  Acc@5: 100.0000 (98.1909)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5859  Acc@1: 87.5000 (84.9589)  Acc@5: 100.0000 (98.1905)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1470/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.6208  Acc@1: 93.7500 (85.0017)  Acc@5: 100.0000 (98.1985)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.5863  Acc@1: 87.5000 (85.0101)  Acc@5: 100.0000 (98.2064)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1490/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.5190  Acc@1: 81.2500 (84.9891)  Acc@5: 100.0000 (98.1975)  time: 0.3514  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [1500/3125]  eta: 0:09:27  Lr: 0.001875  Loss: 0.0117  Acc@1: 87.5000 (85.0058)  Acc@5: 100.0000 (98.2012)  time: 0.3529  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.8338  Acc@1: 87.5000 (85.0306)  Acc@5: 100.0000 (98.2090)  time: 0.3513  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1520/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.5681  Acc@1: 87.5000 (85.0099)  Acc@5: 100.0000 (98.2002)  time: 0.3511  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.4695  Acc@1: 81.2500 (84.9976)  Acc@5: 100.0000 (98.1997)  time: 0.3507  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [1540/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.2281  Acc@1: 81.2500 (85.0097)  Acc@5: 100.0000 (98.1952)  time: 0.3486  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.3487  Acc@1: 81.2500 (84.9694)  Acc@5: 100.0000 (98.1947)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1560/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.5838  Acc@1: 81.2500 (84.9736)  Acc@5: 100.0000 (98.1943)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.7348  Acc@1: 87.5000 (84.9618)  Acc@5: 100.0000 (98.1938)  time: 0.3487  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1580/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.8412  Acc@1: 87.5000 (84.9620)  Acc@5: 100.0000 (98.1894)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.5528  Acc@1: 81.2500 (84.9466)  Acc@5: 100.0000 (98.2008)  time: 0.3499  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1600/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.7114  Acc@1: 81.2500 (84.9469)  Acc@5: 100.0000 (98.1964)  time: 0.3504  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.7306  Acc@1: 81.2500 (84.9395)  Acc@5: 100.0000 (98.1921)  time: 0.3510  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1620/3125]  eta: 0:08:45  Lr: 0.001875  Loss: -0.5971  Acc@1: 81.2500 (84.9206)  Acc@5: 100.0000 (98.1801)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.7197  Acc@1: 87.5000 (84.9441)  Acc@5: 100.0000 (98.1875)  time: 0.3478  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1640/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.5651  Acc@1: 87.5000 (84.9406)  Acc@5: 100.0000 (98.1871)  time: 0.3495  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.5268  Acc@1: 87.5000 (84.9599)  Acc@5: 100.0000 (98.1905)  time: 0.3512  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.3408  Acc@1: 87.5000 (84.9789)  Acc@5: 100.0000 (98.1788)  time: 0.3509  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.4951  Acc@1: 87.5000 (84.9716)  Acc@5: 100.0000 (98.1747)  time: 0.3536  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.3483  Acc@1: 81.2500 (84.9792)  Acc@5: 100.0000 (98.1707)  time: 0.3548  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3631  Acc@1: 87.5000 (84.9941)  Acc@5: 100.0000 (98.1705)  time: 0.3543  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.6534  Acc@1: 87.5000 (84.9941)  Acc@5: 100.0000 (98.1739)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.4884  Acc@1: 81.2500 (84.9868)  Acc@5: 100.0000 (98.1845)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.5247  Acc@1: 87.5000 (84.9942)  Acc@5: 100.0000 (98.1915)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.7645  Acc@1: 87.5000 (85.0195)  Acc@5: 100.0000 (98.1911)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.5994  Acc@1: 87.5000 (85.0194)  Acc@5: 100.0000 (98.1943)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.3099  Acc@1: 81.2500 (85.0050)  Acc@5: 100.0000 (98.2010)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: -0.6245  Acc@1: 81.2500 (84.9979)  Acc@5: 100.0000 (98.2041)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.3800  Acc@1: 87.5000 (85.0226)  Acc@5: 100.0000 (98.2072)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.8500  Acc@1: 93.7500 (85.0611)  Acc@5: 100.0000 (98.2138)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5999  Acc@1: 87.5000 (85.0642)  Acc@5: 100.0000 (98.2133)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.4562  Acc@1: 81.2500 (85.0639)  Acc@5: 100.0000 (98.2128)  time: 0.3498  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.7308  Acc@1: 87.5000 (85.0704)  Acc@5: 100.0000 (98.2192)  time: 0.3496  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.4706  Acc@1: 87.5000 (85.0700)  Acc@5: 100.0000 (98.2153)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.3746  Acc@1: 87.5000 (85.0833)  Acc@5: 100.0000 (98.2182)  time: 0.3510  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.6561  Acc@1: 87.5000 (85.0930)  Acc@5: 100.0000 (98.2177)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.7571  Acc@1: 87.5000 (85.0959)  Acc@5: 100.0000 (98.2273)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.5460  Acc@1: 81.2500 (85.0786)  Acc@5: 100.0000 (98.2268)  time: 0.3502  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.9079  Acc@1: 81.2500 (85.0848)  Acc@5: 100.0000 (98.2296)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.4223  Acc@1: 87.5000 (85.0678)  Acc@5: 100.0000 (98.2323)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.7655  Acc@1: 87.5000 (85.0906)  Acc@5: 100.0000 (98.2417)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.1255  Acc@1: 87.5000 (85.0934)  Acc@5: 100.0000 (98.2443)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.5038  Acc@1: 87.5000 (85.1060)  Acc@5: 100.0000 (98.2503)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.8053  Acc@1: 87.5000 (85.1119)  Acc@5: 100.0000 (98.2464)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.1590  Acc@1: 87.5000 (85.1178)  Acc@5: 100.0000 (98.2522)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6032  Acc@1: 87.5000 (85.1269)  Acc@5: 100.0000 (98.2548)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.2930  Acc@1: 87.5000 (85.1262)  Acc@5: 100.0000 (98.2413)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.5318  Acc@1: 87.5000 (85.1288)  Acc@5: 100.0000 (98.2407)  time: 0.3453  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.3666  Acc@1: 87.5000 (85.1281)  Acc@5: 100.0000 (98.2433)  time: 0.3452  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.5771  Acc@1: 81.2500 (85.1054)  Acc@5: 100.0000 (98.2458)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.3781  Acc@1: 81.2500 (85.1080)  Acc@5: 100.0000 (98.2421)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.6375  Acc@1: 87.5000 (85.1168)  Acc@5: 100.0000 (98.2509)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.6746  Acc@1: 87.5000 (85.1225)  Acc@5: 100.0000 (98.2534)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.3640  Acc@1: 81.2500 (85.1064)  Acc@5: 100.0000 (98.2558)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.5188  Acc@1: 81.2500 (85.0997)  Acc@5: 100.0000 (98.2521)  time: 0.3484  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.0480  Acc@1: 81.2500 (85.0962)  Acc@5: 100.0000 (98.2545)  time: 0.3487  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.8721  Acc@1: 87.5000 (85.0987)  Acc@5: 100.0000 (98.2600)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.6691  Acc@1: 87.5000 (85.1195)  Acc@5: 100.0000 (98.2654)  time: 0.3504  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2188  Acc@1: 87.5000 (85.1099)  Acc@5: 100.0000 (98.2647)  time: 0.3501  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.6711  Acc@1: 81.2500 (85.0913)  Acc@5: 100.0000 (98.2641)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.3611  Acc@1: 87.5000 (85.0909)  Acc@5: 100.0000 (98.2574)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.5510  Acc@1: 87.5000 (85.1053)  Acc@5: 100.0000 (98.2598)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.1876  Acc@1: 87.5000 (85.1167)  Acc@5: 100.0000 (98.2621)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.6090  Acc@1: 87.5000 (85.1397)  Acc@5: 100.0000 (98.2644)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.6605  Acc@1: 87.5000 (85.1361)  Acc@5: 100.0000 (98.2579)  time: 0.3502  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.7059  Acc@1: 87.5000 (85.1355)  Acc@5: 100.0000 (98.2514)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.7850  Acc@1: 87.5000 (85.1523)  Acc@5: 100.0000 (98.2479)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.2327  Acc@1: 87.5000 (85.1429)  Acc@5: 100.0000 (98.2502)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6847  Acc@1: 87.5000 (85.1393)  Acc@5: 100.0000 (98.2554)  time: 0.3511  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4480  Acc@1: 81.2500 (85.1215)  Acc@5: 100.0000 (98.2491)  time: 0.3518  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.8320  Acc@1: 87.5000 (85.1324)  Acc@5: 100.0000 (98.2542)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.5989  Acc@1: 87.5000 (85.1289)  Acc@5: 100.0000 (98.2480)  time: 0.3470  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.7917  Acc@1: 87.5000 (85.1368)  Acc@5: 100.0000 (98.2474)  time: 0.3476  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.4782  Acc@1: 87.5000 (85.1503)  Acc@5: 100.0000 (98.2468)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2757  Acc@1: 87.5000 (85.1580)  Acc@5: 100.0000 (98.2491)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.5306  Acc@1: 87.5000 (85.1489)  Acc@5: 100.0000 (98.2430)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.5239  Acc@1: 81.2500 (85.1483)  Acc@5: 100.0000 (98.2397)  time: 0.3501  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.3790  Acc@1: 87.5000 (85.1697)  Acc@5: 100.0000 (98.2419)  time: 0.3501  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.2153  Acc@1: 87.5000 (85.1717)  Acc@5: 100.0000 (98.2387)  time: 0.3495  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.4944  Acc@1: 87.5000 (85.1710)  Acc@5: 100.0000 (98.2409)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.6705  Acc@1: 81.2500 (85.1593)  Acc@5: 100.0000 (98.2431)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.5648  Acc@1: 81.2500 (85.1505)  Acc@5: 100.0000 (98.2399)  time: 0.3507  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.3946  Acc@1: 87.5000 (85.1606)  Acc@5: 100.0000 (98.2394)  time: 0.3544  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5704  Acc@1: 81.2500 (85.1276)  Acc@5: 100.0000 (98.2335)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.8000  Acc@1: 87.5000 (85.1459)  Acc@5: 100.0000 (98.2411)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.7803  Acc@1: 87.5000 (85.1613)  Acc@5: 100.0000 (98.2486)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6194  Acc@1: 87.5000 (85.1712)  Acc@5: 100.0000 (98.2481)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.7630  Acc@1: 87.5000 (85.1546)  Acc@5: 100.0000 (98.2423)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.4004  Acc@1: 81.2500 (85.1566)  Acc@5: 100.0000 (98.2444)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7245  Acc@1: 87.5000 (85.1690)  Acc@5: 100.0000 (98.2492)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.6093  Acc@1: 87.5000 (85.1762)  Acc@5: 100.0000 (98.2460)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.8158  Acc@1: 87.5000 (85.1728)  Acc@5: 100.0000 (98.2429)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.6755  Acc@1: 87.5000 (85.1695)  Acc@5: 100.0000 (98.2476)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5616  Acc@1: 87.5000 (85.1869)  Acc@5: 100.0000 (98.2497)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4112  Acc@1: 87.5000 (85.1836)  Acc@5: 100.0000 (98.2569)  time: 0.3472  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.1918  Acc@1: 87.5000 (85.1572)  Acc@5: 100.0000 (98.2589)  time: 0.3506  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.5282  Acc@1: 87.5000 (85.1668)  Acc@5: 100.0000 (98.2609)  time: 0.3507  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6821  Acc@1: 87.5000 (85.1432)  Acc@5: 100.0000 (98.2578)  time: 0.3510  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.2094  Acc@1: 81.2500 (85.1427)  Acc@5: 100.0000 (98.2598)  time: 0.3516  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.0342  Acc@1: 87.5000 (85.1446)  Acc@5: 100.0000 (98.2542)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.4474  Acc@1: 87.5000 (85.1541)  Acc@5: 100.0000 (98.2512)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.3809  Acc@1: 87.5000 (85.1609)  Acc@5: 100.0000 (98.2507)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.5291  Acc@1: 87.5000 (85.1603)  Acc@5: 100.0000 (98.2502)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6609  Acc@1: 81.2500 (85.1572)  Acc@5: 100.0000 (98.2571)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.3358  Acc@1: 81.2500 (85.1738)  Acc@5: 100.0000 (98.2591)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.6015  Acc@1: 87.5000 (85.1756)  Acc@5: 100.0000 (98.2536)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.2774  Acc@1: 87.5000 (85.1847)  Acc@5: 100.0000 (98.2531)  time: 0.3470  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.9028  Acc@1: 87.5000 (85.2060)  Acc@5: 100.0000 (98.2575)  time: 0.3468  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.6482  Acc@1: 87.5000 (85.2125)  Acc@5: 100.0000 (98.2570)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6266  Acc@1: 87.5000 (85.2359)  Acc@5: 100.0000 (98.2589)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.2550  Acc@1: 87.5000 (85.2349)  Acc@5: 100.0000 (98.2536)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.7546  Acc@1: 87.5000 (85.2485)  Acc@5: 100.0000 (98.2507)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.5811  Acc@1: 87.5000 (85.2595)  Acc@5: 100.0000 (98.2526)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7745  Acc@1: 87.5000 (85.2490)  Acc@5: 100.0000 (98.2449)  time: 0.3454  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.5559  Acc@1: 81.2500 (85.2480)  Acc@5: 100.0000 (98.2469)  time: 0.3454  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.9277  Acc@1: 87.5000 (85.2518)  Acc@5: 100.0000 (98.2393)  time: 0.3456  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.1659  Acc@1: 81.2500 (85.2367)  Acc@5: 93.7500 (98.2294)  time: 0.3463  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.9176  Acc@1: 81.2500 (85.2523)  Acc@5: 100.0000 (98.2290)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.2183  Acc@1: 87.5000 (85.2490)  Acc@5: 100.0000 (98.2263)  time: 0.3489  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6103  Acc@1: 87.5000 (85.2667)  Acc@5: 100.0000 (98.2236)  time: 0.3483  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.3392  Acc@1: 87.5000 (85.2564)  Acc@5: 100.0000 (98.2209)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.3562  Acc@1: 81.2500 (85.2508)  Acc@5: 100.0000 (98.2252)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.3567  Acc@1: 81.2500 (85.2568)  Acc@5: 100.0000 (98.2225)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.7477  Acc@1: 87.5000 (85.2766)  Acc@5: 100.0000 (98.2222)  time: 0.3492  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.7790  Acc@1: 93.7500 (85.2916)  Acc@5: 100.0000 (98.2195)  time: 0.3517  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5542  Acc@1: 81.2500 (85.2631)  Acc@5: 100.0000 (98.2237)  time: 0.3518  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.0851  Acc@1: 81.2500 (85.2599)  Acc@5: 100.0000 (98.2211)  time: 0.3495  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.3103  Acc@1: 81.2500 (85.2567)  Acc@5: 100.0000 (98.2162)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.8944  Acc@1: 87.5000 (85.2671)  Acc@5: 100.0000 (98.2159)  time: 0.3514  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4048  Acc@1: 87.5000 (85.2908)  Acc@5: 100.0000 (98.2156)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2790/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.4689  Acc@1: 87.5000 (85.2763)  Acc@5: 100.0000 (98.2130)  time: 0.3546  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4940  Acc@1: 81.2500 (85.2820)  Acc@5: 100.0000 (98.2127)  time: 0.3555  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7502  Acc@1: 87.5000 (85.2810)  Acc@5: 100.0000 (98.2146)  time: 0.3506  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.8592  Acc@1: 87.5000 (85.2911)  Acc@5: 100.0000 (98.2209)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.8534  Acc@1: 81.2500 (85.2835)  Acc@5: 100.0000 (98.2206)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.8608  Acc@1: 81.2500 (85.2935)  Acc@5: 100.0000 (98.2269)  time: 0.3480  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.2921  Acc@1: 87.5000 (85.2946)  Acc@5: 100.0000 (98.2265)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.2355  Acc@1: 87.5000 (85.2936)  Acc@5: 100.0000 (98.2305)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.4198  Acc@1: 81.2500 (85.2752)  Acc@5: 100.0000 (98.2280)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.0306  Acc@1: 81.2500 (85.2699)  Acc@5: 100.0000 (98.2320)  time: 0.3505  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.3533  Acc@1: 87.5000 (85.2733)  Acc@5: 100.0000 (98.2294)  time: 0.3499  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4154  Acc@1: 81.2500 (85.2702)  Acc@5: 100.0000 (98.2291)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.9070  Acc@1: 87.5000 (85.2843)  Acc@5: 100.0000 (98.2308)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7294  Acc@1: 87.5000 (85.2876)  Acc@5: 100.0000 (98.2305)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.2951  Acc@1: 81.2500 (85.2781)  Acc@5: 100.0000 (98.2301)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: 0.0039  Acc@1: 81.2500 (85.2814)  Acc@5: 100.0000 (98.2319)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.5561  Acc@1: 87.5000 (85.2889)  Acc@5: 100.0000 (98.2273)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4345  Acc@1: 87.5000 (85.2900)  Acc@5: 100.0000 (98.2270)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.4416  Acc@1: 87.5000 (85.2933)  Acc@5: 100.0000 (98.2224)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.1721  Acc@1: 87.5000 (85.2944)  Acc@5: 100.0000 (98.2221)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6246  Acc@1: 87.5000 (85.2934)  Acc@5: 100.0000 (98.2197)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.4085  Acc@1: 87.5000 (85.3007)  Acc@5: 100.0000 (98.2214)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4640  Acc@1: 81.2500 (85.2956)  Acc@5: 100.0000 (98.2170)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.3568  Acc@1: 81.2500 (85.3029)  Acc@5: 100.0000 (98.2167)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7699  Acc@1: 81.2500 (85.2916)  Acc@5: 100.0000 (98.2143)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: 0.0139  Acc@1: 81.2500 (85.2906)  Acc@5: 100.0000 (98.2181)  time: 0.3472  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6789  Acc@1: 87.5000 (85.2938)  Acc@5: 100.0000 (98.2178)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.8456  Acc@1: 87.5000 (85.2908)  Acc@5: 100.0000 (98.2155)  time: 0.3526  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.3269  Acc@1: 81.2500 (85.2776)  Acc@5: 100.0000 (98.2172)  time: 0.3539  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.5244  Acc@1: 81.2500 (85.2808)  Acc@5: 100.0000 (98.2128)  time: 0.3530  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.3524  Acc@1: 87.5000 (85.2697)  Acc@5: 100.0000 (98.2126)  time: 0.3521  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.6047  Acc@1: 81.2500 (85.2648)  Acc@5: 100.0000 (98.2143)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5406  Acc@1: 81.2500 (85.2660)  Acc@5: 100.0000 (98.2180)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.4054  Acc@1: 81.2500 (85.2611)  Acc@5: 100.0000 (98.2237)  time: 0.3518  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5139  Acc@1: 81.2500 (85.2500)  Acc@5: 100.0000 (98.2220)  time: 0.3514  data: 0.0017  max mem: 2502
Train: Epoch[2/5] Total time: 0:18:11 (0.3494 s / it)
{0: {0: 0, 1: 0, 2: 99872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 99888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 99936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.5139  Acc@1: 81.2500 (85.2500)  Acc@5: 100.0000 (98.2220)
Train: Epoch[3/5]  [   0/3125]  eta: 0:40:47  Lr: 0.001875  Loss: -0.6613  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7832  data: 0.4340  max mem: 2502
Train: Epoch[3/5]  [  10/3125]  eta: 0:20:12  Lr: 0.001875  Loss: -0.5304  Acc@1: 81.2500 (84.6591)  Acc@5: 100.0000 (98.2955)  time: 0.3891  data: 0.0398  max mem: 2502
Train: Epoch[3/5]  [  20/3125]  eta: 0:19:08  Lr: 0.001875  Loss: -0.8090  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.2143)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  30/3125]  eta: 0:18:42  Lr: 0.001875  Loss: -0.6183  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (98.3871)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  40/3125]  eta: 0:18:27  Lr: 0.001875  Loss: -0.5778  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (98.4756)  time: 0.3475  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  50/3125]  eta: 0:18:17  Lr: 0.001875  Loss: -0.2463  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (98.5294)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  60/3125]  eta: 0:18:07  Lr: 0.001875  Loss: -0.6085  Acc@1: 87.5000 (86.6803)  Acc@5: 100.0000 (98.5656)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  70/3125]  eta: 0:17:59  Lr: 0.001875  Loss: -0.7206  Acc@1: 87.5000 (86.5317)  Acc@5: 100.0000 (98.5915)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  80/3125]  eta: 0:17:53  Lr: 0.001875  Loss: -0.0582  Acc@1: 87.5000 (86.5741)  Acc@5: 100.0000 (98.3796)  time: 0.3453  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [  90/3125]  eta: 0:17:47  Lr: 0.001875  Loss: -0.4024  Acc@1: 87.5000 (86.0577)  Acc@5: 100.0000 (98.4203)  time: 0.3459  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 100/3125]  eta: 0:17:42  Lr: 0.001875  Loss: -0.5609  Acc@1: 87.5000 (86.3243)  Acc@5: 100.0000 (98.4530)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 110/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.4757  Acc@1: 87.5000 (86.0360)  Acc@5: 100.0000 (98.4797)  time: 0.3472  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 120/3125]  eta: 0:17:34  Lr: 0.001875  Loss: -0.6300  Acc@1: 87.5000 (86.0021)  Acc@5: 100.0000 (98.2955)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 130/3125]  eta: 0:17:30  Lr: 0.001875  Loss: -0.7626  Acc@1: 87.5000 (86.2118)  Acc@5: 100.0000 (98.2824)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 140/3125]  eta: 0:17:26  Lr: 0.001875  Loss: -0.9239  Acc@1: 87.5000 (86.3032)  Acc@5: 100.0000 (98.3156)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 150/3125]  eta: 0:17:22  Lr: 0.001875  Loss: -0.4720  Acc@1: 87.5000 (86.0927)  Acc@5: 100.0000 (98.4272)  time: 0.3497  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 160/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6239  Acc@1: 87.5000 (86.3354)  Acc@5: 100.0000 (98.4084)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 170/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.8645  Acc@1: 87.5000 (86.4401)  Acc@5: 100.0000 (98.4284)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 180/3125]  eta: 0:17:12  Lr: 0.001875  Loss: -0.6056  Acc@1: 87.5000 (86.5677)  Acc@5: 100.0000 (98.4807)  time: 0.3513  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 190/3125]  eta: 0:17:09  Lr: 0.001875  Loss: -0.7914  Acc@1: 87.5000 (86.7147)  Acc@5: 100.0000 (98.4620)  time: 0.3538  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 200/3125]  eta: 0:17:06  Lr: 0.001875  Loss: -0.6024  Acc@1: 87.5000 (86.8470)  Acc@5: 100.0000 (98.5075)  time: 0.3530  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 210/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.4899  Acc@1: 87.5000 (86.9076)  Acc@5: 100.0000 (98.5190)  time: 0.3561  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 220/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.3465  Acc@1: 87.5000 (86.8778)  Acc@5: 100.0000 (98.5577)  time: 0.3536  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 230/3125]  eta: 0:16:56  Lr: 0.001875  Loss: -0.4955  Acc@1: 81.2500 (86.7695)  Acc@5: 100.0000 (98.5660)  time: 0.3489  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 240/3125]  eta: 0:16:52  Lr: 0.001875  Loss: -0.7765  Acc@1: 81.2500 (86.7479)  Acc@5: 100.0000 (98.4959)  time: 0.3514  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [ 250/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.3311  Acc@1: 87.5000 (86.8277)  Acc@5: 100.0000 (98.4811)  time: 0.3504  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 260/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.1005  Acc@1: 87.5000 (86.7337)  Acc@5: 100.0000 (98.4674)  time: 0.3494  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 270/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.4174  Acc@1: 81.2500 (86.6928)  Acc@5: 100.0000 (98.4317)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 280/3125]  eta: 0:16:38  Lr: 0.001875  Loss: -0.3965  Acc@1: 87.5000 (86.7215)  Acc@5: 100.0000 (98.4431)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 290/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.4062  Acc@1: 81.2500 (86.5550)  Acc@5: 100.0000 (98.4536)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 300/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.5771  Acc@1: 81.2500 (86.4826)  Acc@5: 100.0000 (98.4219)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 310/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.3979  Acc@1: 87.5000 (86.5153)  Acc@5: 100.0000 (98.4526)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 320/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.5091  Acc@1: 87.5000 (86.4681)  Acc@5: 100.0000 (98.4424)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 330/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.5126  Acc@1: 87.5000 (86.5559)  Acc@5: 100.0000 (98.4517)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 340/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.4666  Acc@1: 87.5000 (86.4553)  Acc@5: 100.0000 (98.4787)  time: 0.3472  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 350/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3162  Acc@1: 81.2500 (86.3426)  Acc@5: 100.0000 (98.4687)  time: 0.3469  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 360/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.4822  Acc@1: 81.2500 (86.2708)  Acc@5: 100.0000 (98.4418)  time: 0.3468  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 370/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.1816  Acc@1: 87.5000 (86.4218)  Acc@5: 100.0000 (98.4333)  time: 0.3471  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 380/3125]  eta: 0:16:00  Lr: 0.001875  Loss: -0.7961  Acc@1: 87.5000 (86.4337)  Acc@5: 100.0000 (98.4580)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 390/3125]  eta: 0:15:56  Lr: 0.001875  Loss: -0.4500  Acc@1: 87.5000 (86.4450)  Acc@5: 100.0000 (98.4815)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 400/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.3717  Acc@1: 81.2500 (86.3155)  Acc@5: 100.0000 (98.4414)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 410/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.6779  Acc@1: 81.2500 (86.2682)  Acc@5: 100.0000 (98.4489)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 420/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.3744  Acc@1: 87.5000 (86.2975)  Acc@5: 100.0000 (98.4857)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 430/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.5356  Acc@1: 87.5000 (86.2819)  Acc@5: 100.0000 (98.4774)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 440/3125]  eta: 0:15:37  Lr: 0.001875  Loss: -0.5563  Acc@1: 87.5000 (86.2954)  Acc@5: 100.0000 (98.4836)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 450/3125]  eta: 0:15:33  Lr: 0.001875  Loss: -0.3733  Acc@1: 81.2500 (86.2528)  Acc@5: 100.0000 (98.4895)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 460/3125]  eta: 0:15:30  Lr: 0.001875  Loss: -0.8163  Acc@1: 87.5000 (86.3476)  Acc@5: 100.0000 (98.5087)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 470/3125]  eta: 0:15:26  Lr: 0.001875  Loss: -0.6914  Acc@1: 93.7500 (86.4252)  Acc@5: 100.0000 (98.5271)  time: 0.3465  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 480/3125]  eta: 0:15:23  Lr: 0.001875  Loss: -0.1878  Acc@1: 87.5000 (86.4345)  Acc@5: 100.0000 (98.5187)  time: 0.3499  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 490/3125]  eta: 0:15:19  Lr: 0.001875  Loss: -0.4711  Acc@1: 87.5000 (86.4562)  Acc@5: 100.0000 (98.5489)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 500/3125]  eta: 0:15:16  Lr: 0.001875  Loss: -0.6479  Acc@1: 87.5000 (86.5020)  Acc@5: 100.0000 (98.5404)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 510/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.5943  Acc@1: 87.5000 (86.5460)  Acc@5: 100.0000 (98.5323)  time: 0.3527  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 520/3125]  eta: 0:15:09  Lr: 0.001875  Loss: -0.5352  Acc@1: 87.5000 (86.5283)  Acc@5: 100.0000 (98.5365)  time: 0.3513  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 530/3125]  eta: 0:15:06  Lr: 0.001875  Loss: -0.1410  Acc@1: 87.5000 (86.4642)  Acc@5: 100.0000 (98.5169)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 540/3125]  eta: 0:15:02  Lr: 0.001875  Loss: -0.5240  Acc@1: 87.5000 (86.4140)  Acc@5: 100.0000 (98.4982)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 550/3125]  eta: 0:14:59  Lr: 0.001875  Loss: -0.5365  Acc@1: 81.2500 (86.3997)  Acc@5: 100.0000 (98.5254)  time: 0.3502  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 560/3125]  eta: 0:14:55  Lr: 0.001875  Loss: -0.3524  Acc@1: 81.2500 (86.2968)  Acc@5: 100.0000 (98.5071)  time: 0.3504  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 570/3125]  eta: 0:14:52  Lr: 0.001875  Loss: -0.4209  Acc@1: 81.2500 (86.3507)  Acc@5: 100.0000 (98.5114)  time: 0.3514  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 580/3125]  eta: 0:14:49  Lr: 0.001875  Loss: -0.7873  Acc@1: 87.5000 (86.3705)  Acc@5: 100.0000 (98.5370)  time: 0.3517  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 590/3125]  eta: 0:14:45  Lr: 0.001875  Loss: -0.7295  Acc@1: 87.5000 (86.3684)  Acc@5: 100.0000 (98.5300)  time: 0.3513  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 600/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.4999  Acc@1: 87.5000 (86.3873)  Acc@5: 100.0000 (98.5337)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 610/3125]  eta: 0:14:38  Lr: 0.001875  Loss: -0.8845  Acc@1: 87.5000 (86.4157)  Acc@5: 100.0000 (98.5475)  time: 0.3475  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 620/3125]  eta: 0:14:34  Lr: 0.001875  Loss: -0.7141  Acc@1: 87.5000 (86.4332)  Acc@5: 100.0000 (98.5407)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 630/3125]  eta: 0:14:31  Lr: 0.001875  Loss: -0.4313  Acc@1: 87.5000 (86.4204)  Acc@5: 100.0000 (98.5341)  time: 0.3483  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 640/3125]  eta: 0:14:28  Lr: 0.001875  Loss: 0.0512  Acc@1: 87.5000 (86.3690)  Acc@5: 100.0000 (98.5179)  time: 0.3518  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 650/3125]  eta: 0:14:24  Lr: 0.001875  Loss: -0.7746  Acc@1: 87.5000 (86.3575)  Acc@5: 100.0000 (98.5407)  time: 0.3532  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 660/3125]  eta: 0:14:21  Lr: 0.001875  Loss: -0.2722  Acc@1: 87.5000 (86.3181)  Acc@5: 100.0000 (98.5344)  time: 0.3514  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 670/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.7668  Acc@1: 87.5000 (86.3077)  Acc@5: 100.0000 (98.5190)  time: 0.3554  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 680/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.1771  Acc@1: 87.5000 (86.2702)  Acc@5: 100.0000 (98.5040)  time: 0.3535  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 690/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.6138  Acc@1: 87.5000 (86.2789)  Acc@5: 100.0000 (98.4986)  time: 0.3483  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 700/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.5405  Acc@1: 87.5000 (86.2964)  Acc@5: 100.0000 (98.5200)  time: 0.3484  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 710/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.3578  Acc@1: 87.5000 (86.3221)  Acc@5: 100.0000 (98.5232)  time: 0.3476  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 720/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.3913  Acc@1: 87.5000 (86.3471)  Acc@5: 100.0000 (98.5437)  time: 0.3478  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 730/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.8029  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (98.5380)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 740/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.5412  Acc@1: 87.5000 (86.4204)  Acc@5: 100.0000 (98.5493)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 750/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7575  Acc@1: 87.5000 (86.4680)  Acc@5: 100.0000 (98.5436)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 760/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.5203  Acc@1: 87.5000 (86.4241)  Acc@5: 100.0000 (98.5053)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 770/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.5951  Acc@1: 87.5000 (86.4381)  Acc@5: 100.0000 (98.5003)  time: 0.3511  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 780/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.3535  Acc@1: 87.5000 (86.4437)  Acc@5: 100.0000 (98.5035)  time: 0.3526  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 790/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.6561  Acc@1: 87.5000 (86.4649)  Acc@5: 100.0000 (98.5145)  time: 0.3507  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 800/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.8437  Acc@1: 87.5000 (86.4700)  Acc@5: 100.0000 (98.5019)  time: 0.3494  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 810/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.8151  Acc@1: 87.5000 (86.4673)  Acc@5: 100.0000 (98.5049)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 820/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.6071  Acc@1: 87.5000 (86.4875)  Acc@5: 100.0000 (98.5155)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 830/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.2824  Acc@1: 87.5000 (86.5072)  Acc@5: 100.0000 (98.5184)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 840/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.3926  Acc@1: 87.5000 (86.5339)  Acc@5: 100.0000 (98.5137)  time: 0.3511  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 850/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.4503  Acc@1: 87.5000 (86.5085)  Acc@5: 100.0000 (98.5238)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 860/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4172  Acc@1: 81.2500 (86.4837)  Acc@5: 100.0000 (98.5337)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 870/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.6528  Acc@1: 87.5000 (86.5026)  Acc@5: 100.0000 (98.5362)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 880/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.6991  Acc@1: 87.5000 (86.5281)  Acc@5: 100.0000 (98.5386)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 890/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.4162  Acc@1: 87.5000 (86.5320)  Acc@5: 100.0000 (98.5410)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 900/3125]  eta: 0:12:57  Lr: 0.001875  Loss: -0.3281  Acc@1: 87.5000 (86.5427)  Acc@5: 100.0000 (98.5433)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 910/3125]  eta: 0:12:53  Lr: 0.001875  Loss: -0.5119  Acc@1: 87.5000 (86.5875)  Acc@5: 100.0000 (98.5387)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 920/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.0452  Acc@1: 87.5000 (86.5839)  Acc@5: 100.0000 (98.5206)  time: 0.3470  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 930/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.8285  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.5097)  time: 0.3453  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 940/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.2727  Acc@1: 87.5000 (86.5635)  Acc@5: 100.0000 (98.4989)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 950/3125]  eta: 0:12:39  Lr: 0.001875  Loss: -0.6696  Acc@1: 81.2500 (86.5405)  Acc@5: 100.0000 (98.4950)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 960/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.2533  Acc@1: 87.5000 (86.5114)  Acc@5: 100.0000 (98.4912)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 970/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.7218  Acc@1: 87.5000 (86.5667)  Acc@5: 100.0000 (98.5003)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 980/3125]  eta: 0:12:28  Lr: 0.001875  Loss: -0.3725  Acc@1: 87.5000 (86.5380)  Acc@5: 100.0000 (98.4901)  time: 0.3450  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 990/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.9302  Acc@1: 87.5000 (86.5161)  Acc@5: 100.0000 (98.4927)  time: 0.3452  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1000/3125]  eta: 0:12:21  Lr: 0.001875  Loss: -0.4907  Acc@1: 87.5000 (86.5322)  Acc@5: 100.0000 (98.5015)  time: 0.3460  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1010/3125]  eta: 0:12:18  Lr: 0.001875  Loss: -0.0185  Acc@1: 87.5000 (86.4985)  Acc@5: 100.0000 (98.4978)  time: 0.3483  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1020/3125]  eta: 0:12:14  Lr: 0.001875  Loss: -0.2699  Acc@1: 81.2500 (86.4226)  Acc@5: 100.0000 (98.4880)  time: 0.3507  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [1030/3125]  eta: 0:12:11  Lr: 0.001875  Loss: -0.3232  Acc@1: 81.2500 (86.4452)  Acc@5: 100.0000 (98.4845)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1040/3125]  eta: 0:12:07  Lr: 0.001875  Loss: -0.5557  Acc@1: 87.5000 (86.4313)  Acc@5: 100.0000 (98.4990)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1050/3125]  eta: 0:12:04  Lr: 0.001875  Loss: -0.4900  Acc@1: 87.5000 (86.4474)  Acc@5: 100.0000 (98.4955)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1060/3125]  eta: 0:12:00  Lr: 0.001875  Loss: -0.4618  Acc@1: 87.5000 (86.4574)  Acc@5: 100.0000 (98.5038)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1070/3125]  eta: 0:11:57  Lr: 0.001875  Loss: -0.5213  Acc@1: 87.5000 (86.4496)  Acc@5: 100.0000 (98.5119)  time: 0.3518  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1080/3125]  eta: 0:11:53  Lr: 0.001875  Loss: -0.2588  Acc@1: 87.5000 (86.4709)  Acc@5: 100.0000 (98.5083)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1090/3125]  eta: 0:11:50  Lr: 0.001875  Loss: -0.5151  Acc@1: 87.5000 (86.4746)  Acc@5: 100.0000 (98.5105)  time: 0.3487  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1100/3125]  eta: 0:11:46  Lr: 0.001875  Loss: -0.7238  Acc@1: 87.5000 (86.4839)  Acc@5: 100.0000 (98.5070)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1110/3125]  eta: 0:11:43  Lr: 0.001875  Loss: -0.8279  Acc@1: 87.5000 (86.4649)  Acc@5: 100.0000 (98.5149)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1120/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.4104  Acc@1: 87.5000 (86.4574)  Acc@5: 100.0000 (98.5169)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1130/3125]  eta: 0:11:36  Lr: 0.001875  Loss: -0.3132  Acc@1: 87.5000 (86.4777)  Acc@5: 100.0000 (98.5245)  time: 0.3518  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1140/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.0149  Acc@1: 87.5000 (86.4483)  Acc@5: 100.0000 (98.5156)  time: 0.3520  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1150/3125]  eta: 0:11:29  Lr: 0.001875  Loss: -0.7673  Acc@1: 87.5000 (86.4140)  Acc@5: 100.0000 (98.5013)  time: 0.3556  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [1160/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.2589  Acc@1: 87.5000 (86.3910)  Acc@5: 100.0000 (98.5034)  time: 0.3552  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [1170/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.4422  Acc@1: 87.5000 (86.3845)  Acc@5: 100.0000 (98.5056)  time: 0.3498  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [1180/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.7238  Acc@1: 87.5000 (86.3992)  Acc@5: 100.0000 (98.5076)  time: 0.3507  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [1190/3125]  eta: 0:11:15  Lr: 0.001875  Loss: -0.6777  Acc@1: 87.5000 (86.4242)  Acc@5: 100.0000 (98.5097)  time: 0.3513  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [1200/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.6893  Acc@1: 87.5000 (86.4020)  Acc@5: 100.0000 (98.5065)  time: 0.3510  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.7427  Acc@1: 81.2500 (86.3130)  Acc@5: 100.0000 (98.4878)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1220/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.2994  Acc@1: 81.2500 (86.2971)  Acc@5: 100.0000 (98.5002)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1230/3125]  eta: 0:11:01  Lr: 0.001875  Loss: -0.7281  Acc@1: 87.5000 (86.3424)  Acc@5: 100.0000 (98.5124)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1240/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.6900  Acc@1: 87.5000 (86.3165)  Acc@5: 100.0000 (98.5093)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.6671  Acc@1: 87.5000 (86.3259)  Acc@5: 100.0000 (98.5162)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1260/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.4592  Acc@1: 87.5000 (86.3600)  Acc@5: 100.0000 (98.5180)  time: 0.3497  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.4592  Acc@1: 87.5000 (86.3739)  Acc@5: 100.0000 (98.5100)  time: 0.3546  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1280/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.2616  Acc@1: 87.5000 (86.3534)  Acc@5: 100.0000 (98.4973)  time: 0.3542  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.6630  Acc@1: 87.5000 (86.3817)  Acc@5: 100.0000 (98.4992)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1300/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.4112  Acc@1: 87.5000 (86.3566)  Acc@5: 100.0000 (98.4963)  time: 0.3488  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.6065  Acc@1: 81.2500 (86.3272)  Acc@5: 100.0000 (98.5031)  time: 0.3475  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [1320/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.1076  Acc@1: 87.5000 (86.3219)  Acc@5: 100.0000 (98.5097)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.6786  Acc@1: 81.2500 (86.2697)  Acc@5: 100.0000 (98.5115)  time: 0.3470  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1340/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.3239  Acc@1: 81.2500 (86.2789)  Acc@5: 100.0000 (98.4993)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.1222  Acc@1: 87.5000 (86.2694)  Acc@5: 100.0000 (98.5011)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1360/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.7182  Acc@1: 87.5000 (86.2922)  Acc@5: 100.0000 (98.5121)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1370/3125]  eta: 0:10:12  Lr: 0.001875  Loss: -0.2129  Acc@1: 87.5000 (86.2828)  Acc@5: 100.0000 (98.4956)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1380/3125]  eta: 0:10:09  Lr: 0.001875  Loss: 0.0147  Acc@1: 87.5000 (86.2735)  Acc@5: 100.0000 (98.5020)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1390/3125]  eta: 0:10:05  Lr: 0.001875  Loss: -0.1101  Acc@1: 87.5000 (86.2779)  Acc@5: 100.0000 (98.5083)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1400/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.1018  Acc@1: 87.5000 (86.2732)  Acc@5: 100.0000 (98.4921)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1410/3125]  eta: 0:09:58  Lr: 0.001875  Loss: -0.6094  Acc@1: 87.5000 (86.2553)  Acc@5: 100.0000 (98.4940)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.3615  Acc@1: 81.2500 (86.2509)  Acc@5: 100.0000 (98.4914)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1430/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.4520  Acc@1: 81.2500 (86.2028)  Acc@5: 100.0000 (98.4976)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7899  Acc@1: 81.2500 (86.1771)  Acc@5: 100.0000 (98.4906)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1450/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.2772  Acc@1: 81.2500 (86.1906)  Acc@5: 100.0000 (98.4967)  time: 0.3445  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.4415  Acc@1: 87.5000 (86.1952)  Acc@5: 100.0000 (98.4942)  time: 0.3469  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1470/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.6270  Acc@1: 87.5000 (86.1871)  Acc@5: 100.0000 (98.4917)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.3900  Acc@1: 87.5000 (86.1791)  Acc@5: 100.0000 (98.4976)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1490/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.5974  Acc@1: 81.2500 (86.1502)  Acc@5: 100.0000 (98.4951)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1500/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.3249  Acc@1: 81.2500 (86.1218)  Acc@5: 100.0000 (98.4843)  time: 0.3482  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1510/3125]  eta: 0:09:23  Lr: 0.001875  Loss: -0.3303  Acc@1: 81.2500 (86.1143)  Acc@5: 100.0000 (98.4778)  time: 0.3488  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1520/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.7937  Acc@1: 87.5000 (86.1275)  Acc@5: 100.0000 (98.4755)  time: 0.3499  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [1530/3125]  eta: 0:09:16  Lr: 0.001875  Loss: -0.3148  Acc@1: 87.5000 (86.1447)  Acc@5: 100.0000 (98.4773)  time: 0.3502  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1540/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.3768  Acc@1: 87.5000 (86.1697)  Acc@5: 100.0000 (98.4791)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1550/3125]  eta: 0:09:09  Lr: 0.001875  Loss: -0.7615  Acc@1: 87.5000 (86.1863)  Acc@5: 100.0000 (98.4848)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1560/3125]  eta: 0:09:06  Lr: 0.001875  Loss: 0.0053  Acc@1: 87.5000 (86.1587)  Acc@5: 100.0000 (98.4906)  time: 0.3518  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1570/3125]  eta: 0:09:02  Lr: 0.001875  Loss: -0.6388  Acc@1: 81.2500 (86.1513)  Acc@5: 100.0000 (98.4922)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1580/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.7784  Acc@1: 81.2500 (86.1361)  Acc@5: 100.0000 (98.4938)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1590/3125]  eta: 0:08:55  Lr: 0.001875  Loss: -0.4901  Acc@1: 81.2500 (86.1251)  Acc@5: 100.0000 (98.4994)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1600/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.4574  Acc@1: 87.5000 (86.1493)  Acc@5: 100.0000 (98.5009)  time: 0.3547  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1610/3125]  eta: 0:08:48  Lr: 0.001875  Loss: -0.6033  Acc@1: 87.5000 (86.1538)  Acc@5: 100.0000 (98.5025)  time: 0.3544  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1620/3125]  eta: 0:08:45  Lr: 0.001875  Loss: -0.8251  Acc@1: 87.5000 (86.1737)  Acc@5: 100.0000 (98.4886)  time: 0.3532  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.2558  Acc@1: 87.5000 (86.1703)  Acc@5: 93.7500 (98.4749)  time: 0.3548  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1640/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.4068  Acc@1: 81.2500 (86.1441)  Acc@5: 100.0000 (98.4803)  time: 0.3550  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.0878  Acc@1: 81.2500 (86.1220)  Acc@5: 100.0000 (98.4555)  time: 0.3554  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1660/3125]  eta: 0:08:31  Lr: 0.001875  Loss: -0.4176  Acc@1: 81.2500 (86.1228)  Acc@5: 100.0000 (98.4535)  time: 0.3519  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: 0.2826  Acc@1: 81.2500 (86.1086)  Acc@5: 100.0000 (98.4403)  time: 0.3496  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1680/3125]  eta: 0:08:24  Lr: 0.001875  Loss: -0.6599  Acc@1: 87.5000 (86.1169)  Acc@5: 100.0000 (98.4273)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.6288  Acc@1: 87.5000 (86.1177)  Acc@5: 100.0000 (98.4255)  time: 0.3496  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1700/3125]  eta: 0:08:17  Lr: 0.001875  Loss: -0.3652  Acc@1: 81.2500 (86.1221)  Acc@5: 100.0000 (98.4274)  time: 0.3493  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.4462  Acc@1: 81.2500 (86.1156)  Acc@5: 100.0000 (98.4256)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1720/3125]  eta: 0:08:10  Lr: 0.001875  Loss: -0.6192  Acc@1: 87.5000 (86.1381)  Acc@5: 100.0000 (98.4311)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.4625  Acc@1: 87.5000 (86.1352)  Acc@5: 100.0000 (98.4366)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1740/3125]  eta: 0:08:03  Lr: 0.001875  Loss: 0.1502  Acc@1: 87.5000 (86.1323)  Acc@5: 100.0000 (98.4348)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: 0.0007  Acc@1: 87.5000 (86.1365)  Acc@5: 100.0000 (98.4366)  time: 0.3492  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1760/3125]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7340  Acc@1: 87.5000 (86.1300)  Acc@5: 100.0000 (98.4348)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.5707  Acc@1: 87.5000 (86.1307)  Acc@5: 100.0000 (98.4366)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1780/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.3197  Acc@1: 87.5000 (86.1349)  Acc@5: 100.0000 (98.4278)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5234  Acc@1: 87.5000 (86.1495)  Acc@5: 100.0000 (98.4366)  time: 0.3509  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1800/3125]  eta: 0:07:42  Lr: 0.001875  Loss: -0.7492  Acc@1: 87.5000 (86.1605)  Acc@5: 100.0000 (98.4349)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.2442  Acc@1: 87.5000 (86.1575)  Acc@5: 100.0000 (98.4332)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1820/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.4693  Acc@1: 81.2500 (86.1443)  Acc@5: 100.0000 (98.4246)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.3260  Acc@1: 87.5000 (86.1483)  Acc@5: 100.0000 (98.4298)  time: 0.3543  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1840/3125]  eta: 0:07:28  Lr: 0.001875  Loss: -0.8238  Acc@1: 87.5000 (86.1454)  Acc@5: 100.0000 (98.4282)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.6196  Acc@1: 81.2500 (86.1325)  Acc@5: 100.0000 (98.4299)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1860/3125]  eta: 0:07:21  Lr: 0.001875  Loss: -0.2481  Acc@1: 81.2500 (86.1264)  Acc@5: 100.0000 (98.4283)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.6485  Acc@1: 87.5000 (86.1304)  Acc@5: 100.0000 (98.4300)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1880/3125]  eta: 0:07:14  Lr: 0.001875  Loss: -0.8579  Acc@1: 87.5000 (86.1543)  Acc@5: 100.0000 (98.4350)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.1326  Acc@1: 87.5000 (86.1416)  Acc@5: 100.0000 (98.4235)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:07  Lr: 0.001875  Loss: -0.7337  Acc@1: 87.5000 (86.1389)  Acc@5: 100.0000 (98.4252)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.6992  Acc@1: 87.5000 (86.1362)  Acc@5: 100.0000 (98.4269)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1920/3125]  eta: 0:07:00  Lr: 0.001875  Loss: -0.8302  Acc@1: 87.5000 (86.1596)  Acc@5: 100.0000 (98.4253)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.3953  Acc@1: 87.5000 (86.1600)  Acc@5: 100.0000 (98.4237)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1940/3125]  eta: 0:06:53  Lr: 0.001875  Loss: -0.5490  Acc@1: 87.5000 (86.1508)  Acc@5: 100.0000 (98.4254)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.7569  Acc@1: 87.5000 (86.1609)  Acc@5: 100.0000 (98.4239)  time: 0.3457  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1960/3125]  eta: 0:06:46  Lr: 0.001875  Loss: -0.4390  Acc@1: 87.5000 (86.1550)  Acc@5: 100.0000 (98.4224)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.7000  Acc@1: 87.5000 (86.1618)  Acc@5: 100.0000 (98.4272)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1980/3125]  eta: 0:06:39  Lr: 0.001875  Loss: -0.6205  Acc@1: 87.5000 (86.1623)  Acc@5: 100.0000 (98.4320)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.5487  Acc@1: 87.5000 (86.1408)  Acc@5: 100.0000 (98.4367)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2000/3125]  eta: 0:06:32  Lr: 0.001875  Loss: -0.7147  Acc@1: 81.2500 (86.1351)  Acc@5: 100.0000 (98.4383)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.6939  Acc@1: 81.2500 (86.1263)  Acc@5: 100.0000 (98.4336)  time: 0.3503  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [2020/3125]  eta: 0:06:25  Lr: 0.001875  Loss: -0.7031  Acc@1: 87.5000 (86.1517)  Acc@5: 100.0000 (98.4290)  time: 0.3494  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.3966  Acc@1: 87.5000 (86.1491)  Acc@5: 100.0000 (98.4244)  time: 0.3478  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2040/3125]  eta: 0:06:18  Lr: 0.001875  Loss: -0.3353  Acc@1: 81.2500 (86.1434)  Acc@5: 100.0000 (98.4291)  time: 0.3487  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.7126  Acc@1: 81.2500 (86.1470)  Acc@5: 100.0000 (98.4367)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:11  Lr: 0.001875  Loss: -0.6194  Acc@1: 87.5000 (86.1445)  Acc@5: 100.0000 (98.4352)  time: 0.3493  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.3782  Acc@1: 81.2500 (86.1389)  Acc@5: 100.0000 (98.4398)  time: 0.3482  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2080/3125]  eta: 0:06:04  Lr: 0.001875  Loss: -0.5718  Acc@1: 81.2500 (86.1305)  Acc@5: 100.0000 (98.4322)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6754  Acc@1: 87.5000 (86.1549)  Acc@5: 100.0000 (98.4338)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2100/3125]  eta: 0:05:57  Lr: 0.001875  Loss: -0.7166  Acc@1: 87.5000 (86.1554)  Acc@5: 100.0000 (98.4353)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.2351  Acc@1: 87.5000 (86.1588)  Acc@5: 100.0000 (98.4368)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2120/3125]  eta: 0:05:50  Lr: 0.001875  Loss: -0.2762  Acc@1: 81.2500 (86.1445)  Acc@5: 100.0000 (98.4412)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.5572  Acc@1: 87.5000 (86.1421)  Acc@5: 100.0000 (98.4456)  time: 0.3523  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.1172  Acc@1: 87.5000 (86.1484)  Acc@5: 100.0000 (98.4528)  time: 0.3543  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.6536  Acc@1: 87.5000 (86.1373)  Acc@5: 100.0000 (98.4513)  time: 0.3564  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6116  Acc@1: 87.5000 (86.1638)  Acc@5: 100.0000 (98.4469)  time: 0.3538  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.5254  Acc@1: 87.5000 (86.1700)  Acc@5: 100.0000 (98.4454)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.6229  Acc@1: 87.5000 (86.1933)  Acc@5: 100.0000 (98.4468)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.4816  Acc@1: 87.5000 (86.1935)  Acc@5: 100.0000 (98.4453)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4970  Acc@1: 87.5000 (86.1938)  Acc@5: 100.0000 (98.4467)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.0580  Acc@1: 87.5000 (86.2025)  Acc@5: 100.0000 (98.4424)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.5652  Acc@1: 81.2500 (86.1830)  Acc@5: 100.0000 (98.4354)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.3392  Acc@1: 81.2500 (86.1693)  Acc@5: 100.0000 (98.4340)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.6730  Acc@1: 87.5000 (86.1780)  Acc@5: 100.0000 (98.4326)  time: 0.3505  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.7209  Acc@1: 87.5000 (86.1728)  Acc@5: 100.0000 (98.4340)  time: 0.3509  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.2602  Acc@1: 87.5000 (86.1566)  Acc@5: 100.0000 (98.4327)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: 0.0086  Acc@1: 81.2500 (86.1405)  Acc@5: 100.0000 (98.4368)  time: 0.3505  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6440  Acc@1: 87.5000 (86.1546)  Acc@5: 100.0000 (98.4382)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.6351  Acc@1: 87.5000 (86.1687)  Acc@5: 100.0000 (98.4450)  time: 0.3513  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4566  Acc@1: 87.5000 (86.1745)  Acc@5: 100.0000 (98.4355)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.7107  Acc@1: 87.5000 (86.1748)  Acc@5: 100.0000 (98.4395)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.7666  Acc@1: 87.5000 (86.1644)  Acc@5: 100.0000 (98.4382)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.5591  Acc@1: 87.5000 (86.1594)  Acc@5: 100.0000 (98.4368)  time: 0.3471  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.6663  Acc@1: 87.5000 (86.1544)  Acc@5: 100.0000 (98.4382)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.4397  Acc@1: 81.2500 (86.1442)  Acc@5: 100.0000 (98.4395)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5472  Acc@1: 87.5000 (86.1526)  Acc@5: 100.0000 (98.4435)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.3367  Acc@1: 87.5000 (86.1477)  Acc@5: 100.0000 (98.4474)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7424  Acc@1: 87.5000 (86.1560)  Acc@5: 100.0000 (98.4513)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.6081  Acc@1: 87.5000 (86.1512)  Acc@5: 100.0000 (98.4447)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3351  Acc@1: 81.2500 (86.1334)  Acc@5: 100.0000 (98.4434)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.3917  Acc@1: 81.2500 (86.1079)  Acc@5: 100.0000 (98.4343)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.4675  Acc@1: 81.2500 (86.1137)  Acc@5: 100.0000 (98.4407)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.5657  Acc@1: 87.5000 (86.1091)  Acc@5: 100.0000 (98.4369)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4798  Acc@1: 87.5000 (86.1097)  Acc@5: 100.0000 (98.4356)  time: 0.3479  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.8618  Acc@1: 87.5000 (86.1001)  Acc@5: 100.0000 (98.4343)  time: 0.3482  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.2827  Acc@1: 87.5000 (86.1032)  Acc@5: 100.0000 (98.4381)  time: 0.3475  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.6002  Acc@1: 87.5000 (86.1038)  Acc@5: 100.0000 (98.4419)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7479  Acc@1: 87.5000 (86.1044)  Acc@5: 100.0000 (98.4406)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6725  Acc@1: 81.2500 (86.0924)  Acc@5: 100.0000 (98.4469)  time: 0.3562  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6179  Acc@1: 81.2500 (86.0906)  Acc@5: 100.0000 (98.4481)  time: 0.3555  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.7116  Acc@1: 87.5000 (86.1012)  Acc@5: 100.0000 (98.4493)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6732  Acc@1: 93.7500 (86.1241)  Acc@5: 100.0000 (98.4530)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.4774  Acc@1: 93.7500 (86.1270)  Acc@5: 100.0000 (98.4542)  time: 0.3481  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.6389  Acc@1: 87.5000 (86.1177)  Acc@5: 100.0000 (98.4603)  time: 0.3486  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.5111  Acc@1: 87.5000 (86.0961)  Acc@5: 100.0000 (98.4516)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.2849  Acc@1: 87.5000 (86.1016)  Acc@5: 100.0000 (98.4552)  time: 0.3504  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.6640  Acc@1: 87.5000 (86.0900)  Acc@5: 100.0000 (98.4418)  time: 0.3501  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6835  Acc@1: 87.5000 (86.0979)  Acc@5: 100.0000 (98.4454)  time: 0.3504  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.5141  Acc@1: 87.5000 (86.1130)  Acc@5: 100.0000 (98.4441)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.1449  Acc@1: 87.5000 (86.1039)  Acc@5: 100.0000 (98.4381)  time: 0.3549  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.7960  Acc@1: 87.5000 (86.1021)  Acc@5: 100.0000 (98.4417)  time: 0.3544  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.6706  Acc@1: 87.5000 (86.1050)  Acc@5: 100.0000 (98.4429)  time: 0.3463  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.3657  Acc@1: 87.5000 (86.1269)  Acc@5: 100.0000 (98.4440)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.4805  Acc@1: 87.5000 (86.1227)  Acc@5: 100.0000 (98.4428)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.4909  Acc@1: 81.2500 (86.1090)  Acc@5: 100.0000 (98.4393)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.5196  Acc@1: 87.5000 (86.1283)  Acc@5: 100.0000 (98.4381)  time: 0.3470  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.7504  Acc@1: 87.5000 (86.1382)  Acc@5: 100.0000 (98.4416)  time: 0.3468  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.1259  Acc@1: 87.5000 (86.1339)  Acc@5: 100.0000 (98.4404)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5142  Acc@1: 81.2500 (86.1367)  Acc@5: 100.0000 (98.4369)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.5900  Acc@1: 87.5000 (86.1371)  Acc@5: 100.0000 (98.4404)  time: 0.3455  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.6381  Acc@1: 87.5000 (86.1536)  Acc@5: 100.0000 (98.4415)  time: 0.3452  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.7618  Acc@1: 87.5000 (86.1471)  Acc@5: 100.0000 (98.4427)  time: 0.3458  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.7235  Acc@1: 87.5000 (86.1521)  Acc@5: 100.0000 (98.4438)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.7400  Acc@1: 87.5000 (86.1706)  Acc@5: 100.0000 (98.4426)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.9213  Acc@1: 93.7500 (86.1891)  Acc@5: 100.0000 (98.4437)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.7762  Acc@1: 87.5000 (86.1961)  Acc@5: 100.0000 (98.4426)  time: 0.3468  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.6367  Acc@1: 87.5000 (86.2099)  Acc@5: 100.0000 (98.4437)  time: 0.3466  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.5997  Acc@1: 87.5000 (86.2100)  Acc@5: 100.0000 (98.4471)  time: 0.3474  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2790/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.6886  Acc@1: 87.5000 (86.2325)  Acc@5: 100.0000 (98.4504)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.6459  Acc@1: 87.5000 (86.2393)  Acc@5: 100.0000 (98.4514)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2810/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6279  Acc@1: 81.2500 (86.2171)  Acc@5: 100.0000 (98.4481)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7234  Acc@1: 81.2500 (86.2261)  Acc@5: 100.0000 (98.4469)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:42  Lr: 0.001875  Loss: -0.6910  Acc@1: 81.2500 (86.2151)  Acc@5: 100.0000 (98.4436)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.3666  Acc@1: 81.2500 (86.2130)  Acc@5: 100.0000 (98.4446)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5069  Acc@1: 87.5000 (86.2197)  Acc@5: 100.0000 (98.4435)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.2248  Acc@1: 87.5000 (86.2199)  Acc@5: 100.0000 (98.4446)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.8006  Acc@1: 81.2500 (86.2200)  Acc@5: 100.0000 (98.4413)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1588  Acc@1: 81.2500 (86.2027)  Acc@5: 100.0000 (98.4402)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.8575  Acc@1: 81.2500 (86.2094)  Acc@5: 100.0000 (98.4413)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.6604  Acc@1: 87.5000 (86.2203)  Acc@5: 100.0000 (98.4423)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.6810  Acc@1: 87.5000 (86.2204)  Acc@5: 100.0000 (98.4413)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.1790  Acc@1: 87.5000 (86.2076)  Acc@5: 100.0000 (98.4380)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.6697  Acc@1: 81.2500 (86.2035)  Acc@5: 100.0000 (98.4412)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5701  Acc@1: 81.2500 (86.1994)  Acc@5: 100.0000 (98.4380)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.4068  Acc@1: 81.2500 (86.1784)  Acc@5: 100.0000 (98.4327)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4893  Acc@1: 81.2500 (86.1744)  Acc@5: 100.0000 (98.4296)  time: 0.3481  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7000  Acc@1: 87.5000 (86.1768)  Acc@5: 100.0000 (98.4286)  time: 0.3468  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.2948  Acc@1: 87.5000 (86.1791)  Acc@5: 100.0000 (98.4275)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5004  Acc@1: 87.5000 (86.1794)  Acc@5: 100.0000 (98.4286)  time: 0.3465  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5795  Acc@1: 81.2500 (86.1567)  Acc@5: 100.0000 (98.4318)  time: 0.3461  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.2725  Acc@1: 81.2500 (86.1508)  Acc@5: 100.0000 (98.4370)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.7003  Acc@1: 87.5000 (86.1532)  Acc@5: 100.0000 (98.4380)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.4696  Acc@1: 87.5000 (86.1576)  Acc@5: 100.0000 (98.4370)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.6404  Acc@1: 87.5000 (86.1538)  Acc@5: 100.0000 (98.4401)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5578  Acc@1: 81.2500 (86.1439)  Acc@5: 100.0000 (98.4411)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.4285  Acc@1: 87.5000 (86.1606)  Acc@5: 100.0000 (98.4421)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.5285  Acc@1: 93.7500 (86.1710)  Acc@5: 100.0000 (98.4472)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.5649  Acc@1: 87.5000 (86.1672)  Acc@5: 100.0000 (98.4522)  time: 0.3509  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.6480  Acc@1: 87.5000 (86.1796)  Acc@5: 100.0000 (98.4552)  time: 0.3489  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.7106  Acc@1: 93.7500 (86.1940)  Acc@5: 100.0000 (98.4582)  time: 0.3490  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.7845  Acc@1: 93.7500 (86.1962)  Acc@5: 100.0000 (98.4591)  time: 0.3511  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5081  Acc@1: 87.5000 (86.2023)  Acc@5: 100.0000 (98.4580)  time: 0.3515  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5527  Acc@1: 87.5000 (86.2040)  Acc@5: 100.0000 (98.4540)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[3/5] Total time: 0:18:11 (0.3492 s / it)
{0: {0: 0, 1: 0, 2: 149872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 149888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 149936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.5527  Acc@1: 87.5000 (86.2040)  Acc@5: 100.0000 (98.4540)
Train: Epoch[4/5]  [   0/3125]  eta: 0:35:16  Lr: 0.001875  Loss: -0.4114  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6772  data: 0.3287  max mem: 2502
Train: Epoch[4/5]  [  10/3125]  eta: 0:19:47  Lr: 0.001875  Loss: -0.7949  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.7273)  time: 0.3811  data: 0.0320  max mem: 2502
Train: Epoch[4/5]  [  20/3125]  eta: 0:18:54  Lr: 0.001875  Loss: -0.2996  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.2143)  time: 0.3498  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [  30/3125]  eta: 0:18:33  Lr: 0.001875  Loss: -0.3586  Acc@1: 87.5000 (86.0887)  Acc@5: 100.0000 (98.5887)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [  40/3125]  eta: 0:18:24  Lr: 0.001875  Loss: -0.4808  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.9329)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [  50/3125]  eta: 0:18:20  Lr: 0.001875  Loss: -0.6187  Acc@1: 87.5000 (86.5196)  Acc@5: 100.0000 (99.0196)  time: 0.3550  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [  60/3125]  eta: 0:18:13  Lr: 0.001875  Loss: -0.7048  Acc@1: 87.5000 (86.5779)  Acc@5: 100.0000 (98.9754)  time: 0.3543  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [  70/3125]  eta: 0:18:08  Lr: 0.001875  Loss: -0.6359  Acc@1: 87.5000 (86.7958)  Acc@5: 100.0000 (98.9437)  time: 0.3517  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [  80/3125]  eta: 0:18:01  Lr: 0.001875  Loss: -0.9716  Acc@1: 87.5000 (86.6512)  Acc@5: 100.0000 (98.9969)  time: 0.3509  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [  90/3125]  eta: 0:17:56  Lr: 0.001875  Loss: -0.6344  Acc@1: 87.5000 (86.4011)  Acc@5: 100.0000 (98.9011)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 100/3125]  eta: 0:17:51  Lr: 0.001875  Loss: -0.4190  Acc@1: 87.5000 (86.2624)  Acc@5: 100.0000 (98.8861)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 110/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.4769  Acc@1: 87.5000 (86.2613)  Acc@5: 100.0000 (98.9865)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 120/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.1661  Acc@1: 87.5000 (86.2603)  Acc@5: 100.0000 (99.0186)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 130/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.7848  Acc@1: 87.5000 (86.3073)  Acc@5: 100.0000 (98.9981)  time: 0.3489  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 140/3125]  eta: 0:17:32  Lr: 0.001875  Loss: -0.7293  Acc@1: 87.5000 (86.3475)  Acc@5: 100.0000 (98.9362)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 150/3125]  eta: 0:17:28  Lr: 0.001875  Loss: -0.4616  Acc@1: 87.5000 (86.2583)  Acc@5: 100.0000 (98.9652)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 160/3125]  eta: 0:17:24  Lr: 0.001875  Loss: -0.6586  Acc@1: 81.2500 (86.1413)  Acc@5: 100.0000 (98.7966)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 170/3125]  eta: 0:17:21  Lr: 0.001875  Loss: -0.8281  Acc@1: 81.2500 (86.1842)  Acc@5: 100.0000 (98.8304)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 180/3125]  eta: 0:17:16  Lr: 0.001875  Loss: -0.5336  Acc@1: 87.5000 (86.3605)  Acc@5: 100.0000 (98.7914)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 190/3125]  eta: 0:17:12  Lr: 0.001875  Loss: -0.7639  Acc@1: 93.7500 (86.7147)  Acc@5: 100.0000 (98.8220)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 200/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.4246  Acc@1: 93.7500 (86.8159)  Acc@5: 100.0000 (98.8495)  time: 0.3557  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 210/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.7251  Acc@1: 87.5000 (86.9372)  Acc@5: 100.0000 (98.8744)  time: 0.3561  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 220/3125]  eta: 0:17:02  Lr: 0.001875  Loss: -0.7125  Acc@1: 87.5000 (86.8778)  Acc@5: 100.0000 (98.8971)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 230/3125]  eta: 0:16:58  Lr: 0.001875  Loss: -0.3834  Acc@1: 81.2500 (86.7424)  Acc@5: 100.0000 (98.9177)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 240/3125]  eta: 0:16:54  Lr: 0.001875  Loss: -0.1344  Acc@1: 81.2500 (86.5923)  Acc@5: 100.0000 (98.8330)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 250/3125]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6238  Acc@1: 87.5000 (86.7032)  Acc@5: 100.0000 (98.8048)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 260/3125]  eta: 0:16:46  Lr: 0.001875  Loss: -0.7254  Acc@1: 87.5000 (86.5182)  Acc@5: 100.0000 (98.7787)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 270/3125]  eta: 0:16:42  Lr: 0.001875  Loss: -0.3931  Acc@1: 81.2500 (86.4161)  Acc@5: 100.0000 (98.7315)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 280/3125]  eta: 0:16:38  Lr: 0.001875  Loss: -0.3183  Acc@1: 81.2500 (86.3879)  Acc@5: 100.0000 (98.7544)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 290/3125]  eta: 0:16:35  Lr: 0.001875  Loss: -0.6520  Acc@1: 87.5000 (86.3832)  Acc@5: 100.0000 (98.7758)  time: 0.3513  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 300/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.6811  Acc@1: 87.5000 (86.3164)  Acc@5: 100.0000 (98.7957)  time: 0.3524  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 310/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.4315  Acc@1: 87.5000 (86.2942)  Acc@5: 100.0000 (98.7942)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 320/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.8845  Acc@1: 87.5000 (86.3318)  Acc@5: 100.0000 (98.7734)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 330/3125]  eta: 0:16:20  Lr: 0.001875  Loss: -0.2305  Acc@1: 87.5000 (86.4237)  Acc@5: 100.0000 (98.7538)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 340/3125]  eta: 0:16:16  Lr: 0.001875  Loss: -0.7045  Acc@1: 87.5000 (86.4003)  Acc@5: 100.0000 (98.7537)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 350/3125]  eta: 0:16:12  Lr: 0.001875  Loss: -0.2912  Acc@1: 87.5000 (86.2714)  Acc@5: 100.0000 (98.7358)  time: 0.3476  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 360/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.6311  Acc@1: 87.5000 (86.3227)  Acc@5: 100.0000 (98.7535)  time: 0.3483  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 370/3125]  eta: 0:16:05  Lr: 0.001875  Loss: -0.5972  Acc@1: 87.5000 (86.3039)  Acc@5: 100.0000 (98.7702)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 380/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.4992  Acc@1: 87.5000 (86.3845)  Acc@5: 100.0000 (98.7205)  time: 0.3451  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 390/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.6351  Acc@1: 93.7500 (86.4770)  Acc@5: 100.0000 (98.7372)  time: 0.3462  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 400/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.4095  Acc@1: 87.5000 (86.5181)  Acc@5: 100.0000 (98.7531)  time: 0.3470  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 410/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.7174  Acc@1: 87.5000 (86.4811)  Acc@5: 100.0000 (98.7074)  time: 0.3463  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 420/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.4201  Acc@1: 81.2500 (86.4311)  Acc@5: 100.0000 (98.7084)  time: 0.3461  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 430/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.6832  Acc@1: 81.2500 (86.3979)  Acc@5: 100.0000 (98.6949)  time: 0.3452  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 440/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.4722  Acc@1: 87.5000 (86.3804)  Acc@5: 100.0000 (98.6961)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 450/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.7941  Acc@1: 81.2500 (86.3636)  Acc@5: 100.0000 (98.6835)  time: 0.3462  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 460/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.5987  Acc@1: 81.2500 (86.3341)  Acc@5: 100.0000 (98.6578)  time: 0.3477  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 470/3125]  eta: 0:15:27  Lr: 0.001875  Loss: -0.0555  Acc@1: 81.2500 (86.2792)  Acc@5: 100.0000 (98.6465)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 480/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.3288  Acc@1: 87.5000 (86.3306)  Acc@5: 100.0000 (98.6616)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 490/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.5695  Acc@1: 87.5000 (86.3798)  Acc@5: 100.0000 (98.6762)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 500/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.2960  Acc@1: 87.5000 (86.4521)  Acc@5: 100.0000 (98.6901)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 510/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.6368  Acc@1: 87.5000 (86.4604)  Acc@5: 100.0000 (98.7035)  time: 0.3503  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 520/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.6976  Acc@1: 87.5000 (86.4923)  Acc@5: 100.0000 (98.7284)  time: 0.3491  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 530/3125]  eta: 0:15:06  Lr: 0.001875  Loss: -0.5822  Acc@1: 87.5000 (86.4407)  Acc@5: 100.0000 (98.7170)  time: 0.3501  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 540/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.6945  Acc@1: 87.5000 (86.3909)  Acc@5: 100.0000 (98.6830)  time: 0.3503  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [ 550/3125]  eta: 0:14:59  Lr: 0.001875  Loss: -0.6419  Acc@1: 87.5000 (86.5018)  Acc@5: 100.0000 (98.7069)  time: 0.3500  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 560/3125]  eta: 0:14:56  Lr: 0.001875  Loss: -0.2115  Acc@1: 87.5000 (86.4528)  Acc@5: 100.0000 (98.6965)  time: 0.3511  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 570/3125]  eta: 0:14:52  Lr: 0.001875  Loss: -0.6540  Acc@1: 87.5000 (86.5149)  Acc@5: 100.0000 (98.7084)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 580/3125]  eta: 0:14:49  Lr: 0.001875  Loss: -0.5903  Acc@1: 87.5000 (86.5103)  Acc@5: 100.0000 (98.7091)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 590/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.7352  Acc@1: 87.5000 (86.5059)  Acc@5: 100.0000 (98.7098)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 600/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.7257  Acc@1: 87.5000 (86.5017)  Acc@5: 100.0000 (98.6689)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 610/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.4939  Acc@1: 87.5000 (86.4669)  Acc@5: 100.0000 (98.6395)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 620/3125]  eta: 0:14:35  Lr: 0.001875  Loss: -0.7060  Acc@1: 87.5000 (86.5238)  Acc@5: 100.0000 (98.6413)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 630/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.0818  Acc@1: 87.5000 (86.5293)  Acc@5: 100.0000 (98.6331)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 640/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.5041  Acc@1: 87.5000 (86.5152)  Acc@5: 100.0000 (98.5959)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 650/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.3192  Acc@1: 87.5000 (86.5591)  Acc@5: 100.0000 (98.5887)  time: 0.3562  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 660/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7624  Acc@1: 87.5000 (86.5450)  Acc@5: 100.0000 (98.5911)  time: 0.3604  data: 0.0024  max mem: 2502
Train: Epoch[4/5]  [ 670/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.5351  Acc@1: 87.5000 (86.5592)  Acc@5: 100.0000 (98.5842)  time: 0.3566  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [ 680/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.5950  Acc@1: 87.5000 (86.5180)  Acc@5: 100.0000 (98.5866)  time: 0.3542  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 690/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.6088  Acc@1: 81.2500 (86.4689)  Acc@5: 100.0000 (98.5800)  time: 0.3520  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 700/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.7752  Acc@1: 87.5000 (86.5460)  Acc@5: 100.0000 (98.5824)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 710/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.6646  Acc@1: 93.7500 (86.5594)  Acc@5: 100.0000 (98.5935)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 720/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.5717  Acc@1: 87.5000 (86.5985)  Acc@5: 100.0000 (98.5870)  time: 0.3507  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 730/3125]  eta: 0:13:58  Lr: 0.001875  Loss: -0.4401  Acc@1: 87.5000 (86.6023)  Acc@5: 100.0000 (98.5893)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 740/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6827  Acc@1: 87.5000 (86.5638)  Acc@5: 100.0000 (98.5746)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 750/3125]  eta: 0:13:51  Lr: 0.001875  Loss: -0.2063  Acc@1: 87.5000 (86.6178)  Acc@5: 100.0000 (98.5769)  time: 0.3506  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 760/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.5939  Acc@1: 87.5000 (86.5555)  Acc@5: 100.0000 (98.5545)  time: 0.3502  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 770/3125]  eta: 0:13:44  Lr: 0.001875  Loss: 0.3362  Acc@1: 87.5000 (86.5597)  Acc@5: 100.0000 (98.5490)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 780/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.6571  Acc@1: 87.5000 (86.6037)  Acc@5: 100.0000 (98.5435)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 790/3125]  eta: 0:13:37  Lr: 0.001875  Loss: -0.6495  Acc@1: 87.5000 (86.6308)  Acc@5: 100.0000 (98.5382)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 800/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.3724  Acc@1: 87.5000 (86.5871)  Acc@5: 100.0000 (98.5253)  time: 0.3502  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 810/3125]  eta: 0:13:30  Lr: 0.001875  Loss: -0.6757  Acc@1: 87.5000 (86.6369)  Acc@5: 100.0000 (98.5281)  time: 0.3504  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 820/3125]  eta: 0:13:27  Lr: 0.001875  Loss: -0.5859  Acc@1: 87.5000 (86.5789)  Acc@5: 100.0000 (98.5384)  time: 0.3523  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [ 830/3125]  eta: 0:13:23  Lr: 0.001875  Loss: -0.7837  Acc@1: 87.5000 (86.6200)  Acc@5: 100.0000 (98.5484)  time: 0.3523  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [ 840/3125]  eta: 0:13:20  Lr: 0.001875  Loss: -0.4201  Acc@1: 87.5000 (86.5859)  Acc@5: 100.0000 (98.5434)  time: 0.3509  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 850/3125]  eta: 0:13:16  Lr: 0.001875  Loss: -0.4582  Acc@1: 87.5000 (86.6260)  Acc@5: 100.0000 (98.5605)  time: 0.3504  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 860/3125]  eta: 0:13:13  Lr: 0.001875  Loss: -0.6989  Acc@1: 87.5000 (86.5999)  Acc@5: 100.0000 (98.5700)  time: 0.3494  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 870/3125]  eta: 0:13:09  Lr: 0.001875  Loss: -0.5847  Acc@1: 87.5000 (86.6461)  Acc@5: 100.0000 (98.5577)  time: 0.3537  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 880/3125]  eta: 0:13:06  Lr: 0.001875  Loss: -0.5172  Acc@1: 87.5000 (86.6700)  Acc@5: 100.0000 (98.5741)  time: 0.3532  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 890/3125]  eta: 0:13:02  Lr: 0.001875  Loss: -0.6844  Acc@1: 87.5000 (86.6933)  Acc@5: 100.0000 (98.5760)  time: 0.3473  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 900/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.3746  Acc@1: 87.5000 (86.7231)  Acc@5: 100.0000 (98.5849)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 910/3125]  eta: 0:12:55  Lr: 0.001875  Loss: -0.2737  Acc@1: 87.5000 (86.7110)  Acc@5: 100.0000 (98.5867)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 920/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.6374  Acc@1: 87.5000 (86.7264)  Acc@5: 100.0000 (98.5749)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 930/3125]  eta: 0:12:48  Lr: 0.001875  Loss: -0.2098  Acc@1: 87.5000 (86.7481)  Acc@5: 100.0000 (98.5499)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 940/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.3296  Acc@1: 81.2500 (86.6830)  Acc@5: 100.0000 (98.5521)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 950/3125]  eta: 0:12:41  Lr: 0.001875  Loss: -0.1999  Acc@1: 81.2500 (86.6982)  Acc@5: 100.0000 (98.5344)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 960/3125]  eta: 0:12:37  Lr: 0.001875  Loss: 0.0326  Acc@1: 87.5000 (86.6740)  Acc@5: 100.0000 (98.5237)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 970/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.6456  Acc@1: 81.2500 (86.6568)  Acc@5: 100.0000 (98.5067)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 980/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.8140  Acc@1: 87.5000 (86.7100)  Acc@5: 100.0000 (98.5155)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 990/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.4875  Acc@1: 87.5000 (86.7432)  Acc@5: 100.0000 (98.5242)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1000/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.8529  Acc@1: 87.5000 (86.8007)  Acc@5: 100.0000 (98.5202)  time: 0.3448  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.2198  Acc@1: 93.7500 (86.8200)  Acc@5: 100.0000 (98.5287)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1020/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.8416  Acc@1: 87.5000 (86.8144)  Acc@5: 100.0000 (98.5247)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.3613  Acc@1: 87.5000 (86.8150)  Acc@5: 100.0000 (98.5269)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1040/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.4309  Acc@1: 87.5000 (86.8096)  Acc@5: 100.0000 (98.5411)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.2878  Acc@1: 87.5000 (86.8042)  Acc@5: 100.0000 (98.5252)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1060/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.2835  Acc@1: 87.5000 (86.8049)  Acc@5: 100.0000 (98.5214)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.5359  Acc@1: 87.5000 (86.8172)  Acc@5: 100.0000 (98.5236)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1080/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.4119  Acc@1: 87.5000 (86.8756)  Acc@5: 100.0000 (98.5315)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.4246  Acc@1: 93.7500 (86.8756)  Acc@5: 100.0000 (98.5277)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1100/3125]  eta: 0:11:47  Lr: 0.001875  Loss: 0.0805  Acc@1: 87.5000 (86.8358)  Acc@5: 100.0000 (98.5354)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.4201  Acc@1: 81.2500 (86.7743)  Acc@5: 100.0000 (98.5149)  time: 0.3493  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1120/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.6427  Acc@1: 87.5000 (86.7585)  Acc@5: 100.0000 (98.5281)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.1516  Acc@1: 87.5000 (86.7429)  Acc@5: 100.0000 (98.5301)  time: 0.3497  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1140/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.6619  Acc@1: 87.5000 (86.7660)  Acc@5: 100.0000 (98.5375)  time: 0.3510  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.6032  Acc@1: 87.5000 (86.7615)  Acc@5: 100.0000 (98.5393)  time: 0.3509  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1160/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.1063  Acc@1: 87.5000 (86.7679)  Acc@5: 100.0000 (98.5465)  time: 0.3565  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.8662  Acc@1: 87.5000 (86.8008)  Acc@5: 100.0000 (98.5536)  time: 0.3559  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1180/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.2890  Acc@1: 87.5000 (86.8226)  Acc@5: 100.0000 (98.5552)  time: 0.3521  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.5348  Acc@1: 87.5000 (86.8073)  Acc@5: 100.0000 (98.5359)  time: 0.3528  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1200/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.5990  Acc@1: 87.5000 (86.8079)  Acc@5: 100.0000 (98.5377)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.6509  Acc@1: 87.5000 (86.8342)  Acc@5: 100.0000 (98.5446)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1220/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.8170  Acc@1: 87.5000 (86.8141)  Acc@5: 100.0000 (98.5514)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.5499  Acc@1: 87.5000 (86.7943)  Acc@5: 100.0000 (98.5378)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1240/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.4012  Acc@1: 87.5000 (86.8050)  Acc@5: 100.0000 (98.5395)  time: 0.3491  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.8115  Acc@1: 87.5000 (86.8155)  Acc@5: 100.0000 (98.5462)  time: 0.3499  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [1260/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.8164  Acc@1: 87.5000 (86.8259)  Acc@5: 100.0000 (98.5527)  time: 0.3517  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.4992  Acc@1: 87.5000 (86.8411)  Acc@5: 100.0000 (98.5641)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1280/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.7591  Acc@1: 87.5000 (86.8413)  Acc@5: 100.0000 (98.5656)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7090  Acc@1: 81.2500 (86.8271)  Acc@5: 100.0000 (98.5767)  time: 0.3527  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1300/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.4017  Acc@1: 87.5000 (86.8322)  Acc@5: 100.0000 (98.5780)  time: 0.3523  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.5524  Acc@1: 87.5000 (86.8230)  Acc@5: 100.0000 (98.5793)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1320/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.4269  Acc@1: 81.2500 (86.7998)  Acc@5: 100.0000 (98.5806)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1330/3125]  eta: 0:10:28  Lr: 0.001875  Loss: -0.5313  Acc@1: 87.5000 (86.7909)  Acc@5: 100.0000 (98.5772)  time: 0.3570  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1340/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.6324  Acc@1: 87.5000 (86.7823)  Acc@5: 100.0000 (98.5645)  time: 0.3568  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1350/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.6412  Acc@1: 87.5000 (86.8014)  Acc@5: 100.0000 (98.5659)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1360/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.1868  Acc@1: 87.5000 (86.7928)  Acc@5: 100.0000 (98.5626)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1370/3125]  eta: 0:10:14  Lr: 0.001875  Loss: -0.5553  Acc@1: 87.5000 (86.8025)  Acc@5: 100.0000 (98.5640)  time: 0.3467  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1380/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.8776  Acc@1: 87.5000 (86.8166)  Acc@5: 100.0000 (98.5563)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1390/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5247  Acc@1: 87.5000 (86.7991)  Acc@5: 100.0000 (98.5487)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1400/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.4354  Acc@1: 87.5000 (86.8175)  Acc@5: 100.0000 (98.5501)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.4428  Acc@1: 87.5000 (86.8179)  Acc@5: 100.0000 (98.5560)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1420/3125]  eta: 0:09:56  Lr: 0.001875  Loss: -0.3028  Acc@1: 81.2500 (86.7831)  Acc@5: 100.0000 (98.5618)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.6901  Acc@1: 81.2500 (86.7925)  Acc@5: 100.0000 (98.5718)  time: 0.3545  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1440/3125]  eta: 0:09:49  Lr: 0.001875  Loss: -0.6220  Acc@1: 87.5000 (86.7713)  Acc@5: 100.0000 (98.5730)  time: 0.3538  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.8409  Acc@1: 87.5000 (86.7677)  Acc@5: 100.0000 (98.5700)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1460/3125]  eta: 0:09:42  Lr: 0.001875  Loss: -0.3934  Acc@1: 87.5000 (86.7514)  Acc@5: 100.0000 (98.5669)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1470/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.2615  Acc@1: 81.2500 (86.7352)  Acc@5: 100.0000 (98.5597)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1480/3125]  eta: 0:09:35  Lr: 0.001875  Loss: -0.4583  Acc@1: 81.2500 (86.7235)  Acc@5: 100.0000 (98.5525)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1490/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.4301  Acc@1: 81.2500 (86.7119)  Acc@5: 100.0000 (98.5580)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1500/3125]  eta: 0:09:28  Lr: 0.001875  Loss: -0.5476  Acc@1: 87.5000 (86.7130)  Acc@5: 100.0000 (98.5593)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.3306  Acc@1: 87.5000 (86.6893)  Acc@5: 100.0000 (98.5688)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1520/3125]  eta: 0:09:21  Lr: 0.001875  Loss: -0.5711  Acc@1: 87.5000 (86.6700)  Acc@5: 100.0000 (98.5659)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.5237  Acc@1: 87.5000 (86.6795)  Acc@5: 100.0000 (98.5671)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1540/3125]  eta: 0:09:14  Lr: 0.001875  Loss: -0.8032  Acc@1: 93.7500 (86.7091)  Acc@5: 100.0000 (98.5642)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.7731  Acc@1: 93.7500 (86.7344)  Acc@5: 100.0000 (98.5614)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1560/3125]  eta: 0:09:07  Lr: 0.001875  Loss: -0.6111  Acc@1: 87.5000 (86.7152)  Acc@5: 100.0000 (98.5586)  time: 0.3472  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.3944  Acc@1: 87.5000 (86.7004)  Acc@5: 100.0000 (98.5559)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1580/3125]  eta: 0:09:00  Lr: 0.001875  Loss: -0.5562  Acc@1: 81.2500 (86.6975)  Acc@5: 100.0000 (98.5571)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.2319  Acc@1: 87.5000 (86.6908)  Acc@5: 100.0000 (98.5583)  time: 0.3505  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1600/3125]  eta: 0:08:53  Lr: 0.001875  Loss: -0.5241  Acc@1: 87.5000 (86.6841)  Acc@5: 100.0000 (98.5556)  time: 0.3501  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5086  Acc@1: 87.5000 (86.7008)  Acc@5: 100.0000 (98.5607)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1620/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.5051  Acc@1: 87.5000 (86.7019)  Acc@5: 100.0000 (98.5541)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.3804  Acc@1: 87.5000 (86.6761)  Acc@5: 100.0000 (98.5553)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1640/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.2546  Acc@1: 81.2500 (86.6735)  Acc@5: 100.0000 (98.5527)  time: 0.3515  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.9363  Acc@1: 81.2500 (86.6710)  Acc@5: 100.0000 (98.5615)  time: 0.3523  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.7025  Acc@1: 81.2500 (86.6797)  Acc@5: 100.0000 (98.5626)  time: 0.3577  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.6221  Acc@1: 81.2500 (86.6472)  Acc@5: 100.0000 (98.5563)  time: 0.3572  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.2901  Acc@1: 81.2500 (86.6300)  Acc@5: 100.0000 (98.5463)  time: 0.3495  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.1442  Acc@1: 87.5000 (86.6240)  Acc@5: 100.0000 (98.5438)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: 0.0684  Acc@1: 87.5000 (86.6255)  Acc@5: 100.0000 (98.5376)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.2660  Acc@1: 87.5000 (86.6306)  Acc@5: 100.0000 (98.5389)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.5183  Acc@1: 87.5000 (86.6357)  Acc@5: 100.0000 (98.5401)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.3720  Acc@1: 87.5000 (86.6371)  Acc@5: 100.0000 (98.5413)  time: 0.3499  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.4145  Acc@1: 87.5000 (86.6348)  Acc@5: 100.0000 (98.5353)  time: 0.3530  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.7345  Acc@1: 87.5000 (86.6576)  Acc@5: 100.0000 (98.5330)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: 0.2076  Acc@1: 87.5000 (86.6660)  Acc@5: 100.0000 (98.5200)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.8116  Acc@1: 87.5000 (86.6636)  Acc@5: 100.0000 (98.5143)  time: 0.3470  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.5209  Acc@1: 87.5000 (86.6578)  Acc@5: 100.0000 (98.5156)  time: 0.3472  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.4261  Acc@1: 81.2500 (86.6101)  Acc@5: 100.0000 (98.5169)  time: 0.3468  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.5528  Acc@1: 81.2500 (86.6220)  Acc@5: 100.0000 (98.5217)  time: 0.3467  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.2944  Acc@1: 87.5000 (86.6131)  Acc@5: 100.0000 (98.5195)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.4660  Acc@1: 87.5000 (86.6179)  Acc@5: 100.0000 (98.5242)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.4183  Acc@1: 87.5000 (86.6296)  Acc@5: 100.0000 (98.5288)  time: 0.3449  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.2860  Acc@1: 87.5000 (86.6037)  Acc@5: 100.0000 (98.5300)  time: 0.3447  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.5930  Acc@1: 81.2500 (86.5816)  Acc@5: 100.0000 (98.5244)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.7265  Acc@1: 81.2500 (86.5865)  Acc@5: 100.0000 (98.5290)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.6729  Acc@1: 87.5000 (86.5947)  Acc@5: 100.0000 (98.5235)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.4759  Acc@1: 87.5000 (86.5962)  Acc@5: 100.0000 (98.5247)  time: 0.3507  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.5935  Acc@1: 87.5000 (86.5845)  Acc@5: 100.0000 (98.5292)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.8211  Acc@1: 81.2500 (86.5893)  Acc@5: 100.0000 (98.5370)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.8643  Acc@1: 87.5000 (86.5908)  Acc@5: 100.0000 (98.5315)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.4428  Acc@1: 87.5000 (86.5793)  Acc@5: 100.0000 (98.5262)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.6829  Acc@1: 81.2500 (86.5549)  Acc@5: 100.0000 (98.5306)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6335  Acc@1: 81.2500 (86.5469)  Acc@5: 100.0000 (98.5285)  time: 0.3535  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.4889  Acc@1: 87.5000 (86.5293)  Acc@5: 100.0000 (98.5296)  time: 0.3529  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.5167  Acc@1: 87.5000 (86.5534)  Acc@5: 100.0000 (98.5371)  time: 0.3527  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.3371  Acc@1: 87.5000 (86.5297)  Acc@5: 100.0000 (98.5382)  time: 0.3528  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.4467  Acc@1: 81.2500 (86.5346)  Acc@5: 100.0000 (98.5424)  time: 0.3506  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.4183  Acc@1: 87.5000 (86.5331)  Acc@5: 100.0000 (98.5403)  time: 0.3508  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.6886  Acc@1: 87.5000 (86.5442)  Acc@5: 100.0000 (98.5382)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.8163  Acc@1: 87.5000 (86.5770)  Acc@5: 100.0000 (98.5424)  time: 0.3507  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.5543  Acc@1: 87.5000 (86.5599)  Acc@5: 100.0000 (98.5403)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.2715  Acc@1: 87.5000 (86.5768)  Acc@5: 100.0000 (98.5352)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.5847  Acc@1: 87.5000 (86.5844)  Acc@5: 100.0000 (98.5301)  time: 0.3526  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.5244  Acc@1: 87.5000 (86.5980)  Acc@5: 100.0000 (98.5312)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.6898  Acc@1: 87.5000 (86.6206)  Acc@5: 100.0000 (98.5323)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.6630  Acc@1: 87.5000 (86.6097)  Acc@5: 100.0000 (98.5243)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5666  Acc@1: 87.5000 (86.6170)  Acc@5: 100.0000 (98.5253)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.0766  Acc@1: 87.5000 (86.6182)  Acc@5: 100.0000 (98.5234)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.4822  Acc@1: 87.5000 (86.6135)  Acc@5: 100.0000 (98.5275)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.4134  Acc@1: 87.5000 (86.6029)  Acc@5: 100.0000 (98.5285)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.5345  Acc@1: 87.5000 (86.5865)  Acc@5: 100.0000 (98.5237)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.6056  Acc@1: 81.2500 (86.5673)  Acc@5: 100.0000 (98.5160)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.5819  Acc@1: 87.5000 (86.5688)  Acc@5: 100.0000 (98.5112)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.4015  Acc@1: 87.5000 (86.5644)  Acc@5: 100.0000 (98.5152)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6340  Acc@1: 87.5000 (86.5774)  Acc@5: 100.0000 (98.5163)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6023  Acc@1: 87.5000 (86.5816)  Acc@5: 100.0000 (98.5231)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4176  Acc@1: 87.5000 (86.5916)  Acc@5: 100.0000 (98.5242)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.7404  Acc@1: 87.5000 (86.5957)  Acc@5: 100.0000 (98.5252)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4156  Acc@1: 87.5000 (86.6084)  Acc@5: 100.0000 (98.5262)  time: 0.3501  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.9040  Acc@1: 87.5000 (86.6209)  Acc@5: 100.0000 (98.5273)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.5360  Acc@1: 87.5000 (86.6164)  Acc@5: 100.0000 (98.5226)  time: 0.3491  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.5822  Acc@1: 81.2500 (86.6063)  Acc@5: 100.0000 (98.5264)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.6457  Acc@1: 87.5000 (86.6075)  Acc@5: 100.0000 (98.5274)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.7707  Acc@1: 87.5000 (86.6060)  Acc@5: 100.0000 (98.5257)  time: 0.3519  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.1268  Acc@1: 87.5000 (86.5850)  Acc@5: 100.0000 (98.5128)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5974  Acc@1: 87.5000 (86.5973)  Acc@5: 100.0000 (98.5194)  time: 0.3541  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.3503  Acc@1: 87.5000 (86.6068)  Acc@5: 100.0000 (98.5231)  time: 0.3518  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.6823  Acc@1: 87.5000 (86.6243)  Acc@5: 100.0000 (98.5268)  time: 0.3492  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.6258  Acc@1: 87.5000 (86.6308)  Acc@5: 100.0000 (98.5278)  time: 0.3493  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.7958  Acc@1: 87.5000 (86.6319)  Acc@5: 100.0000 (98.5261)  time: 0.3502  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: 0.0053  Acc@1: 87.5000 (86.6275)  Acc@5: 100.0000 (98.5190)  time: 0.3498  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.7616  Acc@1: 87.5000 (86.6340)  Acc@5: 100.0000 (98.5173)  time: 0.3507  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: 0.0436  Acc@1: 87.5000 (86.6163)  Acc@5: 100.0000 (98.5076)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.4823  Acc@1: 87.5000 (86.6201)  Acc@5: 100.0000 (98.5060)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.6016  Acc@1: 87.5000 (86.6291)  Acc@5: 100.0000 (98.5043)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.3866  Acc@1: 87.5000 (86.6169)  Acc@5: 100.0000 (98.5027)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7893  Acc@1: 87.5000 (86.6180)  Acc@5: 100.0000 (98.5064)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.1862  Acc@1: 87.5000 (86.6191)  Acc@5: 100.0000 (98.5022)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.7178  Acc@1: 87.5000 (86.6097)  Acc@5: 100.0000 (98.5006)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.3389  Acc@1: 87.5000 (86.6108)  Acc@5: 100.0000 (98.5017)  time: 0.3463  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.4007  Acc@1: 87.5000 (86.6016)  Acc@5: 100.0000 (98.5001)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.3715  Acc@1: 87.5000 (86.6079)  Acc@5: 100.0000 (98.5063)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.5971  Acc@1: 87.5000 (86.6243)  Acc@5: 100.0000 (98.5073)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6973  Acc@1: 87.5000 (86.6305)  Acc@5: 100.0000 (98.5134)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.3166  Acc@1: 81.2500 (86.6188)  Acc@5: 100.0000 (98.5118)  time: 0.3466  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7659  Acc@1: 87.5000 (86.6173)  Acc@5: 100.0000 (98.5102)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7353  Acc@1: 87.5000 (86.6107)  Acc@5: 100.0000 (98.5011)  time: 0.3518  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.4178  Acc@1: 87.5000 (86.6193)  Acc@5: 100.0000 (98.4996)  time: 0.3504  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.2454  Acc@1: 87.5000 (86.6229)  Acc@5: 100.0000 (98.5031)  time: 0.3497  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.7748  Acc@1: 87.5000 (86.6338)  Acc@5: 100.0000 (98.5091)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.4580  Acc@1: 87.5000 (86.6323)  Acc@5: 100.0000 (98.5100)  time: 0.3483  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.7206  Acc@1: 87.5000 (86.6431)  Acc@5: 100.0000 (98.5159)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.8767  Acc@1: 87.5000 (86.6613)  Acc@5: 100.0000 (98.5119)  time: 0.3504  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.2469  Acc@1: 87.5000 (86.6645)  Acc@5: 100.0000 (98.5153)  time: 0.3529  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.5589  Acc@1: 87.5000 (86.6629)  Acc@5: 100.0000 (98.5113)  time: 0.3561  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.7006  Acc@1: 87.5000 (86.6783)  Acc@5: 100.0000 (98.5123)  time: 0.3552  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.4538  Acc@1: 87.5000 (86.6767)  Acc@5: 100.0000 (98.5108)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.5628  Acc@1: 87.5000 (86.6726)  Acc@5: 100.0000 (98.5117)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.3733  Acc@1: 87.5000 (86.6662)  Acc@5: 100.0000 (98.5174)  time: 0.3496  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.5781  Acc@1: 87.5000 (86.6742)  Acc@5: 100.0000 (98.5111)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.2965  Acc@1: 87.5000 (86.6749)  Acc@5: 100.0000 (98.5120)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.4269  Acc@1: 87.5000 (86.6733)  Acc@5: 100.0000 (98.5153)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.7114  Acc@1: 93.7500 (86.6906)  Acc@5: 100.0000 (98.5115)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.8045  Acc@1: 87.5000 (86.6866)  Acc@5: 100.0000 (98.5100)  time: 0.3488  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6018  Acc@1: 87.5000 (86.6944)  Acc@5: 100.0000 (98.5156)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.6508  Acc@1: 87.5000 (86.6787)  Acc@5: 100.0000 (98.5165)  time: 0.3474  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: 0.1832  Acc@1: 81.2500 (86.6724)  Acc@5: 100.0000 (98.5173)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.2959  Acc@1: 87.5000 (86.6755)  Acc@5: 100.0000 (98.5229)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.7646  Acc@1: 87.5000 (86.6577)  Acc@5: 100.0000 (98.5214)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.6101  Acc@1: 81.2500 (86.6470)  Acc@5: 100.0000 (98.5222)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.1870  Acc@1: 81.2500 (86.6409)  Acc@5: 100.0000 (98.5185)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.6050  Acc@1: 87.5000 (86.6555)  Acc@5: 100.0000 (98.5216)  time: 0.3464  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.4168  Acc@1: 93.7500 (86.6677)  Acc@5: 100.0000 (98.5247)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.7227  Acc@1: 87.5000 (86.6617)  Acc@5: 100.0000 (98.5278)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.2748  Acc@1: 81.2500 (86.6421)  Acc@5: 100.0000 (98.5218)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.4137  Acc@1: 81.2500 (86.6339)  Acc@5: 100.0000 (98.5226)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4633  Acc@1: 87.5000 (86.6190)  Acc@5: 100.0000 (98.5167)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2790/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.4521  Acc@1: 87.5000 (86.6199)  Acc@5: 100.0000 (98.5108)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4804  Acc@1: 87.5000 (86.6253)  Acc@5: 100.0000 (98.5117)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7132  Acc@1: 87.5000 (86.6306)  Acc@5: 100.0000 (98.5103)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.4127  Acc@1: 87.5000 (86.6382)  Acc@5: 100.0000 (98.5090)  time: 0.3486  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.6221  Acc@1: 87.5000 (86.6412)  Acc@5: 100.0000 (98.5076)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.4770  Acc@1: 87.5000 (86.6486)  Acc@5: 100.0000 (98.5106)  time: 0.3494  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6462  Acc@1: 87.5000 (86.6516)  Acc@5: 100.0000 (98.5137)  time: 0.3489  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7407  Acc@1: 87.5000 (86.6524)  Acc@5: 100.0000 (98.5167)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.8392  Acc@1: 93.7500 (86.6684)  Acc@5: 100.0000 (98.5153)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2340  Acc@1: 93.7500 (86.6756)  Acc@5: 100.0000 (98.5118)  time: 0.3493  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.5798  Acc@1: 93.7500 (86.6893)  Acc@5: 100.0000 (98.5169)  time: 0.3504  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: 0.0160  Acc@1: 93.7500 (86.7029)  Acc@5: 100.0000 (98.5199)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7803  Acc@1: 87.5000 (86.6992)  Acc@5: 100.0000 (98.5186)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8134  Acc@1: 87.5000 (86.7040)  Acc@5: 100.0000 (98.5193)  time: 0.3553  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.3767  Acc@1: 87.5000 (86.7025)  Acc@5: 100.0000 (98.5201)  time: 0.3539  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.4801  Acc@1: 87.5000 (86.6988)  Acc@5: 100.0000 (98.5230)  time: 0.3552  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1633  Acc@1: 87.5000 (86.6867)  Acc@5: 100.0000 (98.5132)  time: 0.3552  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6622  Acc@1: 87.5000 (86.6979)  Acc@5: 100.0000 (98.5140)  time: 0.3500  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.4867  Acc@1: 93.7500 (86.7111)  Acc@5: 100.0000 (98.5169)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.1328  Acc@1: 87.5000 (86.7033)  Acc@5: 100.0000 (98.5156)  time: 0.3493  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6296  Acc@1: 87.5000 (86.7018)  Acc@5: 100.0000 (98.5164)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.6671  Acc@1: 87.5000 (86.7128)  Acc@5: 100.0000 (98.5151)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3547  Acc@1: 87.5000 (86.7195)  Acc@5: 100.0000 (98.5179)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.8092  Acc@1: 87.5000 (86.7262)  Acc@5: 100.0000 (98.5208)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6970  Acc@1: 87.5000 (86.7329)  Acc@5: 100.0000 (98.5215)  time: 0.3486  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.4970  Acc@1: 87.5000 (86.7252)  Acc@5: 100.0000 (98.5141)  time: 0.3479  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.4078  Acc@1: 81.2500 (86.7298)  Acc@5: 100.0000 (98.5107)  time: 0.3473  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.3890  Acc@1: 87.5000 (86.7241)  Acc@5: 100.0000 (98.5136)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.4193  Acc@1: 87.5000 (86.7307)  Acc@5: 100.0000 (98.5143)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.7642  Acc@1: 87.5000 (86.7312)  Acc@5: 100.0000 (98.5171)  time: 0.3486  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.4542  Acc@1: 87.5000 (86.7438)  Acc@5: 100.0000 (98.5159)  time: 0.3538  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5710  Acc@1: 87.5000 (86.7361)  Acc@5: 100.0000 (98.5186)  time: 0.3532  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4624  Acc@1: 87.5000 (86.7426)  Acc@5: 100.0000 (98.5214)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5168  Acc@1: 87.5000 (86.7530)  Acc@5: 100.0000 (98.5161)  time: 0.3464  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7406  Acc@1: 87.5000 (86.7580)  Acc@5: 100.0000 (98.5140)  time: 0.3464  data: 0.0007  max mem: 2502
Train: Epoch[4/5] Total time: 0:18:12 (0.3495 s / it)
{0: {0: 0, 1: 0, 2: 199872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 199888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 199936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.7406  Acc@1: 87.5000 (86.7580)  Acc@5: 100.0000 (98.5140)
Train: Epoch[5/5]  [   0/3125]  eta: 0:37:05  Lr: 0.001875  Loss: -0.3777  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7120  data: 0.3659  max mem: 2502
Train: Epoch[5/5]  [  10/3125]  eta: 0:19:44  Lr: 0.001875  Loss: -0.2185  Acc@1: 87.5000 (81.8182)  Acc@5: 100.0000 (97.7273)  time: 0.3802  data: 0.0336  max mem: 2502
Train: Epoch[5/5]  [  20/3125]  eta: 0:18:51  Lr: 0.001875  Loss: -0.2949  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.9167)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  30/3125]  eta: 0:18:30  Lr: 0.001875  Loss: -0.7684  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.3871)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  40/3125]  eta: 0:18:17  Lr: 0.001875  Loss: -0.6275  Acc@1: 87.5000 (87.8049)  Acc@5: 100.0000 (98.1707)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  50/3125]  eta: 0:18:07  Lr: 0.001875  Loss: -0.3915  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (98.1618)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  60/3125]  eta: 0:17:59  Lr: 0.001875  Loss: -0.8682  Acc@1: 87.5000 (87.6025)  Acc@5: 100.0000 (98.0533)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  70/3125]  eta: 0:17:52  Lr: 0.001875  Loss: -0.2091  Acc@1: 87.5000 (88.0282)  Acc@5: 100.0000 (98.2394)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  80/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.7348  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (98.0710)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  90/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.5871  Acc@1: 87.5000 (87.4313)  Acc@5: 100.0000 (98.2830)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 100/3125]  eta: 0:17:36  Lr: 0.001875  Loss: -0.6312  Acc@1: 87.5000 (87.8094)  Acc@5: 100.0000 (98.3911)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 110/3125]  eta: 0:17:33  Lr: 0.001875  Loss: -0.8106  Acc@1: 93.7500 (88.1194)  Acc@5: 100.0000 (98.4234)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 120/3125]  eta: 0:17:29  Lr: 0.001875  Loss: -0.5048  Acc@1: 87.5000 (87.9649)  Acc@5: 100.0000 (98.3988)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 130/3125]  eta: 0:17:25  Lr: 0.001875  Loss: -0.8193  Acc@1: 87.5000 (88.2156)  Acc@5: 100.0000 (98.4733)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 140/3125]  eta: 0:17:20  Lr: 0.001875  Loss: -0.0789  Acc@1: 87.5000 (88.0762)  Acc@5: 100.0000 (98.4929)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 150/3125]  eta: 0:17:17  Lr: 0.001875  Loss: -0.3136  Acc@1: 87.5000 (88.0795)  Acc@5: 100.0000 (98.4272)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 160/3125]  eta: 0:17:13  Lr: 0.001875  Loss: -0.8206  Acc@1: 87.5000 (87.8882)  Acc@5: 100.0000 (98.4084)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 170/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.4867  Acc@1: 87.5000 (87.9386)  Acc@5: 100.0000 (98.4649)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 180/3125]  eta: 0:17:06  Lr: 0.001875  Loss: -0.6635  Acc@1: 81.2500 (87.6036)  Acc@5: 100.0000 (98.4116)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 190/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.5961  Acc@1: 87.5000 (87.6636)  Acc@5: 100.0000 (98.4620)  time: 0.3493  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 200/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.5764  Acc@1: 87.5000 (87.7488)  Acc@5: 100.0000 (98.4764)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 210/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5419  Acc@1: 87.5000 (87.6185)  Acc@5: 100.0000 (98.4597)  time: 0.3524  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 220/3125]  eta: 0:16:54  Lr: 0.001875  Loss: -0.6251  Acc@1: 87.5000 (87.6414)  Acc@5: 100.0000 (98.5011)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 230/3125]  eta: 0:16:50  Lr: 0.001875  Loss: -0.5290  Acc@1: 87.5000 (87.4459)  Acc@5: 100.0000 (98.5390)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 240/3125]  eta: 0:16:47  Lr: 0.001875  Loss: -0.5062  Acc@1: 87.5000 (87.4222)  Acc@5: 100.0000 (98.5996)  time: 0.3501  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 250/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.6281  Acc@1: 87.5000 (87.5249)  Acc@5: 100.0000 (98.6305)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 260/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.6964  Acc@1: 87.5000 (87.6197)  Acc@5: 100.0000 (98.6111)  time: 0.3523  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 270/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.0018  Acc@1: 93.7500 (87.7306)  Acc@5: 100.0000 (98.6162)  time: 0.3507  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 280/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.4182  Acc@1: 93.7500 (87.6779)  Acc@5: 100.0000 (98.5988)  time: 0.3518  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [ 290/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.5124  Acc@1: 87.5000 (87.6503)  Acc@5: 100.0000 (98.5825)  time: 0.3519  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [ 300/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.6200  Acc@1: 87.5000 (87.6038)  Acc@5: 100.0000 (98.4842)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 310/3125]  eta: 0:16:24  Lr: 0.001875  Loss: -0.4228  Acc@1: 87.5000 (87.5804)  Acc@5: 100.0000 (98.4928)  time: 0.3507  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 320/3125]  eta: 0:16:20  Lr: 0.001875  Loss: -0.7105  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4618)  time: 0.3498  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 330/3125]  eta: 0:16:17  Lr: 0.001875  Loss: 0.1035  Acc@1: 87.5000 (87.3867)  Acc@5: 100.0000 (98.4517)  time: 0.3508  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 340/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.8762  Acc@1: 87.5000 (87.4450)  Acc@5: 100.0000 (98.4421)  time: 0.3530  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 350/3125]  eta: 0:16:10  Lr: 0.001875  Loss: -0.7126  Acc@1: 87.5000 (87.3397)  Acc@5: 100.0000 (98.3974)  time: 0.3517  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 360/3125]  eta: 0:16:07  Lr: 0.001875  Loss: -0.3624  Acc@1: 81.2500 (87.1711)  Acc@5: 100.0000 (98.4072)  time: 0.3534  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 370/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.3721  Acc@1: 87.5000 (87.1294)  Acc@5: 100.0000 (98.3996)  time: 0.3564  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 380/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.2258  Acc@1: 87.5000 (87.0571)  Acc@5: 100.0000 (98.4088)  time: 0.3521  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 390/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.6967  Acc@1: 87.5000 (87.1164)  Acc@5: 100.0000 (98.4175)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 400/3125]  eta: 0:15:54  Lr: 0.001875  Loss: -0.4603  Acc@1: 87.5000 (87.1883)  Acc@5: 100.0000 (98.4258)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 410/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.8392  Acc@1: 87.5000 (87.2263)  Acc@5: 100.0000 (98.4489)  time: 0.3482  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 420/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.5316  Acc@1: 87.5000 (87.1734)  Acc@5: 100.0000 (98.4561)  time: 0.3478  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 430/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.4930  Acc@1: 87.5000 (87.1665)  Acc@5: 100.0000 (98.4194)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 440/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.7408  Acc@1: 87.5000 (87.1740)  Acc@5: 100.0000 (98.4127)  time: 0.3487  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 450/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.5066  Acc@1: 87.5000 (87.1397)  Acc@5: 100.0000 (98.4202)  time: 0.3483  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 460/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.8082  Acc@1: 87.5000 (87.1611)  Acc@5: 100.0000 (98.4544)  time: 0.3482  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 470/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.4590  Acc@1: 87.5000 (87.1815)  Acc@5: 100.0000 (98.4607)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 480/3125]  eta: 0:15:25  Lr: 0.001875  Loss: -0.7852  Acc@1: 87.5000 (87.0972)  Acc@5: 100.0000 (98.4407)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 490/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.4138  Acc@1: 87.5000 (87.1436)  Acc@5: 100.0000 (98.4470)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 500/3125]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5158  Acc@1: 87.5000 (87.1881)  Acc@5: 100.0000 (98.4157)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 510/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.5583  Acc@1: 87.5000 (87.1331)  Acc@5: 100.0000 (98.4344)  time: 0.3515  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 520/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.7887  Acc@1: 81.2500 (87.1161)  Acc@5: 100.0000 (98.4285)  time: 0.3523  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 530/3125]  eta: 0:15:08  Lr: 0.001875  Loss: -0.4949  Acc@1: 81.2500 (87.0645)  Acc@5: 100.0000 (98.4463)  time: 0.3510  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 540/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.7732  Acc@1: 87.5000 (87.1650)  Acc@5: 100.0000 (98.4519)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 550/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.4468  Acc@1: 87.5000 (87.1257)  Acc@5: 100.0000 (98.4574)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 560/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.4466  Acc@1: 87.5000 (87.0878)  Acc@5: 100.0000 (98.4626)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 570/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.3684  Acc@1: 87.5000 (87.1388)  Acc@5: 100.0000 (98.4785)  time: 0.3526  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 580/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.4574  Acc@1: 87.5000 (87.1880)  Acc@5: 100.0000 (98.4725)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 590/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.2484  Acc@1: 87.5000 (87.1510)  Acc@5: 100.0000 (98.4666)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 600/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.7003  Acc@1: 93.7500 (87.2296)  Acc@5: 100.0000 (98.4817)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 610/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.8770  Acc@1: 93.7500 (87.2545)  Acc@5: 100.0000 (98.5065)  time: 0.3485  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 620/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.4423  Acc@1: 87.5000 (87.1880)  Acc@5: 100.0000 (98.4903)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 630/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.2511  Acc@1: 87.5000 (87.1731)  Acc@5: 100.0000 (98.5044)  time: 0.3454  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 640/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.6508  Acc@1: 87.5000 (87.2270)  Acc@5: 100.0000 (98.5179)  time: 0.3451  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 650/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.3750  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.5119)  time: 0.3470  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 660/3125]  eta: 0:14:21  Lr: 0.001875  Loss: -0.6144  Acc@1: 87.5000 (87.1974)  Acc@5: 100.0000 (98.5061)  time: 0.3510  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 670/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.5846  Acc@1: 87.5000 (87.1740)  Acc@5: 100.0000 (98.5097)  time: 0.3532  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 680/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.4119  Acc@1: 87.5000 (87.2063)  Acc@5: 100.0000 (98.5132)  time: 0.3533  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 690/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.7486  Acc@1: 87.5000 (87.2287)  Acc@5: 100.0000 (98.5257)  time: 0.3495  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 700/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.6137  Acc@1: 87.5000 (87.2414)  Acc@5: 100.0000 (98.5200)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 710/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.7553  Acc@1: 87.5000 (87.2275)  Acc@5: 100.0000 (98.5144)  time: 0.3473  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 720/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.1731  Acc@1: 87.5000 (87.2313)  Acc@5: 100.0000 (98.5264)  time: 0.3469  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 730/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.4702  Acc@1: 87.5000 (87.2264)  Acc@5: 100.0000 (98.5123)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 740/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.5251  Acc@1: 87.5000 (87.2048)  Acc@5: 100.0000 (98.4987)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 750/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.6809  Acc@1: 87.5000 (87.1671)  Acc@5: 100.0000 (98.5103)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 760/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.6188  Acc@1: 87.5000 (87.1961)  Acc@5: 100.0000 (98.4970)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 770/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.7016  Acc@1: 87.5000 (87.1839)  Acc@5: 100.0000 (98.4922)  time: 0.3453  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 780/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.5023  Acc@1: 87.5000 (87.2119)  Acc@5: 100.0000 (98.5035)  time: 0.3458  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 790/3125]  eta: 0:13:35  Lr: 0.001875  Loss: -0.1966  Acc@1: 93.7500 (87.2551)  Acc@5: 100.0000 (98.5145)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 800/3125]  eta: 0:13:31  Lr: 0.001875  Loss: -0.5307  Acc@1: 87.5000 (87.2425)  Acc@5: 100.0000 (98.5253)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 810/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.5537  Acc@1: 87.5000 (87.2380)  Acc@5: 100.0000 (98.5435)  time: 0.3467  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 820/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.6371  Acc@1: 87.5000 (87.2564)  Acc@5: 100.0000 (98.5384)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 830/3125]  eta: 0:13:21  Lr: 0.001875  Loss: -0.7404  Acc@1: 87.5000 (87.2518)  Acc@5: 100.0000 (98.5184)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 840/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.4843  Acc@1: 87.5000 (87.2845)  Acc@5: 100.0000 (98.5137)  time: 0.3511  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 850/3125]  eta: 0:13:14  Lr: 0.001875  Loss: -0.3758  Acc@1: 93.7500 (87.3164)  Acc@5: 100.0000 (98.5238)  time: 0.3500  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 860/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.5128  Acc@1: 87.5000 (87.3185)  Acc@5: 100.0000 (98.5192)  time: 0.3490  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 870/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.5958  Acc@1: 87.5000 (87.3278)  Acc@5: 100.0000 (98.5218)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 880/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.8106  Acc@1: 87.5000 (87.2659)  Acc@5: 100.0000 (98.4960)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 890/3125]  eta: 0:13:00  Lr: 0.001875  Loss: -0.4046  Acc@1: 87.5000 (87.2896)  Acc@5: 100.0000 (98.4919)  time: 0.3520  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 900/3125]  eta: 0:12:57  Lr: 0.001875  Loss: -0.5966  Acc@1: 87.5000 (87.2433)  Acc@5: 100.0000 (98.4878)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 910/3125]  eta: 0:12:53  Lr: 0.001875  Loss: -0.7021  Acc@1: 87.5000 (87.2050)  Acc@5: 100.0000 (98.4769)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 920/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.7225  Acc@1: 87.5000 (87.2014)  Acc@5: 100.0000 (98.4731)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 930/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.7881  Acc@1: 87.5000 (87.1979)  Acc@5: 100.0000 (98.4761)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 940/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.6635  Acc@1: 87.5000 (87.1878)  Acc@5: 100.0000 (98.4724)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 950/3125]  eta: 0:12:39  Lr: 0.001875  Loss: -0.8284  Acc@1: 87.5000 (87.1648)  Acc@5: 100.0000 (98.4621)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 960/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.5981  Acc@1: 87.5000 (87.2138)  Acc@5: 100.0000 (98.4716)  time: 0.3504  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 970/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.6932  Acc@1: 93.7500 (87.2297)  Acc@5: 100.0000 (98.4809)  time: 0.3521  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 980/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.4958  Acc@1: 87.5000 (87.2133)  Acc@5: 100.0000 (98.4709)  time: 0.3532  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 990/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.4473  Acc@1: 87.5000 (87.2036)  Acc@5: 100.0000 (98.4738)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1000/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.7331  Acc@1: 87.5000 (87.1878)  Acc@5: 100.0000 (98.4828)  time: 0.3504  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.7516  Acc@1: 81.2500 (87.1724)  Acc@5: 100.0000 (98.4792)  time: 0.3510  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1020/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.5297  Acc@1: 87.5000 (87.1572)  Acc@5: 100.0000 (98.4635)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.7848  Acc@1: 87.5000 (87.1848)  Acc@5: 100.0000 (98.4663)  time: 0.3498  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1040/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.5704  Acc@1: 87.5000 (87.1578)  Acc@5: 100.0000 (98.4510)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.5115  Acc@1: 87.5000 (87.2086)  Acc@5: 100.0000 (98.4598)  time: 0.3499  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1060/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.5242  Acc@1: 87.5000 (87.1760)  Acc@5: 100.0000 (98.4684)  time: 0.3508  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.5192  Acc@1: 87.5000 (87.1790)  Acc@5: 100.0000 (98.4769)  time: 0.3511  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1080/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.7014  Acc@1: 87.5000 (87.1762)  Acc@5: 100.0000 (98.4794)  time: 0.3546  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.4522  Acc@1: 87.5000 (87.1735)  Acc@5: 100.0000 (98.4934)  time: 0.3538  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1100/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.6866  Acc@1: 87.5000 (87.1878)  Acc@5: 100.0000 (98.4957)  time: 0.3501  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.5264  Acc@1: 87.5000 (87.1850)  Acc@5: 100.0000 (98.4811)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1120/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.6082  Acc@1: 87.5000 (87.1822)  Acc@5: 100.0000 (98.4891)  time: 0.3538  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.8511  Acc@1: 87.5000 (87.1795)  Acc@5: 100.0000 (98.4803)  time: 0.3527  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1140/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.2473  Acc@1: 81.2500 (87.1275)  Acc@5: 100.0000 (98.4663)  time: 0.3478  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.5009  Acc@1: 81.2500 (87.1036)  Acc@5: 100.0000 (98.4742)  time: 0.3471  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1160/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.7884  Acc@1: 87.5000 (87.1016)  Acc@5: 100.0000 (98.4819)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.7006  Acc@1: 87.5000 (87.1531)  Acc@5: 100.0000 (98.4895)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1180/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.5709  Acc@1: 93.7500 (87.1507)  Acc@5: 100.0000 (98.4812)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.4598  Acc@1: 87.5000 (87.1641)  Acc@5: 100.0000 (98.4782)  time: 0.3454  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1200/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.4194  Acc@1: 87.5000 (87.1565)  Acc@5: 100.0000 (98.4648)  time: 0.3502  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.4703  Acc@1: 87.5000 (87.1645)  Acc@5: 100.0000 (98.4672)  time: 0.3531  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1220/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.4813  Acc@1: 87.5000 (87.1468)  Acc@5: 100.0000 (98.4695)  time: 0.3523  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.8460  Acc@1: 87.5000 (87.1598)  Acc@5: 100.0000 (98.4616)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1240/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.3867  Acc@1: 87.5000 (87.1172)  Acc@5: 100.0000 (98.4539)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.4038  Acc@1: 81.2500 (87.0254)  Acc@5: 100.0000 (98.4462)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1260/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.5112  Acc@1: 81.2500 (87.0341)  Acc@5: 100.0000 (98.4536)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.4688  Acc@1: 87.5000 (87.0181)  Acc@5: 100.0000 (98.4559)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1280/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.3256  Acc@1: 87.5000 (87.0316)  Acc@5: 100.0000 (98.4485)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.6104  Acc@1: 87.5000 (87.0546)  Acc@5: 100.0000 (98.4557)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1300/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.4766  Acc@1: 93.7500 (87.0772)  Acc@5: 100.0000 (98.4579)  time: 0.3522  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.5472  Acc@1: 87.5000 (87.0852)  Acc@5: 100.0000 (98.4601)  time: 0.3508  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1320/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.6015  Acc@1: 87.5000 (87.0789)  Acc@5: 100.0000 (98.4529)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.4573  Acc@1: 87.5000 (87.0821)  Acc@5: 100.0000 (98.4598)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1340/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.8355  Acc@1: 93.7500 (87.0992)  Acc@5: 100.0000 (98.4666)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.4272  Acc@1: 93.7500 (87.0883)  Acc@5: 100.0000 (98.4641)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1360/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.5936  Acc@1: 81.2500 (87.0821)  Acc@5: 100.0000 (98.4570)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.4429  Acc@1: 87.5000 (87.0669)  Acc@5: 100.0000 (98.4637)  time: 0.3463  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1380/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.6709  Acc@1: 87.5000 (87.0655)  Acc@5: 100.0000 (98.4658)  time: 0.3461  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1390/3125]  eta: 0:10:05  Lr: 0.001875  Loss: -0.7677  Acc@1: 87.5000 (87.0821)  Acc@5: 100.0000 (98.4723)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1400/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.5099  Acc@1: 87.5000 (87.0896)  Acc@5: 100.0000 (98.4788)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1410/3125]  eta: 0:09:58  Lr: 0.001875  Loss: -0.6835  Acc@1: 87.5000 (87.0792)  Acc@5: 100.0000 (98.4895)  time: 0.3457  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.7145  Acc@1: 87.5000 (87.0690)  Acc@5: 100.0000 (98.4914)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1430/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.3341  Acc@1: 87.5000 (87.0763)  Acc@5: 100.0000 (98.4757)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7324  Acc@1: 87.5000 (87.0749)  Acc@5: 100.0000 (98.4733)  time: 0.3496  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1450/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.6556  Acc@1: 87.5000 (87.0606)  Acc@5: 100.0000 (98.4752)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.7818  Acc@1: 81.2500 (87.0594)  Acc@5: 100.0000 (98.4813)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1470/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.5908  Acc@1: 87.5000 (87.0581)  Acc@5: 100.0000 (98.4747)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.7088  Acc@1: 87.5000 (87.0400)  Acc@5: 100.0000 (98.4765)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1490/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.6772  Acc@1: 87.5000 (87.0305)  Acc@5: 100.0000 (98.4742)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1500/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.7031  Acc@1: 87.5000 (87.0461)  Acc@5: 100.0000 (98.4719)  time: 0.3522  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.5252  Acc@1: 87.5000 (87.0367)  Acc@5: 100.0000 (98.4778)  time: 0.3517  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1520/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.4188  Acc@1: 87.5000 (87.0274)  Acc@5: 100.0000 (98.4796)  time: 0.3540  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.6895  Acc@1: 87.5000 (87.0224)  Acc@5: 100.0000 (98.4855)  time: 0.3536  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1540/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.6392  Acc@1: 87.5000 (87.0295)  Acc@5: 100.0000 (98.4872)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.4166  Acc@1: 87.5000 (87.0245)  Acc@5: 100.0000 (98.4848)  time: 0.3517  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1560/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.6812  Acc@1: 81.2500 (86.9875)  Acc@5: 100.0000 (98.4865)  time: 0.3502  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.5115  Acc@1: 81.2500 (86.9709)  Acc@5: 100.0000 (98.4922)  time: 0.3493  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1580/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.3818  Acc@1: 87.5000 (86.9782)  Acc@5: 100.0000 (98.4859)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.2866  Acc@1: 87.5000 (87.0050)  Acc@5: 100.0000 (98.4915)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1600/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.7638  Acc@1: 87.5000 (86.9964)  Acc@5: 100.0000 (98.4931)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.7739  Acc@1: 87.5000 (87.0189)  Acc@5: 100.0000 (98.4986)  time: 0.3467  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1620/3125]  eta: 0:08:45  Lr: 0.001875  Loss: -0.5718  Acc@1: 87.5000 (87.0103)  Acc@5: 100.0000 (98.5002)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.7690  Acc@1: 87.5000 (87.0325)  Acc@5: 100.0000 (98.5094)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1640/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.4262  Acc@1: 93.7500 (87.0620)  Acc@5: 100.0000 (98.5108)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.8367  Acc@1: 93.7500 (87.0684)  Acc@5: 100.0000 (98.5123)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1660/3125]  eta: 0:08:31  Lr: 0.001875  Loss: -0.5429  Acc@1: 87.5000 (87.0710)  Acc@5: 100.0000 (98.5099)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.6286  Acc@1: 87.5000 (87.0773)  Acc@5: 100.0000 (98.5039)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1680/3125]  eta: 0:08:24  Lr: 0.001875  Loss: -0.2440  Acc@1: 87.5000 (87.0538)  Acc@5: 100.0000 (98.4979)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3697  Acc@1: 87.5000 (87.0676)  Acc@5: 100.0000 (98.4957)  time: 0.3452  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1700/3125]  eta: 0:08:17  Lr: 0.001875  Loss: -0.3201  Acc@1: 87.5000 (87.0628)  Acc@5: 100.0000 (98.5046)  time: 0.3467  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.5708  Acc@1: 87.5000 (87.0653)  Acc@5: 100.0000 (98.5060)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1720/3125]  eta: 0:08:10  Lr: 0.001875  Loss: 0.0822  Acc@1: 87.5000 (87.0787)  Acc@5: 100.0000 (98.5038)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.7756  Acc@1: 87.5000 (87.0595)  Acc@5: 100.0000 (98.5016)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1740/3125]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6116  Acc@1: 87.5000 (87.0800)  Acc@5: 100.0000 (98.5066)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1750/3125]  eta: 0:07:59  Lr: 0.001875  Loss: -0.7223  Acc@1: 87.5000 (87.0610)  Acc@5: 100.0000 (98.5009)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1760/3125]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7737  Acc@1: 87.5000 (87.0741)  Acc@5: 100.0000 (98.5094)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1770/3125]  eta: 0:07:52  Lr: 0.001875  Loss: -0.9053  Acc@1: 87.5000 (87.0589)  Acc@5: 100.0000 (98.5001)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1780/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.7291  Acc@1: 87.5000 (87.0859)  Acc@5: 100.0000 (98.5051)  time: 0.3466  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1790/3125]  eta: 0:07:45  Lr: 0.001875  Loss: -0.3170  Acc@1: 93.7500 (87.0777)  Acc@5: 100.0000 (98.5029)  time: 0.3503  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1800/3125]  eta: 0:07:42  Lr: 0.001875  Loss: -0.4521  Acc@1: 87.5000 (87.0627)  Acc@5: 100.0000 (98.5043)  time: 0.3503  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.7484  Acc@1: 87.5000 (87.0686)  Acc@5: 100.0000 (98.5022)  time: 0.3517  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1820/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.5699  Acc@1: 87.5000 (87.0607)  Acc@5: 100.0000 (98.5036)  time: 0.3515  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.2322  Acc@1: 87.5000 (87.0665)  Acc@5: 100.0000 (98.5083)  time: 0.3506  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1840/3125]  eta: 0:07:28  Lr: 0.001875  Loss: -0.5262  Acc@1: 93.7500 (87.0926)  Acc@5: 100.0000 (98.5062)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.5996  Acc@1: 87.5000 (87.1049)  Acc@5: 100.0000 (98.5076)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1860/3125]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6524  Acc@1: 87.5000 (87.0936)  Acc@5: 100.0000 (98.5089)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.2533  Acc@1: 87.5000 (87.0891)  Acc@5: 100.0000 (98.5135)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1880/3125]  eta: 0:07:14  Lr: 0.001875  Loss: -0.7100  Acc@1: 87.5000 (87.0980)  Acc@5: 100.0000 (98.5114)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.7705  Acc@1: 87.5000 (87.1001)  Acc@5: 100.0000 (98.5028)  time: 0.3501  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:07  Lr: 0.001875  Loss: -0.8006  Acc@1: 87.5000 (87.1186)  Acc@5: 100.0000 (98.5041)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.6207  Acc@1: 87.5000 (87.0977)  Acc@5: 100.0000 (98.5054)  time: 0.3493  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1920/3125]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5205  Acc@1: 87.5000 (87.0998)  Acc@5: 100.0000 (98.5001)  time: 0.3497  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.3775  Acc@1: 87.5000 (87.0889)  Acc@5: 100.0000 (98.4982)  time: 0.3495  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1940/3125]  eta: 0:06:53  Lr: 0.001875  Loss: -0.5927  Acc@1: 93.7500 (87.1168)  Acc@5: 100.0000 (98.4995)  time: 0.3487  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: 0.0626  Acc@1: 93.7500 (87.1060)  Acc@5: 100.0000 (98.4944)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1960/3125]  eta: 0:06:46  Lr: 0.001875  Loss: -0.7783  Acc@1: 81.2500 (87.1016)  Acc@5: 100.0000 (98.4893)  time: 0.3526  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.3268  Acc@1: 81.2500 (87.0783)  Acc@5: 100.0000 (98.4938)  time: 0.3534  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1980/3125]  eta: 0:06:39  Lr: 0.001875  Loss: -0.7284  Acc@1: 81.2500 (87.0709)  Acc@5: 100.0000 (98.4982)  time: 0.3521  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.9059  Acc@1: 87.5000 (87.0731)  Acc@5: 100.0000 (98.4932)  time: 0.3549  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2000/3125]  eta: 0:06:32  Lr: 0.001875  Loss: -0.4955  Acc@1: 87.5000 (87.0721)  Acc@5: 100.0000 (98.4883)  time: 0.3536  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.4719  Acc@1: 87.5000 (87.0835)  Acc@5: 100.0000 (98.4896)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2020/3125]  eta: 0:06:25  Lr: 0.001875  Loss: -0.8345  Acc@1: 87.5000 (87.0701)  Acc@5: 100.0000 (98.4970)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: 0.4788  Acc@1: 87.5000 (87.0692)  Acc@5: 100.0000 (98.4921)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2040/3125]  eta: 0:06:18  Lr: 0.001875  Loss: -0.8476  Acc@1: 87.5000 (87.0407)  Acc@5: 100.0000 (98.4842)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: 0.0647  Acc@1: 87.5000 (87.0399)  Acc@5: 100.0000 (98.4885)  time: 0.3516  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:11  Lr: 0.001875  Loss: -0.5308  Acc@1: 87.5000 (87.0482)  Acc@5: 100.0000 (98.4959)  time: 0.3525  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.5795  Acc@1: 87.5000 (87.0473)  Acc@5: 100.0000 (98.5001)  time: 0.3521  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2080/3125]  eta: 0:06:04  Lr: 0.001875  Loss: -0.4640  Acc@1: 87.5000 (87.0525)  Acc@5: 100.0000 (98.5043)  time: 0.3522  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.8012  Acc@1: 87.5000 (87.0516)  Acc@5: 100.0000 (98.5085)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.7218  Acc@1: 81.2500 (87.0359)  Acc@5: 100.0000 (98.5156)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.4456  Acc@1: 87.5000 (87.0381)  Acc@5: 100.0000 (98.5197)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.6437  Acc@1: 87.5000 (87.0433)  Acc@5: 100.0000 (98.5266)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.3758  Acc@1: 87.5000 (87.0278)  Acc@5: 100.0000 (98.5189)  time: 0.3504  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.2311  Acc@1: 87.5000 (87.0329)  Acc@5: 100.0000 (98.5200)  time: 0.3501  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.5789  Acc@1: 87.5000 (87.0322)  Acc@5: 100.0000 (98.5268)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.5506  Acc@1: 87.5000 (87.0257)  Acc@5: 100.0000 (98.5279)  time: 0.3495  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.7550  Acc@1: 87.5000 (87.0077)  Acc@5: 100.0000 (98.5318)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4478  Acc@1: 81.2500 (86.9985)  Acc@5: 100.0000 (98.5299)  time: 0.3542  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.3807  Acc@1: 87.5000 (86.9979)  Acc@5: 100.0000 (98.5338)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.9051  Acc@1: 87.5000 (87.0031)  Acc@5: 100.0000 (98.5291)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.6727  Acc@1: 93.7500 (87.0110)  Acc@5: 100.0000 (98.5301)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.6915  Acc@1: 87.5000 (87.0160)  Acc@5: 100.0000 (98.5283)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.9163  Acc@1: 87.5000 (87.0266)  Acc@5: 100.0000 (98.5264)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.8356  Acc@1: 87.5000 (87.0315)  Acc@5: 100.0000 (98.5274)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.8232  Acc@1: 87.5000 (87.0585)  Acc@5: 100.0000 (98.5284)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.7947  Acc@1: 93.7500 (87.0771)  Acc@5: 100.0000 (98.5349)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.4152  Acc@1: 87.5000 (87.0789)  Acc@5: 100.0000 (98.5414)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: 0.1113  Acc@1: 87.5000 (87.0589)  Acc@5: 100.0000 (98.5396)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.4742  Acc@1: 87.5000 (87.0771)  Acc@5: 100.0000 (98.5459)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.5482  Acc@1: 87.5000 (87.0681)  Acc@5: 100.0000 (98.5414)  time: 0.3470  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.6641  Acc@1: 87.5000 (87.0862)  Acc@5: 100.0000 (98.5450)  time: 0.3494  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.6904  Acc@1: 87.5000 (87.0799)  Acc@5: 100.0000 (98.5432)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.8064  Acc@1: 81.2500 (87.0603)  Acc@5: 100.0000 (98.5360)  time: 0.3525  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.6249  Acc@1: 87.5000 (87.0702)  Acc@5: 100.0000 (98.5396)  time: 0.3530  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.7773  Acc@1: 87.5000 (87.0693)  Acc@5: 100.0000 (98.5405)  time: 0.3565  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5474  Acc@1: 87.5000 (87.0712)  Acc@5: 100.0000 (98.5440)  time: 0.3568  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.3551  Acc@1: 87.5000 (87.0756)  Acc@5: 100.0000 (98.5370)  time: 0.3496  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7820  Acc@1: 87.5000 (87.0826)  Acc@5: 100.0000 (98.5405)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.4954  Acc@1: 87.5000 (87.0792)  Acc@5: 100.0000 (98.5440)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.6535  Acc@1: 87.5000 (87.0835)  Acc@5: 100.0000 (98.5449)  time: 0.3536  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.5100  Acc@1: 87.5000 (87.0852)  Acc@5: 100.0000 (98.5405)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.7378  Acc@1: 87.5000 (87.0973)  Acc@5: 100.0000 (98.5440)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.7031  Acc@1: 87.5000 (87.0912)  Acc@5: 100.0000 (98.5448)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.5602  Acc@1: 87.5000 (87.1031)  Acc@5: 100.0000 (98.5482)  time: 0.3473  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6858  Acc@1: 87.5000 (87.1124)  Acc@5: 100.0000 (98.5516)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.7254  Acc@1: 87.5000 (87.0962)  Acc@5: 100.0000 (98.5550)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.3254  Acc@1: 87.5000 (87.0978)  Acc@5: 100.0000 (98.5583)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.4494  Acc@1: 87.5000 (87.0818)  Acc@5: 100.0000 (98.5565)  time: 0.3455  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.5092  Acc@1: 87.5000 (87.0860)  Acc@5: 100.0000 (98.5573)  time: 0.3450  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.9207  Acc@1: 87.5000 (87.0927)  Acc@5: 100.0000 (98.5606)  time: 0.3447  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.4369  Acc@1: 87.5000 (87.0843)  Acc@5: 100.0000 (98.5613)  time: 0.3449  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.8840  Acc@1: 87.5000 (87.0959)  Acc@5: 100.0000 (98.5596)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.5089  Acc@1: 87.5000 (87.1197)  Acc@5: 100.0000 (98.5653)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.6586  Acc@1: 87.5000 (87.1261)  Acc@5: 100.0000 (98.5660)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.7624  Acc@1: 87.5000 (87.1374)  Acc@5: 100.0000 (98.5643)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.7294  Acc@1: 87.5000 (87.1339)  Acc@5: 100.0000 (98.5601)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.4622  Acc@1: 87.5000 (87.1426)  Acc@5: 100.0000 (98.5609)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.5855  Acc@1: 87.5000 (87.1586)  Acc@5: 100.0000 (98.5616)  time: 0.3512  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.8788  Acc@1: 87.5000 (87.1551)  Acc@5: 100.0000 (98.5623)  time: 0.3531  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.4737  Acc@1: 87.5000 (87.1540)  Acc@5: 100.0000 (98.5631)  time: 0.3524  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.5253  Acc@1: 87.5000 (87.1601)  Acc@5: 100.0000 (98.5662)  time: 0.3528  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.6075  Acc@1: 87.5000 (87.1638)  Acc@5: 100.0000 (98.5716)  time: 0.3521  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.0876  Acc@1: 87.5000 (87.1532)  Acc@5: 100.0000 (98.5676)  time: 0.3510  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.4641  Acc@1: 87.5000 (87.1521)  Acc@5: 100.0000 (98.5659)  time: 0.3514  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.4672  Acc@1: 87.5000 (87.1393)  Acc@5: 100.0000 (98.5619)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6657  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.5626)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.7246  Acc@1: 87.5000 (87.1373)  Acc@5: 100.0000 (98.5539)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.5494  Acc@1: 81.2500 (87.1270)  Acc@5: 100.0000 (98.5523)  time: 0.3493  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5331  Acc@1: 81.2500 (87.1237)  Acc@5: 100.0000 (98.5530)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.7636  Acc@1: 87.5000 (87.1344)  Acc@5: 100.0000 (98.5538)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.4348  Acc@1: 87.5000 (87.1473)  Acc@5: 100.0000 (98.5545)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.4650  Acc@1: 87.5000 (87.1532)  Acc@5: 100.0000 (98.5529)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.7567  Acc@1: 87.5000 (87.1613)  Acc@5: 100.0000 (98.5536)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.4322  Acc@1: 87.5000 (87.1625)  Acc@5: 100.0000 (98.5589)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4323  Acc@1: 87.5000 (87.1569)  Acc@5: 100.0000 (98.5573)  time: 0.3494  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6327  Acc@1: 87.5000 (87.1537)  Acc@5: 100.0000 (98.5580)  time: 0.3487  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.6404  Acc@1: 87.5000 (87.1617)  Acc@5: 100.0000 (98.5610)  time: 0.3555  data: 0.0024  max mem: 2502
Train: Epoch[5/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4970  Acc@1: 87.5000 (87.1674)  Acc@5: 100.0000 (98.5594)  time: 0.3571  data: 0.0026  max mem: 2502
Train: Epoch[5/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.6899  Acc@1: 87.5000 (87.1731)  Acc@5: 100.0000 (98.5556)  time: 0.3553  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.9206  Acc@1: 93.7500 (87.1876)  Acc@5: 100.0000 (98.5586)  time: 0.3583  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.6978  Acc@1: 87.5000 (87.1843)  Acc@5: 100.0000 (98.5592)  time: 0.3532  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.6383  Acc@1: 93.7500 (87.2009)  Acc@5: 100.0000 (98.5599)  time: 0.3503  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.7314  Acc@1: 93.7500 (87.2064)  Acc@5: 100.0000 (98.5540)  time: 0.3501  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.7339  Acc@1: 87.5000 (87.2118)  Acc@5: 100.0000 (98.5546)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.7878  Acc@1: 87.5000 (87.2128)  Acc@5: 100.0000 (98.5597)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.4929  Acc@1: 87.5000 (87.2095)  Acc@5: 100.0000 (98.5582)  time: 0.3501  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.5873  Acc@1: 87.5000 (87.2148)  Acc@5: 100.0000 (98.5567)  time: 0.3490  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6494  Acc@1: 87.5000 (87.2115)  Acc@5: 100.0000 (98.5530)  time: 0.3484  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.1883  Acc@1: 87.5000 (87.2125)  Acc@5: 100.0000 (98.5472)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5860  Acc@1: 87.5000 (87.2178)  Acc@5: 100.0000 (98.5522)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7024  Acc@1: 87.5000 (87.2166)  Acc@5: 100.0000 (98.5508)  time: 0.3482  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8967  Acc@1: 87.5000 (87.2111)  Acc@5: 100.0000 (98.5514)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7980  Acc@1: 87.5000 (87.1993)  Acc@5: 100.0000 (98.5521)  time: 0.3483  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.1841  Acc@1: 81.2500 (87.1855)  Acc@5: 100.0000 (98.5549)  time: 0.3496  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.3190  Acc@1: 87.5000 (87.1908)  Acc@5: 100.0000 (98.5513)  time: 0.3508  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6267  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.5520)  time: 0.3520  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.3943  Acc@1: 87.5000 (87.1971)  Acc@5: 100.0000 (98.5527)  time: 0.3519  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6479  Acc@1: 87.5000 (87.1939)  Acc@5: 100.0000 (98.5575)  time: 0.3545  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.2154  Acc@1: 87.5000 (87.1866)  Acc@5: 100.0000 (98.5561)  time: 0.3540  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.6375  Acc@1: 87.5000 (87.1876)  Acc@5: 100.0000 (98.5546)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3613  Acc@1: 87.5000 (87.1907)  Acc@5: 100.0000 (98.5574)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.6808  Acc@1: 93.7500 (87.2083)  Acc@5: 100.0000 (98.5559)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6606  Acc@1: 87.5000 (87.1948)  Acc@5: 100.0000 (98.5545)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5513  Acc@1: 87.5000 (87.1938)  Acc@5: 100.0000 (98.5552)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5401  Acc@1: 87.5000 (87.1989)  Acc@5: 100.0000 (98.5517)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.8597  Acc@1: 87.5000 (87.2080)  Acc@5: 100.0000 (98.5503)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.5810  Acc@1: 87.5000 (87.2008)  Acc@5: 100.0000 (98.5530)  time: 0.3461  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.7969  Acc@1: 87.5000 (87.1998)  Acc@5: 100.0000 (98.5536)  time: 0.3458  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.5973  Acc@1: 87.5000 (87.1947)  Acc@5: 100.0000 (98.5543)  time: 0.3469  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.4438  Acc@1: 87.5000 (87.1836)  Acc@5: 100.0000 (98.5589)  time: 0.3461  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5529  Acc@1: 81.2500 (87.1826)  Acc@5: 100.0000 (98.5595)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.7711  Acc@1: 87.5000 (87.1816)  Acc@5: 100.0000 (98.5602)  time: 0.3462  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4802  Acc@1: 87.5000 (87.1860)  Acc@5: 100.0000 (98.5620)  time: 0.3458  data: 0.0007  max mem: 2502
Train: Epoch[5/5] Total time: 0:18:12 (0.3495 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 0, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 0, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4802  Acc@1: 87.5000 (87.1860)  Acc@5: 100.0000 (98.5620)
Test: [Task 1]  [   0/1627]  eta: 0:14:42  Loss: 1.2027 (1.2027)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5424  data: 0.3280  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:33  Loss: 1.1901 (1.0979)  Acc@1: 68.7500 (69.3182)  Acc@5: 93.7500 (94.3182)  time: 0.2433  data: 0.0301  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:08  Loss: 1.0968 (1.0734)  Acc@1: 68.7500 (71.1310)  Acc@5: 93.7500 (93.7500)  time: 0.2139  data: 0.0006  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:05:58  Loss: 1.0453 (1.0758)  Acc@1: 75.0000 (71.5726)  Acc@5: 93.7500 (93.7500)  time: 0.2146  data: 0.0007  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:05:53  Loss: 1.1378 (1.0999)  Acc@1: 68.7500 (70.1220)  Acc@5: 93.7500 (93.5976)  time: 0.2155  data: 0.0009  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:48  Loss: 1.1377 (1.0743)  Acc@1: 68.7500 (71.3235)  Acc@5: 93.7500 (93.8725)  time: 0.2159  data: 0.0011  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:45  Loss: 1.1377 (1.0965)  Acc@1: 75.0000 (70.5943)  Acc@5: 93.7500 (93.5451)  time: 0.2151  data: 0.0007  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:41  Loss: 1.0481 (1.0881)  Acc@1: 68.7500 (71.1268)  Acc@5: 93.7500 (93.5739)  time: 0.2152  data: 0.0008  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:39  Loss: 0.8821 (1.0767)  Acc@1: 75.0000 (71.5278)  Acc@5: 93.7500 (93.9043)  time: 0.2167  data: 0.0010  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:36  Loss: 1.0081 (1.0894)  Acc@1: 68.7500 (70.9478)  Acc@5: 93.7500 (93.7500)  time: 0.2166  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:33  Loss: 1.1846 (1.1088)  Acc@1: 68.7500 (70.5446)  Acc@5: 87.5000 (93.2550)  time: 0.2158  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:31  Loss: 1.0042 (1.0969)  Acc@1: 68.7500 (70.7770)  Acc@5: 93.7500 (93.6937)  time: 0.2165  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:29  Loss: 1.0042 (1.0951)  Acc@1: 68.7500 (70.9711)  Acc@5: 93.7500 (93.6983)  time: 0.2169  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:26  Loss: 1.0864 (1.0975)  Acc@1: 68.7500 (70.8015)  Acc@5: 93.7500 (93.7500)  time: 0.2164  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:24  Loss: 1.0673 (1.0922)  Acc@1: 68.7500 (70.8777)  Acc@5: 93.7500 (93.7057)  time: 0.2165  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:21  Loss: 0.8127 (1.0744)  Acc@1: 75.0000 (71.3576)  Acc@5: 93.7500 (93.8328)  time: 0.2164  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:19  Loss: 0.8216 (1.0701)  Acc@1: 75.0000 (71.5839)  Acc@5: 100.0000 (93.8665)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:17  Loss: 0.8871 (1.0611)  Acc@1: 75.0000 (71.7471)  Acc@5: 100.0000 (94.0789)  time: 0.2157  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:14  Loss: 1.1108 (1.0720)  Acc@1: 68.7500 (71.4434)  Acc@5: 100.0000 (93.9227)  time: 0.2153  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:12  Loss: 1.1108 (1.0693)  Acc@1: 68.7500 (71.5641)  Acc@5: 93.7500 (93.9463)  time: 0.2156  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:10  Loss: 1.0284 (1.0679)  Acc@1: 75.0000 (71.7662)  Acc@5: 93.7500 (94.0920)  time: 0.2156  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:07  Loss: 1.0284 (1.0662)  Acc@1: 75.0000 (72.0083)  Acc@5: 100.0000 (94.1055)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:05  Loss: 0.8983 (1.0690)  Acc@1: 75.0000 (72.0305)  Acc@5: 93.7500 (94.0611)  time: 0.2170  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:03  Loss: 0.8983 (1.0608)  Acc@1: 75.0000 (72.3214)  Acc@5: 93.7500 (94.1558)  time: 0.2165  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:01  Loss: 0.9484 (1.0575)  Acc@1: 75.0000 (72.3288)  Acc@5: 93.7500 (94.1909)  time: 0.2162  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:04:59  Loss: 0.9625 (1.0626)  Acc@1: 68.7500 (72.3108)  Acc@5: 93.7500 (94.1484)  time: 0.2173  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:04:57  Loss: 0.9625 (1.0623)  Acc@1: 68.7500 (72.3659)  Acc@5: 93.7500 (94.1331)  time: 0.2190  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:54  Loss: 0.9005 (1.0555)  Acc@1: 75.0000 (72.4631)  Acc@5: 100.0000 (94.2574)  time: 0.2194  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:52  Loss: 0.8685 (1.0569)  Acc@1: 75.0000 (72.5311)  Acc@5: 93.7500 (94.1504)  time: 0.2169  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:50  Loss: 1.0528 (1.0572)  Acc@1: 75.0000 (72.4871)  Acc@5: 93.7500 (94.2010)  time: 0.2175  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:48  Loss: 1.0267 (1.0558)  Acc@1: 75.0000 (72.4668)  Acc@5: 100.0000 (94.2276)  time: 0.2200  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:46  Loss: 0.9236 (1.0577)  Acc@1: 75.0000 (72.4477)  Acc@5: 93.7500 (94.2323)  time: 0.2179  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:44  Loss: 1.0216 (1.0557)  Acc@1: 75.0000 (72.4104)  Acc@5: 93.7500 (94.2757)  time: 0.2153  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:41  Loss: 0.9712 (1.0542)  Acc@1: 75.0000 (72.4887)  Acc@5: 93.7500 (94.2976)  time: 0.2151  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:39  Loss: 0.9510 (1.0542)  Acc@1: 75.0000 (72.5257)  Acc@5: 93.7500 (94.3365)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:37  Loss: 1.0061 (1.0532)  Acc@1: 75.0000 (72.5962)  Acc@5: 93.7500 (94.2842)  time: 0.2152  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:35  Loss: 1.0099 (1.0522)  Acc@1: 81.2500 (72.7147)  Acc@5: 93.7500 (94.2348)  time: 0.2153  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:32  Loss: 0.9951 (1.0514)  Acc@1: 75.0000 (72.6078)  Acc@5: 93.7500 (94.2722)  time: 0.2157  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:30  Loss: 0.9782 (1.0503)  Acc@1: 68.7500 (72.5394)  Acc@5: 93.7500 (94.2749)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:28  Loss: 0.9879 (1.0516)  Acc@1: 68.7500 (72.5064)  Acc@5: 93.7500 (94.2455)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:26  Loss: 1.0485 (1.0528)  Acc@1: 75.0000 (72.4595)  Acc@5: 93.7500 (94.2643)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:24  Loss: 0.9921 (1.0540)  Acc@1: 68.7500 (72.4300)  Acc@5: 93.7500 (94.2214)  time: 0.2154  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:21  Loss: 0.9921 (1.0534)  Acc@1: 68.7500 (72.4466)  Acc@5: 93.7500 (94.2548)  time: 0.2153  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:19  Loss: 0.9242 (1.0521)  Acc@1: 68.7500 (72.4188)  Acc@5: 93.7500 (94.2865)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:17  Loss: 1.0522 (1.0516)  Acc@1: 68.7500 (72.4773)  Acc@5: 93.7500 (94.3311)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:15  Loss: 1.1313 (1.0552)  Acc@1: 68.7500 (72.3254)  Acc@5: 93.7500 (94.2627)  time: 0.2151  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 1.0222 (1.0544)  Acc@1: 68.7500 (72.3427)  Acc@5: 93.7500 (94.2652)  time: 0.2161  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:10  Loss: 0.8957 (1.0512)  Acc@1: 75.0000 (72.4788)  Acc@5: 93.7500 (94.2941)  time: 0.2158  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:08  Loss: 1.0390 (1.0554)  Acc@1: 68.7500 (72.3753)  Acc@5: 93.7500 (94.2827)  time: 0.2152  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:06  Loss: 1.0735 (1.0556)  Acc@1: 68.7500 (72.3523)  Acc@5: 93.7500 (94.2592)  time: 0.2167  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:04  Loss: 0.9554 (1.0567)  Acc@1: 75.0000 (72.3678)  Acc@5: 93.7500 (94.2241)  time: 0.2169  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:02  Loss: 1.0271 (1.0624)  Acc@1: 75.0000 (72.2970)  Acc@5: 93.7500 (94.1536)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 1.1494 (1.0701)  Acc@1: 68.7500 (72.1689)  Acc@5: 93.7500 (94.0739)  time: 0.2158  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:03:57  Loss: 1.0078 (1.0658)  Acc@1: 75.0000 (72.3635)  Acc@5: 93.7500 (94.1031)  time: 0.2159  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:55  Loss: 0.9915 (1.0655)  Acc@1: 75.0000 (72.3891)  Acc@5: 93.7500 (94.0850)  time: 0.2156  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:53  Loss: 1.1956 (1.0680)  Acc@1: 68.7500 (72.3004)  Acc@5: 93.7500 (94.0676)  time: 0.2161  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:51  Loss: 1.2560 (1.0705)  Acc@1: 62.5000 (72.1925)  Acc@5: 93.7500 (94.0954)  time: 0.2189  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:49  Loss: 1.0283 (1.0691)  Acc@1: 68.7500 (72.2417)  Acc@5: 93.7500 (94.1003)  time: 0.2179  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:46  Loss: 1.0245 (1.0694)  Acc@1: 68.7500 (72.1816)  Acc@5: 93.7500 (94.0942)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:44  Loss: 1.0810 (1.0687)  Acc@1: 68.7500 (72.1129)  Acc@5: 93.7500 (94.1413)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:42  Loss: 1.0187 (1.0704)  Acc@1: 68.7500 (72.0882)  Acc@5: 93.7500 (94.1348)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:40  Loss: 1.0668 (1.0698)  Acc@1: 75.0000 (72.1052)  Acc@5: 93.7500 (94.1592)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:38  Loss: 1.0923 (1.0714)  Acc@1: 68.7500 (72.0511)  Acc@5: 93.7500 (94.1023)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 0.9202 (1.0719)  Acc@1: 75.0000 (72.0880)  Acc@5: 93.7500 (94.1363)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 0.9193 (1.0719)  Acc@1: 75.0000 (72.1334)  Acc@5: 93.7500 (94.1205)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:31  Loss: 0.9614 (1.0716)  Acc@1: 75.0000 (72.1486)  Acc@5: 93.7500 (94.1436)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:29  Loss: 0.9858 (1.0708)  Acc@1: 75.0000 (72.1823)  Acc@5: 100.0000 (94.1471)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:27  Loss: 1.0980 (1.0706)  Acc@1: 75.0000 (72.2243)  Acc@5: 93.7500 (94.1226)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 1.0365 (1.0701)  Acc@1: 75.0000 (72.2375)  Acc@5: 93.7500 (94.1355)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 1.0055 (1.0681)  Acc@1: 75.0000 (72.3137)  Acc@5: 100.0000 (94.1661)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 1.0756 (1.0683)  Acc@1: 75.0000 (72.3252)  Acc@5: 93.7500 (94.1780)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 1.0515 (1.0662)  Acc@1: 75.0000 (72.3805)  Acc@5: 93.7500 (94.1983)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:16  Loss: 0.9298 (1.0646)  Acc@1: 75.0000 (72.4168)  Acc@5: 93.7500 (94.2094)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 0.9853 (1.0654)  Acc@1: 75.0000 (72.3752)  Acc@5: 93.7500 (94.2117)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 1.0620 (1.0670)  Acc@1: 68.7500 (72.3431)  Acc@5: 93.7500 (94.1886)  time: 0.2140  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 1.0663 (1.0657)  Acc@1: 75.0000 (72.4118)  Acc@5: 93.7500 (94.2077)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 1.1862 (1.0688)  Acc@1: 68.7500 (72.3226)  Acc@5: 93.7500 (94.1606)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 0.9298 (1.0648)  Acc@1: 75.0000 (72.4546)  Acc@5: 93.7500 (94.1877)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:03  Loss: 0.8268 (1.0626)  Acc@1: 81.2500 (72.5192)  Acc@5: 100.0000 (94.2382)  time: 0.2153  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 0.8391 (1.0643)  Acc@1: 75.0000 (72.5427)  Acc@5: 100.0000 (94.2083)  time: 0.2172  data: 0.0020  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 1.0150 (1.0627)  Acc@1: 75.0000 (72.5811)  Acc@5: 93.7500 (94.2182)  time: 0.2170  data: 0.0018  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 0.8484 (1.0616)  Acc@1: 75.0000 (72.6726)  Acc@5: 100.0000 (94.2432)  time: 0.2163  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 0.8877 (1.0613)  Acc@1: 75.0000 (72.6553)  Acc@5: 100.0000 (94.2524)  time: 0.2169  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 0.9457 (1.0612)  Acc@1: 75.0000 (72.6610)  Acc@5: 93.7500 (94.2614)  time: 0.2156  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:50  Loss: 0.8644 (1.0586)  Acc@1: 75.0000 (72.7334)  Acc@5: 100.0000 (94.3148)  time: 0.2167  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 0.8704 (1.0594)  Acc@1: 75.0000 (72.7233)  Acc@5: 100.0000 (94.3155)  time: 0.2167  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 0.9157 (1.0583)  Acc@1: 75.0000 (72.7497)  Acc@5: 93.7500 (94.3235)  time: 0.2158  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 0.8918 (1.0566)  Acc@1: 75.0000 (72.7971)  Acc@5: 100.0000 (94.3384)  time: 0.2161  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 1.0005 (1.0583)  Acc@1: 68.7500 (72.7440)  Acc@5: 100.0000 (94.3601)  time: 0.2156  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 1.0849 (1.0605)  Acc@1: 68.7500 (72.6571)  Acc@5: 93.7500 (94.3603)  time: 0.2150  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:37  Loss: 1.0849 (1.0611)  Acc@1: 62.5000 (72.6068)  Acc@5: 93.7500 (94.3604)  time: 0.2149  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 1.1068 (1.0619)  Acc@1: 68.7500 (72.6125)  Acc@5: 93.7500 (94.3332)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 1.0147 (1.0619)  Acc@1: 68.7500 (72.5841)  Acc@5: 93.7500 (94.3336)  time: 0.2173  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 1.0298 (1.0622)  Acc@1: 62.5000 (72.5363)  Acc@5: 93.7500 (94.3273)  time: 0.2164  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 1.0298 (1.0611)  Acc@1: 68.7500 (72.5558)  Acc@5: 93.7500 (94.3544)  time: 0.2175  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 1.0878 (1.0614)  Acc@1: 68.7500 (72.5026)  Acc@5: 100.0000 (94.3809)  time: 0.2198  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 1.0322 (1.0605)  Acc@1: 68.7500 (72.5156)  Acc@5: 100.0000 (94.4004)  time: 0.2180  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:22  Loss: 0.8504 (1.0592)  Acc@1: 75.0000 (72.5605)  Acc@5: 93.7500 (94.4001)  time: 0.2150  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 0.9557 (1.0593)  Acc@1: 75.0000 (72.5917)  Acc@5: 93.7500 (94.4062)  time: 0.2162  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 1.1092 (1.0622)  Acc@1: 68.7500 (72.5530)  Acc@5: 93.7500 (94.3933)  time: 0.2181  data: 0.0023  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.1794 (1.0628)  Acc@1: 68.7500 (72.5587)  Acc@5: 93.7500 (94.3744)  time: 0.2169  data: 0.0020  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 1.1000 (1.0627)  Acc@1: 75.0000 (72.5952)  Acc@5: 93.7500 (94.3620)  time: 0.2175  data: 0.0022  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 1.1079 (1.0631)  Acc@1: 75.0000 (72.5881)  Acc@5: 93.7500 (94.3438)  time: 0.2173  data: 0.0018  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.8987 (1.0609)  Acc@1: 75.0000 (72.6540)  Acc@5: 93.7500 (94.3562)  time: 0.2159  data: 0.0009  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.7957 (1.0600)  Acc@1: 75.0000 (72.6345)  Acc@5: 93.7500 (94.3684)  time: 0.2161  data: 0.0009  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.8872 (1.0585)  Acc@1: 75.0000 (72.6748)  Acc@5: 100.0000 (94.3982)  time: 0.2156  data: 0.0011  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 1.0240 (1.0588)  Acc@1: 75.0000 (72.6555)  Acc@5: 93.7500 (94.3921)  time: 0.2159  data: 0.0010  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.0572 (1.0592)  Acc@1: 68.7500 (72.6190)  Acc@5: 93.7500 (94.3978)  time: 0.2159  data: 0.0006  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 1.1066 (1.0608)  Acc@1: 68.7500 (72.5775)  Acc@5: 93.7500 (94.3918)  time: 0.2154  data: 0.0006  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 1.0952 (1.0602)  Acc@1: 68.7500 (72.5710)  Acc@5: 93.7500 (94.3916)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 0.9799 (1.0588)  Acc@1: 75.0000 (72.5988)  Acc@5: 93.7500 (94.4085)  time: 0.2166  data: 0.0006  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 0.9814 (1.0592)  Acc@1: 75.0000 (72.6260)  Acc@5: 93.7500 (94.4082)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 0.9973 (1.0605)  Acc@1: 75.0000 (72.5747)  Acc@5: 93.7500 (94.4023)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 0.9973 (1.0607)  Acc@1: 62.5000 (72.5630)  Acc@5: 93.7500 (94.4076)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.2296 (1.0623)  Acc@1: 62.5000 (72.5077)  Acc@5: 93.7500 (94.3909)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 1.3316 (1.0637)  Acc@1: 68.7500 (72.4859)  Acc@5: 87.5000 (94.3473)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 1.1449 (1.0626)  Acc@1: 75.0000 (72.5345)  Acc@5: 93.7500 (94.3745)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 0.9686 (1.0616)  Acc@1: 75.0000 (72.5769)  Acc@5: 100.0000 (94.3745)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 1.0478 (1.0621)  Acc@1: 75.0000 (72.5392)  Acc@5: 93.7500 (94.3903)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.1302 (1.0624)  Acc@1: 68.7500 (72.4969)  Acc@5: 93.7500 (94.3902)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.1302 (1.0631)  Acc@1: 68.7500 (72.4917)  Acc@5: 93.7500 (94.3537)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.9632 (1.0635)  Acc@1: 75.0000 (72.4659)  Acc@5: 93.7500 (94.3538)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 0.9663 (1.0624)  Acc@1: 75.0000 (72.4765)  Acc@5: 100.0000 (94.3745)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 0.9894 (1.0632)  Acc@1: 68.7500 (72.4310)  Acc@5: 93.7500 (94.3542)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 1.0079 (1.0630)  Acc@1: 68.7500 (72.4214)  Acc@5: 93.7500 (94.3443)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.1304 (1.0634)  Acc@1: 68.7500 (72.4121)  Acc@5: 93.7500 (94.3545)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.1304 (1.0631)  Acc@1: 68.7500 (72.4227)  Acc@5: 93.7500 (94.3448)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.0145 (1.0634)  Acc@1: 68.7500 (72.4282)  Acc@5: 93.7500 (94.3204)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 1.0145 (1.0616)  Acc@1: 75.0000 (72.4971)  Acc@5: 93.7500 (94.3404)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 1.0164 (1.0618)  Acc@1: 75.0000 (72.4923)  Acc@5: 93.7500 (94.3309)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.0706 (1.0612)  Acc@1: 75.0000 (72.5404)  Acc@5: 93.7500 (94.3313)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.8700 (1.0596)  Acc@1: 75.0000 (72.5734)  Acc@5: 93.7500 (94.3364)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.7381 (1.0584)  Acc@1: 75.0000 (72.6249)  Acc@5: 93.7500 (94.3414)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.8661 (1.0582)  Acc@1: 75.0000 (72.6334)  Acc@5: 93.7500 (94.3370)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 0.9972 (1.0588)  Acc@1: 68.7500 (72.6137)  Acc@5: 93.7500 (94.3326)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 0.9909 (1.0582)  Acc@1: 75.0000 (72.6360)  Acc@5: 93.7500 (94.3236)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.9909 (1.0580)  Acc@1: 75.0000 (72.6304)  Acc@5: 93.7500 (94.3286)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.9480 (1.0576)  Acc@1: 68.7500 (72.6249)  Acc@5: 100.0000 (94.3472)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.0169 (1.0579)  Acc@1: 68.7500 (72.5969)  Acc@5: 93.7500 (94.3474)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.1297 (1.0575)  Acc@1: 75.0000 (72.6141)  Acc@5: 93.7500 (94.3431)  time: 0.2155  data: 0.0005  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 1.0193 (1.0576)  Acc@1: 75.0000 (72.6178)  Acc@5: 93.7500 (94.3344)  time: 0.2167  data: 0.0009  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 0.9105 (1.0573)  Acc@1: 75.0000 (72.6302)  Acc@5: 93.7500 (94.3347)  time: 0.2173  data: 0.0012  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.9649 (1.0564)  Acc@1: 75.0000 (72.6293)  Acc@5: 100.0000 (94.3526)  time: 0.2159  data: 0.0008  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.1287 (1.0581)  Acc@1: 68.7500 (72.6284)  Acc@5: 93.7500 (94.3309)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1989 (1.0580)  Acc@1: 68.7500 (72.6058)  Acc@5: 93.7500 (94.3269)  time: 0.2168  data: 0.0006  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.1078 (1.0588)  Acc@1: 68.7500 (72.5879)  Acc@5: 93.7500 (94.3186)  time: 0.2161  data: 0.0010  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.0924 (1.0590)  Acc@1: 75.0000 (72.6087)  Acc@5: 93.7500 (94.3104)  time: 0.2168  data: 0.0012  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 0.9979 (1.0587)  Acc@1: 75.0000 (72.6079)  Acc@5: 93.7500 (94.3193)  time: 0.2170  data: 0.0010  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 0.9839 (1.0589)  Acc@1: 68.7500 (72.5945)  Acc@5: 100.0000 (94.3239)  time: 0.2156  data: 0.0008  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.0126 (1.0595)  Acc@1: 68.7500 (72.5813)  Acc@5: 93.7500 (94.3243)  time: 0.2169  data: 0.0015  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.0126 (1.0595)  Acc@1: 68.7500 (72.5933)  Acc@5: 93.7500 (94.3205)  time: 0.2171  data: 0.0014  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.9361 (1.0595)  Acc@1: 68.7500 (72.6092)  Acc@5: 93.7500 (94.3167)  time: 0.2165  data: 0.0007  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.9437 (1.0585)  Acc@1: 75.0000 (72.6372)  Acc@5: 93.7500 (94.3294)  time: 0.2177  data: 0.0013  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.9042 (1.0580)  Acc@1: 75.0000 (72.6486)  Acc@5: 100.0000 (94.3338)  time: 0.2164  data: 0.0012  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.8942 (1.0572)  Acc@1: 75.0000 (72.6679)  Acc@5: 100.0000 (94.3584)  time: 0.2165  data: 0.0007  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.8942 (1.0570)  Acc@1: 75.0000 (72.6870)  Acc@5: 100.0000 (94.3706)  time: 0.2175  data: 0.0010  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.8663 (1.0561)  Acc@1: 81.2500 (72.7498)  Acc@5: 93.7500 (94.3666)  time: 0.2176  data: 0.0010  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.8510 (1.0562)  Acc@1: 81.2500 (72.7681)  Acc@5: 93.7500 (94.3587)  time: 0.2174  data: 0.0010  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.8950 (1.0561)  Acc@1: 75.0000 (72.7783)  Acc@5: 100.0000 (94.3588)  time: 0.2174  data: 0.0017  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 1.0126 (1.0562)  Acc@1: 68.7500 (72.7687)  Acc@5: 100.0000 (94.3707)  time: 0.2177  data: 0.0014  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.0469 (1.0575)  Acc@1: 68.7500 (72.7241)  Acc@5: 100.0000 (94.3785)  time: 0.2173  data: 0.0015  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.1535 (1.0572)  Acc@1: 68.7500 (72.7304)  Acc@5: 93.7500 (94.3746)  time: 0.2168  data: 0.0018  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.8558 (1.0561)  Acc@1: 75.0000 (72.7676)  Acc@5: 93.7500 (94.3823)  time: 0.2159  data: 0.0009  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.8723 (1.0555)  Acc@1: 75.0000 (72.7835)  Acc@5: 93.7500 (94.3838)  time: 0.2157  data: 0.0006  max mem: 2502
Test: [Task 1] Total time: 0:05:51 (0.2162 s / it)
* Acc@1 72.783 Acc@5 94.384 loss 1.056
Test: [Task 2]  [  0/625]  eta: 0:06:13  Loss: 0.2076 (0.2076)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5970  data: 0.3832  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:34  Loss: 0.2076 (0.2423)  Acc@1: 93.7500 (96.0227)  Acc@5: 100.0000 (99.4318)  time: 0.2506  data: 0.0356  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:22  Loss: 0.1865 (0.2314)  Acc@1: 100.0000 (96.1310)  Acc@5: 100.0000 (99.7024)  time: 0.2168  data: 0.0012  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:16  Loss: 0.2193 (0.2634)  Acc@1: 93.7500 (93.9516)  Acc@5: 100.0000 (99.1935)  time: 0.2165  data: 0.0014  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:12  Loss: 0.2834 (0.2691)  Acc@1: 93.7500 (93.9024)  Acc@5: 100.0000 (99.0854)  time: 0.2159  data: 0.0015  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:08  Loss: 0.2910 (0.2834)  Acc@1: 93.7500 (93.5049)  Acc@5: 100.0000 (99.0196)  time: 0.2162  data: 0.0012  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:06  Loss: 0.2910 (0.2817)  Acc@1: 93.7500 (93.3402)  Acc@5: 100.0000 (98.9754)  time: 0.2183  data: 0.0009  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:03  Loss: 0.2886 (0.2785)  Acc@1: 93.7500 (93.5739)  Acc@5: 100.0000 (99.0317)  time: 0.2200  data: 0.0010  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:00  Loss: 0.2833 (0.2833)  Acc@1: 93.7500 (93.4414)  Acc@5: 100.0000 (98.9198)  time: 0.2178  data: 0.0007  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:58  Loss: 0.2267 (0.2757)  Acc@1: 93.7500 (93.6813)  Acc@5: 100.0000 (99.0385)  time: 0.2175  data: 0.0015  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:56  Loss: 0.2246 (0.2738)  Acc@1: 93.7500 (93.6881)  Acc@5: 100.0000 (99.1337)  time: 0.2189  data: 0.0015  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:53  Loss: 0.1990 (0.2739)  Acc@1: 93.7500 (93.8626)  Acc@5: 100.0000 (99.1554)  time: 0.2197  data: 0.0009  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:51  Loss: 0.1994 (0.2739)  Acc@1: 93.7500 (93.9050)  Acc@5: 100.0000 (99.1219)  time: 0.2179  data: 0.0008  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 0.2465 (0.2747)  Acc@1: 93.7500 (93.9408)  Acc@5: 100.0000 (99.1889)  time: 0.2156  data: 0.0005  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:46  Loss: 0.2260 (0.2766)  Acc@1: 93.7500 (94.0603)  Acc@5: 100.0000 (99.1578)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:44  Loss: 0.2194 (0.2814)  Acc@1: 93.7500 (93.9570)  Acc@5: 100.0000 (99.1722)  time: 0.2150  data: 0.0005  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 0.3296 (0.2856)  Acc@1: 93.7500 (93.8276)  Acc@5: 100.0000 (99.0683)  time: 0.2147  data: 0.0007  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.2829 (0.2874)  Acc@1: 93.7500 (93.6404)  Acc@5: 100.0000 (99.0863)  time: 0.2155  data: 0.0008  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.2829 (0.2880)  Acc@1: 93.7500 (93.6119)  Acc@5: 100.0000 (99.1022)  time: 0.2160  data: 0.0009  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:35  Loss: 0.2806 (0.2898)  Acc@1: 93.7500 (93.5864)  Acc@5: 100.0000 (99.0838)  time: 0.2158  data: 0.0010  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.2224 (0.2869)  Acc@1: 93.7500 (93.5634)  Acc@5: 100.0000 (99.1294)  time: 0.2155  data: 0.0008  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.2423 (0.2889)  Acc@1: 93.7500 (93.4242)  Acc@5: 100.0000 (99.1410)  time: 0.2164  data: 0.0013  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.2423 (0.2860)  Acc@1: 93.7500 (93.5803)  Acc@5: 100.0000 (99.1516)  time: 0.2164  data: 0.0014  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 0.1687 (0.2838)  Acc@1: 100.0000 (93.6418)  Acc@5: 100.0000 (99.1883)  time: 0.2164  data: 0.0010  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 0.2643 (0.2838)  Acc@1: 93.7500 (93.6981)  Acc@5: 100.0000 (99.2220)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.2834 (0.2862)  Acc@1: 93.7500 (93.6504)  Acc@5: 100.0000 (99.2032)  time: 0.2150  data: 0.0007  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.2874 (0.2878)  Acc@1: 93.7500 (93.5824)  Acc@5: 100.0000 (99.1858)  time: 0.2160  data: 0.0011  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.3056 (0.2895)  Acc@1: 93.7500 (93.5194)  Acc@5: 100.0000 (99.1697)  time: 0.2161  data: 0.0012  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.3316 (0.2916)  Acc@1: 93.7500 (93.3941)  Acc@5: 100.0000 (99.1770)  time: 0.2150  data: 0.0007  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.2759 (0.2929)  Acc@1: 93.7500 (93.4278)  Acc@5: 100.0000 (99.2053)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.2678 (0.2925)  Acc@1: 93.7500 (93.3970)  Acc@5: 100.0000 (99.2317)  time: 0.2167  data: 0.0007  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.2678 (0.2934)  Acc@1: 93.7500 (93.3883)  Acc@5: 100.0000 (99.1961)  time: 0.2158  data: 0.0008  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.1386 (0.2871)  Acc@1: 100.0000 (93.5748)  Acc@5: 100.0000 (99.2212)  time: 0.2153  data: 0.0008  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.1062 (0.2826)  Acc@1: 100.0000 (93.7311)  Acc@5: 100.0000 (99.2447)  time: 0.2158  data: 0.0013  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.1008 (0.2766)  Acc@1: 100.0000 (93.8966)  Acc@5: 100.0000 (99.2669)  time: 0.2163  data: 0.0013  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.0779 (0.2726)  Acc@1: 100.0000 (93.9815)  Acc@5: 100.0000 (99.2877)  time: 0.2161  data: 0.0012  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.1699 (0.2733)  Acc@1: 93.7500 (93.9404)  Acc@5: 100.0000 (99.2902)  time: 0.2156  data: 0.0013  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.2010 (0.2707)  Acc@1: 93.7500 (94.0027)  Acc@5: 100.0000 (99.3093)  time: 0.2160  data: 0.0009  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2625 (0.2753)  Acc@1: 93.7500 (93.8320)  Acc@5: 100.0000 (99.2454)  time: 0.2161  data: 0.0010  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.3136 (0.2754)  Acc@1: 93.7500 (93.7980)  Acc@5: 100.0000 (99.2168)  time: 0.2152  data: 0.0009  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.0960 (0.2716)  Acc@1: 93.7500 (93.8747)  Acc@5: 100.0000 (99.2363)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0784 (0.2696)  Acc@1: 100.0000 (93.9477)  Acc@5: 100.0000 (99.2245)  time: 0.2169  data: 0.0010  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.0862 (0.2687)  Acc@1: 100.0000 (93.9578)  Acc@5: 100.0000 (99.2429)  time: 0.2158  data: 0.0009  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.1274 (0.2658)  Acc@1: 100.0000 (94.0545)  Acc@5: 100.0000 (99.2604)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.0778 (0.2615)  Acc@1: 100.0000 (94.1893)  Acc@5: 100.0000 (99.2772)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.0778 (0.2582)  Acc@1: 100.0000 (94.2212)  Acc@5: 100.0000 (99.2932)  time: 0.2166  data: 0.0005  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.0940 (0.2550)  Acc@1: 100.0000 (94.3059)  Acc@5: 100.0000 (99.3086)  time: 0.2161  data: 0.0005  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1417 (0.2528)  Acc@1: 100.0000 (94.4135)  Acc@5: 100.0000 (99.3232)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1527 (0.2516)  Acc@1: 100.0000 (94.4777)  Acc@5: 100.0000 (99.3373)  time: 0.2150  data: 0.0004  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1497 (0.2495)  Acc@1: 100.0000 (94.5519)  Acc@5: 100.0000 (99.3508)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1355 (0.2472)  Acc@1: 100.0000 (94.6108)  Acc@5: 100.0000 (99.3638)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.1454 (0.2482)  Acc@1: 93.7500 (94.5205)  Acc@5: 100.0000 (99.3762)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.2117 (0.2484)  Acc@1: 93.7500 (94.5298)  Acc@5: 100.0000 (99.3882)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1227 (0.2463)  Acc@1: 100.0000 (94.6092)  Acc@5: 100.0000 (99.3997)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1132 (0.2444)  Acc@1: 100.0000 (94.6511)  Acc@5: 100.0000 (99.4108)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0877 (0.2413)  Acc@1: 100.0000 (94.7255)  Acc@5: 100.0000 (99.4215)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0531 (0.2379)  Acc@1: 100.0000 (94.8195)  Acc@5: 100.0000 (99.4318)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0525 (0.2372)  Acc@1: 100.0000 (94.8336)  Acc@5: 100.0000 (99.4418)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.0692 (0.2343)  Acc@1: 100.0000 (94.9010)  Acc@5: 100.0000 (99.4514)  time: 0.2159  data: 0.0009  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.0842 (0.2329)  Acc@1: 100.0000 (94.9027)  Acc@5: 100.0000 (99.4607)  time: 0.2157  data: 0.0009  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1797 (0.2326)  Acc@1: 93.7500 (94.9043)  Acc@5: 100.0000 (99.4696)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2855 (0.2351)  Acc@1: 93.7500 (94.8241)  Acc@5: 100.0000 (99.4579)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.2855 (0.2349)  Acc@1: 93.7500 (94.8470)  Acc@5: 100.0000 (99.4666)  time: 0.2160  data: 0.0003  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2301 (0.2345)  Acc@1: 93.7500 (94.8600)  Acc@5: 100.0000 (99.4700)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 2] Total time: 0:02:15 (0.2168 s / it)
* Acc@1 94.860 Acc@5 99.470 loss 0.234
Test: [Task 3]  [  0/625]  eta: 0:04:45  Loss: 0.2704 (0.2704)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.4569  data: 0.2391  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:25  Loss: 0.2235 (0.2396)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (98.2955)  time: 0.2365  data: 0.0222  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:16  Loss: 0.2151 (0.2573)  Acc@1: 100.0000 (95.5357)  Acc@5: 100.0000 (98.5119)  time: 0.2140  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:11  Loss: 0.2130 (0.2486)  Acc@1: 100.0000 (95.7661)  Acc@5: 100.0000 (98.9919)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:08  Loss: 0.1451 (0.2193)  Acc@1: 100.0000 (96.7988)  Acc@5: 100.0000 (99.2378)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:05  Loss: 0.1438 (0.2143)  Acc@1: 100.0000 (96.8137)  Acc@5: 100.0000 (99.3873)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:03  Loss: 0.2058 (0.2111)  Acc@1: 100.0000 (96.9262)  Acc@5: 100.0000 (99.4877)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:00  Loss: 0.1359 (0.1990)  Acc@1: 100.0000 (97.1831)  Acc@5: 100.0000 (99.5599)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:01:58  Loss: 0.1359 (0.2039)  Acc@1: 100.0000 (96.9907)  Acc@5: 100.0000 (99.6142)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:55  Loss: 0.1582 (0.2033)  Acc@1: 93.7500 (96.9780)  Acc@5: 100.0000 (99.5879)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:53  Loss: 0.1682 (0.2022)  Acc@1: 100.0000 (97.0916)  Acc@5: 100.0000 (99.5668)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:51  Loss: 0.1682 (0.1967)  Acc@1: 100.0000 (97.2973)  Acc@5: 100.0000 (99.6059)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:49  Loss: 0.1544 (0.1971)  Acc@1: 100.0000 (97.3657)  Acc@5: 100.0000 (99.6384)  time: 0.2151  data: 0.0006  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:47  Loss: 0.1885 (0.1970)  Acc@1: 100.0000 (97.4237)  Acc@5: 100.0000 (99.6183)  time: 0.2156  data: 0.0009  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:44  Loss: 0.1937 (0.2037)  Acc@1: 100.0000 (97.2518)  Acc@5: 100.0000 (99.4681)  time: 0.2173  data: 0.0011  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:42  Loss: 0.2308 (0.2093)  Acc@1: 93.7500 (97.1440)  Acc@5: 100.0000 (99.4205)  time: 0.2176  data: 0.0010  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:40  Loss: 0.1718 (0.2102)  Acc@1: 100.0000 (97.1661)  Acc@5: 100.0000 (99.3789)  time: 0.2161  data: 0.0008  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:38  Loss: 0.1557 (0.2092)  Acc@1: 100.0000 (97.2222)  Acc@5: 100.0000 (99.4152)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.2105 (0.2125)  Acc@1: 100.0000 (97.1340)  Acc@5: 100.0000 (99.3785)  time: 0.2169  data: 0.0006  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.2295 (0.2115)  Acc@1: 93.7500 (97.1204)  Acc@5: 100.0000 (99.4110)  time: 0.2166  data: 0.0006  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:31  Loss: 0.2295 (0.2142)  Acc@1: 93.7500 (97.0460)  Acc@5: 100.0000 (99.4092)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:29  Loss: 0.1900 (0.2161)  Acc@1: 93.7500 (97.0379)  Acc@5: 100.0000 (99.3780)  time: 0.2177  data: 0.0009  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:27  Loss: 0.1887 (0.2188)  Acc@1: 93.7500 (96.8891)  Acc@5: 100.0000 (99.3495)  time: 0.2178  data: 0.0010  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.2178 (0.2192)  Acc@1: 93.7500 (96.9156)  Acc@5: 100.0000 (99.3506)  time: 0.2157  data: 0.0006  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.1784 (0.2212)  Acc@1: 100.0000 (96.8620)  Acc@5: 100.0000 (99.3257)  time: 0.2165  data: 0.0009  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1776 (0.2198)  Acc@1: 100.0000 (96.9124)  Acc@5: 100.0000 (99.3277)  time: 0.2168  data: 0.0010  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1442 (0.2182)  Acc@1: 100.0000 (96.9349)  Acc@5: 100.0000 (99.3056)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:16  Loss: 0.1442 (0.2171)  Acc@1: 100.0000 (96.9096)  Acc@5: 100.0000 (99.3081)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 0.1512 (0.2162)  Acc@1: 93.7500 (96.9084)  Acc@5: 100.0000 (99.3327)  time: 0.2174  data: 0.0011  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.1854 (0.2168)  Acc@1: 93.7500 (96.8428)  Acc@5: 100.0000 (99.3557)  time: 0.2171  data: 0.0012  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.1854 (0.2207)  Acc@1: 93.7500 (96.6985)  Acc@5: 100.0000 (99.3148)  time: 0.2168  data: 0.0011  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1646 (0.2226)  Acc@1: 100.0000 (96.6841)  Acc@5: 100.0000 (99.2765)  time: 0.2171  data: 0.0015  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:06  Loss: 0.1675 (0.2219)  Acc@1: 100.0000 (96.6706)  Acc@5: 100.0000 (99.2601)  time: 0.2166  data: 0.0018  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 0.2063 (0.2227)  Acc@1: 93.7500 (96.6201)  Acc@5: 100.0000 (99.2636)  time: 0.2164  data: 0.0012  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.1658 (0.2210)  Acc@1: 100.0000 (96.6826)  Acc@5: 100.0000 (99.2669)  time: 0.2169  data: 0.0012  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1674 (0.2210)  Acc@1: 100.0000 (96.6702)  Acc@5: 100.0000 (99.2699)  time: 0.2163  data: 0.0013  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.1874 (0.2217)  Acc@1: 93.7500 (96.6066)  Acc@5: 100.0000 (99.2729)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.2069 (0.2221)  Acc@1: 93.7500 (96.5802)  Acc@5: 100.0000 (99.2756)  time: 0.2165  data: 0.0009  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.1779 (0.2204)  Acc@1: 93.7500 (96.6207)  Acc@5: 100.0000 (99.2946)  time: 0.2155  data: 0.0008  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.1625 (0.2216)  Acc@1: 100.0000 (96.5633)  Acc@5: 100.0000 (99.2967)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1634 (0.2205)  Acc@1: 93.7500 (96.5399)  Acc@5: 100.0000 (99.2986)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.2017 (0.2215)  Acc@1: 93.7500 (96.5328)  Acc@5: 100.0000 (99.3005)  time: 0.2154  data: 0.0007  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.2329 (0.2209)  Acc@1: 93.7500 (96.5113)  Acc@5: 100.0000 (99.3171)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1757 (0.2206)  Acc@1: 93.7500 (96.4907)  Acc@5: 100.0000 (99.3329)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.1815 (0.2219)  Acc@1: 93.7500 (96.4427)  Acc@5: 100.0000 (99.3197)  time: 0.2153  data: 0.0009  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.1904 (0.2218)  Acc@1: 100.0000 (96.4662)  Acc@5: 100.0000 (99.3210)  time: 0.2161  data: 0.0011  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.1843 (0.2213)  Acc@1: 100.0000 (96.4751)  Acc@5: 100.0000 (99.3221)  time: 0.2173  data: 0.0009  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1843 (0.2208)  Acc@1: 93.7500 (96.4835)  Acc@5: 100.0000 (99.3232)  time: 0.2186  data: 0.0007  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1804 (0.2216)  Acc@1: 93.7500 (96.4787)  Acc@5: 100.0000 (99.3113)  time: 0.2169  data: 0.0007  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2119 (0.2220)  Acc@1: 93.7500 (96.4740)  Acc@5: 100.0000 (99.2999)  time: 0.2168  data: 0.0015  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2024 (0.2212)  Acc@1: 100.0000 (96.4820)  Acc@5: 100.0000 (99.3139)  time: 0.2196  data: 0.0018  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.1373 (0.2210)  Acc@1: 100.0000 (96.4653)  Acc@5: 100.0000 (99.3273)  time: 0.2194  data: 0.0009  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.1810 (0.2210)  Acc@1: 93.7500 (96.4491)  Acc@5: 100.0000 (99.3402)  time: 0.2168  data: 0.0009  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.1882 (0.2220)  Acc@1: 93.7500 (96.4218)  Acc@5: 100.0000 (99.3526)  time: 0.2152  data: 0.0007  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2079 (0.2230)  Acc@1: 93.7500 (96.4071)  Acc@5: 100.0000 (99.3299)  time: 0.2157  data: 0.0009  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2079 (0.2233)  Acc@1: 100.0000 (96.4156)  Acc@5: 100.0000 (99.3308)  time: 0.2158  data: 0.0009  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1995 (0.2232)  Acc@1: 93.7500 (96.4015)  Acc@5: 100.0000 (99.3427)  time: 0.2154  data: 0.0007  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.1734 (0.2227)  Acc@1: 100.0000 (96.4317)  Acc@5: 100.0000 (99.3433)  time: 0.2164  data: 0.0010  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.1513 (0.2239)  Acc@1: 100.0000 (96.3963)  Acc@5: 100.0000 (99.3438)  time: 0.2157  data: 0.0010  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1823 (0.2233)  Acc@1: 100.0000 (96.4361)  Acc@5: 100.0000 (99.3549)  time: 0.2159  data: 0.0011  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1789 (0.2232)  Acc@1: 100.0000 (96.4122)  Acc@5: 100.0000 (99.3552)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1662 (0.2224)  Acc@1: 93.7500 (96.4096)  Acc@5: 100.0000 (99.3658)  time: 0.2150  data: 0.0005  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.1975 (0.2232)  Acc@1: 93.7500 (96.3869)  Acc@5: 100.0000 (99.3659)  time: 0.2156  data: 0.0007  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1655 (0.2225)  Acc@1: 100.0000 (96.4100)  Acc@5: 100.0000 (99.3700)  time: 0.2155  data: 0.0006  max mem: 2502
Test: [Task 3] Total time: 0:02:15 (0.2167 s / it)
* Acc@1 96.410 Acc@5 99.370 loss 0.222
{0: {0: 0, 1: 26032, 2: 0, 3: 0, 4: 0, 5: 0, 6: 26032, 7: 0, 8: 26032, 9: 0, 10: 0, 11: 0, 12: 26032, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 10000, 3: 10000, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 10000, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 10000, 1: 16, 2: 0, 3: 0, 4: 0, 5: 0, 6: 16, 7: 0, 8: 16, 9: 9984, 10: 0, 11: 0, 12: 0, 13: 9984, 14: 0, 15: 0, 16: 9984, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task3]	Acc@1: 88.0178	Acc@5: 97.7413	Loss: 0.5042	Forgetting: 7.2674	Backward: -7.2674
Train: Epoch[1/5]  [   0/1142]  eta: 0:16:04  Lr: 0.001875  Loss: 2.2596  Acc@1: 12.5000 (12.5000)  Acc@5: 37.5000 (37.5000)  time: 0.8442  data: 0.4787  max mem: 2502
Train: Epoch[1/5]  [  10/1142]  eta: 0:07:26  Lr: 0.001875  Loss: 2.0124  Acc@1: 25.0000 (25.5682)  Acc@5: 68.7500 (63.0682)  time: 0.3946  data: 0.0443  max mem: 2502
Train: Epoch[1/5]  [  20/1142]  eta: 0:06:57  Lr: 0.001875  Loss: 1.7676  Acc@1: 31.2500 (28.8690)  Acc@5: 75.0000 (68.1548)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [  30/1142]  eta: 0:06:45  Lr: 0.001875  Loss: 1.7139  Acc@1: 37.5000 (30.4435)  Acc@5: 81.2500 (72.7823)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [  40/1142]  eta: 0:06:37  Lr: 0.001875  Loss: 1.7931  Acc@1: 37.5000 (31.7073)  Acc@5: 81.2500 (75.4573)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [  50/1142]  eta: 0:06:31  Lr: 0.001875  Loss: 1.5346  Acc@1: 43.7500 (36.0294)  Acc@5: 87.5000 (78.4314)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  60/1142]  eta: 0:06:26  Lr: 0.001875  Loss: 1.6469  Acc@1: 43.7500 (36.7828)  Acc@5: 87.5000 (79.4057)  time: 0.3494  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [  70/1142]  eta: 0:06:21  Lr: 0.001875  Loss: 1.5367  Acc@1: 43.7500 (38.0282)  Acc@5: 87.5000 (80.3697)  time: 0.3502  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [  80/1142]  eta: 0:06:17  Lr: 0.001875  Loss: 1.0790  Acc@1: 43.7500 (39.3519)  Acc@5: 87.5000 (81.0185)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [  90/1142]  eta: 0:06:12  Lr: 0.001875  Loss: 1.0116  Acc@1: 43.7500 (39.8352)  Acc@5: 87.5000 (81.6621)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 100/1142]  eta: 0:06:08  Lr: 0.001875  Loss: 0.9775  Acc@1: 43.7500 (41.5842)  Acc@5: 87.5000 (82.3020)  time: 0.3483  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 110/1142]  eta: 0:06:05  Lr: 0.001875  Loss: 0.9087  Acc@1: 50.0000 (42.0045)  Acc@5: 87.5000 (82.4887)  time: 0.3516  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 120/1142]  eta: 0:06:01  Lr: 0.001875  Loss: 1.3090  Acc@1: 50.0000 (42.7686)  Acc@5: 87.5000 (83.1612)  time: 0.3509  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 130/1142]  eta: 0:05:57  Lr: 0.001875  Loss: 0.6756  Acc@1: 50.0000 (43.1298)  Acc@5: 87.5000 (83.4924)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 140/1142]  eta: 0:05:53  Lr: 0.001875  Loss: 0.8436  Acc@1: 50.0000 (43.1294)  Acc@5: 87.5000 (83.7323)  time: 0.3467  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 150/1142]  eta: 0:05:49  Lr: 0.001875  Loss: 0.9072  Acc@1: 56.2500 (43.9570)  Acc@5: 87.5000 (83.9818)  time: 0.3480  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 160/1142]  eta: 0:05:45  Lr: 0.001875  Loss: 1.1587  Acc@1: 50.0000 (44.0217)  Acc@5: 87.5000 (84.2391)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 170/1142]  eta: 0:05:41  Lr: 0.001875  Loss: 0.7720  Acc@1: 50.0000 (44.3348)  Acc@5: 87.5000 (84.6857)  time: 0.3479  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 180/1142]  eta: 0:05:38  Lr: 0.001875  Loss: 1.1547  Acc@1: 50.0000 (44.6133)  Acc@5: 93.7500 (84.9793)  time: 0.3478  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 190/1142]  eta: 0:05:34  Lr: 0.001875  Loss: 1.0106  Acc@1: 50.0000 (44.6335)  Acc@5: 87.5000 (85.1440)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 200/1142]  eta: 0:05:30  Lr: 0.001875  Loss: 0.6511  Acc@1: 50.0000 (45.6157)  Acc@5: 93.7500 (85.4478)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 210/1142]  eta: 0:05:26  Lr: 0.001875  Loss: 0.7563  Acc@1: 56.2500 (46.2085)  Acc@5: 93.7500 (85.7524)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 220/1142]  eta: 0:05:23  Lr: 0.001875  Loss: 0.5024  Acc@1: 56.2500 (46.6063)  Acc@5: 93.7500 (85.9729)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 230/1142]  eta: 0:05:19  Lr: 0.001875  Loss: 0.7032  Acc@1: 56.2500 (46.9697)  Acc@5: 93.7500 (86.3095)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 240/1142]  eta: 0:05:15  Lr: 0.001875  Loss: 0.7438  Acc@1: 56.2500 (47.5363)  Acc@5: 93.7500 (86.4886)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 250/1142]  eta: 0:05:12  Lr: 0.001875  Loss: 0.8378  Acc@1: 56.2500 (47.7092)  Acc@5: 87.5000 (86.6036)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 260/1142]  eta: 0:05:08  Lr: 0.001875  Loss: 0.5646  Acc@1: 56.2500 (48.0364)  Acc@5: 93.7500 (86.8295)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 270/1142]  eta: 0:05:04  Lr: 0.001875  Loss: 0.0311  Acc@1: 56.2500 (48.2472)  Acc@5: 93.7500 (86.9004)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 280/1142]  eta: 0:05:01  Lr: 0.001875  Loss: 0.6004  Acc@1: 50.0000 (48.3986)  Acc@5: 87.5000 (87.0329)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 290/1142]  eta: 0:04:57  Lr: 0.001875  Loss: 0.3170  Acc@1: 50.0000 (48.4966)  Acc@5: 87.5000 (87.1134)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 300/1142]  eta: 0:04:53  Lr: 0.001875  Loss: 0.3977  Acc@1: 56.2500 (48.8787)  Acc@5: 87.5000 (87.1885)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 310/1142]  eta: 0:04:50  Lr: 0.001875  Loss: 0.3686  Acc@1: 56.2500 (49.2162)  Acc@5: 93.7500 (87.4196)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 320/1142]  eta: 0:04:46  Lr: 0.001875  Loss: 0.1662  Acc@1: 56.2500 (49.4354)  Acc@5: 93.7500 (87.5000)  time: 0.3486  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 330/1142]  eta: 0:04:43  Lr: 0.001875  Loss: 0.2854  Acc@1: 56.2500 (49.6412)  Acc@5: 87.5000 (87.6322)  time: 0.3511  data: 0.0024  max mem: 2502
Train: Epoch[1/5]  [ 340/1142]  eta: 0:04:40  Lr: 0.001875  Loss: 0.2496  Acc@1: 56.2500 (49.9084)  Acc@5: 93.7500 (87.7199)  time: 0.3524  data: 0.0024  max mem: 2502
Train: Epoch[1/5]  [ 350/1142]  eta: 0:04:36  Lr: 0.001875  Loss: -0.0193  Acc@1: 56.2500 (50.1603)  Acc@5: 93.7500 (87.8027)  time: 0.3502  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 360/1142]  eta: 0:04:33  Lr: 0.001875  Loss: 0.1419  Acc@1: 62.5000 (50.5021)  Acc@5: 93.7500 (87.9155)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 370/1142]  eta: 0:04:29  Lr: 0.001875  Loss: 0.1680  Acc@1: 62.5000 (50.7749)  Acc@5: 93.7500 (88.0728)  time: 0.3496  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 380/1142]  eta: 0:04:26  Lr: 0.001875  Loss: 0.6454  Acc@1: 56.2500 (50.8858)  Acc@5: 93.7500 (88.1562)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 390/1142]  eta: 0:04:22  Lr: 0.001875  Loss: 0.0567  Acc@1: 56.2500 (51.0710)  Acc@5: 93.7500 (88.2992)  time: 0.3531  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 400/1142]  eta: 0:04:19  Lr: 0.001875  Loss: 0.3317  Acc@1: 56.2500 (51.3716)  Acc@5: 93.7500 (88.4352)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 410/1142]  eta: 0:04:15  Lr: 0.001875  Loss: 0.3713  Acc@1: 62.5000 (51.7032)  Acc@5: 93.7500 (88.4884)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 420/1142]  eta: 0:04:12  Lr: 0.001875  Loss: 0.1822  Acc@1: 62.5000 (51.7369)  Acc@5: 93.7500 (88.5392)  time: 0.3509  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 430/1142]  eta: 0:04:08  Lr: 0.001875  Loss: -0.0638  Acc@1: 56.2500 (51.8852)  Acc@5: 93.7500 (88.6311)  time: 0.3524  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 440/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.2211  Acc@1: 56.2500 (51.9700)  Acc@5: 93.7500 (88.7472)  time: 0.3506  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 450/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.0808  Acc@1: 62.5000 (52.2312)  Acc@5: 93.7500 (88.7611)  time: 0.3484  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 460/1142]  eta: 0:03:58  Lr: 0.001875  Loss: 0.0682  Acc@1: 62.5000 (52.2777)  Acc@5: 87.5000 (88.7880)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 470/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.3762  Acc@1: 56.2500 (52.4682)  Acc@5: 87.5000 (88.8800)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 480/1142]  eta: 0:03:51  Lr: 0.001875  Loss: 0.6998  Acc@1: 56.2500 (52.4168)  Acc@5: 87.5000 (88.8773)  time: 0.3482  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 490/1142]  eta: 0:03:47  Lr: 0.001875  Loss: 0.2420  Acc@1: 56.2500 (52.5586)  Acc@5: 93.7500 (88.9893)  time: 0.3491  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 500/1142]  eta: 0:03:44  Lr: 0.001875  Loss: 0.0858  Acc@1: 62.5000 (52.8069)  Acc@5: 93.7500 (89.0594)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 510/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.4017  Acc@1: 62.5000 (52.9599)  Acc@5: 93.7500 (89.1145)  time: 0.3538  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 520/1142]  eta: 0:03:37  Lr: 0.001875  Loss: -0.0583  Acc@1: 56.2500 (52.9870)  Acc@5: 87.5000 (89.1075)  time: 0.3536  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: 0.3600  Acc@1: 56.2500 (53.2250)  Acc@5: 87.5000 (89.1478)  time: 0.3539  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 540/1142]  eta: 0:03:30  Lr: 0.001875  Loss: -0.0410  Acc@1: 62.5000 (53.3272)  Acc@5: 87.5000 (89.1751)  time: 0.3545  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.3444  Acc@1: 56.2500 (53.3235)  Acc@5: 87.5000 (89.1788)  time: 0.3501  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 560/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.2215  Acc@1: 56.2500 (53.4202)  Acc@5: 87.5000 (89.1934)  time: 0.3480  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: 0.0173  Acc@1: 56.2500 (53.5355)  Acc@5: 93.7500 (89.2404)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: 0.1211  Acc@1: 56.2500 (53.6898)  Acc@5: 93.7500 (89.2427)  time: 0.3476  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 590/1142]  eta: 0:03:12  Lr: 0.001875  Loss: 0.2432  Acc@1: 62.5000 (53.8177)  Acc@5: 93.7500 (89.3084)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: -0.4438  Acc@1: 62.5000 (53.9621)  Acc@5: 93.7500 (89.3407)  time: 0.3476  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 610/1142]  eta: 0:03:05  Lr: 0.001875  Loss: -0.1851  Acc@1: 68.7500 (54.1735)  Acc@5: 93.7500 (89.3822)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.3925  Acc@1: 56.2500 (54.2069)  Acc@5: 93.7500 (89.3820)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 630/1142]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4477  Acc@1: 56.2500 (54.2888)  Acc@5: 93.7500 (89.4414)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.1626  Acc@1: 62.5000 (54.4657)  Acc@5: 93.7500 (89.4696)  time: 0.3476  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.0424  Acc@1: 68.7500 (54.5987)  Acc@5: 87.5000 (89.4969)  time: 0.3479  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.7110  Acc@1: 62.5000 (54.7088)  Acc@5: 93.7500 (89.5234)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.1619  Acc@1: 62.5000 (54.8342)  Acc@5: 93.7500 (89.5678)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.3198  Acc@1: 62.5000 (54.9284)  Acc@5: 93.7500 (89.5833)  time: 0.3503  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.2475  Acc@1: 56.2500 (54.9385)  Acc@5: 93.7500 (89.6436)  time: 0.3503  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.3563  Acc@1: 62.5000 (55.0553)  Acc@5: 93.7500 (89.6576)  time: 0.3485  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4210  Acc@1: 62.5000 (55.1864)  Acc@5: 93.7500 (89.7240)  time: 0.3474  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.2630  Acc@1: 62.5000 (55.2271)  Acc@5: 93.7500 (89.7365)  time: 0.3482  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: 0.0593  Acc@1: 56.2500 (55.2753)  Acc@5: 87.5000 (89.7401)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.0442  Acc@1: 56.2500 (55.3306)  Acc@5: 87.5000 (89.7436)  time: 0.3545  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.0959  Acc@1: 56.2500 (55.4011)  Acc@5: 93.7500 (89.8219)  time: 0.3546  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.2001  Acc@1: 62.5000 (55.5191)  Acc@5: 93.7500 (89.8571)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.3220  Acc@1: 62.5000 (55.5934)  Acc@5: 93.7500 (89.9076)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.3697  Acc@1: 62.5000 (55.7218)  Acc@5: 93.7500 (89.9408)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.4655  Acc@1: 62.5000 (55.8628)  Acc@5: 93.7500 (90.0205)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.5053  Acc@1: 68.7500 (55.9535)  Acc@5: 100.0000 (90.0905)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.3639  Acc@1: 62.5000 (56.0419)  Acc@5: 93.7500 (90.1588)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.2562  Acc@1: 62.5000 (56.1739)  Acc@5: 93.7500 (90.1949)  time: 0.3445  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.1065  Acc@1: 62.5000 (56.2575)  Acc@5: 93.7500 (90.2076)  time: 0.3499  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.5542  Acc@1: 62.5000 (56.3095)  Acc@5: 93.7500 (90.2497)  time: 0.3552  data: 0.0030  max mem: 2502
Train: Epoch[1/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.7001  Acc@1: 62.5000 (56.3969)  Acc@5: 93.7500 (90.2761)  time: 0.3547  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.1657  Acc@1: 62.5000 (56.4678)  Acc@5: 87.5000 (90.2875)  time: 0.3506  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.2771  Acc@1: 62.5000 (56.5586)  Acc@5: 93.7500 (90.3487)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.3885  Acc@1: 62.5000 (56.5692)  Acc@5: 93.7500 (90.3448)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.1564  Acc@1: 62.5000 (56.6358)  Acc@5: 93.7500 (90.3970)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.1121  Acc@1: 62.5000 (56.7148)  Acc@5: 93.7500 (90.4550)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.0448  Acc@1: 56.2500 (56.6959)  Acc@5: 93.7500 (90.4706)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.3416  Acc@1: 56.2500 (56.6775)  Acc@5: 93.7500 (90.4927)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2666  Acc@1: 56.2500 (56.7132)  Acc@5: 93.7500 (90.5008)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.5184  Acc@1: 56.2500 (56.7349)  Acc@5: 93.7500 (90.5287)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.2415  Acc@1: 56.2500 (56.7429)  Acc@5: 93.7500 (90.5363)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.0568  Acc@1: 62.5000 (56.8548)  Acc@5: 93.7500 (90.5697)  time: 0.3503  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.0210  Acc@1: 68.7500 (57.0160)  Acc@5: 93.7500 (90.5703)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.2901  Acc@1: 75.0000 (57.0846)  Acc@5: 93.7500 (90.6027)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.4848  Acc@1: 56.2500 (57.1077)  Acc@5: 93.7500 (90.6092)  time: 0.3532  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1716  Acc@1: 56.2500 (57.1304)  Acc@5: 87.5000 (90.6156)  time: 0.3543  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.6471  Acc@1: 56.2500 (57.1464)  Acc@5: 93.7500 (90.6281)  time: 0.3519  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6038  Acc@1: 56.2500 (57.1743)  Acc@5: 93.7500 (90.6525)  time: 0.3489  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.5641  Acc@1: 62.5000 (57.2139)  Acc@5: 93.7500 (90.6462)  time: 0.3487  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.0315  Acc@1: 62.5000 (57.3067)  Acc@5: 93.7500 (90.6640)  time: 0.3534  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.0596  Acc@1: 62.5000 (57.3561)  Acc@5: 93.7500 (90.6993)  time: 0.3521  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.5869  Acc@1: 62.5000 (57.3516)  Acc@5: 87.5000 (90.6574)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.7652  Acc@1: 62.5000 (57.3646)  Acc@5: 87.5000 (90.6746)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0750  Acc@1: 68.7500 (57.4237)  Acc@5: 93.7500 (90.6626)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.1122  Acc@1: 56.2500 (57.4015)  Acc@5: 93.7500 (90.6737)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.3497  Acc@1: 56.2500 (57.4648)  Acc@5: 93.7500 (90.6960)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.6892  Acc@1: 62.5000 (57.5439)  Acc@5: 93.7500 (90.7122)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5467  Acc@1: 62.5000 (57.6104)  Acc@5: 93.7500 (90.7393)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5189  Acc@1: 68.7500 (57.6647)  Acc@5: 93.7500 (90.7770)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7501  Acc@1: 62.5000 (57.7125)  Acc@5: 93.7500 (90.8304)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1900  Acc@1: 62.5000 (57.7115)  Acc@5: 93.7500 (90.8240)  time: 0.3381  data: 0.0004  max mem: 2502
Train: Epoch[1/5] Total time: 0:06:38 (0.3492 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 18249, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 17993, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 18265, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 18137, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1900  Acc@1: 62.5000 (57.7115)  Acc@5: 93.7500 (90.8240)
Train: Epoch[2/5]  [   0/1142]  eta: 0:11:07  Lr: 0.001875  Loss: -1.0045  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5848  data: 0.2364  max mem: 2502
Train: Epoch[2/5]  [  10/1142]  eta: 0:06:55  Lr: 0.001875  Loss: -0.6457  Acc@1: 75.0000 (72.1591)  Acc@5: 93.7500 (94.3182)  time: 0.3666  data: 0.0218  max mem: 2502
Train: Epoch[2/5]  [  20/1142]  eta: 0:06:41  Lr: 0.001875  Loss: 0.0573  Acc@1: 68.7500 (69.3452)  Acc@5: 87.5000 (91.6667)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  30/1142]  eta: 0:06:34  Lr: 0.001875  Loss: -0.1964  Acc@1: 62.5000 (67.5403)  Acc@5: 87.5000 (90.7258)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  40/1142]  eta: 0:06:29  Lr: 0.001875  Loss: 0.1409  Acc@1: 62.5000 (66.3110)  Acc@5: 93.7500 (91.3110)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [  50/1142]  eta: 0:06:24  Lr: 0.001875  Loss: -0.5031  Acc@1: 68.7500 (66.6667)  Acc@5: 93.7500 (92.0343)  time: 0.3483  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [  60/1142]  eta: 0:06:20  Lr: 0.001875  Loss: -0.6000  Acc@1: 62.5000 (66.2910)  Acc@5: 93.7500 (92.0082)  time: 0.3484  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [  70/1142]  eta: 0:06:16  Lr: 0.001875  Loss: -0.5576  Acc@1: 62.5000 (66.4613)  Acc@5: 93.7500 (92.1655)  time: 0.3484  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [  80/1142]  eta: 0:06:12  Lr: 0.001875  Loss: -0.3255  Acc@1: 62.5000 (65.6636)  Acc@5: 93.7500 (92.4383)  time: 0.3482  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:08  Lr: 0.001875  Loss: 0.0154  Acc@1: 62.5000 (65.3159)  Acc@5: 93.7500 (92.5137)  time: 0.3476  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:05  Lr: 0.001875  Loss: -0.4931  Acc@1: 62.5000 (65.5322)  Acc@5: 93.7500 (92.5124)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 110/1142]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4326  Acc@1: 56.2500 (64.6396)  Acc@5: 93.7500 (92.1171)  time: 0.3520  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [ 120/1142]  eta: 0:05:58  Lr: 0.001875  Loss: 0.2149  Acc@1: 56.2500 (64.3079)  Acc@5: 87.5000 (91.8388)  time: 0.3514  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [ 130/1142]  eta: 0:05:54  Lr: 0.001875  Loss: -0.5296  Acc@1: 62.5000 (64.6469)  Acc@5: 93.7500 (91.9847)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 140/1142]  eta: 0:05:51  Lr: 0.001875  Loss: -0.1740  Acc@1: 68.7500 (64.6277)  Acc@5: 93.7500 (91.9770)  time: 0.3506  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 150/1142]  eta: 0:05:47  Lr: 0.001875  Loss: 0.7120  Acc@1: 62.5000 (64.4868)  Acc@5: 93.7500 (92.0530)  time: 0.3482  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 160/1142]  eta: 0:05:43  Lr: 0.001875  Loss: -0.8725  Acc@1: 68.7500 (64.9068)  Acc@5: 93.7500 (92.3525)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 170/1142]  eta: 0:05:40  Lr: 0.001875  Loss: 0.0135  Acc@1: 68.7500 (64.9854)  Acc@5: 93.7500 (92.4342)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 180/1142]  eta: 0:05:36  Lr: 0.001875  Loss: -0.2522  Acc@1: 68.7500 (65.2279)  Acc@5: 93.7500 (92.4033)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 190/1142]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6380  Acc@1: 68.7500 (65.4450)  Acc@5: 93.7500 (92.5393)  time: 0.3473  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 200/1142]  eta: 0:05:29  Lr: 0.001875  Loss: -0.8018  Acc@1: 68.7500 (65.5784)  Acc@5: 93.7500 (92.5995)  time: 0.3488  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 210/1142]  eta: 0:05:26  Lr: 0.001875  Loss: 0.1622  Acc@1: 68.7500 (65.2251)  Acc@5: 93.7500 (92.5355)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 220/1142]  eta: 0:05:22  Lr: 0.001875  Loss: -0.0722  Acc@1: 62.5000 (64.9887)  Acc@5: 93.7500 (92.4774)  time: 0.3534  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:19  Lr: 0.001875  Loss: -0.3565  Acc@1: 62.5000 (64.8268)  Acc@5: 93.7500 (92.5054)  time: 0.3521  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:15  Lr: 0.001875  Loss: -0.3811  Acc@1: 62.5000 (64.9118)  Acc@5: 93.7500 (92.5052)  time: 0.3461  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:11  Lr: 0.001875  Loss: -0.4888  Acc@1: 62.5000 (64.6414)  Acc@5: 93.7500 (92.5548)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:08  Lr: 0.001875  Loss: -0.0383  Acc@1: 56.2500 (64.4397)  Acc@5: 93.7500 (92.6006)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.1870  Acc@1: 62.5000 (64.4834)  Acc@5: 93.7500 (92.6199)  time: 0.3457  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 280/1142]  eta: 0:05:01  Lr: 0.001875  Loss: 0.1220  Acc@1: 62.5000 (64.3906)  Acc@5: 93.7500 (92.6157)  time: 0.3453  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 290/1142]  eta: 0:04:57  Lr: 0.001875  Loss: -0.8190  Acc@1: 62.5000 (64.4115)  Acc@5: 93.7500 (92.7191)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 300/1142]  eta: 0:04:54  Lr: 0.001875  Loss: -0.7342  Acc@1: 56.2500 (64.3480)  Acc@5: 93.7500 (92.7118)  time: 0.3514  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 310/1142]  eta: 0:04:50  Lr: 0.001875  Loss: -0.3720  Acc@1: 62.5000 (64.1881)  Acc@5: 93.7500 (92.6246)  time: 0.3511  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 320/1142]  eta: 0:04:47  Lr: 0.001875  Loss: -0.4290  Acc@1: 62.5000 (64.1355)  Acc@5: 87.5000 (92.5428)  time: 0.3495  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 330/1142]  eta: 0:04:43  Lr: 0.001875  Loss: -0.3156  Acc@1: 62.5000 (64.0483)  Acc@5: 87.5000 (92.5415)  time: 0.3466  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 340/1142]  eta: 0:04:40  Lr: 0.001875  Loss: -0.1899  Acc@1: 62.5000 (63.9846)  Acc@5: 93.7500 (92.5220)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 350/1142]  eta: 0:04:36  Lr: 0.001875  Loss: -0.0385  Acc@1: 62.5000 (63.9245)  Acc@5: 93.7500 (92.5214)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 360/1142]  eta: 0:04:32  Lr: 0.001875  Loss: -0.2359  Acc@1: 62.5000 (63.9024)  Acc@5: 93.7500 (92.5900)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 370/1142]  eta: 0:04:29  Lr: 0.001875  Loss: -0.1865  Acc@1: 62.5000 (63.9151)  Acc@5: 93.7500 (92.6044)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:25  Lr: 0.001875  Loss: -0.6135  Acc@1: 62.5000 (63.7631)  Acc@5: 93.7500 (92.5853)  time: 0.3510  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:22  Lr: 0.001875  Loss: -0.0971  Acc@1: 62.5000 (63.8587)  Acc@5: 93.7500 (92.6151)  time: 0.3544  data: 0.0020  max mem: 2502
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:19  Lr: 0.001875  Loss: -0.7152  Acc@1: 62.5000 (63.8560)  Acc@5: 93.7500 (92.5810)  time: 0.3527  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:15  Lr: 0.001875  Loss: -0.0192  Acc@1: 62.5000 (63.8230)  Acc@5: 93.7500 (92.6095)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:12  Lr: 0.001875  Loss: -0.4692  Acc@1: 62.5000 (63.7470)  Acc@5: 93.7500 (92.6811)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:08  Lr: 0.001875  Loss: -0.1869  Acc@1: 62.5000 (63.7616)  Acc@5: 93.7500 (92.6914)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.5572  Acc@1: 68.7500 (63.8747)  Acc@5: 93.7500 (92.6729)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 450/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.6450  Acc@1: 68.7500 (63.8304)  Acc@5: 93.7500 (92.6829)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 460/1142]  eta: 0:03:57  Lr: 0.001875  Loss: -0.1833  Acc@1: 62.5000 (63.8693)  Acc@5: 93.7500 (92.6654)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 470/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.8784  Acc@1: 62.5000 (63.8137)  Acc@5: 93.7500 (92.7150)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 480/1142]  eta: 0:03:50  Lr: 0.001875  Loss: -0.4762  Acc@1: 62.5000 (63.9033)  Acc@5: 93.7500 (92.7885)  time: 0.3452  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 490/1142]  eta: 0:03:47  Lr: 0.001875  Loss: -0.6060  Acc@1: 68.7500 (64.0148)  Acc@5: 93.7500 (92.8208)  time: 0.3479  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 500/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.8399  Acc@1: 68.7500 (64.0344)  Acc@5: 93.7500 (92.8518)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 510/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.2817  Acc@1: 62.5000 (64.0533)  Acc@5: 93.7500 (92.7715)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 520/1142]  eta: 0:03:36  Lr: 0.001875  Loss: -0.5660  Acc@1: 62.5000 (64.1075)  Acc@5: 93.7500 (92.7543)  time: 0.3506  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 530/1142]  eta: 0:03:33  Lr: 0.001875  Loss: -0.0352  Acc@1: 62.5000 (64.1008)  Acc@5: 93.7500 (92.8202)  time: 0.3509  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:30  Lr: 0.001875  Loss: -0.0777  Acc@1: 62.5000 (64.1636)  Acc@5: 93.7500 (92.8258)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7373  Acc@1: 62.5000 (64.1788)  Acc@5: 93.7500 (92.8312)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.3258  Acc@1: 62.5000 (64.2045)  Acc@5: 93.7500 (92.8142)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:19  Lr: 0.001875  Loss: -0.1932  Acc@1: 68.7500 (64.2951)  Acc@5: 93.7500 (92.8634)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: -0.2981  Acc@1: 62.5000 (64.1997)  Acc@5: 93.7500 (92.8464)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:12  Lr: 0.001875  Loss: -0.3714  Acc@1: 62.5000 (64.2132)  Acc@5: 93.7500 (92.8299)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: -0.1073  Acc@1: 62.5000 (64.1327)  Acc@5: 93.7500 (92.8245)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:05  Lr: 0.001875  Loss: -0.1139  Acc@1: 62.5000 (64.1060)  Acc@5: 93.7500 (92.7885)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.4972  Acc@1: 62.5000 (64.0197)  Acc@5: 93.7500 (92.7939)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 630/1142]  eta: 0:02:58  Lr: 0.001875  Loss: -0.7422  Acc@1: 62.5000 (64.0848)  Acc@5: 93.7500 (92.8189)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.5321  Acc@1: 68.7500 (64.0991)  Acc@5: 93.7500 (92.8237)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.3448  Acc@1: 62.5000 (64.0361)  Acc@5: 93.7500 (92.8283)  time: 0.3521  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.1811  Acc@1: 62.5000 (64.0223)  Acc@5: 93.7500 (92.7666)  time: 0.3525  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.4043  Acc@1: 62.5000 (63.9996)  Acc@5: 87.5000 (92.7440)  time: 0.3515  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.0441  Acc@1: 68.7500 (63.9501)  Acc@5: 87.5000 (92.7405)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4235  Acc@1: 68.7500 (63.9743)  Acc@5: 93.7500 (92.7641)  time: 0.3474  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.7046  Acc@1: 68.7500 (64.0603)  Acc@5: 93.7500 (92.7871)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.1811  Acc@1: 68.7500 (64.0823)  Acc@5: 93.7500 (92.7831)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.4832  Acc@1: 62.5000 (64.0777)  Acc@5: 93.7500 (92.8138)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.4919  Acc@1: 68.7500 (64.0988)  Acc@5: 93.7500 (92.8437)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.0736  Acc@1: 68.7500 (64.1279)  Acc@5: 93.7500 (92.8728)  time: 0.3455  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: -0.3716  Acc@1: 62.5000 (64.0729)  Acc@5: 93.7500 (92.8762)  time: 0.3453  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.5485  Acc@1: 62.5000 (64.0933)  Acc@5: 93.7500 (92.8712)  time: 0.3462  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.3638  Acc@1: 68.7500 (64.1618)  Acc@5: 93.7500 (92.8745)  time: 0.3464  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.3064  Acc@1: 68.7500 (64.1245)  Acc@5: 93.7500 (92.8617)  time: 0.3467  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.0610  Acc@1: 62.5000 (64.0171)  Acc@5: 93.7500 (92.8413)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.5152  Acc@1: 56.2500 (63.9513)  Acc@5: 93.7500 (92.8215)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.3281  Acc@1: 62.5000 (63.9257)  Acc@5: 93.7500 (92.8329)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.0323  Acc@1: 62.5000 (63.9540)  Acc@5: 93.7500 (92.8365)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.1203  Acc@1: 68.7500 (63.9741)  Acc@5: 93.7500 (92.8174)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.2406  Acc@1: 62.5000 (63.9492)  Acc@5: 93.7500 (92.8285)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5630  Acc@1: 62.5000 (63.9909)  Acc@5: 93.7500 (92.8173)  time: 0.3478  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6020  Acc@1: 56.2500 (63.9591)  Acc@5: 93.7500 (92.7773)  time: 0.3523  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.3531  Acc@1: 56.2500 (63.9064)  Acc@5: 93.7500 (92.8028)  time: 0.3532  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.2857  Acc@1: 56.2500 (63.8763)  Acc@5: 93.7500 (92.7781)  time: 0.3530  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1034  Acc@1: 62.5000 (63.8258)  Acc@5: 87.5000 (92.7609)  time: 0.3514  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: 0.1431  Acc@1: 62.5000 (63.8319)  Acc@5: 87.5000 (92.7164)  time: 0.3472  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.5058  Acc@1: 68.7500 (63.8790)  Acc@5: 93.7500 (92.7141)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5659  Acc@1: 68.7500 (63.8979)  Acc@5: 93.7500 (92.7524)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.6218  Acc@1: 62.5000 (63.9232)  Acc@5: 93.7500 (92.7564)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.6125  Acc@1: 62.5000 (63.8616)  Acc@5: 93.7500 (92.7537)  time: 0.3470  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4610  Acc@1: 56.2500 (63.8407)  Acc@5: 93.7500 (92.7576)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4854  Acc@1: 56.2500 (63.8072)  Acc@5: 93.7500 (92.7549)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: -0.5456  Acc@1: 62.5000 (63.8195)  Acc@5: 93.7500 (92.7652)  time: 0.3505  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.4731  Acc@1: 68.7500 (63.8825)  Acc@5: 93.7500 (92.7943)  time: 0.3487  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1423  Acc@1: 62.5000 (63.7929)  Acc@5: 93.7500 (92.7788)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.4067  Acc@1: 56.2500 (63.8174)  Acc@5: 93.7500 (92.7885)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.4859  Acc@1: 62.5000 (63.8168)  Acc@5: 93.7500 (92.7918)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6029  Acc@1: 62.5000 (63.8651)  Acc@5: 93.7500 (92.8195)  time: 0.3463  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.2055  Acc@1: 62.5000 (63.8700)  Acc@5: 93.7500 (92.8164)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.1565  Acc@1: 62.5000 (63.8929)  Acc@5: 93.7500 (92.8254)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.3864  Acc@1: 68.7500 (63.9272)  Acc@5: 93.7500 (92.8223)  time: 0.3505  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1218  Acc@1: 68.7500 (63.9373)  Acc@5: 93.7500 (92.8487)  time: 0.3527  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.2262  Acc@1: 62.5000 (63.9064)  Acc@5: 93.7500 (92.8571)  time: 0.3541  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9340  Acc@1: 56.2500 (63.8992)  Acc@5: 93.7500 (92.8770)  time: 0.3521  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.2347  Acc@1: 62.5000 (63.9494)  Acc@5: 93.7500 (92.8678)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4725  Acc@1: 68.7500 (63.9873)  Acc@5: 93.7500 (92.8928)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0454  Acc@1: 68.7500 (63.9514)  Acc@5: 93.7500 (92.8612)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5309  Acc@1: 62.5000 (63.9217)  Acc@5: 93.7500 (92.8524)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7643  Acc@1: 68.7500 (63.9920)  Acc@5: 93.7500 (92.8824)  time: 0.3460  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9628  Acc@1: 68.7500 (63.9954)  Acc@5: 93.7500 (92.8681)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8406  Acc@1: 68.7500 (64.0022)  Acc@5: 93.7500 (92.8716)  time: 0.3369  data: 0.0003  max mem: 2502
Train: Epoch[2/5] Total time: 0:06:38 (0.3487 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 36514, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 36258, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 36530, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 36402, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.8406  Acc@1: 68.7500 (64.0022)  Acc@5: 93.7500 (92.8716)
Train: Epoch[3/5]  [   0/1142]  eta: 0:11:13  Lr: 0.001875  Loss: -0.3471  Acc@1: 62.5000 (62.5000)  Acc@5: 81.2500 (81.2500)  time: 0.5901  data: 0.2414  max mem: 2502
Train: Epoch[3/5]  [  10/1142]  eta: 0:06:55  Lr: 0.001875  Loss: -0.4627  Acc@1: 68.7500 (68.1818)  Acc@5: 100.0000 (94.8864)  time: 0.3667  data: 0.0222  max mem: 2502
Train: Epoch[3/5]  [  20/1142]  eta: 0:06:39  Lr: 0.001875  Loss: -0.9217  Acc@1: 68.7500 (66.3690)  Acc@5: 93.7500 (93.7500)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  30/1142]  eta: 0:06:32  Lr: 0.001875  Loss: -0.5829  Acc@1: 62.5000 (63.3065)  Acc@5: 93.7500 (93.5484)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  40/1142]  eta: 0:06:27  Lr: 0.001875  Loss: -0.2742  Acc@1: 62.5000 (63.7195)  Acc@5: 100.0000 (94.3598)  time: 0.3470  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  50/1142]  eta: 0:06:23  Lr: 0.001875  Loss: -0.7371  Acc@1: 62.5000 (64.0931)  Acc@5: 100.0000 (94.8529)  time: 0.3496  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [  60/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.2508  Acc@1: 56.2500 (62.9098)  Acc@5: 93.7500 (94.1598)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [  70/1142]  eta: 0:06:16  Lr: 0.001875  Loss: -0.2154  Acc@1: 62.5000 (62.6761)  Acc@5: 93.7500 (93.3979)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [  80/1142]  eta: 0:06:12  Lr: 0.001875  Loss: -0.1222  Acc@1: 62.5000 (62.9630)  Acc@5: 87.5000 (93.1327)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:08  Lr: 0.001875  Loss: -0.5443  Acc@1: 68.7500 (63.3242)  Acc@5: 93.7500 (93.2005)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:04  Lr: 0.001875  Loss: 0.3793  Acc@1: 62.5000 (63.2426)  Acc@5: 93.7500 (93.0074)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 110/1142]  eta: 0:06:01  Lr: 0.001875  Loss: 0.3017  Acc@1: 62.5000 (63.1757)  Acc@5: 93.7500 (92.9054)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 120/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.6174  Acc@1: 62.5000 (63.5847)  Acc@5: 93.7500 (93.1302)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 130/1142]  eta: 0:05:54  Lr: 0.001875  Loss: -0.7151  Acc@1: 68.7500 (63.9313)  Acc@5: 93.7500 (93.0821)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 140/1142]  eta: 0:05:50  Lr: 0.001875  Loss: -0.3588  Acc@1: 68.7500 (64.1844)  Acc@5: 93.7500 (93.2624)  time: 0.3502  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 150/1142]  eta: 0:05:47  Lr: 0.001875  Loss: -0.7624  Acc@1: 62.5000 (64.1970)  Acc@5: 93.7500 (93.3775)  time: 0.3504  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 160/1142]  eta: 0:05:44  Lr: 0.001875  Loss: -0.8039  Acc@1: 62.5000 (64.2081)  Acc@5: 93.7500 (93.4394)  time: 0.3531  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 170/1142]  eta: 0:05:40  Lr: 0.001875  Loss: -0.2821  Acc@1: 68.7500 (64.5468)  Acc@5: 93.7500 (93.5673)  time: 0.3530  data: 0.0028  max mem: 2502
Train: Epoch[3/5]  [ 180/1142]  eta: 0:05:37  Lr: 0.001875  Loss: -0.4607  Acc@1: 68.7500 (64.6409)  Acc@5: 93.7500 (93.4392)  time: 0.3506  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [ 190/1142]  eta: 0:05:33  Lr: 0.001875  Loss: -0.1883  Acc@1: 62.5000 (64.3652)  Acc@5: 93.7500 (93.3246)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 200/1142]  eta: 0:05:29  Lr: 0.001875  Loss: -0.4405  Acc@1: 62.5000 (64.4590)  Acc@5: 93.7500 (93.4701)  time: 0.3482  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 210/1142]  eta: 0:05:26  Lr: 0.001875  Loss: 0.0760  Acc@1: 62.5000 (64.4254)  Acc@5: 93.7500 (93.3649)  time: 0.3486  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [ 220/1142]  eta: 0:05:22  Lr: 0.001875  Loss: -0.6891  Acc@1: 62.5000 (64.3100)  Acc@5: 93.7500 (93.3541)  time: 0.3490  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:19  Lr: 0.001875  Loss: -0.2629  Acc@1: 62.5000 (64.4210)  Acc@5: 93.7500 (93.3712)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:15  Lr: 0.001875  Loss: 0.7692  Acc@1: 68.7500 (64.4710)  Acc@5: 93.7500 (93.3351)  time: 0.3486  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.5574  Acc@1: 68.7500 (64.4671)  Acc@5: 93.7500 (93.2769)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:08  Lr: 0.001875  Loss: -0.5476  Acc@1: 62.5000 (64.5115)  Acc@5: 93.7500 (93.1992)  time: 0.3474  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.4066  Acc@1: 62.5000 (64.2989)  Acc@5: 93.7500 (93.1734)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 280/1142]  eta: 0:05:01  Lr: 0.001875  Loss: -0.2115  Acc@1: 62.5000 (64.4795)  Acc@5: 93.7500 (93.0827)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 290/1142]  eta: 0:04:57  Lr: 0.001875  Loss: -0.2793  Acc@1: 62.5000 (64.4545)  Acc@5: 93.7500 (93.0412)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 300/1142]  eta: 0:04:54  Lr: 0.001875  Loss: -0.6331  Acc@1: 62.5000 (64.4518)  Acc@5: 93.7500 (93.0648)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 310/1142]  eta: 0:04:50  Lr: 0.001875  Loss: 0.3202  Acc@1: 62.5000 (64.4092)  Acc@5: 93.7500 (93.1069)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 320/1142]  eta: 0:04:47  Lr: 0.001875  Loss: -0.8225  Acc@1: 68.7500 (64.6223)  Acc@5: 93.7500 (93.2243)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 330/1142]  eta: 0:04:43  Lr: 0.001875  Loss: -0.4949  Acc@1: 68.7500 (64.6715)  Acc@5: 93.7500 (93.2402)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 340/1142]  eta: 0:04:39  Lr: 0.001875  Loss: -0.2674  Acc@1: 68.7500 (64.7911)  Acc@5: 93.7500 (93.2185)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 350/1142]  eta: 0:04:36  Lr: 0.001875  Loss: 0.1116  Acc@1: 62.5000 (64.7258)  Acc@5: 93.7500 (93.2158)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 360/1142]  eta: 0:04:32  Lr: 0.001875  Loss: -0.0988  Acc@1: 62.5000 (64.6988)  Acc@5: 93.7500 (93.1267)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 370/1142]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6814  Acc@1: 68.7500 (64.8585)  Acc@5: 93.7500 (93.2278)  time: 0.3465  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 380/1142]  eta: 0:04:25  Lr: 0.001875  Loss: -0.1872  Acc@1: 68.7500 (64.9442)  Acc@5: 100.0000 (93.3071)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 390/1142]  eta: 0:04:22  Lr: 0.001875  Loss: -0.6298  Acc@1: 68.7500 (64.9776)  Acc@5: 93.7500 (93.3664)  time: 0.3487  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 400/1142]  eta: 0:04:18  Lr: 0.001875  Loss: 0.2479  Acc@1: 68.7500 (64.9314)  Acc@5: 93.7500 (93.4227)  time: 0.3493  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 410/1142]  eta: 0:04:15  Lr: 0.001875  Loss: -0.2287  Acc@1: 68.7500 (64.8571)  Acc@5: 93.7500 (93.4002)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 420/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -0.2626  Acc@1: 68.7500 (65.0386)  Acc@5: 93.7500 (93.4086)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 430/1142]  eta: 0:04:08  Lr: 0.001875  Loss: -0.2190  Acc@1: 68.7500 (65.0377)  Acc@5: 93.7500 (93.4020)  time: 0.3488  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.2876  Acc@1: 56.2500 (65.0510)  Acc@5: 93.7500 (93.4524)  time: 0.3492  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 450/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.5712  Acc@1: 68.7500 (65.2439)  Acc@5: 93.7500 (93.4728)  time: 0.3513  data: 0.0023  max mem: 2502
Train: Epoch[3/5]  [ 460/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.3131  Acc@1: 68.7500 (65.2522)  Acc@5: 93.7500 (93.5195)  time: 0.3528  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [ 470/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.8430  Acc@1: 68.7500 (65.3662)  Acc@5: 93.7500 (93.5775)  time: 0.3550  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 480/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -0.4109  Acc@1: 68.7500 (65.3976)  Acc@5: 100.0000 (93.6331)  time: 0.3560  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 490/1142]  eta: 0:03:47  Lr: 0.001875  Loss: 0.0446  Acc@1: 62.5000 (65.2622)  Acc@5: 93.7500 (93.6354)  time: 0.3530  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 500/1142]  eta: 0:03:44  Lr: 0.001875  Loss: 0.1975  Acc@1: 62.5000 (65.1821)  Acc@5: 93.7500 (93.5504)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 510/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.7576  Acc@1: 62.5000 (65.1419)  Acc@5: 93.7500 (93.5054)  time: 0.3491  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 520/1142]  eta: 0:03:37  Lr: 0.001875  Loss: -0.2032  Acc@1: 62.5000 (65.1272)  Acc@5: 93.7500 (93.5101)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 530/1142]  eta: 0:03:33  Lr: 0.001875  Loss: -0.0252  Acc@1: 62.5000 (65.1601)  Acc@5: 93.7500 (93.5264)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 540/1142]  eta: 0:03:30  Lr: 0.001875  Loss: 0.0267  Acc@1: 68.7500 (65.2033)  Acc@5: 93.7500 (93.5189)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 550/1142]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7438  Acc@1: 68.7500 (65.2790)  Acc@5: 93.7500 (93.5799)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.3016  Acc@1: 68.7500 (65.2741)  Acc@5: 100.0000 (93.5829)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:19  Lr: 0.001875  Loss: -0.2292  Acc@1: 68.7500 (65.2145)  Acc@5: 93.7500 (93.5858)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: -0.4638  Acc@1: 56.2500 (65.0495)  Acc@5: 93.7500 (93.5456)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:12  Lr: 0.001875  Loss: -0.6294  Acc@1: 62.5000 (65.0275)  Acc@5: 93.7500 (93.5279)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: -0.5016  Acc@1: 62.5000 (64.9750)  Acc@5: 93.7500 (93.5212)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:05  Lr: 0.001875  Loss: -0.8826  Acc@1: 62.5000 (65.0982)  Acc@5: 93.7500 (93.5352)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.0703  Acc@1: 68.7500 (64.9960)  Acc@5: 93.7500 (93.5386)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 630/1142]  eta: 0:02:58  Lr: 0.001875  Loss: 0.0391  Acc@1: 68.7500 (65.0753)  Acc@5: 93.7500 (93.5519)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: 0.0332  Acc@1: 68.7500 (65.0644)  Acc@5: 93.7500 (93.5257)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.6437  Acc@1: 62.5000 (64.9962)  Acc@5: 93.7500 (93.5100)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.5141  Acc@1: 62.5000 (65.0151)  Acc@5: 93.7500 (93.5231)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.0980  Acc@1: 68.7500 (65.0428)  Acc@5: 93.7500 (93.5358)  time: 0.3456  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.8419  Acc@1: 62.5000 (64.9963)  Acc@5: 93.7500 (93.5022)  time: 0.3454  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4840  Acc@1: 62.5000 (65.0778)  Acc@5: 93.7500 (93.5058)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.4616  Acc@1: 68.7500 (65.0588)  Acc@5: 93.7500 (93.5360)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.6053  Acc@1: 68.7500 (65.1020)  Acc@5: 93.7500 (93.5127)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.0961  Acc@1: 68.7500 (65.1266)  Acc@5: 93.7500 (93.5246)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.5173  Acc@1: 68.7500 (65.0821)  Acc@5: 93.7500 (93.4508)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.4791  Acc@1: 62.5000 (65.0304)  Acc@5: 93.7500 (93.4464)  time: 0.3460  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: -0.1578  Acc@1: 62.5000 (64.9634)  Acc@5: 93.7500 (93.4587)  time: 0.3483  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: 0.3368  Acc@1: 62.5000 (64.9146)  Acc@5: 93.7500 (93.4461)  time: 0.3509  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8331  Acc@1: 62.5000 (64.9319)  Acc@5: 93.7500 (93.4176)  time: 0.3503  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.4423  Acc@1: 68.7500 (64.9168)  Acc@5: 93.7500 (93.4059)  time: 0.3486  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.3073  Acc@1: 62.5000 (64.8546)  Acc@5: 93.7500 (93.3865)  time: 0.3503  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -1.0132  Acc@1: 62.5000 (64.9579)  Acc@5: 93.7500 (93.3833)  time: 0.3497  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.6210  Acc@1: 62.5000 (64.9199)  Acc@5: 93.7500 (93.4109)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.5817  Acc@1: 62.5000 (64.9361)  Acc@5: 93.7500 (93.4074)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.3770  Acc@1: 68.7500 (64.9519)  Acc@5: 93.7500 (93.3965)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7294  Acc@1: 68.7500 (64.9227)  Acc@5: 93.7500 (93.3859)  time: 0.3490  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.3767  Acc@1: 68.7500 (64.9310)  Acc@5: 93.7500 (93.3828)  time: 0.3498  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.5474  Acc@1: 68.7500 (64.9390)  Acc@5: 93.7500 (93.3362)  time: 0.3489  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.3446  Acc@1: 68.7500 (65.0545)  Acc@5: 93.7500 (93.3697)  time: 0.3491  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.0866  Acc@1: 75.0000 (65.1390)  Acc@5: 93.7500 (93.3882)  time: 0.3502  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.5551  Acc@1: 68.7500 (65.0954)  Acc@5: 93.7500 (93.4133)  time: 0.3490  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5745  Acc@1: 62.5000 (65.0527)  Acc@5: 93.7500 (93.4309)  time: 0.3479  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.3531  Acc@1: 62.5000 (65.0521)  Acc@5: 93.7500 (93.4413)  time: 0.3482  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.0604  Acc@1: 62.5000 (65.0244)  Acc@5: 93.7500 (93.4243)  time: 0.3492  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.1547  Acc@1: 62.5000 (65.1316)  Acc@5: 93.7500 (93.4278)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7108  Acc@1: 75.0000 (65.1567)  Acc@5: 93.7500 (93.4578)  time: 0.3485  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.1291  Acc@1: 68.7500 (65.1617)  Acc@5: 93.7500 (93.4674)  time: 0.3523  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4440  Acc@1: 68.7500 (65.1405)  Acc@5: 93.7500 (93.4703)  time: 0.3529  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.2451  Acc@1: 68.7500 (65.1326)  Acc@5: 93.7500 (93.4732)  time: 0.3520  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.2930  Acc@1: 68.7500 (65.1822)  Acc@5: 100.0000 (93.5143)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.7830  Acc@1: 68.7500 (65.1867)  Acc@5: 93.7500 (93.5166)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.5987  Acc@1: 62.5000 (65.1786)  Acc@5: 93.7500 (93.5190)  time: 0.3476  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: 0.1622  Acc@1: 62.5000 (65.2386)  Acc@5: 93.7500 (93.5089)  time: 0.3485  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.3880  Acc@1: 62.5000 (65.2363)  Acc@5: 93.7500 (93.5051)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.3269  Acc@1: 62.5000 (65.2158)  Acc@5: 93.7500 (93.5196)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.8575  Acc@1: 62.5000 (65.2378)  Acc@5: 100.0000 (93.5399)  time: 0.3492  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.1274  Acc@1: 68.7500 (65.2593)  Acc@5: 93.7500 (93.5240)  time: 0.3514  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.9780  Acc@1: 62.5000 (65.2745)  Acc@5: 93.7500 (93.5379)  time: 0.3514  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0875  Acc@1: 62.5000 (65.2953)  Acc@5: 93.7500 (93.5458)  time: 0.3502  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.3363  Acc@1: 68.7500 (65.3446)  Acc@5: 93.7500 (93.5534)  time: 0.3496  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.7805  Acc@1: 68.7500 (65.4102)  Acc@5: 93.7500 (93.5667)  time: 0.3499  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4086  Acc@1: 68.7500 (65.4292)  Acc@5: 93.7500 (93.5797)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0457  Acc@1: 68.7500 (65.5041)  Acc@5: 93.7500 (93.5587)  time: 0.3495  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6716  Acc@1: 62.5000 (65.4884)  Acc@5: 93.7500 (93.5716)  time: 0.3516  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.1040  Acc@1: 62.5000 (65.4730)  Acc@5: 93.7500 (93.5566)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4382  Acc@1: 62.5000 (65.4798)  Acc@5: 93.7500 (93.5802)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -1.3163  Acc@1: 62.5000 (65.4969)  Acc@5: 93.7500 (93.5834)  time: 0.3412  data: 0.0008  max mem: 2502
Train: Epoch[3/5] Total time: 0:06:38 (0.3491 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 54779, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 54523, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 54795, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 54667, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.3163  Acc@1: 62.5000 (65.4969)  Acc@5: 93.7500 (93.5834)
Train: Epoch[4/5]  [   0/1142]  eta: 0:15:28  Lr: 0.001875  Loss: -0.6989  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.8134  data: 0.4648  max mem: 2502
Train: Epoch[4/5]  [  10/1142]  eta: 0:07:22  Lr: 0.001875  Loss: -0.3914  Acc@1: 68.7500 (67.0455)  Acc@5: 93.7500 (91.4773)  time: 0.3906  data: 0.0433  max mem: 2502
Train: Epoch[4/5]  [  20/1142]  eta: 0:06:57  Lr: 0.001875  Loss: -0.4353  Acc@1: 68.7500 (68.1548)  Acc@5: 93.7500 (94.0476)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [  30/1142]  eta: 0:06:45  Lr: 0.001875  Loss: -0.6920  Acc@1: 68.7500 (64.9194)  Acc@5: 93.7500 (92.7419)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [  40/1142]  eta: 0:06:37  Lr: 0.001875  Loss: 0.0492  Acc@1: 62.5000 (65.7012)  Acc@5: 93.7500 (92.8354)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  50/1142]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6124  Acc@1: 68.7500 (66.9118)  Acc@5: 93.7500 (92.6471)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  60/1142]  eta: 0:06:25  Lr: 0.001875  Loss: -0.5799  Acc@1: 68.7500 (66.3934)  Acc@5: 93.7500 (92.8279)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  70/1142]  eta: 0:06:20  Lr: 0.001875  Loss: -0.3648  Acc@1: 62.5000 (66.5493)  Acc@5: 93.7500 (93.0458)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  80/1142]  eta: 0:06:16  Lr: 0.001875  Loss: -0.3264  Acc@1: 62.5000 (66.5895)  Acc@5: 93.7500 (93.4414)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:11  Lr: 0.001875  Loss: -0.5759  Acc@1: 62.5000 (66.8269)  Acc@5: 93.7500 (93.5440)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:07  Lr: 0.001875  Loss: -0.3676  Acc@1: 62.5000 (66.8936)  Acc@5: 93.7500 (93.2550)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 110/1142]  eta: 0:06:03  Lr: 0.001875  Loss: -0.6425  Acc@1: 68.7500 (67.1734)  Acc@5: 93.7500 (93.3559)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 120/1142]  eta: 0:05:59  Lr: 0.001875  Loss: -0.7920  Acc@1: 75.0000 (67.8202)  Acc@5: 93.7500 (93.6983)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 130/1142]  eta: 0:05:55  Lr: 0.001875  Loss: -0.3571  Acc@1: 68.7500 (67.1279)  Acc@5: 93.7500 (93.4637)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 140/1142]  eta: 0:05:51  Lr: 0.001875  Loss: -0.9252  Acc@1: 62.5000 (67.3316)  Acc@5: 93.7500 (93.6170)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 150/1142]  eta: 0:05:47  Lr: 0.001875  Loss: 0.0064  Acc@1: 68.7500 (67.4255)  Acc@5: 100.0000 (93.5017)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 160/1142]  eta: 0:05:43  Lr: 0.001875  Loss: -1.0917  Acc@1: 68.7500 (67.5854)  Acc@5: 93.7500 (93.4783)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 170/1142]  eta: 0:05:40  Lr: 0.001875  Loss: -0.6352  Acc@1: 68.7500 (67.8728)  Acc@5: 93.7500 (93.7500)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 180/1142]  eta: 0:05:36  Lr: 0.001875  Loss: -0.4265  Acc@1: 68.7500 (67.9558)  Acc@5: 93.7500 (93.6809)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 190/1142]  eta: 0:05:32  Lr: 0.001875  Loss: -0.1451  Acc@1: 62.5000 (67.4738)  Acc@5: 93.7500 (93.8154)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 200/1142]  eta: 0:05:29  Lr: 0.001875  Loss: -0.1677  Acc@1: 62.5000 (67.3818)  Acc@5: 100.0000 (93.9366)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 210/1142]  eta: 0:05:25  Lr: 0.001875  Loss: -0.6123  Acc@1: 62.5000 (67.2097)  Acc@5: 93.7500 (93.9277)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 220/1142]  eta: 0:05:21  Lr: 0.001875  Loss: -1.0169  Acc@1: 62.5000 (67.2794)  Acc@5: 93.7500 (93.9762)  time: 0.3453  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 230/1142]  eta: 0:05:18  Lr: 0.001875  Loss: 0.0362  Acc@1: 68.7500 (67.1266)  Acc@5: 93.7500 (93.8853)  time: 0.3470  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:14  Lr: 0.001875  Loss: -1.0259  Acc@1: 62.5000 (67.2718)  Acc@5: 93.7500 (93.9056)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:11  Lr: 0.001875  Loss: -0.3163  Acc@1: 68.7500 (67.3556)  Acc@5: 93.7500 (93.9243)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:07  Lr: 0.001875  Loss: -0.6818  Acc@1: 62.5000 (67.1216)  Acc@5: 93.7500 (93.9416)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.6426  Acc@1: 68.7500 (67.1587)  Acc@5: 93.7500 (93.9806)  time: 0.3495  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 280/1142]  eta: 0:05:00  Lr: 0.001875  Loss: -0.7362  Acc@1: 68.7500 (67.1708)  Acc@5: 93.7500 (93.9724)  time: 0.3501  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 290/1142]  eta: 0:04:57  Lr: 0.001875  Loss: -0.3500  Acc@1: 75.0000 (67.2466)  Acc@5: 93.7500 (94.0077)  time: 0.3508  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [ 300/1142]  eta: 0:04:53  Lr: 0.001875  Loss: 0.0144  Acc@1: 62.5000 (67.0266)  Acc@5: 93.7500 (93.9369)  time: 0.3494  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 310/1142]  eta: 0:04:50  Lr: 0.001875  Loss: -0.0737  Acc@1: 56.2500 (66.6600)  Acc@5: 93.7500 (93.8907)  time: 0.3495  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [ 320/1142]  eta: 0:04:46  Lr: 0.001875  Loss: -0.2112  Acc@1: 56.2500 (66.6277)  Acc@5: 93.7500 (93.8668)  time: 0.3501  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 330/1142]  eta: 0:04:43  Lr: 0.001875  Loss: -0.3533  Acc@1: 68.7500 (66.6918)  Acc@5: 93.7500 (93.7689)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 340/1142]  eta: 0:04:40  Lr: 0.001875  Loss: -1.0770  Acc@1: 68.7500 (66.8438)  Acc@5: 93.7500 (93.7683)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 350/1142]  eta: 0:04:36  Lr: 0.001875  Loss: -0.2111  Acc@1: 68.7500 (67.0228)  Acc@5: 93.7500 (93.7678)  time: 0.3517  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 360/1142]  eta: 0:04:33  Lr: 0.001875  Loss: 0.4160  Acc@1: 68.7500 (67.0187)  Acc@5: 93.7500 (93.7327)  time: 0.3513  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 370/1142]  eta: 0:04:29  Lr: 0.001875  Loss: -0.5588  Acc@1: 68.7500 (66.8969)  Acc@5: 93.7500 (93.6995)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:26  Lr: 0.001875  Loss: -0.4691  Acc@1: 62.5000 (66.8307)  Acc@5: 93.7500 (93.7336)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:22  Lr: 0.001875  Loss: 0.1023  Acc@1: 68.7500 (66.8478)  Acc@5: 93.7500 (93.6861)  time: 0.3476  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:19  Lr: 0.001875  Loss: -0.2842  Acc@1: 62.5000 (66.7394)  Acc@5: 93.7500 (93.6253)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:15  Lr: 0.001875  Loss: -0.3495  Acc@1: 62.5000 (66.8035)  Acc@5: 93.7500 (93.6892)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:12  Lr: 0.001875  Loss: -0.9630  Acc@1: 68.7500 (66.7310)  Acc@5: 93.7500 (93.7352)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:08  Lr: 0.001875  Loss: -0.2595  Acc@1: 62.5000 (66.6908)  Acc@5: 93.7500 (93.7210)  time: 0.3546  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.0646  Acc@1: 68.7500 (66.7659)  Acc@5: 93.7500 (93.7217)  time: 0.3523  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 450/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.6737  Acc@1: 68.7500 (66.7822)  Acc@5: 93.7500 (93.7639)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 460/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.3541  Acc@1: 68.7500 (66.7842)  Acc@5: 93.7500 (93.7364)  time: 0.3525  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 470/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.2771  Acc@1: 62.5000 (66.7197)  Acc@5: 93.7500 (93.6704)  time: 0.3496  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 480/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -0.3183  Acc@1: 62.5000 (66.6450)  Acc@5: 93.7500 (93.6590)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 490/1142]  eta: 0:03:47  Lr: 0.001875  Loss: -0.5001  Acc@1: 62.5000 (66.4969)  Acc@5: 93.7500 (93.6482)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 500/1142]  eta: 0:03:44  Lr: 0.001875  Loss: -0.7424  Acc@1: 62.5000 (66.4920)  Acc@5: 93.7500 (93.6377)  time: 0.3486  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 510/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.7455  Acc@1: 68.7500 (66.5729)  Acc@5: 93.7500 (93.6644)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 520/1142]  eta: 0:03:37  Lr: 0.001875  Loss: 0.4361  Acc@1: 68.7500 (66.5787)  Acc@5: 93.7500 (93.6060)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 530/1142]  eta: 0:03:33  Lr: 0.001875  Loss: -0.6718  Acc@1: 68.7500 (66.5725)  Acc@5: 93.7500 (93.6323)  time: 0.3491  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:30  Lr: 0.001875  Loss: -0.4098  Acc@1: 68.7500 (66.6474)  Acc@5: 93.7500 (93.6576)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:26  Lr: 0.001875  Loss: 0.0179  Acc@1: 68.7500 (66.6402)  Acc@5: 93.7500 (93.6593)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.4089  Acc@1: 62.5000 (66.5887)  Acc@5: 93.7500 (93.6163)  time: 0.3496  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:19  Lr: 0.001875  Loss: -0.5108  Acc@1: 62.5000 (66.6375)  Acc@5: 93.7500 (93.6077)  time: 0.3485  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: 0.2914  Acc@1: 62.5000 (66.5232)  Acc@5: 93.7500 (93.6102)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:12  Lr: 0.001875  Loss: -0.4272  Acc@1: 62.5000 (66.5186)  Acc@5: 93.7500 (93.6019)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: 0.0594  Acc@1: 68.7500 (66.4829)  Acc@5: 93.7500 (93.5732)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:05  Lr: 0.001875  Loss: 0.0222  Acc@1: 62.5000 (66.3871)  Acc@5: 93.7500 (93.5454)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.2537  Acc@1: 62.5000 (66.3748)  Acc@5: 93.7500 (93.5990)  time: 0.3487  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 630/1142]  eta: 0:02:58  Lr: 0.001875  Loss: 0.0954  Acc@1: 62.5000 (66.3728)  Acc@5: 93.7500 (93.5816)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.4549  Acc@1: 68.7500 (66.4099)  Acc@5: 93.7500 (93.5550)  time: 0.3488  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.3331  Acc@1: 68.7500 (66.4075)  Acc@5: 93.7500 (93.5772)  time: 0.3506  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.0210  Acc@1: 56.2500 (66.2349)  Acc@5: 93.7500 (93.5231)  time: 0.3502  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.4528  Acc@1: 56.2500 (66.2817)  Acc@5: 93.7500 (93.5823)  time: 0.3501  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.5272  Acc@1: 68.7500 (66.3363)  Acc@5: 100.0000 (93.6215)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.3291  Acc@1: 68.7500 (66.3983)  Acc@5: 93.7500 (93.6324)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.6952  Acc@1: 75.0000 (66.5389)  Acc@5: 93.7500 (93.6698)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.6770  Acc@1: 75.0000 (66.5436)  Acc@5: 93.7500 (93.6445)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.2308  Acc@1: 68.7500 (66.5222)  Acc@5: 93.7500 (93.6546)  time: 0.3477  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.5159  Acc@1: 68.7500 (66.5099)  Acc@5: 93.7500 (93.6218)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.8677  Acc@1: 68.7500 (66.5401)  Acc@5: 93.7500 (93.6235)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: 0.0839  Acc@1: 68.7500 (66.5613)  Acc@5: 93.7500 (93.6252)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.2080  Acc@1: 68.7500 (66.5079)  Acc@5: 93.7500 (93.5775)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.4396  Acc@1: 68.7500 (66.4721)  Acc@5: 93.7500 (93.5879)  time: 0.3528  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6299  Acc@1: 68.7500 (66.4453)  Acc@5: 93.7500 (93.5980)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.0756  Acc@1: 62.5000 (66.3875)  Acc@5: 93.7500 (93.5525)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.2373  Acc@1: 62.5000 (66.3311)  Acc@5: 93.7500 (93.5549)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4805  Acc@1: 62.5000 (66.2454)  Acc@5: 93.7500 (93.5342)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.1077  Acc@1: 62.5000 (66.2074)  Acc@5: 87.5000 (93.4912)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.4928  Acc@1: 68.7500 (66.2831)  Acc@5: 93.7500 (93.5093)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.4289  Acc@1: 68.7500 (66.2455)  Acc@5: 93.7500 (93.4676)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.2909  Acc@1: 68.7500 (66.2603)  Acc@5: 93.7500 (93.4636)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.5154  Acc@1: 68.7500 (66.2529)  Acc@5: 93.7500 (93.4596)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5312  Acc@1: 68.7500 (66.2887)  Acc@5: 93.7500 (93.4845)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: 0.1391  Acc@1: 68.7500 (66.2954)  Acc@5: 93.7500 (93.4946)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.7625  Acc@1: 68.7500 (66.3440)  Acc@5: 93.7500 (93.5045)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.1489  Acc@1: 68.7500 (66.2944)  Acc@5: 93.7500 (93.4725)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.1995  Acc@1: 68.7500 (66.3351)  Acc@5: 87.5000 (93.4481)  time: 0.3450  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8698  Acc@1: 68.7500 (66.3070)  Acc@5: 93.7500 (93.4107)  time: 0.3467  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5305  Acc@1: 68.7500 (66.3332)  Acc@5: 93.7500 (93.4076)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.1778  Acc@1: 68.7500 (66.3523)  Acc@5: 93.7500 (93.3913)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4523  Acc@1: 68.7500 (66.3906)  Acc@5: 93.7500 (93.4083)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.7777  Acc@1: 68.7500 (66.3697)  Acc@5: 93.7500 (93.3923)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.5243  Acc@1: 68.7500 (66.4457)  Acc@5: 93.7500 (93.4346)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.4217  Acc@1: 75.0000 (66.5201)  Acc@5: 93.7500 (93.4442)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.3554  Acc@1: 75.0000 (66.5805)  Acc@5: 93.7500 (93.4788)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6085  Acc@1: 75.0000 (66.6271)  Acc@5: 100.0000 (93.4815)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.6067  Acc@1: 68.7500 (66.6481)  Acc@5: 100.0000 (93.5089)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.1874  Acc@1: 68.7500 (66.6136)  Acc@5: 93.7500 (93.4745)  time: 0.3492  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.5114  Acc@1: 62.5000 (66.6101)  Acc@5: 93.7500 (93.4893)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6042  Acc@1: 68.7500 (66.6427)  Acc@5: 93.7500 (93.4978)  time: 0.3501  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.1414  Acc@1: 68.7500 (66.6211)  Acc@5: 93.7500 (93.5062)  time: 0.3560  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0814  Acc@1: 68.7500 (66.5999)  Acc@5: 93.7500 (93.4672)  time: 0.3553  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0415  Acc@1: 62.5000 (66.5616)  Acc@5: 93.7500 (93.4699)  time: 0.3545  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7330  Acc@1: 68.7500 (66.6397)  Acc@5: 93.7500 (93.4898)  time: 0.3544  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.9358  Acc@1: 68.7500 (66.6247)  Acc@5: 93.7500 (93.5037)  time: 0.3492  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4731  Acc@1: 62.5000 (66.5929)  Acc@5: 93.7500 (93.5116)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3937  Acc@1: 62.5000 (66.5448)  Acc@5: 93.7500 (93.4912)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0727  Acc@1: 62.5000 (66.5143)  Acc@5: 93.7500 (93.5103)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8779  Acc@1: 68.7500 (66.5396)  Acc@5: 93.7500 (93.5179)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6469  Acc@1: 68.7500 (66.5699)  Acc@5: 93.7500 (93.5364)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6323  Acc@1: 68.7500 (66.5699)  Acc@5: 93.7500 (93.5396)  time: 0.3407  data: 0.0006  max mem: 2502
Train: Epoch[4/5] Total time: 0:06:38 (0.3492 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 73044, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 72788, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 73060, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 72932, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6323  Acc@1: 68.7500 (66.5699)  Acc@5: 93.7500 (93.5396)
Train: Epoch[5/5]  [   0/1142]  eta: 0:16:49  Lr: 0.001875  Loss: -0.2288  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.8840  data: 0.5350  max mem: 2502
Train: Epoch[5/5]  [  10/1142]  eta: 0:07:28  Lr: 0.001875  Loss: -0.3759  Acc@1: 68.7500 (67.0455)  Acc@5: 93.7500 (92.0455)  time: 0.3966  data: 0.0495  max mem: 2502
Train: Epoch[5/5]  [  20/1142]  eta: 0:07:00  Lr: 0.001875  Loss: -0.2902  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.4524)  time: 0.3493  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [  30/1142]  eta: 0:06:47  Lr: 0.001875  Loss: 0.2409  Acc@1: 68.7500 (67.7419)  Acc@5: 93.7500 (92.3387)  time: 0.3502  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [  40/1142]  eta: 0:06:39  Lr: 0.001875  Loss: -0.2363  Acc@1: 62.5000 (67.6829)  Acc@5: 93.7500 (92.9878)  time: 0.3497  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [  50/1142]  eta: 0:06:32  Lr: 0.001875  Loss: -0.6111  Acc@1: 75.0000 (68.8725)  Acc@5: 93.7500 (93.2598)  time: 0.3493  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [  60/1142]  eta: 0:06:27  Lr: 0.001875  Loss: -0.8342  Acc@1: 75.0000 (68.7500)  Acc@5: 93.7500 (93.1352)  time: 0.3487  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [  70/1142]  eta: 0:06:22  Lr: 0.001875  Loss: -1.0811  Acc@1: 68.7500 (69.4542)  Acc@5: 93.7500 (93.6620)  time: 0.3484  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [  80/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.3217  Acc@1: 68.7500 (68.9043)  Acc@5: 93.7500 (93.7500)  time: 0.3550  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:14  Lr: 0.001875  Loss: -0.9092  Acc@1: 68.7500 (68.9560)  Acc@5: 93.7500 (93.8187)  time: 0.3541  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:09  Lr: 0.001875  Loss: -0.3612  Acc@1: 68.7500 (68.5644)  Acc@5: 93.7500 (93.8738)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 110/1142]  eta: 0:06:05  Lr: 0.001875  Loss: -0.4119  Acc@1: 62.5000 (68.0743)  Acc@5: 93.7500 (93.9189)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 120/1142]  eta: 0:06:01  Lr: 0.001875  Loss: -0.1140  Acc@1: 62.5000 (67.3037)  Acc@5: 93.7500 (93.5950)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 130/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.1165  Acc@1: 62.5000 (67.3664)  Acc@5: 93.7500 (93.7023)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 140/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.2786  Acc@1: 62.5000 (67.5089)  Acc@5: 93.7500 (93.6613)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 150/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.4516  Acc@1: 62.5000 (67.4255)  Acc@5: 93.7500 (93.6672)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 160/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.3235  Acc@1: 62.5000 (66.8866)  Acc@5: 93.7500 (93.5947)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 170/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6837  Acc@1: 56.2500 (66.8129)  Acc@5: 93.7500 (93.6404)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 180/1142]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6485  Acc@1: 56.2500 (66.4710)  Acc@5: 93.7500 (93.5773)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 190/1142]  eta: 0:05:33  Lr: 0.001875  Loss: -0.9642  Acc@1: 56.2500 (66.4267)  Acc@5: 93.7500 (93.5864)  time: 0.3477  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 200/1142]  eta: 0:05:30  Lr: 0.001875  Loss: 0.0616  Acc@1: 68.7500 (66.4179)  Acc@5: 93.7500 (93.5012)  time: 0.3493  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 210/1142]  eta: 0:05:26  Lr: 0.001875  Loss: -0.8011  Acc@1: 68.7500 (66.6173)  Acc@5: 93.7500 (93.6611)  time: 0.3483  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 220/1142]  eta: 0:05:23  Lr: 0.001875  Loss: -0.3487  Acc@1: 68.7500 (66.7138)  Acc@5: 100.0000 (93.7783)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:19  Lr: 0.001875  Loss: -0.3352  Acc@1: 68.7500 (66.9102)  Acc@5: 93.7500 (93.8312)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.4821  Acc@1: 68.7500 (66.9606)  Acc@5: 93.7500 (93.8797)  time: 0.3502  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2160  Acc@1: 62.5000 (66.8078)  Acc@5: 93.7500 (93.7749)  time: 0.3497  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.1202  Acc@1: 62.5000 (66.8103)  Acc@5: 93.7500 (93.8218)  time: 0.3481  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:05  Lr: 0.001875  Loss: -0.8203  Acc@1: 68.7500 (67.0434)  Acc@5: 100.0000 (93.9345)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 280/1142]  eta: 0:05:01  Lr: 0.001875  Loss: -0.5577  Acc@1: 75.0000 (67.3043)  Acc@5: 100.0000 (93.9724)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 290/1142]  eta: 0:04:58  Lr: 0.001875  Loss: -0.4808  Acc@1: 68.7500 (67.2466)  Acc@5: 93.7500 (93.8789)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 300/1142]  eta: 0:04:54  Lr: 0.001875  Loss: -0.4982  Acc@1: 68.7500 (67.3588)  Acc@5: 93.7500 (93.8331)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 310/1142]  eta: 0:04:51  Lr: 0.001875  Loss: -0.5974  Acc@1: 68.7500 (67.3432)  Acc@5: 93.7500 (93.8103)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 320/1142]  eta: 0:04:47  Lr: 0.001875  Loss: -0.3019  Acc@1: 62.5000 (67.2118)  Acc@5: 93.7500 (93.7889)  time: 0.3475  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 330/1142]  eta: 0:04:43  Lr: 0.001875  Loss: -0.5560  Acc@1: 62.5000 (67.2772)  Acc@5: 93.7500 (93.8444)  time: 0.3471  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 340/1142]  eta: 0:04:40  Lr: 0.001875  Loss: -0.4176  Acc@1: 68.7500 (67.2471)  Acc@5: 100.0000 (93.8966)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 350/1142]  eta: 0:04:36  Lr: 0.001875  Loss: -0.2913  Acc@1: 62.5000 (67.1474)  Acc@5: 93.7500 (93.8568)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 360/1142]  eta: 0:04:33  Lr: 0.001875  Loss: -0.4863  Acc@1: 62.5000 (67.1745)  Acc@5: 93.7500 (93.9058)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 370/1142]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6013  Acc@1: 68.7500 (67.3181)  Acc@5: 93.7500 (93.9185)  time: 0.3479  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:26  Lr: 0.001875  Loss: -0.5545  Acc@1: 68.7500 (67.2408)  Acc@5: 93.7500 (93.8812)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:22  Lr: 0.001875  Loss: -0.9128  Acc@1: 68.7500 (67.3753)  Acc@5: 93.7500 (93.9578)  time: 0.3510  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:19  Lr: 0.001875  Loss: -0.3822  Acc@1: 68.7500 (67.3784)  Acc@5: 100.0000 (93.9214)  time: 0.3529  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:15  Lr: 0.001875  Loss: -0.4016  Acc@1: 62.5000 (67.2749)  Acc@5: 93.7500 (93.8869)  time: 0.3537  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:12  Lr: 0.001875  Loss: -0.4423  Acc@1: 62.5000 (67.2803)  Acc@5: 100.0000 (93.9727)  time: 0.3529  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.7055  Acc@1: 68.7500 (67.3724)  Acc@5: 100.0000 (93.9965)  time: 0.3511  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.4189  Acc@1: 62.5000 (67.3044)  Acc@5: 93.7500 (93.9626)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4528  Acc@1: 62.5000 (67.2533)  Acc@5: 93.7500 (93.9717)  time: 0.3498  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 460/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.6879  Acc@1: 62.5000 (67.2044)  Acc@5: 93.7500 (93.9262)  time: 0.3507  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 470/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.3250  Acc@1: 62.5000 (67.1576)  Acc@5: 93.7500 (93.8429)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 480/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -0.0783  Acc@1: 62.5000 (67.1907)  Acc@5: 93.7500 (93.8280)  time: 0.3464  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 490/1142]  eta: 0:03:47  Lr: 0.001875  Loss: -0.7190  Acc@1: 68.7500 (67.3371)  Acc@5: 93.7500 (93.8391)  time: 0.3466  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 500/1142]  eta: 0:03:44  Lr: 0.001875  Loss: -0.3711  Acc@1: 62.5000 (67.1906)  Acc@5: 93.7500 (93.8373)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 510/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.5800  Acc@1: 62.5000 (67.1844)  Acc@5: 93.7500 (93.8601)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 520/1142]  eta: 0:03:37  Lr: 0.001875  Loss: -0.9754  Acc@1: 68.7500 (67.2505)  Acc@5: 93.7500 (93.8580)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 530/1142]  eta: 0:03:33  Lr: 0.001875  Loss: -0.3635  Acc@1: 75.0000 (67.3493)  Acc@5: 93.7500 (93.8795)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:30  Lr: 0.001875  Loss: -0.7615  Acc@1: 68.7500 (67.3637)  Acc@5: 93.7500 (93.8771)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7454  Acc@1: 68.7500 (67.2868)  Acc@5: 93.7500 (93.8861)  time: 0.3462  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.5501  Acc@1: 68.7500 (67.3685)  Acc@5: 93.7500 (93.9171)  time: 0.3489  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:19  Lr: 0.001875  Loss: -0.7187  Acc@1: 68.7500 (67.3380)  Acc@5: 93.7500 (93.8813)  time: 0.3493  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: -0.3270  Acc@1: 62.5000 (67.2655)  Acc@5: 93.7500 (93.8683)  time: 0.3483  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:12  Lr: 0.001875  Loss: -0.2302  Acc@1: 62.5000 (67.1954)  Acc@5: 93.7500 (93.8346)  time: 0.3518  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: -0.1593  Acc@1: 62.5000 (67.2109)  Acc@5: 93.7500 (93.7916)  time: 0.3525  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:05  Lr: 0.001875  Loss: 0.0811  Acc@1: 68.7500 (67.0827)  Acc@5: 93.7500 (93.8011)  time: 0.3530  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.3999  Acc@1: 62.5000 (67.1095)  Acc@5: 93.7500 (93.7601)  time: 0.3524  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 630/1142]  eta: 0:02:58  Lr: 0.001875  Loss: 0.0481  Acc@1: 75.0000 (67.2940)  Acc@5: 93.7500 (93.7995)  time: 0.3490  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.7373  Acc@1: 75.0000 (67.3264)  Acc@5: 93.7500 (93.7890)  time: 0.3493  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -1.0467  Acc@1: 75.0000 (67.4251)  Acc@5: 93.7500 (93.7980)  time: 0.3520  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.2896  Acc@1: 68.7500 (67.4546)  Acc@5: 93.7500 (93.7689)  time: 0.3502  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.3130  Acc@1: 68.7500 (67.4925)  Acc@5: 93.7500 (93.7966)  time: 0.3461  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.6743  Acc@1: 68.7500 (67.4835)  Acc@5: 93.7500 (93.7684)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.7415  Acc@1: 68.7500 (67.4837)  Acc@5: 93.7500 (93.8043)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.6842  Acc@1: 68.7500 (67.5642)  Acc@5: 93.7500 (93.8302)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4040  Acc@1: 68.7500 (67.5897)  Acc@5: 93.7500 (93.8203)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.5122  Acc@1: 68.7500 (67.5884)  Acc@5: 93.7500 (93.8193)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.1637  Acc@1: 62.5000 (67.5530)  Acc@5: 93.7500 (93.8269)  time: 0.3513  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.5855  Acc@1: 62.5000 (67.4848)  Acc@5: 93.7500 (93.8343)  time: 0.3539  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: 0.0008  Acc@1: 62.5000 (67.5266)  Acc@5: 93.7500 (93.8415)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.5987  Acc@1: 75.0000 (67.5673)  Acc@5: 93.7500 (93.8732)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.7050  Acc@1: 75.0000 (67.6637)  Acc@5: 100.0000 (93.9202)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.4869  Acc@1: 75.0000 (67.6777)  Acc@5: 93.7500 (93.9261)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.1090  Acc@1: 68.7500 (67.6517)  Acc@5: 93.7500 (93.9238)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.3324  Acc@1: 62.5000 (67.6264)  Acc@5: 93.7500 (93.9217)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.2042  Acc@1: 62.5000 (67.6480)  Acc@5: 93.7500 (93.9273)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.2969  Acc@1: 68.7500 (67.6462)  Acc@5: 93.7500 (93.9327)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.2023  Acc@1: 68.7500 (67.6444)  Acc@5: 93.7500 (93.9079)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.6165  Acc@1: 68.7500 (67.6353)  Acc@5: 93.7500 (93.8986)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.3366  Acc@1: 68.7500 (67.7071)  Acc@5: 93.7500 (93.9042)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.7511  Acc@1: 68.7500 (67.6974)  Acc@5: 93.7500 (93.9097)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5845  Acc@1: 68.7500 (67.7024)  Acc@5: 93.7500 (93.9150)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8026  Acc@1: 68.7500 (67.7355)  Acc@5: 93.7500 (93.9274)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.2067  Acc@1: 68.7500 (67.7189)  Acc@5: 93.7500 (93.9464)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: 0.0386  Acc@1: 62.5000 (67.6956)  Acc@5: 93.7500 (93.9581)  time: 0.3504  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.1011  Acc@1: 68.7500 (67.7003)  Acc@5: 93.7500 (93.9284)  time: 0.3487  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5798  Acc@1: 68.7500 (67.6846)  Acc@5: 93.7500 (93.9332)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7336  Acc@1: 68.7500 (67.6692)  Acc@5: 93.7500 (93.9245)  time: 0.3509  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.4405  Acc@1: 68.7500 (67.7072)  Acc@5: 93.7500 (93.9160)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7113  Acc@1: 68.7500 (67.7379)  Acc@5: 93.7500 (93.9340)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: 0.1467  Acc@1: 68.7500 (67.7419)  Acc@5: 93.7500 (93.9386)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.3726  Acc@1: 68.7500 (67.7523)  Acc@5: 93.7500 (93.9495)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.2115  Acc@1: 62.5000 (67.7625)  Acc@5: 93.7500 (93.9539)  time: 0.3489  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.1151  Acc@1: 62.5000 (67.6842)  Acc@5: 93.7500 (93.9203)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.0625  Acc@1: 62.5000 (67.6449)  Acc@5: 93.7500 (93.9186)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.0360  Acc@1: 68.7500 (67.6496)  Acc@5: 87.5000 (93.8613)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.5594  Acc@1: 68.7500 (67.6910)  Acc@5: 93.7500 (93.8663)  time: 0.3530  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.0829  Acc@1: 68.7500 (67.7194)  Acc@5: 93.7500 (93.8531)  time: 0.3531  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.0098  Acc@1: 68.7500 (67.7173)  Acc@5: 93.7500 (93.8220)  time: 0.3527  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.6412  Acc@1: 68.7500 (67.6974)  Acc@5: 87.5000 (93.7738)  time: 0.3538  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6069  Acc@1: 68.7500 (67.6838)  Acc@5: 93.7500 (93.7795)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.2160  Acc@1: 68.7500 (67.6646)  Acc@5: 93.7500 (93.7850)  time: 0.3501  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0749  Acc@1: 62.5000 (67.6226)  Acc@5: 93.7500 (93.7963)  time: 0.3501  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.5198  Acc@1: 62.5000 (67.6214)  Acc@5: 93.7500 (93.7901)  time: 0.3477  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7383  Acc@1: 68.7500 (67.6374)  Acc@5: 93.7500 (93.8068)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.4815  Acc@1: 68.7500 (67.6811)  Acc@5: 93.7500 (93.8288)  time: 0.3496  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4403  Acc@1: 75.0000 (67.7297)  Acc@5: 93.7500 (93.8336)  time: 0.3499  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.4594  Acc@1: 68.7500 (67.7111)  Acc@5: 93.7500 (93.8384)  time: 0.3492  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0418  Acc@1: 68.7500 (67.7038)  Acc@5: 93.7500 (93.8486)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9551  Acc@1: 68.7500 (67.7142)  Acc@5: 93.7500 (93.8516)  time: 0.3423  data: 0.0012  max mem: 2502
Train: Epoch[5/5] Total time: 0:06:39 (0.3494 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 91309, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 91053, 4: 0}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 0}, 18: {0: 16, 1: 0, 2: 0, 3: 91197, 4: 0}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.9551  Acc@1: 68.7500 (67.7142)  Acc@5: 93.7500 (93.8516)
Test: [Task 1]  [   0/1627]  eta: 0:18:57  Loss: 1.2843 (1.2843)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6994  data: 0.4823  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:57  Loss: 1.2379 (1.1443)  Acc@1: 68.7500 (67.6136)  Acc@5: 93.7500 (92.6136)  time: 0.2585  data: 0.0442  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:22  Loss: 1.1690 (1.1176)  Acc@1: 62.5000 (69.6429)  Acc@5: 93.7500 (91.9643)  time: 0.2150  data: 0.0005  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:08  Loss: 1.0744 (1.1229)  Acc@1: 75.0000 (69.9597)  Acc@5: 93.7500 (91.9355)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 1.1942 (1.1469)  Acc@1: 68.7500 (68.9024)  Acc@5: 93.7500 (91.7683)  time: 0.2150  data: 0.0005  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:58  Loss: 1.1665 (1.1204)  Acc@1: 68.7500 (70.3431)  Acc@5: 93.7500 (92.1569)  time: 0.2216  data: 0.0017  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:53  Loss: 1.1883 (1.1425)  Acc@1: 75.0000 (69.7746)  Acc@5: 93.7500 (91.7008)  time: 0.2226  data: 0.0018  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:48  Loss: 1.1055 (1.1346)  Acc@1: 68.7500 (69.9824)  Acc@5: 93.7500 (91.9894)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:44  Loss: 0.9155 (1.1223)  Acc@1: 68.7500 (70.3704)  Acc@5: 93.7500 (92.5154)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:40  Loss: 1.0646 (1.1349)  Acc@1: 68.7500 (69.8489)  Acc@5: 93.7500 (92.1703)  time: 0.2141  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:37  Loss: 1.2363 (1.1545)  Acc@1: 68.7500 (69.4926)  Acc@5: 87.5000 (91.5842)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:33  Loss: 1.0761 (1.1427)  Acc@1: 68.7500 (69.7072)  Acc@5: 93.7500 (92.0608)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:31  Loss: 1.0761 (1.1415)  Acc@1: 68.7500 (69.7831)  Acc@5: 93.7500 (92.0455)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:28  Loss: 1.1363 (1.1439)  Acc@1: 68.7500 (69.6565)  Acc@5: 93.7500 (92.0802)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:25  Loss: 1.1097 (1.1381)  Acc@1: 68.7500 (69.7252)  Acc@5: 93.7500 (92.0213)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:22  Loss: 0.8350 (1.1198)  Acc@1: 75.0000 (70.2401)  Acc@5: 93.7500 (92.2599)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:20  Loss: 0.8449 (1.1151)  Acc@1: 75.0000 (70.4581)  Acc@5: 100.0000 (92.3525)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:17  Loss: 0.9283 (1.1057)  Acc@1: 75.0000 (70.6506)  Acc@5: 93.7500 (92.4708)  time: 0.2148  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:15  Loss: 1.1463 (1.1178)  Acc@1: 68.7500 (70.3039)  Acc@5: 93.7500 (92.3343)  time: 0.2145  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:12  Loss: 1.1283 (1.1150)  Acc@1: 68.7500 (70.3861)  Acc@5: 93.7500 (92.2775)  time: 0.2138  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:10  Loss: 1.0771 (1.1140)  Acc@1: 75.0000 (70.6157)  Acc@5: 93.7500 (92.3818)  time: 0.2137  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:07  Loss: 1.0771 (1.1123)  Acc@1: 75.0000 (70.7938)  Acc@5: 93.7500 (92.4467)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:05  Loss: 0.9456 (1.1154)  Acc@1: 68.7500 (70.7862)  Acc@5: 93.7500 (92.3643)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:03  Loss: 0.9456 (1.1067)  Acc@1: 75.0000 (71.1039)  Acc@5: 93.7500 (92.5054)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:00  Loss: 0.9817 (1.1032)  Acc@1: 75.0000 (71.0840)  Acc@5: 93.7500 (92.5052)  time: 0.2135  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:04:58  Loss: 1.0080 (1.1082)  Acc@1: 68.7500 (71.0657)  Acc@5: 93.7500 (92.4552)  time: 0.2134  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:04:56  Loss: 1.0181 (1.1079)  Acc@1: 68.7500 (71.1446)  Acc@5: 93.7500 (92.4569)  time: 0.2131  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:53  Loss: 0.9255 (1.1011)  Acc@1: 75.0000 (71.2638)  Acc@5: 93.7500 (92.6199)  time: 0.2142  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:51  Loss: 0.9094 (1.1024)  Acc@1: 75.0000 (71.3078)  Acc@5: 93.7500 (92.5712)  time: 0.2148  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:49  Loss: 1.1040 (1.1025)  Acc@1: 75.0000 (71.3058)  Acc@5: 93.7500 (92.6332)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:47  Loss: 1.0568 (1.1007)  Acc@1: 75.0000 (71.3040)  Acc@5: 93.7500 (92.6495)  time: 0.2164  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:44  Loss: 1.0578 (1.1031)  Acc@1: 75.0000 (71.2018)  Acc@5: 93.7500 (92.6447)  time: 0.2161  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:42  Loss: 1.0614 (1.1011)  Acc@1: 68.7500 (71.1838)  Acc@5: 93.7500 (92.6791)  time: 0.2157  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:40  Loss: 0.9906 (1.0995)  Acc@1: 68.7500 (71.2613)  Acc@5: 93.7500 (92.7115)  time: 0.2158  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:38  Loss: 0.9906 (1.0994)  Acc@1: 68.7500 (71.2793)  Acc@5: 93.7500 (92.7603)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:36  Loss: 1.0225 (1.0982)  Acc@1: 75.0000 (71.3853)  Acc@5: 93.7500 (92.7172)  time: 0.2162  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:34  Loss: 1.0581 (1.0972)  Acc@1: 75.0000 (71.4855)  Acc@5: 93.7500 (92.6766)  time: 0.2164  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 1.0424 (1.0967)  Acc@1: 68.7500 (71.3612)  Acc@5: 93.7500 (92.7392)  time: 0.2169  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:30  Loss: 1.0321 (1.0955)  Acc@1: 68.7500 (71.2927)  Acc@5: 93.7500 (92.7165)  time: 0.2209  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:27  Loss: 1.0399 (1.0970)  Acc@1: 68.7500 (71.2756)  Acc@5: 93.7500 (92.6790)  time: 0.2215  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:25  Loss: 1.1193 (1.0983)  Acc@1: 68.7500 (71.1970)  Acc@5: 93.7500 (92.7057)  time: 0.2191  data: 0.0025  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:23  Loss: 1.0340 (1.0993)  Acc@1: 68.7500 (71.1831)  Acc@5: 93.7500 (92.6703)  time: 0.2193  data: 0.0024  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:21  Loss: 1.0222 (1.0987)  Acc@1: 68.7500 (71.1847)  Acc@5: 93.7500 (92.7257)  time: 0.2194  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:19  Loss: 0.9616 (1.0973)  Acc@1: 68.7500 (71.1572)  Acc@5: 93.7500 (92.7784)  time: 0.2168  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:17  Loss: 1.0822 (1.0967)  Acc@1: 68.7500 (71.2302)  Acc@5: 93.7500 (92.8430)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:15  Loss: 1.1627 (1.1003)  Acc@1: 68.7500 (71.1059)  Acc@5: 93.7500 (92.7661)  time: 0.2167  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 1.0691 (1.0996)  Acc@1: 68.7500 (71.0954)  Acc@5: 93.7500 (92.7874)  time: 0.2165  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:10  Loss: 0.9392 (1.0963)  Acc@1: 75.0000 (71.2580)  Acc@5: 93.7500 (92.7946)  time: 0.2173  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:08  Loss: 1.1260 (1.1007)  Acc@1: 68.7500 (71.1279)  Acc@5: 93.7500 (92.7495)  time: 0.2172  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:06  Loss: 1.1336 (1.1009)  Acc@1: 62.5000 (71.0922)  Acc@5: 93.7500 (92.7317)  time: 0.2163  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:04  Loss: 0.9933 (1.1019)  Acc@1: 68.7500 (71.0953)  Acc@5: 93.7500 (92.6896)  time: 0.2173  data: 0.0021  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:02  Loss: 1.0737 (1.1076)  Acc@1: 68.7500 (71.0127)  Acc@5: 93.7500 (92.6248)  time: 0.2158  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 1.1738 (1.1153)  Acc@1: 62.5000 (70.8853)  Acc@5: 87.5000 (92.5504)  time: 0.2164  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:03:57  Loss: 1.0475 (1.1109)  Acc@1: 75.0000 (71.0923)  Acc@5: 93.7500 (92.5965)  time: 0.2160  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:55  Loss: 1.0463 (1.1106)  Acc@1: 75.0000 (71.1067)  Acc@5: 93.7500 (92.5716)  time: 0.2151  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:53  Loss: 1.2294 (1.1132)  Acc@1: 68.7500 (71.0299)  Acc@5: 93.7500 (92.5590)  time: 0.2162  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:51  Loss: 1.2976 (1.1159)  Acc@1: 62.5000 (70.9336)  Acc@5: 93.7500 (92.6025)  time: 0.2197  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:49  Loss: 1.0748 (1.1143)  Acc@1: 68.7500 (71.0048)  Acc@5: 93.7500 (92.6007)  time: 0.2185  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:46  Loss: 1.0697 (1.1148)  Acc@1: 68.7500 (70.9660)  Acc@5: 93.7500 (92.5667)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:44  Loss: 1.1285 (1.1140)  Acc@1: 68.7500 (70.9179)  Acc@5: 93.7500 (92.6290)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:42  Loss: 1.0454 (1.1160)  Acc@1: 68.7500 (70.8819)  Acc@5: 93.7500 (92.6165)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:40  Loss: 1.1341 (1.1153)  Acc@1: 68.7500 (70.8879)  Acc@5: 93.7500 (92.6555)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:38  Loss: 1.1341 (1.1168)  Acc@1: 68.7500 (70.8434)  Acc@5: 93.7500 (92.6027)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 0.9852 (1.1173)  Acc@1: 75.0000 (70.8697)  Acc@5: 93.7500 (92.6307)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 0.9611 (1.1172)  Acc@1: 75.0000 (70.9341)  Acc@5: 93.7500 (92.6092)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:31  Loss: 1.0156 (1.1169)  Acc@1: 75.0000 (70.9389)  Acc@5: 93.7500 (92.6171)  time: 0.2156  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:29  Loss: 1.0218 (1.1159)  Acc@1: 68.7500 (70.9909)  Acc@5: 93.7500 (92.6248)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:27  Loss: 1.1127 (1.1155)  Acc@1: 75.0000 (71.0507)  Acc@5: 93.7500 (92.6136)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 1.0669 (1.1149)  Acc@1: 75.0000 (71.0720)  Acc@5: 93.7500 (92.6120)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 1.0459 (1.1127)  Acc@1: 75.0000 (71.1559)  Acc@5: 93.7500 (92.6556)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 1.1173 (1.1129)  Acc@1: 75.0000 (71.1840)  Acc@5: 93.7500 (92.6890)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 1.1049 (1.1108)  Acc@1: 75.0000 (71.2465)  Acc@5: 93.7500 (92.7039)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:16  Loss: 0.9737 (1.1091)  Acc@1: 75.0000 (71.2899)  Acc@5: 93.7500 (92.7271)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 1.0394 (1.1099)  Acc@1: 68.7500 (71.2380)  Acc@5: 93.7500 (92.7326)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 1.0890 (1.1115)  Acc@1: 68.7500 (71.2129)  Acc@5: 93.7500 (92.6957)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 1.1134 (1.1102)  Acc@1: 68.7500 (71.2883)  Acc@5: 93.7500 (92.7180)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 1.2162 (1.1135)  Acc@1: 68.7500 (71.1892)  Acc@5: 93.7500 (92.6741)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 0.9572 (1.1094)  Acc@1: 75.0000 (71.3197)  Acc@5: 93.7500 (92.7205)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:03  Loss: 0.8725 (1.1072)  Acc@1: 75.0000 (71.3828)  Acc@5: 100.0000 (92.7737)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 0.8754 (1.1089)  Acc@1: 75.0000 (71.4128)  Acc@5: 100.0000 (92.7465)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 1.0641 (1.1073)  Acc@1: 75.0000 (71.4419)  Acc@5: 93.7500 (92.7591)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 0.8894 (1.1063)  Acc@1: 75.0000 (71.5244)  Acc@5: 93.7500 (92.7713)  time: 0.2156  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 0.9310 (1.1060)  Acc@1: 75.0000 (71.5134)  Acc@5: 100.0000 (92.7908)  time: 0.2164  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 0.9817 (1.1059)  Acc@1: 68.7500 (71.5102)  Acc@5: 93.7500 (92.7948)  time: 0.2169  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:50  Loss: 0.8809 (1.1034)  Acc@1: 75.0000 (71.5666)  Acc@5: 93.7500 (92.8582)  time: 0.2170  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 0.9417 (1.1043)  Acc@1: 75.0000 (71.5408)  Acc@5: 100.0000 (92.8393)  time: 0.2166  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 0.9474 (1.1032)  Acc@1: 75.0000 (71.5592)  Acc@5: 93.7500 (92.8354)  time: 0.2169  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 0.9445 (1.1014)  Acc@1: 75.0000 (71.6203)  Acc@5: 93.7500 (92.8602)  time: 0.2181  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 1.0342 (1.1031)  Acc@1: 68.7500 (71.5522)  Acc@5: 93.7500 (92.8845)  time: 0.2172  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 1.1629 (1.1054)  Acc@1: 62.5000 (71.4646)  Acc@5: 93.7500 (92.8662)  time: 0.2162  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:37  Loss: 1.1629 (1.1060)  Acc@1: 62.5000 (71.4276)  Acc@5: 93.7500 (92.8482)  time: 0.2182  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 1.1623 (1.1068)  Acc@1: 68.7500 (71.4394)  Acc@5: 93.7500 (92.8101)  time: 0.2172  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 1.0453 (1.1067)  Acc@1: 68.7500 (71.4237)  Acc@5: 93.7500 (92.8203)  time: 0.2155  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 1.1013 (1.1070)  Acc@1: 62.5000 (71.3749)  Acc@5: 93.7500 (92.8102)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 1.1013 (1.1059)  Acc@1: 68.7500 (71.3868)  Acc@5: 93.7500 (92.8401)  time: 0.2158  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 1.1154 (1.1062)  Acc@1: 62.5000 (71.3328)  Acc@5: 93.7500 (92.8628)  time: 0.2170  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 1.0830 (1.1053)  Acc@1: 68.7500 (71.3580)  Acc@5: 93.7500 (92.8720)  time: 0.2173  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:22  Loss: 0.9162 (1.1039)  Acc@1: 75.0000 (71.4019)  Acc@5: 93.7500 (92.8746)  time: 0.2166  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 1.0152 (1.1040)  Acc@1: 75.0000 (71.4386)  Acc@5: 93.7500 (92.8963)  time: 0.2174  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 1.1504 (1.1069)  Acc@1: 68.7500 (71.4051)  Acc@5: 93.7500 (92.8671)  time: 0.2166  data: 0.0009  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.2340 (1.1076)  Acc@1: 68.7500 (71.4098)  Acc@5: 87.5000 (92.8384)  time: 0.2162  data: 0.0008  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 1.1474 (1.1077)  Acc@1: 75.0000 (71.4330)  Acc@5: 87.5000 (92.8227)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 1.1444 (1.1081)  Acc@1: 75.0000 (71.4251)  Acc@5: 87.5000 (92.8134)  time: 0.2178  data: 0.0008  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.9412 (1.1058)  Acc@1: 75.0000 (71.5022)  Acc@5: 93.7500 (92.8407)  time: 0.2181  data: 0.0008  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.8171 (1.1048)  Acc@1: 75.0000 (71.4938)  Acc@5: 93.7500 (92.8494)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.9228 (1.1034)  Acc@1: 75.0000 (71.5331)  Acc@5: 93.7500 (92.8877)  time: 0.2194  data: 0.0008  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 1.0756 (1.1037)  Acc@1: 68.7500 (71.5186)  Acc@5: 93.7500 (92.8841)  time: 0.2211  data: 0.0011  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.1112 (1.1040)  Acc@1: 68.7500 (71.4811)  Acc@5: 93.7500 (92.8805)  time: 0.2179  data: 0.0012  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 1.1483 (1.1056)  Acc@1: 68.7500 (71.4500)  Acc@5: 93.7500 (92.8596)  time: 0.2156  data: 0.0008  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 1.1244 (1.1051)  Acc@1: 68.7500 (71.4482)  Acc@5: 93.7500 (92.8621)  time: 0.2163  data: 0.0013  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 1.0094 (1.1036)  Acc@1: 68.7500 (71.4861)  Acc@5: 93.7500 (92.8701)  time: 0.2166  data: 0.0015  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 1.0094 (1.1040)  Acc@1: 75.0000 (71.5178)  Acc@5: 93.7500 (92.8780)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 1.0291 (1.1052)  Acc@1: 75.0000 (71.4764)  Acc@5: 93.7500 (92.8747)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 1.0291 (1.1054)  Acc@1: 62.5000 (71.4578)  Acc@5: 93.7500 (92.8824)  time: 0.2155  data: 0.0007  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.2935 (1.1070)  Acc@1: 62.5000 (71.3957)  Acc@5: 93.7500 (92.8407)  time: 0.2167  data: 0.0015  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 1.3784 (1.1085)  Acc@1: 62.5000 (71.3727)  Acc@5: 87.5000 (92.7997)  time: 0.2162  data: 0.0013  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 1.1824 (1.1073)  Acc@1: 68.7500 (71.4093)  Acc@5: 93.7500 (92.8348)  time: 0.2153  data: 0.0006  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 1.0172 (1.1062)  Acc@1: 75.0000 (71.4614)  Acc@5: 100.0000 (92.8373)  time: 0.2163  data: 0.0012  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 1.0993 (1.1067)  Acc@1: 75.0000 (71.4331)  Acc@5: 93.7500 (92.8345)  time: 0.2166  data: 0.0013  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.1938 (1.1071)  Acc@1: 68.7500 (71.4001)  Acc@5: 93.7500 (92.8212)  time: 0.2171  data: 0.0014  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.2077 (1.1079)  Acc@1: 68.7500 (71.3884)  Acc@5: 87.5000 (92.7769)  time: 0.2164  data: 0.0012  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 1.0160 (1.1082)  Acc@1: 75.0000 (71.3666)  Acc@5: 93.7500 (92.7539)  time: 0.2150  data: 0.0004  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 1.0009 (1.1071)  Acc@1: 75.0000 (71.3810)  Acc@5: 93.7500 (92.7826)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 1.0154 (1.1079)  Acc@1: 68.7500 (71.3292)  Acc@5: 93.7500 (92.7701)  time: 0.2158  data: 0.0008  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 1.0492 (1.1076)  Acc@1: 68.7500 (71.3235)  Acc@5: 87.5000 (92.7579)  time: 0.2158  data: 0.0008  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.2194 (1.1081)  Acc@1: 68.7500 (71.3080)  Acc@5: 93.7500 (92.7758)  time: 0.2167  data: 0.0009  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.2194 (1.1078)  Acc@1: 68.7500 (71.3224)  Acc@5: 93.7500 (92.7736)  time: 0.2157  data: 0.0008  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.0875 (1.1081)  Acc@1: 68.7500 (71.3365)  Acc@5: 93.7500 (92.7616)  time: 0.2151  data: 0.0006  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 1.0804 (1.1063)  Acc@1: 75.0000 (71.3944)  Acc@5: 93.7500 (92.7888)  time: 0.2161  data: 0.0006  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 1.0804 (1.1065)  Acc@1: 75.0000 (71.3788)  Acc@5: 93.7500 (92.7721)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.1019 (1.1059)  Acc@1: 68.7500 (71.4162)  Acc@5: 93.7500 (92.7796)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.9105 (1.1043)  Acc@1: 75.0000 (71.4531)  Acc@5: 93.7500 (92.7918)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.7813 (1.1030)  Acc@1: 75.0000 (71.5131)  Acc@5: 93.7500 (92.8085)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.8940 (1.1028)  Acc@1: 75.0000 (71.5158)  Acc@5: 93.7500 (92.8015)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.0370 (1.1035)  Acc@1: 68.7500 (71.4998)  Acc@5: 93.7500 (92.7946)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 1.0296 (1.1028)  Acc@1: 75.0000 (71.5303)  Acc@5: 93.7500 (92.7924)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 1.0296 (1.1026)  Acc@1: 75.0000 (71.5283)  Acc@5: 93.7500 (92.7994)  time: 0.2149  data: 0.0004  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 1.0141 (1.1022)  Acc@1: 68.7500 (71.5126)  Acc@5: 93.7500 (92.8200)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.0437 (1.1026)  Acc@1: 68.7500 (71.4881)  Acc@5: 93.7500 (92.8087)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.2030 (1.1022)  Acc@1: 68.7500 (71.5088)  Acc@5: 93.7500 (92.8064)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.0754 (1.1023)  Acc@1: 75.0000 (71.5159)  Acc@5: 93.7500 (92.7953)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 0.9426 (1.1020)  Acc@1: 75.0000 (71.5273)  Acc@5: 93.7500 (92.7932)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.9999 (1.1011)  Acc@1: 75.0000 (71.5297)  Acc@5: 100.0000 (92.8088)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.1814 (1.1028)  Acc@1: 68.7500 (71.5321)  Acc@5: 93.7500 (92.7717)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.2448 (1.1028)  Acc@1: 68.7500 (71.4998)  Acc@5: 87.5000 (92.7568)  time: 0.2131  data: 0.0002  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.2014 (1.1036)  Acc@1: 68.7500 (71.4809)  Acc@5: 93.7500 (92.7464)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.1432 (1.1039)  Acc@1: 75.0000 (71.5050)  Acc@5: 93.7500 (92.7447)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 1.0312 (1.1036)  Acc@1: 75.0000 (71.5032)  Acc@5: 93.7500 (92.7515)  time: 0.2133  data: 0.0002  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.0264 (1.1038)  Acc@1: 68.7500 (71.4889)  Acc@5: 93.7500 (92.7541)  time: 0.2131  data: 0.0003  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.0371 (1.1043)  Acc@1: 68.7500 (71.4705)  Acc@5: 93.7500 (92.7565)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.0371 (1.1043)  Acc@1: 68.7500 (71.4732)  Acc@5: 93.7500 (92.7548)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.9533 (1.1044)  Acc@1: 68.7500 (71.4883)  Acc@5: 93.7500 (92.7573)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.9798 (1.1033)  Acc@1: 75.0000 (71.5196)  Acc@5: 93.7500 (92.7720)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.9728 (1.1029)  Acc@1: 75.0000 (71.5341)  Acc@5: 93.7500 (92.7825)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.9467 (1.1020)  Acc@1: 75.0000 (71.5485)  Acc@5: 100.0000 (92.8050)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.9487 (1.1019)  Acc@1: 75.0000 (71.5708)  Acc@5: 93.7500 (92.8111)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.9174 (1.1009)  Acc@1: 81.2500 (71.6288)  Acc@5: 93.7500 (92.8171)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.9174 (1.1010)  Acc@1: 75.0000 (71.6423)  Acc@5: 93.7500 (92.7992)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.9493 (1.1010)  Acc@1: 75.0000 (71.6596)  Acc@5: 93.7500 (92.8052)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 1.0601 (1.1011)  Acc@1: 68.7500 (71.6570)  Acc@5: 93.7500 (92.8151)  time: 0.2162  data: 0.0015  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.0864 (1.1024)  Acc@1: 68.7500 (71.6076)  Acc@5: 93.7500 (92.7975)  time: 0.2169  data: 0.0019  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.2088 (1.1021)  Acc@1: 68.7500 (71.6131)  Acc@5: 93.7500 (92.7995)  time: 0.2195  data: 0.0030  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.9250 (1.1009)  Acc@1: 75.0000 (71.6533)  Acc@5: 93.7500 (92.8131)  time: 0.2190  data: 0.0028  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9043 (1.1003)  Acc@1: 75.0000 (71.6695)  Acc@5: 93.7500 (92.8127)  time: 0.2180  data: 0.0026  max mem: 2502
Test: [Task 1] Total time: 0:05:51 (0.2161 s / it)
* Acc@1 71.669 Acc@5 92.813 loss 1.100
Test: [Task 2]  [  0/625]  eta: 0:05:50  Loss: 0.2087 (0.2087)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5608  data: 0.3455  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:32  Loss: 0.2087 (0.2479)  Acc@1: 93.7500 (96.0227)  Acc@5: 100.0000 (99.4318)  time: 0.2475  data: 0.0325  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:21  Loss: 0.1901 (0.2382)  Acc@1: 100.0000 (96.1310)  Acc@5: 100.0000 (99.7024)  time: 0.2170  data: 0.0009  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:15  Loss: 0.2251 (0.2711)  Acc@1: 93.7500 (93.9516)  Acc@5: 100.0000 (99.1935)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:11  Loss: 0.2994 (0.2769)  Acc@1: 93.7500 (93.9024)  Acc@5: 100.0000 (99.0854)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:08  Loss: 0.3046 (0.2919)  Acc@1: 93.7500 (93.5049)  Acc@5: 100.0000 (99.0196)  time: 0.2153  data: 0.0007  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:05  Loss: 0.3091 (0.2902)  Acc@1: 93.7500 (93.3402)  Acc@5: 100.0000 (98.9754)  time: 0.2172  data: 0.0010  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:02  Loss: 0.2976 (0.2868)  Acc@1: 93.7500 (93.5739)  Acc@5: 100.0000 (99.0317)  time: 0.2169  data: 0.0007  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:00  Loss: 0.2915 (0.2916)  Acc@1: 93.7500 (93.4414)  Acc@5: 100.0000 (98.9198)  time: 0.2163  data: 0.0013  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:57  Loss: 0.2408 (0.2844)  Acc@1: 93.7500 (93.6813)  Acc@5: 100.0000 (99.0385)  time: 0.2177  data: 0.0016  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:55  Loss: 0.2368 (0.2826)  Acc@1: 93.7500 (93.6262)  Acc@5: 100.0000 (99.0718)  time: 0.2168  data: 0.0010  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:53  Loss: 0.2153 (0.2826)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.0991)  time: 0.2154  data: 0.0006  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.2227 (0.2831)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.0702)  time: 0.2168  data: 0.0014  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.2492 (0.2839)  Acc@1: 93.7500 (93.7977)  Acc@5: 100.0000 (99.1412)  time: 0.2168  data: 0.0016  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:46  Loss: 0.2313 (0.2856)  Acc@1: 93.7500 (93.9273)  Acc@5: 100.0000 (99.0691)  time: 0.2161  data: 0.0010  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:43  Loss: 0.2234 (0.2907)  Acc@1: 93.7500 (93.8328)  Acc@5: 100.0000 (99.0894)  time: 0.2166  data: 0.0017  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.3523 (0.2952)  Acc@1: 93.7500 (93.7112)  Acc@5: 100.0000 (98.9907)  time: 0.2176  data: 0.0018  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.2853 (0.2971)  Acc@1: 93.7500 (93.5307)  Acc@5: 100.0000 (99.0132)  time: 0.2170  data: 0.0011  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.2875 (0.2977)  Acc@1: 93.7500 (93.5083)  Acc@5: 100.0000 (99.0331)  time: 0.2153  data: 0.0007  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.2875 (0.2995)  Acc@1: 93.7500 (93.4882)  Acc@5: 100.0000 (99.0183)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.2305 (0.2967)  Acc@1: 93.7500 (93.4391)  Acc@5: 100.0000 (99.0361)  time: 0.2158  data: 0.0010  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.2459 (0.2990)  Acc@1: 93.7500 (93.3057)  Acc@5: 100.0000 (99.0521)  time: 0.2160  data: 0.0012  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.2459 (0.2961)  Acc@1: 93.7500 (93.4672)  Acc@5: 100.0000 (99.0385)  time: 0.2167  data: 0.0010  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 0.1743 (0.2941)  Acc@1: 100.0000 (93.5335)  Acc@5: 100.0000 (99.0801)  time: 0.2162  data: 0.0009  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.2711 (0.2940)  Acc@1: 93.7500 (93.5944)  Acc@5: 100.0000 (99.1183)  time: 0.2154  data: 0.0006  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.2869 (0.2962)  Acc@1: 93.7500 (93.5508)  Acc@5: 100.0000 (99.0787)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.3061 (0.2979)  Acc@1: 93.7500 (93.4626)  Acc@5: 100.0000 (99.0661)  time: 0.2150  data: 0.0005  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.3283 (0.2997)  Acc@1: 87.5000 (93.4041)  Acc@5: 100.0000 (99.0544)  time: 0.2155  data: 0.0006  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.3352 (0.3018)  Acc@1: 93.7500 (93.2829)  Acc@5: 100.0000 (99.0214)  time: 0.2181  data: 0.0012  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.2879 (0.3033)  Acc@1: 93.7500 (93.2990)  Acc@5: 100.0000 (99.0335)  time: 0.2196  data: 0.0016  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.2778 (0.3028)  Acc@1: 93.7500 (93.2724)  Acc@5: 100.0000 (99.0656)  time: 0.2182  data: 0.0019  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.2778 (0.3037)  Acc@1: 93.7500 (93.2677)  Acc@5: 100.0000 (99.0354)  time: 0.2169  data: 0.0015  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.1447 (0.2971)  Acc@1: 100.0000 (93.4579)  Acc@5: 100.0000 (99.0654)  time: 0.2177  data: 0.0010  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.1099 (0.2925)  Acc@1: 100.0000 (93.6178)  Acc@5: 100.0000 (99.0937)  time: 0.2199  data: 0.0011  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.1062 (0.2863)  Acc@1: 100.0000 (93.7867)  Acc@5: 100.0000 (99.1202)  time: 0.2184  data: 0.0010  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.0853 (0.2822)  Acc@1: 100.0000 (93.8746)  Acc@5: 100.0000 (99.1453)  time: 0.2154  data: 0.0008  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.1746 (0.2828)  Acc@1: 93.7500 (93.8366)  Acc@5: 100.0000 (99.1517)  time: 0.2153  data: 0.0007  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.2068 (0.2801)  Acc@1: 93.7500 (93.9016)  Acc@5: 100.0000 (99.1745)  time: 0.2159  data: 0.0013  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2716 (0.2847)  Acc@1: 93.7500 (93.7336)  Acc@5: 100.0000 (99.1142)  time: 0.2164  data: 0.0014  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.3195 (0.2847)  Acc@1: 93.7500 (93.7020)  Acc@5: 100.0000 (99.0729)  time: 0.2164  data: 0.0012  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.0976 (0.2808)  Acc@1: 93.7500 (93.7812)  Acc@5: 100.0000 (99.0960)  time: 0.2152  data: 0.0009  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0802 (0.2786)  Acc@1: 100.0000 (93.8564)  Acc@5: 100.0000 (99.0876)  time: 0.2154  data: 0.0007  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.0865 (0.2776)  Acc@1: 100.0000 (93.8688)  Acc@5: 100.0000 (99.1093)  time: 0.2166  data: 0.0015  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.1310 (0.2746)  Acc@1: 100.0000 (93.9675)  Acc@5: 100.0000 (99.1299)  time: 0.2171  data: 0.0022  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.0815 (0.2702)  Acc@1: 100.0000 (94.1043)  Acc@5: 100.0000 (99.1497)  time: 0.2180  data: 0.0016  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.0815 (0.2667)  Acc@1: 100.0000 (94.1380)  Acc@5: 100.0000 (99.1685)  time: 0.2177  data: 0.0009  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.0950 (0.2634)  Acc@1: 100.0000 (94.2245)  Acc@5: 100.0000 (99.1866)  time: 0.2164  data: 0.0007  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1465 (0.2612)  Acc@1: 100.0000 (94.3339)  Acc@5: 100.0000 (99.2038)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1559 (0.2598)  Acc@1: 100.0000 (94.3997)  Acc@5: 100.0000 (99.2204)  time: 0.2159  data: 0.0008  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1520 (0.2576)  Acc@1: 100.0000 (94.4756)  Acc@5: 100.0000 (99.2363)  time: 0.2156  data: 0.0011  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1402 (0.2552)  Acc@1: 100.0000 (94.5359)  Acc@5: 100.0000 (99.2515)  time: 0.2164  data: 0.0010  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.1493 (0.2562)  Acc@1: 93.7500 (94.4472)  Acc@5: 100.0000 (99.2661)  time: 0.2167  data: 0.0010  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.2191 (0.2564)  Acc@1: 93.7500 (94.4578)  Acc@5: 100.0000 (99.2682)  time: 0.2160  data: 0.0009  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1235 (0.2542)  Acc@1: 100.0000 (94.5386)  Acc@5: 100.0000 (99.2820)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1166 (0.2523)  Acc@1: 100.0000 (94.5818)  Acc@5: 100.0000 (99.2953)  time: 0.2157  data: 0.0006  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0889 (0.2490)  Acc@1: 100.0000 (94.6574)  Acc@5: 100.0000 (99.3081)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0542 (0.2456)  Acc@1: 100.0000 (94.7527)  Acc@5: 100.0000 (99.3204)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0542 (0.2448)  Acc@1: 100.0000 (94.7680)  Acc@5: 100.0000 (99.3323)  time: 0.2161  data: 0.0011  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.0764 (0.2418)  Acc@1: 100.0000 (94.8365)  Acc@5: 100.0000 (99.3438)  time: 0.2165  data: 0.0019  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.0876 (0.2404)  Acc@1: 100.0000 (94.8393)  Acc@5: 100.0000 (99.3549)  time: 0.2175  data: 0.0013  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1825 (0.2401)  Acc@1: 93.7500 (94.8419)  Acc@5: 100.0000 (99.3656)  time: 0.2170  data: 0.0009  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2953 (0.2426)  Acc@1: 93.7500 (94.7627)  Acc@5: 100.0000 (99.3556)  time: 0.2158  data: 0.0011  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.2953 (0.2424)  Acc@1: 93.7500 (94.7866)  Acc@5: 100.0000 (99.3659)  time: 0.2163  data: 0.0008  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2340 (0.2419)  Acc@1: 93.7500 (94.8000)  Acc@5: 100.0000 (99.3700)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 2] Total time: 0:02:15 (0.2174 s / it)
* Acc@1 94.800 Acc@5 99.370 loss 0.242
Test: [Task 3]  [  0/625]  eta: 0:06:54  Loss: 0.2725 (0.2725)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6630  data: 0.4451  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:39  Loss: 0.2269 (0.2443)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (98.2955)  time: 0.2588  data: 0.0413  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:26  Loss: 0.2204 (0.2619)  Acc@1: 100.0000 (95.5357)  Acc@5: 100.0000 (98.5119)  time: 0.2212  data: 0.0009  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:19  Loss: 0.2193 (0.2533)  Acc@1: 100.0000 (95.7661)  Acc@5: 100.0000 (98.9919)  time: 0.2198  data: 0.0007  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:14  Loss: 0.1490 (0.2236)  Acc@1: 100.0000 (96.7988)  Acc@5: 100.0000 (99.2378)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:10  Loss: 0.1505 (0.2187)  Acc@1: 100.0000 (96.8137)  Acc@5: 100.0000 (99.3873)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:06  Loss: 0.2109 (0.2155)  Acc@1: 100.0000 (96.9262)  Acc@5: 100.0000 (99.4877)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:03  Loss: 0.1389 (0.2033)  Acc@1: 100.0000 (97.1831)  Acc@5: 100.0000 (99.5599)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:00  Loss: 0.1389 (0.2082)  Acc@1: 100.0000 (96.9907)  Acc@5: 100.0000 (99.6142)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:58  Loss: 0.1606 (0.2076)  Acc@1: 93.7500 (96.9780)  Acc@5: 100.0000 (99.5879)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:55  Loss: 0.1711 (0.2066)  Acc@1: 100.0000 (97.0916)  Acc@5: 100.0000 (99.5668)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:53  Loss: 0.1711 (0.2011)  Acc@1: 100.0000 (97.2973)  Acc@5: 100.0000 (99.6059)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:50  Loss: 0.1621 (0.2016)  Acc@1: 100.0000 (97.3657)  Acc@5: 100.0000 (99.6384)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:48  Loss: 0.1908 (0.2015)  Acc@1: 100.0000 (97.4237)  Acc@5: 100.0000 (99.6183)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:46  Loss: 0.1989 (0.2082)  Acc@1: 100.0000 (97.2518)  Acc@5: 100.0000 (99.4681)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 0.2335 (0.2138)  Acc@1: 93.7500 (97.1440)  Acc@5: 100.0000 (99.4205)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:41  Loss: 0.1755 (0.2147)  Acc@1: 100.0000 (97.1661)  Acc@5: 100.0000 (99.3789)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:39  Loss: 0.1643 (0.2137)  Acc@1: 100.0000 (97.2222)  Acc@5: 100.0000 (99.4152)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.2124 (0.2170)  Acc@1: 100.0000 (97.1340)  Acc@5: 100.0000 (99.3785)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.2330 (0.2160)  Acc@1: 93.7500 (97.1204)  Acc@5: 100.0000 (99.4110)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 0.2330 (0.2188)  Acc@1: 93.7500 (97.0460)  Acc@5: 100.0000 (99.4092)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:30  Loss: 0.1930 (0.2206)  Acc@1: 93.7500 (97.0379)  Acc@5: 100.0000 (99.3780)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:27  Loss: 0.1930 (0.2233)  Acc@1: 93.7500 (96.8891)  Acc@5: 100.0000 (99.3495)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.2201 (0.2237)  Acc@1: 93.7500 (96.9156)  Acc@5: 100.0000 (99.3506)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.1802 (0.2257)  Acc@1: 100.0000 (96.8620)  Acc@5: 100.0000 (99.3257)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1802 (0.2243)  Acc@1: 100.0000 (96.9124)  Acc@5: 100.0000 (99.3277)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:18  Loss: 0.1457 (0.2227)  Acc@1: 100.0000 (96.9349)  Acc@5: 100.0000 (99.3056)  time: 0.2143  data: 0.0004  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:16  Loss: 0.1457 (0.2216)  Acc@1: 100.0000 (96.9096)  Acc@5: 100.0000 (99.3081)  time: 0.2146  data: 0.0005  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 0.1544 (0.2207)  Acc@1: 93.7500 (96.9084)  Acc@5: 100.0000 (99.3327)  time: 0.2161  data: 0.0009  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.1889 (0.2212)  Acc@1: 93.7500 (96.8428)  Acc@5: 100.0000 (99.3557)  time: 0.2162  data: 0.0013  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.1889 (0.2253)  Acc@1: 93.7500 (96.6985)  Acc@5: 100.0000 (99.2940)  time: 0.2158  data: 0.0014  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1673 (0.2271)  Acc@1: 100.0000 (96.6841)  Acc@5: 100.0000 (99.2564)  time: 0.2168  data: 0.0016  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:05  Loss: 0.1699 (0.2264)  Acc@1: 100.0000 (96.6706)  Acc@5: 100.0000 (99.2407)  time: 0.2166  data: 0.0011  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 0.2099 (0.2272)  Acc@1: 93.7500 (96.6201)  Acc@5: 100.0000 (99.2447)  time: 0.2173  data: 0.0017  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.1732 (0.2255)  Acc@1: 100.0000 (96.6826)  Acc@5: 100.0000 (99.2485)  time: 0.2171  data: 0.0018  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1742 (0.2255)  Acc@1: 100.0000 (96.6524)  Acc@5: 100.0000 (99.2521)  time: 0.2159  data: 0.0012  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.1892 (0.2261)  Acc@1: 93.7500 (96.5893)  Acc@5: 100.0000 (99.2555)  time: 0.2161  data: 0.0013  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.2084 (0.2266)  Acc@1: 93.7500 (96.5633)  Acc@5: 100.0000 (99.2588)  time: 0.2160  data: 0.0008  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.1853 (0.2249)  Acc@1: 93.7500 (96.6043)  Acc@5: 100.0000 (99.2782)  time: 0.2180  data: 0.0010  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.1665 (0.2261)  Acc@1: 100.0000 (96.5473)  Acc@5: 100.0000 (99.2807)  time: 0.2191  data: 0.0008  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1665 (0.2250)  Acc@1: 93.7500 (96.5243)  Acc@5: 100.0000 (99.2830)  time: 0.2175  data: 0.0007  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.2056 (0.2260)  Acc@1: 93.7500 (96.5176)  Acc@5: 100.0000 (99.2701)  time: 0.2163  data: 0.0010  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.2345 (0.2254)  Acc@1: 93.7500 (96.4964)  Acc@5: 100.0000 (99.2874)  time: 0.2169  data: 0.0011  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1834 (0.2251)  Acc@1: 93.7500 (96.4762)  Acc@5: 100.0000 (99.2894)  time: 0.2175  data: 0.0008  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.1872 (0.2264)  Acc@1: 93.7500 (96.4286)  Acc@5: 100.0000 (99.2772)  time: 0.2167  data: 0.0007  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.1944 (0.2263)  Acc@1: 100.0000 (96.4523)  Acc@5: 100.0000 (99.2794)  time: 0.2154  data: 0.0006  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.1872 (0.2258)  Acc@1: 100.0000 (96.4615)  Acc@5: 100.0000 (99.2815)  time: 0.2167  data: 0.0016  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1872 (0.2253)  Acc@1: 93.7500 (96.4703)  Acc@5: 100.0000 (99.2834)  time: 0.2175  data: 0.0019  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1830 (0.2261)  Acc@1: 93.7500 (96.4657)  Acc@5: 100.0000 (99.2594)  time: 0.2170  data: 0.0018  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2178 (0.2265)  Acc@1: 93.7500 (96.4613)  Acc@5: 100.0000 (99.2490)  time: 0.2171  data: 0.0018  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2041 (0.2256)  Acc@1: 100.0000 (96.4696)  Acc@5: 100.0000 (99.2640)  time: 0.2165  data: 0.0011  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.1440 (0.2254)  Acc@1: 100.0000 (96.4530)  Acc@5: 100.0000 (99.2661)  time: 0.2160  data: 0.0008  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.1863 (0.2255)  Acc@1: 93.7500 (96.4371)  Acc@5: 100.0000 (99.2802)  time: 0.2163  data: 0.0013  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.1925 (0.2265)  Acc@1: 93.7500 (96.4101)  Acc@5: 100.0000 (99.2938)  time: 0.2171  data: 0.0013  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2111 (0.2275)  Acc@1: 93.7500 (96.3956)  Acc@5: 100.0000 (99.2722)  time: 0.2163  data: 0.0007  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2111 (0.2278)  Acc@1: 100.0000 (96.4043)  Acc@5: 100.0000 (99.2627)  time: 0.2158  data: 0.0007  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2059 (0.2277)  Acc@1: 93.7500 (96.3904)  Acc@5: 100.0000 (99.2758)  time: 0.2208  data: 0.0008  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.1794 (0.2272)  Acc@1: 100.0000 (96.4208)  Acc@5: 100.0000 (99.2776)  time: 0.2207  data: 0.0011  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.1543 (0.2284)  Acc@1: 100.0000 (96.3855)  Acc@5: 100.0000 (99.2793)  time: 0.2152  data: 0.0006  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1891 (0.2278)  Acc@1: 100.0000 (96.4255)  Acc@5: 100.0000 (99.2915)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1816 (0.2277)  Acc@1: 100.0000 (96.4018)  Acc@5: 100.0000 (99.2928)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1678 (0.2269)  Acc@1: 93.7500 (96.3993)  Acc@5: 100.0000 (99.3044)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2083 (0.2277)  Acc@1: 93.7500 (96.3768)  Acc@5: 100.0000 (99.3056)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1673 (0.2270)  Acc@1: 100.0000 (96.4000)  Acc@5: 100.0000 (99.3100)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 3] Total time: 0:02:15 (0.2167 s / it)
* Acc@1 96.400 Acc@5 99.310 loss 0.227
Test: [Task 4]  [ 0/29]  eta: 0:00:13  Loss: 1.9888 (1.9888)  Acc@1: 18.7500 (18.7500)  Acc@5: 87.5000 (87.5000)  time: 0.4736  data: 0.2606  max mem: 2502
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 1.9888 (2.0183)  Acc@1: 50.0000 (42.6136)  Acc@5: 87.5000 (82.3864)  time: 0.2379  data: 0.0239  max mem: 2502
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.7641 (1.8079)  Acc@1: 56.2500 (53.8690)  Acc@5: 81.2500 (81.8452)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.5479 (1.6751)  Acc@1: 68.7500 (58.1699)  Acc@5: 87.5000 (83.2244)  time: 0.2200  data: 0.0003  max mem: 2502
Test: [Task 4] Total time: 0:00:06 (0.2304 s / it)
* Acc@1 58.170 Acc@5 83.224 loss 1.675
{0: {0: 0, 1: 26032, 2: 0, 3: 0, 4: 0, 5: 0, 6: 26032, 7: 0, 8: 26032, 9: 0, 10: 0, 11: 0, 12: 26032, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 10000, 3: 10000, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 10000, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 10000, 1: 16, 2: 0, 3: 0, 4: 0, 5: 0, 6: 16, 7: 0, 8: 16, 9: 9984, 10: 0, 11: 0, 12: 0, 13: 9984, 14: 0, 15: 0, 16: 9984, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 176, 3: 176, 4: 0, 5: 299, 6: 0, 7: 299, 8: 0, 9: 0, 10: 0, 11: 160, 12: 0, 13: 0, 14: 283, 15: 160, 16: 0, 17: 0, 18: 283, 19: 0}}
[Average accuracy till task4]	Acc@1: 80.2599	Acc@5: 93.6793	Loss: 0.8111	Forgetting: 5.2396	Backward: -5.2396
Train: Epoch[1/5]  [   0/3750]  eta: 0:41:06  Lr: 0.001875  Loss: 1.7990  Acc@1: 12.5000 (12.5000)  Acc@5: 43.7500 (43.7500)  time: 0.6577  data: 0.2936  max mem: 2502
Train: Epoch[1/5]  [  10/3750]  eta: 0:23:51  Lr: 0.001875  Loss: 1.7808  Acc@1: 25.0000 (23.8636)  Acc@5: 62.5000 (64.2045)  time: 0.3827  data: 0.0282  max mem: 2503
Train: Epoch[1/5]  [  20/3750]  eta: 0:22:47  Lr: 0.001875  Loss: 1.6701  Acc@1: 31.2500 (28.5714)  Acc@5: 81.2500 (75.2976)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:31  Lr: 0.001875  Loss: 1.5308  Acc@1: 31.2500 (33.2661)  Acc@5: 87.5000 (81.0484)  time: 0.3526  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:12  Lr: 0.001875  Loss: 1.2464  Acc@1: 50.0000 (38.7195)  Acc@5: 93.7500 (84.1463)  time: 0.3511  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [  50/3750]  eta: 0:21:59  Lr: 0.001875  Loss: 0.8501  Acc@1: 56.2500 (43.8725)  Acc@5: 93.7500 (86.0294)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:50  Lr: 0.001875  Loss: 0.7530  Acc@1: 68.7500 (48.3607)  Acc@5: 93.7500 (87.6025)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:42  Lr: 0.001875  Loss: 0.9871  Acc@1: 68.7500 (50.4401)  Acc@5: 93.7500 (88.8204)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:35  Lr: 0.001875  Loss: 0.5636  Acc@1: 62.5000 (52.2377)  Acc@5: 93.7500 (89.1975)  time: 0.3468  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:29  Lr: 0.001875  Loss: 0.6493  Acc@1: 62.5000 (53.5027)  Acc@5: 93.7500 (89.9725)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:23  Lr: 0.001875  Loss: 0.7511  Acc@1: 68.7500 (54.6411)  Acc@5: 93.7500 (90.5322)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:17  Lr: 0.001875  Loss: 0.2880  Acc@1: 62.5000 (55.7432)  Acc@5: 100.0000 (91.1599)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:12  Lr: 0.001875  Loss: 0.3790  Acc@1: 62.5000 (56.5083)  Acc@5: 100.0000 (91.6322)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:07  Lr: 0.001875  Loss: 0.5059  Acc@1: 62.5000 (57.4905)  Acc@5: 100.0000 (92.0324)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:02  Lr: 0.001875  Loss: 0.3065  Acc@1: 68.7500 (58.3777)  Acc@5: 93.7500 (92.2872)  time: 0.3447  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 150/3750]  eta: 0:20:57  Lr: 0.001875  Loss: 0.0138  Acc@1: 68.7500 (58.9404)  Acc@5: 93.7500 (92.5083)  time: 0.3450  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 160/3750]  eta: 0:20:53  Lr: 0.001875  Loss: 0.2815  Acc@1: 62.5000 (59.2003)  Acc@5: 93.7500 (92.7795)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 170/3750]  eta: 0:20:49  Lr: 0.001875  Loss: 0.4135  Acc@1: 68.7500 (59.9050)  Acc@5: 100.0000 (93.0190)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:45  Lr: 0.001875  Loss: 0.2279  Acc@1: 68.7500 (60.6354)  Acc@5: 100.0000 (93.1630)  time: 0.3478  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:42  Lr: 0.001875  Loss: 0.1891  Acc@1: 75.0000 (61.2565)  Acc@5: 100.0000 (93.2592)  time: 0.3491  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:38  Lr: 0.001875  Loss: 0.2138  Acc@1: 68.7500 (61.6915)  Acc@5: 100.0000 (93.5634)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:34  Lr: 0.001875  Loss: 0.0899  Acc@1: 68.7500 (61.7595)  Acc@5: 100.0000 (93.6315)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:31  Lr: 0.001875  Loss: 0.2893  Acc@1: 62.5000 (61.8778)  Acc@5: 100.0000 (93.8914)  time: 0.3480  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:27  Lr: 0.001875  Loss: 0.3517  Acc@1: 62.5000 (62.0942)  Acc@5: 100.0000 (93.9665)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:24  Lr: 0.001875  Loss: 0.0715  Acc@1: 68.7500 (62.5000)  Acc@5: 100.0000 (94.1131)  time: 0.3487  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.1533  Acc@1: 75.0000 (63.0229)  Acc@5: 93.7500 (94.1733)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.0468  Acc@1: 75.0000 (63.5057)  Acc@5: 93.7500 (94.2050)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:13  Lr: 0.001875  Loss: 0.1165  Acc@1: 75.0000 (63.7223)  Acc@5: 93.7500 (94.2343)  time: 0.3480  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:10  Lr: 0.001875  Loss: 0.3691  Acc@1: 68.7500 (63.9457)  Acc@5: 93.7500 (94.3283)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.1653  Acc@1: 68.7500 (64.2612)  Acc@5: 100.0000 (94.4373)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:03  Lr: 0.001875  Loss: 0.1978  Acc@1: 75.0000 (64.7010)  Acc@5: 100.0000 (94.5598)  time: 0.3484  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:00  Lr: 0.001875  Loss: 0.6601  Acc@1: 75.0000 (64.8714)  Acc@5: 100.0000 (94.6543)  time: 0.3507  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 320/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -0.1329  Acc@1: 75.0000 (65.2259)  Acc@5: 100.0000 (94.7235)  time: 0.3511  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 330/3750]  eta: 0:19:53  Lr: 0.001875  Loss: 0.2956  Acc@1: 75.0000 (65.2946)  Acc@5: 100.0000 (94.7696)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.1298  Acc@1: 62.5000 (65.2493)  Acc@5: 100.0000 (94.8864)  time: 0.3510  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.2236  Acc@1: 68.7500 (65.3134)  Acc@5: 100.0000 (95.0142)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:42  Lr: 0.001875  Loss: 0.0480  Acc@1: 68.7500 (65.4086)  Acc@5: 100.0000 (95.0312)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.3997  Acc@1: 68.7500 (65.5323)  Acc@5: 93.7500 (95.0303)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.1689  Acc@1: 68.7500 (65.5676)  Acc@5: 100.0000 (95.1280)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:32  Lr: 0.001875  Loss: 0.0152  Acc@1: 68.7500 (65.8088)  Acc@5: 100.0000 (95.2206)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:28  Lr: 0.001875  Loss: 0.2702  Acc@1: 75.0000 (65.8510)  Acc@5: 100.0000 (95.3086)  time: 0.3496  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.2661  Acc@1: 68.7500 (66.0584)  Acc@5: 100.0000 (95.4075)  time: 0.3485  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.1696  Acc@1: 75.0000 (66.1075)  Acc@5: 100.0000 (95.4276)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.0872  Acc@1: 62.5000 (66.0963)  Acc@5: 100.0000 (95.4901)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -0.0879  Acc@1: 68.7500 (66.3265)  Acc@5: 100.0000 (95.5357)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.5125  Acc@1: 75.0000 (66.5188)  Acc@5: 100.0000 (95.5793)  time: 0.3496  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.3615  Acc@1: 68.7500 (66.5401)  Acc@5: 100.0000 (95.6074)  time: 0.3500  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.0705  Acc@1: 75.0000 (66.6667)  Acc@5: 100.0000 (95.6741)  time: 0.3547  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.2040  Acc@1: 75.0000 (66.6970)  Acc@5: 100.0000 (95.6861)  time: 0.3537  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 490/3750]  eta: 0:18:57  Lr: 0.001875  Loss: 0.0264  Acc@1: 68.7500 (66.7770)  Acc@5: 100.0000 (95.7485)  time: 0.3470  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.4621  Acc@1: 68.7500 (66.9536)  Acc@5: 100.0000 (95.7834)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.7916  Acc@1: 75.0000 (67.0621)  Acc@5: 100.0000 (95.8293)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.5358  Acc@1: 75.0000 (67.1425)  Acc@5: 100.0000 (95.8493)  time: 0.3469  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.3835  Acc@1: 75.0000 (67.2316)  Acc@5: 100.0000 (95.8922)  time: 0.3456  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.1450  Acc@1: 68.7500 (67.2828)  Acc@5: 100.0000 (95.9450)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.4342  Acc@1: 68.7500 (67.3435)  Acc@5: 100.0000 (95.9732)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.1142  Acc@1: 68.7500 (67.3128)  Acc@5: 100.0000 (96.0116)  time: 0.3503  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.3986  Acc@1: 68.7500 (67.4256)  Acc@5: 100.0000 (96.0377)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.1764  Acc@1: 75.0000 (67.5882)  Acc@5: 100.0000 (96.0628)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.4870  Acc@1: 75.0000 (67.7136)  Acc@5: 100.0000 (96.1083)  time: 0.3463  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.1153  Acc@1: 75.0000 (67.8661)  Acc@5: 100.0000 (96.1314)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.0504  Acc@1: 75.0000 (67.9317)  Acc@5: 100.0000 (96.1538)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.3620  Acc@1: 68.7500 (67.9247)  Acc@5: 100.0000 (96.1655)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.4117  Acc@1: 68.7500 (67.9972)  Acc@5: 100.0000 (96.1965)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.3776  Acc@1: 68.7500 (68.0285)  Acc@5: 100.0000 (96.1973)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:01  Lr: 0.001875  Loss: 0.0732  Acc@1: 68.7500 (68.0012)  Acc@5: 100.0000 (96.1790)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 660/3750]  eta: 0:17:57  Lr: 0.001875  Loss: 0.0578  Acc@1: 62.5000 (67.9936)  Acc@5: 100.0000 (96.1989)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.1628  Acc@1: 68.7500 (68.0048)  Acc@5: 100.0000 (96.2183)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.5713  Acc@1: 68.7500 (68.1076)  Acc@5: 100.0000 (96.2463)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.3205  Acc@1: 75.0000 (68.1802)  Acc@5: 100.0000 (96.2735)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.2535  Acc@1: 75.0000 (68.2596)  Acc@5: 100.0000 (96.2553)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.1228  Acc@1: 75.0000 (68.3984)  Acc@5: 100.0000 (96.2904)  time: 0.3482  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.4422  Acc@1: 75.0000 (68.4553)  Acc@5: 100.0000 (96.3419)  time: 0.3500  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.2340  Acc@1: 68.7500 (68.4593)  Acc@5: 100.0000 (96.3834)  time: 0.3492  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.5638  Acc@1: 75.0000 (68.5138)  Acc@5: 100.0000 (96.4153)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:25  Lr: 0.001875  Loss: 0.0376  Acc@1: 75.0000 (68.5336)  Acc@5: 100.0000 (96.3965)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.3695  Acc@1: 75.0000 (68.7007)  Acc@5: 93.7500 (96.4028)  time: 0.3500  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.7799  Acc@1: 75.0000 (68.7662)  Acc@5: 100.0000 (96.4332)  time: 0.3495  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.5371  Acc@1: 68.7500 (68.8060)  Acc@5: 100.0000 (96.4149)  time: 0.3498  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:12  Lr: 0.001875  Loss: 0.0693  Acc@1: 68.7500 (68.8053)  Acc@5: 100.0000 (96.4286)  time: 0.3510  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.4852  Acc@1: 75.0000 (68.8983)  Acc@5: 100.0000 (96.4341)  time: 0.3498  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.2284  Acc@1: 68.7500 (68.8810)  Acc@5: 100.0000 (96.4473)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.7149  Acc@1: 68.7500 (68.9555)  Acc@5: 100.0000 (96.4753)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 830/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.3115  Acc@1: 75.0000 (68.9531)  Acc@5: 100.0000 (96.4726)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.4662  Acc@1: 68.7500 (68.9804)  Acc@5: 100.0000 (96.4774)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.6763  Acc@1: 68.7500 (69.0071)  Acc@5: 100.0000 (96.4821)  time: 0.3495  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.3580  Acc@1: 68.7500 (69.0476)  Acc@5: 100.0000 (96.4866)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.4915  Acc@1: 75.0000 (69.0801)  Acc@5: 100.0000 (96.5055)  time: 0.3534  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.3308  Acc@1: 75.0000 (69.0409)  Acc@5: 100.0000 (96.5238)  time: 0.3540  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.2865  Acc@1: 75.0000 (69.1007)  Acc@5: 100.0000 (96.5418)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.5871  Acc@1: 75.0000 (69.1315)  Acc@5: 93.7500 (96.5178)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.7150  Acc@1: 68.7500 (69.1616)  Acc@5: 93.7500 (96.5011)  time: 0.3471  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.3054  Acc@1: 75.0000 (69.2182)  Acc@5: 93.7500 (96.5119)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.2865  Acc@1: 75.0000 (69.2871)  Acc@5: 100.0000 (96.5360)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.8620  Acc@1: 75.0000 (69.3677)  Acc@5: 100.0000 (96.5662)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.0531  Acc@1: 75.0000 (69.3809)  Acc@5: 100.0000 (96.5694)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.0083  Acc@1: 75.0000 (69.4654)  Acc@5: 100.0000 (96.6051)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.7546  Acc@1: 75.0000 (69.5481)  Acc@5: 100.0000 (96.6208)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.4912  Acc@1: 75.0000 (69.6228)  Acc@5: 100.0000 (96.6361)  time: 0.3451  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.5861  Acc@1: 81.2500 (69.7086)  Acc@5: 100.0000 (96.6574)  time: 0.3457  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1000/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.6712  Acc@1: 81.2500 (69.7927)  Acc@5: 100.0000 (96.6783)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.5243  Acc@1: 75.0000 (69.8009)  Acc@5: 100.0000 (96.7050)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -0.8604  Acc@1: 68.7500 (69.8457)  Acc@5: 100.0000 (96.7189)  time: 0.3476  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.6961  Acc@1: 68.7500 (69.8654)  Acc@5: 100.0000 (96.7386)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.3321  Acc@1: 68.7500 (69.8607)  Acc@5: 100.0000 (96.7459)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.3356  Acc@1: 75.0000 (69.9334)  Acc@5: 100.0000 (96.7531)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.7597  Acc@1: 75.0000 (69.9517)  Acc@5: 100.0000 (96.7719)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.5664  Acc@1: 75.0000 (70.0222)  Acc@5: 100.0000 (96.7904)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -0.5133  Acc@1: 75.0000 (70.0451)  Acc@5: 100.0000 (96.8085)  time: 0.3511  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.1327  Acc@1: 75.0000 (70.1077)  Acc@5: 100.0000 (96.8378)  time: 0.3510  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.5903  Acc@1: 75.0000 (70.1294)  Acc@5: 100.0000 (96.8381)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.8267  Acc@1: 75.0000 (70.1901)  Acc@5: 100.0000 (96.8497)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.4908  Acc@1: 81.2500 (70.2777)  Acc@5: 100.0000 (96.8499)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -0.2913  Acc@1: 75.0000 (70.2641)  Acc@5: 100.0000 (96.8501)  time: 0.3488  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.7326  Acc@1: 68.7500 (70.2783)  Acc@5: 100.0000 (96.8723)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.8162  Acc@1: 75.0000 (70.3573)  Acc@5: 100.0000 (96.8831)  time: 0.3473  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.8018  Acc@1: 81.2500 (70.4188)  Acc@5: 100.0000 (96.9046)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1170/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.4587  Acc@1: 81.2500 (70.4953)  Acc@5: 100.0000 (96.9310)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.8420  Acc@1: 75.0000 (70.5070)  Acc@5: 100.0000 (96.9359)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.8144  Acc@1: 75.0000 (70.5867)  Acc@5: 100.0000 (96.9458)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.7547  Acc@1: 75.0000 (70.6182)  Acc@5: 100.0000 (96.9661)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.4313  Acc@1: 75.0000 (70.6338)  Acc@5: 100.0000 (96.9447)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.5446  Acc@1: 68.7500 (70.6286)  Acc@5: 93.7500 (96.9492)  time: 0.3463  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.1125  Acc@1: 68.7500 (70.6286)  Acc@5: 100.0000 (96.9435)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.8566  Acc@1: 75.0000 (70.6789)  Acc@5: 100.0000 (96.9631)  time: 0.3484  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.1931  Acc@1: 75.0000 (70.7084)  Acc@5: 100.0000 (96.9724)  time: 0.3474  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.3722  Acc@1: 75.0000 (70.7573)  Acc@5: 100.0000 (96.9766)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -0.3800  Acc@1: 81.2500 (70.8153)  Acc@5: 100.0000 (96.9906)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.6019  Acc@1: 75.0000 (70.8724)  Acc@5: 100.0000 (97.0092)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.7965  Acc@1: 81.2500 (70.9285)  Acc@5: 100.0000 (97.0178)  time: 0.3458  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.8834  Acc@1: 75.0000 (70.9646)  Acc@5: 100.0000 (97.0359)  time: 0.3454  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.7429  Acc@1: 75.0000 (71.0002)  Acc@5: 100.0000 (97.0442)  time: 0.3465  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.3243  Acc@1: 75.0000 (71.0115)  Acc@5: 100.0000 (97.0572)  time: 0.3492  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.4475  Acc@1: 75.0000 (71.0086)  Acc@5: 100.0000 (97.0464)  time: 0.3490  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1340/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.5488  Acc@1: 68.7500 (71.0337)  Acc@5: 100.0000 (97.0498)  time: 0.3480  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.4319  Acc@1: 68.7500 (71.0446)  Acc@5: 100.0000 (97.0485)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.6184  Acc@1: 68.7500 (71.0691)  Acc@5: 100.0000 (97.0656)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -0.0744  Acc@1: 75.0000 (71.0749)  Acc@5: 100.0000 (97.0687)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.1689  Acc@1: 75.0000 (71.1350)  Acc@5: 100.0000 (97.0854)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.1808  Acc@1: 75.0000 (71.1314)  Acc@5: 100.0000 (97.0974)  time: 0.3494  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.2568  Acc@1: 75.0000 (71.1144)  Acc@5: 100.0000 (97.1092)  time: 0.3514  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:35  Lr: 0.001875  Loss: 0.0366  Acc@1: 75.0000 (71.1685)  Acc@5: 100.0000 (97.1208)  time: 0.3517  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.8551  Acc@1: 75.0000 (71.1823)  Acc@5: 100.0000 (97.1323)  time: 0.3532  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.6236  Acc@1: 68.7500 (71.1871)  Acc@5: 100.0000 (97.1392)  time: 0.3516  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:24  Lr: 0.001875  Loss: 0.5299  Acc@1: 62.5000 (71.1659)  Acc@5: 100.0000 (97.1417)  time: 0.3490  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.4297  Acc@1: 75.0000 (71.2224)  Acc@5: 100.0000 (97.1485)  time: 0.3488  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.4632  Acc@1: 75.0000 (71.2355)  Acc@5: 100.0000 (97.1509)  time: 0.3476  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -0.7922  Acc@1: 75.0000 (71.2610)  Acc@5: 100.0000 (97.1575)  time: 0.3487  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.0851  Acc@1: 75.0000 (71.3074)  Acc@5: 100.0000 (97.1472)  time: 0.3487  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -0.3697  Acc@1: 75.0000 (71.3405)  Acc@5: 100.0000 (97.1621)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.6852  Acc@1: 75.0000 (71.3649)  Acc@5: 100.0000 (97.1810)  time: 0.3482  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.3911  Acc@1: 75.0000 (71.3807)  Acc@5: 100.0000 (97.1914)  time: 0.3513  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1520/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.6258  Acc@1: 68.7500 (71.3881)  Acc@5: 100.0000 (97.1976)  time: 0.3510  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.3651  Acc@1: 75.0000 (71.4402)  Acc@5: 100.0000 (97.2118)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.3589  Acc@1: 75.0000 (71.4593)  Acc@5: 100.0000 (97.2096)  time: 0.3465  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.6141  Acc@1: 81.2500 (71.5063)  Acc@5: 100.0000 (97.2195)  time: 0.3469  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.4303  Acc@1: 75.0000 (71.5247)  Acc@5: 100.0000 (97.2333)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.3999  Acc@1: 75.0000 (71.5587)  Acc@5: 100.0000 (97.2430)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.3488  Acc@1: 75.0000 (71.5844)  Acc@5: 100.0000 (97.2486)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.8469  Acc@1: 75.0000 (71.6216)  Acc@5: 100.0000 (97.2541)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.6889  Acc@1: 81.2500 (71.6779)  Acc@5: 100.0000 (97.2595)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.3940  Acc@1: 75.0000 (71.6985)  Acc@5: 100.0000 (97.2610)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.1459  Acc@1: 75.0000 (71.6996)  Acc@5: 100.0000 (97.2625)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.7292  Acc@1: 75.0000 (71.7198)  Acc@5: 100.0000 (97.2678)  time: 0.3464  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.1195  Acc@1: 75.0000 (71.7474)  Acc@5: 100.0000 (97.2730)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.7870  Acc@1: 81.2500 (71.8012)  Acc@5: 100.0000 (97.2857)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.6435  Acc@1: 81.2500 (71.8242)  Acc@5: 100.0000 (97.2908)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.6465  Acc@1: 75.0000 (71.8320)  Acc@5: 100.0000 (97.2995)  time: 0.3472  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.5734  Acc@1: 75.0000 (71.8583)  Acc@5: 100.0000 (97.3119)  time: 0.3477  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [1690/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.6953  Acc@1: 75.0000 (71.8990)  Acc@5: 100.0000 (97.3019)  time: 0.3485  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.7994  Acc@1: 81.2500 (71.9650)  Acc@5: 100.0000 (97.3104)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.7121  Acc@1: 81.2500 (71.9937)  Acc@5: 100.0000 (97.3188)  time: 0.3503  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.2089  Acc@1: 75.0000 (72.0148)  Acc@5: 100.0000 (97.3308)  time: 0.3513  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.4731  Acc@1: 75.0000 (72.0465)  Acc@5: 100.0000 (97.3317)  time: 0.3519  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.4926  Acc@1: 75.0000 (72.0706)  Acc@5: 100.0000 (97.3399)  time: 0.3515  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.2433  Acc@1: 75.0000 (72.0981)  Acc@5: 100.0000 (97.3408)  time: 0.3492  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.2492  Acc@1: 81.2500 (72.1323)  Acc@5: 100.0000 (97.3488)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.6320  Acc@1: 81.2500 (72.1450)  Acc@5: 100.0000 (97.3497)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.6352  Acc@1: 75.0000 (72.1505)  Acc@5: 100.0000 (97.3470)  time: 0.3476  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.4196  Acc@1: 75.0000 (72.1420)  Acc@5: 100.0000 (97.3548)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.4281  Acc@1: 68.7500 (72.1335)  Acc@5: 100.0000 (97.3591)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.2245  Acc@1: 68.7500 (72.1252)  Acc@5: 100.0000 (97.3668)  time: 0.3494  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.4390  Acc@1: 75.0000 (72.1410)  Acc@5: 100.0000 (97.3812)  time: 0.3495  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.3322  Acc@1: 75.0000 (72.1498)  Acc@5: 100.0000 (97.3921)  time: 0.3483  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -0.8091  Acc@1: 75.0000 (72.1856)  Acc@5: 100.0000 (97.3927)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.7236  Acc@1: 81.2500 (72.1941)  Acc@5: 100.0000 (97.3832)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1860/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -0.6811  Acc@1: 81.2500 (72.2495)  Acc@5: 100.0000 (97.3939)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.8503  Acc@1: 81.2500 (72.2842)  Acc@5: 100.0000 (97.3978)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.2203  Acc@1: 75.0000 (72.2854)  Acc@5: 100.0000 (97.3950)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.4488  Acc@1: 75.0000 (72.3063)  Acc@5: 100.0000 (97.3989)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.7538  Acc@1: 75.0000 (72.3304)  Acc@5: 100.0000 (97.4093)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.8417  Acc@1: 75.0000 (72.3182)  Acc@5: 100.0000 (97.4065)  time: 0.3463  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.3378  Acc@1: 75.0000 (72.3484)  Acc@5: 100.0000 (97.4135)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.6580  Acc@1: 81.2500 (72.3783)  Acc@5: 100.0000 (97.4107)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -0.4492  Acc@1: 75.0000 (72.3886)  Acc@5: 100.0000 (97.4143)  time: 0.3454  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.6500  Acc@1: 75.0000 (72.3892)  Acc@5: 100.0000 (97.4212)  time: 0.3467  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.8437  Acc@1: 75.0000 (72.3993)  Acc@5: 100.0000 (97.4184)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.6267  Acc@1: 75.0000 (72.4315)  Acc@5: 100.0000 (97.4157)  time: 0.3482  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -0.6104  Acc@1: 75.0000 (72.4382)  Acc@5: 100.0000 (97.4161)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.3229  Acc@1: 75.0000 (72.4510)  Acc@5: 100.0000 (97.4259)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -0.7265  Acc@1: 75.0000 (72.4544)  Acc@5: 100.0000 (97.4357)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.5918  Acc@1: 75.0000 (72.5012)  Acc@5: 100.0000 (97.4453)  time: 0.3479  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.5075  Acc@1: 75.0000 (72.5229)  Acc@5: 100.0000 (97.4518)  time: 0.3485  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2030/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.4251  Acc@1: 75.0000 (72.5412)  Acc@5: 100.0000 (97.4612)  time: 0.3521  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.4201  Acc@1: 75.0000 (72.5318)  Acc@5: 100.0000 (97.4584)  time: 0.3531  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.2609  Acc@1: 75.0000 (72.5439)  Acc@5: 100.0000 (97.4677)  time: 0.3507  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.2425  Acc@1: 75.0000 (72.5315)  Acc@5: 100.0000 (97.4557)  time: 0.3517  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.3359  Acc@1: 75.0000 (72.5646)  Acc@5: 100.0000 (97.4650)  time: 0.3508  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5060  Acc@1: 75.0000 (72.5583)  Acc@5: 100.0000 (97.4712)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.1524  Acc@1: 68.7500 (72.5789)  Acc@5: 100.0000 (97.4713)  time: 0.3498  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.8581  Acc@1: 81.2500 (72.6172)  Acc@5: 100.0000 (97.4744)  time: 0.3496  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.1879  Acc@1: 81.2500 (72.6551)  Acc@5: 100.0000 (97.4775)  time: 0.3483  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.5890  Acc@1: 81.2500 (72.6691)  Acc@5: 100.0000 (97.4776)  time: 0.3484  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.5999  Acc@1: 75.0000 (72.6977)  Acc@5: 100.0000 (97.4836)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.0048  Acc@1: 75.0000 (72.6909)  Acc@5: 100.0000 (97.4924)  time: 0.3475  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.5930  Acc@1: 75.0000 (72.7220)  Acc@5: 100.0000 (97.5041)  time: 0.3497  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.4905  Acc@1: 75.0000 (72.7441)  Acc@5: 100.0000 (97.4983)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.6938  Acc@1: 75.0000 (72.7459)  Acc@5: 100.0000 (97.4954)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.5539  Acc@1: 75.0000 (72.7591)  Acc@5: 100.0000 (97.5040)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.5963  Acc@1: 81.2500 (72.8064)  Acc@5: 100.0000 (97.5154)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2200/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.9156  Acc@1: 81.2500 (72.8220)  Acc@5: 100.0000 (97.5182)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.4313  Acc@1: 81.2500 (72.8432)  Acc@5: 100.0000 (97.5209)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.5506  Acc@1: 81.2500 (72.8641)  Acc@5: 100.0000 (97.5321)  time: 0.3463  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.6885  Acc@1: 81.2500 (72.9045)  Acc@5: 100.0000 (97.5375)  time: 0.3460  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.6822  Acc@1: 81.2500 (72.9334)  Acc@5: 100.0000 (97.5374)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.4206  Acc@1: 75.0000 (72.9231)  Acc@5: 100.0000 (97.5428)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.3916  Acc@1: 75.0000 (72.9517)  Acc@5: 100.0000 (97.5453)  time: 0.3484  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.4211  Acc@1: 81.2500 (72.9690)  Acc@5: 100.0000 (97.5534)  time: 0.3491  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.3734  Acc@1: 75.0000 (72.9779)  Acc@5: 100.0000 (97.5559)  time: 0.3495  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.5646  Acc@1: 75.0000 (72.9758)  Acc@5: 100.0000 (97.5611)  time: 0.3503  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.6768  Acc@1: 75.0000 (72.9982)  Acc@5: 100.0000 (97.5636)  time: 0.3505  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5020  Acc@1: 75.0000 (72.9933)  Acc@5: 100.0000 (97.5714)  time: 0.3497  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.4709  Acc@1: 75.0000 (73.0154)  Acc@5: 100.0000 (97.5792)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.9244  Acc@1: 81.2500 (73.0534)  Acc@5: 100.0000 (97.5815)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.4474  Acc@1: 81.2500 (73.0564)  Acc@5: 100.0000 (97.5785)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.4443  Acc@1: 75.0000 (73.0700)  Acc@5: 100.0000 (97.5808)  time: 0.3478  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.2791  Acc@1: 81.2500 (73.1046)  Acc@5: 100.0000 (97.5858)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.2828  Acc@1: 75.0000 (73.1232)  Acc@5: 100.0000 (97.5854)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -0.5824  Acc@1: 75.0000 (73.1442)  Acc@5: 100.0000 (97.5877)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.8621  Acc@1: 75.0000 (73.1572)  Acc@5: 100.0000 (97.5847)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.4445  Acc@1: 75.0000 (73.1674)  Acc@5: 100.0000 (97.5869)  time: 0.3482  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.6467  Acc@1: 75.0000 (73.1906)  Acc@5: 100.0000 (97.5944)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -0.5238  Acc@1: 81.2500 (73.2084)  Acc@5: 100.0000 (97.6017)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.5338  Acc@1: 81.2500 (73.2338)  Acc@5: 100.0000 (97.6064)  time: 0.3459  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.5535  Acc@1: 81.2500 (73.2589)  Acc@5: 100.0000 (97.6162)  time: 0.3463  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.8662  Acc@1: 81.2500 (73.2992)  Acc@5: 100.0000 (97.6234)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.8523  Acc@1: 81.2500 (73.2985)  Acc@5: 100.0000 (97.6204)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.8509  Acc@1: 81.2500 (73.3205)  Acc@5: 100.0000 (97.6249)  time: 0.3459  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.7725  Acc@1: 81.2500 (73.3550)  Acc@5: 100.0000 (97.6320)  time: 0.3456  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.0104  Acc@1: 75.0000 (73.3440)  Acc@5: 100.0000 (97.6415)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.3118  Acc@1: 68.7500 (73.3357)  Acc@5: 100.0000 (97.6384)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -0.4590  Acc@1: 75.0000 (73.3498)  Acc@5: 100.0000 (97.6454)  time: 0.3467  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.8248  Acc@1: 75.0000 (73.3811)  Acc@5: 100.0000 (97.6473)  time: 0.3487  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.8008  Acc@1: 81.2500 (73.3949)  Acc@5: 100.0000 (97.6492)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.1724  Acc@1: 75.0000 (73.4086)  Acc@5: 100.0000 (97.6535)  time: 0.3481  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.3025  Acc@1: 68.7500 (73.4075)  Acc@5: 100.0000 (97.6529)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6691  Acc@1: 75.0000 (73.4308)  Acc@5: 100.0000 (97.6547)  time: 0.3489  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.4833  Acc@1: 81.2500 (73.4612)  Acc@5: 100.0000 (97.6590)  time: 0.3499  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.5775  Acc@1: 75.0000 (73.4623)  Acc@5: 100.0000 (97.6584)  time: 0.3501  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.7162  Acc@1: 68.7500 (73.4755)  Acc@5: 100.0000 (97.6602)  time: 0.3503  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.5146  Acc@1: 75.0000 (73.4838)  Acc@5: 100.0000 (97.6644)  time: 0.3502  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.3500  Acc@1: 75.0000 (73.5015)  Acc@5: 100.0000 (97.6661)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.1668  Acc@1: 81.2500 (73.5192)  Acc@5: 100.0000 (97.6703)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.4635  Acc@1: 75.0000 (73.5248)  Acc@5: 100.0000 (97.6720)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.5512  Acc@1: 75.0000 (73.5422)  Acc@5: 100.0000 (97.6713)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.7482  Acc@1: 81.2500 (73.5784)  Acc@5: 100.0000 (97.6778)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.5687  Acc@1: 75.0000 (73.5485)  Acc@5: 100.0000 (97.6818)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.7166  Acc@1: 68.7500 (73.5516)  Acc@5: 100.0000 (97.6835)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.3368  Acc@1: 75.0000 (73.5500)  Acc@5: 100.0000 (97.6874)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.3807  Acc@1: 75.0000 (73.5554)  Acc@5: 100.0000 (97.6914)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.3848  Acc@1: 75.0000 (73.5630)  Acc@5: 100.0000 (97.6953)  time: 0.3534  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.3100  Acc@1: 75.0000 (73.5706)  Acc@5: 100.0000 (97.6969)  time: 0.3541  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2720/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.6555  Acc@1: 75.0000 (73.5552)  Acc@5: 100.0000 (97.7008)  time: 0.3515  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.7098  Acc@1: 75.0000 (73.5720)  Acc@5: 100.0000 (97.6977)  time: 0.3536  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.0739  Acc@1: 75.0000 (73.5817)  Acc@5: 100.0000 (97.7016)  time: 0.3518  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.8513  Acc@1: 81.2500 (73.5914)  Acc@5: 100.0000 (97.6986)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.5156  Acc@1: 81.2500 (73.6124)  Acc@5: 100.0000 (97.7024)  time: 0.3485  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6572  Acc@1: 75.0000 (73.6106)  Acc@5: 100.0000 (97.7039)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6209  Acc@1: 75.0000 (73.6111)  Acc@5: 100.0000 (97.7122)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.1527  Acc@1: 75.0000 (73.6183)  Acc@5: 100.0000 (97.7114)  time: 0.3491  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.6614  Acc@1: 75.0000 (73.6456)  Acc@5: 100.0000 (97.7196)  time: 0.3502  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.5353  Acc@1: 81.2500 (73.6660)  Acc@5: 100.0000 (97.7210)  time: 0.3502  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.3435  Acc@1: 75.0000 (73.6707)  Acc@5: 100.0000 (97.7291)  time: 0.3502  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.7361  Acc@1: 75.0000 (73.6710)  Acc@5: 100.0000 (97.7371)  time: 0.3500  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.9104  Acc@1: 81.2500 (73.7086)  Acc@5: 100.0000 (97.7429)  time: 0.3507  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -1.0110  Acc@1: 81.2500 (73.7329)  Acc@5: 100.0000 (97.7420)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.8566  Acc@1: 81.2500 (73.7504)  Acc@5: 100.0000 (97.7412)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.5610  Acc@1: 81.2500 (73.7744)  Acc@5: 100.0000 (97.7403)  time: 0.3502  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.6056  Acc@1: 75.0000 (73.7700)  Acc@5: 100.0000 (97.7395)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.8910  Acc@1: 75.0000 (73.7807)  Acc@5: 100.0000 (97.7387)  time: 0.3487  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.3919  Acc@1: 75.0000 (73.7720)  Acc@5: 100.0000 (97.7422)  time: 0.3484  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -1.0540  Acc@1: 75.0000 (73.7848)  Acc@5: 100.0000 (97.7413)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.4379  Acc@1: 81.2500 (73.8039)  Acc@5: 100.0000 (97.7469)  time: 0.3475  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.6990  Acc@1: 75.0000 (73.7995)  Acc@5: 100.0000 (97.7439)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.5129  Acc@1: 75.0000 (73.8184)  Acc@5: 100.0000 (97.7431)  time: 0.3475  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.5069  Acc@1: 75.0000 (73.8097)  Acc@5: 100.0000 (97.7444)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.7682  Acc@1: 68.7500 (73.7969)  Acc@5: 100.0000 (97.7478)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.1792  Acc@1: 75.0000 (73.8262)  Acc@5: 100.0000 (97.7512)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.6820  Acc@1: 75.0000 (73.8280)  Acc@5: 100.0000 (97.7566)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.5323  Acc@1: 75.0000 (73.8340)  Acc@5: 100.0000 (97.7537)  time: 0.3472  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.6265  Acc@1: 81.2500 (73.8504)  Acc@5: 100.0000 (97.7612)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.6827  Acc@1: 81.2500 (73.8708)  Acc@5: 100.0000 (97.7665)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.6566  Acc@1: 75.0000 (73.8745)  Acc@5: 100.0000 (97.7698)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.2920  Acc@1: 75.0000 (73.8824)  Acc@5: 100.0000 (97.7689)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.5216  Acc@1: 75.0000 (73.8922)  Acc@5: 100.0000 (97.7742)  time: 0.3456  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: 0.0726  Acc@1: 75.0000 (73.9102)  Acc@5: 100.0000 (97.7692)  time: 0.3457  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.5997  Acc@1: 75.0000 (73.9301)  Acc@5: 100.0000 (97.7744)  time: 0.3454  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.6956  Acc@1: 75.0000 (73.9417)  Acc@5: 100.0000 (97.7735)  time: 0.3452  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.6026  Acc@1: 75.0000 (73.9451)  Acc@5: 100.0000 (97.7787)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.4357  Acc@1: 75.0000 (73.9627)  Acc@5: 100.0000 (97.7819)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.3603  Acc@1: 75.0000 (73.9640)  Acc@5: 100.0000 (97.7830)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7060  Acc@1: 75.0000 (73.9593)  Acc@5: 100.0000 (97.7801)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.6597  Acc@1: 81.2500 (73.9807)  Acc@5: 100.0000 (97.7772)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5347  Acc@1: 81.2500 (73.9840)  Acc@5: 100.0000 (97.7743)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.8332  Acc@1: 75.0000 (73.9792)  Acc@5: 100.0000 (97.7754)  time: 0.3485  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.3407  Acc@1: 75.0000 (73.9964)  Acc@5: 100.0000 (97.7785)  time: 0.3476  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.7516  Acc@1: 81.2500 (73.9995)  Acc@5: 100.0000 (97.7816)  time: 0.3488  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.8630  Acc@1: 81.2500 (74.0244)  Acc@5: 100.0000 (97.7866)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.3738  Acc@1: 81.2500 (74.0412)  Acc@5: 100.0000 (97.7935)  time: 0.3498  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.3937  Acc@1: 81.2500 (74.0638)  Acc@5: 100.0000 (97.7946)  time: 0.3498  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.5020  Acc@1: 81.2500 (74.0667)  Acc@5: 100.0000 (97.7956)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.7166  Acc@1: 75.0000 (74.0754)  Acc@5: 100.0000 (97.7927)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.1315  Acc@1: 75.0000 (74.0822)  Acc@5: 100.0000 (97.7938)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.9343  Acc@1: 75.0000 (74.0986)  Acc@5: 100.0000 (97.7948)  time: 0.3496  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.4061  Acc@1: 75.0000 (74.1052)  Acc@5: 100.0000 (97.7997)  time: 0.3499  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.6016  Acc@1: 81.2500 (74.1310)  Acc@5: 100.0000 (97.8045)  time: 0.3488  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.3836  Acc@1: 81.2500 (74.1471)  Acc@5: 100.0000 (97.8074)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.4225  Acc@1: 81.2500 (74.1535)  Acc@5: 100.0000 (97.8065)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.6003  Acc@1: 81.2500 (74.1657)  Acc@5: 100.0000 (97.8036)  time: 0.3496  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.4037  Acc@1: 75.0000 (74.1720)  Acc@5: 100.0000 (97.8103)  time: 0.3497  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.8047  Acc@1: 75.0000 (74.1745)  Acc@5: 100.0000 (97.8169)  time: 0.3498  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.3828  Acc@1: 81.2500 (74.1864)  Acc@5: 100.0000 (97.8160)  time: 0.3505  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.0925  Acc@1: 81.2500 (74.1945)  Acc@5: 100.0000 (97.8169)  time: 0.3493  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.5375  Acc@1: 75.0000 (74.1932)  Acc@5: 100.0000 (97.8178)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.2981  Acc@1: 75.0000 (74.2106)  Acc@5: 100.0000 (97.8169)  time: 0.3562  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6003  Acc@1: 75.0000 (74.2204)  Acc@5: 100.0000 (97.8178)  time: 0.3563  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.7226  Acc@1: 75.0000 (74.2227)  Acc@5: 100.0000 (97.8224)  time: 0.3560  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.6714  Acc@1: 81.2500 (74.2510)  Acc@5: 100.0000 (97.8271)  time: 0.3580  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.5574  Acc@1: 81.2500 (74.2624)  Acc@5: 100.0000 (97.8298)  time: 0.3521  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6730  Acc@1: 81.2500 (74.2867)  Acc@5: 100.0000 (97.8343)  time: 0.3485  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.6883  Acc@1: 81.2500 (74.2925)  Acc@5: 100.0000 (97.8389)  time: 0.3495  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.5639  Acc@1: 75.0000 (74.3019)  Acc@5: 100.0000 (97.8379)  time: 0.3494  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.6319  Acc@1: 81.2500 (74.3149)  Acc@5: 100.0000 (97.8387)  time: 0.3490  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.5366  Acc@1: 75.0000 (74.3205)  Acc@5: 100.0000 (97.8450)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.5946  Acc@1: 81.2500 (74.3425)  Acc@5: 100.0000 (97.8495)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7404  Acc@1: 81.2500 (74.3553)  Acc@5: 100.0000 (97.8503)  time: 0.3487  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.4647  Acc@1: 75.0000 (74.3625)  Acc@5: 100.0000 (97.8456)  time: 0.3485  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.1349  Acc@1: 68.7500 (74.3500)  Acc@5: 100.0000 (97.8482)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.7324  Acc@1: 75.0000 (74.3644)  Acc@5: 100.0000 (97.8508)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.4549  Acc@1: 81.2500 (74.3823)  Acc@5: 100.0000 (97.8534)  time: 0.3496  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.4491  Acc@1: 81.2500 (74.3912)  Acc@5: 100.0000 (97.8560)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.4219  Acc@1: 75.0000 (74.3965)  Acc@5: 100.0000 (97.8550)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7044  Acc@1: 75.0000 (74.4089)  Acc@5: 100.0000 (97.8593)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.7514  Acc@1: 75.0000 (74.4159)  Acc@5: 100.0000 (97.8636)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9051  Acc@1: 75.0000 (74.4387)  Acc@5: 100.0000 (97.8696)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.7838  Acc@1: 81.2500 (74.4561)  Acc@5: 100.0000 (97.8738)  time: 0.3481  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6875  Acc@1: 81.2500 (74.4664)  Acc@5: 100.0000 (97.8745)  time: 0.3498  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.5182  Acc@1: 81.2500 (74.4819)  Acc@5: 100.0000 (97.8735)  time: 0.3509  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.1061  Acc@1: 75.0000 (74.4834)  Acc@5: 100.0000 (97.8794)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.8505  Acc@1: 75.0000 (74.4900)  Acc@5: 100.0000 (97.8801)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.9364  Acc@1: 75.0000 (74.4949)  Acc@5: 100.0000 (97.8843)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.7975  Acc@1: 81.2500 (74.5188)  Acc@5: 100.0000 (97.8867)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4039  Acc@1: 81.2500 (74.5305)  Acc@5: 100.0000 (97.8873)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.6583  Acc@1: 75.0000 (74.5353)  Acc@5: 100.0000 (97.8863)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1978  Acc@1: 75.0000 (74.5434)  Acc@5: 100.0000 (97.8869)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5246  Acc@1: 81.2500 (74.5737)  Acc@5: 100.0000 (97.8927)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5394  Acc@1: 81.2500 (74.5698)  Acc@5: 100.0000 (97.8967)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4177  Acc@1: 75.0000 (74.5846)  Acc@5: 100.0000 (97.8974)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6041  Acc@1: 75.0000 (74.5908)  Acc@5: 100.0000 (97.9014)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.3378  Acc@1: 75.0000 (74.5953)  Acc@5: 100.0000 (97.9003)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7720  Acc@1: 75.0000 (74.6082)  Acc@5: 100.0000 (97.9026)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0962  Acc@1: 75.0000 (74.6076)  Acc@5: 100.0000 (97.9082)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6675  Acc@1: 75.0000 (74.6137)  Acc@5: 100.0000 (97.9088)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.4457  Acc@1: 81.2500 (74.6264)  Acc@5: 100.0000 (97.9077)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5416  Acc@1: 81.2500 (74.6391)  Acc@5: 100.0000 (97.9117)  time: 0.3456  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6108  Acc@1: 75.0000 (74.6367)  Acc@5: 100.0000 (97.9133)  time: 0.3464  data: 0.0008  max mem: 2503
Train: Epoch[1/5] Total time: 0:21:46 (0.3485 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 91309, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 91053, 4: 60000}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 59968}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 60000}, 18: {0: 16, 1: 0, 2: 0, 3: 91197, 4: 32}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 60000}}
Averaged stats: Lr: 0.001875  Loss: 0.6108  Acc@1: 75.0000 (74.6367)  Acc@5: 100.0000 (97.9133)
Train: Epoch[2/5]  [   0/3750]  eta: 0:54:34  Lr: 0.001875  Loss: -0.6889  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.8733  data: 0.5193  max mem: 2503
Train: Epoch[2/5]  [  10/3750]  eta: 0:24:41  Lr: 0.001875  Loss: -0.6040  Acc@1: 75.0000 (78.4091)  Acc@5: 100.0000 (98.2955)  time: 0.3961  data: 0.0487  max mem: 2503
Train: Epoch[2/5]  [  20/3750]  eta: 0:23:17  Lr: 0.001875  Loss: -0.5179  Acc@1: 75.0000 (76.7857)  Acc@5: 100.0000 (98.2143)  time: 0.3498  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:41  Lr: 0.001875  Loss: -0.7866  Acc@1: 81.2500 (77.6210)  Acc@5: 100.0000 (98.5887)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:23  Lr: 0.001875  Loss: -0.6498  Acc@1: 81.2500 (77.4390)  Acc@5: 100.0000 (98.1707)  time: 0.3488  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:09  Lr: 0.001875  Loss: -0.5722  Acc@1: 75.0000 (77.2059)  Acc@5: 100.0000 (98.4069)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -0.4291  Acc@1: 75.0000 (76.6393)  Acc@5: 100.0000 (98.5656)  time: 0.3486  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.8751  Acc@1: 75.0000 (76.4965)  Acc@5: 100.0000 (98.6796)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.8276  Acc@1: 81.2500 (77.4691)  Acc@5: 100.0000 (98.6883)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.9041  Acc@1: 81.2500 (77.3352)  Acc@5: 100.0000 (98.6264)  time: 0.3497  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -0.9045  Acc@1: 75.0000 (77.4134)  Acc@5: 100.0000 (98.5767)  time: 0.3496  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.3863  Acc@1: 75.0000 (77.8153)  Acc@5: 100.0000 (98.5360)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -0.5186  Acc@1: 75.0000 (77.7893)  Acc@5: 100.0000 (98.5537)  time: 0.3497  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.7024  Acc@1: 75.0000 (77.8626)  Acc@5: 100.0000 (98.4733)  time: 0.3506  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.4976  Acc@1: 75.0000 (78.0142)  Acc@5: 100.0000 (98.4929)  time: 0.3481  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.6657  Acc@1: 81.2500 (78.1457)  Acc@5: 100.0000 (98.3858)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.6600  Acc@1: 75.0000 (78.1056)  Acc@5: 100.0000 (98.3307)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 170/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.2749  Acc@1: 75.0000 (78.2529)  Acc@5: 100.0000 (98.3187)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.4029  Acc@1: 81.2500 (78.1423)  Acc@5: 100.0000 (98.3080)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.6778  Acc@1: 75.0000 (77.9450)  Acc@5: 100.0000 (98.3639)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.8021  Acc@1: 75.0000 (78.1716)  Acc@5: 100.0000 (98.3831)  time: 0.3474  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.4835  Acc@1: 75.0000 (77.9325)  Acc@5: 100.0000 (98.3709)  time: 0.3509  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.9014  Acc@1: 75.0000 (77.9412)  Acc@5: 100.0000 (98.3314)  time: 0.3548  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.6854  Acc@1: 75.0000 (77.7597)  Acc@5: 100.0000 (98.2684)  time: 0.3521  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.7803  Acc@1: 75.0000 (77.8786)  Acc@5: 100.0000 (98.2365)  time: 0.3559  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.7682  Acc@1: 81.2500 (78.0129)  Acc@5: 100.0000 (98.1823)  time: 0.3555  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:27  Lr: 0.001875  Loss: -0.5567  Acc@1: 68.7500 (77.7778)  Acc@5: 100.0000 (98.2280)  time: 0.3483  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.7748  Acc@1: 75.0000 (77.9982)  Acc@5: 100.0000 (98.2472)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.1519  Acc@1: 81.2500 (77.8247)  Acc@5: 100.0000 (98.2206)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.3976  Acc@1: 75.0000 (77.9424)  Acc@5: 100.0000 (98.1959)  time: 0.3479  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.4082  Acc@1: 68.7500 (77.5540)  Acc@5: 100.0000 (98.1728)  time: 0.3491  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.6338  Acc@1: 68.7500 (77.4518)  Acc@5: 100.0000 (98.1109)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 320/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.8814  Acc@1: 81.2500 (77.5117)  Acc@5: 100.0000 (98.1308)  time: 0.3488  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 330/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.8696  Acc@1: 81.2500 (77.4736)  Acc@5: 100.0000 (98.1684)  time: 0.3503  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.8747  Acc@1: 75.0000 (77.3644)  Acc@5: 100.0000 (98.1855)  time: 0.3507  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.4617  Acc@1: 75.0000 (77.2436)  Acc@5: 100.0000 (98.1838)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.5403  Acc@1: 75.0000 (77.2161)  Acc@5: 100.0000 (98.2168)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.7117  Acc@1: 81.2500 (77.3080)  Acc@5: 100.0000 (98.2143)  time: 0.3479  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.5664  Acc@1: 81.2500 (77.4114)  Acc@5: 100.0000 (98.2119)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -1.0073  Acc@1: 81.2500 (77.4457)  Acc@5: 100.0000 (98.2257)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.7203  Acc@1: 81.2500 (77.6029)  Acc@5: 100.0000 (98.2232)  time: 0.3492  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.4283  Acc@1: 81.2500 (77.6308)  Acc@5: 100.0000 (98.2208)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.5113  Acc@1: 81.2500 (77.5980)  Acc@5: 100.0000 (98.2334)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.4673  Acc@1: 75.0000 (77.6537)  Acc@5: 100.0000 (98.2309)  time: 0.3487  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.5027  Acc@1: 81.2500 (77.7494)  Acc@5: 100.0000 (98.2568)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.5817  Acc@1: 75.0000 (77.7300)  Acc@5: 100.0000 (98.2677)  time: 0.3528  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.6397  Acc@1: 75.0000 (77.6979)  Acc@5: 100.0000 (98.2646)  time: 0.3524  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.7863  Acc@1: 75.0000 (77.7468)  Acc@5: 100.0000 (98.2749)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.2175  Acc@1: 81.2500 (77.7027)  Acc@5: 100.0000 (98.2978)  time: 0.3469  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 490/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.5711  Acc@1: 75.0000 (77.6731)  Acc@5: 100.0000 (98.3198)  time: 0.3475  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.3076  Acc@1: 75.0000 (77.7570)  Acc@5: 100.0000 (98.3159)  time: 0.3472  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.4536  Acc@1: 81.2500 (77.7520)  Acc@5: 100.0000 (98.2999)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.8463  Acc@1: 75.0000 (77.8311)  Acc@5: 100.0000 (98.3325)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.8485  Acc@1: 81.2500 (77.7660)  Acc@5: 100.0000 (98.3404)  time: 0.3476  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.2005  Acc@1: 75.0000 (77.6456)  Acc@5: 100.0000 (98.3364)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.6931  Acc@1: 75.0000 (77.6996)  Acc@5: 100.0000 (98.3326)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.7286  Acc@1: 81.2500 (77.6404)  Acc@5: 100.0000 (98.3400)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.8802  Acc@1: 75.0000 (77.6598)  Acc@5: 100.0000 (98.3581)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.4688  Acc@1: 81.2500 (77.7539)  Acc@5: 100.0000 (98.3649)  time: 0.3454  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.3134  Acc@1: 81.2500 (77.7390)  Acc@5: 100.0000 (98.3714)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.4848  Acc@1: 75.0000 (77.7454)  Acc@5: 100.0000 (98.3777)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.5089  Acc@1: 75.0000 (77.7005)  Acc@5: 100.0000 (98.3940)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.5224  Acc@1: 75.0000 (77.6570)  Acc@5: 100.0000 (98.3998)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.2717  Acc@1: 75.0000 (77.6050)  Acc@5: 100.0000 (98.4152)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.5516  Acc@1: 75.0000 (77.5254)  Acc@5: 100.0000 (98.4009)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.5243  Acc@1: 75.0000 (77.5154)  Acc@5: 100.0000 (98.4063)  time: 0.3479  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 660/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.5016  Acc@1: 75.0000 (77.4868)  Acc@5: 100.0000 (98.4304)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.9086  Acc@1: 75.0000 (77.4497)  Acc@5: 100.0000 (98.4352)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.6873  Acc@1: 75.0000 (77.4688)  Acc@5: 100.0000 (98.4306)  time: 0.3470  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.5494  Acc@1: 75.0000 (77.4331)  Acc@5: 100.0000 (98.4352)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.4538  Acc@1: 75.0000 (77.4429)  Acc@5: 100.0000 (98.4308)  time: 0.3488  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -0.3729  Acc@1: 75.0000 (77.4525)  Acc@5: 100.0000 (98.4265)  time: 0.3489  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.0545  Acc@1: 75.0000 (77.3578)  Acc@5: 100.0000 (98.3963)  time: 0.3486  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -0.7328  Acc@1: 68.7500 (77.3170)  Acc@5: 100.0000 (98.4097)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.5156  Acc@1: 75.0000 (77.3195)  Acc@5: 100.0000 (98.3974)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.2023  Acc@1: 81.2500 (77.3885)  Acc@5: 100.0000 (98.3772)  time: 0.3477  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.4952  Acc@1: 75.0000 (77.3242)  Acc@5: 100.0000 (98.3656)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.8671  Acc@1: 75.0000 (77.3427)  Acc@5: 100.0000 (98.3787)  time: 0.3488  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.7072  Acc@1: 75.0000 (77.2967)  Acc@5: 100.0000 (98.3835)  time: 0.3496  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.8460  Acc@1: 81.2500 (77.3388)  Acc@5: 100.0000 (98.3802)  time: 0.3505  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.7742  Acc@1: 81.2500 (77.3642)  Acc@5: 100.0000 (98.3692)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.2563  Acc@1: 81.2500 (77.3582)  Acc@5: 100.0000 (98.3816)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.3814  Acc@1: 75.0000 (77.4056)  Acc@5: 100.0000 (98.3937)  time: 0.3487  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 830/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.7419  Acc@1: 81.2500 (77.4594)  Acc@5: 100.0000 (98.3980)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.6424  Acc@1: 81.2500 (77.5193)  Acc@5: 100.0000 (98.4096)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.4969  Acc@1: 75.0000 (77.4824)  Acc@5: 100.0000 (98.4063)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.2843  Acc@1: 75.0000 (77.5261)  Acc@5: 100.0000 (98.4103)  time: 0.3546  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.5777  Acc@1: 75.0000 (77.5258)  Acc@5: 100.0000 (98.4142)  time: 0.3556  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -1.0090  Acc@1: 75.0000 (77.5681)  Acc@5: 100.0000 (98.4251)  time: 0.3538  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.6995  Acc@1: 81.2500 (77.5884)  Acc@5: 100.0000 (98.4287)  time: 0.3528  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.6503  Acc@1: 75.0000 (77.5805)  Acc@5: 100.0000 (98.4323)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.5786  Acc@1: 75.0000 (77.5316)  Acc@5: 100.0000 (98.4221)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.7699  Acc@1: 75.0000 (77.5312)  Acc@5: 100.0000 (98.4324)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.4609  Acc@1: 81.2500 (77.5309)  Acc@5: 100.0000 (98.4358)  time: 0.3472  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.2283  Acc@1: 75.0000 (77.4774)  Acc@5: 100.0000 (98.4126)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.8221  Acc@1: 75.0000 (77.4974)  Acc@5: 100.0000 (98.4227)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:14  Lr: 0.001875  Loss: 0.0328  Acc@1: 75.0000 (77.4714)  Acc@5: 100.0000 (98.4196)  time: 0.3507  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.6950  Acc@1: 75.0000 (77.4459)  Acc@5: 100.0000 (98.4230)  time: 0.3509  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.5241  Acc@1: 75.0000 (77.4337)  Acc@5: 100.0000 (98.4391)  time: 0.3475  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4711  Acc@1: 81.2500 (77.4659)  Acc@5: 100.0000 (98.4422)  time: 0.3469  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1000/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.4138  Acc@1: 75.0000 (77.4538)  Acc@5: 100.0000 (98.4515)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.4601  Acc@1: 75.0000 (77.4172)  Acc@5: 100.0000 (98.4607)  time: 0.3495  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.7657  Acc@1: 75.0000 (77.4486)  Acc@5: 100.0000 (98.4635)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.6899  Acc@1: 81.2500 (77.4855)  Acc@5: 100.0000 (98.4724)  time: 0.3473  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.6420  Acc@1: 81.2500 (77.4976)  Acc@5: 100.0000 (98.4810)  time: 0.3473  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.5618  Acc@1: 81.2500 (77.5095)  Acc@5: 100.0000 (98.4657)  time: 0.3496  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.7860  Acc@1: 75.0000 (77.4564)  Acc@5: 100.0000 (98.4743)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.9727  Acc@1: 75.0000 (77.4743)  Acc@5: 100.0000 (98.4769)  time: 0.3487  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.8704  Acc@1: 81.2500 (77.5439)  Acc@5: 100.0000 (98.4910)  time: 0.3499  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.4220  Acc@1: 81.2500 (77.5321)  Acc@5: 100.0000 (98.4876)  time: 0.3501  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.6204  Acc@1: 81.2500 (77.5658)  Acc@5: 100.0000 (98.4957)  time: 0.3545  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.4406  Acc@1: 75.0000 (77.4865)  Acc@5: 100.0000 (98.4980)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.8269  Acc@1: 75.0000 (77.5256)  Acc@5: 100.0000 (98.5114)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.5151  Acc@1: 81.2500 (77.5199)  Acc@5: 100.0000 (98.5190)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.3294  Acc@1: 75.0000 (77.5471)  Acc@5: 100.0000 (98.5210)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.1930  Acc@1: 81.2500 (77.5521)  Acc@5: 100.0000 (98.5285)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.3834  Acc@1: 75.0000 (77.5624)  Acc@5: 100.0000 (98.5357)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1170/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.1360  Acc@1: 75.0000 (77.5566)  Acc@5: 100.0000 (98.5376)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.9196  Acc@1: 81.2500 (77.5826)  Acc@5: 100.0000 (98.5447)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.4353  Acc@1: 81.2500 (77.6029)  Acc@5: 100.0000 (98.5569)  time: 0.3462  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.8288  Acc@1: 75.0000 (77.5968)  Acc@5: 100.0000 (98.5637)  time: 0.3453  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.5858  Acc@1: 81.2500 (77.6218)  Acc@5: 100.0000 (98.5498)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.2223  Acc@1: 81.2500 (77.6157)  Acc@5: 100.0000 (98.5360)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.4675  Acc@1: 75.0000 (77.6147)  Acc@5: 100.0000 (98.5429)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.6561  Acc@1: 81.2500 (77.6591)  Acc@5: 100.0000 (98.5445)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.6628  Acc@1: 81.2500 (77.6779)  Acc@5: 100.0000 (98.5512)  time: 0.3455  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.7514  Acc@1: 75.0000 (77.7012)  Acc@5: 100.0000 (98.5527)  time: 0.3451  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.3967  Acc@1: 75.0000 (77.6849)  Acc@5: 100.0000 (98.5592)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.8355  Acc@1: 75.0000 (77.7078)  Acc@5: 100.0000 (98.5558)  time: 0.3458  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.4665  Acc@1: 81.2500 (77.7450)  Acc@5: 100.0000 (98.5525)  time: 0.3479  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.8595  Acc@1: 81.2500 (77.7815)  Acc@5: 100.0000 (98.5540)  time: 0.3486  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.7172  Acc@1: 81.2500 (77.8032)  Acc@5: 100.0000 (98.5507)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.4789  Acc@1: 81.2500 (77.8293)  Acc@5: 100.0000 (98.5522)  time: 0.3502  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.1712  Acc@1: 75.0000 (77.8221)  Acc@5: 100.0000 (98.5490)  time: 0.3507  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [1340/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.2072  Acc@1: 75.0000 (77.8104)  Acc@5: 100.0000 (98.5598)  time: 0.3519  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.5568  Acc@1: 75.0000 (77.8174)  Acc@5: 100.0000 (98.5613)  time: 0.3502  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6984  Acc@1: 81.2500 (77.8518)  Acc@5: 100.0000 (98.5672)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7429  Acc@1: 81.2500 (77.8629)  Acc@5: 100.0000 (98.5731)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.5304  Acc@1: 75.0000 (77.8512)  Acc@5: 100.0000 (98.5744)  time: 0.3492  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6206  Acc@1: 81.2500 (77.8846)  Acc@5: 100.0000 (98.5757)  time: 0.3480  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.5420  Acc@1: 81.2500 (77.9131)  Acc@5: 100.0000 (98.5724)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.7849  Acc@1: 81.2500 (77.9102)  Acc@5: 100.0000 (98.5560)  time: 0.3498  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.8712  Acc@1: 75.0000 (77.9381)  Acc@5: 100.0000 (98.5618)  time: 0.3512  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.0735  Acc@1: 81.2500 (77.9612)  Acc@5: 100.0000 (98.5631)  time: 0.3517  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.4817  Acc@1: 81.2500 (77.9624)  Acc@5: 100.0000 (98.5470)  time: 0.3514  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.4903  Acc@1: 75.0000 (77.9032)  Acc@5: 100.0000 (98.5484)  time: 0.3520  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -0.7719  Acc@1: 68.7500 (77.9090)  Acc@5: 100.0000 (98.5327)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.5498  Acc@1: 75.0000 (77.8934)  Acc@5: 100.0000 (98.5384)  time: 0.3486  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.8281  Acc@1: 75.0000 (77.9077)  Acc@5: 100.0000 (98.5230)  time: 0.3539  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.5270  Acc@1: 75.0000 (77.8798)  Acc@5: 100.0000 (98.5287)  time: 0.3557  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.5803  Acc@1: 75.0000 (77.8814)  Acc@5: 100.0000 (98.5343)  time: 0.3527  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1510/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.7992  Acc@1: 75.0000 (77.8582)  Acc@5: 100.0000 (98.5275)  time: 0.3533  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.7283  Acc@1: 75.0000 (77.8600)  Acc@5: 100.0000 (98.5330)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.2187  Acc@1: 75.0000 (77.8209)  Acc@5: 100.0000 (98.5304)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.6061  Acc@1: 81.2500 (77.8634)  Acc@5: 100.0000 (98.5399)  time: 0.3486  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.5411  Acc@1: 81.2500 (77.8651)  Acc@5: 100.0000 (98.5413)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.9539  Acc@1: 81.2500 (77.8908)  Acc@5: 100.0000 (98.5426)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.6115  Acc@1: 81.2500 (77.8923)  Acc@5: 100.0000 (98.5439)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.7642  Acc@1: 81.2500 (77.8898)  Acc@5: 100.0000 (98.5492)  time: 0.3491  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.3530  Acc@1: 75.0000 (77.9030)  Acc@5: 100.0000 (98.5504)  time: 0.3495  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.6254  Acc@1: 81.2500 (77.9005)  Acc@5: 100.0000 (98.5478)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.7010  Acc@1: 75.0000 (77.8864)  Acc@5: 100.0000 (98.5413)  time: 0.3506  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.4721  Acc@1: 81.2500 (77.9110)  Acc@5: 100.0000 (98.5426)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.3972  Acc@1: 81.2500 (77.9162)  Acc@5: 100.0000 (98.5477)  time: 0.3469  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.6381  Acc@1: 81.2500 (77.9365)  Acc@5: 100.0000 (98.5451)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.2755  Acc@1: 75.0000 (77.9338)  Acc@5: 100.0000 (98.5463)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.5035  Acc@1: 75.0000 (77.9425)  Acc@5: 100.0000 (98.5513)  time: 0.3497  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.8278  Acc@1: 81.2500 (77.9623)  Acc@5: 100.0000 (98.5450)  time: 0.3497  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.6286  Acc@1: 81.2500 (77.9707)  Acc@5: 100.0000 (98.5500)  time: 0.3508  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.6550  Acc@1: 81.2500 (77.9938)  Acc@5: 100.0000 (98.5512)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.8030  Acc@1: 81.2500 (78.0056)  Acc@5: 100.0000 (98.5523)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.3710  Acc@1: 81.2500 (78.0099)  Acc@5: 100.0000 (98.5571)  time: 0.3538  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.4215  Acc@1: 81.2500 (78.0106)  Acc@5: 100.0000 (98.5619)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.4061  Acc@1: 75.0000 (78.0004)  Acc@5: 100.0000 (98.5630)  time: 0.3463  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.5443  Acc@1: 75.0000 (78.0191)  Acc@5: 100.0000 (98.5605)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.0180  Acc@1: 75.0000 (78.0019)  Acc@5: 100.0000 (98.5615)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.1518  Acc@1: 81.2500 (77.9955)  Acc@5: 100.0000 (98.5626)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.5179  Acc@1: 81.2500 (78.0032)  Acc@5: 100.0000 (98.5672)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.5486  Acc@1: 81.2500 (78.0004)  Acc@5: 100.0000 (98.5717)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.7098  Acc@1: 75.0000 (78.0046)  Acc@5: 100.0000 (98.5762)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.6079  Acc@1: 75.0000 (77.9949)  Acc@5: 100.0000 (98.5772)  time: 0.3460  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.4149  Acc@1: 75.0000 (78.0025)  Acc@5: 100.0000 (98.5850)  time: 0.3452  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.4504  Acc@1: 68.7500 (77.9551)  Acc@5: 100.0000 (98.5825)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.1334  Acc@1: 68.7500 (77.9151)  Acc@5: 100.0000 (98.5800)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.4996  Acc@1: 75.0000 (77.9026)  Acc@5: 100.0000 (98.5741)  time: 0.3467  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.2878  Acc@1: 75.0000 (77.9241)  Acc@5: 100.0000 (98.5751)  time: 0.3491  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1860/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.8056  Acc@1: 75.0000 (77.9453)  Acc@5: 100.0000 (98.5760)  time: 0.3500  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.2094  Acc@1: 81.2500 (77.9730)  Acc@5: 100.0000 (98.5736)  time: 0.3492  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.4517  Acc@1: 81.2500 (77.9871)  Acc@5: 100.0000 (98.5779)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.8029  Acc@1: 81.2500 (78.0044)  Acc@5: 100.0000 (98.5821)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.6972  Acc@1: 81.2500 (78.0116)  Acc@5: 100.0000 (98.5797)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.2439  Acc@1: 75.0000 (77.9925)  Acc@5: 100.0000 (98.5773)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.7921  Acc@1: 81.2500 (78.0193)  Acc@5: 100.0000 (98.5815)  time: 0.3513  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.5195  Acc@1: 75.0000 (77.9842)  Acc@5: 100.0000 (98.5888)  time: 0.3527  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.7883  Acc@1: 75.0000 (78.0139)  Acc@5: 100.0000 (98.5929)  time: 0.3514  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -1.0274  Acc@1: 81.2500 (78.0497)  Acc@5: 100.0000 (98.5969)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.7412  Acc@1: 81.2500 (78.0533)  Acc@5: 100.0000 (98.5945)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.8446  Acc@1: 81.2500 (78.0537)  Acc@5: 100.0000 (98.5921)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.3203  Acc@1: 81.2500 (78.0603)  Acc@5: 100.0000 (98.5960)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.4997  Acc@1: 75.0000 (78.0481)  Acc@5: 100.0000 (98.5843)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.6642  Acc@1: 75.0000 (78.0360)  Acc@5: 100.0000 (98.5882)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.4241  Acc@1: 75.0000 (78.0147)  Acc@5: 100.0000 (98.5797)  time: 0.3490  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.7630  Acc@1: 75.0000 (78.0369)  Acc@5: 100.0000 (98.5836)  time: 0.3537  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.8851  Acc@1: 81.2500 (78.0311)  Acc@5: 100.0000 (98.5814)  time: 0.3536  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.4310  Acc@1: 81.2500 (78.0377)  Acc@5: 100.0000 (98.5822)  time: 0.3471  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.1722  Acc@1: 81.2500 (78.0260)  Acc@5: 100.0000 (98.5769)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.6554  Acc@1: 75.0000 (78.0052)  Acc@5: 100.0000 (98.5808)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -0.5688  Acc@1: 75.0000 (77.9877)  Acc@5: 100.0000 (98.5816)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.5401  Acc@1: 68.7500 (77.9673)  Acc@5: 100.0000 (98.5854)  time: 0.3474  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.3145  Acc@1: 68.7500 (77.9591)  Acc@5: 100.0000 (98.5802)  time: 0.3489  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.8130  Acc@1: 81.2500 (77.9837)  Acc@5: 100.0000 (98.5840)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.4957  Acc@1: 81.2500 (77.9932)  Acc@5: 100.0000 (98.5878)  time: 0.3456  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.5216  Acc@1: 75.0000 (77.9850)  Acc@5: 100.0000 (98.5915)  time: 0.3456  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.6910  Acc@1: 81.2500 (78.0179)  Acc@5: 100.0000 (98.5951)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.1960  Acc@1: 81.2500 (78.0184)  Acc@5: 100.0000 (98.5900)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.8123  Acc@1: 81.2500 (78.0248)  Acc@5: 100.0000 (98.5908)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.3589  Acc@1: 81.2500 (78.0281)  Acc@5: 100.0000 (98.5944)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.5723  Acc@1: 81.2500 (78.0257)  Acc@5: 100.0000 (98.5865)  time: 0.3452  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.4755  Acc@1: 75.0000 (78.0204)  Acc@5: 100.0000 (98.5872)  time: 0.3472  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.5450  Acc@1: 81.2500 (78.0266)  Acc@5: 100.0000 (98.5908)  time: 0.3480  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.8362  Acc@1: 81.2500 (78.0185)  Acc@5: 100.0000 (98.5944)  time: 0.3475  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.6970  Acc@1: 81.2500 (78.0246)  Acc@5: 100.0000 (98.6007)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.5723  Acc@1: 81.2500 (78.0307)  Acc@5: 100.0000 (98.5986)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -0.7126  Acc@1: 81.2500 (78.0312)  Acc@5: 100.0000 (98.5993)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.4751  Acc@1: 75.0000 (78.0204)  Acc@5: 100.0000 (98.5944)  time: 0.3473  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.6821  Acc@1: 75.0000 (78.0348)  Acc@5: 100.0000 (98.5895)  time: 0.3483  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.9380  Acc@1: 75.0000 (78.0296)  Acc@5: 100.0000 (98.5875)  time: 0.3490  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.6804  Acc@1: 75.0000 (78.0245)  Acc@5: 100.0000 (98.5799)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.6664  Acc@1: 81.2500 (78.0250)  Acc@5: 100.0000 (98.5807)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.5789  Acc@1: 81.2500 (78.0445)  Acc@5: 100.0000 (98.5869)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.3839  Acc@1: 81.2500 (78.0394)  Acc@5: 100.0000 (98.5821)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -0.4949  Acc@1: 75.0000 (78.0425)  Acc@5: 100.0000 (98.5856)  time: 0.3485  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.5619  Acc@1: 81.2500 (78.0509)  Acc@5: 100.0000 (98.5863)  time: 0.3480  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.5715  Acc@1: 81.2500 (78.0486)  Acc@5: 100.0000 (98.5897)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.7490  Acc@1: 75.0000 (78.0409)  Acc@5: 100.0000 (98.5903)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.7899  Acc@1: 75.0000 (78.0306)  Acc@5: 100.0000 (98.5857)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.0433  Acc@1: 75.0000 (78.0072)  Acc@5: 100.0000 (98.5891)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.7051  Acc@1: 75.0000 (78.0024)  Acc@5: 100.0000 (98.5950)  time: 0.3474  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -0.6573  Acc@1: 81.2500 (78.0134)  Acc@5: 100.0000 (98.5957)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.6018  Acc@1: 81.2500 (78.0374)  Acc@5: 100.0000 (98.5963)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.4835  Acc@1: 81.2500 (78.0222)  Acc@5: 100.0000 (98.5995)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.3408  Acc@1: 75.0000 (78.0408)  Acc@5: 100.0000 (98.6054)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -0.6885  Acc@1: 81.2500 (78.0334)  Acc@5: 100.0000 (98.6085)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.3999  Acc@1: 75.0000 (78.0286)  Acc@5: 100.0000 (98.5963)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.6830  Acc@1: 75.0000 (78.0264)  Acc@5: 100.0000 (98.5943)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.0978  Acc@1: 75.0000 (78.0319)  Acc@5: 100.0000 (98.5899)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.5137  Acc@1: 81.2500 (78.0323)  Acc@5: 100.0000 (98.5931)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.3873  Acc@1: 81.2500 (78.0479)  Acc@5: 100.0000 (98.5886)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.6664  Acc@1: 81.2500 (78.0431)  Acc@5: 100.0000 (98.5893)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.4340  Acc@1: 75.0000 (78.0309)  Acc@5: 100.0000 (98.5874)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.6858  Acc@1: 81.2500 (78.0463)  Acc@5: 100.0000 (98.5906)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.4776  Acc@1: 81.2500 (78.0391)  Acc@5: 100.0000 (98.5962)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.5605  Acc@1: 75.0000 (78.0271)  Acc@5: 100.0000 (98.5943)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.1675  Acc@1: 75.0000 (77.9954)  Acc@5: 100.0000 (98.5925)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.9129  Acc@1: 81.2500 (78.0155)  Acc@5: 100.0000 (98.5955)  time: 0.3448  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.6936  Acc@1: 81.2500 (78.0405)  Acc@5: 100.0000 (98.5986)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.8318  Acc@1: 75.0000 (78.0286)  Acc@5: 100.0000 (98.5943)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.9481  Acc@1: 81.2500 (78.0509)  Acc@5: 100.0000 (98.5949)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.5628  Acc@1: 81.2500 (78.0390)  Acc@5: 100.0000 (98.5979)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.4471  Acc@1: 75.0000 (78.0442)  Acc@5: 100.0000 (98.6009)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.3142  Acc@1: 81.2500 (78.0349)  Acc@5: 100.0000 (98.6063)  time: 0.3460  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.6676  Acc@1: 68.7500 (78.0233)  Acc@5: 100.0000 (98.6045)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.3769  Acc@1: 75.0000 (78.0403)  Acc@5: 100.0000 (98.6074)  time: 0.3489  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -1.0288  Acc@1: 81.2500 (78.0668)  Acc@5: 100.0000 (98.6079)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.7033  Acc@1: 81.2500 (78.0718)  Acc@5: 100.0000 (98.6132)  time: 0.3508  data: 0.0028  max mem: 2503
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.7629  Acc@1: 81.2500 (78.0720)  Acc@5: 100.0000 (98.6184)  time: 0.3516  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.4235  Acc@1: 81.2500 (78.0769)  Acc@5: 100.0000 (98.6189)  time: 0.3493  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.7798  Acc@1: 81.2500 (78.0724)  Acc@5: 100.0000 (98.6171)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.3854  Acc@1: 81.2500 (78.0725)  Acc@5: 100.0000 (98.6199)  time: 0.3511  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.7562  Acc@1: 81.2500 (78.0727)  Acc@5: 100.0000 (98.6134)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.1944  Acc@1: 75.0000 (78.0614)  Acc@5: 100.0000 (98.6024)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.7513  Acc@1: 75.0000 (78.0708)  Acc@5: 100.0000 (98.6075)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.7548  Acc@1: 81.2500 (78.0894)  Acc@5: 100.0000 (98.6103)  time: 0.3500  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.6046  Acc@1: 81.2500 (78.0918)  Acc@5: 100.0000 (98.6131)  time: 0.3506  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.9678  Acc@1: 81.2500 (78.0851)  Acc@5: 100.0000 (98.6136)  time: 0.3500  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.5110  Acc@1: 75.0000 (78.0875)  Acc@5: 100.0000 (98.6141)  time: 0.3500  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.4026  Acc@1: 81.2500 (78.0967)  Acc@5: 100.0000 (98.6169)  time: 0.3504  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.5990  Acc@1: 81.2500 (78.0991)  Acc@5: 100.0000 (98.6151)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.3372  Acc@1: 81.2500 (78.1104)  Acc@5: 100.0000 (98.6066)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -1.0570  Acc@1: 81.2500 (78.1261)  Acc@5: 100.0000 (98.6027)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.2967  Acc@1: 75.0000 (78.1328)  Acc@5: 100.0000 (98.6032)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.7706  Acc@1: 81.2500 (78.1439)  Acc@5: 100.0000 (98.5993)  time: 0.3549  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.4183  Acc@1: 81.2500 (78.1571)  Acc@5: 100.0000 (98.5976)  time: 0.3528  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.5170  Acc@1: 81.2500 (78.1857)  Acc@5: 100.0000 (98.6025)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.6486  Acc@1: 81.2500 (78.1921)  Acc@5: 100.0000 (98.6052)  time: 0.3480  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.2102  Acc@1: 75.0000 (78.1787)  Acc@5: 100.0000 (98.6058)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.9151  Acc@1: 75.0000 (78.1894)  Acc@5: 100.0000 (98.6106)  time: 0.3480  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.7406  Acc@1: 81.2500 (78.2023)  Acc@5: 100.0000 (98.6111)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.6999  Acc@1: 81.2500 (78.1955)  Acc@5: 100.0000 (98.6073)  time: 0.3496  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.0988  Acc@1: 75.0000 (78.1845)  Acc@5: 100.0000 (98.6099)  time: 0.3498  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.8771  Acc@1: 75.0000 (78.1735)  Acc@5: 100.0000 (98.6039)  time: 0.3513  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6098  Acc@1: 75.0000 (78.1733)  Acc@5: 100.0000 (98.6044)  time: 0.3521  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.5283  Acc@1: 75.0000 (78.1710)  Acc@5: 100.0000 (98.6071)  time: 0.3507  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.7395  Acc@1: 75.0000 (78.1517)  Acc@5: 100.0000 (98.6054)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.7669  Acc@1: 81.2500 (78.1856)  Acc@5: 100.0000 (98.6080)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.3919  Acc@1: 81.2500 (78.1769)  Acc@5: 100.0000 (98.6022)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.2075  Acc@1: 68.7500 (78.1451)  Acc@5: 100.0000 (98.6027)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.6780  Acc@1: 81.2500 (78.1618)  Acc@5: 100.0000 (98.6053)  time: 0.3489  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.4187  Acc@1: 81.2500 (78.1575)  Acc@5: 100.0000 (98.5974)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.6703  Acc@1: 75.0000 (78.1532)  Acc@5: 100.0000 (98.5937)  time: 0.3513  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.4860  Acc@1: 75.0000 (78.1448)  Acc@5: 100.0000 (98.5984)  time: 0.3517  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.8231  Acc@1: 81.2500 (78.1676)  Acc@5: 100.0000 (98.6010)  time: 0.3475  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.6110  Acc@1: 81.2500 (78.1674)  Acc@5: 100.0000 (98.6056)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.3463  Acc@1: 81.2500 (78.1673)  Acc@5: 100.0000 (98.6061)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.7343  Acc@1: 75.0000 (78.1527)  Acc@5: 100.0000 (98.6065)  time: 0.3472  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.8349  Acc@1: 75.0000 (78.1568)  Acc@5: 100.0000 (98.6070)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.7800  Acc@1: 75.0000 (78.1464)  Acc@5: 100.0000 (98.6054)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.7432  Acc@1: 68.7500 (78.1219)  Acc@5: 100.0000 (98.6079)  time: 0.3470  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.3589  Acc@1: 75.0000 (78.1220)  Acc@5: 100.0000 (98.6104)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.5864  Acc@1: 75.0000 (78.1199)  Acc@5: 100.0000 (98.6089)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.7920  Acc@1: 75.0000 (78.1280)  Acc@5: 100.0000 (98.6033)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.5806  Acc@1: 81.2500 (78.1360)  Acc@5: 100.0000 (98.6058)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.7026  Acc@1: 81.2500 (78.1500)  Acc@5: 100.0000 (98.6102)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.6192  Acc@1: 75.0000 (78.1360)  Acc@5: 100.0000 (98.6087)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.6083  Acc@1: 75.0000 (78.1280)  Acc@5: 100.0000 (98.6091)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.8440  Acc@1: 81.2500 (78.1319)  Acc@5: 100.0000 (98.6076)  time: 0.3454  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.6659  Acc@1: 81.2500 (78.1319)  Acc@5: 100.0000 (98.6100)  time: 0.3463  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.6162  Acc@1: 75.0000 (78.1220)  Acc@5: 100.0000 (98.6124)  time: 0.3474  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.9539  Acc@1: 75.0000 (78.1201)  Acc@5: 100.0000 (98.6129)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.1894  Acc@1: 81.2500 (78.1279)  Acc@5: 100.0000 (98.6133)  time: 0.3510  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.3459  Acc@1: 81.2500 (78.1240)  Acc@5: 100.0000 (98.6157)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.6318  Acc@1: 81.2500 (78.1377)  Acc@5: 100.0000 (98.6180)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.7329  Acc@1: 81.2500 (78.1473)  Acc@5: 100.0000 (98.6204)  time: 0.3499  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.7905  Acc@1: 81.2500 (78.1453)  Acc@5: 100.0000 (98.6188)  time: 0.3495  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.7917  Acc@1: 75.0000 (78.1433)  Acc@5: 100.0000 (98.6212)  time: 0.3515  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.8224  Acc@1: 75.0000 (78.1413)  Acc@5: 100.0000 (98.6216)  time: 0.3529  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.3212  Acc@1: 81.2500 (78.1432)  Acc@5: 100.0000 (98.6239)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.7595  Acc@1: 81.2500 (78.1470)  Acc@5: 100.0000 (98.6243)  time: 0.3471  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.6996  Acc@1: 75.0000 (78.1336)  Acc@5: 100.0000 (98.6247)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.9993  Acc@1: 75.0000 (78.1316)  Acc@5: 100.0000 (98.6250)  time: 0.3503  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.9409  Acc@1: 75.0000 (78.1259)  Acc@5: 100.0000 (98.6216)  time: 0.3516  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.9637  Acc@1: 75.0000 (78.1259)  Acc@5: 100.0000 (98.6201)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.5209  Acc@1: 81.2500 (78.1278)  Acc@5: 100.0000 (98.6243)  time: 0.3508  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.9497  Acc@1: 81.2500 (78.1334)  Acc@5: 100.0000 (98.6209)  time: 0.3512  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.2984  Acc@1: 81.2500 (78.1390)  Acc@5: 100.0000 (98.6250)  time: 0.3492  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6685  Acc@1: 75.0000 (78.1315)  Acc@5: 100.0000 (98.6273)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.7233  Acc@1: 75.0000 (78.1315)  Acc@5: 100.0000 (98.6239)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.0793  Acc@1: 81.2500 (78.1463)  Acc@5: 100.0000 (98.6224)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8355  Acc@1: 81.2500 (78.1629)  Acc@5: 100.0000 (98.6210)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.8488  Acc@1: 81.2500 (78.1609)  Acc@5: 100.0000 (98.6232)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.7865  Acc@1: 75.0000 (78.1553)  Acc@5: 100.0000 (98.6236)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6752  Acc@1: 75.0000 (78.1461)  Acc@5: 100.0000 (98.6239)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.6781  Acc@1: 81.2500 (78.1588)  Acc@5: 100.0000 (98.6280)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.2381  Acc@1: 81.2500 (78.1715)  Acc@5: 100.0000 (98.6301)  time: 0.3488  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9746  Acc@1: 81.2500 (78.1895)  Acc@5: 100.0000 (98.6305)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.5135  Acc@1: 75.0000 (78.1802)  Acc@5: 100.0000 (98.6308)  time: 0.3493  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5428  Acc@1: 75.0000 (78.1909)  Acc@5: 100.0000 (98.6348)  time: 0.3488  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.8179  Acc@1: 81.2500 (78.1889)  Acc@5: 100.0000 (98.6369)  time: 0.3495  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.1956  Acc@1: 81.2500 (78.1851)  Acc@5: 100.0000 (98.6372)  time: 0.3480  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3048  Acc@1: 81.2500 (78.1814)  Acc@5: 100.0000 (98.6411)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8126  Acc@1: 81.2500 (78.1866)  Acc@5: 100.0000 (98.6450)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5079  Acc@1: 75.0000 (78.1882)  Acc@5: 100.0000 (98.6453)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2214  Acc@1: 75.0000 (78.1862)  Acc@5: 100.0000 (98.6474)  time: 0.3474  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.6722  Acc@1: 81.2500 (78.1967)  Acc@5: 100.0000 (98.6477)  time: 0.3480  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4993  Acc@1: 81.2500 (78.2124)  Acc@5: 100.0000 (98.6480)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.8169  Acc@1: 81.2500 (78.2156)  Acc@5: 100.0000 (98.6483)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.8341  Acc@1: 81.2500 (78.2154)  Acc@5: 100.0000 (98.6468)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.4644  Acc@1: 75.0000 (78.2204)  Acc@5: 100.0000 (98.6488)  time: 0.3459  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.2920  Acc@1: 81.2500 (78.2254)  Acc@5: 100.0000 (98.6456)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6449  Acc@1: 81.2500 (78.2390)  Acc@5: 100.0000 (98.6494)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8989  Acc@1: 81.2500 (78.2352)  Acc@5: 100.0000 (98.6514)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.4331  Acc@1: 75.0000 (78.2453)  Acc@5: 100.0000 (98.6517)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8011  Acc@1: 81.2500 (78.2605)  Acc@5: 100.0000 (98.6537)  time: 0.3476  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.4978  Acc@1: 75.0000 (78.2412)  Acc@5: 100.0000 (98.6574)  time: 0.3500  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5486  Acc@1: 75.0000 (78.2426)  Acc@5: 100.0000 (98.6542)  time: 0.3502  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6124  Acc@1: 75.0000 (78.2337)  Acc@5: 100.0000 (98.6528)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5615  Acc@1: 75.0000 (78.2232)  Acc@5: 100.0000 (98.6547)  time: 0.3492  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7912  Acc@1: 75.0000 (78.2263)  Acc@5: 100.0000 (98.6567)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9289  Acc@1: 81.2500 (78.2362)  Acc@5: 100.0000 (98.6519)  time: 0.3505  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0657  Acc@1: 81.2500 (78.2359)  Acc@5: 100.0000 (98.6538)  time: 0.3496  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6150  Acc@1: 81.2500 (78.2390)  Acc@5: 100.0000 (98.6507)  time: 0.3491  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.5184  Acc@1: 81.2500 (78.2454)  Acc@5: 100.0000 (98.6543)  time: 0.3493  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7355  Acc@1: 81.2500 (78.2485)  Acc@5: 100.0000 (98.6529)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.8129  Acc@1: 81.2500 (78.2515)  Acc@5: 100.0000 (98.6498)  time: 0.3502  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6727  Acc@1: 81.2500 (78.2478)  Acc@5: 100.0000 (98.6518)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9428  Acc@1: 81.2500 (78.2633)  Acc@5: 100.0000 (98.6467)  time: 0.3488  data: 0.0017  max mem: 2503
Train: Epoch[2/5] Total time: 0:21:48 (0.3488 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 91309, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 91053, 4: 120000}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 119968}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 120000}, 18: {0: 16, 1: 0, 2: 0, 3: 91197, 4: 32}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 120000}}
Averaged stats: Lr: 0.001875  Loss: -0.9428  Acc@1: 81.2500 (78.2633)  Acc@5: 100.0000 (98.6467)
Train: Epoch[3/5]  [   0/3750]  eta: 0:47:16  Lr: 0.001875  Loss: -1.0206  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7565  data: 0.4045  max mem: 2503
Train: Epoch[3/5]  [  10/3750]  eta: 0:24:12  Lr: 0.001875  Loss: -0.1901  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (97.7273)  time: 0.3883  data: 0.0376  max mem: 2503
Train: Epoch[3/5]  [  20/3750]  eta: 0:23:08  Lr: 0.001875  Loss: -0.5852  Acc@1: 81.2500 (78.5714)  Acc@5: 100.0000 (98.2143)  time: 0.3531  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:47  Lr: 0.001875  Loss: -0.4795  Acc@1: 81.2500 (78.6290)  Acc@5: 100.0000 (98.1855)  time: 0.3564  data: 0.0033  max mem: 2503
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:27  Lr: 0.001875  Loss: -0.4239  Acc@1: 81.2500 (78.0488)  Acc@5: 100.0000 (98.1707)  time: 0.3538  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [  50/3750]  eta: 0:22:12  Lr: 0.001875  Loss: -0.6953  Acc@1: 75.0000 (77.4510)  Acc@5: 100.0000 (98.4069)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [  60/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.8080  Acc@1: 75.0000 (77.1516)  Acc@5: 100.0000 (98.5656)  time: 0.3474  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.7797  Acc@1: 75.0000 (77.2887)  Acc@5: 100.0000 (98.6796)  time: 0.3471  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.5224  Acc@1: 75.0000 (77.3148)  Acc@5: 100.0000 (98.8426)  time: 0.3474  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.8947  Acc@1: 81.2500 (77.7473)  Acc@5: 100.0000 (98.8324)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.7987  Acc@1: 81.2500 (77.8465)  Acc@5: 100.0000 (98.8861)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.3209  Acc@1: 75.0000 (77.7027)  Acc@5: 100.0000 (98.8176)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -0.7686  Acc@1: 75.0000 (77.9442)  Acc@5: 100.0000 (98.9153)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -0.4297  Acc@1: 75.0000 (77.8149)  Acc@5: 100.0000 (98.9504)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.9291  Acc@1: 75.0000 (78.2358)  Acc@5: 100.0000 (98.9805)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.7014  Acc@1: 75.0000 (78.1457)  Acc@5: 100.0000 (99.0066)  time: 0.3476  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.9028  Acc@1: 81.2500 (78.4938)  Acc@5: 100.0000 (98.9907)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 170/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.5318  Acc@1: 81.2500 (78.2164)  Acc@5: 100.0000 (98.9035)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.8026  Acc@1: 75.0000 (78.1423)  Acc@5: 100.0000 (98.8950)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.3704  Acc@1: 81.2500 (78.1741)  Acc@5: 100.0000 (98.8547)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.7464  Acc@1: 75.0000 (78.0162)  Acc@5: 100.0000 (98.9117)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.6217  Acc@1: 75.0000 (77.7844)  Acc@5: 100.0000 (98.8448)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.7629  Acc@1: 81.2500 (77.8563)  Acc@5: 100.0000 (98.7839)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.2707  Acc@1: 81.2500 (77.8680)  Acc@5: 100.0000 (98.7825)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.9869  Acc@1: 75.0000 (77.9824)  Acc@5: 100.0000 (98.7811)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.2994  Acc@1: 81.2500 (77.9382)  Acc@5: 100.0000 (98.7301)  time: 0.3470  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.6348  Acc@1: 81.2500 (77.9454)  Acc@5: 100.0000 (98.7308)  time: 0.3460  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.5210  Acc@1: 81.2500 (77.9982)  Acc@5: 100.0000 (98.6624)  time: 0.3462  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -0.8578  Acc@1: 81.2500 (78.0249)  Acc@5: 100.0000 (98.6210)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.7105  Acc@1: 81.2500 (78.0713)  Acc@5: 100.0000 (98.5610)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.7669  Acc@1: 81.2500 (78.2392)  Acc@5: 100.0000 (98.6088)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.9272  Acc@1: 75.0000 (78.1953)  Acc@5: 100.0000 (98.6334)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 320/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.5443  Acc@1: 75.0000 (78.1347)  Acc@5: 100.0000 (98.6176)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.7107  Acc@1: 75.0000 (78.1533)  Acc@5: 100.0000 (98.6594)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.4931  Acc@1: 75.0000 (78.1158)  Acc@5: 100.0000 (98.6987)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.6031  Acc@1: 75.0000 (78.0983)  Acc@5: 100.0000 (98.7179)  time: 0.3481  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.7060  Acc@1: 81.2500 (78.1856)  Acc@5: 100.0000 (98.7535)  time: 0.3511  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.0907  Acc@1: 81.2500 (78.2513)  Acc@5: 100.0000 (98.7365)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.5723  Acc@1: 75.0000 (78.1168)  Acc@5: 100.0000 (98.7041)  time: 0.3504  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.6533  Acc@1: 75.0000 (78.1650)  Acc@5: 100.0000 (98.7052)  time: 0.3502  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.6012  Acc@1: 81.2500 (78.2887)  Acc@5: 100.0000 (98.7064)  time: 0.3499  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.9931  Acc@1: 81.2500 (78.3607)  Acc@5: 100.0000 (98.7226)  time: 0.3500  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.7066  Acc@1: 81.2500 (78.4145)  Acc@5: 100.0000 (98.7381)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.7766  Acc@1: 81.2500 (78.4948)  Acc@5: 100.0000 (98.7529)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.6852  Acc@1: 81.2500 (78.5147)  Acc@5: 100.0000 (98.7670)  time: 0.3494  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.7830  Acc@1: 75.0000 (78.4368)  Acc@5: 100.0000 (98.7666)  time: 0.3494  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.6932  Acc@1: 75.0000 (78.5249)  Acc@5: 100.0000 (98.7934)  time: 0.3505  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.7538  Acc@1: 81.2500 (78.5563)  Acc@5: 100.0000 (98.7659)  time: 0.3497  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.4821  Acc@1: 81.2500 (78.5213)  Acc@5: 100.0000 (98.7786)  time: 0.3487  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 490/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.3226  Acc@1: 75.0000 (78.4878)  Acc@5: 100.0000 (98.7780)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.5642  Acc@1: 81.2500 (78.5554)  Acc@5: 100.0000 (98.7899)  time: 0.3487  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.5004  Acc@1: 81.2500 (78.5592)  Acc@5: 100.0000 (98.7891)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.4023  Acc@1: 81.2500 (78.6348)  Acc@5: 100.0000 (98.7884)  time: 0.3494  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.5374  Acc@1: 81.2500 (78.6723)  Acc@5: 100.0000 (98.7877)  time: 0.3526  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.7602  Acc@1: 75.0000 (78.6044)  Acc@5: 100.0000 (98.7754)  time: 0.3524  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -0.8791  Acc@1: 75.0000 (78.6298)  Acc@5: 100.0000 (98.7636)  time: 0.3511  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.6234  Acc@1: 75.0000 (78.5316)  Acc@5: 100.0000 (98.7299)  time: 0.3513  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.6059  Acc@1: 81.2500 (78.5792)  Acc@5: 100.0000 (98.6865)  time: 0.3512  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.6744  Acc@1: 81.2500 (78.6145)  Acc@5: 100.0000 (98.7091)  time: 0.3524  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.7387  Acc@1: 75.0000 (78.6062)  Acc@5: 100.0000 (98.6992)  time: 0.3516  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.5572  Acc@1: 75.0000 (78.5566)  Acc@5: 100.0000 (98.7001)  time: 0.3497  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.1015  Acc@1: 81.2500 (78.6109)  Acc@5: 100.0000 (98.6907)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.2075  Acc@1: 75.0000 (78.4622)  Acc@5: 100.0000 (98.6715)  time: 0.3513  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.5406  Acc@1: 75.0000 (78.5261)  Acc@5: 100.0000 (98.6826)  time: 0.3518  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.5890  Acc@1: 81.2500 (78.4711)  Acc@5: 100.0000 (98.6544)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.7474  Acc@1: 75.0000 (78.4082)  Acc@5: 100.0000 (98.6751)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 660/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.7646  Acc@1: 81.2500 (78.4701)  Acc@5: 100.0000 (98.6952)  time: 0.3505  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.7149  Acc@1: 81.2500 (78.5022)  Acc@5: 100.0000 (98.7053)  time: 0.3519  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.3206  Acc@1: 81.2500 (78.5426)  Acc@5: 100.0000 (98.7151)  time: 0.3503  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.3188  Acc@1: 81.2500 (78.6089)  Acc@5: 100.0000 (98.6975)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.7821  Acc@1: 81.2500 (78.6287)  Acc@5: 100.0000 (98.6894)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.6771  Acc@1: 81.2500 (78.6656)  Acc@5: 100.0000 (98.6990)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -1.0708  Acc@1: 81.2500 (78.7361)  Acc@5: 100.0000 (98.6997)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.2190  Acc@1: 81.2500 (78.7449)  Acc@5: 100.0000 (98.6833)  time: 0.3483  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6852  Acc@1: 87.5000 (78.8377)  Acc@5: 100.0000 (98.6673)  time: 0.3491  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.5430  Acc@1: 81.2500 (78.7949)  Acc@5: 100.0000 (98.6518)  time: 0.3538  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.8360  Acc@1: 75.0000 (78.7779)  Acc@5: 100.0000 (98.6613)  time: 0.3546  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.0474  Acc@1: 81.2500 (78.8181)  Acc@5: 100.0000 (98.6381)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.7038  Acc@1: 81.2500 (78.8492)  Acc@5: 100.0000 (98.6556)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.7246  Acc@1: 81.2500 (78.8480)  Acc@5: 100.0000 (98.6647)  time: 0.3479  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.2878  Acc@1: 75.0000 (78.8077)  Acc@5: 100.0000 (98.6501)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.8916  Acc@1: 75.0000 (78.8533)  Acc@5: 100.0000 (98.6514)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.8709  Acc@1: 75.0000 (78.7759)  Acc@5: 100.0000 (98.6526)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 830/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.6797  Acc@1: 81.2500 (78.8282)  Acc@5: 100.0000 (98.6613)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5045  Acc@1: 81.2500 (78.7976)  Acc@5: 100.0000 (98.6697)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.7014  Acc@1: 81.2500 (78.8411)  Acc@5: 100.0000 (98.6854)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.5250  Acc@1: 87.5000 (78.8545)  Acc@5: 100.0000 (98.6861)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.6671  Acc@1: 81.2500 (78.8318)  Acc@5: 100.0000 (98.6940)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.3269  Acc@1: 81.2500 (78.8805)  Acc@5: 100.0000 (98.7089)  time: 0.3470  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.6914  Acc@1: 81.2500 (78.8721)  Acc@5: 100.0000 (98.7163)  time: 0.3462  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.5304  Acc@1: 75.0000 (78.8152)  Acc@5: 100.0000 (98.7236)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.6919  Acc@1: 75.0000 (78.7802)  Acc@5: 100.0000 (98.7239)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.4271  Acc@1: 75.0000 (78.8002)  Acc@5: 100.0000 (98.7242)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.8153  Acc@1: 75.0000 (78.7661)  Acc@5: 100.0000 (98.7044)  time: 0.3458  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.5012  Acc@1: 81.2500 (78.7991)  Acc@5: 100.0000 (98.7181)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.8694  Acc@1: 87.5000 (78.8446)  Acc@5: 100.0000 (98.7119)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.8002  Acc@1: 87.5000 (78.8827)  Acc@5: 100.0000 (98.7188)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.6141  Acc@1: 81.2500 (78.9135)  Acc@5: 100.0000 (98.7255)  time: 0.3478  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.7285  Acc@1: 81.2500 (78.9055)  Acc@5: 100.0000 (98.7322)  time: 0.3487  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.5589  Acc@1: 75.0000 (78.8787)  Acc@5: 100.0000 (98.7197)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1000/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.8193  Acc@1: 75.0000 (78.8649)  Acc@5: 100.0000 (98.7138)  time: 0.3500  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.2214  Acc@1: 81.2500 (78.8947)  Acc@5: 100.0000 (98.7018)  time: 0.3513  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.4376  Acc@1: 81.2500 (78.9055)  Acc@5: 100.0000 (98.7084)  time: 0.3502  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -0.7127  Acc@1: 81.2500 (78.9161)  Acc@5: 100.0000 (98.7148)  time: 0.3501  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.8965  Acc@1: 81.2500 (78.9685)  Acc@5: 100.0000 (98.7092)  time: 0.3509  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.6773  Acc@1: 81.2500 (78.9724)  Acc@5: 100.0000 (98.7215)  time: 0.3506  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.4842  Acc@1: 81.2500 (78.9821)  Acc@5: 100.0000 (98.7217)  time: 0.3501  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.6799  Acc@1: 81.2500 (79.0266)  Acc@5: 100.0000 (98.7278)  time: 0.3508  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.4053  Acc@1: 81.2500 (79.0414)  Acc@5: 100.0000 (98.7222)  time: 0.3511  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.5278  Acc@1: 75.0000 (78.9757)  Acc@5: 100.0000 (98.7110)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.2715  Acc@1: 75.0000 (78.9907)  Acc@5: 100.0000 (98.7057)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.4742  Acc@1: 75.0000 (78.9941)  Acc@5: 100.0000 (98.7117)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.4903  Acc@1: 81.2500 (79.0087)  Acc@5: 100.0000 (98.7177)  time: 0.3521  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.7081  Acc@1: 81.2500 (79.0451)  Acc@5: 100.0000 (98.7179)  time: 0.3510  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.6580  Acc@1: 81.2500 (79.0918)  Acc@5: 100.0000 (98.7237)  time: 0.3531  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.4561  Acc@1: 81.2500 (79.1106)  Acc@5: 100.0000 (98.7185)  time: 0.3518  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.7838  Acc@1: 75.0000 (79.0644)  Acc@5: 100.0000 (98.7134)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1170/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.8021  Acc@1: 68.7500 (79.0297)  Acc@5: 100.0000 (98.7084)  time: 0.3486  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.4224  Acc@1: 81.2500 (79.0432)  Acc@5: 100.0000 (98.7034)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.7605  Acc@1: 81.2500 (79.0302)  Acc@5: 100.0000 (98.6986)  time: 0.3501  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.5125  Acc@1: 81.2500 (79.0591)  Acc@5: 100.0000 (98.6938)  time: 0.3496  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.6460  Acc@1: 81.2500 (79.0566)  Acc@5: 100.0000 (98.6994)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.6105  Acc@1: 81.2500 (79.1001)  Acc@5: 100.0000 (98.7101)  time: 0.3510  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.7360  Acc@1: 81.2500 (79.1227)  Acc@5: 100.0000 (98.7155)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.6640  Acc@1: 81.2500 (79.0894)  Acc@5: 100.0000 (98.7107)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.3943  Acc@1: 75.0000 (79.0767)  Acc@5: 100.0000 (98.7060)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.4009  Acc@1: 75.0000 (79.0593)  Acc@5: 100.0000 (98.7163)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.4806  Acc@1: 75.0000 (79.0618)  Acc@5: 100.0000 (98.7166)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -0.4384  Acc@1: 75.0000 (79.0057)  Acc@5: 100.0000 (98.7022)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.3898  Acc@1: 75.0000 (78.9843)  Acc@5: 100.0000 (98.7074)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.2933  Acc@1: 75.0000 (78.9537)  Acc@5: 100.0000 (98.6981)  time: 0.3490  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.8641  Acc@1: 81.2500 (78.9760)  Acc@5: 100.0000 (98.7033)  time: 0.3504  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.2312  Acc@1: 81.2500 (78.9790)  Acc@5: 100.0000 (98.7036)  time: 0.3502  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.8258  Acc@1: 81.2500 (79.0195)  Acc@5: 100.0000 (98.7087)  time: 0.3489  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1340/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.8530  Acc@1: 87.5000 (79.0501)  Acc@5: 100.0000 (98.6997)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.7156  Acc@1: 81.2500 (79.0063)  Acc@5: 100.0000 (98.7093)  time: 0.3500  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.8763  Acc@1: 75.0000 (79.0136)  Acc@5: 100.0000 (98.7142)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.9176  Acc@1: 81.2500 (79.0345)  Acc@5: 100.0000 (98.7236)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.6963  Acc@1: 81.2500 (79.0188)  Acc@5: 100.0000 (98.7102)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.2846  Acc@1: 81.2500 (79.0169)  Acc@5: 100.0000 (98.7105)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.6832  Acc@1: 81.2500 (79.0105)  Acc@5: 100.0000 (98.6974)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.4998  Acc@1: 75.0000 (79.0087)  Acc@5: 100.0000 (98.7066)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.7260  Acc@1: 75.0000 (78.9937)  Acc@5: 100.0000 (98.7069)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.6443  Acc@1: 75.0000 (78.9963)  Acc@5: 100.0000 (98.7028)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.7948  Acc@1: 81.2500 (79.0423)  Acc@5: 100.0000 (98.7118)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.5508  Acc@1: 81.2500 (79.0231)  Acc@5: 100.0000 (98.7121)  time: 0.3448  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -0.4252  Acc@1: 75.0000 (79.0212)  Acc@5: 100.0000 (98.7124)  time: 0.3450  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.2810  Acc@1: 81.2500 (79.0449)  Acc@5: 100.0000 (98.7084)  time: 0.3456  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.2425  Acc@1: 81.2500 (79.0302)  Acc@5: 100.0000 (98.7086)  time: 0.3453  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.4072  Acc@1: 81.2500 (79.0241)  Acc@5: 100.0000 (98.7131)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.7357  Acc@1: 81.2500 (79.0473)  Acc@5: 100.0000 (98.7175)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1510/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.5329  Acc@1: 81.2500 (79.0577)  Acc@5: 100.0000 (98.7095)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.5113  Acc@1: 75.0000 (79.0311)  Acc@5: 100.0000 (98.6892)  time: 0.3466  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.8982  Acc@1: 75.0000 (79.0211)  Acc@5: 100.0000 (98.6937)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.7177  Acc@1: 81.2500 (79.0355)  Acc@5: 100.0000 (98.6819)  time: 0.3474  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.4561  Acc@1: 87.5000 (79.0458)  Acc@5: 100.0000 (98.6823)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.7455  Acc@1: 81.2500 (79.0239)  Acc@5: 100.0000 (98.6827)  time: 0.3489  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.2334  Acc@1: 75.0000 (78.9744)  Acc@5: 100.0000 (98.6752)  time: 0.3483  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.8816  Acc@1: 75.0000 (78.9690)  Acc@5: 100.0000 (98.6717)  time: 0.3495  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.6016  Acc@1: 81.2500 (78.9794)  Acc@5: 100.0000 (98.6644)  time: 0.3495  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.8326  Acc@1: 81.2500 (78.9897)  Acc@5: 100.0000 (98.6610)  time: 0.3477  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.9769  Acc@1: 81.2500 (79.0154)  Acc@5: 100.0000 (98.6693)  time: 0.3488  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.8034  Acc@1: 81.2500 (79.0291)  Acc@5: 100.0000 (98.6737)  time: 0.3490  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.5313  Acc@1: 81.2500 (79.0428)  Acc@5: 100.0000 (98.6703)  time: 0.3487  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.7667  Acc@1: 81.2500 (79.0524)  Acc@5: 100.0000 (98.6708)  time: 0.3494  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.6397  Acc@1: 81.2500 (79.0544)  Acc@5: 100.0000 (98.6713)  time: 0.3494  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.7141  Acc@1: 75.0000 (79.0563)  Acc@5: 100.0000 (98.6717)  time: 0.3487  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.8722  Acc@1: 81.2500 (79.0769)  Acc@5: 100.0000 (98.6685)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.6743  Acc@1: 81.2500 (79.0675)  Acc@5: 100.0000 (98.6652)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1690/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.5893  Acc@1: 81.2500 (79.0546)  Acc@5: 100.0000 (98.6657)  time: 0.3530  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.6973  Acc@1: 81.2500 (79.0601)  Acc@5: 100.0000 (98.6736)  time: 0.3513  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.9792  Acc@1: 81.2500 (79.0620)  Acc@5: 100.0000 (98.6777)  time: 0.3541  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.4792  Acc@1: 81.2500 (79.0674)  Acc@5: 100.0000 (98.6854)  time: 0.3542  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.8460  Acc@1: 75.0000 (79.0511)  Acc@5: 100.0000 (98.6893)  time: 0.3487  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.8145  Acc@1: 81.2500 (79.0566)  Acc@5: 100.0000 (98.6969)  time: 0.3488  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.6990  Acc@1: 81.2500 (79.0298)  Acc@5: 100.0000 (98.6900)  time: 0.3479  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.3629  Acc@1: 81.2500 (79.0566)  Acc@5: 100.0000 (98.6904)  time: 0.3507  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.8903  Acc@1: 87.5000 (79.0796)  Acc@5: 100.0000 (98.6872)  time: 0.3535  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.9779  Acc@1: 81.2500 (79.0883)  Acc@5: 100.0000 (98.6910)  time: 0.3504  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.6135  Acc@1: 81.2500 (79.1039)  Acc@5: 100.0000 (98.6914)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.7341  Acc@1: 81.2500 (79.1227)  Acc@5: 100.0000 (98.6952)  time: 0.3480  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.7609  Acc@1: 81.2500 (79.1207)  Acc@5: 100.0000 (98.7024)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.7777  Acc@1: 75.0000 (79.1049)  Acc@5: 100.0000 (98.7061)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.9964  Acc@1: 75.0000 (79.1200)  Acc@5: 100.0000 (98.7029)  time: 0.3480  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.5133  Acc@1: 81.2500 (79.0942)  Acc@5: 100.0000 (98.7065)  time: 0.3493  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.6527  Acc@1: 75.0000 (79.0924)  Acc@5: 100.0000 (98.7068)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1860/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.9318  Acc@1: 81.2500 (79.0805)  Acc@5: 100.0000 (98.7037)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.3717  Acc@1: 81.2500 (79.0854)  Acc@5: 100.0000 (98.7106)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:52  Lr: 0.001875  Loss: 0.1464  Acc@1: 81.2500 (79.0670)  Acc@5: 100.0000 (98.7041)  time: 0.3567  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.6339  Acc@1: 75.0000 (79.0653)  Acc@5: 100.0000 (98.7110)  time: 0.3565  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.8650  Acc@1: 75.0000 (79.0637)  Acc@5: 100.0000 (98.7112)  time: 0.3470  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.2988  Acc@1: 75.0000 (79.0587)  Acc@5: 100.0000 (98.7114)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.2425  Acc@1: 81.2500 (79.0701)  Acc@5: 100.0000 (98.7116)  time: 0.3471  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.6710  Acc@1: 81.2500 (79.0588)  Acc@5: 100.0000 (98.6989)  time: 0.3470  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.1978  Acc@1: 75.0000 (79.0540)  Acc@5: 100.0000 (98.7023)  time: 0.3473  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.6470  Acc@1: 75.0000 (79.0492)  Acc@5: 100.0000 (98.7026)  time: 0.3472  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.6191  Acc@1: 81.2500 (79.0572)  Acc@5: 100.0000 (98.7060)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.9821  Acc@1: 81.2500 (79.0747)  Acc@5: 100.0000 (98.7062)  time: 0.3467  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.5006  Acc@1: 81.2500 (79.0888)  Acc@5: 100.0000 (98.7065)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.5854  Acc@1: 75.0000 (79.0777)  Acc@5: 100.0000 (98.7004)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.6051  Acc@1: 75.0000 (79.0636)  Acc@5: 100.0000 (98.7006)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.6662  Acc@1: 81.2500 (79.0807)  Acc@5: 100.0000 (98.7071)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.3288  Acc@1: 81.2500 (79.0636)  Acc@5: 100.0000 (98.7042)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2030/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.8069  Acc@1: 75.0000 (79.0467)  Acc@5: 100.0000 (98.7014)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.7816  Acc@1: 75.0000 (79.0391)  Acc@5: 100.0000 (98.7016)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.5566  Acc@1: 81.2500 (79.0681)  Acc@5: 100.0000 (98.6958)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.7089  Acc@1: 81.2500 (79.0787)  Acc@5: 100.0000 (98.6960)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -0.5380  Acc@1: 81.2500 (79.0922)  Acc@5: 100.0000 (98.6933)  time: 0.3504  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.8925  Acc@1: 81.2500 (79.1086)  Acc@5: 100.0000 (98.6965)  time: 0.3504  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.5673  Acc@1: 81.2500 (79.1099)  Acc@5: 100.0000 (98.6908)  time: 0.3477  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.7921  Acc@1: 81.2500 (79.1111)  Acc@5: 100.0000 (98.6881)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.5867  Acc@1: 81.2500 (79.1213)  Acc@5: 100.0000 (98.6884)  time: 0.3482  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.4915  Acc@1: 81.2500 (79.1313)  Acc@5: 100.0000 (98.6858)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.5471  Acc@1: 81.2500 (79.1442)  Acc@5: 100.0000 (98.6861)  time: 0.3503  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.6975  Acc@1: 81.2500 (79.1453)  Acc@5: 100.0000 (98.6864)  time: 0.3493  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.8706  Acc@1: 81.2500 (79.1463)  Acc@5: 100.0000 (98.6779)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.9124  Acc@1: 75.0000 (79.1532)  Acc@5: 100.0000 (98.6783)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.5213  Acc@1: 75.0000 (79.1484)  Acc@5: 100.0000 (98.6728)  time: 0.3497  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.4447  Acc@1: 81.2500 (79.1466)  Acc@5: 100.0000 (98.6732)  time: 0.3502  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.9560  Acc@1: 81.2500 (79.1562)  Acc@5: 100.0000 (98.6736)  time: 0.3496  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2200/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.9255  Acc@1: 81.2500 (79.1714)  Acc@5: 100.0000 (98.6711)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.6535  Acc@1: 81.2500 (79.1780)  Acc@5: 100.0000 (98.6658)  time: 0.3504  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.7323  Acc@1: 81.2500 (79.1957)  Acc@5: 100.0000 (98.6690)  time: 0.3497  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -0.6167  Acc@1: 81.2500 (79.1881)  Acc@5: 100.0000 (98.6721)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.5300  Acc@1: 81.2500 (79.1946)  Acc@5: 100.0000 (98.6753)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.3527  Acc@1: 75.0000 (79.1704)  Acc@5: 100.0000 (98.6728)  time: 0.3487  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.2098  Acc@1: 68.7500 (79.1492)  Acc@5: 100.0000 (98.6704)  time: 0.3485  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.8260  Acc@1: 75.0000 (79.1336)  Acc@5: 100.0000 (98.6707)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.4021  Acc@1: 75.0000 (79.1155)  Acc@5: 100.0000 (98.6656)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.6142  Acc@1: 81.2500 (79.1248)  Acc@5: 100.0000 (98.6687)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.8024  Acc@1: 81.2500 (79.1259)  Acc@5: 100.0000 (98.6636)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -0.8988  Acc@1: 81.2500 (79.1216)  Acc@5: 100.0000 (98.6640)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.7629  Acc@1: 81.2500 (79.1308)  Acc@5: 100.0000 (98.6644)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.4804  Acc@1: 81.2500 (79.1425)  Acc@5: 100.0000 (98.6701)  time: 0.3524  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.8444  Acc@1: 81.2500 (79.1462)  Acc@5: 100.0000 (98.6731)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:08  Lr: 0.001875  Loss: 0.0136  Acc@1: 81.2500 (79.1472)  Acc@5: 100.0000 (98.6708)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.4180  Acc@1: 81.2500 (79.1534)  Acc@5: 100.0000 (98.6738)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2370/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.5103  Acc@1: 75.0000 (79.1254)  Acc@5: 100.0000 (98.6741)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.4581  Acc@1: 75.0000 (79.1212)  Acc@5: 100.0000 (98.6744)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.7983  Acc@1: 81.2500 (79.1301)  Acc@5: 100.0000 (98.6747)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.7823  Acc@1: 81.2500 (79.1207)  Acc@5: 100.0000 (98.6724)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.3222  Acc@1: 75.0000 (79.1036)  Acc@5: 100.0000 (98.6650)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.8340  Acc@1: 81.2500 (79.1176)  Acc@5: 100.0000 (98.6679)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.8604  Acc@1: 81.2500 (79.1161)  Acc@5: 100.0000 (98.6657)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.6404  Acc@1: 81.2500 (79.1120)  Acc@5: 100.0000 (98.6686)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.7115  Acc@1: 81.2500 (79.0978)  Acc@5: 100.0000 (98.6587)  time: 0.3450  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.6194  Acc@1: 81.2500 (79.1193)  Acc@5: 100.0000 (98.6642)  time: 0.3448  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -1.0318  Acc@1: 81.2500 (79.1102)  Acc@5: 100.0000 (98.6620)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.5645  Acc@1: 81.2500 (79.1238)  Acc@5: 100.0000 (98.6623)  time: 0.3457  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.3244  Acc@1: 81.2500 (79.1223)  Acc@5: 100.0000 (98.6627)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.7785  Acc@1: 75.0000 (79.1134)  Acc@5: 100.0000 (98.6680)  time: 0.3502  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.7616  Acc@1: 87.5000 (79.1567)  Acc@5: 100.0000 (98.6659)  time: 0.3510  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.6074  Acc@1: 81.2500 (79.1551)  Acc@5: 100.0000 (98.6687)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.5101  Acc@1: 75.0000 (79.1510)  Acc@5: 100.0000 (98.6641)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.9441  Acc@1: 75.0000 (79.1421)  Acc@5: 100.0000 (98.6619)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.9917  Acc@1: 75.0000 (79.1356)  Acc@5: 100.0000 (98.6647)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.4059  Acc@1: 81.2500 (79.1585)  Acc@5: 100.0000 (98.6626)  time: 0.3506  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.7517  Acc@1: 87.5000 (79.1788)  Acc@5: 100.0000 (98.6630)  time: 0.3497  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.8603  Acc@1: 81.2500 (79.1723)  Acc@5: 100.0000 (98.6633)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.6924  Acc@1: 81.2500 (79.1876)  Acc@5: 100.0000 (98.6612)  time: 0.3514  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: 0.0994  Acc@1: 81.2500 (79.1739)  Acc@5: 100.0000 (98.6640)  time: 0.3519  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.3395  Acc@1: 81.2500 (79.1842)  Acc@5: 100.0000 (98.6619)  time: 0.3525  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.3599  Acc@1: 81.2500 (79.1802)  Acc@5: 100.0000 (98.6575)  time: 0.3537  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.7721  Acc@1: 75.0000 (79.1857)  Acc@5: 100.0000 (98.6578)  time: 0.3508  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.4033  Acc@1: 81.2500 (79.1888)  Acc@5: 100.0000 (98.6582)  time: 0.3502  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.9239  Acc@1: 75.0000 (79.1753)  Acc@5: 100.0000 (98.6609)  time: 0.3497  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.5747  Acc@1: 75.0000 (79.1714)  Acc@5: 100.0000 (98.6659)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.8709  Acc@1: 75.0000 (79.1487)  Acc@5: 100.0000 (98.6662)  time: 0.3506  data: 0.0025  max mem: 2503
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.9812  Acc@1: 75.0000 (79.1612)  Acc@5: 100.0000 (98.6642)  time: 0.3509  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.6455  Acc@1: 81.2500 (79.1597)  Acc@5: 100.0000 (98.6622)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.3432  Acc@1: 75.0000 (79.1466)  Acc@5: 100.0000 (98.6625)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.8740  Acc@1: 75.0000 (79.1521)  Acc@5: 100.0000 (98.6605)  time: 0.3502  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.4467  Acc@1: 75.0000 (79.1299)  Acc@5: 100.0000 (98.6586)  time: 0.3498  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.6119  Acc@1: 75.0000 (79.1331)  Acc@5: 100.0000 (98.6635)  time: 0.3555  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.6235  Acc@1: 81.2500 (79.1408)  Acc@5: 100.0000 (98.6684)  time: 0.3553  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.3941  Acc@1: 81.2500 (79.1394)  Acc@5: 100.0000 (98.6664)  time: 0.3479  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.8081  Acc@1: 81.2500 (79.1470)  Acc@5: 100.0000 (98.6712)  time: 0.3472  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.4720  Acc@1: 81.2500 (79.1546)  Acc@5: 100.0000 (98.6738)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -1.0191  Acc@1: 81.2500 (79.1487)  Acc@5: 100.0000 (98.6695)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.7465  Acc@1: 75.0000 (79.1607)  Acc@5: 100.0000 (98.6676)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.8133  Acc@1: 81.2500 (79.1615)  Acc@5: 100.0000 (98.6657)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.6255  Acc@1: 75.0000 (79.1555)  Acc@5: 100.0000 (98.6682)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.5040  Acc@1: 81.2500 (79.1652)  Acc@5: 100.0000 (98.6663)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.4650  Acc@1: 81.2500 (79.1836)  Acc@5: 100.0000 (98.6665)  time: 0.3462  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -1.0115  Acc@1: 81.2500 (79.1887)  Acc@5: 100.0000 (98.6668)  time: 0.3460  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.8547  Acc@1: 81.2500 (79.1893)  Acc@5: 100.0000 (98.6693)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.5164  Acc@1: 81.2500 (79.2031)  Acc@5: 100.0000 (98.6718)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.3249  Acc@1: 81.2500 (79.1971)  Acc@5: 100.0000 (98.6721)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.4915  Acc@1: 81.2500 (79.2043)  Acc@5: 100.0000 (98.6745)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.8505  Acc@1: 81.2500 (79.2027)  Acc@5: 100.0000 (98.6704)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.6353  Acc@1: 81.2500 (79.2141)  Acc@5: 100.0000 (98.6707)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.4725  Acc@1: 81.2500 (79.2125)  Acc@5: 100.0000 (98.6731)  time: 0.3453  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.9098  Acc@1: 81.2500 (79.2152)  Acc@5: 100.0000 (98.6691)  time: 0.3453  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.7969  Acc@1: 81.2500 (79.2285)  Acc@5: 100.0000 (98.6673)  time: 0.3462  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.1123  Acc@1: 81.2500 (79.2163)  Acc@5: 100.0000 (98.6718)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.5630  Acc@1: 81.2500 (79.2231)  Acc@5: 100.0000 (98.6763)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.5114  Acc@1: 75.0000 (79.2025)  Acc@5: 100.0000 (98.6787)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.1903  Acc@1: 75.0000 (79.1863)  Acc@5: 100.0000 (98.6747)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.8334  Acc@1: 87.5000 (79.2268)  Acc@5: 100.0000 (98.6770)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.3497  Acc@1: 87.5000 (79.2294)  Acc@5: 100.0000 (98.6752)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.8800  Acc@1: 81.2500 (79.2298)  Acc@5: 100.0000 (98.6713)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.7973  Acc@1: 81.2500 (79.2282)  Acc@5: 100.0000 (98.6736)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.1388  Acc@1: 81.2500 (79.2101)  Acc@5: 100.0000 (98.6739)  time: 0.3491  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.8387  Acc@1: 81.2500 (79.2045)  Acc@5: 100.0000 (98.6741)  time: 0.3506  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.6659  Acc@1: 75.0000 (79.1906)  Acc@5: 100.0000 (98.6723)  time: 0.3518  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.4263  Acc@1: 75.0000 (79.1872)  Acc@5: 100.0000 (98.6705)  time: 0.3501  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -1.0111  Acc@1: 81.2500 (79.1898)  Acc@5: 100.0000 (98.6728)  time: 0.3493  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.5178  Acc@1: 81.2500 (79.1924)  Acc@5: 100.0000 (98.6690)  time: 0.3484  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.8147  Acc@1: 81.2500 (79.1971)  Acc@5: 100.0000 (98.6693)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.5264  Acc@1: 81.2500 (79.1997)  Acc@5: 100.0000 (98.6695)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.8356  Acc@1: 81.2500 (79.2063)  Acc@5: 100.0000 (98.6718)  time: 0.3472  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.5471  Acc@1: 75.0000 (79.2068)  Acc@5: 100.0000 (98.6761)  time: 0.3510  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.6760  Acc@1: 75.0000 (79.2154)  Acc@5: 100.0000 (98.6803)  time: 0.3526  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.5796  Acc@1: 75.0000 (79.2099)  Acc@5: 100.0000 (98.6825)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.5510  Acc@1: 81.2500 (79.2065)  Acc@5: 100.0000 (98.6728)  time: 0.3504  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.9305  Acc@1: 81.2500 (79.2070)  Acc@5: 100.0000 (98.6770)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.8023  Acc@1: 75.0000 (79.2016)  Acc@5: 100.0000 (98.6792)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4177  Acc@1: 75.0000 (79.1962)  Acc@5: 100.0000 (98.6834)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.8898  Acc@1: 75.0000 (79.1968)  Acc@5: 100.0000 (98.6797)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.3830  Acc@1: 75.0000 (79.1895)  Acc@5: 100.0000 (98.6799)  time: 0.3495  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.3044  Acc@1: 75.0000 (79.1803)  Acc@5: 100.0000 (98.6762)  time: 0.3489  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.9922  Acc@1: 75.0000 (79.1809)  Acc@5: 100.0000 (98.6764)  time: 0.3497  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.7260  Acc@1: 81.2500 (79.1912)  Acc@5: 100.0000 (98.6767)  time: 0.3512  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.4204  Acc@1: 81.2500 (79.1841)  Acc@5: 100.0000 (98.6769)  time: 0.3497  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.8931  Acc@1: 75.0000 (79.1847)  Acc@5: 100.0000 (98.6771)  time: 0.3493  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.8017  Acc@1: 81.2500 (79.1929)  Acc@5: 100.0000 (98.6773)  time: 0.3492  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.7245  Acc@1: 81.2500 (79.2050)  Acc@5: 100.0000 (98.6795)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.5296  Acc@1: 81.2500 (79.2093)  Acc@5: 100.0000 (98.6816)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.7754  Acc@1: 75.0000 (79.1927)  Acc@5: 100.0000 (98.6799)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: 0.0722  Acc@1: 75.0000 (79.1743)  Acc@5: 100.0000 (98.6763)  time: 0.3480  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.6276  Acc@1: 75.0000 (79.1522)  Acc@5: 100.0000 (98.6746)  time: 0.3479  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.6048  Acc@1: 75.0000 (79.1641)  Acc@5: 100.0000 (98.6749)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4699  Acc@1: 81.2500 (79.1742)  Acc@5: 100.0000 (98.6751)  time: 0.3495  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.7757  Acc@1: 81.2500 (79.1692)  Acc@5: 100.0000 (98.6772)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.4670  Acc@1: 81.2500 (79.1791)  Acc@5: 100.0000 (98.6812)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.5759  Acc@1: 81.2500 (79.1816)  Acc@5: 100.0000 (98.6851)  time: 0.3468  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.6970  Acc@1: 81.2500 (79.1710)  Acc@5: 100.0000 (98.6890)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.3530  Acc@1: 75.0000 (79.1623)  Acc@5: 100.0000 (98.6855)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.5184  Acc@1: 75.0000 (79.1667)  Acc@5: 100.0000 (98.6875)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6331  Acc@1: 75.0000 (79.1710)  Acc@5: 100.0000 (98.6877)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.6317  Acc@1: 81.2500 (79.1624)  Acc@5: 100.0000 (98.6897)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.8172  Acc@1: 81.2500 (79.1740)  Acc@5: 100.0000 (98.6917)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.5158  Acc@1: 81.2500 (79.1654)  Acc@5: 100.0000 (98.6956)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.6605  Acc@1: 81.2500 (79.1697)  Acc@5: 100.0000 (98.6939)  time: 0.3460  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9191  Acc@1: 81.2500 (79.1594)  Acc@5: 100.0000 (98.6959)  time: 0.3455  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8197  Acc@1: 81.2500 (79.1691)  Acc@5: 100.0000 (98.6960)  time: 0.3450  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6407  Acc@1: 81.2500 (79.1661)  Acc@5: 100.0000 (98.6908)  time: 0.3464  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6456  Acc@1: 81.2500 (79.1811)  Acc@5: 100.0000 (98.6945)  time: 0.3489  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.4343  Acc@1: 81.2500 (79.1888)  Acc@5: 100.0000 (98.6929)  time: 0.3502  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3376  Acc@1: 81.2500 (79.1840)  Acc@5: 100.0000 (98.6913)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0350  Acc@1: 81.2500 (79.1863)  Acc@5: 100.0000 (98.6914)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.9151  Acc@1: 81.2500 (79.1833)  Acc@5: 100.0000 (98.6952)  time: 0.3482  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8035  Acc@1: 81.2500 (79.1838)  Acc@5: 100.0000 (98.6936)  time: 0.3482  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.7277  Acc@1: 75.0000 (79.1649)  Acc@5: 100.0000 (98.6902)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.6299  Acc@1: 75.0000 (79.1637)  Acc@5: 100.0000 (98.6886)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.9181  Acc@1: 81.2500 (79.1643)  Acc@5: 100.0000 (98.6905)  time: 0.3484  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.9587  Acc@1: 81.2500 (79.1632)  Acc@5: 100.0000 (98.6889)  time: 0.3487  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.6054  Acc@1: 81.2500 (79.1795)  Acc@5: 100.0000 (98.6908)  time: 0.3482  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.9463  Acc@1: 87.5000 (79.1870)  Acc@5: 100.0000 (98.6928)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.8951  Acc@1: 81.2500 (79.1858)  Acc@5: 100.0000 (98.6947)  time: 0.3499  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4148  Acc@1: 81.2500 (79.1950)  Acc@5: 100.0000 (98.6931)  time: 0.3518  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.2944  Acc@1: 81.2500 (79.1921)  Acc@5: 100.0000 (98.6898)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8520  Acc@1: 81.2500 (79.2012)  Acc@5: 100.0000 (98.6899)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.6166  Acc@1: 81.2500 (79.2120)  Acc@5: 100.0000 (98.6918)  time: 0.3518  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5131  Acc@1: 81.2500 (79.2210)  Acc@5: 100.0000 (98.6937)  time: 0.3491  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6578  Acc@1: 75.0000 (79.2249)  Acc@5: 100.0000 (98.6939)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.4435  Acc@1: 75.0000 (79.2304)  Acc@5: 100.0000 (98.6940)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3341  Acc@1: 81.2500 (79.2274)  Acc@5: 100.0000 (98.6942)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7407  Acc@1: 81.2500 (79.2312)  Acc@5: 100.0000 (98.6977)  time: 0.3489  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8164  Acc@1: 81.2500 (79.2282)  Acc@5: 100.0000 (98.6945)  time: 0.3486  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5925  Acc@1: 75.0000 (79.2201)  Acc@5: 100.0000 (98.6980)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.4948  Acc@1: 75.0000 (79.2239)  Acc@5: 100.0000 (98.6998)  time: 0.3476  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9975  Acc@1: 75.0000 (79.2176)  Acc@5: 100.0000 (98.6983)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.8842  Acc@1: 75.0000 (79.2231)  Acc@5: 100.0000 (98.6984)  time: 0.3533  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.1479  Acc@1: 75.0000 (79.2051)  Acc@5: 100.0000 (98.6985)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5021  Acc@1: 81.2500 (79.2067)  Acc@5: 100.0000 (98.6967)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[3/5] Total time: 0:21:48 (0.3490 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 91309, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 91053, 4: 180000}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 179968}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 180000}, 18: {0: 16, 1: 0, 2: 0, 3: 91197, 4: 32}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 180000}}
Averaged stats: Lr: 0.001875  Loss: -0.5021  Acc@1: 81.2500 (79.2067)  Acc@5: 100.0000 (98.6967)
Train: Epoch[4/5]  [   0/3750]  eta: 0:42:54  Lr: 0.001875  Loss: -0.4747  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6866  data: 0.3362  max mem: 2503
Train: Epoch[4/5]  [  10/3750]  eta: 0:23:36  Lr: 0.001875  Loss: -0.5409  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (97.7273)  time: 0.3788  data: 0.0309  max mem: 2503
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:37  Lr: 0.001875  Loss: -0.9119  Acc@1: 75.0000 (78.5714)  Acc@5: 100.0000 (98.8095)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:13  Lr: 0.001875  Loss: -0.1597  Acc@1: 75.0000 (78.2258)  Acc@5: 100.0000 (98.3871)  time: 0.3474  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [  40/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -0.9744  Acc@1: 75.0000 (79.2683)  Acc@5: 100.0000 (98.1707)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  50/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -0.4112  Acc@1: 75.0000 (79.1667)  Acc@5: 100.0000 (98.4069)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:40  Lr: 0.001875  Loss: -0.5920  Acc@1: 75.0000 (78.5861)  Acc@5: 100.0000 (98.5656)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -0.5554  Acc@1: 75.0000 (78.1690)  Acc@5: 100.0000 (98.4155)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.5507  Acc@1: 75.0000 (78.0093)  Acc@5: 100.0000 (98.4568)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.9275  Acc@1: 81.2500 (77.8159)  Acc@5: 100.0000 (98.5577)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.8320  Acc@1: 81.2500 (78.2797)  Acc@5: 100.0000 (98.6386)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.5372  Acc@1: 81.2500 (78.7725)  Acc@5: 100.0000 (98.5923)  time: 0.3450  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -0.1012  Acc@1: 81.2500 (78.2025)  Acc@5: 100.0000 (98.5537)  time: 0.3458  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.7293  Acc@1: 81.2500 (78.5305)  Acc@5: 100.0000 (98.5687)  time: 0.3464  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [ 140/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.6348  Acc@1: 81.2500 (78.6348)  Acc@5: 100.0000 (98.6259)  time: 0.3479  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 150/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.5335  Acc@1: 75.0000 (78.2699)  Acc@5: 100.0000 (98.5099)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 160/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.5259  Acc@1: 75.0000 (78.1444)  Acc@5: 100.0000 (98.4860)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.5110  Acc@1: 75.0000 (78.4722)  Acc@5: 100.0000 (98.5015)  time: 0.3500  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.7414  Acc@1: 81.2500 (78.7638)  Acc@5: 100.0000 (98.4807)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.5196  Acc@1: 81.2500 (78.7304)  Acc@5: 100.0000 (98.4293)  time: 0.3489  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.2302  Acc@1: 75.0000 (78.6692)  Acc@5: 100.0000 (98.5075)  time: 0.3497  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -0.9838  Acc@1: 81.2500 (78.7915)  Acc@5: 100.0000 (98.5782)  time: 0.3480  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:31  Lr: 0.001875  Loss: 0.2245  Acc@1: 81.2500 (78.8179)  Acc@5: 100.0000 (98.5294)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.7661  Acc@1: 81.2500 (78.8420)  Acc@5: 100.0000 (98.5660)  time: 0.3491  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.6910  Acc@1: 81.2500 (78.9160)  Acc@5: 100.0000 (98.5996)  time: 0.3523  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.8400  Acc@1: 75.0000 (78.9094)  Acc@5: 100.0000 (98.5807)  time: 0.3524  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.0251  Acc@1: 75.0000 (78.8793)  Acc@5: 100.0000 (98.5393)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.4542  Acc@1: 81.2500 (79.0821)  Acc@5: 100.0000 (98.5470)  time: 0.3531  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.7743  Acc@1: 81.2500 (79.0258)  Acc@5: 100.0000 (98.5543)  time: 0.3531  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.6490  Acc@1: 81.2500 (78.9734)  Acc@5: 100.0000 (98.5825)  time: 0.3484  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:05  Lr: 0.001875  Loss: 0.2886  Acc@1: 81.2500 (78.8414)  Acc@5: 100.0000 (98.5465)  time: 0.3496  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.7267  Acc@1: 81.2500 (78.9590)  Acc@5: 100.0000 (98.5129)  time: 0.3494  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [ 320/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.6718  Acc@1: 81.2500 (79.0498)  Acc@5: 100.0000 (98.5397)  time: 0.3488  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.4636  Acc@1: 75.0000 (78.9653)  Acc@5: 100.0000 (98.5650)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.4918  Acc@1: 81.2500 (79.1606)  Acc@5: 100.0000 (98.6070)  time: 0.3484  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.6570  Acc@1: 81.2500 (79.2023)  Acc@5: 100.0000 (98.6289)  time: 0.3484  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.7916  Acc@1: 81.2500 (79.2417)  Acc@5: 100.0000 (98.6323)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.5848  Acc@1: 81.2500 (79.3801)  Acc@5: 100.0000 (98.6523)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.5936  Acc@1: 81.2500 (79.3143)  Acc@5: 100.0000 (98.6220)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.9261  Acc@1: 75.0000 (79.2359)  Acc@5: 100.0000 (98.6573)  time: 0.3489  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.5422  Acc@1: 75.0000 (79.1615)  Acc@5: 100.0000 (98.6908)  time: 0.3581  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:27  Lr: 0.001875  Loss: 0.1602  Acc@1: 81.2500 (79.2427)  Acc@5: 100.0000 (98.6922)  time: 0.3575  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.9050  Acc@1: 81.2500 (79.3498)  Acc@5: 100.0000 (98.7233)  time: 0.3475  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.5609  Acc@1: 81.2500 (79.4809)  Acc@5: 100.0000 (98.7094)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.6978  Acc@1: 81.2500 (79.4926)  Acc@5: 100.0000 (98.7387)  time: 0.3476  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.7594  Acc@1: 81.2500 (79.4762)  Acc@5: 100.0000 (98.7666)  time: 0.3476  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.6200  Acc@1: 81.2500 (79.4469)  Acc@5: 100.0000 (98.7663)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.6740  Acc@1: 81.2500 (79.4851)  Acc@5: 100.0000 (98.7659)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.1684  Acc@1: 81.2500 (79.6258)  Acc@5: 100.0000 (98.7916)  time: 0.3456  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 490/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.8458  Acc@1: 81.2500 (79.6207)  Acc@5: 100.0000 (98.7907)  time: 0.3456  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.4572  Acc@1: 75.0000 (79.5659)  Acc@5: 100.0000 (98.7899)  time: 0.3455  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.4938  Acc@1: 75.0000 (79.4887)  Acc@5: 100.0000 (98.7524)  time: 0.3462  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.7514  Acc@1: 75.0000 (79.4506)  Acc@5: 100.0000 (98.7524)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.7942  Acc@1: 81.2500 (79.4727)  Acc@5: 100.0000 (98.7524)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.2642  Acc@1: 81.2500 (79.4478)  Acc@5: 100.0000 (98.7523)  time: 0.3504  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.0607  Acc@1: 81.2500 (79.4238)  Acc@5: 100.0000 (98.7636)  time: 0.3508  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.1178  Acc@1: 75.0000 (79.4118)  Acc@5: 100.0000 (98.7299)  time: 0.3540  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.7722  Acc@1: 81.2500 (79.4877)  Acc@5: 100.0000 (98.7522)  time: 0.3533  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.3949  Acc@1: 81.2500 (79.4105)  Acc@5: 100.0000 (98.7629)  time: 0.3481  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.6732  Acc@1: 81.2500 (79.4734)  Acc@5: 100.0000 (98.7521)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.6855  Acc@1: 87.5000 (79.5757)  Acc@5: 100.0000 (98.7521)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.5163  Acc@1: 81.2500 (79.5827)  Acc@5: 100.0000 (98.7520)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.9339  Acc@1: 81.2500 (79.6598)  Acc@5: 100.0000 (98.7621)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.6677  Acc@1: 81.2500 (79.6454)  Acc@5: 100.0000 (98.7619)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.4245  Acc@1: 81.2500 (79.6119)  Acc@5: 100.0000 (98.7617)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.8503  Acc@1: 75.0000 (79.6275)  Acc@5: 100.0000 (98.7423)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 660/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.9599  Acc@1: 81.2500 (79.6993)  Acc@5: 100.0000 (98.7613)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.7279  Acc@1: 81.2500 (79.7038)  Acc@5: 100.0000 (98.7519)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.7044  Acc@1: 81.2500 (79.7632)  Acc@5: 100.0000 (98.7610)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.6911  Acc@1: 87.5000 (79.8752)  Acc@5: 100.0000 (98.7789)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.6295  Acc@1: 87.5000 (79.8948)  Acc@5: 100.0000 (98.7964)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.8260  Acc@1: 81.2500 (79.8875)  Acc@5: 100.0000 (98.7957)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.6592  Acc@1: 81.2500 (79.8804)  Acc@5: 100.0000 (98.8037)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.6128  Acc@1: 81.2500 (79.9162)  Acc@5: 100.0000 (98.8116)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.9507  Acc@1: 81.2500 (79.9173)  Acc@5: 100.0000 (98.7770)  time: 0.3497  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.5788  Acc@1: 81.2500 (79.9184)  Acc@5: 100.0000 (98.7850)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.6681  Acc@1: 81.2500 (79.9195)  Acc@5: 100.0000 (98.8009)  time: 0.3487  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6388  Acc@1: 81.2500 (80.0178)  Acc@5: 100.0000 (98.8165)  time: 0.3486  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.5497  Acc@1: 81.2500 (80.0496)  Acc@5: 100.0000 (98.8316)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.3246  Acc@1: 81.2500 (79.9858)  Acc@5: 100.0000 (98.8306)  time: 0.3526  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.7217  Acc@1: 81.2500 (80.0874)  Acc@5: 100.0000 (98.8374)  time: 0.3513  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.3555  Acc@1: 81.2500 (80.0401)  Acc@5: 100.0000 (98.8286)  time: 0.3518  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.2723  Acc@1: 81.2500 (80.0167)  Acc@5: 100.0000 (98.7896)  time: 0.3512  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 830/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.5865  Acc@1: 81.2500 (79.9865)  Acc@5: 100.0000 (98.7816)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.4857  Acc@1: 81.2500 (80.0163)  Acc@5: 100.0000 (98.7812)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.1951  Acc@1: 81.2500 (79.9941)  Acc@5: 100.0000 (98.7955)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -0.6765  Acc@1: 81.2500 (80.0232)  Acc@5: 100.0000 (98.7950)  time: 0.3482  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.9314  Acc@1: 81.2500 (80.0588)  Acc@5: 100.0000 (98.8017)  time: 0.3487  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -0.6151  Acc@1: 87.5000 (80.1149)  Acc@5: 100.0000 (98.8011)  time: 0.3483  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.7654  Acc@1: 81.2500 (80.0856)  Acc@5: 100.0000 (98.8145)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -0.3521  Acc@1: 75.0000 (80.0291)  Acc@5: 100.0000 (98.8069)  time: 0.3513  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.5884  Acc@1: 75.0000 (80.0357)  Acc@5: 100.0000 (98.8200)  time: 0.3513  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -0.7541  Acc@1: 81.2500 (79.9946)  Acc@5: 100.0000 (98.8192)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.6868  Acc@1: 81.2500 (80.0081)  Acc@5: 100.0000 (98.8319)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.4827  Acc@1: 75.0000 (79.9349)  Acc@5: 100.0000 (98.8310)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.7624  Acc@1: 75.0000 (79.9750)  Acc@5: 100.0000 (98.8236)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.6355  Acc@1: 75.0000 (79.8842)  Acc@5: 100.0000 (98.8098)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.1599  Acc@1: 75.0000 (79.9112)  Acc@5: 100.0000 (98.8028)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.9809  Acc@1: 81.2500 (79.8675)  Acc@5: 100.0000 (98.8022)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.4955  Acc@1: 75.0000 (79.8562)  Acc@5: 100.0000 (98.7954)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1000/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.8034  Acc@1: 81.2500 (79.8452)  Acc@5: 100.0000 (98.8012)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.7620  Acc@1: 81.2500 (79.8652)  Acc@5: 100.0000 (98.8069)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.6478  Acc@1: 81.2500 (79.8849)  Acc@5: 100.0000 (98.8002)  time: 0.3457  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.5530  Acc@1: 81.2500 (79.9285)  Acc@5: 100.0000 (98.8058)  time: 0.3455  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -0.8873  Acc@1: 87.5000 (80.0012)  Acc@5: 100.0000 (98.8052)  time: 0.3466  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.4552  Acc@1: 81.2500 (79.9893)  Acc@5: 100.0000 (98.7988)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.7356  Acc@1: 81.2500 (80.0012)  Acc@5: 100.0000 (98.7983)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.7419  Acc@1: 81.2500 (79.9837)  Acc@5: 100.0000 (98.7979)  time: 0.3497  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.6167  Acc@1: 81.2500 (80.0185)  Acc@5: 100.0000 (98.7974)  time: 0.3501  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.7233  Acc@1: 81.2500 (80.0355)  Acc@5: 100.0000 (98.7970)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.6990  Acc@1: 75.0000 (80.0238)  Acc@5: 100.0000 (98.8022)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.4487  Acc@1: 81.2500 (80.0518)  Acc@5: 100.0000 (98.8074)  time: 0.3486  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.2275  Acc@1: 81.2500 (80.0234)  Acc@5: 100.0000 (98.7790)  time: 0.3490  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -0.7552  Acc@1: 75.0000 (79.9679)  Acc@5: 100.0000 (98.7732)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.6474  Acc@1: 81.2500 (79.9682)  Acc@5: 100.0000 (98.7785)  time: 0.3481  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.8990  Acc@1: 75.0000 (79.9305)  Acc@5: 100.0000 (98.7674)  time: 0.3485  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -0.9867  Acc@1: 75.0000 (79.9042)  Acc@5: 100.0000 (98.7618)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1170/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.8226  Acc@1: 81.2500 (79.9157)  Acc@5: 100.0000 (98.7617)  time: 0.3526  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.5257  Acc@1: 81.2500 (79.8846)  Acc@5: 100.0000 (98.7616)  time: 0.3505  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.7898  Acc@1: 75.0000 (79.8541)  Acc@5: 100.0000 (98.7668)  time: 0.3519  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.5289  Acc@1: 75.0000 (79.8449)  Acc@5: 100.0000 (98.7667)  time: 0.3525  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.6220  Acc@1: 81.2500 (79.8410)  Acc@5: 100.0000 (98.7717)  time: 0.3488  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.6982  Acc@1: 81.2500 (79.8423)  Acc@5: 100.0000 (98.7715)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.5805  Acc@1: 81.2500 (79.8589)  Acc@5: 100.0000 (98.7713)  time: 0.3500  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.5247  Acc@1: 81.2500 (79.8550)  Acc@5: 100.0000 (98.7712)  time: 0.3497  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.5616  Acc@1: 81.2500 (79.8611)  Acc@5: 100.0000 (98.7710)  time: 0.3486  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.8509  Acc@1: 81.2500 (79.8870)  Acc@5: 100.0000 (98.7758)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.3235  Acc@1: 87.5000 (79.9223)  Acc@5: 100.0000 (98.7657)  time: 0.3485  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.8642  Acc@1: 81.2500 (79.9278)  Acc@5: 100.0000 (98.7607)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.8251  Acc@1: 81.2500 (79.9526)  Acc@5: 100.0000 (98.7655)  time: 0.3492  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.3647  Acc@1: 81.2500 (79.9481)  Acc@5: 100.0000 (98.7606)  time: 0.3486  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.4077  Acc@1: 81.2500 (79.9390)  Acc@5: 100.0000 (98.7557)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.9798  Acc@1: 81.2500 (79.9773)  Acc@5: 100.0000 (98.7557)  time: 0.3531  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.5326  Acc@1: 87.5000 (80.0056)  Acc@5: 100.0000 (98.7509)  time: 0.3518  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1340/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.8669  Acc@1: 87.5000 (80.0242)  Acc@5: 100.0000 (98.7509)  time: 0.3470  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.6100  Acc@1: 75.0000 (79.9500)  Acc@5: 100.0000 (98.7556)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.8923  Acc@1: 75.0000 (79.9366)  Acc@5: 100.0000 (98.7509)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.6521  Acc@1: 81.2500 (79.9599)  Acc@5: 100.0000 (98.7509)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.4705  Acc@1: 75.0000 (79.9194)  Acc@5: 100.0000 (98.7328)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6467  Acc@1: 81.2500 (79.9380)  Acc@5: 100.0000 (98.7329)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.6431  Acc@1: 81.2500 (79.9295)  Acc@5: 100.0000 (98.7330)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.7248  Acc@1: 81.2500 (79.9433)  Acc@5: 100.0000 (98.7376)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.6053  Acc@1: 81.2500 (79.9657)  Acc@5: 100.0000 (98.7377)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.6187  Acc@1: 81.2500 (79.9790)  Acc@5: 100.0000 (98.7465)  time: 0.3459  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4886  Acc@1: 81.2500 (79.9705)  Acc@5: 100.0000 (98.7465)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.8971  Acc@1: 81.2500 (79.9578)  Acc@5: 100.0000 (98.7379)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.6118  Acc@1: 81.2500 (79.9538)  Acc@5: 100.0000 (98.7380)  time: 0.3508  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.7363  Acc@1: 81.2500 (79.9541)  Acc@5: 100.0000 (98.7424)  time: 0.3531  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.6884  Acc@1: 81.2500 (79.9671)  Acc@5: 100.0000 (98.7508)  time: 0.3521  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.6994  Acc@1: 81.2500 (79.9589)  Acc@5: 100.0000 (98.7550)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.7369  Acc@1: 75.0000 (79.9425)  Acc@5: 100.0000 (98.7508)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.5943  Acc@1: 75.0000 (79.9471)  Acc@5: 100.0000 (98.7550)  time: 0.3519  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.5853  Acc@1: 81.2500 (79.9474)  Acc@5: 100.0000 (98.7508)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.8013  Acc@1: 81.2500 (79.9804)  Acc@5: 100.0000 (98.7549)  time: 0.3463  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.4351  Acc@1: 81.2500 (79.9765)  Acc@5: 100.0000 (98.7508)  time: 0.3453  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.6488  Acc@1: 81.2500 (79.9847)  Acc@5: 100.0000 (98.7508)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.8677  Acc@1: 75.0000 (79.9528)  Acc@5: 100.0000 (98.7508)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.6335  Acc@1: 75.0000 (79.9411)  Acc@5: 100.0000 (98.7468)  time: 0.3454  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.2755  Acc@1: 81.2500 (79.9494)  Acc@5: 100.0000 (98.7429)  time: 0.3492  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.9465  Acc@1: 81.2500 (79.9340)  Acc@5: 100.0000 (98.7311)  time: 0.3509  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -0.3239  Acc@1: 75.0000 (79.9344)  Acc@5: 100.0000 (98.7196)  time: 0.3488  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.5911  Acc@1: 75.0000 (79.9154)  Acc@5: 100.0000 (98.7236)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -0.4593  Acc@1: 75.0000 (79.9198)  Acc@5: 100.0000 (98.7238)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.5546  Acc@1: 81.2500 (79.9088)  Acc@5: 100.0000 (98.7239)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:15  Lr: 0.001875  Loss: -0.8962  Acc@1: 81.2500 (79.9208)  Acc@5: 100.0000 (98.7279)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.6895  Acc@1: 81.2500 (79.9326)  Acc@5: 100.0000 (98.7167)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -0.5461  Acc@1: 75.0000 (79.9067)  Acc@5: 100.0000 (98.7169)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.7933  Acc@1: 75.0000 (79.9147)  Acc@5: 100.0000 (98.7246)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1680/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.9265  Acc@1: 81.2500 (79.9301)  Acc@5: 100.0000 (98.7247)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.6986  Acc@1: 81.2500 (79.9342)  Acc@5: 100.0000 (98.7175)  time: 0.3452  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.8910  Acc@1: 81.2500 (79.9456)  Acc@5: 100.0000 (98.7177)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.4661  Acc@1: 81.2500 (79.9459)  Acc@5: 100.0000 (98.7252)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.2283  Acc@1: 81.2500 (79.9245)  Acc@5: 100.0000 (98.7253)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.7184  Acc@1: 75.0000 (79.9213)  Acc@5: 100.0000 (98.7218)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.8357  Acc@1: 87.5000 (79.9576)  Acc@5: 100.0000 (98.7292)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -0.4944  Acc@1: 87.5000 (79.9864)  Acc@5: 100.0000 (98.7364)  time: 0.3505  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.5457  Acc@1: 87.5000 (79.9972)  Acc@5: 100.0000 (98.7365)  time: 0.3490  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.5733  Acc@1: 81.2500 (79.9901)  Acc@5: 100.0000 (98.7366)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.8009  Acc@1: 81.2500 (80.0147)  Acc@5: 100.0000 (98.7367)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.6907  Acc@1: 81.2500 (80.0251)  Acc@5: 100.0000 (98.7367)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.5308  Acc@1: 81.2500 (80.0111)  Acc@5: 100.0000 (98.7403)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.5678  Acc@1: 81.2500 (80.0007)  Acc@5: 100.0000 (98.7369)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.7960  Acc@1: 81.2500 (80.0144)  Acc@5: 100.0000 (98.7370)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -0.9733  Acc@1: 81.2500 (80.0246)  Acc@5: 100.0000 (98.7439)  time: 0.3493  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -0.8713  Acc@1: 81.2500 (80.0177)  Acc@5: 100.0000 (98.7507)  time: 0.3488  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.4709  Acc@1: 75.0000 (79.9973)  Acc@5: 100.0000 (98.7507)  time: 0.3502  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -0.3469  Acc@1: 75.0000 (79.9940)  Acc@5: 100.0000 (98.7473)  time: 0.3512  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.8746  Acc@1: 81.2500 (79.9840)  Acc@5: 100.0000 (98.7373)  time: 0.3516  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.7327  Acc@1: 75.0000 (79.9575)  Acc@5: 100.0000 (98.7374)  time: 0.3521  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.3605  Acc@1: 68.7500 (79.9114)  Acc@5: 100.0000 (98.7441)  time: 0.3487  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.6688  Acc@1: 81.2500 (79.9283)  Acc@5: 100.0000 (98.7441)  time: 0.3471  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7858  Acc@1: 81.2500 (79.9320)  Acc@5: 100.0000 (98.7507)  time: 0.3474  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.1493  Acc@1: 75.0000 (79.8998)  Acc@5: 100.0000 (98.7474)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -0.7697  Acc@1: 75.0000 (79.8841)  Acc@5: 100.0000 (98.7377)  time: 0.3489  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.6493  Acc@1: 75.0000 (79.8783)  Acc@5: 100.0000 (98.7410)  time: 0.3518  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -0.0762  Acc@1: 81.2500 (79.8853)  Acc@5: 100.0000 (98.7442)  time: 0.3511  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.8282  Acc@1: 81.2500 (79.9018)  Acc@5: 100.0000 (98.7475)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.3039  Acc@1: 75.0000 (79.8865)  Acc@5: 100.0000 (98.7443)  time: 0.3487  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.7567  Acc@1: 81.2500 (79.9060)  Acc@5: 100.0000 (98.7475)  time: 0.3487  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.2716  Acc@1: 81.2500 (79.9127)  Acc@5: 100.0000 (98.7506)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.8943  Acc@1: 87.5000 (79.9257)  Acc@5: 100.0000 (98.7537)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.6565  Acc@1: 75.0000 (79.9012)  Acc@5: 100.0000 (98.7475)  time: 0.3536  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.5895  Acc@1: 75.0000 (79.9048)  Acc@5: 100.0000 (98.7475)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2030/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.7230  Acc@1: 81.2500 (79.9145)  Acc@5: 100.0000 (98.7506)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.6999  Acc@1: 81.2500 (79.9394)  Acc@5: 100.0000 (98.7506)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.8904  Acc@1: 81.2500 (79.9092)  Acc@5: 100.0000 (98.7537)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.2950  Acc@1: 75.0000 (79.9127)  Acc@5: 100.0000 (98.7567)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.6874  Acc@1: 81.2500 (79.8980)  Acc@5: 100.0000 (98.7597)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.5446  Acc@1: 75.0000 (79.8925)  Acc@5: 100.0000 (98.7596)  time: 0.3474  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.7829  Acc@1: 75.0000 (79.8840)  Acc@5: 100.0000 (98.7626)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.5724  Acc@1: 81.2500 (79.8786)  Acc@5: 100.0000 (98.7565)  time: 0.3480  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -1.1076  Acc@1: 81.2500 (79.8822)  Acc@5: 100.0000 (98.7536)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.3853  Acc@1: 81.2500 (79.8857)  Acc@5: 100.0000 (98.7565)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.2970  Acc@1: 81.2500 (79.8803)  Acc@5: 100.0000 (98.7565)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.3082  Acc@1: 81.2500 (79.8780)  Acc@5: 100.0000 (98.7564)  time: 0.3455  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.6746  Acc@1: 75.0000 (79.8785)  Acc@5: 100.0000 (98.7593)  time: 0.3456  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.4869  Acc@1: 75.0000 (79.8531)  Acc@5: 100.0000 (98.7621)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.7863  Acc@1: 81.2500 (79.8538)  Acc@5: 100.0000 (98.7592)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.7012  Acc@1: 81.2500 (79.8573)  Acc@5: 100.0000 (98.7592)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.7970  Acc@1: 81.2500 (79.8408)  Acc@5: 100.0000 (98.7591)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2200/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.2769  Acc@1: 81.2500 (79.8330)  Acc@5: 100.0000 (98.7562)  time: 0.3472  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.9258  Acc@1: 81.2500 (79.8649)  Acc@5: 100.0000 (98.7619)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.0223  Acc@1: 81.2500 (79.8599)  Acc@5: 100.0000 (98.7646)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.6038  Acc@1: 81.2500 (79.8689)  Acc@5: 100.0000 (98.7702)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.4242  Acc@1: 75.0000 (79.8416)  Acc@5: 100.0000 (98.7729)  time: 0.3481  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.2194  Acc@1: 75.0000 (79.8478)  Acc@5: 100.0000 (98.7755)  time: 0.3474  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.5916  Acc@1: 81.2500 (79.8458)  Acc@5: 100.0000 (98.7782)  time: 0.3499  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.7723  Acc@1: 81.2500 (79.8464)  Acc@5: 100.0000 (98.7726)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.5000  Acc@1: 81.2500 (79.8498)  Acc@5: 100.0000 (98.7752)  time: 0.3489  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.7658  Acc@1: 75.0000 (79.8314)  Acc@5: 100.0000 (98.7669)  time: 0.3499  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.6823  Acc@1: 75.0000 (79.8267)  Acc@5: 100.0000 (98.7668)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3869  Acc@1: 75.0000 (79.8112)  Acc@5: 100.0000 (98.7668)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.4552  Acc@1: 75.0000 (79.8120)  Acc@5: 100.0000 (98.7667)  time: 0.3482  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.6142  Acc@1: 81.2500 (79.8155)  Acc@5: 100.0000 (98.7720)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.9614  Acc@1: 81.2500 (79.7976)  Acc@5: 100.0000 (98.7666)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.7552  Acc@1: 81.2500 (79.8091)  Acc@5: 100.0000 (98.7691)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.4597  Acc@1: 81.2500 (79.8073)  Acc@5: 100.0000 (98.7717)  time: 0.3472  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.4398  Acc@1: 75.0000 (79.7976)  Acc@5: 100.0000 (98.7769)  time: 0.3486  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -0.6316  Acc@1: 81.2500 (79.8247)  Acc@5: 100.0000 (98.7715)  time: 0.3510  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.7279  Acc@1: 81.2500 (79.8149)  Acc@5: 100.0000 (98.7714)  time: 0.3527  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.2834  Acc@1: 75.0000 (79.8183)  Acc@5: 100.0000 (98.7739)  time: 0.3517  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.7887  Acc@1: 81.2500 (79.8165)  Acc@5: 100.0000 (98.7738)  time: 0.3539  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -1.0065  Acc@1: 81.2500 (79.8146)  Acc@5: 100.0000 (98.7738)  time: 0.3529  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.6021  Acc@1: 75.0000 (79.7948)  Acc@5: 100.0000 (98.7737)  time: 0.3483  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.7539  Acc@1: 81.2500 (79.8162)  Acc@5: 100.0000 (98.7787)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: 0.2702  Acc@1: 81.2500 (79.8016)  Acc@5: 100.0000 (98.7760)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.2982  Acc@1: 81.2500 (79.8050)  Acc@5: 100.0000 (98.7759)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.9808  Acc@1: 87.5000 (79.8310)  Acc@5: 100.0000 (98.7809)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.4256  Acc@1: 81.2500 (79.8141)  Acc@5: 100.0000 (98.7858)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.8446  Acc@1: 75.0000 (79.8148)  Acc@5: 100.0000 (98.7856)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.7276  Acc@1: 81.2500 (79.8231)  Acc@5: 100.0000 (98.7880)  time: 0.3494  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.6847  Acc@1: 81.2500 (79.8362)  Acc@5: 100.0000 (98.7928)  time: 0.3481  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.0102  Acc@1: 81.2500 (79.8369)  Acc@5: 100.0000 (98.7926)  time: 0.3488  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.1781  Acc@1: 75.0000 (79.8178)  Acc@5: 100.0000 (98.7900)  time: 0.3486  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.7871  Acc@1: 75.0000 (79.8209)  Acc@5: 100.0000 (98.7923)  time: 0.3505  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.5180  Acc@1: 81.2500 (79.8167)  Acc@5: 100.0000 (98.7921)  time: 0.3514  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6741  Acc@1: 75.0000 (79.8126)  Acc@5: 100.0000 (98.7944)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.3842  Acc@1: 81.2500 (79.8133)  Acc@5: 100.0000 (98.7967)  time: 0.3496  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.5368  Acc@1: 81.2500 (79.8213)  Acc@5: 100.0000 (98.7965)  time: 0.3498  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.5156  Acc@1: 81.2500 (79.8437)  Acc@5: 100.0000 (98.8011)  time: 0.3515  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.8542  Acc@1: 81.2500 (79.8443)  Acc@5: 100.0000 (98.8009)  time: 0.3590  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.8608  Acc@1: 75.0000 (79.8209)  Acc@5: 100.0000 (98.8031)  time: 0.3555  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.8461  Acc@1: 75.0000 (79.8216)  Acc@5: 100.0000 (98.8053)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6634  Acc@1: 81.2500 (79.8318)  Acc@5: 100.0000 (98.8099)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.7133  Acc@1: 81.2500 (79.8301)  Acc@5: 100.0000 (98.8120)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.5254  Acc@1: 81.2500 (79.8402)  Acc@5: 100.0000 (98.8118)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.8905  Acc@1: 87.5000 (79.8431)  Acc@5: 100.0000 (98.8162)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.4401  Acc@1: 81.2500 (79.8343)  Acc@5: 100.0000 (98.8160)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.8992  Acc@1: 81.2500 (79.8536)  Acc@5: 100.0000 (98.8134)  time: 0.3471  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.2481  Acc@1: 87.5000 (79.8495)  Acc@5: 100.0000 (98.8109)  time: 0.3460  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.6432  Acc@1: 81.2500 (79.8431)  Acc@5: 100.0000 (98.8060)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.5043  Acc@1: 75.0000 (79.8437)  Acc@5: 100.0000 (98.8104)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.8478  Acc@1: 81.2500 (79.8626)  Acc@5: 100.0000 (98.8125)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.9378  Acc@1: 81.2500 (79.8586)  Acc@5: 100.0000 (98.8077)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -1.0153  Acc@1: 81.2500 (79.8728)  Acc@5: 100.0000 (98.8120)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.5027  Acc@1: 81.2500 (79.8687)  Acc@5: 100.0000 (98.8118)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.8413  Acc@1: 75.0000 (79.8556)  Acc@5: 100.0000 (98.8093)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.8049  Acc@1: 81.2500 (79.8651)  Acc@5: 100.0000 (98.8046)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.5756  Acc@1: 81.2500 (79.8566)  Acc@5: 100.0000 (98.8044)  time: 0.3492  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6360  Acc@1: 81.2500 (79.8750)  Acc@5: 100.0000 (98.8020)  time: 0.3509  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.5828  Acc@1: 81.2500 (79.8688)  Acc@5: 100.0000 (98.8062)  time: 0.3497  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.5404  Acc@1: 81.2500 (79.8648)  Acc@5: 100.0000 (98.7994)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.4057  Acc@1: 81.2500 (79.8564)  Acc@5: 100.0000 (98.7992)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.6275  Acc@1: 81.2500 (79.8547)  Acc@5: 100.0000 (98.8012)  time: 0.3530  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.5983  Acc@1: 81.2500 (79.8442)  Acc@5: 100.0000 (98.8010)  time: 0.3543  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.6376  Acc@1: 81.2500 (79.8711)  Acc@5: 100.0000 (98.8031)  time: 0.3523  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.4201  Acc@1: 81.2500 (79.8759)  Acc@5: 100.0000 (98.7941)  time: 0.3488  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.6404  Acc@1: 81.2500 (79.8807)  Acc@5: 100.0000 (98.7918)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.7583  Acc@1: 81.2500 (79.8789)  Acc@5: 100.0000 (98.7895)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.5272  Acc@1: 81.2500 (79.8815)  Acc@5: 100.0000 (98.7915)  time: 0.3484  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.5982  Acc@1: 81.2500 (79.8862)  Acc@5: 100.0000 (98.7935)  time: 0.3483  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.7035  Acc@1: 81.2500 (79.8909)  Acc@5: 100.0000 (98.7955)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.1330  Acc@1: 81.2500 (79.8892)  Acc@5: 100.0000 (98.7911)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.4523  Acc@1: 81.2500 (79.8895)  Acc@5: 100.0000 (98.7909)  time: 0.3485  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.5948  Acc@1: 81.2500 (79.9005)  Acc@5: 100.0000 (98.7887)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.4258  Acc@1: 81.2500 (79.8903)  Acc@5: 100.0000 (98.7928)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.6966  Acc@1: 81.2500 (79.9012)  Acc@5: 100.0000 (98.7905)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.4965  Acc@1: 87.5000 (79.9037)  Acc@5: 100.0000 (98.7904)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.8455  Acc@1: 81.2500 (79.8935)  Acc@5: 100.0000 (98.7924)  time: 0.3469  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.1954  Acc@1: 81.2500 (79.8918)  Acc@5: 100.0000 (98.7964)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.7086  Acc@1: 75.0000 (79.8713)  Acc@5: 100.0000 (98.7921)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5472  Acc@1: 75.0000 (79.8696)  Acc@5: 100.0000 (98.7919)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.8736  Acc@1: 75.0000 (79.8535)  Acc@5: 100.0000 (98.7918)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.8028  Acc@1: 75.0000 (79.8355)  Acc@5: 100.0000 (98.7917)  time: 0.3468  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.8090  Acc@1: 81.2500 (79.8298)  Acc@5: 100.0000 (98.7915)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.4996  Acc@1: 81.2500 (79.8345)  Acc@5: 100.0000 (98.7914)  time: 0.3493  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.9579  Acc@1: 81.2500 (79.8309)  Acc@5: 100.0000 (98.7933)  time: 0.3509  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.6331  Acc@1: 75.0000 (79.8152)  Acc@5: 100.0000 (98.7972)  time: 0.3500  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.2788  Acc@1: 75.0000 (79.8036)  Acc@5: 100.0000 (98.7910)  time: 0.3514  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.6416  Acc@1: 81.2500 (79.8204)  Acc@5: 100.0000 (98.7949)  time: 0.3505  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.7985  Acc@1: 81.2500 (79.8392)  Acc@5: 100.0000 (98.7988)  time: 0.3483  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.7038  Acc@1: 87.5000 (79.8477)  Acc@5: 100.0000 (98.8006)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.3934  Acc@1: 81.2500 (79.8402)  Acc@5: 100.0000 (98.8005)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.9505  Acc@1: 81.2500 (79.8447)  Acc@5: 100.0000 (98.8003)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.8243  Acc@1: 81.2500 (79.8452)  Acc@5: 100.0000 (98.8021)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.4689  Acc@1: 81.2500 (79.8358)  Acc@5: 100.0000 (98.8040)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.2375  Acc@1: 81.2500 (79.8402)  Acc@5: 100.0000 (98.8077)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.1646  Acc@1: 81.2500 (79.8467)  Acc@5: 100.0000 (98.8056)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.7591  Acc@1: 81.2500 (79.8432)  Acc@5: 100.0000 (98.8074)  time: 0.3503  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.4368  Acc@1: 81.2500 (79.8515)  Acc@5: 100.0000 (98.8111)  time: 0.3510  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.8998  Acc@1: 81.2500 (79.8637)  Acc@5: 100.0000 (98.8090)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.6981  Acc@1: 81.2500 (79.8797)  Acc@5: 100.0000 (98.8068)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.5843  Acc@1: 81.2500 (79.8762)  Acc@5: 100.0000 (98.8086)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.5975  Acc@1: 75.0000 (79.8708)  Acc@5: 100.0000 (98.8104)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.7320  Acc@1: 75.0000 (79.8693)  Acc@5: 100.0000 (98.8102)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.4931  Acc@1: 81.2500 (79.8812)  Acc@5: 100.0000 (98.8100)  time: 0.3502  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.9839  Acc@1: 75.0000 (79.8624)  Acc@5: 100.0000 (98.8117)  time: 0.3519  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.3972  Acc@1: 81.2500 (79.8609)  Acc@5: 100.0000 (98.8115)  time: 0.3510  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.3600  Acc@1: 81.2500 (79.8480)  Acc@5: 100.0000 (98.8132)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.5830  Acc@1: 75.0000 (79.8352)  Acc@5: 100.0000 (98.8093)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.7193  Acc@1: 75.0000 (79.8205)  Acc@5: 100.0000 (98.8091)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.9786  Acc@1: 81.2500 (79.8380)  Acc@5: 100.0000 (98.8089)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.7259  Acc@1: 81.2500 (79.8235)  Acc@5: 100.0000 (98.8050)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.7775  Acc@1: 81.2500 (79.8334)  Acc@5: 100.0000 (98.8067)  time: 0.3513  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.8008  Acc@1: 81.2500 (79.8395)  Acc@5: 100.0000 (98.8084)  time: 0.3537  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.3606  Acc@1: 75.0000 (79.8176)  Acc@5: 100.0000 (98.8082)  time: 0.3523  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.7859  Acc@1: 75.0000 (79.8256)  Acc@5: 100.0000 (98.8099)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.8341  Acc@1: 81.2500 (79.8372)  Acc@5: 100.0000 (98.8116)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.6794  Acc@1: 81.2500 (79.8451)  Acc@5: 100.0000 (98.8132)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.7238  Acc@1: 81.2500 (79.8363)  Acc@5: 100.0000 (98.8130)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.1282  Acc@1: 81.2500 (79.8313)  Acc@5: 100.0000 (98.8165)  time: 0.3466  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6308  Acc@1: 75.0000 (79.8226)  Acc@5: 100.0000 (98.8182)  time: 0.3503  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.0546  Acc@1: 75.0000 (79.7976)  Acc@5: 100.0000 (98.8143)  time: 0.3519  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.7850  Acc@1: 75.0000 (79.8146)  Acc@5: 100.0000 (98.8141)  time: 0.3521  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9202  Acc@1: 87.5000 (79.8369)  Acc@5: 100.0000 (98.8121)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.4852  Acc@1: 81.2500 (79.8392)  Acc@5: 100.0000 (98.8137)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5860  Acc@1: 81.2500 (79.8433)  Acc@5: 100.0000 (98.8154)  time: 0.3470  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6420  Acc@1: 81.2500 (79.8401)  Acc@5: 100.0000 (98.8152)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6597  Acc@1: 81.2500 (79.8477)  Acc@5: 100.0000 (98.8186)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.4658  Acc@1: 81.2500 (79.8285)  Acc@5: 100.0000 (98.8184)  time: 0.3470  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8983  Acc@1: 68.7500 (79.8147)  Acc@5: 100.0000 (98.8182)  time: 0.3464  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.4959  Acc@1: 75.0000 (79.8206)  Acc@5: 100.0000 (98.8216)  time: 0.3466  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8039  Acc@1: 87.5000 (79.8282)  Acc@5: 100.0000 (98.8249)  time: 0.3468  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.8285  Acc@1: 81.2500 (79.8357)  Acc@5: 100.0000 (98.8247)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5211  Acc@1: 81.2500 (79.8203)  Acc@5: 100.0000 (98.8227)  time: 0.3492  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.3468  Acc@1: 81.2500 (79.8261)  Acc@5: 100.0000 (98.8225)  time: 0.3496  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6863  Acc@1: 81.2500 (79.8231)  Acc@5: 100.0000 (98.8223)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.1025  Acc@1: 81.2500 (79.8271)  Acc@5: 100.0000 (98.8204)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.7367  Acc@1: 81.2500 (79.8206)  Acc@5: 100.0000 (98.8167)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.7295  Acc@1: 81.2500 (79.8315)  Acc@5: 100.0000 (98.8200)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.9300  Acc@1: 81.2500 (79.8389)  Acc@5: 100.0000 (98.8198)  time: 0.3492  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.9301  Acc@1: 81.2500 (79.8342)  Acc@5: 100.0000 (98.8196)  time: 0.3514  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8122  Acc@1: 81.2500 (79.8485)  Acc@5: 100.0000 (98.8211)  time: 0.3524  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.3775  Acc@1: 81.2500 (79.8609)  Acc@5: 100.0000 (98.8209)  time: 0.3531  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5812  Acc@1: 81.2500 (79.8750)  Acc@5: 100.0000 (98.8190)  time: 0.3507  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7045  Acc@1: 81.2500 (79.8668)  Acc@5: 100.0000 (98.8188)  time: 0.3491  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0267  Acc@1: 75.0000 (79.8706)  Acc@5: 100.0000 (98.8186)  time: 0.3502  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5322  Acc@1: 81.2500 (79.8761)  Acc@5: 100.0000 (98.8184)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1486  Acc@1: 75.0000 (79.8662)  Acc@5: 100.0000 (98.8217)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8648  Acc@1: 68.7500 (79.8513)  Acc@5: 100.0000 (98.8164)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9018  Acc@1: 75.0000 (79.8450)  Acc@5: 100.0000 (98.8128)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.7021  Acc@1: 75.0000 (79.8420)  Acc@5: 100.0000 (98.8143)  time: 0.3528  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7228  Acc@1: 81.2500 (79.8508)  Acc@5: 100.0000 (98.8142)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.6036  Acc@1: 81.2500 (79.8479)  Acc@5: 100.0000 (98.8157)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6894  Acc@1: 81.2500 (79.8450)  Acc@5: 100.0000 (98.8172)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0180  Acc@1: 81.2500 (79.8500)  Acc@5: 100.0000 (98.8183)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[4/5] Total time: 0:21:47 (0.3488 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 91309, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 91053, 4: 240000}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 239968}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 240000}, 18: {0: 16, 1: 0, 2: 0, 3: 91197, 4: 32}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 240000}}
Averaged stats: Lr: 0.001875  Loss: -1.0180  Acc@1: 81.2500 (79.8500)  Acc@5: 100.0000 (98.8183)
Train: Epoch[5/5]  [   0/3750]  eta: 0:46:44  Lr: 0.001875  Loss: -0.7762  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7478  data: 0.3989  max mem: 2503
Train: Epoch[5/5]  [  10/3750]  eta: 0:23:55  Lr: 0.001875  Loss: -0.7188  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (100.0000)  time: 0.3839  data: 0.0369  max mem: 2503
Train: Epoch[5/5]  [  20/3750]  eta: 0:22:52  Lr: 0.001875  Loss: -0.0155  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (99.4048)  time: 0.3488  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:20  Lr: 0.001875  Loss: -0.4497  Acc@1: 81.2500 (81.6532)  Acc@5: 100.0000 (99.5968)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:04  Lr: 0.001875  Loss: -0.5566  Acc@1: 75.0000 (80.0305)  Acc@5: 100.0000 (99.3902)  time: 0.3455  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [  50/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.9854  Acc@1: 75.0000 (80.7598)  Acc@5: 100.0000 (99.5098)  time: 0.3457  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.1970  Acc@1: 81.2500 (80.3279)  Acc@5: 100.0000 (99.3852)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:35  Lr: 0.001875  Loss: -0.5828  Acc@1: 75.0000 (80.2817)  Acc@5: 100.0000 (99.1197)  time: 0.3453  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.6191  Acc@1: 81.2500 (80.4012)  Acc@5: 100.0000 (99.1512)  time: 0.3454  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -0.7851  Acc@1: 81.2500 (80.7005)  Acc@5: 100.0000 (99.1071)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -0.6208  Acc@1: 81.2500 (80.8787)  Acc@5: 100.0000 (99.0718)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.9739  Acc@1: 81.2500 (81.0248)  Acc@5: 100.0000 (98.9865)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.4746  Acc@1: 81.2500 (81.0950)  Acc@5: 100.0000 (98.9669)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -0.4401  Acc@1: 81.2500 (81.0115)  Acc@5: 100.0000 (98.9981)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.2477  Acc@1: 81.2500 (80.8511)  Acc@5: 100.0000 (98.9805)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 150/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.5411  Acc@1: 75.0000 (80.5877)  Acc@5: 100.0000 (99.0066)  time: 0.3488  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 160/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.6141  Acc@1: 75.0000 (80.4348)  Acc@5: 100.0000 (98.9519)  time: 0.3487  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.5470  Acc@1: 81.2500 (80.7018)  Acc@5: 100.0000 (98.9035)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.6107  Acc@1: 81.2500 (80.8011)  Acc@5: 100.0000 (98.8950)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.6758  Acc@1: 81.2500 (80.8901)  Acc@5: 100.0000 (98.8874)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.6203  Acc@1: 81.2500 (80.7836)  Acc@5: 100.0000 (98.9428)  time: 0.3477  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.8389  Acc@1: 75.0000 (80.5095)  Acc@5: 100.0000 (98.9929)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.9405  Acc@1: 75.0000 (80.4581)  Acc@5: 100.0000 (98.9819)  time: 0.3509  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.6241  Acc@1: 81.2500 (80.3030)  Acc@5: 100.0000 (98.9719)  time: 0.3538  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:27  Lr: 0.001875  Loss: -0.6929  Acc@1: 81.2500 (80.3164)  Acc@5: 100.0000 (98.9627)  time: 0.3526  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.8174  Acc@1: 87.5000 (80.4781)  Acc@5: 100.0000 (99.0040)  time: 0.3512  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.4630  Acc@1: 81.2500 (80.5077)  Acc@5: 100.0000 (99.0182)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.5821  Acc@1: 81.2500 (80.5120)  Acc@5: 100.0000 (98.9852)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.5536  Acc@1: 75.0000 (80.2491)  Acc@5: 100.0000 (98.9991)  time: 0.3486  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.9158  Acc@1: 75.0000 (80.3265)  Acc@5: 100.0000 (99.0120)  time: 0.3471  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.8573  Acc@1: 81.2500 (80.3987)  Acc@5: 100.0000 (99.0241)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.4546  Acc@1: 87.5000 (80.5265)  Acc@5: 100.0000 (99.0354)  time: 0.3488  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 320/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.6828  Acc@1: 81.2500 (80.4517)  Acc@5: 100.0000 (99.0654)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.5126  Acc@1: 75.0000 (80.2870)  Acc@5: 100.0000 (98.9804)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:52  Lr: 0.001875  Loss: -0.6435  Acc@1: 75.0000 (80.1870)  Acc@5: 100.0000 (99.0103)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -0.9482  Acc@1: 75.0000 (80.2528)  Acc@5: 100.0000 (98.9850)  time: 0.3513  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.9591  Acc@1: 81.2500 (80.3497)  Acc@5: 100.0000 (99.0132)  time: 0.3488  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -0.6946  Acc@1: 81.2500 (80.3403)  Acc@5: 100.0000 (99.0229)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.3599  Acc@1: 75.0000 (80.3642)  Acc@5: 100.0000 (98.9829)  time: 0.3520  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.6995  Acc@1: 81.2500 (80.4188)  Acc@5: 100.0000 (98.9930)  time: 0.3509  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.4169  Acc@1: 81.2500 (80.4084)  Acc@5: 100.0000 (98.9869)  time: 0.3460  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.3274  Acc@1: 81.2500 (80.3528)  Acc@5: 100.0000 (98.9659)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.5548  Acc@1: 81.2500 (80.2702)  Acc@5: 100.0000 (98.9757)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.7586  Acc@1: 81.2500 (80.2639)  Acc@5: 100.0000 (98.9849)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.6880  Acc@1: 81.2500 (80.2296)  Acc@5: 100.0000 (98.9229)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.0142  Acc@1: 81.2500 (80.2384)  Acc@5: 100.0000 (98.9052)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.2112  Acc@1: 81.2500 (80.2332)  Acc@5: 100.0000 (98.9018)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.6685  Acc@1: 81.2500 (80.3344)  Acc@5: 100.0000 (98.9119)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.8544  Acc@1: 87.5000 (80.3144)  Acc@5: 100.0000 (98.9215)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.8976  Acc@1: 81.2500 (80.3080)  Acc@5: 100.0000 (98.9180)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.5538  Acc@1: 81.2500 (80.2645)  Acc@5: 100.0000 (98.9147)  time: 0.3458  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -1.0140  Acc@1: 81.2500 (80.2960)  Acc@5: 100.0000 (98.8870)  time: 0.3460  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.4500  Acc@1: 81.2500 (80.3143)  Acc@5: 100.0000 (98.8964)  time: 0.3487  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.5979  Acc@1: 81.2500 (80.3319)  Acc@5: 100.0000 (98.9171)  time: 0.3504  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.6065  Acc@1: 81.2500 (80.3027)  Acc@5: 100.0000 (98.9372)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.7824  Acc@1: 81.2500 (80.3085)  Acc@5: 100.0000 (98.9564)  time: 0.3485  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.5302  Acc@1: 81.2500 (80.2696)  Acc@5: 100.0000 (98.9416)  time: 0.3493  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -1.0130  Acc@1: 81.2500 (80.3087)  Acc@5: 100.0000 (98.9492)  time: 0.3494  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.7441  Acc@1: 81.2500 (80.2711)  Acc@5: 100.0000 (98.9565)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.3623  Acc@1: 81.2500 (80.2876)  Acc@5: 100.0000 (98.9636)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.7130  Acc@1: 87.5000 (80.3973)  Acc@5: 100.0000 (98.9809)  time: 0.3510  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.7700  Acc@1: 87.5000 (80.5135)  Acc@5: 100.0000 (98.9771)  time: 0.3512  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.8655  Acc@1: 87.5000 (80.4952)  Acc@5: 100.0000 (98.9734)  time: 0.3513  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.5023  Acc@1: 81.2500 (80.4873)  Acc@5: 100.0000 (98.9897)  time: 0.3535  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.7685  Acc@1: 81.2500 (80.4407)  Acc@5: 100.0000 (99.0055)  time: 0.3520  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.8914  Acc@1: 81.2500 (80.4724)  Acc@5: 100.0000 (99.0111)  time: 0.3488  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.9087  Acc@1: 81.2500 (80.4841)  Acc@5: 100.0000 (99.0072)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.6089  Acc@1: 75.0000 (80.4210)  Acc@5: 100.0000 (99.0220)  time: 0.3496  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.1390  Acc@1: 75.0000 (80.3965)  Acc@5: 100.0000 (99.0180)  time: 0.3507  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.9391  Acc@1: 81.2500 (80.3907)  Acc@5: 100.0000 (99.0051)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.5883  Acc@1: 81.2500 (80.4208)  Acc@5: 100.0000 (99.0014)  time: 0.3487  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -1.0071  Acc@1: 81.2500 (80.4237)  Acc@5: 100.0000 (98.9979)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.2247  Acc@1: 75.0000 (80.3398)  Acc@5: 100.0000 (98.9771)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -0.8203  Acc@1: 75.0000 (80.3352)  Acc@5: 100.0000 (98.9740)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.4262  Acc@1: 75.0000 (80.3222)  Acc@5: 100.0000 (98.9879)  time: 0.3476  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.7615  Acc@1: 81.2500 (80.3928)  Acc@5: 100.0000 (98.9930)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.6501  Acc@1: 81.2500 (80.3548)  Acc@5: 100.0000 (98.9980)  time: 0.3479  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.7509  Acc@1: 75.0000 (80.3178)  Acc@5: 100.0000 (98.9948)  time: 0.3481  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.2349  Acc@1: 75.0000 (80.3457)  Acc@5: 100.0000 (98.9917)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.7532  Acc@1: 81.2500 (80.4283)  Acc@5: 100.0000 (99.0044)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.3313  Acc@1: 87.5000 (80.4463)  Acc@5: 100.0000 (99.0091)  time: 0.3458  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.3765  Acc@1: 87.5000 (80.4793)  Acc@5: 100.0000 (99.0213)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 820/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.8310  Acc@1: 81.2500 (80.4811)  Acc@5: 100.0000 (99.0027)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 830/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.5076  Acc@1: 81.2500 (80.4603)  Acc@5: 100.0000 (98.9997)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.5898  Acc@1: 81.2500 (80.4400)  Acc@5: 100.0000 (98.9744)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.4351  Acc@1: 81.2500 (80.4495)  Acc@5: 100.0000 (98.9718)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.3542  Acc@1: 81.2500 (80.4370)  Acc@5: 100.0000 (98.9692)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.7618  Acc@1: 81.2500 (80.4750)  Acc@5: 100.0000 (98.9739)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.4263  Acc@1: 81.2500 (80.5264)  Acc@5: 100.0000 (98.9855)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.8149  Acc@1: 81.2500 (80.5275)  Acc@5: 100.0000 (98.9899)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.8507  Acc@1: 81.2500 (80.5147)  Acc@5: 100.0000 (98.9872)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.9084  Acc@1: 81.2500 (80.5708)  Acc@5: 100.0000 (98.9984)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.6302  Acc@1: 87.5000 (80.5782)  Acc@5: 100.0000 (99.0024)  time: 0.3488  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.6990  Acc@1: 87.5000 (80.6122)  Acc@5: 100.0000 (99.0132)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.4004  Acc@1: 81.2500 (80.5991)  Acc@5: 100.0000 (99.0170)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.4669  Acc@1: 81.2500 (80.5665)  Acc@5: 100.0000 (99.0208)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.6601  Acc@1: 81.2500 (80.6191)  Acc@5: 100.0000 (99.0114)  time: 0.3480  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -0.6334  Acc@1: 81.2500 (80.6256)  Acc@5: 100.0000 (99.0088)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.9560  Acc@1: 81.2500 (80.6639)  Acc@5: 100.0000 (99.0061)  time: 0.3486  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.9612  Acc@1: 81.2500 (80.6446)  Acc@5: 100.0000 (99.0098)  time: 0.3498  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1000/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.6788  Acc@1: 81.2500 (80.7005)  Acc@5: 100.0000 (99.0197)  time: 0.3505  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.5667  Acc@1: 87.5000 (80.7307)  Acc@5: 100.0000 (99.0171)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.8885  Acc@1: 87.5000 (80.7786)  Acc@5: 100.0000 (99.0267)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.4839  Acc@1: 81.2500 (80.7468)  Acc@5: 100.0000 (99.0240)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -0.8925  Acc@1: 81.2500 (80.7457)  Acc@5: 100.0000 (99.0214)  time: 0.3486  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.8004  Acc@1: 81.2500 (80.7445)  Acc@5: 100.0000 (99.0307)  time: 0.3499  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.5924  Acc@1: 81.2500 (80.7316)  Acc@5: 100.0000 (99.0339)  time: 0.3508  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.8317  Acc@1: 87.5000 (80.7831)  Acc@5: 100.0000 (99.0371)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.4681  Acc@1: 81.2500 (80.7643)  Acc@5: 100.0000 (99.0402)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.7734  Acc@1: 81.2500 (80.7917)  Acc@5: 100.0000 (99.0376)  time: 0.3522  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.6677  Acc@1: 81.2500 (80.7675)  Acc@5: 100.0000 (99.0293)  time: 0.3490  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.3466  Acc@1: 81.2500 (80.7775)  Acc@5: 100.0000 (99.0380)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.5619  Acc@1: 87.5000 (80.8207)  Acc@5: 100.0000 (99.0355)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.8807  Acc@1: 87.5000 (80.8411)  Acc@5: 100.0000 (99.0329)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.2650  Acc@1: 75.0000 (80.7680)  Acc@5: 100.0000 (99.0250)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.8556  Acc@1: 75.0000 (80.7776)  Acc@5: 100.0000 (99.0334)  time: 0.3508  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -0.5180  Acc@1: 81.2500 (80.7870)  Acc@5: 100.0000 (99.0310)  time: 0.3505  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1170/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.6398  Acc@1: 75.0000 (80.7376)  Acc@5: 100.0000 (99.0179)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.9367  Acc@1: 75.0000 (80.7367)  Acc@5: 100.0000 (99.0262)  time: 0.3495  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.6550  Acc@1: 81.2500 (80.7147)  Acc@5: 100.0000 (99.0344)  time: 0.3497  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.5919  Acc@1: 81.2500 (80.7036)  Acc@5: 100.0000 (99.0269)  time: 0.3501  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.6073  Acc@1: 81.2500 (80.6823)  Acc@5: 100.0000 (99.0349)  time: 0.3497  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.2830  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (99.0377)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.9737  Acc@1: 87.5000 (80.7423)  Acc@5: 100.0000 (99.0303)  time: 0.3503  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.9650  Acc@1: 81.2500 (80.7162)  Acc@5: 100.0000 (99.0330)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.5907  Acc@1: 75.0000 (80.7104)  Acc@5: 100.0000 (99.0358)  time: 0.3528  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.8305  Acc@1: 75.0000 (80.7048)  Acc@5: 100.0000 (99.0434)  time: 0.3535  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.3892  Acc@1: 75.0000 (80.6845)  Acc@5: 100.0000 (99.0411)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.3296  Acc@1: 75.0000 (80.6548)  Acc@5: 100.0000 (99.0437)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.5617  Acc@1: 81.2500 (80.6545)  Acc@5: 100.0000 (99.0414)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.9088  Acc@1: 81.2500 (80.6207)  Acc@5: 100.0000 (99.0488)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.8605  Acc@1: 81.2500 (80.6302)  Acc@5: 100.0000 (99.0418)  time: 0.3482  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:07  Lr: 0.001875  Loss: 0.0825  Acc@1: 81.2500 (80.6065)  Acc@5: 100.0000 (99.0443)  time: 0.3486  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.5902  Acc@1: 81.2500 (80.6302)  Acc@5: 100.0000 (99.0468)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1340/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.6623  Acc@1: 81.2500 (80.6068)  Acc@5: 100.0000 (99.0446)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.9169  Acc@1: 81.2500 (80.6578)  Acc@5: 100.0000 (99.0470)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6571  Acc@1: 87.5000 (80.6898)  Acc@5: 100.0000 (99.0540)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7373  Acc@1: 81.2500 (80.6847)  Acc@5: 100.0000 (99.0563)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.7452  Acc@1: 81.2500 (80.7024)  Acc@5: 100.0000 (99.0587)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.5771  Acc@1: 81.2500 (80.6704)  Acc@5: 100.0000 (99.0564)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.8258  Acc@1: 75.0000 (80.6478)  Acc@5: 100.0000 (99.0632)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.3413  Acc@1: 75.0000 (80.6476)  Acc@5: 100.0000 (99.0609)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.9780  Acc@1: 81.2500 (80.6342)  Acc@5: 100.0000 (99.0544)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.6623  Acc@1: 81.2500 (80.6254)  Acc@5: 100.0000 (99.0610)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.5043  Acc@1: 81.2500 (80.5864)  Acc@5: 100.0000 (99.0588)  time: 0.3495  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.0913  Acc@1: 81.2500 (80.5910)  Acc@5: 100.0000 (99.0610)  time: 0.3494  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.3863  Acc@1: 81.2500 (80.5741)  Acc@5: 100.0000 (99.0631)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.9316  Acc@1: 81.2500 (80.6127)  Acc@5: 100.0000 (99.0525)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4163  Acc@1: 81.2500 (80.5874)  Acc@5: 100.0000 (99.0505)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.8329  Acc@1: 75.0000 (80.6003)  Acc@5: 100.0000 (99.0568)  time: 0.3488  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.7563  Acc@1: 81.2500 (80.6046)  Acc@5: 100.0000 (99.0590)  time: 0.3495  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.6258  Acc@1: 75.0000 (80.5841)  Acc@5: 100.0000 (99.0569)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:57  Lr: 0.001875  Loss: 0.0936  Acc@1: 75.0000 (80.5638)  Acc@5: 100.0000 (99.0590)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.4424  Acc@1: 75.0000 (80.5478)  Acc@5: 100.0000 (99.0529)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.2652  Acc@1: 75.0000 (80.5605)  Acc@5: 100.0000 (99.0509)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.2594  Acc@1: 81.2500 (80.5529)  Acc@5: 100.0000 (99.0490)  time: 0.3510  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.3711  Acc@1: 81.2500 (80.5774)  Acc@5: 100.0000 (99.0431)  time: 0.3506  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.6234  Acc@1: 81.2500 (80.5538)  Acc@5: 100.0000 (99.0333)  time: 0.3529  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.7966  Acc@1: 81.2500 (80.5661)  Acc@5: 100.0000 (99.0315)  time: 0.3521  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.7849  Acc@1: 81.2500 (80.5743)  Acc@5: 100.0000 (99.0336)  time: 0.3480  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.5413  Acc@1: 81.2500 (80.5746)  Acc@5: 100.0000 (99.0319)  time: 0.3489  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.5707  Acc@1: 81.2500 (80.5982)  Acc@5: 100.0000 (99.0340)  time: 0.3497  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.6968  Acc@1: 81.2500 (80.6177)  Acc@5: 100.0000 (99.0245)  time: 0.3485  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.4524  Acc@1: 81.2500 (80.5756)  Acc@5: 100.0000 (99.0267)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.4333  Acc@1: 81.2500 (80.5987)  Acc@5: 100.0000 (99.0212)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.3359  Acc@1: 81.2500 (80.5989)  Acc@5: 100.0000 (99.0233)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.6210  Acc@1: 81.2500 (80.6066)  Acc@5: 100.0000 (99.0217)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.8427  Acc@1: 81.2500 (80.6142)  Acc@5: 100.0000 (99.0275)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.9059  Acc@1: 81.2500 (80.6440)  Acc@5: 100.0000 (99.0259)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.8534  Acc@1: 81.2500 (80.6475)  Acc@5: 100.0000 (99.0242)  time: 0.3552  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.4440  Acc@1: 75.0000 (80.6437)  Acc@5: 100.0000 (99.0226)  time: 0.3550  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.8129  Acc@1: 81.2500 (80.6546)  Acc@5: 100.0000 (99.0137)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -1.1000  Acc@1: 81.2500 (80.6580)  Acc@5: 100.0000 (99.0122)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.7730  Acc@1: 81.2500 (80.6795)  Acc@5: 100.0000 (99.0143)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.6612  Acc@1: 81.2500 (80.6361)  Acc@5: 100.0000 (99.0200)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -0.8612  Acc@1: 81.2500 (80.6503)  Acc@5: 100.0000 (99.0113)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.7821  Acc@1: 81.2500 (80.6466)  Acc@5: 100.0000 (99.0133)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.2320  Acc@1: 81.2500 (80.6501)  Acc@5: 100.0000 (99.0083)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.4085  Acc@1: 75.0000 (80.6359)  Acc@5: 100.0000 (99.0034)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.5375  Acc@1: 81.2500 (80.6428)  Acc@5: 100.0000 (99.0089)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.4864  Acc@1: 81.2500 (80.6045)  Acc@5: 100.0000 (99.0006)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.7041  Acc@1: 75.0000 (80.5943)  Acc@5: 100.0000 (98.9957)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.9698  Acc@1: 75.0000 (80.5910)  Acc@5: 100.0000 (99.0012)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -0.7711  Acc@1: 81.2500 (80.6083)  Acc@5: 100.0000 (98.9999)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.7296  Acc@1: 81.2500 (80.5948)  Acc@5: 100.0000 (98.9883)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.6677  Acc@1: 81.2500 (80.6118)  Acc@5: 100.0000 (98.9938)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.6690  Acc@1: 81.2500 (80.5985)  Acc@5: 100.0000 (98.9925)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.7949  Acc@1: 81.2500 (80.6153)  Acc@5: 100.0000 (98.9845)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.7234  Acc@1: 81.2500 (80.6120)  Acc@5: 100.0000 (98.9899)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.6931  Acc@1: 81.2500 (80.6253)  Acc@5: 100.0000 (98.9886)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.4277  Acc@1: 81.2500 (80.6089)  Acc@5: 100.0000 (98.9874)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7484  Acc@1: 75.0000 (80.5828)  Acc@5: 100.0000 (98.9829)  time: 0.3495  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.6291  Acc@1: 81.2500 (80.6026)  Acc@5: 100.0000 (98.9784)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4737  Acc@1: 81.2500 (80.5962)  Acc@5: 100.0000 (98.9772)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.9866  Acc@1: 81.2500 (80.5835)  Acc@5: 100.0000 (98.9760)  time: 0.3481  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -0.7464  Acc@1: 75.0000 (80.5709)  Acc@5: 100.0000 (98.9749)  time: 0.3491  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.8527  Acc@1: 81.2500 (80.5743)  Acc@5: 100.0000 (98.9769)  time: 0.3515  data: 0.0025  max mem: 2503
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.4072  Acc@1: 81.2500 (80.5936)  Acc@5: 100.0000 (98.9789)  time: 0.3538  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.7829  Acc@1: 81.2500 (80.5780)  Acc@5: 100.0000 (98.9778)  time: 0.3522  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.7544  Acc@1: 75.0000 (80.5908)  Acc@5: 100.0000 (98.9766)  time: 0.3502  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.4475  Acc@1: 87.5000 (80.5972)  Acc@5: 100.0000 (98.9755)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.7613  Acc@1: 81.2500 (80.5973)  Acc@5: 100.0000 (98.9713)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.7435  Acc@1: 81.2500 (80.6346)  Acc@5: 100.0000 (98.9733)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2030/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.9974  Acc@1: 87.5000 (80.6592)  Acc@5: 100.0000 (98.9722)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.7128  Acc@1: 81.2500 (80.6498)  Acc@5: 100.0000 (98.9711)  time: 0.3496  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.7217  Acc@1: 81.2500 (80.6466)  Acc@5: 100.0000 (98.9700)  time: 0.3498  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.8326  Acc@1: 81.2500 (80.6738)  Acc@5: 100.0000 (98.9750)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.5804  Acc@1: 81.2500 (80.6615)  Acc@5: 100.0000 (98.9739)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.8160  Acc@1: 81.2500 (80.6854)  Acc@5: 100.0000 (98.9668)  time: 0.3504  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.9979  Acc@1: 81.2500 (80.6881)  Acc@5: 100.0000 (98.9658)  time: 0.3516  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.5611  Acc@1: 75.0000 (80.6729)  Acc@5: 100.0000 (98.9648)  time: 0.3494  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.9545  Acc@1: 75.0000 (80.6638)  Acc@5: 100.0000 (98.9638)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.9136  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (98.9628)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -1.0188  Acc@1: 81.2500 (80.6576)  Acc@5: 100.0000 (98.9676)  time: 0.3503  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.9767  Acc@1: 81.2500 (80.6632)  Acc@5: 100.0000 (98.9666)  time: 0.3499  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.5739  Acc@1: 81.2500 (80.6573)  Acc@5: 100.0000 (98.9714)  time: 0.3474  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.7485  Acc@1: 81.2500 (80.6658)  Acc@5: 100.0000 (98.9762)  time: 0.3468  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.3561  Acc@1: 81.2500 (80.6512)  Acc@5: 100.0000 (98.9722)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.4685  Acc@1: 75.0000 (80.6453)  Acc@5: 100.0000 (98.9655)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.8018  Acc@1: 81.2500 (80.6424)  Acc@5: 100.0000 (98.9645)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2200/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.9872  Acc@1: 81.2500 (80.6338)  Acc@5: 100.0000 (98.9579)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.6713  Acc@1: 75.0000 (80.6111)  Acc@5: 100.0000 (98.9626)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.8247  Acc@1: 81.2500 (80.6365)  Acc@5: 100.0000 (98.9560)  time: 0.3468  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -0.8939  Acc@1: 81.2500 (80.6505)  Acc@5: 100.0000 (98.9579)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.5482  Acc@1: 81.2500 (80.6560)  Acc@5: 100.0000 (98.9597)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.2674  Acc@1: 75.0000 (80.6392)  Acc@5: 100.0000 (98.9505)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.8509  Acc@1: 75.0000 (80.6336)  Acc@5: 100.0000 (98.9496)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.2928  Acc@1: 75.0000 (80.6253)  Acc@5: 100.0000 (98.9487)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -1.0557  Acc@1: 87.5000 (80.6636)  Acc@5: 100.0000 (98.9533)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.7885  Acc@1: 87.5000 (80.6580)  Acc@5: 100.0000 (98.9497)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.6891  Acc@1: 87.5000 (80.6660)  Acc@5: 100.0000 (98.9543)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -0.5401  Acc@1: 81.2500 (80.6523)  Acc@5: 100.0000 (98.9507)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.8012  Acc@1: 81.2500 (80.6710)  Acc@5: 100.0000 (98.9525)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.5792  Acc@1: 81.2500 (80.6682)  Acc@5: 100.0000 (98.9543)  time: 0.3471  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.0020  Acc@1: 81.2500 (80.6546)  Acc@5: 100.0000 (98.9508)  time: 0.3488  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.9628  Acc@1: 81.2500 (80.6678)  Acc@5: 100.0000 (98.9552)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.8608  Acc@1: 87.5000 (80.7100)  Acc@5: 100.0000 (98.9544)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.6061  Acc@1: 87.5000 (80.7043)  Acc@5: 100.0000 (98.9535)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -0.4728  Acc@1: 81.2500 (80.6988)  Acc@5: 100.0000 (98.9579)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -1.0897  Acc@1: 81.2500 (80.7246)  Acc@5: 100.0000 (98.9570)  time: 0.3476  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.6879  Acc@1: 81.2500 (80.7294)  Acc@5: 100.0000 (98.9562)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.4930  Acc@1: 81.2500 (80.7212)  Acc@5: 100.0000 (98.9553)  time: 0.3500  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -0.5760  Acc@1: 75.0000 (80.7105)  Acc@5: 100.0000 (98.9596)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.7077  Acc@1: 81.2500 (80.7255)  Acc@5: 100.0000 (98.9639)  time: 0.3496  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.5473  Acc@1: 81.2500 (80.7226)  Acc@5: 100.0000 (98.9630)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.3221  Acc@1: 81.2500 (80.7273)  Acc@5: 100.0000 (98.9647)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.6725  Acc@1: 81.2500 (80.7116)  Acc@5: 100.0000 (98.9638)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.9247  Acc@1: 81.2500 (80.7315)  Acc@5: 100.0000 (98.9604)  time: 0.3481  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.5874  Acc@1: 81.2500 (80.7235)  Acc@5: 100.0000 (98.9571)  time: 0.3478  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.7438  Acc@1: 81.2500 (80.7131)  Acc@5: 100.0000 (98.9562)  time: 0.3475  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.6589  Acc@1: 75.0000 (80.7152)  Acc@5: 100.0000 (98.9579)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.7816  Acc@1: 81.2500 (80.7074)  Acc@5: 100.0000 (98.9596)  time: 0.3514  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.7261  Acc@1: 81.2500 (80.7120)  Acc@5: 100.0000 (98.9612)  time: 0.3500  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.6534  Acc@1: 81.2500 (80.7067)  Acc@5: 100.0000 (98.9629)  time: 0.3501  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.8934  Acc@1: 81.2500 (80.6966)  Acc@5: 100.0000 (98.9546)  time: 0.3500  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.1897  Acc@1: 81.2500 (80.7012)  Acc@5: 100.0000 (98.9514)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.4862  Acc@1: 81.2500 (80.6936)  Acc@5: 100.0000 (98.9482)  time: 0.3483  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.4682  Acc@1: 75.0000 (80.6787)  Acc@5: 100.0000 (98.9523)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.7530  Acc@1: 75.0000 (80.6616)  Acc@5: 100.0000 (98.9539)  time: 0.3487  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.2795  Acc@1: 75.0000 (80.6518)  Acc@5: 100.0000 (98.9555)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.8391  Acc@1: 75.0000 (80.6469)  Acc@5: 100.0000 (98.9571)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.0824  Acc@1: 75.0000 (80.6205)  Acc@5: 100.0000 (98.9563)  time: 0.3490  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.7309  Acc@1: 81.2500 (80.6252)  Acc@5: 100.0000 (98.9579)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.9745  Acc@1: 81.2500 (80.6371)  Acc@5: 100.0000 (98.9571)  time: 0.3479  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.7202  Acc@1: 81.2500 (80.6134)  Acc@5: 100.0000 (98.9516)  time: 0.3476  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.6842  Acc@1: 81.2500 (80.6205)  Acc@5: 100.0000 (98.9485)  time: 0.3473  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.8315  Acc@1: 81.2500 (80.6205)  Acc@5: 100.0000 (98.9454)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.6085  Acc@1: 81.2500 (80.6182)  Acc@5: 100.0000 (98.9494)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.8574  Acc@1: 81.2500 (80.6066)  Acc@5: 100.0000 (98.9486)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.8497  Acc@1: 81.2500 (80.6067)  Acc@5: 100.0000 (98.9502)  time: 0.3470  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.9760  Acc@1: 81.2500 (80.6183)  Acc@5: 100.0000 (98.9541)  time: 0.3525  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.8178  Acc@1: 81.2500 (80.6275)  Acc@5: 100.0000 (98.9533)  time: 0.3535  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.4513  Acc@1: 81.2500 (80.6252)  Acc@5: 100.0000 (98.9572)  time: 0.3485  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.8516  Acc@1: 81.2500 (80.6298)  Acc@5: 100.0000 (98.9587)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.6772  Acc@1: 81.2500 (80.6321)  Acc@5: 100.0000 (98.9557)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.4681  Acc@1: 81.2500 (80.6252)  Acc@5: 100.0000 (98.9549)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.7475  Acc@1: 81.2500 (80.6275)  Acc@5: 100.0000 (98.9587)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.7836  Acc@1: 81.2500 (80.6297)  Acc@5: 100.0000 (98.9625)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -1.0007  Acc@1: 81.2500 (80.6297)  Acc@5: 100.0000 (98.9640)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.5921  Acc@1: 81.2500 (80.6207)  Acc@5: 100.0000 (98.9677)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.4043  Acc@1: 81.2500 (80.6185)  Acc@5: 100.0000 (98.9669)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.7674  Acc@1: 81.2500 (80.6163)  Acc@5: 100.0000 (98.9639)  time: 0.3476  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.8782  Acc@1: 81.2500 (80.6208)  Acc@5: 100.0000 (98.9653)  time: 0.3494  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.7041  Acc@1: 81.2500 (80.6252)  Acc@5: 100.0000 (98.9668)  time: 0.3487  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.7908  Acc@1: 81.2500 (80.6186)  Acc@5: 100.0000 (98.9660)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.8317  Acc@1: 81.2500 (80.6230)  Acc@5: 100.0000 (98.9675)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.6287  Acc@1: 81.2500 (80.6274)  Acc@5: 100.0000 (98.9667)  time: 0.3506  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.4791  Acc@1: 81.2500 (80.6317)  Acc@5: 100.0000 (98.9681)  time: 0.3504  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.9497  Acc@1: 81.2500 (80.6317)  Acc@5: 100.0000 (98.9652)  time: 0.3484  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.9115  Acc@1: 81.2500 (80.6490)  Acc@5: 100.0000 (98.9666)  time: 0.3489  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.5430  Acc@1: 81.2500 (80.6618)  Acc@5: 100.0000 (98.9616)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6593  Acc@1: 87.5000 (80.6767)  Acc@5: 100.0000 (98.9630)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -1.0437  Acc@1: 81.2500 (80.6787)  Acc@5: 100.0000 (98.9623)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.3122  Acc@1: 75.0000 (80.6785)  Acc@5: 100.0000 (98.9615)  time: 0.3472  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.6023  Acc@1: 75.0000 (80.6741)  Acc@5: 100.0000 (98.9608)  time: 0.3478  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.8083  Acc@1: 81.2500 (80.6887)  Acc@5: 100.0000 (98.9622)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.7801  Acc@1: 87.5000 (80.7054)  Acc@5: 100.0000 (98.9615)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.8075  Acc@1: 81.2500 (80.6904)  Acc@5: 100.0000 (98.9629)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.8693  Acc@1: 81.2500 (80.7007)  Acc@5: 100.0000 (98.9622)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.6195  Acc@1: 87.5000 (80.7192)  Acc@5: 100.0000 (98.9636)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.6817  Acc@1: 87.5000 (80.7273)  Acc@5: 100.0000 (98.9670)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.7976  Acc@1: 87.5000 (80.7435)  Acc@5: 100.0000 (98.9684)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.5613  Acc@1: 87.5000 (80.7349)  Acc@5: 100.0000 (98.9697)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.9027  Acc@1: 81.2500 (80.7324)  Acc@5: 100.0000 (98.9710)  time: 0.3446  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.6451  Acc@1: 81.2500 (80.7321)  Acc@5: 100.0000 (98.9683)  time: 0.3445  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.1396  Acc@1: 81.2500 (80.7358)  Acc@5: 100.0000 (98.9676)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.8992  Acc@1: 81.2500 (80.7395)  Acc@5: 100.0000 (98.9668)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7156  Acc@1: 81.2500 (80.7310)  Acc@5: 100.0000 (98.9682)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.5509  Acc@1: 75.0000 (80.7347)  Acc@5: 100.0000 (98.9675)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.2266  Acc@1: 81.2500 (80.7344)  Acc@5: 100.0000 (98.9688)  time: 0.3482  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.6258  Acc@1: 81.2500 (80.7381)  Acc@5: 100.0000 (98.9681)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.6359  Acc@1: 81.2500 (80.7357)  Acc@5: 100.0000 (98.9654)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.4144  Acc@1: 81.2500 (80.7353)  Acc@5: 100.0000 (98.9667)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.5808  Acc@1: 81.2500 (80.7270)  Acc@5: 100.0000 (98.9620)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: 0.0680  Acc@1: 81.2500 (80.7267)  Acc@5: 100.0000 (98.9613)  time: 0.3486  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.5989  Acc@1: 81.2500 (80.7244)  Acc@5: 100.0000 (98.9626)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.6872  Acc@1: 81.2500 (80.7280)  Acc@5: 100.0000 (98.9600)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.3281  Acc@1: 81.2500 (80.7119)  Acc@5: 100.0000 (98.9593)  time: 0.3503  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.4914  Acc@1: 75.0000 (80.7156)  Acc@5: 100.0000 (98.9606)  time: 0.3491  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.9019  Acc@1: 81.2500 (80.7173)  Acc@5: 100.0000 (98.9600)  time: 0.3480  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.3104  Acc@1: 81.2500 (80.7209)  Acc@5: 100.0000 (98.9613)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.7937  Acc@1: 87.5000 (80.7264)  Acc@5: 100.0000 (98.9606)  time: 0.3491  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.4633  Acc@1: 81.2500 (80.7183)  Acc@5: 100.0000 (98.9600)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.8222  Acc@1: 81.2500 (80.7316)  Acc@5: 100.0000 (98.9612)  time: 0.3504  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.6796  Acc@1: 81.2500 (80.7428)  Acc@5: 100.0000 (98.9606)  time: 0.3523  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.4844  Acc@1: 81.2500 (80.7329)  Acc@5: 100.0000 (98.9638)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.4610  Acc@1: 75.0000 (80.7268)  Acc@5: 100.0000 (98.9650)  time: 0.3532  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.9577  Acc@1: 81.2500 (80.7437)  Acc@5: 100.0000 (98.9644)  time: 0.3506  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.6696  Acc@1: 81.2500 (80.7490)  Acc@5: 100.0000 (98.9637)  time: 0.3479  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.7221  Acc@1: 81.2500 (80.7429)  Acc@5: 100.0000 (98.9650)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.6865  Acc@1: 81.2500 (80.7407)  Acc@5: 100.0000 (98.9643)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.7425  Acc@1: 81.2500 (80.7252)  Acc@5: 100.0000 (98.9542)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.5174  Acc@1: 75.0000 (80.7174)  Acc@5: 100.0000 (98.9517)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.8038  Acc@1: 75.0000 (80.7134)  Acc@5: 100.0000 (98.9511)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.8422  Acc@1: 81.2500 (80.7169)  Acc@5: 100.0000 (98.9524)  time: 0.3494  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6347  Acc@1: 75.0000 (80.7091)  Acc@5: 100.0000 (98.9518)  time: 0.3503  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.3751  Acc@1: 81.2500 (80.7107)  Acc@5: 100.0000 (98.9531)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.5977  Acc@1: 81.2500 (80.6993)  Acc@5: 100.0000 (98.9525)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.1067  Acc@1: 75.0000 (80.6843)  Acc@5: 100.0000 (98.9463)  time: 0.3486  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.7442  Acc@1: 81.2500 (80.6915)  Acc@5: 100.0000 (98.9494)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.9036  Acc@1: 81.2500 (80.6969)  Acc@5: 100.0000 (98.9470)  time: 0.3466  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6253  Acc@1: 81.2500 (80.6930)  Acc@5: 100.0000 (98.9464)  time: 0.3465  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.6225  Acc@1: 81.2500 (80.7056)  Acc@5: 100.0000 (98.9458)  time: 0.3462  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8806  Acc@1: 81.2500 (80.7072)  Acc@5: 100.0000 (98.9489)  time: 0.3462  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6245  Acc@1: 81.2500 (80.7214)  Acc@5: 100.0000 (98.9520)  time: 0.3472  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8035  Acc@1: 81.2500 (80.7230)  Acc@5: 100.0000 (98.9514)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.4330  Acc@1: 81.2500 (80.7191)  Acc@5: 100.0000 (98.9526)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7328  Acc@1: 75.0000 (80.7062)  Acc@5: 100.0000 (98.9502)  time: 0.3464  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.3946  Acc@1: 75.0000 (80.7078)  Acc@5: 100.0000 (98.9515)  time: 0.3461  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.7718  Acc@1: 81.2500 (80.7093)  Acc@5: 100.0000 (98.9527)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.6892  Acc@1: 81.2500 (80.7037)  Acc@5: 100.0000 (98.9539)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.7528  Acc@1: 75.0000 (80.6893)  Acc@5: 100.0000 (98.9515)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7336  Acc@1: 75.0000 (80.6909)  Acc@5: 100.0000 (98.9545)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.5326  Acc@1: 81.2500 (80.6854)  Acc@5: 100.0000 (98.9557)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.8955  Acc@1: 81.2500 (80.6781)  Acc@5: 100.0000 (98.9480)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.9451  Acc@1: 81.2500 (80.6762)  Acc@5: 100.0000 (98.9475)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.2868  Acc@1: 81.2500 (80.6743)  Acc@5: 100.0000 (98.9452)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.8113  Acc@1: 81.2500 (80.6689)  Acc@5: 100.0000 (98.9446)  time: 0.3506  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: 0.1104  Acc@1: 75.0000 (80.6479)  Acc@5: 100.0000 (98.9441)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6086  Acc@1: 81.2500 (80.6565)  Acc@5: 100.0000 (98.9470)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8423  Acc@1: 81.2500 (80.6529)  Acc@5: 100.0000 (98.9482)  time: 0.3519  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.4926  Acc@1: 81.2500 (80.6390)  Acc@5: 100.0000 (98.9477)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4928  Acc@1: 75.0000 (80.6234)  Acc@5: 100.0000 (98.9488)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.5503  Acc@1: 81.2500 (80.6286)  Acc@5: 100.0000 (98.9483)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.4776  Acc@1: 81.2500 (80.6286)  Acc@5: 100.0000 (98.9512)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7514  Acc@1: 81.2500 (80.6320)  Acc@5: 100.0000 (98.9523)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.7856  Acc@1: 81.2500 (80.6303)  Acc@5: 100.0000 (98.9518)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5886  Acc@1: 81.2500 (80.6388)  Acc@5: 100.0000 (98.9546)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6353  Acc@1: 81.2500 (80.6303)  Acc@5: 100.0000 (98.9524)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.1562  Acc@1: 87.5000 (80.6421)  Acc@5: 100.0000 (98.9535)  time: 0.3538  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2251  Acc@1: 81.2500 (80.6336)  Acc@5: 100.0000 (98.9530)  time: 0.3489  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.4484  Acc@1: 75.0000 (80.6184)  Acc@5: 100.0000 (98.9491)  time: 0.3518  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7035  Acc@1: 81.2500 (80.6268)  Acc@5: 100.0000 (98.9519)  time: 0.3502  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.6734  Acc@1: 81.2500 (80.6118)  Acc@5: 100.0000 (98.9497)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7202  Acc@1: 81.2500 (80.6268)  Acc@5: 100.0000 (98.9491)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7593  Acc@1: 81.2500 (80.6317)  Acc@5: 100.0000 (98.9500)  time: 0.3459  data: 0.0015  max mem: 2503
Train: Epoch[5/5] Total time: 0:21:47 (0.3486 s / it)
{0: {0: 0, 1: 0, 2: 249872, 3: 0, 4: 0}, 1: {0: 366237, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 3: {0: 0, 1: 299984, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 16, 3: 0, 4: 0}, 5: {0: 32, 1: 0, 2: 32, 3: 91309, 4: 0}, 6: {0: 366253, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 91053, 4: 300000}, 8: {0: 366269, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 249888, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 80, 3: 16, 4: 299968}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 366205, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 14: {0: 0, 1: 16, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 249936, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 128, 3: 48, 4: 300000}, 18: {0: 16, 1: 0, 2: 0, 3: 91197, 4: 32}, 19: {0: 128, 1: 0, 2: 48, 3: 352, 4: 300000}}
Averaged stats: Lr: 0.001875  Loss: -0.7593  Acc@1: 81.2500 (80.6317)  Acc@5: 100.0000 (98.9500)
Test: [Task 1]  [   0/1627]  eta: 0:13:50  Loss: 1.3465 (1.3465)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5106  data: 0.2881  max mem: 2503
Test: [Task 1]  [  10/1627]  eta: 0:06:29  Loss: 1.3247 (1.2110)  Acc@1: 62.5000 (63.6364)  Acc@5: 93.7500 (90.9091)  time: 0.2407  data: 0.0264  max mem: 2503
Test: [Task 1]  [  20/1627]  eta: 0:06:05  Loss: 1.2246 (1.1868)  Acc@1: 62.5000 (66.6667)  Acc@5: 93.7500 (91.0714)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [  30/1627]  eta: 0:05:56  Loss: 1.1265 (1.1855)  Acc@1: 68.7500 (67.3387)  Acc@5: 93.7500 (90.7258)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [  40/1627]  eta: 0:05:50  Loss: 1.2472 (1.2082)  Acc@1: 68.7500 (66.4634)  Acc@5: 87.5000 (90.3963)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 1]  [  50/1627]  eta: 0:05:46  Loss: 1.2009 (1.1812)  Acc@1: 68.7500 (67.5245)  Acc@5: 93.7500 (91.0539)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [  60/1627]  eta: 0:05:44  Loss: 1.2350 (1.2045)  Acc@1: 68.7500 (67.0082)  Acc@5: 93.7500 (90.5738)  time: 0.2173  data: 0.0008  max mem: 2503
Test: [Task 1]  [  70/1627]  eta: 0:05:41  Loss: 1.1655 (1.1955)  Acc@1: 68.7500 (67.3415)  Acc@5: 93.7500 (91.0211)  time: 0.2176  data: 0.0008  max mem: 2503
Test: [Task 1]  [  80/1627]  eta: 0:05:38  Loss: 0.9485 (1.1841)  Acc@1: 68.7500 (67.9012)  Acc@5: 93.7500 (91.5123)  time: 0.2165  data: 0.0005  max mem: 2503
Test: [Task 1]  [  90/1627]  eta: 0:05:35  Loss: 1.1286 (1.1972)  Acc@1: 62.5000 (67.5137)  Acc@5: 93.7500 (91.2088)  time: 0.2164  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 100/1627]  eta: 0:05:33  Loss: 1.2803 (1.2164)  Acc@1: 62.5000 (67.2030)  Acc@5: 87.5000 (90.6559)  time: 0.2174  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 110/1627]  eta: 0:05:31  Loss: 1.1057 (1.2039)  Acc@1: 68.7500 (67.5676)  Acc@5: 93.7500 (91.1599)  time: 0.2201  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 120/1627]  eta: 0:05:29  Loss: 1.1307 (1.2031)  Acc@1: 68.7500 (67.6653)  Acc@5: 93.7500 (91.1674)  time: 0.2181  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 130/1627]  eta: 0:05:26  Loss: 1.2285 (1.2065)  Acc@1: 68.7500 (67.4141)  Acc@5: 93.7500 (91.1260)  time: 0.2141  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 140/1627]  eta: 0:05:23  Loss: 1.1647 (1.1995)  Acc@1: 62.5000 (67.5532)  Acc@5: 93.7500 (91.0904)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 150/1627]  eta: 0:05:21  Loss: 0.8633 (1.1804)  Acc@1: 75.0000 (68.2119)  Acc@5: 93.7500 (91.3907)  time: 0.2136  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 160/1627]  eta: 0:05:18  Loss: 0.8967 (1.1749)  Acc@1: 75.0000 (68.4394)  Acc@5: 100.0000 (91.5373)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 170/1627]  eta: 0:05:16  Loss: 0.9915 (1.1649)  Acc@1: 75.0000 (68.7135)  Acc@5: 93.7500 (91.6667)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 180/1627]  eta: 0:05:13  Loss: 1.2134 (1.1766)  Acc@1: 68.7500 (68.4047)  Acc@5: 87.5000 (91.4019)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 190/1627]  eta: 0:05:11  Loss: 1.1949 (1.1734)  Acc@1: 68.7500 (68.3901)  Acc@5: 87.5000 (91.3613)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 200/1627]  eta: 0:05:08  Loss: 1.1322 (1.1722)  Acc@1: 68.7500 (68.5634)  Acc@5: 93.7500 (91.4179)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 210/1627]  eta: 0:05:06  Loss: 1.1322 (1.1706)  Acc@1: 68.7500 (68.6908)  Acc@5: 93.7500 (91.4692)  time: 0.2131  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 220/1627]  eta: 0:05:04  Loss: 1.0146 (1.1738)  Acc@1: 68.7500 (68.7217)  Acc@5: 93.7500 (91.3744)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 230/1627]  eta: 0:05:02  Loss: 1.0146 (1.1650)  Acc@1: 75.0000 (69.1017)  Acc@5: 93.7500 (91.5584)  time: 0.2153  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 240/1627]  eta: 0:05:00  Loss: 1.0045 (1.1613)  Acc@1: 75.0000 (69.1131)  Acc@5: 93.7500 (91.5456)  time: 0.2186  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 250/1627]  eta: 0:04:57  Loss: 1.0643 (1.1661)  Acc@1: 68.7500 (69.1235)  Acc@5: 87.5000 (91.4841)  time: 0.2186  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 260/1627]  eta: 0:04:55  Loss: 1.0714 (1.1664)  Acc@1: 68.7500 (69.2289)  Acc@5: 93.7500 (91.4751)  time: 0.2163  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 270/1627]  eta: 0:04:53  Loss: 0.9814 (1.1592)  Acc@1: 75.0000 (69.3727)  Acc@5: 93.7500 (91.6513)  time: 0.2164  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 280/1627]  eta: 0:04:51  Loss: 0.9696 (1.1606)  Acc@1: 75.0000 (69.3950)  Acc@5: 93.7500 (91.6148)  time: 0.2183  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 290/1627]  eta: 0:04:49  Loss: 1.1809 (1.1605)  Acc@1: 68.7500 (69.4373)  Acc@5: 93.7500 (91.6452)  time: 0.2206  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 300/1627]  eta: 0:04:47  Loss: 1.1167 (1.1585)  Acc@1: 75.0000 (69.4975)  Acc@5: 93.7500 (91.6736)  time: 0.2186  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 310/1627]  eta: 0:04:45  Loss: 1.1217 (1.1608)  Acc@1: 68.7500 (69.3931)  Acc@5: 93.7500 (91.7002)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 320/1627]  eta: 0:04:42  Loss: 1.1279 (1.1592)  Acc@1: 68.7500 (69.3536)  Acc@5: 93.7500 (91.7251)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 330/1627]  eta: 0:04:40  Loss: 1.0195 (1.1578)  Acc@1: 68.7500 (69.4109)  Acc@5: 93.7500 (91.7674)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 340/1627]  eta: 0:04:38  Loss: 1.0195 (1.1575)  Acc@1: 68.7500 (69.4648)  Acc@5: 93.7500 (91.8072)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 350/1627]  eta: 0:04:36  Loss: 1.0752 (1.1567)  Acc@1: 75.0000 (69.5513)  Acc@5: 93.7500 (91.7201)  time: 0.2148  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 360/1627]  eta: 0:04:33  Loss: 1.1165 (1.1555)  Acc@1: 75.0000 (69.6330)  Acc@5: 93.7500 (91.6898)  time: 0.2138  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 1.1041 (1.1550)  Acc@1: 68.7500 (69.4912)  Acc@5: 93.7500 (91.7790)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 380/1627]  eta: 0:04:29  Loss: 1.0771 (1.1538)  Acc@1: 68.7500 (69.4718)  Acc@5: 93.7500 (91.7815)  time: 0.2135  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 390/1627]  eta: 0:04:27  Loss: 1.1023 (1.1557)  Acc@1: 68.7500 (69.4214)  Acc@5: 93.7500 (91.7359)  time: 0.2136  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 400/1627]  eta: 0:04:24  Loss: 1.1817 (1.1569)  Acc@1: 62.5000 (69.3111)  Acc@5: 93.7500 (91.7706)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 410/1627]  eta: 0:04:22  Loss: 1.1189 (1.1579)  Acc@1: 68.7500 (69.3127)  Acc@5: 93.7500 (91.7275)  time: 0.2154  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 420/1627]  eta: 0:04:20  Loss: 1.0611 (1.1572)  Acc@1: 68.7500 (69.2993)  Acc@5: 93.7500 (91.7904)  time: 0.2178  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 430/1627]  eta: 0:04:18  Loss: 1.0486 (1.1557)  Acc@1: 68.7500 (69.2720)  Acc@5: 93.7500 (91.8503)  time: 0.2173  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 440/1627]  eta: 0:04:16  Loss: 1.1422 (1.1551)  Acc@1: 68.7500 (69.3169)  Acc@5: 93.7500 (91.8934)  time: 0.2162  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 450/1627]  eta: 0:04:14  Loss: 1.2351 (1.1588)  Acc@1: 68.7500 (69.1796)  Acc@5: 93.7500 (91.8237)  time: 0.2159  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 1.1224 (1.1579)  Acc@1: 68.7500 (69.1838)  Acc@5: 93.7500 (91.8520)  time: 0.2189  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 470/1627]  eta: 0:04:10  Loss: 0.9856 (1.1546)  Acc@1: 75.0000 (69.3339)  Acc@5: 93.7500 (91.8524)  time: 0.2192  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 480/1627]  eta: 0:04:07  Loss: 1.1839 (1.1591)  Acc@1: 68.7500 (69.1918)  Acc@5: 93.7500 (91.8139)  time: 0.2150  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 1.1967 (1.1595)  Acc@1: 62.5000 (69.1573)  Acc@5: 93.7500 (91.8024)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 1.0645 (1.1605)  Acc@1: 68.7500 (69.1866)  Acc@5: 93.7500 (91.7540)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 510/1627]  eta: 0:04:01  Loss: 1.1521 (1.1665)  Acc@1: 68.7500 (69.0558)  Acc@5: 93.7500 (91.6830)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 1.2543 (1.1743)  Acc@1: 56.2500 (68.8940)  Acc@5: 87.5000 (91.5787)  time: 0.2130  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 530/1627]  eta: 0:03:56  Loss: 1.1067 (1.1697)  Acc@1: 75.0000 (69.1031)  Acc@5: 87.5000 (91.6314)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 1.1067 (1.1694)  Acc@1: 75.0000 (69.1081)  Acc@5: 93.7500 (91.6128)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 1.2810 (1.1721)  Acc@1: 68.7500 (69.0336)  Acc@5: 93.7500 (91.5721)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 1.3647 (1.1750)  Acc@1: 62.5000 (68.9171)  Acc@5: 93.7500 (91.5887)  time: 0.2136  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 570/1627]  eta: 0:03:48  Loss: 1.1679 (1.1735)  Acc@1: 62.5000 (69.0018)  Acc@5: 93.7500 (91.6046)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 580/1627]  eta: 0:03:45  Loss: 1.1363 (1.1742)  Acc@1: 68.7500 (68.9436)  Acc@5: 87.5000 (91.5663)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 590/1627]  eta: 0:03:43  Loss: 1.1875 (1.1732)  Acc@1: 62.5000 (68.9192)  Acc@5: 93.7500 (91.6349)  time: 0.2166  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 1.1136 (1.1752)  Acc@1: 62.5000 (68.8852)  Acc@5: 93.7500 (91.5973)  time: 0.2169  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 1.1628 (1.1743)  Acc@1: 68.7500 (68.8830)  Acc@5: 93.7500 (91.6428)  time: 0.2157  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 1.1628 (1.1757)  Acc@1: 68.7500 (68.8205)  Acc@5: 93.7500 (91.5962)  time: 0.2160  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 1.0299 (1.1760)  Acc@1: 75.0000 (68.8590)  Acc@5: 93.7500 (91.6105)  time: 0.2182  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 1.0209 (1.1760)  Acc@1: 75.0000 (68.9450)  Acc@5: 93.7500 (91.5854)  time: 0.2216  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 650/1627]  eta: 0:03:30  Loss: 1.0814 (1.1759)  Acc@1: 68.7500 (68.9516)  Acc@5: 93.7500 (91.5995)  time: 0.2196  data: 0.0014  max mem: 2503
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 1.0924 (1.1747)  Acc@1: 68.7500 (69.0242)  Acc@5: 93.7500 (91.6131)  time: 0.2153  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 1.1649 (1.1742)  Acc@1: 75.0000 (69.0760)  Acc@5: 93.7500 (91.5984)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 1.1201 (1.1736)  Acc@1: 68.7500 (69.0988)  Acc@5: 93.7500 (91.5841)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 1.0847 (1.1716)  Acc@1: 75.0000 (69.1932)  Acc@5: 93.7500 (91.6245)  time: 0.2143  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 1.1605 (1.1718)  Acc@1: 75.0000 (69.2136)  Acc@5: 93.7500 (91.6459)  time: 0.2142  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 710/1627]  eta: 0:03:17  Loss: 1.1561 (1.1697)  Acc@1: 68.7500 (69.2686)  Acc@5: 93.7500 (91.6667)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 1.0607 (1.1682)  Acc@1: 75.0000 (69.3135)  Acc@5: 93.7500 (91.6869)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 1.0869 (1.1691)  Acc@1: 68.7500 (69.2544)  Acc@5: 93.7500 (91.6724)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 1.1199 (1.1705)  Acc@1: 68.7500 (69.2476)  Acc@5: 93.7500 (91.6161)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 1.1327 (1.1692)  Acc@1: 68.7500 (69.3076)  Acc@5: 87.5000 (91.6278)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 1.2528 (1.1726)  Acc@1: 68.7500 (69.1771)  Acc@5: 87.5000 (91.5654)  time: 0.2172  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 770/1627]  eta: 0:03:04  Loss: 1.0127 (1.1684)  Acc@1: 68.7500 (69.3174)  Acc@5: 87.5000 (91.6180)  time: 0.2191  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 780/1627]  eta: 0:03:02  Loss: 0.9112 (1.1660)  Acc@1: 75.0000 (69.3982)  Acc@5: 100.0000 (91.6693)  time: 0.2180  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 0.9331 (1.1677)  Acc@1: 75.0000 (69.4374)  Acc@5: 93.7500 (91.6245)  time: 0.2168  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 1.0949 (1.1658)  Acc@1: 68.7500 (69.4679)  Acc@5: 93.7500 (91.6355)  time: 0.2166  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 0.9780 (1.1650)  Acc@1: 75.0000 (69.5361)  Acc@5: 93.7500 (91.6615)  time: 0.2196  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 1.0092 (1.1646)  Acc@1: 75.0000 (69.5113)  Acc@5: 100.0000 (91.6870)  time: 0.2204  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 1.0288 (1.1645)  Acc@1: 68.7500 (69.5171)  Acc@5: 93.7500 (91.6968)  time: 0.2178  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 0.9320 (1.1619)  Acc@1: 75.0000 (69.5675)  Acc@5: 93.7500 (91.7658)  time: 0.2154  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 1.0123 (1.1628)  Acc@1: 75.0000 (69.5285)  Acc@5: 93.7500 (91.7450)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 1.0123 (1.1617)  Acc@1: 68.7500 (69.5630)  Acc@5: 93.7500 (91.7538)  time: 0.2144  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 0.9810 (1.1600)  Acc@1: 68.7500 (69.6254)  Acc@5: 93.7500 (91.7767)  time: 0.2140  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 1.1428 (1.1617)  Acc@1: 62.5000 (69.5446)  Acc@5: 93.7500 (91.7920)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 1.2024 (1.1641)  Acc@1: 62.5000 (69.4515)  Acc@5: 93.7500 (91.7579)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 900/1627]  eta: 0:02:36  Loss: 1.2024 (1.1645)  Acc@1: 62.5000 (69.4229)  Acc@5: 87.5000 (91.7453)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 1.2077 (1.1652)  Acc@1: 68.7500 (69.4498)  Acc@5: 93.7500 (91.7124)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 1.1458 (1.1650)  Acc@1: 68.7500 (69.4422)  Acc@5: 93.7500 (91.7345)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 1.1575 (1.1655)  Acc@1: 62.5000 (69.4079)  Acc@5: 93.7500 (91.7159)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 1.1521 (1.1643)  Acc@1: 62.5000 (69.4208)  Acc@5: 93.7500 (91.7574)  time: 0.2151  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 1.1521 (1.1649)  Acc@1: 62.5000 (69.3809)  Acc@5: 93.7500 (91.7652)  time: 0.2165  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 960/1627]  eta: 0:02:23  Loss: 1.1147 (1.1640)  Acc@1: 68.7500 (69.4199)  Acc@5: 93.7500 (91.7729)  time: 0.2166  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 0.9738 (1.1628)  Acc@1: 68.7500 (69.4580)  Acc@5: 93.7500 (91.7739)  time: 0.2158  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 1.0708 (1.1628)  Acc@1: 68.7500 (69.4890)  Acc@5: 93.7500 (91.7877)  time: 0.2176  data: 0.0018  max mem: 2503
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 1.2343 (1.1661)  Acc@1: 68.7500 (69.4501)  Acc@5: 87.5000 (91.7571)  time: 0.2193  data: 0.0018  max mem: 2503
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.3382 (1.1667)  Acc@1: 68.7500 (69.4431)  Acc@5: 87.5000 (91.7333)  time: 0.2166  data: 0.0006  max mem: 2503
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 1.1880 (1.1667)  Acc@1: 68.7500 (69.4609)  Acc@5: 87.5000 (91.7223)  time: 0.2143  data: 0.0005  max mem: 2503
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 1.1932 (1.1670)  Acc@1: 68.7500 (69.4540)  Acc@5: 87.5000 (91.7116)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 0.9653 (1.1647)  Acc@1: 75.0000 (69.5320)  Acc@5: 93.7500 (91.7435)  time: 0.2136  data: 0.0003  max mem: 2503
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.9157 (1.1636)  Acc@1: 75.0000 (69.5305)  Acc@5: 93.7500 (91.7567)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.9634 (1.1621)  Acc@1: 75.0000 (69.5766)  Acc@5: 93.7500 (91.7935)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 1.1291 (1.1624)  Acc@1: 68.7500 (69.5629)  Acc@5: 93.7500 (91.7943)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.1367 (1.1628)  Acc@1: 68.7500 (69.5320)  Acc@5: 93.7500 (91.7834)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1080/1627]  eta: 0:01:57  Loss: 1.2170 (1.1644)  Acc@1: 62.5000 (69.5016)  Acc@5: 93.7500 (91.7669)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 1.1806 (1.1639)  Acc@1: 68.7500 (69.5062)  Acc@5: 93.7500 (91.7564)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 1.0579 (1.1623)  Acc@1: 68.7500 (69.5561)  Acc@5: 93.7500 (91.7688)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 1.0579 (1.1630)  Acc@1: 75.0000 (69.5770)  Acc@5: 93.7500 (91.7811)  time: 0.2161  data: 0.0005  max mem: 2503
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 1.0716 (1.1643)  Acc@1: 75.0000 (69.5473)  Acc@5: 93.7500 (91.7707)  time: 0.2197  data: 0.0011  max mem: 2503
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 1.0856 (1.1647)  Acc@1: 62.5000 (69.5071)  Acc@5: 93.7500 (91.7717)  time: 0.2185  data: 0.0010  max mem: 2503
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.3665 (1.1663)  Acc@1: 62.5000 (69.4457)  Acc@5: 87.5000 (91.7287)  time: 0.2155  data: 0.0009  max mem: 2503
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 1.4497 (1.1677)  Acc@1: 62.5000 (69.4396)  Acc@5: 87.5000 (91.6866)  time: 0.2173  data: 0.0009  max mem: 2503
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 1.2677 (1.1664)  Acc@1: 68.7500 (69.4875)  Acc@5: 93.7500 (91.7097)  time: 0.2200  data: 0.0008  max mem: 2503
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 1.0926 (1.1654)  Acc@1: 75.0000 (69.5399)  Acc@5: 93.7500 (91.7165)  time: 0.2192  data: 0.0009  max mem: 2503
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 1.1732 (1.1659)  Acc@1: 68.7500 (69.5015)  Acc@5: 87.5000 (91.7125)  time: 0.2156  data: 0.0006  max mem: 2503
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.2133 (1.1662)  Acc@1: 62.5000 (69.4742)  Acc@5: 87.5000 (91.6877)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.2430 (1.1670)  Acc@1: 68.7500 (69.4577)  Acc@5: 87.5000 (91.6528)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 1.0507 (1.1675)  Acc@1: 75.0000 (69.4364)  Acc@5: 93.7500 (91.6237)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 1.0338 (1.1664)  Acc@1: 68.7500 (69.4513)  Acc@5: 93.7500 (91.6513)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 1.0699 (1.1672)  Acc@1: 68.7500 (69.3999)  Acc@5: 93.7500 (91.6328)  time: 0.2136  data: 0.0003  max mem: 2503
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 1.1026 (1.1669)  Acc@1: 68.7500 (69.3997)  Acc@5: 87.5000 (91.6297)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.2914 (1.1674)  Acc@1: 68.7500 (69.3945)  Acc@5: 87.5000 (91.6367)  time: 0.2130  data: 0.0003  max mem: 2503
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.3165 (1.1670)  Acc@1: 68.7500 (69.4142)  Acc@5: 93.7500 (91.6336)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 1]  [1270/1627]  eta: 0:01:16  Loss: 1.2314 (1.1674)  Acc@1: 62.5000 (69.4089)  Acc@5: 93.7500 (91.6257)  time: 0.2130  data: 0.0003  max mem: 2503
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 1.1464 (1.1655)  Acc@1: 68.7500 (69.4770)  Acc@5: 93.7500 (91.6520)  time: 0.2145  data: 0.0004  max mem: 2503
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 1.1245 (1.1658)  Acc@1: 75.0000 (69.4568)  Acc@5: 93.7500 (91.6441)  time: 0.2187  data: 0.0011  max mem: 2503
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.1597 (1.1651)  Acc@1: 68.7500 (69.5042)  Acc@5: 93.7500 (91.6507)  time: 0.2213  data: 0.0016  max mem: 2503
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.9713 (1.1634)  Acc@1: 75.0000 (69.5509)  Acc@5: 93.7500 (91.6667)  time: 0.2182  data: 0.0012  max mem: 2503
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.8196 (1.1621)  Acc@1: 75.0000 (69.6158)  Acc@5: 93.7500 (91.6824)  time: 0.2165  data: 0.0017  max mem: 2503
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.9650 (1.1619)  Acc@1: 75.0000 (69.6140)  Acc@5: 93.7500 (91.6745)  time: 0.2191  data: 0.0020  max mem: 2503
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 1.0843 (1.1625)  Acc@1: 68.7500 (69.6076)  Acc@5: 93.7500 (91.6713)  time: 0.2201  data: 0.0011  max mem: 2503
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 1.0589 (1.1620)  Acc@1: 68.7500 (69.6151)  Acc@5: 93.7500 (91.6682)  time: 0.2171  data: 0.0006  max mem: 2503
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 1.0986 (1.1617)  Acc@1: 68.7500 (69.6179)  Acc@5: 87.5000 (91.6651)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 1.0636 (1.1612)  Acc@1: 68.7500 (69.6070)  Acc@5: 93.7500 (91.6758)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.0636 (1.1616)  Acc@1: 68.7500 (69.5918)  Acc@5: 93.7500 (91.6546)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.2619 (1.1612)  Acc@1: 68.7500 (69.6172)  Acc@5: 87.5000 (91.6517)  time: 0.2144  data: 0.0004  max mem: 2503
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 1.1212 (1.1613)  Acc@1: 75.0000 (69.6244)  Acc@5: 93.7500 (91.6488)  time: 0.2147  data: 0.0004  max mem: 2503
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 1.0796 (1.1611)  Acc@1: 68.7500 (69.6403)  Acc@5: 93.7500 (91.6504)  time: 0.2148  data: 0.0004  max mem: 2503
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 1.0796 (1.1602)  Acc@1: 68.7500 (69.6473)  Acc@5: 93.7500 (91.6696)  time: 0.2143  data: 0.0004  max mem: 2503
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.2628 (1.1620)  Acc@1: 68.7500 (69.6454)  Acc@5: 93.7500 (91.6274)  time: 0.2148  data: 0.0004  max mem: 2503
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.2802 (1.1619)  Acc@1: 68.7500 (69.6175)  Acc@5: 87.5000 (91.6204)  time: 0.2150  data: 0.0008  max mem: 2503
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.2454 (1.1629)  Acc@1: 68.7500 (69.5899)  Acc@5: 87.5000 (91.5963)  time: 0.2143  data: 0.0007  max mem: 2503
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.2077 (1.1631)  Acc@1: 68.7500 (69.6141)  Acc@5: 87.5000 (91.5982)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 1.1194 (1.1629)  Acc@1: 68.7500 (69.6210)  Acc@5: 93.7500 (91.6044)  time: 0.2137  data: 0.0004  max mem: 2503
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.1187 (1.1631)  Acc@1: 68.7500 (69.6109)  Acc@5: 93.7500 (91.6104)  time: 0.2136  data: 0.0004  max mem: 2503
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.1082 (1.1635)  Acc@1: 68.7500 (69.6051)  Acc@5: 93.7500 (91.6122)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.1082 (1.1635)  Acc@1: 68.7500 (69.6161)  Acc@5: 93.7500 (91.6139)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.0266 (1.1636)  Acc@1: 68.7500 (69.6186)  Acc@5: 93.7500 (91.6157)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.0250 (1.1625)  Acc@1: 75.0000 (69.6540)  Acc@5: 93.7500 (91.6338)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 1.0234 (1.1620)  Acc@1: 68.7500 (69.6604)  Acc@5: 93.7500 (91.6435)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 1.0293 (1.1611)  Acc@1: 68.7500 (69.6828)  Acc@5: 93.7500 (91.6734)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 1.0293 (1.1609)  Acc@1: 68.7500 (69.7010)  Acc@5: 93.7500 (91.6788)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.9405 (1.1598)  Acc@1: 75.0000 (69.7670)  Acc@5: 93.7500 (91.6880)  time: 0.2138  data: 0.0004  max mem: 2503
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.9405 (1.1600)  Acc@1: 75.0000 (69.7764)  Acc@5: 93.7500 (91.6773)  time: 0.2144  data: 0.0005  max mem: 2503
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.1096 (1.1600)  Acc@1: 68.7500 (69.7857)  Acc@5: 93.7500 (91.6825)  time: 0.2150  data: 0.0008  max mem: 2503
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 1.1523 (1.1601)  Acc@1: 68.7500 (69.7832)  Acc@5: 93.7500 (91.6955)  time: 0.2160  data: 0.0013  max mem: 2503
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.1873 (1.1614)  Acc@1: 68.7500 (69.7377)  Acc@5: 87.5000 (91.6771)  time: 0.2155  data: 0.0011  max mem: 2503
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.2512 (1.1610)  Acc@1: 68.7500 (69.7393)  Acc@5: 87.5000 (91.6744)  time: 0.2151  data: 0.0006  max mem: 2503
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.9894 (1.1598)  Acc@1: 75.0000 (69.7833)  Acc@5: 93.7500 (91.6872)  time: 0.2150  data: 0.0004  max mem: 2503
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9895 (1.1592)  Acc@1: 75.0000 (69.8026)  Acc@5: 93.7500 (91.6910)  time: 0.2148  data: 0.0004  max mem: 2503
Test: [Task 1] Total time: 0:05:50 (0.2157 s / it)
* Acc@1 69.803 Acc@5 91.691 loss 1.159
Test: [Task 2]  [  0/625]  eta: 0:06:42  Loss: 0.3752 (0.3752)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6434  data: 0.4296  max mem: 2503
Test: [Task 2]  [ 10/625]  eta: 0:02:37  Loss: 0.3771 (0.4454)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.2569  data: 0.0405  max mem: 2503
Test: [Task 2]  [ 20/625]  eta: 0:02:24  Loss: 0.3695 (0.4099)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (99.4048)  time: 0.2178  data: 0.0016  max mem: 2503
Test: [Task 2]  [ 30/625]  eta: 0:02:17  Loss: 0.3656 (0.4515)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.9919)  time: 0.2174  data: 0.0013  max mem: 2503
Test: [Task 2]  [ 40/625]  eta: 0:02:13  Loss: 0.4822 (0.4634)  Acc@1: 81.2500 (86.4329)  Acc@5: 100.0000 (98.9329)  time: 0.2168  data: 0.0011  max mem: 2503
Test: [Task 2]  [ 50/625]  eta: 0:02:09  Loss: 0.5241 (0.4785)  Acc@1: 81.2500 (85.6618)  Acc@5: 100.0000 (98.8971)  time: 0.2156  data: 0.0013  max mem: 2503
Test: [Task 2]  [ 60/625]  eta: 0:02:06  Loss: 0.5241 (0.4777)  Acc@1: 81.2500 (85.8607)  Acc@5: 100.0000 (98.7705)  time: 0.2157  data: 0.0010  max mem: 2503
Test: [Task 2]  [ 70/625]  eta: 0:02:03  Loss: 0.4340 (0.4754)  Acc@1: 87.5000 (86.0035)  Acc@5: 100.0000 (98.7676)  time: 0.2157  data: 0.0009  max mem: 2503
Test: [Task 2]  [ 80/625]  eta: 0:02:00  Loss: 0.4766 (0.4849)  Acc@1: 81.2500 (85.5710)  Acc@5: 100.0000 (98.6111)  time: 0.2152  data: 0.0010  max mem: 2503
Test: [Task 2]  [ 90/625]  eta: 0:01:58  Loss: 0.4766 (0.4792)  Acc@1: 81.2500 (85.6456)  Acc@5: 100.0000 (98.6264)  time: 0.2150  data: 0.0008  max mem: 2503
Test: [Task 2]  [100/625]  eta: 0:01:55  Loss: 0.4299 (0.4731)  Acc@1: 87.5000 (85.4579)  Acc@5: 100.0000 (98.7005)  time: 0.2145  data: 0.0005  max mem: 2503
Test: [Task 2]  [110/625]  eta: 0:01:53  Loss: 0.4085 (0.4764)  Acc@1: 81.2500 (85.3041)  Acc@5: 100.0000 (98.6486)  time: 0.2143  data: 0.0005  max mem: 2503
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.4039 (0.4752)  Acc@1: 87.5000 (85.3306)  Acc@5: 100.0000 (98.6570)  time: 0.2148  data: 0.0008  max mem: 2503
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.4187 (0.4810)  Acc@1: 87.5000 (84.9714)  Acc@5: 100.0000 (98.7595)  time: 0.2150  data: 0.0007  max mem: 2503
Test: [Task 2]  [140/625]  eta: 0:01:46  Loss: 0.4957 (0.4830)  Acc@1: 87.5000 (85.0621)  Acc@5: 100.0000 (98.6702)  time: 0.2151  data: 0.0006  max mem: 2503
Test: [Task 2]  [150/625]  eta: 0:01:43  Loss: 0.5027 (0.4886)  Acc@1: 81.2500 (84.8096)  Acc@5: 100.0000 (98.7169)  time: 0.2157  data: 0.0007  max mem: 2503
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.4818 (0.4931)  Acc@1: 81.2500 (84.5109)  Acc@5: 100.0000 (98.6413)  time: 0.2157  data: 0.0006  max mem: 2503
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.4636 (0.4941)  Acc@1: 81.2500 (84.4298)  Acc@5: 100.0000 (98.6111)  time: 0.2159  data: 0.0006  max mem: 2503
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.4501 (0.4942)  Acc@1: 81.2500 (84.3577)  Acc@5: 100.0000 (98.6533)  time: 0.2176  data: 0.0010  max mem: 2503
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.4501 (0.4954)  Acc@1: 81.2500 (84.4241)  Acc@5: 100.0000 (98.6257)  time: 0.2175  data: 0.0011  max mem: 2503
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.4590 (0.4935)  Acc@1: 81.2500 (84.3284)  Acc@5: 100.0000 (98.6318)  time: 0.2155  data: 0.0007  max mem: 2503
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.4420 (0.4940)  Acc@1: 81.2500 (84.2121)  Acc@5: 100.0000 (98.6374)  time: 0.2153  data: 0.0006  max mem: 2503
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.4398 (0.4892)  Acc@1: 81.2500 (84.4740)  Acc@5: 100.0000 (98.6425)  time: 0.2150  data: 0.0006  max mem: 2503
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 0.4332 (0.4880)  Acc@1: 87.5000 (84.4697)  Acc@5: 100.0000 (98.7013)  time: 0.2139  data: 0.0004  max mem: 2503
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.4777 (0.4886)  Acc@1: 87.5000 (84.5436)  Acc@5: 100.0000 (98.7552)  time: 0.2141  data: 0.0005  max mem: 2503
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.5551 (0.4909)  Acc@1: 87.5000 (84.5120)  Acc@5: 100.0000 (98.6803)  time: 0.2142  data: 0.0006  max mem: 2503
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.5551 (0.4922)  Acc@1: 81.2500 (84.4588)  Acc@5: 100.0000 (98.6830)  time: 0.2147  data: 0.0005  max mem: 2503
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.5555 (0.4952)  Acc@1: 81.2500 (84.3865)  Acc@5: 100.0000 (98.6624)  time: 0.2158  data: 0.0008  max mem: 2503
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 0.5624 (0.4959)  Acc@1: 81.2500 (84.3194)  Acc@5: 100.0000 (98.6210)  time: 0.2155  data: 0.0008  max mem: 2503
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.5318 (0.4968)  Acc@1: 87.5000 (84.4072)  Acc@5: 100.0000 (98.6469)  time: 0.2147  data: 0.0005  max mem: 2503
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.5436 (0.4963)  Acc@1: 87.5000 (84.3854)  Acc@5: 100.0000 (98.6711)  time: 0.2154  data: 0.0008  max mem: 2503
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.5315 (0.4989)  Acc@1: 81.2500 (84.3047)  Acc@5: 100.0000 (98.6535)  time: 0.2157  data: 0.0008  max mem: 2503
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.3363 (0.4912)  Acc@1: 87.5000 (84.5405)  Acc@5: 100.0000 (98.6955)  time: 0.2149  data: 0.0007  max mem: 2503
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 0.3282 (0.4885)  Acc@1: 87.5000 (84.5921)  Acc@5: 100.0000 (98.7349)  time: 0.2159  data: 0.0011  max mem: 2503
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.2036 (0.4785)  Acc@1: 93.7500 (84.8974)  Acc@5: 100.0000 (98.7720)  time: 0.2165  data: 0.0014  max mem: 2503
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.1808 (0.4716)  Acc@1: 93.7500 (85.1140)  Acc@5: 100.0000 (98.8070)  time: 0.2150  data: 0.0011  max mem: 2503
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.2817 (0.4713)  Acc@1: 87.5000 (85.1108)  Acc@5: 100.0000 (98.8227)  time: 0.2151  data: 0.0008  max mem: 2503
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.3583 (0.4660)  Acc@1: 87.5000 (85.3100)  Acc@5: 100.0000 (98.8544)  time: 0.2154  data: 0.0007  max mem: 2503
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.3598 (0.4678)  Acc@1: 87.5000 (85.3018)  Acc@5: 100.0000 (98.7861)  time: 0.2153  data: 0.0006  max mem: 2503
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 0.3501 (0.4658)  Acc@1: 87.5000 (85.4380)  Acc@5: 100.0000 (98.7372)  time: 0.2166  data: 0.0008  max mem: 2503
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.1993 (0.4596)  Acc@1: 93.7500 (85.6453)  Acc@5: 100.0000 (98.7687)  time: 0.2164  data: 0.0014  max mem: 2503
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.1635 (0.4575)  Acc@1: 93.7500 (85.7056)  Acc@5: 100.0000 (98.7682)  time: 0.2146  data: 0.0010  max mem: 2503
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.2169 (0.4581)  Acc@1: 87.5000 (85.5998)  Acc@5: 100.0000 (98.7827)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.3870 (0.4555)  Acc@1: 87.5000 (85.6439)  Acc@5: 100.0000 (98.8109)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.1893 (0.4496)  Acc@1: 93.7500 (85.8277)  Acc@5: 100.0000 (98.8379)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.1765 (0.4440)  Acc@1: 93.7500 (86.0033)  Acc@5: 100.0000 (98.8636)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.1664 (0.4384)  Acc@1: 93.7500 (86.2120)  Acc@5: 100.0000 (98.8883)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.2704 (0.4380)  Acc@1: 93.7500 (86.1996)  Acc@5: 100.0000 (98.9119)  time: 0.2142  data: 0.0004  max mem: 2503
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.3463 (0.4360)  Acc@1: 87.5000 (86.2526)  Acc@5: 100.0000 (98.9345)  time: 0.2143  data: 0.0004  max mem: 2503
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.2885 (0.4320)  Acc@1: 93.7500 (86.3926)  Acc@5: 100.0000 (98.9562)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.2036 (0.4275)  Acc@1: 93.7500 (86.5644)  Acc@5: 100.0000 (98.9770)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.2432 (0.4276)  Acc@1: 93.7500 (86.5460)  Acc@5: 100.0000 (98.9971)  time: 0.2146  data: 0.0004  max mem: 2503
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.4404 (0.4321)  Acc@1: 81.2500 (86.3364)  Acc@5: 100.0000 (99.0043)  time: 0.2144  data: 0.0004  max mem: 2503
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.3465 (0.4302)  Acc@1: 81.2500 (86.3583)  Acc@5: 100.0000 (99.0231)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.3278 (0.4276)  Acc@1: 93.7500 (86.4256)  Acc@5: 100.0000 (99.0411)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.1755 (0.4225)  Acc@1: 93.7500 (86.6039)  Acc@5: 100.0000 (99.0585)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.1072 (0.4172)  Acc@1: 100.0000 (86.8204)  Acc@5: 100.0000 (99.0753)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.1349 (0.4167)  Acc@1: 100.0000 (86.8433)  Acc@5: 100.0000 (99.0915)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.1743 (0.4121)  Acc@1: 93.7500 (86.9944)  Acc@5: 100.0000 (99.1071)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1878 (0.4102)  Acc@1: 93.7500 (87.0558)  Acc@5: 100.0000 (99.1117)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.3826 (0.4113)  Acc@1: 87.5000 (86.9904)  Acc@5: 100.0000 (99.1161)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.6046 (0.4187)  Acc@1: 75.0000 (86.7124)  Acc@5: 100.0000 (99.1101)  time: 0.2136  data: 0.0003  max mem: 2503
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.5763 (0.4193)  Acc@1: 75.0000 (86.6747)  Acc@5: 100.0000 (99.1143)  time: 0.2136  data: 0.0003  max mem: 2503
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.4647 (0.4194)  Acc@1: 81.2500 (86.6700)  Acc@5: 100.0000 (99.1200)  time: 0.2136  data: 0.0003  max mem: 2503
Test: [Task 2] Total time: 0:02:14 (0.2159 s / it)
* Acc@1 86.670 Acc@5 99.120 loss 0.419
Test: [Task 3]  [  0/625]  eta: 0:05:41  Loss: 0.2822 (0.2822)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5464  data: 0.3338  max mem: 2503
Test: [Task 3]  [ 10/625]  eta: 0:02:29  Loss: 0.2666 (0.2653)  Acc@1: 93.7500 (95.4545)  Acc@5: 100.0000 (98.2955)  time: 0.2438  data: 0.0306  max mem: 2503
Test: [Task 3]  [ 20/625]  eta: 0:02:18  Loss: 0.2467 (0.2817)  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (97.9167)  time: 0.2136  data: 0.0003  max mem: 2503
Test: [Task 3]  [ 30/625]  eta: 0:02:13  Loss: 0.2441 (0.2733)  Acc@1: 93.7500 (95.1613)  Acc@5: 100.0000 (98.5887)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 3]  [ 40/625]  eta: 0:02:09  Loss: 0.1694 (0.2417)  Acc@1: 100.0000 (96.3415)  Acc@5: 100.0000 (98.9329)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 3]  [ 50/625]  eta: 0:02:07  Loss: 0.1682 (0.2360)  Acc@1: 100.0000 (96.4461)  Acc@5: 100.0000 (99.1422)  time: 0.2173  data: 0.0009  max mem: 2503
Test: [Task 3]  [ 60/625]  eta: 0:02:04  Loss: 0.2319 (0.2334)  Acc@1: 100.0000 (96.6189)  Acc@5: 100.0000 (99.2828)  time: 0.2180  data: 0.0015  max mem: 2503
Test: [Task 3]  [ 70/625]  eta: 0:02:02  Loss: 0.1483 (0.2206)  Acc@1: 100.0000 (96.8310)  Acc@5: 100.0000 (99.3838)  time: 0.2165  data: 0.0015  max mem: 2503
Test: [Task 3]  [ 80/625]  eta: 0:01:59  Loss: 0.1625 (0.2259)  Acc@1: 93.7500 (96.5278)  Acc@5: 100.0000 (99.4599)  time: 0.2160  data: 0.0011  max mem: 2503
Test: [Task 3]  [ 90/625]  eta: 0:01:57  Loss: 0.1844 (0.2251)  Acc@1: 93.7500 (96.5659)  Acc@5: 100.0000 (99.4505)  time: 0.2159  data: 0.0009  max mem: 2503
Test: [Task 3]  [100/625]  eta: 0:01:54  Loss: 0.1847 (0.2238)  Acc@1: 100.0000 (96.7203)  Acc@5: 100.0000 (99.4431)  time: 0.2166  data: 0.0008  max mem: 2503
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 0.1847 (0.2182)  Acc@1: 100.0000 (96.9595)  Acc@5: 100.0000 (99.4932)  time: 0.2163  data: 0.0011  max mem: 2503
Test: [Task 3]  [120/625]  eta: 0:01:50  Loss: 0.1778 (0.2189)  Acc@1: 100.0000 (97.0558)  Acc@5: 100.0000 (99.5351)  time: 0.2159  data: 0.0009  max mem: 2503
Test: [Task 3]  [130/625]  eta: 0:01:48  Loss: 0.2031 (0.2188)  Acc@1: 100.0000 (97.1374)  Acc@5: 100.0000 (99.5229)  time: 0.2154  data: 0.0006  max mem: 2503
Test: [Task 3]  [140/625]  eta: 0:01:45  Loss: 0.2331 (0.2259)  Acc@1: 93.7500 (96.9415)  Acc@5: 100.0000 (99.3794)  time: 0.2148  data: 0.0007  max mem: 2503
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 0.2552 (0.2314)  Acc@1: 93.7500 (96.8543)  Acc@5: 100.0000 (99.3377)  time: 0.2156  data: 0.0014  max mem: 2503
Test: [Task 3]  [160/625]  eta: 0:01:41  Loss: 0.1871 (0.2321)  Acc@1: 100.0000 (96.8944)  Acc@5: 100.0000 (99.3012)  time: 0.2166  data: 0.0019  max mem: 2503
Test: [Task 3]  [170/625]  eta: 0:01:39  Loss: 0.1812 (0.2311)  Acc@1: 100.0000 (96.9664)  Acc@5: 100.0000 (99.3421)  time: 0.2166  data: 0.0014  max mem: 2503
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.2344 (0.2349)  Acc@1: 100.0000 (96.7887)  Acc@5: 100.0000 (99.3094)  time: 0.2160  data: 0.0011  max mem: 2503
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.2572 (0.2340)  Acc@1: 93.7500 (96.7605)  Acc@5: 100.0000 (99.3455)  time: 0.2163  data: 0.0010  max mem: 2503
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 0.2572 (0.2370)  Acc@1: 93.7500 (96.6729)  Acc@5: 100.0000 (99.3470)  time: 0.2167  data: 0.0015  max mem: 2503
Test: [Task 3]  [210/625]  eta: 0:01:30  Loss: 0.2101 (0.2389)  Acc@1: 93.7500 (96.6232)  Acc@5: 100.0000 (99.2891)  time: 0.2160  data: 0.0017  max mem: 2503
Test: [Task 3]  [220/625]  eta: 0:01:28  Loss: 0.2101 (0.2415)  Acc@1: 93.7500 (96.4932)  Acc@5: 100.0000 (99.2647)  time: 0.2150  data: 0.0010  max mem: 2503
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.2273 (0.2417)  Acc@1: 93.7500 (96.5368)  Acc@5: 100.0000 (99.2424)  time: 0.2177  data: 0.0015  max mem: 2503
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.1990 (0.2435)  Acc@1: 93.7500 (96.4730)  Acc@5: 100.0000 (99.2220)  time: 0.2191  data: 0.0017  max mem: 2503
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1936 (0.2421)  Acc@1: 100.0000 (96.4890)  Acc@5: 100.0000 (99.2281)  time: 0.2170  data: 0.0012  max mem: 2503
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1578 (0.2406)  Acc@1: 100.0000 (96.5278)  Acc@5: 100.0000 (99.2098)  time: 0.2166  data: 0.0010  max mem: 2503
Test: [Task 3]  [270/625]  eta: 0:01:17  Loss: 0.1607 (0.2394)  Acc@1: 100.0000 (96.5175)  Acc@5: 100.0000 (99.2159)  time: 0.2180  data: 0.0009  max mem: 2503
Test: [Task 3]  [280/625]  eta: 0:01:15  Loss: 0.1663 (0.2382)  Acc@1: 93.7500 (96.5302)  Acc@5: 100.0000 (99.2438)  time: 0.2189  data: 0.0014  max mem: 2503
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.1976 (0.2388)  Acc@1: 93.7500 (96.4777)  Acc@5: 100.0000 (99.2483)  time: 0.2171  data: 0.0013  max mem: 2503
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.1976 (0.2429)  Acc@1: 93.7500 (96.3040)  Acc@5: 100.0000 (99.1902)  time: 0.2159  data: 0.0008  max mem: 2503
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1728 (0.2447)  Acc@1: 100.0000 (96.2822)  Acc@5: 100.0000 (99.1359)  time: 0.2154  data: 0.0006  max mem: 2503
Test: [Task 3]  [320/625]  eta: 0:01:06  Loss: 0.1844 (0.2438)  Acc@1: 100.0000 (96.2812)  Acc@5: 100.0000 (99.1238)  time: 0.2154  data: 0.0006  max mem: 2503
Test: [Task 3]  [330/625]  eta: 0:01:04  Loss: 0.2294 (0.2447)  Acc@1: 93.7500 (96.2236)  Acc@5: 100.0000 (99.1125)  time: 0.2163  data: 0.0011  max mem: 2503
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.1828 (0.2429)  Acc@1: 100.0000 (96.2793)  Acc@5: 100.0000 (99.1202)  time: 0.2158  data: 0.0009  max mem: 2503
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1851 (0.2428)  Acc@1: 100.0000 (96.2607)  Acc@5: 100.0000 (99.1097)  time: 0.2156  data: 0.0011  max mem: 2503
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.2020 (0.2434)  Acc@1: 93.7500 (96.2084)  Acc@5: 100.0000 (99.1170)  time: 0.2155  data: 0.0010  max mem: 2503
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.2156 (0.2441)  Acc@1: 93.7500 (96.1759)  Acc@5: 100.0000 (99.1240)  time: 0.2149  data: 0.0007  max mem: 2503
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.2054 (0.2424)  Acc@1: 93.7500 (96.2270)  Acc@5: 100.0000 (99.1470)  time: 0.2152  data: 0.0007  max mem: 2503
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.1773 (0.2436)  Acc@1: 100.0000 (96.1637)  Acc@5: 100.0000 (99.1528)  time: 0.2150  data: 0.0004  max mem: 2503
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1827 (0.2426)  Acc@1: 93.7500 (96.1347)  Acc@5: 100.0000 (99.1584)  time: 0.2153  data: 0.0008  max mem: 2503
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.2433 (0.2436)  Acc@1: 93.7500 (96.1375)  Acc@5: 100.0000 (99.1484)  time: 0.2152  data: 0.0007  max mem: 2503
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.2433 (0.2430)  Acc@1: 93.7500 (96.1253)  Acc@5: 100.0000 (99.1686)  time: 0.2146  data: 0.0004  max mem: 2503
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1977 (0.2428)  Acc@1: 93.7500 (96.1137)  Acc@5: 100.0000 (99.1589)  time: 0.2144  data: 0.0006  max mem: 2503
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.1998 (0.2440)  Acc@1: 93.7500 (96.0601)  Acc@5: 100.0000 (99.1497)  time: 0.2154  data: 0.0008  max mem: 2503
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.2106 (0.2439)  Acc@1: 93.7500 (96.0920)  Acc@5: 100.0000 (99.1547)  time: 0.2158  data: 0.0007  max mem: 2503
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.2106 (0.2435)  Acc@1: 100.0000 (96.1090)  Acc@5: 100.0000 (99.1594)  time: 0.2158  data: 0.0009  max mem: 2503
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.2227 (0.2429)  Acc@1: 93.7500 (96.1253)  Acc@5: 100.0000 (99.1640)  time: 0.2203  data: 0.0017  max mem: 2503
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.2050 (0.2437)  Acc@1: 93.7500 (96.1149)  Acc@5: 100.0000 (99.1424)  time: 0.2190  data: 0.0013  max mem: 2503
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2385 (0.2440)  Acc@1: 93.7500 (96.1176)  Acc@5: 100.0000 (99.1344)  time: 0.2144  data: 0.0004  max mem: 2503
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2085 (0.2432)  Acc@1: 100.0000 (96.1327)  Acc@5: 100.0000 (99.1517)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.1551 (0.2429)  Acc@1: 100.0000 (96.1228)  Acc@5: 100.0000 (99.1561)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.1942 (0.2430)  Acc@1: 93.7500 (96.1012)  Acc@5: 100.0000 (99.1723)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.2392 (0.2440)  Acc@1: 93.7500 (96.0805)  Acc@5: 100.0000 (99.1879)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2392 (0.2451)  Acc@1: 93.7500 (96.0605)  Acc@5: 100.0000 (99.1567)  time: 0.2146  data: 0.0004  max mem: 2503
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2263 (0.2454)  Acc@1: 100.0000 (96.0753)  Acc@5: 100.0000 (99.1493)  time: 0.2144  data: 0.0004  max mem: 2503
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2288 (0.2453)  Acc@1: 93.7500 (96.0673)  Acc@5: 100.0000 (99.1644)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.2059 (0.2448)  Acc@1: 100.0000 (96.1033)  Acc@5: 100.0000 (99.1681)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.1693 (0.2460)  Acc@1: 100.0000 (96.0736)  Acc@5: 100.0000 (99.1717)  time: 0.2142  data: 0.0004  max mem: 2503
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1981 (0.2454)  Acc@1: 100.0000 (96.1189)  Acc@5: 100.0000 (99.1857)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1943 (0.2452)  Acc@1: 100.0000 (96.1002)  Acc@5: 100.0000 (99.1889)  time: 0.2143  data: 0.0004  max mem: 2503
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1916 (0.2444)  Acc@1: 93.7500 (96.1027)  Acc@5: 100.0000 (99.2021)  time: 0.2144  data: 0.0005  max mem: 2503
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2323 (0.2453)  Acc@1: 93.7500 (96.0749)  Acc@5: 100.0000 (99.1948)  time: 0.2138  data: 0.0004  max mem: 2503
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1975 (0.2446)  Acc@1: 93.7500 (96.0900)  Acc@5: 100.0000 (99.2000)  time: 0.2133  data: 0.0003  max mem: 2503
Test: [Task 3] Total time: 0:02:15 (0.2165 s / it)
* Acc@1 96.090 Acc@5 99.200 loss 0.245
Test: [Task 4]  [ 0/29]  eta: 0:00:14  Loss: 2.0453 (2.0453)  Acc@1: 18.7500 (18.7500)  Acc@5: 87.5000 (87.5000)  time: 0.5066  data: 0.2921  max mem: 2503
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 2.1060 (2.2085)  Acc@1: 43.7500 (38.6364)  Acc@5: 81.2500 (78.9773)  time: 0.2402  data: 0.0268  max mem: 2503
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.9869 (2.0454)  Acc@1: 43.7500 (48.5119)  Acc@5: 81.2500 (79.1667)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.8516 (1.9028)  Acc@1: 62.5000 (52.9412)  Acc@5: 81.2500 (80.3922)  time: 0.2100  data: 0.0002  max mem: 2503
Test: [Task 4] Total time: 0:00:06 (0.2246 s / it)
* Acc@1 52.941 Acc@5 80.392 loss 1.903
Test: [Task 5]  [  0/625]  eta: 0:05:03  Loss: 0.2085 (0.2085)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4849  data: 0.2669  max mem: 2503
Test: [Task 5]  [ 10/625]  eta: 0:02:26  Loss: 0.4484 (0.4720)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (99.4318)  time: 0.2379  data: 0.0245  max mem: 2503
Test: [Task 5]  [ 20/625]  eta: 0:02:16  Loss: 0.4321 (0.4122)  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (99.7024)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 30/625]  eta: 0:02:12  Loss: 0.4403 (0.4475)  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (99.1935)  time: 0.2130  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 40/625]  eta: 0:02:08  Loss: 0.4636 (0.4416)  Acc@1: 87.5000 (89.4817)  Acc@5: 100.0000 (99.2378)  time: 0.2128  data: 0.0002  max mem: 2503
Test: [Task 5]  [ 50/625]  eta: 0:02:05  Loss: 0.4829 (0.4648)  Acc@1: 87.5000 (88.6029)  Acc@5: 100.0000 (98.5294)  time: 0.2127  data: 0.0002  max mem: 2503
Test: [Task 5]  [ 60/625]  eta: 0:02:02  Loss: 0.4706 (0.4584)  Acc@1: 87.5000 (88.5246)  Acc@5: 100.0000 (98.6680)  time: 0.2129  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 70/625]  eta: 0:02:00  Loss: 0.4158 (0.4600)  Acc@1: 87.5000 (88.3803)  Acc@5: 100.0000 (98.5035)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 80/625]  eta: 0:01:57  Loss: 0.4555 (0.4678)  Acc@1: 87.5000 (88.2716)  Acc@5: 100.0000 (98.4568)  time: 0.2131  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 90/625]  eta: 0:01:55  Loss: 0.4308 (0.4596)  Acc@1: 93.7500 (88.6676)  Acc@5: 100.0000 (98.4890)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 5]  [100/625]  eta: 0:01:53  Loss: 0.3774 (0.4678)  Acc@1: 87.5000 (88.3663)  Acc@5: 100.0000 (98.3911)  time: 0.2132  data: 0.0003  max mem: 2503
Test: [Task 5]  [110/625]  eta: 0:01:50  Loss: 0.4646 (0.4680)  Acc@1: 87.5000 (88.2320)  Acc@5: 100.0000 (98.4234)  time: 0.2130  data: 0.0003  max mem: 2503
Test: [Task 5]  [120/625]  eta: 0:01:48  Loss: 0.3651 (0.4602)  Acc@1: 87.5000 (88.3264)  Acc@5: 100.0000 (98.5021)  time: 0.2129  data: 0.0003  max mem: 2503
Test: [Task 5]  [130/625]  eta: 0:01:46  Loss: 0.4448 (0.4664)  Acc@1: 87.5000 (88.1202)  Acc@5: 100.0000 (98.4256)  time: 0.2138  data: 0.0005  max mem: 2503
Test: [Task 5]  [140/625]  eta: 0:01:44  Loss: 0.4939 (0.4650)  Acc@1: 87.5000 (88.0762)  Acc@5: 100.0000 (98.3599)  time: 0.2145  data: 0.0007  max mem: 2503
Test: [Task 5]  [150/625]  eta: 0:01:42  Loss: 0.4074 (0.4667)  Acc@1: 87.5000 (87.9967)  Acc@5: 100.0000 (98.3858)  time: 0.2145  data: 0.0006  max mem: 2503
Test: [Task 5]  [160/625]  eta: 0:01:40  Loss: 0.5110 (0.4728)  Acc@1: 87.5000 (87.7329)  Acc@5: 100.0000 (98.3307)  time: 0.2166  data: 0.0012  max mem: 2503
Test: [Task 5]  [170/625]  eta: 0:01:37  Loss: 0.5293 (0.4805)  Acc@1: 87.5000 (87.4269)  Acc@5: 100.0000 (98.2822)  time: 0.2167  data: 0.0017  max mem: 2503
Test: [Task 5]  [180/625]  eta: 0:01:35  Loss: 0.4865 (0.4828)  Acc@1: 87.5000 (87.5345)  Acc@5: 100.0000 (98.1699)  time: 0.2150  data: 0.0012  max mem: 2503
Test: [Task 5]  [190/625]  eta: 0:01:33  Loss: 0.5575 (0.4961)  Acc@1: 87.5000 (87.2382)  Acc@5: 93.7500 (97.9385)  time: 0.2162  data: 0.0009  max mem: 2503
Test: [Task 5]  [200/625]  eta: 0:01:31  Loss: 0.5575 (0.4938)  Acc@1: 87.5000 (87.3445)  Acc@5: 100.0000 (97.9167)  time: 0.2158  data: 0.0008  max mem: 2503
Test: [Task 5]  [210/625]  eta: 0:01:29  Loss: 0.5590 (0.5006)  Acc@1: 81.2500 (87.2038)  Acc@5: 100.0000 (97.8081)  time: 0.2145  data: 0.0005  max mem: 2503
Test: [Task 5]  [220/625]  eta: 0:01:27  Loss: 0.6030 (0.5012)  Acc@1: 81.2500 (87.2455)  Acc@5: 100.0000 (97.7941)  time: 0.2165  data: 0.0015  max mem: 2503
Test: [Task 5]  [230/625]  eta: 0:01:25  Loss: 0.4618 (0.5006)  Acc@1: 87.5000 (87.2835)  Acc@5: 100.0000 (97.8355)  time: 0.2162  data: 0.0016  max mem: 2503
Test: [Task 5]  [240/625]  eta: 0:01:22  Loss: 0.4618 (0.5010)  Acc@1: 87.5000 (87.2147)  Acc@5: 100.0000 (97.8475)  time: 0.2144  data: 0.0007  max mem: 2503
Test: [Task 5]  [250/625]  eta: 0:01:20  Loss: 0.5151 (0.5036)  Acc@1: 87.5000 (87.1265)  Acc@5: 100.0000 (97.7839)  time: 0.2162  data: 0.0018  max mem: 2503
Test: [Task 5]  [260/625]  eta: 0:01:18  Loss: 0.4855 (0.5036)  Acc@1: 87.5000 (87.0690)  Acc@5: 100.0000 (97.7969)  time: 0.2162  data: 0.0017  max mem: 2503
Test: [Task 5]  [270/625]  eta: 0:01:16  Loss: 0.4157 (0.5022)  Acc@1: 87.5000 (87.0849)  Acc@5: 100.0000 (97.8321)  time: 0.2153  data: 0.0008  max mem: 2503
Test: [Task 5]  [280/625]  eta: 0:01:14  Loss: 0.4053 (0.4994)  Acc@1: 87.5000 (87.1441)  Acc@5: 100.0000 (97.8870)  time: 0.2157  data: 0.0009  max mem: 2503
Test: [Task 5]  [290/625]  eta: 0:01:12  Loss: 0.4431 (0.4978)  Acc@1: 87.5000 (87.1778)  Acc@5: 100.0000 (97.9167)  time: 0.2150  data: 0.0008  max mem: 2503
Test: [Task 5]  [300/625]  eta: 0:01:10  Loss: 0.5147 (0.5010)  Acc@1: 81.2500 (87.1055)  Acc@5: 100.0000 (97.9236)  time: 0.2148  data: 0.0009  max mem: 2503
Test: [Task 5]  [310/625]  eta: 0:01:07  Loss: 0.5416 (0.5009)  Acc@1: 87.5000 (87.0780)  Acc@5: 100.0000 (97.9301)  time: 0.2159  data: 0.0010  max mem: 2503
Test: [Task 5]  [320/625]  eta: 0:01:05  Loss: 0.5073 (0.5012)  Acc@1: 87.5000 (87.0717)  Acc@5: 100.0000 (97.9361)  time: 0.2156  data: 0.0009  max mem: 2503
Test: [Task 5]  [330/625]  eta: 0:01:03  Loss: 0.4310 (0.4998)  Acc@1: 87.5000 (87.1790)  Acc@5: 100.0000 (97.9607)  time: 0.2149  data: 0.0007  max mem: 2503
Test: [Task 5]  [340/625]  eta: 0:01:01  Loss: 0.3668 (0.4958)  Acc@1: 93.7500 (87.3534)  Acc@5: 100.0000 (97.9472)  time: 0.2148  data: 0.0006  max mem: 2503
Test: [Task 5]  [350/625]  eta: 0:00:59  Loss: 0.4386 (0.5019)  Acc@1: 87.5000 (87.1973)  Acc@5: 100.0000 (97.8989)  time: 0.2152  data: 0.0009  max mem: 2503
Test: [Task 5]  [360/625]  eta: 0:00:57  Loss: 0.5103 (0.5004)  Acc@1: 87.5000 (87.2922)  Acc@5: 100.0000 (97.9398)  time: 0.2160  data: 0.0013  max mem: 2503
Test: [Task 5]  [370/625]  eta: 0:00:54  Loss: 0.3935 (0.4981)  Acc@1: 87.5000 (87.3484)  Acc@5: 100.0000 (97.9953)  time: 0.2149  data: 0.0009  max mem: 2503
Test: [Task 5]  [380/625]  eta: 0:00:52  Loss: 0.4453 (0.4991)  Acc@1: 87.5000 (87.3524)  Acc@5: 100.0000 (97.9987)  time: 0.2141  data: 0.0005  max mem: 2503
Test: [Task 5]  [390/625]  eta: 0:00:50  Loss: 0.5160 (0.5008)  Acc@1: 81.2500 (87.1963)  Acc@5: 100.0000 (98.0019)  time: 0.2145  data: 0.0005  max mem: 2503
Test: [Task 5]  [400/625]  eta: 0:00:48  Loss: 0.5267 (0.4999)  Acc@1: 81.2500 (87.1883)  Acc@5: 100.0000 (98.0206)  time: 0.2154  data: 0.0005  max mem: 2503
Test: [Task 5]  [410/625]  eta: 0:00:46  Loss: 0.4606 (0.4996)  Acc@1: 87.5000 (87.1959)  Acc@5: 100.0000 (97.9927)  time: 0.2154  data: 0.0006  max mem: 2503
Test: [Task 5]  [420/625]  eta: 0:00:44  Loss: 0.5198 (0.5007)  Acc@1: 87.5000 (87.0992)  Acc@5: 100.0000 (97.9958)  time: 0.2149  data: 0.0008  max mem: 2503
Test: [Task 5]  [430/625]  eta: 0:00:41  Loss: 0.4295 (0.4996)  Acc@1: 87.5000 (87.1810)  Acc@5: 100.0000 (98.0278)  time: 0.2156  data: 0.0011  max mem: 2503
Test: [Task 5]  [440/625]  eta: 0:00:39  Loss: 0.4147 (0.4997)  Acc@1: 93.7500 (87.1882)  Acc@5: 100.0000 (98.0442)  time: 0.2166  data: 0.0012  max mem: 2503
Test: [Task 5]  [450/625]  eta: 0:00:37  Loss: 0.4381 (0.4988)  Acc@1: 87.5000 (87.1535)  Acc@5: 100.0000 (98.0599)  time: 0.2172  data: 0.0011  max mem: 2503
Test: [Task 5]  [460/625]  eta: 0:00:35  Loss: 0.4729 (0.4983)  Acc@1: 87.5000 (87.1475)  Acc@5: 100.0000 (98.0613)  time: 0.2166  data: 0.0011  max mem: 2503
Test: [Task 5]  [470/625]  eta: 0:00:33  Loss: 0.4151 (0.4951)  Acc@1: 87.5000 (87.2346)  Acc@5: 100.0000 (98.1024)  time: 0.2167  data: 0.0014  max mem: 2503
Test: [Task 5]  [480/625]  eta: 0:00:31  Loss: 0.4109 (0.4956)  Acc@1: 87.5000 (87.2141)  Acc@5: 100.0000 (98.1029)  time: 0.2200  data: 0.0015  max mem: 2503
Test: [Task 5]  [490/625]  eta: 0:00:29  Loss: 0.4518 (0.4954)  Acc@1: 87.5000 (87.2454)  Acc@5: 100.0000 (98.1034)  time: 0.2191  data: 0.0010  max mem: 2503
Test: [Task 5]  [500/625]  eta: 0:00:26  Loss: 0.4518 (0.4958)  Acc@1: 87.5000 (87.1756)  Acc@5: 100.0000 (98.0913)  time: 0.2150  data: 0.0006  max mem: 2503
Test: [Task 5]  [510/625]  eta: 0:00:24  Loss: 0.4918 (0.4960)  Acc@1: 87.5000 (87.1942)  Acc@5: 100.0000 (98.0797)  time: 0.2147  data: 0.0009  max mem: 2503
Test: [Task 5]  [520/625]  eta: 0:00:22  Loss: 0.4618 (0.4948)  Acc@1: 87.5000 (87.2121)  Acc@5: 100.0000 (98.0926)  time: 0.2148  data: 0.0008  max mem: 2503
Test: [Task 5]  [530/625]  eta: 0:00:20  Loss: 0.4218 (0.4930)  Acc@1: 87.5000 (87.2764)  Acc@5: 100.0000 (98.0932)  time: 0.2152  data: 0.0013  max mem: 2503
Test: [Task 5]  [540/625]  eta: 0:00:18  Loss: 0.3763 (0.4912)  Acc@1: 87.5000 (87.3152)  Acc@5: 100.0000 (98.1169)  time: 0.2160  data: 0.0016  max mem: 2503
Test: [Task 5]  [550/625]  eta: 0:00:16  Loss: 0.3770 (0.4934)  Acc@1: 87.5000 (87.2278)  Acc@5: 100.0000 (98.0944)  time: 0.2159  data: 0.0011  max mem: 2503
Test: [Task 5]  [560/625]  eta: 0:00:14  Loss: 0.4067 (0.4933)  Acc@1: 81.2500 (87.1881)  Acc@5: 100.0000 (98.0949)  time: 0.2159  data: 0.0010  max mem: 2503
Test: [Task 5]  [570/625]  eta: 0:00:11  Loss: 0.3855 (0.4923)  Acc@1: 87.5000 (87.2154)  Acc@5: 100.0000 (98.0954)  time: 0.2162  data: 0.0011  max mem: 2503
Test: [Task 5]  [580/625]  eta: 0:00:09  Loss: 0.5164 (0.4936)  Acc@1: 81.2500 (87.1665)  Acc@5: 100.0000 (98.0852)  time: 0.2155  data: 0.0010  max mem: 2503
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 0.5164 (0.4924)  Acc@1: 81.2500 (87.2462)  Acc@5: 100.0000 (98.0859)  time: 0.2152  data: 0.0008  max mem: 2503
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 0.4002 (0.4909)  Acc@1: 93.7500 (87.3232)  Acc@5: 100.0000 (98.0865)  time: 0.2154  data: 0.0011  max mem: 2503
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.3952 (0.4900)  Acc@1: 87.5000 (87.3670)  Acc@5: 100.0000 (98.0872)  time: 0.2150  data: 0.0009  max mem: 2503
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.3552 (0.4882)  Acc@1: 93.7500 (87.4698)  Acc@5: 100.0000 (98.0978)  time: 0.2156  data: 0.0006  max mem: 2503
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.3670 (0.4888)  Acc@1: 93.7500 (87.4100)  Acc@5: 100.0000 (98.1000)  time: 0.2162  data: 0.0006  max mem: 2503
Test: [Task 5] Total time: 0:02:14 (0.2159 s / it)
* Acc@1 87.410 Acc@5 98.100 loss 0.489
{0: {0: 0, 1: 26032, 2: 0, 3: 0, 4: 0, 5: 0, 6: 26032, 7: 0, 8: 26032, 9: 0, 10: 0, 11: 0, 12: 26032, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 10000, 3: 10000, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 10000, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 10000, 1: 16, 2: 0, 3: 0, 4: 0, 5: 0, 6: 16, 7: 0, 8: 16, 9: 9984, 10: 0, 11: 0, 12: 0, 13: 9984, 14: 0, 15: 0, 16: 9984, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 176, 3: 176, 4: 0, 5: 299, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 459, 12: 0, 13: 0, 14: 283, 15: 160, 16: 0, 17: 0, 18: 283, 19: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 10000, 8: 0, 9: 0, 10: 10000, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 10000, 18: 0, 19: 10000}}
[Average accuracy till task5]	Acc@1: 78.5827	Acc@5: 93.7006	Loss: 0.8429	Forgetting: 7.8136	Backward: -7.8136
Total training time: 8:45:22
