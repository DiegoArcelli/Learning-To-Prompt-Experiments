/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_frequency_pen', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=True, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=False, train_type='l2p', eval_task_id=False, frequency_penalization=True, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=False, prompts_per_task=4, prompts_per_class=1, freeze_keys=False)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 207410
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 2:31:09  Lr: 0.001875  Loss: 2.3002  Acc@1: 12.5000 (12.5000)  Acc@5: 68.7500 (68.7500)  time: 1.9807  data: 0.5528  max mem: 2497
Train: Epoch[1/5]  [  10/4579]  eta: 0:37:31  Lr: 0.001875  Loss: 2.1737  Acc@1: 18.7500 (15.9091)  Acc@5: 50.0000 (56.8182)  time: 0.4927  data: 0.0506  max mem: 2500
Train: Epoch[1/5]  [  20/4579]  eta: 0:32:06  Lr: 0.001875  Loss: 2.4522  Acc@1: 12.5000 (15.1786)  Acc@5: 56.2500 (60.1190)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  30/4579]  eta: 0:30:16  Lr: 0.001875  Loss: 1.9384  Acc@1: 18.7500 (17.9435)  Acc@5: 62.5000 (60.8871)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  40/4579]  eta: 0:29:10  Lr: 0.001875  Loss: 1.9888  Acc@1: 25.0000 (19.3598)  Acc@5: 68.7500 (63.2622)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  50/4579]  eta: 0:28:28  Lr: 0.001875  Loss: 1.8787  Acc@1: 25.0000 (20.5882)  Acc@5: 68.7500 (63.2353)  time: 0.3431  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  60/4579]  eta: 0:28:01  Lr: 0.001875  Loss: 2.1061  Acc@1: 31.2500 (22.3361)  Acc@5: 68.7500 (64.3443)  time: 0.3446  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  70/4579]  eta: 0:27:39  Lr: 0.001875  Loss: 1.9293  Acc@1: 31.2500 (22.8873)  Acc@5: 68.7500 (65.5810)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  80/4579]  eta: 0:27:21  Lr: 0.001875  Loss: 1.7547  Acc@1: 31.2500 (24.4599)  Acc@5: 75.0000 (66.7438)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  90/4579]  eta: 0:27:11  Lr: 0.001875  Loss: 1.8100  Acc@1: 31.2500 (25.0687)  Acc@5: 75.0000 (67.7198)  time: 0.3470  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 100/4579]  eta: 0:27:02  Lr: 0.001875  Loss: 1.8165  Acc@1: 31.2500 (25.6188)  Acc@5: 75.0000 (68.2550)  time: 0.3516  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 110/4579]  eta: 0:26:55  Lr: 0.001875  Loss: 1.5818  Acc@1: 31.2500 (26.4640)  Acc@5: 75.0000 (69.0315)  time: 0.3524  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 120/4579]  eta: 0:26:49  Lr: 0.001875  Loss: 1.6143  Acc@1: 31.2500 (26.5496)  Acc@5: 75.0000 (69.5248)  time: 0.3536  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 130/4579]  eta: 0:26:44  Lr: 0.001875  Loss: 1.4807  Acc@1: 31.2500 (26.6698)  Acc@5: 75.0000 (69.7996)  time: 0.3557  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 140/4579]  eta: 0:26:40  Lr: 0.001875  Loss: 1.7109  Acc@1: 25.0000 (26.9947)  Acc@5: 75.0000 (70.2128)  time: 0.3590  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [ 150/4579]  eta: 0:26:33  Lr: 0.001875  Loss: 1.2238  Acc@1: 31.2500 (27.2765)  Acc@5: 75.0000 (70.9437)  time: 0.3545  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 160/4579]  eta: 0:26:27  Lr: 0.001875  Loss: 1.5070  Acc@1: 37.5000 (27.8339)  Acc@5: 81.2500 (71.5450)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 170/4579]  eta: 0:26:21  Lr: 0.001875  Loss: 1.6403  Acc@1: 31.2500 (28.0702)  Acc@5: 81.2500 (72.0760)  time: 0.3513  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 180/4579]  eta: 0:26:16  Lr: 0.001875  Loss: 1.3707  Acc@1: 31.2500 (28.5566)  Acc@5: 81.2500 (72.5829)  time: 0.3506  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 190/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 1.3092  Acc@1: 37.5000 (29.1230)  Acc@5: 81.2500 (73.2330)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 200/4579]  eta: 0:26:03  Lr: 0.001875  Loss: 1.4548  Acc@1: 37.5000 (29.4154)  Acc@5: 81.2500 (73.3520)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 210/4579]  eta: 0:25:58  Lr: 0.001875  Loss: 1.3306  Acc@1: 37.5000 (29.5320)  Acc@5: 75.0000 (73.4893)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 220/4579]  eta: 0:25:53  Lr: 0.001875  Loss: 1.2471  Acc@1: 37.5000 (29.8925)  Acc@5: 75.0000 (73.7274)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 230/4579]  eta: 0:25:47  Lr: 0.001875  Loss: 1.1505  Acc@1: 37.5000 (30.1407)  Acc@5: 81.2500 (74.0801)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 240/4579]  eta: 0:25:42  Lr: 0.001875  Loss: 1.5341  Acc@1: 31.2500 (30.2386)  Acc@5: 75.0000 (74.1442)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 250/4579]  eta: 0:25:37  Lr: 0.001875  Loss: 1.2865  Acc@1: 31.2500 (30.3536)  Acc@5: 75.0000 (74.4273)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 260/4579]  eta: 0:25:32  Lr: 0.001875  Loss: 1.2785  Acc@1: 31.2500 (30.4598)  Acc@5: 81.2500 (74.8324)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 270/4579]  eta: 0:25:27  Lr: 0.001875  Loss: 0.9788  Acc@1: 31.2500 (30.6734)  Acc@5: 81.2500 (74.9077)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 280/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 1.0992  Acc@1: 37.5000 (30.9164)  Acc@5: 75.0000 (74.9110)  time: 0.3555  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 290/4579]  eta: 0:25:21  Lr: 0.001875  Loss: 1.1380  Acc@1: 37.5000 (31.0567)  Acc@5: 81.2500 (75.1289)  time: 0.3580  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [ 300/4579]  eta: 0:25:18  Lr: 0.001875  Loss: 0.9960  Acc@1: 31.2500 (31.1669)  Acc@5: 87.5000 (75.5191)  time: 0.3563  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 310/4579]  eta: 0:25:15  Lr: 0.001875  Loss: 1.1434  Acc@1: 37.5000 (31.4309)  Acc@5: 87.5000 (75.8240)  time: 0.3608  data: 0.0036  max mem: 2500
Train: Epoch[1/5]  [ 320/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 0.7932  Acc@1: 43.7500 (31.6783)  Acc@5: 87.5000 (76.1877)  time: 0.3649  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [ 330/4579]  eta: 0:25:10  Lr: 0.001875  Loss: 0.5344  Acc@1: 43.7500 (31.9486)  Acc@5: 87.5000 (76.3218)  time: 0.3627  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 340/4579]  eta: 0:25:07  Lr: 0.001875  Loss: 0.8403  Acc@1: 43.7500 (32.2031)  Acc@5: 87.5000 (76.6312)  time: 0.3579  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 350/4579]  eta: 0:25:04  Lr: 0.001875  Loss: 0.3815  Acc@1: 37.5000 (32.3540)  Acc@5: 81.2500 (76.7450)  time: 0.3569  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 360/4579]  eta: 0:25:01  Lr: 0.001875  Loss: 1.2181  Acc@1: 37.5000 (32.5485)  Acc@5: 81.2500 (76.9564)  time: 0.3604  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 370/4579]  eta: 0:24:57  Lr: 0.001875  Loss: 1.0355  Acc@1: 37.5000 (32.7830)  Acc@5: 81.2500 (77.1058)  time: 0.3562  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 380/4579]  eta: 0:24:52  Lr: 0.001875  Loss: 1.0846  Acc@1: 43.7500 (33.0052)  Acc@5: 81.2500 (77.2638)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 390/4579]  eta: 0:24:48  Lr: 0.001875  Loss: 0.3367  Acc@1: 43.7500 (33.3600)  Acc@5: 81.2500 (77.3657)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 400/4579]  eta: 0:24:44  Lr: 0.001875  Loss: 0.3552  Acc@1: 43.7500 (33.6814)  Acc@5: 81.2500 (77.5094)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 410/4579]  eta: 0:24:40  Lr: 0.001875  Loss: 0.5417  Acc@1: 43.7500 (33.9112)  Acc@5: 87.5000 (77.7372)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 420/4579]  eta: 0:24:35  Lr: 0.001875  Loss: 0.6976  Acc@1: 43.7500 (34.0410)  Acc@5: 81.2500 (77.8207)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 430/4579]  eta: 0:24:31  Lr: 0.001875  Loss: 0.7478  Acc@1: 43.7500 (34.3532)  Acc@5: 81.2500 (78.0017)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 440/4579]  eta: 0:24:27  Lr: 0.001875  Loss: 0.1163  Acc@1: 43.7500 (34.6230)  Acc@5: 87.5000 (78.2455)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 450/4579]  eta: 0:24:22  Lr: 0.001875  Loss: 0.4098  Acc@1: 43.7500 (34.8947)  Acc@5: 87.5000 (78.5200)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 460/4579]  eta: 0:24:19  Lr: 0.001875  Loss: 0.4715  Acc@1: 43.7500 (35.1274)  Acc@5: 87.5000 (78.7148)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 470/4579]  eta: 0:24:15  Lr: 0.001875  Loss: 0.6959  Acc@1: 43.7500 (35.2442)  Acc@5: 87.5000 (78.9145)  time: 0.3547  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 480/4579]  eta: 0:24:12  Lr: 0.001875  Loss: 0.6589  Acc@1: 43.7500 (35.3690)  Acc@5: 81.2500 (78.9631)  time: 0.3572  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 490/4579]  eta: 0:24:09  Lr: 0.001875  Loss: 0.7442  Acc@1: 43.7500 (35.6415)  Acc@5: 81.2500 (78.9969)  time: 0.3555  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [ 500/4579]  eta: 0:24:06  Lr: 0.001875  Loss: 0.6423  Acc@1: 43.7500 (35.7285)  Acc@5: 81.2500 (79.0669)  time: 0.3589  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [ 510/4579]  eta: 0:24:03  Lr: 0.001875  Loss: 0.5626  Acc@1: 50.0000 (36.0568)  Acc@5: 87.5000 (79.2197)  time: 0.3632  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 520/4579]  eta: 0:24:00  Lr: 0.001875  Loss: -0.0485  Acc@1: 50.0000 (36.3604)  Acc@5: 87.5000 (79.3786)  time: 0.3621  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 530/4579]  eta: 0:23:56  Lr: 0.001875  Loss: 0.3296  Acc@1: 43.7500 (36.4407)  Acc@5: 87.5000 (79.4609)  time: 0.3563  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 540/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 0.4610  Acc@1: 43.7500 (36.6335)  Acc@5: 87.5000 (79.5402)  time: 0.3559  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 550/4579]  eta: 0:23:51  Lr: 0.001875  Loss: 0.6630  Acc@1: 43.7500 (36.7740)  Acc@5: 87.5000 (79.6166)  time: 0.3662  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 560/4579]  eta: 0:23:47  Lr: 0.001875  Loss: 0.6482  Acc@1: 37.5000 (36.8761)  Acc@5: 87.5000 (79.7906)  time: 0.3652  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 570/4579]  eta: 0:23:43  Lr: 0.001875  Loss: 0.4741  Acc@1: 43.7500 (37.0841)  Acc@5: 87.5000 (79.9584)  time: 0.3529  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 580/4579]  eta: 0:23:39  Lr: 0.001875  Loss: 0.5094  Acc@1: 43.7500 (37.1880)  Acc@5: 87.5000 (80.1312)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 590/4579]  eta: 0:23:35  Lr: 0.001875  Loss: 0.5121  Acc@1: 37.5000 (37.3202)  Acc@5: 87.5000 (80.2136)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 600/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 0.1831  Acc@1: 43.7500 (37.5520)  Acc@5: 87.5000 (80.3245)  time: 0.3519  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 610/4579]  eta: 0:23:28  Lr: 0.001875  Loss: 0.1729  Acc@1: 43.7500 (37.6023)  Acc@5: 81.2500 (80.3294)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 620/4579]  eta: 0:23:24  Lr: 0.001875  Loss: 0.7034  Acc@1: 43.7500 (37.7415)  Acc@5: 87.5000 (80.4549)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 630/4579]  eta: 0:23:20  Lr: 0.001875  Loss: 0.5681  Acc@1: 43.7500 (37.8170)  Acc@5: 87.5000 (80.4873)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 640/4579]  eta: 0:23:16  Lr: 0.001875  Loss: -0.1470  Acc@1: 43.7500 (37.9485)  Acc@5: 87.5000 (80.6357)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 650/4579]  eta: 0:23:12  Lr: 0.001875  Loss: 0.4513  Acc@1: 43.7500 (38.0472)  Acc@5: 87.5000 (80.6836)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 660/4579]  eta: 0:23:09  Lr: 0.001875  Loss: 0.7375  Acc@1: 43.7500 (38.1241)  Acc@5: 81.2500 (80.7016)  time: 0.3539  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 670/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 0.6165  Acc@1: 43.7500 (38.1800)  Acc@5: 87.5000 (80.7843)  time: 0.3616  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 680/4579]  eta: 0:23:02  Lr: 0.001875  Loss: 0.4805  Acc@1: 50.0000 (38.3076)  Acc@5: 87.5000 (80.8829)  time: 0.3581  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 690/4579]  eta: 0:22:59  Lr: 0.001875  Loss: 0.2961  Acc@1: 50.0000 (38.4316)  Acc@5: 87.5000 (81.0058)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 700/4579]  eta: 0:22:55  Lr: 0.001875  Loss: 0.3743  Acc@1: 43.7500 (38.4897)  Acc@5: 87.5000 (81.1163)  time: 0.3571  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 710/4579]  eta: 0:22:53  Lr: 0.001875  Loss: 0.3099  Acc@1: 43.7500 (38.4845)  Acc@5: 87.5000 (81.1357)  time: 0.3652  data: 0.0035  max mem: 2500
Train: Epoch[1/5]  [ 720/4579]  eta: 0:22:49  Lr: 0.001875  Loss: 0.4376  Acc@1: 37.5000 (38.5489)  Acc@5: 81.2500 (81.1980)  time: 0.3664  data: 0.0067  max mem: 2500
Train: Epoch[1/5]  [ 730/4579]  eta: 0:22:46  Lr: 0.001875  Loss: 0.3469  Acc@1: 43.7500 (38.6200)  Acc@5: 87.5000 (81.2756)  time: 0.3623  data: 0.0059  max mem: 2500
Train: Epoch[1/5]  [ 740/4579]  eta: 0:22:43  Lr: 0.001875  Loss: 0.3214  Acc@1: 50.0000 (38.8495)  Acc@5: 87.5000 (81.3512)  time: 0.3605  data: 0.0040  max mem: 2500
Train: Epoch[1/5]  [ 750/4579]  eta: 0:22:40  Lr: 0.001875  Loss: 0.4831  Acc@1: 50.0000 (38.9397)  Acc@5: 87.5000 (81.4331)  time: 0.3623  data: 0.0040  max mem: 2500
Train: Epoch[1/5]  [ 760/4579]  eta: 0:22:36  Lr: 0.001875  Loss: 0.1309  Acc@1: 43.7500 (39.0933)  Acc@5: 87.5000 (81.5539)  time: 0.3586  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [ 770/4579]  eta: 0:22:32  Lr: 0.001875  Loss: 0.4576  Acc@1: 43.7500 (39.1537)  Acc@5: 87.5000 (81.6067)  time: 0.3503  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 780/4579]  eta: 0:22:29  Lr: 0.001875  Loss: 0.7142  Acc@1: 43.7500 (39.3246)  Acc@5: 87.5000 (81.6181)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 790/4579]  eta: 0:22:25  Lr: 0.001875  Loss: 0.0540  Acc@1: 43.7500 (39.3963)  Acc@5: 87.5000 (81.6846)  time: 0.3513  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 800/4579]  eta: 0:22:21  Lr: 0.001875  Loss: 0.4904  Acc@1: 50.0000 (39.5209)  Acc@5: 87.5000 (81.7806)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 810/4579]  eta: 0:22:17  Lr: 0.001875  Loss: 0.1764  Acc@1: 50.0000 (39.6347)  Acc@5: 87.5000 (81.8665)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 820/4579]  eta: 0:22:14  Lr: 0.001875  Loss: 0.0395  Acc@1: 50.0000 (39.8295)  Acc@5: 87.5000 (81.9580)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 830/4579]  eta: 0:22:10  Lr: 0.001875  Loss: -0.1545  Acc@1: 50.0000 (39.9368)  Acc@5: 87.5000 (82.0472)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 840/4579]  eta: 0:22:06  Lr: 0.001875  Loss: 0.6948  Acc@1: 50.0000 (40.0342)  Acc@5: 87.5000 (82.1121)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 850/4579]  eta: 0:22:02  Lr: 0.001875  Loss: 0.3276  Acc@1: 50.0000 (40.1366)  Acc@5: 87.5000 (82.1240)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 860/4579]  eta: 0:21:58  Lr: 0.001875  Loss: 0.2273  Acc@1: 50.0000 (40.2729)  Acc@5: 87.5000 (82.1356)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 870/4579]  eta: 0:21:55  Lr: 0.001875  Loss: 0.0398  Acc@1: 50.0000 (40.3200)  Acc@5: 87.5000 (82.2044)  time: 0.3526  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 880/4579]  eta: 0:21:52  Lr: 0.001875  Loss: 0.6343  Acc@1: 43.7500 (40.4157)  Acc@5: 87.5000 (82.2645)  time: 0.3584  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 890/4579]  eta: 0:21:48  Lr: 0.001875  Loss: 0.4052  Acc@1: 43.7500 (40.4882)  Acc@5: 87.5000 (82.3583)  time: 0.3583  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 900/4579]  eta: 0:21:45  Lr: 0.001875  Loss: 0.3323  Acc@1: 43.7500 (40.6077)  Acc@5: 87.5000 (82.3668)  time: 0.3564  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 910/4579]  eta: 0:21:42  Lr: 0.001875  Loss: 0.2346  Acc@1: 50.0000 (40.6765)  Acc@5: 87.5000 (82.4369)  time: 0.3625  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 920/4579]  eta: 0:21:38  Lr: 0.001875  Loss: 0.5805  Acc@1: 37.5000 (40.6555)  Acc@5: 87.5000 (82.4511)  time: 0.3646  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 930/4579]  eta: 0:21:35  Lr: 0.001875  Loss: 0.5653  Acc@1: 37.5000 (40.6619)  Acc@5: 87.5000 (82.5322)  time: 0.3631  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 940/4579]  eta: 0:21:32  Lr: 0.001875  Loss: -0.1462  Acc@1: 43.7500 (40.7678)  Acc@5: 87.5000 (82.5717)  time: 0.3621  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 950/4579]  eta: 0:21:28  Lr: 0.001875  Loss: 0.0100  Acc@1: 43.7500 (40.7466)  Acc@5: 87.5000 (82.5907)  time: 0.3579  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 960/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 0.0752  Acc@1: 43.7500 (40.8299)  Acc@5: 87.5000 (82.6418)  time: 0.3600  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [ 970/4579]  eta: 0:21:21  Lr: 0.001875  Loss: 0.0947  Acc@1: 50.0000 (40.9372)  Acc@5: 87.5000 (82.6661)  time: 0.3557  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 980/4579]  eta: 0:21:18  Lr: 0.001875  Loss: 0.1762  Acc@1: 50.0000 (41.0487)  Acc@5: 87.5000 (82.7090)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 990/4579]  eta: 0:21:14  Lr: 0.001875  Loss: 0.6494  Acc@1: 50.0000 (41.1201)  Acc@5: 87.5000 (82.7699)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1000/4579]  eta: 0:21:10  Lr: 0.001875  Loss: -0.0548  Acc@1: 50.0000 (41.2338)  Acc@5: 87.5000 (82.8047)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1010/4579]  eta: 0:21:06  Lr: 0.001875  Loss: 0.1364  Acc@1: 50.0000 (41.2957)  Acc@5: 87.5000 (82.8573)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1020/4579]  eta: 0:21:03  Lr: 0.001875  Loss: 0.3448  Acc@1: 50.0000 (41.4545)  Acc@5: 87.5000 (82.8967)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1030/4579]  eta: 0:20:59  Lr: 0.001875  Loss: 0.7815  Acc@1: 50.0000 (41.5192)  Acc@5: 87.5000 (82.9110)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1040/4579]  eta: 0:20:55  Lr: 0.001875  Loss: 0.8376  Acc@1: 50.0000 (41.6547)  Acc@5: 87.5000 (82.9851)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1050/4579]  eta: 0:20:51  Lr: 0.001875  Loss: 0.1899  Acc@1: 50.0000 (41.7281)  Acc@5: 87.5000 (83.0459)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1060/4579]  eta: 0:20:48  Lr: 0.001875  Loss: -0.1066  Acc@1: 50.0000 (41.8179)  Acc@5: 87.5000 (83.0761)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1070/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.0740  Acc@1: 50.0000 (41.8884)  Acc@5: 87.5000 (83.1116)  time: 0.3524  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1080/4579]  eta: 0:20:41  Lr: 0.001875  Loss: 0.1261  Acc@1: 56.2500 (42.0155)  Acc@5: 87.5000 (83.1695)  time: 0.3575  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1090/4579]  eta: 0:20:37  Lr: 0.001875  Loss: 0.1415  Acc@1: 56.2500 (42.1173)  Acc@5: 87.5000 (83.1978)  time: 0.3591  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [1100/4579]  eta: 0:20:34  Lr: 0.001875  Loss: 0.3944  Acc@1: 56.2500 (42.2173)  Acc@5: 87.5000 (83.2539)  time: 0.3581  data: 0.0037  max mem: 2500
Train: Epoch[1/5]  [1110/4579]  eta: 0:20:30  Lr: 0.001875  Loss: 0.0324  Acc@1: 56.2500 (42.3099)  Acc@5: 87.5000 (83.2696)  time: 0.3600  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1120/4579]  eta: 0:20:27  Lr: 0.001875  Loss: 0.0682  Acc@1: 56.2500 (42.4008)  Acc@5: 87.5000 (83.3296)  time: 0.3628  data: 0.0047  max mem: 2500
Train: Epoch[1/5]  [1130/4579]  eta: 0:20:24  Lr: 0.001875  Loss: 0.0667  Acc@1: 50.0000 (42.4127)  Acc@5: 87.5000 (83.3886)  time: 0.3608  data: 0.0050  max mem: 2500
Train: Epoch[1/5]  [1140/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.0404  Acc@1: 43.7500 (42.4463)  Acc@5: 87.5000 (83.4411)  time: 0.3597  data: 0.0032  max mem: 2500
Train: Epoch[1/5]  [1150/4579]  eta: 0:20:17  Lr: 0.001875  Loss: 0.2544  Acc@1: 50.0000 (42.5011)  Acc@5: 87.5000 (83.4492)  time: 0.3576  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [1160/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.3896  Acc@1: 56.2500 (42.6464)  Acc@5: 87.5000 (83.5002)  time: 0.3548  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1170/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.0300  Acc@1: 56.2500 (42.6932)  Acc@5: 87.5000 (83.5184)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1180/4579]  eta: 0:20:06  Lr: 0.001875  Loss: 0.5897  Acc@1: 50.0000 (42.7710)  Acc@5: 87.5000 (83.5468)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1190/4579]  eta: 0:20:02  Lr: 0.001875  Loss: -0.0600  Acc@1: 43.7500 (42.7844)  Acc@5: 87.5000 (83.5695)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1200/4579]  eta: 0:19:58  Lr: 0.001875  Loss: 0.6618  Acc@1: 43.7500 (42.8653)  Acc@5: 87.5000 (83.5814)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1210/4579]  eta: 0:19:55  Lr: 0.001875  Loss: 0.0530  Acc@1: 56.2500 (42.9707)  Acc@5: 87.5000 (83.6654)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1220/4579]  eta: 0:19:51  Lr: 0.001875  Loss: 0.1781  Acc@1: 62.5000 (43.1153)  Acc@5: 93.7500 (83.7121)  time: 0.3485  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1230/4579]  eta: 0:19:47  Lr: 0.001875  Loss: -0.1182  Acc@1: 62.5000 (43.2169)  Acc@5: 93.7500 (83.7683)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1240/4579]  eta: 0:19:43  Lr: 0.001875  Loss: 0.3082  Acc@1: 62.5000 (43.2867)  Acc@5: 93.7500 (83.8034)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1250/4579]  eta: 0:19:40  Lr: 0.001875  Loss: 0.2774  Acc@1: 50.0000 (43.3253)  Acc@5: 87.5000 (83.8379)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1260/4579]  eta: 0:19:36  Lr: 0.001875  Loss: 0.1679  Acc@1: 43.7500 (43.3386)  Acc@5: 87.5000 (83.8372)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1270/4579]  eta: 0:19:33  Lr: 0.001875  Loss: 0.2291  Acc@1: 50.0000 (43.4107)  Acc@5: 87.5000 (83.8808)  time: 0.3529  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1280/4579]  eta: 0:19:29  Lr: 0.001875  Loss: 0.1256  Acc@1: 50.0000 (43.4670)  Acc@5: 87.5000 (83.9139)  time: 0.3514  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1290/4579]  eta: 0:19:25  Lr: 0.001875  Loss: -0.1171  Acc@1: 50.0000 (43.5321)  Acc@5: 87.5000 (83.9417)  time: 0.3532  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1300/4579]  eta: 0:19:22  Lr: 0.001875  Loss: -0.3246  Acc@1: 50.0000 (43.5674)  Acc@5: 87.5000 (83.9787)  time: 0.3569  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1310/4579]  eta: 0:19:18  Lr: 0.001875  Loss: -0.0006  Acc@1: 56.2500 (43.6928)  Acc@5: 87.5000 (83.9912)  time: 0.3570  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [1320/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.1289  Acc@1: 56.2500 (43.7737)  Acc@5: 87.5000 (84.0131)  time: 0.3595  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [1330/4579]  eta: 0:19:11  Lr: 0.001875  Loss: -0.5075  Acc@1: 50.0000 (43.8580)  Acc@5: 87.5000 (84.0768)  time: 0.3577  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1340/4579]  eta: 0:19:08  Lr: 0.001875  Loss: 0.1556  Acc@1: 50.0000 (43.8991)  Acc@5: 93.7500 (84.1350)  time: 0.3529  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1350/4579]  eta: 0:19:04  Lr: 0.001875  Loss: 0.2432  Acc@1: 50.0000 (43.9258)  Acc@5: 87.5000 (84.1414)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1360/4579]  eta: 0:19:01  Lr: 0.001875  Loss: 0.4213  Acc@1: 50.0000 (43.9980)  Acc@5: 87.5000 (84.1890)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1370/4579]  eta: 0:18:57  Lr: 0.001875  Loss: -0.1622  Acc@1: 50.0000 (44.0326)  Acc@5: 87.5000 (84.2268)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1380/4579]  eta: 0:18:53  Lr: 0.001875  Loss: -0.0930  Acc@1: 50.0000 (44.0985)  Acc@5: 93.7500 (84.2777)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1390/4579]  eta: 0:18:50  Lr: 0.001875  Loss: 0.2238  Acc@1: 50.0000 (44.1319)  Acc@5: 93.7500 (84.3323)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1400/4579]  eta: 0:18:46  Lr: 0.001875  Loss: 0.0483  Acc@1: 50.0000 (44.1872)  Acc@5: 87.5000 (84.3728)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1410/4579]  eta: 0:18:42  Lr: 0.001875  Loss: -0.0818  Acc@1: 50.0000 (44.2151)  Acc@5: 87.5000 (84.3816)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1420/4579]  eta: 0:18:38  Lr: 0.001875  Loss: 0.2059  Acc@1: 56.2500 (44.2998)  Acc@5: 87.5000 (84.4256)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1430/4579]  eta: 0:18:35  Lr: 0.001875  Loss: 0.2929  Acc@1: 50.0000 (44.3396)  Acc@5: 87.5000 (84.4471)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1440/4579]  eta: 0:18:31  Lr: 0.001875  Loss: -0.1557  Acc@1: 50.0000 (44.4093)  Acc@5: 87.5000 (84.4769)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1450/4579]  eta: 0:18:28  Lr: 0.001875  Loss: -0.1508  Acc@1: 56.2500 (44.5038)  Acc@5: 87.5000 (84.5021)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1460/4579]  eta: 0:18:24  Lr: 0.001875  Loss: -0.0555  Acc@1: 56.2500 (44.5457)  Acc@5: 87.5000 (84.5140)  time: 0.3555  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1470/4579]  eta: 0:18:21  Lr: 0.001875  Loss: -0.3468  Acc@1: 56.2500 (44.6465)  Acc@5: 87.5000 (84.5683)  time: 0.3569  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1480/4579]  eta: 0:18:17  Lr: 0.001875  Loss: 0.0346  Acc@1: 56.2500 (44.7080)  Acc@5: 87.5000 (84.5881)  time: 0.3564  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1490/4579]  eta: 0:18:14  Lr: 0.001875  Loss: -0.0012  Acc@1: 56.2500 (44.7351)  Acc@5: 87.5000 (84.6035)  time: 0.3565  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1500/4579]  eta: 0:18:10  Lr: 0.001875  Loss: 0.1559  Acc@1: 50.0000 (44.7826)  Acc@5: 87.5000 (84.6186)  time: 0.3543  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1510/4579]  eta: 0:18:07  Lr: 0.001875  Loss: -0.1031  Acc@1: 50.0000 (44.8875)  Acc@5: 87.5000 (84.6583)  time: 0.3553  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [1520/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.0283  Acc@1: 56.2500 (44.9540)  Acc@5: 93.7500 (84.7099)  time: 0.3536  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1530/4579]  eta: 0:17:59  Lr: 0.001875  Loss: 0.1794  Acc@1: 50.0000 (44.9788)  Acc@5: 93.7500 (84.7404)  time: 0.3500  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1540/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.2224  Acc@1: 50.0000 (45.0114)  Acc@5: 93.7500 (84.7745)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1550/4579]  eta: 0:17:52  Lr: 0.001875  Loss: -0.1868  Acc@1: 56.2500 (45.0919)  Acc@5: 87.5000 (84.8042)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1560/4579]  eta: 0:17:48  Lr: 0.001875  Loss: 0.1835  Acc@1: 56.2500 (45.1874)  Acc@5: 87.5000 (84.8455)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1570/4579]  eta: 0:17:45  Lr: 0.001875  Loss: 0.5348  Acc@1: 50.0000 (45.1822)  Acc@5: 87.5000 (84.8623)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1580/4579]  eta: 0:17:41  Lr: 0.001875  Loss: -0.2721  Acc@1: 50.0000 (45.2522)  Acc@5: 87.5000 (84.8830)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1590/4579]  eta: 0:17:37  Lr: 0.001875  Loss: -0.0474  Acc@1: 50.0000 (45.2624)  Acc@5: 87.5000 (84.8994)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1600/4579]  eta: 0:17:34  Lr: 0.001875  Loss: 0.0710  Acc@1: 50.0000 (45.3349)  Acc@5: 87.5000 (84.9196)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1610/4579]  eta: 0:17:30  Lr: 0.001875  Loss: 0.4129  Acc@1: 56.2500 (45.4066)  Acc@5: 87.5000 (84.9317)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1620/4579]  eta: 0:17:26  Lr: 0.001875  Loss: 0.3495  Acc@1: 56.2500 (45.4465)  Acc@5: 87.5000 (84.9476)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1630/4579]  eta: 0:17:23  Lr: 0.001875  Loss: -0.0655  Acc@1: 56.2500 (45.5204)  Acc@5: 87.5000 (84.9862)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1640/4579]  eta: 0:17:19  Lr: 0.001875  Loss: 0.0372  Acc@1: 56.2500 (45.5705)  Acc@5: 93.7500 (85.0244)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1650/4579]  eta: 0:17:16  Lr: 0.001875  Loss: -0.2845  Acc@1: 50.0000 (45.6163)  Acc@5: 93.7500 (85.0469)  time: 0.3570  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1660/4579]  eta: 0:17:12  Lr: 0.001875  Loss: 0.2964  Acc@1: 50.0000 (45.6502)  Acc@5: 87.5000 (85.0880)  time: 0.3574  data: 0.0037  max mem: 2500
Train: Epoch[1/5]  [1670/4579]  eta: 0:17:09  Lr: 0.001875  Loss: -0.4106  Acc@1: 56.2500 (45.7361)  Acc@5: 87.5000 (85.1100)  time: 0.3589  data: 0.0037  max mem: 2500
Train: Epoch[1/5]  [1680/4579]  eta: 0:17:06  Lr: 0.001875  Loss: 0.2866  Acc@1: 50.0000 (45.7391)  Acc@5: 87.5000 (85.1019)  time: 0.3654  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [1690/4579]  eta: 0:17:02  Lr: 0.001875  Loss: -0.1672  Acc@1: 50.0000 (45.7976)  Acc@5: 87.5000 (85.1087)  time: 0.3615  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [1700/4579]  eta: 0:16:59  Lr: 0.001875  Loss: 0.0936  Acc@1: 56.2500 (45.8811)  Acc@5: 87.5000 (85.1337)  time: 0.3565  data: 0.0035  max mem: 2500
Train: Epoch[1/5]  [1710/4579]  eta: 0:16:55  Lr: 0.001875  Loss: 0.7859  Acc@1: 50.0000 (45.8686)  Acc@5: 87.5000 (85.1293)  time: 0.3604  data: 0.0067  max mem: 2500
Train: Epoch[1/5]  [1720/4579]  eta: 0:16:52  Lr: 0.001875  Loss: -0.4101  Acc@1: 50.0000 (45.9399)  Acc@5: 87.5000 (85.1431)  time: 0.3562  data: 0.0049  max mem: 2500
Train: Epoch[1/5]  [1730/4579]  eta: 0:16:48  Lr: 0.001875  Loss: 0.0874  Acc@1: 56.2500 (46.0066)  Acc@5: 87.5000 (85.1567)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1740/4579]  eta: 0:16:44  Lr: 0.001875  Loss: 0.2290  Acc@1: 56.2500 (46.0511)  Acc@5: 87.5000 (85.1738)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1750/4579]  eta: 0:16:41  Lr: 0.001875  Loss: 0.7007  Acc@1: 56.2500 (46.1379)  Acc@5: 87.5000 (85.2013)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1760/4579]  eta: 0:16:37  Lr: 0.001875  Loss: 0.1092  Acc@1: 56.2500 (46.2202)  Acc@5: 93.7500 (85.2250)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1770/4579]  eta: 0:16:34  Lr: 0.001875  Loss: -0.0648  Acc@1: 62.5000 (46.3015)  Acc@5: 93.7500 (85.2555)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1780/4579]  eta: 0:16:30  Lr: 0.001875  Loss: -0.0899  Acc@1: 56.2500 (46.3574)  Acc@5: 93.7500 (85.2786)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1790/4579]  eta: 0:16:26  Lr: 0.001875  Loss: 0.2649  Acc@1: 56.2500 (46.4091)  Acc@5: 87.5000 (85.2806)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1800/4579]  eta: 0:16:23  Lr: 0.001875  Loss: 0.1944  Acc@1: 56.2500 (46.4534)  Acc@5: 87.5000 (85.3172)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1810/4579]  eta: 0:16:19  Lr: 0.001875  Loss: 0.4577  Acc@1: 56.2500 (46.4936)  Acc@5: 93.7500 (85.3292)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1820/4579]  eta: 0:16:15  Lr: 0.001875  Loss: -0.2835  Acc@1: 56.2500 (46.5301)  Acc@5: 87.5000 (85.3549)  time: 0.3503  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1830/4579]  eta: 0:16:12  Lr: 0.001875  Loss: -0.0820  Acc@1: 56.2500 (46.5866)  Acc@5: 87.5000 (85.3768)  time: 0.3565  data: 0.0037  max mem: 2500
Train: Epoch[1/5]  [1840/4579]  eta: 0:16:08  Lr: 0.001875  Loss: 0.1065  Acc@1: 56.2500 (46.6594)  Acc@5: 93.7500 (85.4223)  time: 0.3588  data: 0.0056  max mem: 2500
Train: Epoch[1/5]  [1850/4579]  eta: 0:16:05  Lr: 0.001875  Loss: 0.1718  Acc@1: 56.2500 (46.7079)  Acc@5: 93.7500 (85.4437)  time: 0.3604  data: 0.0044  max mem: 2500
Train: Epoch[1/5]  [1860/4579]  eta: 0:16:02  Lr: 0.001875  Loss: 0.2095  Acc@1: 56.2500 (46.7558)  Acc@5: 87.5000 (85.4614)  time: 0.3601  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [1870/4579]  eta: 0:15:58  Lr: 0.001875  Loss: -0.3279  Acc@1: 62.5000 (46.8499)  Acc@5: 93.7500 (85.4957)  time: 0.3591  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [1880/4579]  eta: 0:15:55  Lr: 0.001875  Loss: -0.2293  Acc@1: 56.2500 (46.8866)  Acc@5: 93.7500 (85.4964)  time: 0.3584  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1890/4579]  eta: 0:15:51  Lr: 0.001875  Loss: -0.2446  Acc@1: 50.0000 (46.9461)  Acc@5: 87.5000 (85.5004)  time: 0.3575  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [1900/4579]  eta: 0:15:48  Lr: 0.001875  Loss: 0.0876  Acc@1: 56.2500 (46.9950)  Acc@5: 87.5000 (85.4978)  time: 0.3583  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [1910/4579]  eta: 0:15:44  Lr: 0.001875  Loss: 0.3319  Acc@1: 50.0000 (47.0075)  Acc@5: 87.5000 (85.5082)  time: 0.3591  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [1920/4579]  eta: 0:15:41  Lr: 0.001875  Loss: 0.0123  Acc@1: 50.0000 (47.0458)  Acc@5: 87.5000 (85.5154)  time: 0.3547  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [1930/4579]  eta: 0:15:37  Lr: 0.001875  Loss: -0.0437  Acc@1: 56.2500 (47.0935)  Acc@5: 87.5000 (85.5386)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1940/4579]  eta: 0:15:33  Lr: 0.001875  Loss: 0.0648  Acc@1: 56.2500 (47.1503)  Acc@5: 87.5000 (85.5648)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1950/4579]  eta: 0:15:30  Lr: 0.001875  Loss: 0.2872  Acc@1: 62.5000 (47.2034)  Acc@5: 87.5000 (85.5875)  time: 0.3498  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1960/4579]  eta: 0:15:26  Lr: 0.001875  Loss: -0.0664  Acc@1: 56.2500 (47.2495)  Acc@5: 87.5000 (85.5973)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1970/4579]  eta: 0:15:23  Lr: 0.001875  Loss: 0.1857  Acc@1: 56.2500 (47.2888)  Acc@5: 87.5000 (85.6196)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1980/4579]  eta: 0:15:19  Lr: 0.001875  Loss: 0.3336  Acc@1: 56.2500 (47.3467)  Acc@5: 87.5000 (85.6291)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1990/4579]  eta: 0:15:15  Lr: 0.001875  Loss: -0.1622  Acc@1: 56.2500 (47.3788)  Acc@5: 87.5000 (85.6385)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2000/4579]  eta: 0:15:12  Lr: 0.001875  Loss: 0.0200  Acc@1: 56.2500 (47.4419)  Acc@5: 93.7500 (85.6634)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2010/4579]  eta: 0:15:08  Lr: 0.001875  Loss: -0.1171  Acc@1: 56.2500 (47.4453)  Acc@5: 87.5000 (85.6819)  time: 0.3489  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2020/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 0.6470  Acc@1: 50.0000 (47.4579)  Acc@5: 87.5000 (85.6971)  time: 0.3546  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [2030/4579]  eta: 0:15:01  Lr: 0.001875  Loss: 0.1075  Acc@1: 50.0000 (47.5074)  Acc@5: 87.5000 (85.7121)  time: 0.3591  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [2040/4579]  eta: 0:14:58  Lr: 0.001875  Loss: 0.4064  Acc@1: 56.2500 (47.5441)  Acc@5: 87.5000 (85.6963)  time: 0.3573  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2050/4579]  eta: 0:14:54  Lr: 0.001875  Loss: -0.0205  Acc@1: 56.2500 (47.6109)  Acc@5: 87.5000 (85.7204)  time: 0.3598  data: 0.0039  max mem: 2500
Train: Epoch[1/5]  [2060/4579]  eta: 0:14:51  Lr: 0.001875  Loss: 0.2956  Acc@1: 56.2500 (47.6528)  Acc@5: 93.7500 (85.7563)  time: 0.3623  data: 0.0043  max mem: 2500
Train: Epoch[1/5]  [2070/4579]  eta: 0:14:47  Lr: 0.001875  Loss: -0.4650  Acc@1: 50.0000 (47.6823)  Acc@5: 93.7500 (85.7708)  time: 0.3607  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2080/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 0.2345  Acc@1: 56.2500 (47.7204)  Acc@5: 87.5000 (85.7941)  time: 0.3596  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2090/4579]  eta: 0:14:40  Lr: 0.001875  Loss: 0.3717  Acc@1: 56.2500 (47.7433)  Acc@5: 87.5000 (85.7903)  time: 0.3562  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2100/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 0.3486  Acc@1: 56.2500 (47.7987)  Acc@5: 87.5000 (85.7925)  time: 0.3598  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2110/4579]  eta: 0:14:33  Lr: 0.001875  Loss: 0.3825  Acc@1: 62.5000 (47.8565)  Acc@5: 87.5000 (85.8154)  time: 0.3563  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2120/4579]  eta: 0:14:30  Lr: 0.001875  Loss: 0.0391  Acc@1: 56.2500 (47.8725)  Acc@5: 93.7500 (85.8469)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2130/4579]  eta: 0:14:26  Lr: 0.001875  Loss: 0.0464  Acc@1: 50.0000 (47.9030)  Acc@5: 87.5000 (85.8488)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2140/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 0.4826  Acc@1: 56.2500 (47.9157)  Acc@5: 87.5000 (85.8623)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2150/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.0776  Acc@1: 56.2500 (47.9661)  Acc@5: 93.7500 (85.8845)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2160/4579]  eta: 0:14:15  Lr: 0.001875  Loss: 0.2845  Acc@1: 56.2500 (48.0275)  Acc@5: 87.5000 (85.9064)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2170/4579]  eta: 0:14:12  Lr: 0.001875  Loss: -0.0403  Acc@1: 50.0000 (48.0424)  Acc@5: 87.5000 (85.9051)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2180/4579]  eta: 0:14:08  Lr: 0.001875  Loss: -0.0318  Acc@1: 50.0000 (48.0915)  Acc@5: 87.5000 (85.9182)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2190/4579]  eta: 0:14:05  Lr: 0.001875  Loss: -0.2658  Acc@1: 56.2500 (48.1344)  Acc@5: 87.5000 (85.9197)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2200/4579]  eta: 0:14:01  Lr: 0.001875  Loss: -0.3693  Acc@1: 56.2500 (48.1912)  Acc@5: 87.5000 (85.9467)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2210/4579]  eta: 0:13:57  Lr: 0.001875  Loss: 0.3658  Acc@1: 56.2500 (48.2107)  Acc@5: 87.5000 (85.9340)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2220/4579]  eta: 0:13:54  Lr: 0.001875  Loss: 0.1513  Acc@1: 56.2500 (48.2440)  Acc@5: 81.2500 (85.9354)  time: 0.3550  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2230/4579]  eta: 0:13:50  Lr: 0.001875  Loss: -0.2982  Acc@1: 56.2500 (48.2771)  Acc@5: 87.5000 (85.9564)  time: 0.3562  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2240/4579]  eta: 0:13:47  Lr: 0.001875  Loss: 0.1413  Acc@1: 56.2500 (48.3015)  Acc@5: 87.5000 (85.9661)  time: 0.3541  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2250/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.3829  Acc@1: 56.2500 (48.3480)  Acc@5: 87.5000 (85.9896)  time: 0.3547  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2260/4579]  eta: 0:13:40  Lr: 0.001875  Loss: 0.1703  Acc@1: 50.0000 (48.3553)  Acc@5: 87.5000 (86.0045)  time: 0.3555  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2270/4579]  eta: 0:13:36  Lr: 0.001875  Loss: 0.0277  Acc@1: 50.0000 (48.3790)  Acc@5: 87.5000 (86.0194)  time: 0.3599  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2280/4579]  eta: 0:13:33  Lr: 0.001875  Loss: 0.3845  Acc@1: 50.0000 (48.3916)  Acc@5: 87.5000 (86.0259)  time: 0.3620  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [2290/4579]  eta: 0:13:29  Lr: 0.001875  Loss: 0.1980  Acc@1: 50.0000 (48.4123)  Acc@5: 87.5000 (86.0350)  time: 0.3567  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2300/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.0211  Acc@1: 50.0000 (48.4327)  Acc@5: 87.5000 (86.0468)  time: 0.3554  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2310/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.5455  Acc@1: 50.0000 (48.4531)  Acc@5: 93.7500 (86.0693)  time: 0.3566  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2320/4579]  eta: 0:13:19  Lr: 0.001875  Loss: 0.4093  Acc@1: 50.0000 (48.4624)  Acc@5: 87.5000 (86.0674)  time: 0.3578  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2330/4579]  eta: 0:13:15  Lr: 0.001875  Loss: 0.2116  Acc@1: 56.2500 (48.4905)  Acc@5: 87.5000 (86.0709)  time: 0.3550  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2340/4579]  eta: 0:13:12  Lr: 0.001875  Loss: 0.0022  Acc@1: 56.2500 (48.5396)  Acc@5: 93.7500 (86.1037)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2350/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.0584  Acc@1: 62.5000 (48.5777)  Acc@5: 93.7500 (86.1256)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2360/4579]  eta: 0:13:05  Lr: 0.001875  Loss: -0.0639  Acc@1: 56.2500 (48.6182)  Acc@5: 93.7500 (86.1499)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2370/4579]  eta: 0:13:01  Lr: 0.001875  Loss: 0.2368  Acc@1: 56.2500 (48.6583)  Acc@5: 87.5000 (86.1530)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2380/4579]  eta: 0:12:57  Lr: 0.001875  Loss: -0.5628  Acc@1: 62.5000 (48.7112)  Acc@5: 87.5000 (86.1692)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2390/4579]  eta: 0:12:54  Lr: 0.001875  Loss: 0.0173  Acc@1: 56.2500 (48.7322)  Acc@5: 87.5000 (86.1695)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2400/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -0.4351  Acc@1: 56.2500 (48.8026)  Acc@5: 93.7500 (86.2115)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2410/4579]  eta: 0:12:47  Lr: 0.001875  Loss: 0.1326  Acc@1: 56.2500 (48.8257)  Acc@5: 93.7500 (86.2194)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2420/4579]  eta: 0:12:43  Lr: 0.001875  Loss: -0.3431  Acc@1: 56.2500 (48.8589)  Acc@5: 87.5000 (86.2376)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2430/4579]  eta: 0:12:40  Lr: 0.001875  Loss: 0.6592  Acc@1: 50.0000 (48.8508)  Acc@5: 87.5000 (86.2454)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2440/4579]  eta: 0:12:36  Lr: 0.001875  Loss: 0.1155  Acc@1: 50.0000 (48.8811)  Acc@5: 87.5000 (86.2505)  time: 0.3582  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [2450/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.3443  Acc@1: 56.2500 (48.9443)  Acc@5: 93.7500 (86.2837)  time: 0.3575  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [2460/4579]  eta: 0:12:29  Lr: 0.001875  Loss: 0.1248  Acc@1: 62.5000 (48.9486)  Acc@5: 93.7500 (86.2835)  time: 0.3585  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2470/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.3774  Acc@1: 56.2500 (48.9731)  Acc@5: 87.5000 (86.2758)  time: 0.3631  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [2480/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.2669  Acc@1: 56.2500 (49.0075)  Acc@5: 87.5000 (86.2782)  time: 0.3654  data: 0.0032  max mem: 2500
Train: Epoch[1/5]  [2490/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.2677  Acc@1: 62.5000 (49.0641)  Acc@5: 93.7500 (86.3107)  time: 0.3620  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [2500/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 0.0337  Acc@1: 62.5000 (49.1054)  Acc@5: 93.7500 (86.3255)  time: 0.3602  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [2510/4579]  eta: 0:12:12  Lr: 0.001875  Loss: 0.0037  Acc@1: 62.5000 (49.1413)  Acc@5: 93.7500 (86.3451)  time: 0.3617  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [2520/4579]  eta: 0:12:08  Lr: 0.001875  Loss: -0.2548  Acc@1: 62.5000 (49.1868)  Acc@5: 93.7500 (86.3720)  time: 0.3562  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2530/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.3909  Acc@1: 62.5000 (49.2493)  Acc@5: 93.7500 (86.3962)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2540/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 0.2079  Acc@1: 56.2500 (49.2793)  Acc@5: 93.7500 (86.4177)  time: 0.3505  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2550/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.2552  Acc@1: 56.2500 (49.3066)  Acc@5: 93.7500 (86.4318)  time: 0.3513  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2560/4579]  eta: 0:11:54  Lr: 0.001875  Loss: 0.7400  Acc@1: 56.2500 (49.3435)  Acc@5: 87.5000 (86.4384)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2570/4579]  eta: 0:11:50  Lr: 0.001875  Loss: -0.2533  Acc@1: 56.2500 (49.3607)  Acc@5: 93.7500 (86.4474)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2580/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.1558  Acc@1: 56.2500 (49.3849)  Acc@5: 87.5000 (86.4563)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2590/4579]  eta: 0:11:43  Lr: 0.001875  Loss: 0.2424  Acc@1: 56.2500 (49.3970)  Acc@5: 81.2500 (86.4435)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2600/4579]  eta: 0:11:40  Lr: 0.001875  Loss: -0.3040  Acc@1: 56.2500 (49.4089)  Acc@5: 87.5000 (86.4691)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2610/4579]  eta: 0:11:36  Lr: 0.001875  Loss: -0.0105  Acc@1: 50.0000 (49.4255)  Acc@5: 93.7500 (86.4755)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2620/4579]  eta: 0:11:33  Lr: 0.001875  Loss: -0.1933  Acc@1: 56.2500 (49.4563)  Acc@5: 93.7500 (86.4937)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2630/4579]  eta: 0:11:29  Lr: 0.001875  Loss: -0.0267  Acc@1: 56.2500 (49.4869)  Acc@5: 93.7500 (86.5023)  time: 0.3535  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2640/4579]  eta: 0:11:25  Lr: 0.001875  Loss: 0.4535  Acc@1: 56.2500 (49.5149)  Acc@5: 87.5000 (86.5155)  time: 0.3564  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2650/4579]  eta: 0:11:22  Lr: 0.001875  Loss: -0.1875  Acc@1: 56.2500 (49.5285)  Acc@5: 93.7500 (86.5381)  time: 0.3542  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2660/4579]  eta: 0:11:18  Lr: 0.001875  Loss: -0.5183  Acc@1: 56.2500 (49.5678)  Acc@5: 93.7500 (86.5535)  time: 0.3578  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [2670/4579]  eta: 0:11:15  Lr: 0.001875  Loss: -0.2507  Acc@1: 56.2500 (49.5835)  Acc@5: 87.5000 (86.5640)  time: 0.3623  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [2680/4579]  eta: 0:11:11  Lr: 0.001875  Loss: -0.3414  Acc@1: 56.2500 (49.6107)  Acc@5: 87.5000 (86.5815)  time: 0.3581  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2690/4579]  eta: 0:11:08  Lr: 0.001875  Loss: 0.8878  Acc@1: 50.0000 (49.6028)  Acc@5: 87.5000 (86.5803)  time: 0.3544  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2700/4579]  eta: 0:11:04  Lr: 0.001875  Loss: -0.1882  Acc@1: 50.0000 (49.6298)  Acc@5: 87.5000 (86.5883)  time: 0.3545  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2710/4579]  eta: 0:11:01  Lr: 0.001875  Loss: 0.2912  Acc@1: 56.2500 (49.6519)  Acc@5: 87.5000 (86.5778)  time: 0.3544  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2720/4579]  eta: 0:10:57  Lr: 0.001875  Loss: 0.0031  Acc@1: 56.2500 (49.6922)  Acc@5: 87.5000 (86.5858)  time: 0.3583  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2730/4579]  eta: 0:10:54  Lr: 0.001875  Loss: 0.2567  Acc@1: 56.2500 (49.7071)  Acc@5: 87.5000 (86.5754)  time: 0.3573  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2740/4579]  eta: 0:10:50  Lr: 0.001875  Loss: 0.2080  Acc@1: 43.7500 (49.7173)  Acc@5: 87.5000 (86.5765)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2750/4579]  eta: 0:10:47  Lr: 0.001875  Loss: -0.0536  Acc@1: 50.0000 (49.7342)  Acc@5: 87.5000 (86.5799)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2760/4579]  eta: 0:10:43  Lr: 0.001875  Loss: -0.0690  Acc@1: 56.2500 (49.7510)  Acc@5: 93.7500 (86.6058)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2770/4579]  eta: 0:10:40  Lr: 0.001875  Loss: 0.2941  Acc@1: 56.2500 (49.7632)  Acc@5: 87.5000 (86.5955)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2780/4579]  eta: 0:10:36  Lr: 0.001875  Loss: 0.0183  Acc@1: 56.2500 (49.7955)  Acc@5: 87.5000 (86.6055)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2790/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.0001  Acc@1: 50.0000 (49.7985)  Acc@5: 87.5000 (86.6087)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2800/4579]  eta: 0:10:29  Lr: 0.001875  Loss: -0.1134  Acc@1: 50.0000 (49.8215)  Acc@5: 81.2500 (86.6030)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2810/4579]  eta: 0:10:25  Lr: 0.001875  Loss: -0.1568  Acc@1: 56.2500 (49.8466)  Acc@5: 87.5000 (86.6218)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2820/4579]  eta: 0:10:22  Lr: 0.001875  Loss: -0.2128  Acc@1: 62.5000 (49.8892)  Acc@5: 93.7500 (86.6337)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2830/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.1699  Acc@1: 62.5000 (49.9007)  Acc@5: 87.5000 (86.6390)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2840/4579]  eta: 0:10:15  Lr: 0.001875  Loss: -0.1101  Acc@1: 62.5000 (49.9472)  Acc@5: 93.7500 (86.6508)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2850/4579]  eta: 0:10:11  Lr: 0.001875  Loss: -0.1901  Acc@1: 62.5000 (49.9978)  Acc@5: 93.7500 (86.6692)  time: 0.3540  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2860/4579]  eta: 0:10:07  Lr: 0.001875  Loss: -0.3721  Acc@1: 56.2500 (50.0328)  Acc@5: 93.7500 (86.6808)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2870/4579]  eta: 0:10:04  Lr: 0.001875  Loss: 0.2983  Acc@1: 56.2500 (50.0610)  Acc@5: 93.7500 (86.6902)  time: 0.3554  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2880/4579]  eta: 0:10:00  Lr: 0.001875  Loss: -0.5029  Acc@1: 50.0000 (50.0781)  Acc@5: 87.5000 (86.6865)  time: 0.3620  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [2890/4579]  eta: 0:09:57  Lr: 0.001875  Loss: -0.6319  Acc@1: 56.2500 (50.1232)  Acc@5: 93.7500 (86.7088)  time: 0.3658  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [2900/4579]  eta: 0:09:53  Lr: 0.001875  Loss: -0.0729  Acc@1: 62.5000 (50.1724)  Acc@5: 87.5000 (86.7072)  time: 0.3597  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2910/4579]  eta: 0:09:50  Lr: 0.001875  Loss: 0.0284  Acc@1: 56.2500 (50.1911)  Acc@5: 87.5000 (86.7099)  time: 0.3556  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2920/4579]  eta: 0:09:46  Lr: 0.001875  Loss: -0.0546  Acc@1: 56.2500 (50.2075)  Acc@5: 87.5000 (86.7126)  time: 0.3608  data: 0.0033  max mem: 2500
Train: Epoch[1/5]  [2930/4579]  eta: 0:09:43  Lr: 0.001875  Loss: 0.3548  Acc@1: 56.2500 (50.2239)  Acc@5: 87.5000 (86.7195)  time: 0.3601  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [2940/4579]  eta: 0:09:39  Lr: 0.001875  Loss: -0.2461  Acc@1: 56.2500 (50.2423)  Acc@5: 87.5000 (86.7371)  time: 0.3548  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2950/4579]  eta: 0:09:36  Lr: 0.001875  Loss: -0.1852  Acc@1: 56.2500 (50.2838)  Acc@5: 87.5000 (86.7333)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2960/4579]  eta: 0:09:32  Lr: 0.001875  Loss: 0.0151  Acc@1: 62.5000 (50.3187)  Acc@5: 87.5000 (86.7443)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2970/4579]  eta: 0:09:29  Lr: 0.001875  Loss: -0.1949  Acc@1: 62.5000 (50.3597)  Acc@5: 93.7500 (86.7553)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2980/4579]  eta: 0:09:25  Lr: 0.001875  Loss: 0.4024  Acc@1: 56.2500 (50.3732)  Acc@5: 93.7500 (86.7767)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2990/4579]  eta: 0:09:22  Lr: 0.001875  Loss: -0.3891  Acc@1: 62.5000 (50.4096)  Acc@5: 93.7500 (86.7916)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3000/4579]  eta: 0:09:18  Lr: 0.001875  Loss: 0.0315  Acc@1: 62.5000 (50.4269)  Acc@5: 87.5000 (86.7898)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3010/4579]  eta: 0:09:14  Lr: 0.001875  Loss: -0.1078  Acc@1: 56.2500 (50.4525)  Acc@5: 87.5000 (86.8026)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3020/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.3982  Acc@1: 62.5000 (50.4779)  Acc@5: 87.5000 (86.8028)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3030/4579]  eta: 0:09:07  Lr: 0.001875  Loss: -0.0163  Acc@1: 56.2500 (50.4990)  Acc@5: 87.5000 (86.8092)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3040/4579]  eta: 0:09:04  Lr: 0.001875  Loss: -0.3107  Acc@1: 56.2500 (50.5220)  Acc@5: 87.5000 (86.8197)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3050/4579]  eta: 0:09:00  Lr: 0.001875  Loss: -0.2813  Acc@1: 56.2500 (50.5510)  Acc@5: 93.7500 (86.8301)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3060/4579]  eta: 0:08:57  Lr: 0.001875  Loss: 0.4603  Acc@1: 62.5000 (50.5901)  Acc@5: 93.7500 (86.8466)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3070/4579]  eta: 0:08:53  Lr: 0.001875  Loss: 0.2311  Acc@1: 56.2500 (50.6044)  Acc@5: 93.7500 (86.8589)  time: 0.3555  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3080/4579]  eta: 0:08:50  Lr: 0.001875  Loss: 0.0715  Acc@1: 50.0000 (50.6126)  Acc@5: 87.5000 (86.8610)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3090/4579]  eta: 0:08:46  Lr: 0.001875  Loss: -0.5138  Acc@1: 50.0000 (50.6430)  Acc@5: 87.5000 (86.8651)  time: 0.3575  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3100/4579]  eta: 0:08:43  Lr: 0.001875  Loss: -0.4423  Acc@1: 62.5000 (50.6712)  Acc@5: 93.7500 (86.8812)  time: 0.3623  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [3110/4579]  eta: 0:08:39  Lr: 0.001875  Loss: 0.4068  Acc@1: 56.2500 (50.6891)  Acc@5: 87.5000 (86.8772)  time: 0.3613  data: 0.0037  max mem: 2500
Train: Epoch[1/5]  [3120/4579]  eta: 0:08:36  Lr: 0.001875  Loss: -0.4681  Acc@1: 56.2500 (50.7249)  Acc@5: 87.5000 (86.9012)  time: 0.3605  data: 0.0045  max mem: 2500
Train: Epoch[1/5]  [3130/4579]  eta: 0:08:32  Lr: 0.001875  Loss: -0.0568  Acc@1: 56.2500 (50.7346)  Acc@5: 93.7500 (86.9111)  time: 0.3578  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [3140/4579]  eta: 0:08:29  Lr: 0.001875  Loss: -0.1711  Acc@1: 50.0000 (50.7183)  Acc@5: 87.5000 (86.9050)  time: 0.3571  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [3150/4579]  eta: 0:08:25  Lr: 0.001875  Loss: 0.3644  Acc@1: 43.7500 (50.7220)  Acc@5: 87.5000 (86.9109)  time: 0.3593  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3160/4579]  eta: 0:08:22  Lr: 0.001875  Loss: 0.0396  Acc@1: 56.2500 (50.7474)  Acc@5: 93.7500 (86.9286)  time: 0.3571  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3170/4579]  eta: 0:08:18  Lr: 0.001875  Loss: 0.2308  Acc@1: 56.2500 (50.7608)  Acc@5: 87.5000 (86.9186)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3180/4579]  eta: 0:08:14  Lr: 0.001875  Loss: -0.3962  Acc@1: 56.2500 (50.7781)  Acc@5: 87.5000 (86.9302)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3190/4579]  eta: 0:08:11  Lr: 0.001875  Loss: 0.3346  Acc@1: 56.2500 (50.7991)  Acc@5: 87.5000 (86.9379)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3200/4579]  eta: 0:08:07  Lr: 0.001875  Loss: -0.3669  Acc@1: 56.2500 (50.8005)  Acc@5: 87.5000 (86.9416)  time: 0.3522  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3210/4579]  eta: 0:08:04  Lr: 0.001875  Loss: -0.0300  Acc@1: 56.2500 (50.8409)  Acc@5: 87.5000 (86.9492)  time: 0.3519  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3220/4579]  eta: 0:08:00  Lr: 0.001875  Loss: -0.2966  Acc@1: 62.5000 (50.8887)  Acc@5: 87.5000 (86.9489)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3230/4579]  eta: 0:07:57  Lr: 0.001875  Loss: -0.1636  Acc@1: 62.5000 (50.9285)  Acc@5: 87.5000 (86.9661)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3240/4579]  eta: 0:07:53  Lr: 0.001875  Loss: -0.2171  Acc@1: 62.5000 (50.9681)  Acc@5: 93.7500 (86.9948)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3250/4579]  eta: 0:07:50  Lr: 0.001875  Loss: 0.1703  Acc@1: 62.5000 (51.0266)  Acc@5: 100.0000 (87.0155)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3260/4579]  eta: 0:07:46  Lr: 0.001875  Loss: -0.0451  Acc@1: 56.2500 (51.0541)  Acc@5: 93.7500 (87.0266)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3270/4579]  eta: 0:07:43  Lr: 0.001875  Loss: -0.2176  Acc@1: 56.2500 (51.0700)  Acc@5: 93.7500 (87.0414)  time: 0.3569  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3280/4579]  eta: 0:07:39  Lr: 0.001875  Loss: 0.2102  Acc@1: 56.2500 (51.0915)  Acc@5: 93.7500 (87.0504)  time: 0.3586  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3290/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.4295  Acc@1: 56.2500 (51.1072)  Acc@5: 87.5000 (87.0518)  time: 0.3602  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [3300/4579]  eta: 0:07:32  Lr: 0.001875  Loss: 0.3018  Acc@1: 56.2500 (51.1322)  Acc@5: 87.5000 (87.0645)  time: 0.3643  data: 0.0039  max mem: 2500
Train: Epoch[1/5]  [3310/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.2432  Acc@1: 56.2500 (51.1571)  Acc@5: 93.7500 (87.0828)  time: 0.3648  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3320/4579]  eta: 0:07:25  Lr: 0.001875  Loss: -0.0844  Acc@1: 56.2500 (51.1819)  Acc@5: 93.7500 (87.0879)  time: 0.3613  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3330/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6928  Acc@1: 62.5000 (51.2234)  Acc@5: 93.7500 (87.1060)  time: 0.3575  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [3340/4579]  eta: 0:07:18  Lr: 0.001875  Loss: -0.2897  Acc@1: 62.5000 (51.2403)  Acc@5: 87.5000 (87.1146)  time: 0.3583  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [3350/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.3084  Acc@1: 56.2500 (51.2645)  Acc@5: 87.5000 (87.1121)  time: 0.3613  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [3360/4579]  eta: 0:07:11  Lr: 0.001875  Loss: -0.5016  Acc@1: 56.2500 (51.2905)  Acc@5: 87.5000 (87.1244)  time: 0.3571  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [3370/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.0071  Acc@1: 56.2500 (51.3164)  Acc@5: 87.5000 (87.1255)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3380/4579]  eta: 0:07:04  Lr: 0.001875  Loss: -0.1241  Acc@1: 56.2500 (51.3310)  Acc@5: 87.5000 (87.1358)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3390/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5622  Acc@1: 56.2500 (51.3547)  Acc@5: 87.5000 (87.1369)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3400/4579]  eta: 0:06:57  Lr: 0.001875  Loss: 0.4090  Acc@1: 56.2500 (51.3654)  Acc@5: 87.5000 (87.1527)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3410/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.2072  Acc@1: 56.2500 (51.3797)  Acc@5: 87.5000 (87.1574)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3420/4579]  eta: 0:06:50  Lr: 0.001875  Loss: -0.2508  Acc@1: 62.5000 (51.4141)  Acc@5: 87.5000 (87.1657)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3430/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.5982  Acc@1: 62.5000 (51.4373)  Acc@5: 93.7500 (87.1849)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3440/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.2395  Acc@1: 56.2500 (51.4440)  Acc@5: 93.7500 (87.1858)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3450/4579]  eta: 0:06:39  Lr: 0.001875  Loss: 0.1510  Acc@1: 56.2500 (51.4633)  Acc@5: 87.5000 (87.1939)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3460/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.3457  Acc@1: 56.2500 (51.4609)  Acc@5: 87.5000 (87.1966)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3470/4579]  eta: 0:06:32  Lr: 0.001875  Loss: 0.2872  Acc@1: 56.2500 (51.4837)  Acc@5: 87.5000 (87.2101)  time: 0.3539  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3480/4579]  eta: 0:06:28  Lr: 0.001875  Loss: 0.1334  Acc@1: 50.0000 (51.4741)  Acc@5: 87.5000 (87.2073)  time: 0.3577  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3490/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.3575  Acc@1: 50.0000 (51.4949)  Acc@5: 87.5000 (87.2135)  time: 0.3634  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [3500/4579]  eta: 0:06:21  Lr: 0.001875  Loss: 0.0984  Acc@1: 56.2500 (51.5085)  Acc@5: 87.5000 (87.2197)  time: 0.3651  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [3510/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.0357  Acc@1: 50.0000 (51.5202)  Acc@5: 87.5000 (87.2259)  time: 0.3595  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3520/4579]  eta: 0:06:14  Lr: 0.001875  Loss: 0.0356  Acc@1: 56.2500 (51.5443)  Acc@5: 87.5000 (87.2373)  time: 0.3539  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3530/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.0163  Acc@1: 56.2500 (51.5576)  Acc@5: 87.5000 (87.2433)  time: 0.3579  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [3540/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.3588  Acc@1: 56.2500 (51.5779)  Acc@5: 93.7500 (87.2511)  time: 0.3601  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [3550/4579]  eta: 0:06:04  Lr: 0.001875  Loss: 0.4177  Acc@1: 62.5000 (51.6034)  Acc@5: 93.7500 (87.2606)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3560/4579]  eta: 0:06:00  Lr: 0.001875  Loss: -0.0061  Acc@1: 56.2500 (51.6200)  Acc@5: 87.5000 (87.2666)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3570/4579]  eta: 0:05:57  Lr: 0.001875  Loss: 0.6736  Acc@1: 56.2500 (51.6382)  Acc@5: 87.5000 (87.2620)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3580/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.4111  Acc@1: 56.2500 (51.6633)  Acc@5: 87.5000 (87.2696)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3590/4579]  eta: 0:05:49  Lr: 0.001875  Loss: -0.4685  Acc@1: 56.2500 (51.6726)  Acc@5: 93.7500 (87.2772)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3600/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.0592  Acc@1: 56.2500 (51.6974)  Acc@5: 87.5000 (87.2865)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3610/4579]  eta: 0:05:42  Lr: 0.001875  Loss: -0.2270  Acc@1: 56.2500 (51.7291)  Acc@5: 87.5000 (87.3010)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3620/4579]  eta: 0:05:39  Lr: 0.001875  Loss: 0.3888  Acc@1: 56.2500 (51.7295)  Acc@5: 93.7500 (87.3067)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3630/4579]  eta: 0:05:35  Lr: 0.001875  Loss: 0.0148  Acc@1: 56.2500 (51.7471)  Acc@5: 93.7500 (87.3193)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3640/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.0763  Acc@1: 62.5000 (51.7698)  Acc@5: 93.7500 (87.3318)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3650/4579]  eta: 0:05:28  Lr: 0.001875  Loss: -0.2083  Acc@1: 62.5000 (51.7957)  Acc@5: 93.7500 (87.3442)  time: 0.3516  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3660/4579]  eta: 0:05:25  Lr: 0.001875  Loss: -0.2381  Acc@1: 62.5000 (51.8233)  Acc@5: 93.7500 (87.3634)  time: 0.3571  data: 0.0032  max mem: 2500
Train: Epoch[1/5]  [3670/4579]  eta: 0:05:21  Lr: 0.001875  Loss: 0.8737  Acc@1: 68.7500 (51.8472)  Acc@5: 93.7500 (87.3706)  time: 0.3567  data: 0.0039  max mem: 2500
Train: Epoch[1/5]  [3680/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.2950  Acc@1: 62.5000 (51.8762)  Acc@5: 93.7500 (87.3862)  time: 0.3580  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [3690/4579]  eta: 0:05:14  Lr: 0.001875  Loss: -0.3306  Acc@1: 62.5000 (51.8948)  Acc@5: 93.7500 (87.3984)  time: 0.3608  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3700/4579]  eta: 0:05:10  Lr: 0.001875  Loss: 0.1696  Acc@1: 56.2500 (51.9032)  Acc@5: 87.5000 (87.4088)  time: 0.3609  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3710/4579]  eta: 0:05:07  Lr: 0.001875  Loss: -0.0147  Acc@1: 50.0000 (51.9149)  Acc@5: 87.5000 (87.4175)  time: 0.3581  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3720/4579]  eta: 0:05:03  Lr: 0.001875  Loss: -0.2267  Acc@1: 50.0000 (51.9148)  Acc@5: 93.7500 (87.4261)  time: 0.3563  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [3730/4579]  eta: 0:05:00  Lr: 0.001875  Loss: 0.2006  Acc@1: 56.2500 (51.9315)  Acc@5: 93.7500 (87.4347)  time: 0.3586  data: 0.0042  max mem: 2500
Train: Epoch[1/5]  [3740/4579]  eta: 0:04:56  Lr: 0.001875  Loss: -0.1470  Acc@1: 62.5000 (51.9564)  Acc@5: 93.7500 (87.4432)  time: 0.3610  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [3750/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 0.2717  Acc@1: 56.2500 (51.9545)  Acc@5: 87.5000 (87.4483)  time: 0.3555  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3760/4579]  eta: 0:04:49  Lr: 0.001875  Loss: -0.1059  Acc@1: 56.2500 (51.9725)  Acc@5: 87.5000 (87.4601)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3770/4579]  eta: 0:04:46  Lr: 0.001875  Loss: -0.2403  Acc@1: 62.5000 (51.9889)  Acc@5: 87.5000 (87.4586)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3780/4579]  eta: 0:04:42  Lr: 0.001875  Loss: -0.1161  Acc@1: 62.5000 (52.0101)  Acc@5: 93.7500 (87.4736)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3790/4579]  eta: 0:04:39  Lr: 0.001875  Loss: -0.0856  Acc@1: 62.5000 (52.0377)  Acc@5: 93.7500 (87.4885)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3800/4579]  eta: 0:04:35  Lr: 0.001875  Loss: -0.2381  Acc@1: 62.5000 (52.0603)  Acc@5: 93.7500 (87.4951)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3810/4579]  eta: 0:04:32  Lr: 0.001875  Loss: 0.4472  Acc@1: 56.2500 (52.0762)  Acc@5: 87.5000 (87.4934)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3820/4579]  eta: 0:04:28  Lr: 0.001875  Loss: -0.3520  Acc@1: 56.2500 (52.0806)  Acc@5: 87.5000 (87.5033)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3830/4579]  eta: 0:04:24  Lr: 0.001875  Loss: 0.0462  Acc@1: 56.2500 (52.0931)  Acc@5: 93.7500 (87.5163)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3840/4579]  eta: 0:04:21  Lr: 0.001875  Loss: -0.3450  Acc@1: 56.2500 (52.1218)  Acc@5: 93.7500 (87.5244)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3850/4579]  eta: 0:04:17  Lr: 0.001875  Loss: 0.5966  Acc@1: 62.5000 (52.1342)  Acc@5: 87.5000 (87.5308)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3860/4579]  eta: 0:04:14  Lr: 0.001875  Loss: -0.4606  Acc@1: 56.2500 (52.1594)  Acc@5: 87.5000 (87.5308)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:10  Lr: 0.001875  Loss: -0.1361  Acc@1: 62.5000 (52.1700)  Acc@5: 87.5000 (87.5371)  time: 0.3532  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:07  Lr: 0.001875  Loss: -0.2043  Acc@1: 56.2500 (52.1885)  Acc@5: 87.5000 (87.5386)  time: 0.3550  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [3890/4579]  eta: 0:04:03  Lr: 0.001875  Loss: -0.1166  Acc@1: 56.2500 (52.1926)  Acc@5: 87.5000 (87.5369)  time: 0.3587  data: 0.0041  max mem: 2500
Train: Epoch[1/5]  [3900/4579]  eta: 0:04:00  Lr: 0.001875  Loss: -0.2806  Acc@1: 62.5000 (52.2158)  Acc@5: 93.7500 (87.5449)  time: 0.3601  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [3910/4579]  eta: 0:03:56  Lr: 0.001875  Loss: -0.1991  Acc@1: 62.5000 (52.2261)  Acc@5: 93.7500 (87.5543)  time: 0.3576  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [3920/4579]  eta: 0:03:53  Lr: 0.001875  Loss: -0.0961  Acc@1: 50.0000 (52.2284)  Acc@5: 87.5000 (87.5478)  time: 0.3571  data: 0.0035  max mem: 2500
Train: Epoch[1/5]  [3930/4579]  eta: 0:03:49  Lr: 0.001875  Loss: 0.1307  Acc@1: 56.2500 (52.2370)  Acc@5: 87.5000 (87.5445)  time: 0.3579  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [3940/4579]  eta: 0:03:46  Lr: 0.001875  Loss: -0.1067  Acc@1: 56.2500 (52.2583)  Acc@5: 93.7500 (87.5650)  time: 0.3542  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3950/4579]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7175  Acc@1: 56.2500 (52.2573)  Acc@5: 93.7500 (87.5617)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3960/4579]  eta: 0:03:38  Lr: 0.001875  Loss: -0.2550  Acc@1: 56.2500 (52.2911)  Acc@5: 93.7500 (87.5805)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3970/4579]  eta: 0:03:35  Lr: 0.001875  Loss: 0.0130  Acc@1: 62.5000 (52.3136)  Acc@5: 93.7500 (87.5897)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3980/4579]  eta: 0:03:31  Lr: 0.001875  Loss: 0.3225  Acc@1: 62.5000 (52.3502)  Acc@5: 93.7500 (87.6020)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3990/4579]  eta: 0:03:28  Lr: 0.001875  Loss: 0.0937  Acc@1: 62.5000 (52.3553)  Acc@5: 93.7500 (87.6096)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4000/4579]  eta: 0:03:24  Lr: 0.001875  Loss: -0.0773  Acc@1: 56.2500 (52.3744)  Acc@5: 87.5000 (87.6156)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:21  Lr: 0.001875  Loss: 0.2490  Acc@1: 56.2500 (52.3950)  Acc@5: 87.5000 (87.6169)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:17  Lr: 0.001875  Loss: -0.4745  Acc@1: 56.2500 (52.4186)  Acc@5: 87.5000 (87.6321)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:14  Lr: 0.001875  Loss: -0.2870  Acc@1: 56.2500 (52.4358)  Acc@5: 93.7500 (87.6318)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:10  Lr: 0.001875  Loss: 0.3799  Acc@1: 56.2500 (52.4592)  Acc@5: 87.5000 (87.6346)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:07  Lr: 0.001875  Loss: 0.2374  Acc@1: 56.2500 (52.4732)  Acc@5: 87.5000 (87.6373)  time: 0.3529  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4060/4579]  eta: 0:03:03  Lr: 0.001875  Loss: 0.4957  Acc@1: 56.2500 (52.4809)  Acc@5: 87.5000 (87.6385)  time: 0.3576  data: 0.0033  max mem: 2500
Train: Epoch[1/5]  [4070/4579]  eta: 0:03:00  Lr: 0.001875  Loss: -0.2163  Acc@1: 62.5000 (52.5040)  Acc@5: 87.5000 (87.6443)  time: 0.3573  data: 0.0040  max mem: 2500
Train: Epoch[1/5]  [4080/4579]  eta: 0:02:56  Lr: 0.001875  Loss: 0.4829  Acc@1: 62.5000 (52.5070)  Acc@5: 87.5000 (87.6470)  time: 0.3566  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [4090/4579]  eta: 0:02:52  Lr: 0.001875  Loss: -0.1412  Acc@1: 56.2500 (52.5177)  Acc@5: 93.7500 (87.6528)  time: 0.3586  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4100/4579]  eta: 0:02:49  Lr: 0.001875  Loss: -0.2130  Acc@1: 56.2500 (52.5421)  Acc@5: 93.7500 (87.6676)  time: 0.3614  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [4110/4579]  eta: 0:02:45  Lr: 0.001875  Loss: 0.0720  Acc@1: 62.5000 (52.5617)  Acc@5: 93.7500 (87.6672)  time: 0.3589  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [4120/4579]  eta: 0:02:42  Lr: 0.001875  Loss: -0.2192  Acc@1: 56.2500 (52.5692)  Acc@5: 87.5000 (87.6729)  time: 0.3561  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [4130/4579]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4234  Acc@1: 56.2500 (52.5977)  Acc@5: 87.5000 (87.6800)  time: 0.3618  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4140/4579]  eta: 0:02:35  Lr: 0.001875  Loss: -0.3695  Acc@1: 62.5000 (52.6201)  Acc@5: 87.5000 (87.6902)  time: 0.3616  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:31  Lr: 0.001875  Loss: 0.3562  Acc@1: 62.5000 (52.6439)  Acc@5: 93.7500 (87.7018)  time: 0.3530  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:28  Lr: 0.001875  Loss: -0.3223  Acc@1: 62.5000 (52.6631)  Acc@5: 87.5000 (87.6968)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:24  Lr: 0.001875  Loss: 0.0572  Acc@1: 56.2500 (52.6747)  Acc@5: 87.5000 (87.7008)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:21  Lr: 0.001875  Loss: 0.1025  Acc@1: 56.2500 (52.6878)  Acc@5: 87.5000 (87.7108)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:17  Lr: 0.001875  Loss: 0.1838  Acc@1: 56.2500 (52.7022)  Acc@5: 93.7500 (87.7162)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:14  Lr: 0.001875  Loss: 0.1171  Acc@1: 56.2500 (52.7002)  Acc@5: 87.5000 (87.7157)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:10  Lr: 0.001875  Loss: 1.2589  Acc@1: 56.2500 (52.7191)  Acc@5: 87.5000 (87.7137)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1994  Acc@1: 62.5000 (52.7408)  Acc@5: 87.5000 (87.7162)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:03  Lr: 0.001875  Loss: -0.1318  Acc@1: 62.5000 (52.7520)  Acc@5: 87.5000 (87.7142)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4240/4579]  eta: 0:01:59  Lr: 0.001875  Loss: 0.2492  Acc@1: 62.5000 (52.7706)  Acc@5: 87.5000 (87.7152)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4250/4579]  eta: 0:01:56  Lr: 0.001875  Loss: 0.1273  Acc@1: 62.5000 (52.7758)  Acc@5: 87.5000 (87.7176)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4260/4579]  eta: 0:01:52  Lr: 0.001875  Loss: -0.3628  Acc@1: 62.5000 (52.8045)  Acc@5: 87.5000 (87.7215)  time: 0.3546  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [4270/4579]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7291  Acc@1: 62.5000 (52.8272)  Acc@5: 93.7500 (87.7312)  time: 0.3570  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [4280/4579]  eta: 0:01:45  Lr: 0.001875  Loss: -0.3576  Acc@1: 62.5000 (52.8542)  Acc@5: 93.7500 (87.7438)  time: 0.3607  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:42  Lr: 0.001875  Loss: -0.1220  Acc@1: 62.5000 (52.8723)  Acc@5: 93.7500 (87.7622)  time: 0.3647  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:38  Lr: 0.001875  Loss: -0.7133  Acc@1: 62.5000 (52.9005)  Acc@5: 93.7500 (87.7703)  time: 0.3636  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:35  Lr: 0.001875  Loss: -0.3391  Acc@1: 56.2500 (52.9097)  Acc@5: 87.5000 (87.7769)  time: 0.3558  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:31  Lr: 0.001875  Loss: 0.3181  Acc@1: 62.5000 (52.9420)  Acc@5: 87.5000 (87.7792)  time: 0.3543  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:28  Lr: 0.001875  Loss: -0.0181  Acc@1: 62.5000 (52.9684)  Acc@5: 87.5000 (87.7901)  time: 0.3586  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5763  Acc@1: 62.5000 (52.9817)  Acc@5: 93.7500 (87.7952)  time: 0.3545  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1571  Acc@1: 62.5000 (53.0051)  Acc@5: 93.7500 (87.8045)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:17  Lr: 0.001875  Loss: 0.2680  Acc@1: 62.5000 (53.0297)  Acc@5: 93.7500 (87.8110)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.2028  Acc@1: 62.5000 (53.0399)  Acc@5: 87.5000 (87.8174)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3255  Acc@1: 56.2500 (53.0415)  Acc@5: 87.5000 (87.8153)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6952  Acc@1: 56.2500 (53.0560)  Acc@5: 93.7500 (87.8274)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:03  Lr: 0.001875  Loss: -0.0239  Acc@1: 62.5000 (53.0760)  Acc@5: 87.5000 (87.8309)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: 0.0098  Acc@1: 62.5000 (53.0945)  Acc@5: 87.5000 (87.8429)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4420/4579]  eta: 0:00:56  Lr: 0.001875  Loss: -0.0211  Acc@1: 62.5000 (53.1271)  Acc@5: 93.7500 (87.8520)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: 0.2015  Acc@1: 62.5000 (53.1342)  Acc@5: 93.7500 (87.8597)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:49  Lr: 0.001875  Loss: -0.2407  Acc@1: 56.2500 (53.1651)  Acc@5: 93.7500 (87.8673)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1931  Acc@1: 68.7500 (53.1903)  Acc@5: 93.7500 (87.8805)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:42  Lr: 0.001875  Loss: -0.2718  Acc@1: 56.2500 (53.1972)  Acc@5: 87.5000 (87.8755)  time: 0.3548  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5226  Acc@1: 50.0000 (53.1970)  Acc@5: 87.5000 (87.8872)  time: 0.3591  data: 0.0035  max mem: 2500
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:35  Lr: 0.001875  Loss: -0.4281  Acc@1: 56.2500 (53.2247)  Acc@5: 93.7500 (87.9017)  time: 0.3602  data: 0.0033  max mem: 2500
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.3254  Acc@1: 68.7500 (53.2342)  Acc@5: 93.7500 (87.9064)  time: 0.3633  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.0274  Acc@1: 62.5000 (53.2590)  Acc@5: 93.7500 (87.9138)  time: 0.3585  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0661  Acc@1: 62.5000 (53.2739)  Acc@5: 93.7500 (87.9184)  time: 0.3538  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.1042  Acc@1: 62.5000 (53.2971)  Acc@5: 93.7500 (87.9258)  time: 0.3574  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: 0.5370  Acc@1: 56.2500 (53.2995)  Acc@5: 93.7500 (87.9345)  time: 0.3568  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0875  Acc@1: 56.2500 (53.3142)  Acc@5: 87.5000 (87.9377)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.3691  Acc@1: 62.5000 (53.3399)  Acc@5: 87.5000 (87.9408)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.3503  Acc@1: 62.5000 (53.3532)  Acc@5: 87.5000 (87.9440)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.1477  Acc@1: 62.5000 (53.3773)  Acc@5: 93.7500 (87.9553)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.9238  Acc@1: 56.2500 (53.3751)  Acc@5: 87.5000 (87.9547)  time: 0.3570  data: 0.0010  max mem: 2500
Train: Epoch[1/5] Total time: 0:27:00 (0.3539 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.9238  Acc@1: 56.2500 (53.3751)  Acc@5: 87.5000 (87.9547)
Train: Epoch[2/5]  [   0/4579]  eta: 0:57:43  Lr: 0.001875  Loss: -0.3061  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7563  data: 0.3991  max mem: 2500
Train: Epoch[2/5]  [  10/4579]  eta: 0:29:15  Lr: 0.001875  Loss: -0.3515  Acc@1: 62.5000 (63.0682)  Acc@5: 93.7500 (91.4773)  time: 0.3843  data: 0.0367  max mem: 2500
Train: Epoch[2/5]  [  20/4579]  eta: 0:27:50  Lr: 0.001875  Loss: -0.4993  Acc@1: 62.5000 (65.1786)  Acc@5: 93.7500 (90.7738)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  30/4579]  eta: 0:27:15  Lr: 0.001875  Loss: 0.5603  Acc@1: 62.5000 (62.2984)  Acc@5: 93.7500 (90.7258)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  40/4579]  eta: 0:26:56  Lr: 0.001875  Loss: 0.4992  Acc@1: 56.2500 (61.2805)  Acc@5: 93.7500 (90.0915)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  50/4579]  eta: 0:26:45  Lr: 0.001875  Loss: -0.1855  Acc@1: 56.2500 (61.3971)  Acc@5: 87.5000 (89.9510)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  60/4579]  eta: 0:26:39  Lr: 0.001875  Loss: -0.2384  Acc@1: 62.5000 (61.4754)  Acc@5: 87.5000 (90.2664)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  70/4579]  eta: 0:26:35  Lr: 0.001875  Loss: -0.2858  Acc@1: 62.5000 (61.3556)  Acc@5: 93.7500 (89.9648)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  80/4579]  eta: 0:26:31  Lr: 0.001875  Loss: 0.7211  Acc@1: 62.5000 (60.8025)  Acc@5: 87.5000 (89.6605)  time: 0.3533  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [  90/4579]  eta: 0:26:31  Lr: 0.001875  Loss: 0.0148  Acc@1: 62.5000 (61.1951)  Acc@5: 87.5000 (89.8352)  time: 0.3570  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [ 100/4579]  eta: 0:26:28  Lr: 0.001875  Loss: -0.2594  Acc@1: 62.5000 (61.3243)  Acc@5: 93.7500 (89.7277)  time: 0.3580  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [ 110/4579]  eta: 0:26:26  Lr: 0.001875  Loss: -0.1405  Acc@1: 62.5000 (60.9234)  Acc@5: 87.5000 (89.7523)  time: 0.3570  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 120/4579]  eta: 0:26:23  Lr: 0.001875  Loss: 0.5423  Acc@1: 56.2500 (60.6405)  Acc@5: 87.5000 (89.5661)  time: 0.3576  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 130/4579]  eta: 0:26:21  Lr: 0.001875  Loss: -0.0631  Acc@1: 56.2500 (60.4008)  Acc@5: 87.5000 (89.4561)  time: 0.3581  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 140/4579]  eta: 0:26:18  Lr: 0.001875  Loss: -0.3151  Acc@1: 56.2500 (60.0621)  Acc@5: 87.5000 (89.3174)  time: 0.3589  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 150/4579]  eta: 0:26:17  Lr: 0.001875  Loss: -0.2380  Acc@1: 56.2500 (59.8096)  Acc@5: 93.7500 (89.5695)  time: 0.3614  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [ 160/4579]  eta: 0:26:12  Lr: 0.001875  Loss: 0.0047  Acc@1: 50.0000 (59.5885)  Acc@5: 93.7500 (89.7904)  time: 0.3572  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 170/4579]  eta: 0:26:07  Lr: 0.001875  Loss: -0.0246  Acc@1: 56.2500 (59.3567)  Acc@5: 93.7500 (89.7661)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 180/4579]  eta: 0:26:02  Lr: 0.001875  Loss: 0.3986  Acc@1: 62.5000 (59.4959)  Acc@5: 93.7500 (89.9862)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 190/4579]  eta: 0:25:57  Lr: 0.001875  Loss: -0.1752  Acc@1: 62.5000 (59.5550)  Acc@5: 87.5000 (89.7579)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 200/4579]  eta: 0:25:52  Lr: 0.001875  Loss: -0.2129  Acc@1: 62.5000 (59.5771)  Acc@5: 87.5000 (89.8010)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 210/4579]  eta: 0:25:47  Lr: 0.001875  Loss: -0.0073  Acc@1: 62.5000 (59.8934)  Acc@5: 87.5000 (89.7216)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 220/4579]  eta: 0:25:43  Lr: 0.001875  Loss: 0.0982  Acc@1: 62.5000 (60.0113)  Acc@5: 87.5000 (89.6210)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 230/4579]  eta: 0:25:38  Lr: 0.001875  Loss: -0.1851  Acc@1: 62.5000 (60.3084)  Acc@5: 93.7500 (89.8810)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 240/4579]  eta: 0:25:34  Lr: 0.001875  Loss: -0.4827  Acc@1: 68.7500 (60.6587)  Acc@5: 93.7500 (89.8859)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 250/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 0.2104  Acc@1: 62.5000 (60.5827)  Acc@5: 93.7500 (89.8904)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 260/4579]  eta: 0:25:25  Lr: 0.001875  Loss: -0.3046  Acc@1: 62.5000 (60.7280)  Acc@5: 93.7500 (90.0623)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 270/4579]  eta: 0:25:22  Lr: 0.001875  Loss: -0.2691  Acc@1: 62.5000 (60.7011)  Acc@5: 93.7500 (90.1522)  time: 0.3555  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [ 280/4579]  eta: 0:25:19  Lr: 0.001875  Loss: -0.0285  Acc@1: 62.5000 (60.8096)  Acc@5: 93.7500 (90.1690)  time: 0.3568  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [ 290/4579]  eta: 0:25:17  Lr: 0.001875  Loss: 0.0276  Acc@1: 62.5000 (60.8892)  Acc@5: 93.7500 (90.1203)  time: 0.3595  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 300/4579]  eta: 0:25:15  Lr: 0.001875  Loss: -0.1985  Acc@1: 62.5000 (61.0257)  Acc@5: 93.7500 (90.1370)  time: 0.3641  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [ 310/4579]  eta: 0:25:12  Lr: 0.001875  Loss: 0.0020  Acc@1: 68.7500 (61.2138)  Acc@5: 93.7500 (90.1527)  time: 0.3613  data: 0.0045  max mem: 2500
Train: Epoch[2/5]  [ 320/4579]  eta: 0:25:09  Lr: 0.001875  Loss: -0.0978  Acc@1: 62.5000 (61.0592)  Acc@5: 93.7500 (90.2453)  time: 0.3557  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 330/4579]  eta: 0:25:05  Lr: 0.001875  Loss: -0.1844  Acc@1: 62.5000 (61.0838)  Acc@5: 93.7500 (90.1813)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 340/4579]  eta: 0:25:02  Lr: 0.001875  Loss: -0.0022  Acc@1: 62.5000 (61.0337)  Acc@5: 87.5000 (90.1760)  time: 0.3545  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 350/4579]  eta: 0:24:58  Lr: 0.001875  Loss: -0.1027  Acc@1: 56.2500 (61.0399)  Acc@5: 93.7500 (90.2778)  time: 0.3548  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 360/4579]  eta: 0:24:54  Lr: 0.001875  Loss: 0.3039  Acc@1: 56.2500 (61.0111)  Acc@5: 93.7500 (90.3047)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 370/4579]  eta: 0:24:49  Lr: 0.001875  Loss: 0.2488  Acc@1: 62.5000 (61.0849)  Acc@5: 93.7500 (90.3133)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 380/4579]  eta: 0:24:45  Lr: 0.001875  Loss: 0.1427  Acc@1: 62.5000 (61.0728)  Acc@5: 93.7500 (90.3215)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 390/4579]  eta: 0:24:41  Lr: 0.001875  Loss: 0.2248  Acc@1: 56.2500 (60.9974)  Acc@5: 87.5000 (90.2334)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 400/4579]  eta: 0:24:37  Lr: 0.001875  Loss: -0.7456  Acc@1: 62.5000 (61.1284)  Acc@5: 87.5000 (90.3055)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 410/4579]  eta: 0:24:33  Lr: 0.001875  Loss: -0.3456  Acc@1: 68.7500 (61.1922)  Acc@5: 93.7500 (90.3437)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 420/4579]  eta: 0:24:29  Lr: 0.001875  Loss: -0.0791  Acc@1: 62.5000 (61.1787)  Acc@5: 87.5000 (90.2316)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 430/4579]  eta: 0:24:25  Lr: 0.001875  Loss: 0.0121  Acc@1: 62.5000 (61.1369)  Acc@5: 87.5000 (90.2697)  time: 0.3491  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 440/4579]  eta: 0:24:21  Lr: 0.001875  Loss: -0.2805  Acc@1: 62.5000 (61.1961)  Acc@5: 93.7500 (90.2920)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 450/4579]  eta: 0:24:18  Lr: 0.001875  Loss: -0.0604  Acc@1: 62.5000 (61.1142)  Acc@5: 87.5000 (90.1746)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 460/4579]  eta: 0:24:15  Lr: 0.001875  Loss: -0.4317  Acc@1: 62.5000 (61.1714)  Acc@5: 93.7500 (90.2386)  time: 0.3612  data: 0.0038  max mem: 2500
Train: Epoch[2/5]  [ 470/4579]  eta: 0:24:12  Lr: 0.001875  Loss: 0.5751  Acc@1: 62.5000 (61.1730)  Acc@5: 93.7500 (90.2335)  time: 0.3603  data: 0.0052  max mem: 2500
Train: Epoch[2/5]  [ 480/4579]  eta: 0:24:09  Lr: 0.001875  Loss: -0.6892  Acc@1: 62.5000 (61.2136)  Acc@5: 93.7500 (90.2417)  time: 0.3586  data: 0.0040  max mem: 2500
Train: Epoch[2/5]  [ 490/4579]  eta: 0:24:06  Lr: 0.001875  Loss: -0.1959  Acc@1: 62.5000 (61.2907)  Acc@5: 87.5000 (90.2622)  time: 0.3596  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [ 500/4579]  eta: 0:24:03  Lr: 0.001875  Loss: -0.2958  Acc@1: 62.5000 (61.2026)  Acc@5: 87.5000 (90.2944)  time: 0.3623  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [ 510/4579]  eta: 0:24:00  Lr: 0.001875  Loss: 0.1110  Acc@1: 56.2500 (61.1424)  Acc@5: 93.7500 (90.3131)  time: 0.3572  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 520/4579]  eta: 0:23:56  Lr: 0.001875  Loss: 0.4270  Acc@1: 62.5000 (61.1684)  Acc@5: 87.5000 (90.2591)  time: 0.3542  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 530/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 0.2403  Acc@1: 62.5000 (61.1347)  Acc@5: 87.5000 (90.1483)  time: 0.3577  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [ 540/4579]  eta: 0:23:49  Lr: 0.001875  Loss: -0.2316  Acc@1: 62.5000 (61.1252)  Acc@5: 87.5000 (90.1571)  time: 0.3556  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [ 550/4579]  eta: 0:23:45  Lr: 0.001875  Loss: -0.4103  Acc@1: 62.5000 (61.2069)  Acc@5: 93.7500 (90.1996)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 560/4579]  eta: 0:23:41  Lr: 0.001875  Loss: 0.1995  Acc@1: 56.2500 (61.1074)  Acc@5: 93.7500 (90.1627)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 570/4579]  eta: 0:23:38  Lr: 0.001875  Loss: -0.1762  Acc@1: 62.5000 (61.1756)  Acc@5: 93.7500 (90.2145)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 580/4579]  eta: 0:23:34  Lr: 0.001875  Loss: 0.1420  Acc@1: 62.5000 (61.1876)  Acc@5: 93.7500 (90.2108)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 590/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.0417  Acc@1: 56.2500 (61.1041)  Acc@5: 93.7500 (90.2179)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 600/4579]  eta: 0:23:26  Lr: 0.001875  Loss: 0.3333  Acc@1: 56.2500 (61.1169)  Acc@5: 93.7500 (90.2246)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 610/4579]  eta: 0:23:22  Lr: 0.001875  Loss: -0.8190  Acc@1: 56.2500 (61.2111)  Acc@5: 93.7500 (90.2414)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 620/4579]  eta: 0:23:18  Lr: 0.001875  Loss: 0.2296  Acc@1: 56.2500 (61.2319)  Acc@5: 93.7500 (90.3180)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 630/4579]  eta: 0:23:15  Lr: 0.001875  Loss: -0.3103  Acc@1: 56.2500 (61.1926)  Acc@5: 93.7500 (90.3724)  time: 0.3475  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 640/4579]  eta: 0:23:11  Lr: 0.001875  Loss: -0.3593  Acc@1: 62.5000 (61.2422)  Acc@5: 93.7500 (90.3764)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 650/4579]  eta: 0:23:07  Lr: 0.001875  Loss: -0.0815  Acc@1: 56.2500 (61.2423)  Acc@5: 87.5000 (90.3802)  time: 0.3525  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 660/4579]  eta: 0:23:04  Lr: 0.001875  Loss: 0.5967  Acc@1: 56.2500 (61.1668)  Acc@5: 87.5000 (90.3555)  time: 0.3535  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 670/4579]  eta: 0:23:01  Lr: 0.001875  Loss: 0.0355  Acc@1: 62.5000 (61.2425)  Acc@5: 87.5000 (90.3502)  time: 0.3555  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 680/4579]  eta: 0:22:57  Lr: 0.001875  Loss: -0.4064  Acc@1: 68.7500 (61.3620)  Acc@5: 93.7500 (90.3910)  time: 0.3586  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 690/4579]  eta: 0:22:54  Lr: 0.001875  Loss: -0.8459  Acc@1: 68.7500 (61.5141)  Acc@5: 93.7500 (90.4486)  time: 0.3605  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 700/4579]  eta: 0:22:51  Lr: 0.001875  Loss: -0.5281  Acc@1: 68.7500 (61.6084)  Acc@5: 93.7500 (90.4690)  time: 0.3596  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 710/4579]  eta: 0:22:48  Lr: 0.001875  Loss: 0.4385  Acc@1: 62.5000 (61.5946)  Acc@5: 93.7500 (90.4887)  time: 0.3582  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [ 720/4579]  eta: 0:22:45  Lr: 0.001875  Loss: -0.1723  Acc@1: 62.5000 (61.5378)  Acc@5: 93.7500 (90.5166)  time: 0.3588  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [ 730/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.1877  Acc@1: 56.2500 (61.4313)  Acc@5: 87.5000 (90.5010)  time: 0.3571  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 740/4579]  eta: 0:22:37  Lr: 0.001875  Loss: -0.6421  Acc@1: 56.2500 (61.3782)  Acc@5: 93.7500 (90.5196)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 750/4579]  eta: 0:22:33  Lr: 0.001875  Loss: 0.2421  Acc@1: 56.2500 (61.3515)  Acc@5: 93.7500 (90.5043)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 760/4579]  eta: 0:22:30  Lr: 0.001875  Loss: -0.6906  Acc@1: 62.5000 (61.3420)  Acc@5: 87.5000 (90.4977)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 770/4579]  eta: 0:22:26  Lr: 0.001875  Loss: 0.6107  Acc@1: 56.2500 (61.2840)  Acc@5: 87.5000 (90.4831)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 780/4579]  eta: 0:22:22  Lr: 0.001875  Loss: -0.0222  Acc@1: 56.2500 (61.2836)  Acc@5: 87.5000 (90.4850)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 790/4579]  eta: 0:22:18  Lr: 0.001875  Loss: -0.2456  Acc@1: 62.5000 (61.2674)  Acc@5: 87.5000 (90.4551)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 800/4579]  eta: 0:22:15  Lr: 0.001875  Loss: -0.4865  Acc@1: 62.5000 (61.3140)  Acc@5: 93.7500 (90.5119)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 810/4579]  eta: 0:22:11  Lr: 0.001875  Loss: 0.0416  Acc@1: 56.2500 (61.2130)  Acc@5: 93.7500 (90.4516)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 820/4579]  eta: 0:22:07  Lr: 0.001875  Loss: -0.5256  Acc@1: 62.5000 (61.2591)  Acc@5: 93.7500 (90.4918)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 830/4579]  eta: 0:22:03  Lr: 0.001875  Loss: 0.0061  Acc@1: 62.5000 (61.2515)  Acc@5: 87.5000 (90.4483)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 840/4579]  eta: 0:22:00  Lr: 0.001875  Loss: 0.5258  Acc@1: 62.5000 (61.2292)  Acc@5: 87.5000 (90.4429)  time: 0.3521  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [ 850/4579]  eta: 0:21:57  Lr: 0.001875  Loss: 0.2835  Acc@1: 62.5000 (61.2515)  Acc@5: 87.5000 (90.4157)  time: 0.3567  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [ 860/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 0.1112  Acc@1: 62.5000 (61.2732)  Acc@5: 87.5000 (90.4181)  time: 0.3551  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 870/4579]  eta: 0:21:50  Lr: 0.001875  Loss: -0.0074  Acc@1: 62.5000 (61.2586)  Acc@5: 87.5000 (90.3918)  time: 0.3574  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 880/4579]  eta: 0:21:47  Lr: 0.001875  Loss: 0.0522  Acc@1: 56.2500 (61.2514)  Acc@5: 93.7500 (90.4370)  time: 0.3643  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [ 890/4579]  eta: 0:21:44  Lr: 0.001875  Loss: 0.1331  Acc@1: 56.2500 (61.1813)  Acc@5: 93.7500 (90.4321)  time: 0.3623  data: 0.0036  max mem: 2500
Train: Epoch[2/5]  [ 900/4579]  eta: 0:21:40  Lr: 0.001875  Loss: -0.3142  Acc@1: 56.2500 (61.1612)  Acc@5: 93.7500 (90.4550)  time: 0.3574  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [ 910/4579]  eta: 0:21:37  Lr: 0.001875  Loss: -0.1214  Acc@1: 62.5000 (61.1965)  Acc@5: 87.5000 (90.4226)  time: 0.3570  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [ 920/4579]  eta: 0:21:33  Lr: 0.001875  Loss: -0.0731  Acc@1: 62.5000 (61.2039)  Acc@5: 93.7500 (90.4791)  time: 0.3545  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [ 930/4579]  eta: 0:21:29  Lr: 0.001875  Loss: -0.0925  Acc@1: 62.5000 (61.2245)  Acc@5: 93.7500 (90.5142)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 940/4579]  eta: 0:21:26  Lr: 0.001875  Loss: 0.2475  Acc@1: 62.5000 (61.2779)  Acc@5: 93.7500 (90.5088)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 950/4579]  eta: 0:21:22  Lr: 0.001875  Loss: -0.3571  Acc@1: 62.5000 (61.3302)  Acc@5: 93.7500 (90.5428)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 960/4579]  eta: 0:21:18  Lr: 0.001875  Loss: 0.0625  Acc@1: 62.5000 (61.3163)  Acc@5: 93.7500 (90.5632)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 970/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.5647  Acc@1: 56.2500 (61.3157)  Acc@5: 93.7500 (90.5510)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 980/4579]  eta: 0:21:11  Lr: 0.001875  Loss: 0.0023  Acc@1: 62.5000 (61.3341)  Acc@5: 93.7500 (90.5772)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/4579]  eta: 0:21:07  Lr: 0.001875  Loss: 0.7093  Acc@1: 62.5000 (61.3143)  Acc@5: 93.7500 (90.5714)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1000/4579]  eta: 0:21:03  Lr: 0.001875  Loss: 0.4128  Acc@1: 62.5000 (61.2762)  Acc@5: 87.5000 (90.5657)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1010/4579]  eta: 0:21:00  Lr: 0.001875  Loss: -0.3554  Acc@1: 62.5000 (61.3316)  Acc@5: 93.7500 (90.5972)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1020/4579]  eta: 0:20:56  Lr: 0.001875  Loss: -0.0658  Acc@1: 62.5000 (61.3063)  Acc@5: 93.7500 (90.6219)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1030/4579]  eta: 0:20:53  Lr: 0.001875  Loss: -0.3680  Acc@1: 62.5000 (61.3785)  Acc@5: 93.7500 (90.6280)  time: 0.3590  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [1040/4579]  eta: 0:20:50  Lr: 0.001875  Loss: -0.1993  Acc@1: 68.7500 (61.4313)  Acc@5: 93.7500 (90.6280)  time: 0.3601  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [1050/4579]  eta: 0:20:46  Lr: 0.001875  Loss: 0.3441  Acc@1: 62.5000 (61.4355)  Acc@5: 93.7500 (90.6458)  time: 0.3545  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1060/4579]  eta: 0:20:43  Lr: 0.001875  Loss: -0.4068  Acc@1: 56.2500 (61.4456)  Acc@5: 93.7500 (90.6574)  time: 0.3592  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [1070/4579]  eta: 0:20:40  Lr: 0.001875  Loss: 0.1958  Acc@1: 56.2500 (61.4204)  Acc@5: 93.7500 (90.6513)  time: 0.3643  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [1080/4579]  eta: 0:20:36  Lr: 0.001875  Loss: 0.0299  Acc@1: 56.2500 (61.4073)  Acc@5: 93.7500 (90.6510)  time: 0.3609  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [1090/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.1458  Acc@1: 62.5000 (61.4058)  Acc@5: 93.7500 (90.6565)  time: 0.3558  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1100/4579]  eta: 0:20:29  Lr: 0.001875  Loss: -0.0033  Acc@1: 62.5000 (61.4782)  Acc@5: 87.5000 (90.6278)  time: 0.3551  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1110/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.5004  Acc@1: 68.7500 (61.5549)  Acc@5: 93.7500 (90.6728)  time: 0.3553  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1120/4579]  eta: 0:20:22  Lr: 0.001875  Loss: -0.3379  Acc@1: 62.5000 (61.5355)  Acc@5: 93.7500 (90.6668)  time: 0.3549  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1130/4579]  eta: 0:20:19  Lr: 0.001875  Loss: 0.2672  Acc@1: 62.5000 (61.4998)  Acc@5: 87.5000 (90.6333)  time: 0.3544  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1140/4579]  eta: 0:20:15  Lr: 0.001875  Loss: -0.2964  Acc@1: 62.5000 (61.4921)  Acc@5: 87.5000 (90.6496)  time: 0.3528  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1150/4579]  eta: 0:20:12  Lr: 0.001875  Loss: 0.0071  Acc@1: 62.5000 (61.5063)  Acc@5: 93.7500 (90.6440)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1160/4579]  eta: 0:20:08  Lr: 0.001875  Loss: 0.1695  Acc@1: 56.2500 (61.4933)  Acc@5: 93.7500 (90.6385)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1170/4579]  eta: 0:20:04  Lr: 0.001875  Loss: 0.1226  Acc@1: 56.2500 (61.4806)  Acc@5: 93.7500 (90.6650)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1180/4579]  eta: 0:20:01  Lr: 0.001875  Loss: 0.0974  Acc@1: 56.2500 (61.4627)  Acc@5: 93.7500 (90.6700)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1190/4579]  eta: 0:19:57  Lr: 0.001875  Loss: -0.1344  Acc@1: 62.5000 (61.5449)  Acc@5: 93.7500 (90.6853)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1200/4579]  eta: 0:19:53  Lr: 0.001875  Loss: 0.5961  Acc@1: 62.5000 (61.5164)  Acc@5: 87.5000 (90.6484)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1210/4579]  eta: 0:19:50  Lr: 0.001875  Loss: -0.2049  Acc@1: 62.5000 (61.4781)  Acc@5: 87.5000 (90.6740)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1220/4579]  eta: 0:19:46  Lr: 0.001875  Loss: 0.2901  Acc@1: 56.2500 (61.4353)  Acc@5: 93.7500 (90.7146)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1230/4579]  eta: 0:19:43  Lr: 0.001875  Loss: -0.6127  Acc@1: 56.2500 (61.4338)  Acc@5: 93.7500 (90.7189)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1240/4579]  eta: 0:19:39  Lr: 0.001875  Loss: -0.1263  Acc@1: 62.5000 (61.4625)  Acc@5: 93.7500 (90.7383)  time: 0.3576  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1250/4579]  eta: 0:19:36  Lr: 0.001875  Loss: -0.2792  Acc@1: 62.5000 (61.4558)  Acc@5: 93.7500 (90.7574)  time: 0.3578  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [1260/4579]  eta: 0:19:33  Lr: 0.001875  Loss: 0.4967  Acc@1: 62.5000 (61.4096)  Acc@5: 93.7500 (90.7316)  time: 0.3625  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1270/4579]  eta: 0:19:29  Lr: 0.001875  Loss: 0.2219  Acc@1: 62.5000 (61.4182)  Acc@5: 93.7500 (90.7307)  time: 0.3674  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1280/4579]  eta: 0:19:26  Lr: 0.001875  Loss: -0.2557  Acc@1: 62.5000 (61.3827)  Acc@5: 87.5000 (90.7299)  time: 0.3620  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [1290/4579]  eta: 0:19:22  Lr: 0.001875  Loss: -0.3430  Acc@1: 62.5000 (61.4398)  Acc@5: 87.5000 (90.7242)  time: 0.3566  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [1300/4579]  eta: 0:19:19  Lr: 0.001875  Loss: -0.5652  Acc@1: 68.7500 (61.4719)  Acc@5: 93.7500 (90.7571)  time: 0.3555  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1310/4579]  eta: 0:19:16  Lr: 0.001875  Loss: 0.0656  Acc@1: 68.7500 (61.4798)  Acc@5: 93.7500 (90.7656)  time: 0.3583  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1320/4579]  eta: 0:19:12  Lr: 0.001875  Loss: 0.1303  Acc@1: 68.7500 (61.5064)  Acc@5: 93.7500 (90.7646)  time: 0.3620  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1330/4579]  eta: 0:19:09  Lr: 0.001875  Loss: 0.1995  Acc@1: 62.5000 (61.4904)  Acc@5: 93.7500 (90.7729)  time: 0.3561  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1340/4579]  eta: 0:19:05  Lr: 0.001875  Loss: 0.3091  Acc@1: 62.5000 (61.5259)  Acc@5: 93.7500 (90.7858)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1350/4579]  eta: 0:19:02  Lr: 0.001875  Loss: 0.0389  Acc@1: 62.5000 (61.5146)  Acc@5: 93.7500 (90.8077)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1360/4579]  eta: 0:18:58  Lr: 0.001875  Loss: -0.5799  Acc@1: 56.2500 (61.5173)  Acc@5: 93.7500 (90.8156)  time: 0.3533  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1370/4579]  eta: 0:18:54  Lr: 0.001875  Loss: 0.1367  Acc@1: 62.5000 (61.5108)  Acc@5: 87.5000 (90.7960)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1380/4579]  eta: 0:18:51  Lr: 0.001875  Loss: 0.1276  Acc@1: 62.5000 (61.5179)  Acc@5: 87.5000 (90.8038)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1390/4579]  eta: 0:18:47  Lr: 0.001875  Loss: 0.2941  Acc@1: 62.5000 (61.5430)  Acc@5: 93.7500 (90.8294)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1400/4579]  eta: 0:18:43  Lr: 0.001875  Loss: -0.1534  Acc@1: 62.5000 (61.5364)  Acc@5: 93.7500 (90.8146)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1410/4579]  eta: 0:18:40  Lr: 0.001875  Loss: 0.5152  Acc@1: 56.2500 (61.5167)  Acc@5: 87.5000 (90.8044)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1420/4579]  eta: 0:18:36  Lr: 0.001875  Loss: 0.1101  Acc@1: 62.5000 (61.5192)  Acc@5: 93.7500 (90.8031)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1430/4579]  eta: 0:18:33  Lr: 0.001875  Loss: 0.2600  Acc@1: 62.5000 (61.5042)  Acc@5: 93.7500 (90.8063)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1440/4579]  eta: 0:18:29  Lr: 0.001875  Loss: 0.0223  Acc@1: 62.5000 (61.5241)  Acc@5: 87.5000 (90.7920)  time: 0.3563  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1450/4579]  eta: 0:18:26  Lr: 0.001875  Loss: -0.3223  Acc@1: 56.2500 (61.4835)  Acc@5: 87.5000 (90.7865)  time: 0.3561  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1460/4579]  eta: 0:18:22  Lr: 0.001875  Loss: -0.1544  Acc@1: 56.2500 (61.4861)  Acc@5: 93.7500 (90.7854)  time: 0.3578  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1470/4579]  eta: 0:18:19  Lr: 0.001875  Loss: 0.0543  Acc@1: 62.5000 (61.4760)  Acc@5: 93.7500 (90.7716)  time: 0.3612  data: 0.0032  max mem: 2500
Train: Epoch[2/5]  [1480/4579]  eta: 0:18:16  Lr: 0.001875  Loss: -0.3906  Acc@1: 56.2500 (61.4661)  Acc@5: 87.5000 (90.7411)  time: 0.3610  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [1490/4579]  eta: 0:18:12  Lr: 0.001875  Loss: -0.1881  Acc@1: 56.2500 (61.4814)  Acc@5: 93.7500 (90.7445)  time: 0.3580  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1500/4579]  eta: 0:18:09  Lr: 0.001875  Loss: -0.3335  Acc@1: 62.5000 (61.4965)  Acc@5: 87.5000 (90.7478)  time: 0.3551  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1510/4579]  eta: 0:18:05  Lr: 0.001875  Loss: -0.5336  Acc@1: 62.5000 (61.5156)  Acc@5: 87.5000 (90.7594)  time: 0.3556  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1520/4579]  eta: 0:18:02  Lr: 0.001875  Loss: 0.0225  Acc@1: 62.5000 (61.5138)  Acc@5: 87.5000 (90.7339)  time: 0.3557  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1530/4579]  eta: 0:17:58  Lr: 0.001875  Loss: -0.1850  Acc@1: 62.5000 (61.5202)  Acc@5: 87.5000 (90.7291)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1540/4579]  eta: 0:17:54  Lr: 0.001875  Loss: -0.3093  Acc@1: 62.5000 (61.5063)  Acc@5: 93.7500 (90.7487)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1550/4579]  eta: 0:17:51  Lr: 0.001875  Loss: -0.1851  Acc@1: 62.5000 (61.5530)  Acc@5: 93.7500 (90.7681)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1560/4579]  eta: 0:17:47  Lr: 0.001875  Loss: -0.1313  Acc@1: 62.5000 (61.5391)  Acc@5: 93.7500 (90.7711)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1570/4579]  eta: 0:17:43  Lr: 0.001875  Loss: -0.1979  Acc@1: 62.5000 (61.5253)  Acc@5: 87.5000 (90.7662)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1580/4579]  eta: 0:17:40  Lr: 0.001875  Loss: 0.3223  Acc@1: 56.2500 (61.5117)  Acc@5: 87.5000 (90.7812)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1590/4579]  eta: 0:17:36  Lr: 0.001875  Loss: -0.5038  Acc@1: 56.2500 (61.5218)  Acc@5: 93.7500 (90.7880)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1600/4579]  eta: 0:17:33  Lr: 0.001875  Loss: -0.5623  Acc@1: 62.5000 (61.5280)  Acc@5: 93.7500 (90.8065)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1610/4579]  eta: 0:17:29  Lr: 0.001875  Loss: -0.3918  Acc@1: 56.2500 (61.5146)  Acc@5: 93.7500 (90.8054)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1620/4579]  eta: 0:17:25  Lr: 0.001875  Loss: -0.0847  Acc@1: 56.2500 (61.5014)  Acc@5: 93.7500 (90.8120)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1630/4579]  eta: 0:17:22  Lr: 0.001875  Loss: -0.3491  Acc@1: 62.5000 (61.5075)  Acc@5: 93.7500 (90.8185)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1640/4579]  eta: 0:17:18  Lr: 0.001875  Loss: -0.0319  Acc@1: 62.5000 (61.5098)  Acc@5: 93.7500 (90.8402)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1650/4579]  eta: 0:17:15  Lr: 0.001875  Loss: -0.2931  Acc@1: 62.5000 (61.5120)  Acc@5: 93.7500 (90.8465)  time: 0.3533  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1660/4579]  eta: 0:17:11  Lr: 0.001875  Loss: 0.0281  Acc@1: 62.5000 (61.5443)  Acc@5: 93.7500 (90.8639)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1670/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.3301  Acc@1: 68.7500 (61.5836)  Acc@5: 93.7500 (90.8775)  time: 0.3533  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1680/4579]  eta: 0:17:04  Lr: 0.001875  Loss: 0.0061  Acc@1: 62.5000 (61.5556)  Acc@5: 93.7500 (90.8760)  time: 0.3559  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [1690/4579]  eta: 0:17:01  Lr: 0.001875  Loss: -0.5243  Acc@1: 56.2500 (61.5612)  Acc@5: 87.5000 (90.8560)  time: 0.3580  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [1700/4579]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5827  Acc@1: 62.5000 (61.5410)  Acc@5: 87.5000 (90.8473)  time: 0.3566  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1710/4579]  eta: 0:16:54  Lr: 0.001875  Loss: -0.1847  Acc@1: 56.2500 (61.5357)  Acc@5: 87.5000 (90.8533)  time: 0.3536  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1720/4579]  eta: 0:16:50  Lr: 0.001875  Loss: -0.1194  Acc@1: 56.2500 (61.5158)  Acc@5: 87.5000 (90.8483)  time: 0.3547  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [1730/4579]  eta: 0:16:47  Lr: 0.001875  Loss: -0.1115  Acc@1: 62.5000 (61.5324)  Acc@5: 87.5000 (90.8543)  time: 0.3559  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [1740/4579]  eta: 0:16:43  Lr: 0.001875  Loss: -0.7133  Acc@1: 62.5000 (61.5630)  Acc@5: 93.7500 (90.8601)  time: 0.3542  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [1750/4579]  eta: 0:16:39  Lr: 0.001875  Loss: -0.6409  Acc@1: 62.5000 (61.5898)  Acc@5: 87.5000 (90.8409)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1760/4579]  eta: 0:16:36  Lr: 0.001875  Loss: 0.0543  Acc@1: 62.5000 (61.6269)  Acc@5: 93.7500 (90.8468)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1770/4579]  eta: 0:16:32  Lr: 0.001875  Loss: 0.2701  Acc@1: 62.5000 (61.6107)  Acc@5: 93.7500 (90.8279)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1780/4579]  eta: 0:16:29  Lr: 0.001875  Loss: -0.6092  Acc@1: 62.5000 (61.6122)  Acc@5: 93.7500 (90.8303)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1790/4579]  eta: 0:16:25  Lr: 0.001875  Loss: -0.2310  Acc@1: 62.5000 (61.6311)  Acc@5: 93.7500 (90.8326)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1800/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.3250  Acc@1: 62.5000 (61.6047)  Acc@5: 93.7500 (90.8384)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1810/4579]  eta: 0:16:18  Lr: 0.001875  Loss: -0.1725  Acc@1: 56.2500 (61.5958)  Acc@5: 93.7500 (90.8096)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1820/4579]  eta: 0:16:14  Lr: 0.001875  Loss: -0.1275  Acc@1: 62.5000 (61.6385)  Acc@5: 93.7500 (90.8258)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1830/4579]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3002  Acc@1: 68.7500 (61.6364)  Acc@5: 93.7500 (90.8144)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1840/4579]  eta: 0:16:07  Lr: 0.001875  Loss: -0.1846  Acc@1: 62.5000 (61.6547)  Acc@5: 93.7500 (90.8338)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1850/4579]  eta: 0:16:03  Lr: 0.001875  Loss: 0.0584  Acc@1: 62.5000 (61.6322)  Acc@5: 93.7500 (90.8327)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1860/4579]  eta: 0:16:00  Lr: 0.001875  Loss: 0.1613  Acc@1: 56.2500 (61.6033)  Acc@5: 93.7500 (90.8383)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1870/4579]  eta: 0:15:56  Lr: 0.001875  Loss: -0.1639  Acc@1: 56.2500 (61.5947)  Acc@5: 87.5000 (90.8271)  time: 0.3524  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1880/4579]  eta: 0:15:53  Lr: 0.001875  Loss: -0.1376  Acc@1: 62.5000 (61.6361)  Acc@5: 87.5000 (90.8393)  time: 0.3533  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1890/4579]  eta: 0:15:49  Lr: 0.001875  Loss: -0.2725  Acc@1: 62.5000 (61.6308)  Acc@5: 93.7500 (90.8283)  time: 0.3542  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1900/4579]  eta: 0:15:46  Lr: 0.001875  Loss: 0.2954  Acc@1: 56.2500 (61.6320)  Acc@5: 93.7500 (90.8403)  time: 0.3577  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [1910/4579]  eta: 0:15:42  Lr: 0.001875  Loss: 0.0831  Acc@1: 62.5000 (61.6366)  Acc@5: 93.7500 (90.8359)  time: 0.3553  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1920/4579]  eta: 0:15:39  Lr: 0.001875  Loss: -0.1339  Acc@1: 62.5000 (61.6378)  Acc@5: 87.5000 (90.8414)  time: 0.3531  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1930/4579]  eta: 0:15:35  Lr: 0.001875  Loss: -0.4903  Acc@1: 56.2500 (61.6164)  Acc@5: 87.5000 (90.8370)  time: 0.3548  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1940/4579]  eta: 0:15:32  Lr: 0.001875  Loss: 0.1045  Acc@1: 56.2500 (61.6048)  Acc@5: 87.5000 (90.8230)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1950/4579]  eta: 0:15:28  Lr: 0.001875  Loss: -0.7381  Acc@1: 56.2500 (61.6158)  Acc@5: 93.7500 (90.8380)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1960/4579]  eta: 0:15:25  Lr: 0.001875  Loss: -0.3978  Acc@1: 62.5000 (61.6235)  Acc@5: 93.7500 (90.8465)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1970/4579]  eta: 0:15:21  Lr: 0.001875  Loss: 0.0690  Acc@1: 62.5000 (61.6216)  Acc@5: 93.7500 (90.8422)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1980/4579]  eta: 0:15:17  Lr: 0.001875  Loss: 0.0349  Acc@1: 62.5000 (61.6166)  Acc@5: 87.5000 (90.8253)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1990/4579]  eta: 0:15:14  Lr: 0.001875  Loss: -0.3180  Acc@1: 62.5000 (61.6556)  Acc@5: 93.7500 (90.8338)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2000/4579]  eta: 0:15:10  Lr: 0.001875  Loss: -0.2715  Acc@1: 62.5000 (61.6535)  Acc@5: 87.5000 (90.8202)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2010/4579]  eta: 0:15:07  Lr: 0.001875  Loss: -0.0802  Acc@1: 62.5000 (61.6453)  Acc@5: 87.5000 (90.8255)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2020/4579]  eta: 0:15:03  Lr: 0.001875  Loss: -0.2490  Acc@1: 62.5000 (61.6712)  Acc@5: 93.7500 (90.8337)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2030/4579]  eta: 0:14:59  Lr: 0.001875  Loss: 0.6226  Acc@1: 62.5000 (61.6414)  Acc@5: 87.5000 (90.8235)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2040/4579]  eta: 0:14:56  Lr: 0.001875  Loss: -0.0322  Acc@1: 56.2500 (61.6150)  Acc@5: 87.5000 (90.8164)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2050/4579]  eta: 0:14:52  Lr: 0.001875  Loss: -0.5561  Acc@1: 56.2500 (61.5919)  Acc@5: 87.5000 (90.8063)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2060/4579]  eta: 0:14:49  Lr: 0.001875  Loss: 0.2723  Acc@1: 56.2500 (61.5842)  Acc@5: 87.5000 (90.8024)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2070/4579]  eta: 0:14:45  Lr: 0.001875  Loss: -0.3925  Acc@1: 56.2500 (61.5796)  Acc@5: 87.5000 (90.7955)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2080/4579]  eta: 0:14:42  Lr: 0.001875  Loss: 0.0736  Acc@1: 62.5000 (61.5900)  Acc@5: 93.7500 (90.8037)  time: 0.3559  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2090/4579]  eta: 0:14:38  Lr: 0.001875  Loss: -0.4315  Acc@1: 68.7500 (61.6212)  Acc@5: 93.7500 (90.8058)  time: 0.3592  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2100/4579]  eta: 0:14:35  Lr: 0.001875  Loss: -0.6105  Acc@1: 68.7500 (61.6284)  Acc@5: 87.5000 (90.8020)  time: 0.3603  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2110/4579]  eta: 0:14:31  Lr: 0.001875  Loss: -0.5700  Acc@1: 68.7500 (61.6621)  Acc@5: 93.7500 (90.8189)  time: 0.3581  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2120/4579]  eta: 0:14:28  Lr: 0.001875  Loss: -0.6441  Acc@1: 68.7500 (61.6955)  Acc@5: 93.7500 (90.8445)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2130/4579]  eta: 0:14:24  Lr: 0.001875  Loss: 0.3870  Acc@1: 62.5000 (61.6788)  Acc@5: 93.7500 (90.8435)  time: 0.3540  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [2140/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.0732  Acc@1: 56.2500 (61.6593)  Acc@5: 87.5000 (90.8366)  time: 0.3571  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [2150/4579]  eta: 0:14:17  Lr: 0.001875  Loss: -0.7448  Acc@1: 56.2500 (61.6283)  Acc@5: 87.5000 (90.8328)  time: 0.3531  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2160/4579]  eta: 0:14:14  Lr: 0.001875  Loss: 0.1176  Acc@1: 56.2500 (61.6410)  Acc@5: 93.7500 (90.8318)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2170/4579]  eta: 0:14:10  Lr: 0.001875  Loss: 0.2959  Acc@1: 56.2500 (61.6076)  Acc@5: 87.5000 (90.8251)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2180/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.3787  Acc@1: 50.0000 (61.5744)  Acc@5: 87.5000 (90.8213)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2190/4579]  eta: 0:14:03  Lr: 0.001875  Loss: -0.2003  Acc@1: 62.5000 (61.5900)  Acc@5: 93.7500 (90.8318)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2200/4579]  eta: 0:13:59  Lr: 0.001875  Loss: -0.2374  Acc@1: 62.5000 (61.6282)  Acc@5: 93.7500 (90.8252)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2210/4579]  eta: 0:13:56  Lr: 0.001875  Loss: -0.1920  Acc@1: 68.7500 (61.6520)  Acc@5: 93.7500 (90.8215)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2220/4579]  eta: 0:13:52  Lr: 0.001875  Loss: 0.2290  Acc@1: 62.5000 (61.6333)  Acc@5: 87.5000 (90.8009)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2230/4579]  eta: 0:13:49  Lr: 0.001875  Loss: -0.4072  Acc@1: 62.5000 (61.6372)  Acc@5: 87.5000 (90.8001)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2240/4579]  eta: 0:13:45  Lr: 0.001875  Loss: 0.3330  Acc@1: 62.5000 (61.6159)  Acc@5: 87.5000 (90.7965)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2250/4579]  eta: 0:13:42  Lr: 0.001875  Loss: -0.4557  Acc@1: 56.2500 (61.5865)  Acc@5: 87.5000 (90.7847)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2260/4579]  eta: 0:13:38  Lr: 0.001875  Loss: -0.1988  Acc@1: 62.5000 (61.5906)  Acc@5: 87.5000 (90.7784)  time: 0.3558  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2270/4579]  eta: 0:13:35  Lr: 0.001875  Loss: -0.4316  Acc@1: 62.5000 (61.5780)  Acc@5: 87.5000 (90.7777)  time: 0.3567  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [2280/4579]  eta: 0:13:31  Lr: 0.001875  Loss: -0.4165  Acc@1: 56.2500 (61.5684)  Acc@5: 93.7500 (90.7771)  time: 0.3552  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2290/4579]  eta: 0:13:28  Lr: 0.001875  Loss: -0.4609  Acc@1: 62.5000 (61.5779)  Acc@5: 93.7500 (90.7873)  time: 0.3592  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [2300/4579]  eta: 0:13:24  Lr: 0.001875  Loss: -0.7281  Acc@1: 62.5000 (61.5901)  Acc@5: 93.7500 (90.7812)  time: 0.3631  data: 0.0040  max mem: 2500
Train: Epoch[2/5]  [2310/4579]  eta: 0:13:21  Lr: 0.001875  Loss: -0.5121  Acc@1: 62.5000 (61.6075)  Acc@5: 93.7500 (90.7859)  time: 0.3603  data: 0.0039  max mem: 2500
Train: Epoch[2/5]  [2320/4579]  eta: 0:13:17  Lr: 0.001875  Loss: -0.1692  Acc@1: 62.5000 (61.6221)  Acc@5: 93.7500 (90.7906)  time: 0.3557  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [2330/4579]  eta: 0:13:14  Lr: 0.001875  Loss: -0.2488  Acc@1: 62.5000 (61.6179)  Acc@5: 93.7500 (90.7819)  time: 0.3595  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2340/4579]  eta: 0:13:10  Lr: 0.001875  Loss: 0.5595  Acc@1: 62.5000 (61.6270)  Acc@5: 93.7500 (90.7812)  time: 0.3595  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2350/4579]  eta: 0:13:07  Lr: 0.001875  Loss: -0.2858  Acc@1: 56.2500 (61.6254)  Acc@5: 93.7500 (90.7858)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2360/4579]  eta: 0:13:03  Lr: 0.001875  Loss: -0.7704  Acc@1: 62.5000 (61.6344)  Acc@5: 93.7500 (90.8090)  time: 0.3501  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2370/4579]  eta: 0:13:00  Lr: 0.001875  Loss: 0.2463  Acc@1: 62.5000 (61.6565)  Acc@5: 93.7500 (90.8187)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2380/4579]  eta: 0:12:56  Lr: 0.001875  Loss: -0.2723  Acc@1: 62.5000 (61.6521)  Acc@5: 93.7500 (90.8153)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2390/4579]  eta: 0:12:52  Lr: 0.001875  Loss: -0.4633  Acc@1: 62.5000 (61.6452)  Acc@5: 87.5000 (90.8041)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2400/4579]  eta: 0:12:49  Lr: 0.001875  Loss: -0.2005  Acc@1: 62.5000 (61.6670)  Acc@5: 87.5000 (90.8059)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2410/4579]  eta: 0:12:45  Lr: 0.001875  Loss: 0.0441  Acc@1: 62.5000 (61.6497)  Acc@5: 93.7500 (90.8129)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2420/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.4613  Acc@1: 62.5000 (61.6662)  Acc@5: 93.7500 (90.8277)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2430/4579]  eta: 0:12:38  Lr: 0.001875  Loss: -0.3978  Acc@1: 62.5000 (61.6747)  Acc@5: 93.7500 (90.8242)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2440/4579]  eta: 0:12:35  Lr: 0.001875  Loss: 0.3368  Acc@1: 62.5000 (61.6730)  Acc@5: 87.5000 (90.8183)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2450/4579]  eta: 0:12:31  Lr: 0.001875  Loss: 0.1903  Acc@1: 62.5000 (61.6942)  Acc@5: 87.5000 (90.8048)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2460/4579]  eta: 0:12:28  Lr: 0.001875  Loss: -0.7096  Acc@1: 62.5000 (61.7178)  Acc@5: 93.7500 (90.8218)  time: 0.3543  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2470/4579]  eta: 0:12:24  Lr: 0.001875  Loss: 0.0035  Acc@1: 62.5000 (61.7286)  Acc@5: 93.7500 (90.8185)  time: 0.3557  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2480/4579]  eta: 0:12:21  Lr: 0.001875  Loss: 0.0027  Acc@1: 62.5000 (61.7241)  Acc@5: 87.5000 (90.8228)  time: 0.3575  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2490/4579]  eta: 0:12:17  Lr: 0.001875  Loss: -0.3120  Acc@1: 62.5000 (61.7423)  Acc@5: 93.7500 (90.8245)  time: 0.3582  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [2500/4579]  eta: 0:12:14  Lr: 0.001875  Loss: -0.1884  Acc@1: 68.7500 (61.7678)  Acc@5: 93.7500 (90.8337)  time: 0.3558  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2510/4579]  eta: 0:12:10  Lr: 0.001875  Loss: 0.1508  Acc@1: 62.5000 (61.7583)  Acc@5: 93.7500 (90.8378)  time: 0.3572  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2520/4579]  eta: 0:12:07  Lr: 0.001875  Loss: 0.0588  Acc@1: 62.5000 (61.7562)  Acc@5: 93.7500 (90.8394)  time: 0.3582  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2530/4579]  eta: 0:12:03  Lr: 0.001875  Loss: -0.2869  Acc@1: 62.5000 (61.7444)  Acc@5: 87.5000 (90.8386)  time: 0.3538  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2540/4579]  eta: 0:11:59  Lr: 0.001875  Loss: -0.1709  Acc@1: 62.5000 (61.7547)  Acc@5: 87.5000 (90.8328)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2550/4579]  eta: 0:11:56  Lr: 0.001875  Loss: 0.7589  Acc@1: 62.5000 (61.7478)  Acc@5: 87.5000 (90.8271)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2560/4579]  eta: 0:11:52  Lr: 0.001875  Loss: -0.1418  Acc@1: 56.2500 (61.7215)  Acc@5: 93.7500 (90.8337)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2570/4579]  eta: 0:11:49  Lr: 0.001875  Loss: -0.0113  Acc@1: 56.2500 (61.7124)  Acc@5: 93.7500 (90.8426)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2580/4579]  eta: 0:11:45  Lr: 0.001875  Loss: 0.0381  Acc@1: 62.5000 (61.7154)  Acc@5: 93.7500 (90.8587)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2590/4579]  eta: 0:11:42  Lr: 0.001875  Loss: -0.1093  Acc@1: 68.7500 (61.7377)  Acc@5: 93.7500 (90.8698)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2600/4579]  eta: 0:11:38  Lr: 0.001875  Loss: -0.2022  Acc@1: 68.7500 (61.7407)  Acc@5: 93.7500 (90.8689)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2610/4579]  eta: 0:11:35  Lr: 0.001875  Loss: -0.0804  Acc@1: 68.7500 (61.7508)  Acc@5: 93.7500 (90.8680)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2620/4579]  eta: 0:11:31  Lr: 0.001875  Loss: 0.0992  Acc@1: 68.7500 (61.7655)  Acc@5: 93.7500 (90.8837)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2630/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 0.1273  Acc@1: 56.2500 (61.7446)  Acc@5: 93.7500 (90.8899)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2640/4579]  eta: 0:11:24  Lr: 0.001875  Loss: -0.3225  Acc@1: 56.2500 (61.7522)  Acc@5: 93.7500 (90.8936)  time: 0.3550  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [2650/4579]  eta: 0:11:20  Lr: 0.001875  Loss: -0.6369  Acc@1: 62.5000 (61.7597)  Acc@5: 93.7500 (90.9020)  time: 0.3561  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [2660/4579]  eta: 0:11:17  Lr: 0.001875  Loss: 0.0723  Acc@1: 62.5000 (61.7461)  Acc@5: 93.7500 (90.9127)  time: 0.3586  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2670/4579]  eta: 0:11:13  Lr: 0.001875  Loss: 0.0180  Acc@1: 56.2500 (61.7395)  Acc@5: 93.7500 (90.9046)  time: 0.3612  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2680/4579]  eta: 0:11:10  Lr: 0.001875  Loss: 0.0543  Acc@1: 56.2500 (61.7424)  Acc@5: 87.5000 (90.9036)  time: 0.3577  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2690/4579]  eta: 0:11:07  Lr: 0.001875  Loss: 0.0892  Acc@1: 56.2500 (61.7173)  Acc@5: 87.5000 (90.8933)  time: 0.3577  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [2700/4579]  eta: 0:11:03  Lr: 0.001875  Loss: -0.4032  Acc@1: 62.5000 (61.7387)  Acc@5: 87.5000 (90.8853)  time: 0.3593  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2710/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.1296  Acc@1: 68.7500 (61.7438)  Acc@5: 87.5000 (90.8844)  time: 0.3606  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [2720/4579]  eta: 0:10:56  Lr: 0.001875  Loss: -0.2350  Acc@1: 62.5000 (61.7650)  Acc@5: 87.5000 (90.8811)  time: 0.3563  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2730/4579]  eta: 0:10:52  Lr: 0.001875  Loss: 0.0832  Acc@1: 62.5000 (61.7700)  Acc@5: 93.7500 (90.8916)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2740/4579]  eta: 0:10:49  Lr: 0.001875  Loss: 0.0431  Acc@1: 62.5000 (61.7544)  Acc@5: 93.7500 (90.8747)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2750/4579]  eta: 0:10:45  Lr: 0.001875  Loss: 0.7498  Acc@1: 56.2500 (61.7321)  Acc@5: 87.5000 (90.8670)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2760/4579]  eta: 0:10:42  Lr: 0.001875  Loss: -1.0183  Acc@1: 62.5000 (61.7598)  Acc@5: 93.7500 (90.8819)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2770/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 0.1332  Acc@1: 62.5000 (61.7444)  Acc@5: 87.5000 (90.8652)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2780/4579]  eta: 0:10:35  Lr: 0.001875  Loss: 0.1943  Acc@1: 62.5000 (61.7584)  Acc@5: 87.5000 (90.8643)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2790/4579]  eta: 0:10:31  Lr: 0.001875  Loss: -0.0552  Acc@1: 62.5000 (61.7543)  Acc@5: 87.5000 (90.8613)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2800/4579]  eta: 0:10:28  Lr: 0.001875  Loss: -0.1667  Acc@1: 56.2500 (61.7614)  Acc@5: 87.5000 (90.8649)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2810/4579]  eta: 0:10:24  Lr: 0.001875  Loss: -0.6580  Acc@1: 62.5000 (61.7863)  Acc@5: 93.7500 (90.8796)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2820/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.4806  Acc@1: 68.7500 (61.8021)  Acc@5: 93.7500 (90.8765)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2830/4579]  eta: 0:10:17  Lr: 0.001875  Loss: -0.2577  Acc@1: 62.5000 (61.8090)  Acc@5: 93.7500 (90.8800)  time: 0.3556  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2840/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.3584  Acc@1: 62.5000 (61.7960)  Acc@5: 93.7500 (90.8725)  time: 0.3561  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2850/4579]  eta: 0:10:10  Lr: 0.001875  Loss: -0.4982  Acc@1: 62.5000 (61.8116)  Acc@5: 93.7500 (90.8782)  time: 0.3578  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2860/4579]  eta: 0:10:06  Lr: 0.001875  Loss: 0.3144  Acc@1: 68.7500 (61.8250)  Acc@5: 93.7500 (90.8729)  time: 0.3605  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2870/4579]  eta: 0:10:03  Lr: 0.001875  Loss: 0.4777  Acc@1: 62.5000 (61.8404)  Acc@5: 93.7500 (90.8851)  time: 0.3584  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2880/4579]  eta: 0:09:59  Lr: 0.001875  Loss: 0.0349  Acc@1: 62.5000 (61.8448)  Acc@5: 93.7500 (90.8864)  time: 0.3573  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2890/4579]  eta: 0:09:56  Lr: 0.001875  Loss: -0.4310  Acc@1: 62.5000 (61.8385)  Acc@5: 93.7500 (90.8963)  time: 0.3570  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2900/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.1231  Acc@1: 62.5000 (61.8364)  Acc@5: 93.7500 (90.8975)  time: 0.3560  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2910/4579]  eta: 0:09:49  Lr: 0.001875  Loss: -0.4050  Acc@1: 62.5000 (61.8258)  Acc@5: 93.7500 (90.9009)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2920/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.1643  Acc@1: 62.5000 (61.8346)  Acc@5: 87.5000 (90.8999)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2930/4579]  eta: 0:09:42  Lr: 0.001875  Loss: -0.1519  Acc@1: 62.5000 (61.8347)  Acc@5: 87.5000 (90.8883)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2940/4579]  eta: 0:09:38  Lr: 0.001875  Loss: 0.0758  Acc@1: 62.5000 (61.8327)  Acc@5: 93.7500 (90.8917)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2950/4579]  eta: 0:09:35  Lr: 0.001875  Loss: 0.1924  Acc@1: 62.5000 (61.8329)  Acc@5: 93.7500 (90.8887)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2960/4579]  eta: 0:09:31  Lr: 0.001875  Loss: -0.6304  Acc@1: 62.5000 (61.8478)  Acc@5: 87.5000 (90.8857)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2970/4579]  eta: 0:09:28  Lr: 0.001875  Loss: -0.9332  Acc@1: 68.7500 (61.8689)  Acc@5: 87.5000 (90.8848)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2980/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.1969  Acc@1: 62.5000 (61.8668)  Acc@5: 93.7500 (90.8965)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2990/4579]  eta: 0:09:20  Lr: 0.001875  Loss: -0.3359  Acc@1: 62.5000 (61.8669)  Acc@5: 93.7500 (90.8977)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3000/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.5076  Acc@1: 62.5000 (61.8773)  Acc@5: 87.5000 (90.9009)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3010/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.2667  Acc@1: 62.5000 (61.8794)  Acc@5: 93.7500 (90.8980)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3020/4579]  eta: 0:09:10  Lr: 0.001875  Loss: -0.5387  Acc@1: 62.5000 (61.8731)  Acc@5: 93.7500 (90.9012)  time: 0.3556  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3030/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.0595  Acc@1: 62.5000 (61.8979)  Acc@5: 93.7500 (90.8982)  time: 0.3584  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [3040/4579]  eta: 0:09:03  Lr: 0.001875  Loss: -0.5039  Acc@1: 68.7500 (61.9122)  Acc@5: 93.7500 (90.8973)  time: 0.3579  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [3050/4579]  eta: 0:08:59  Lr: 0.001875  Loss: 0.0022  Acc@1: 62.5000 (61.9080)  Acc@5: 93.7500 (90.8964)  time: 0.3604  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [3060/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.3769  Acc@1: 62.5000 (61.9262)  Acc@5: 93.7500 (90.9098)  time: 0.3590  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [3070/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.9956  Acc@1: 62.5000 (61.9383)  Acc@5: 93.7500 (90.9089)  time: 0.3560  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3080/4579]  eta: 0:08:49  Lr: 0.001875  Loss: -0.2160  Acc@1: 68.7500 (61.9421)  Acc@5: 93.7500 (90.9060)  time: 0.3554  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3090/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.3239  Acc@1: 68.7500 (61.9480)  Acc@5: 87.5000 (90.9071)  time: 0.3548  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3100/4579]  eta: 0:08:42  Lr: 0.001875  Loss: -0.4515  Acc@1: 62.5000 (61.9478)  Acc@5: 93.7500 (90.9082)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3110/4579]  eta: 0:08:38  Lr: 0.001875  Loss: 0.0607  Acc@1: 56.2500 (61.9355)  Acc@5: 87.5000 (90.8972)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3120/4579]  eta: 0:08:35  Lr: 0.001875  Loss: -0.2053  Acc@1: 56.2500 (61.9333)  Acc@5: 93.7500 (90.9004)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3130/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.4680  Acc@1: 62.5000 (61.9371)  Acc@5: 93.7500 (90.8955)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3140/4579]  eta: 0:08:28  Lr: 0.001875  Loss: -0.3636  Acc@1: 68.7500 (61.9528)  Acc@5: 93.7500 (90.8986)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3150/4579]  eta: 0:08:24  Lr: 0.001875  Loss: 0.3207  Acc@1: 62.5000 (61.9466)  Acc@5: 93.7500 (90.8977)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3160/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.7899  Acc@1: 62.5000 (61.9622)  Acc@5: 93.7500 (90.9087)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3170/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.3108  Acc@1: 62.5000 (61.9659)  Acc@5: 93.7500 (90.9000)  time: 0.3503  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3180/4579]  eta: 0:08:13  Lr: 0.001875  Loss: 0.2760  Acc@1: 62.5000 (61.9695)  Acc@5: 93.7500 (90.9109)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3190/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.4542  Acc@1: 62.5000 (61.9751)  Acc@5: 93.7500 (90.9159)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3200/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.2877  Acc@1: 62.5000 (61.9943)  Acc@5: 93.7500 (90.9228)  time: 0.3536  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3210/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6353  Acc@1: 62.5000 (61.9998)  Acc@5: 93.7500 (90.9316)  time: 0.3589  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [3220/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.3192  Acc@1: 68.7500 (62.0091)  Acc@5: 93.7500 (90.9403)  time: 0.3571  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [3230/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.0131  Acc@1: 62.5000 (61.9971)  Acc@5: 93.7500 (90.9451)  time: 0.3571  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3240/4579]  eta: 0:07:52  Lr: 0.001875  Loss: 0.3307  Acc@1: 56.2500 (62.0025)  Acc@5: 93.7500 (90.9384)  time: 0.3614  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [3250/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.1392  Acc@1: 68.7500 (62.0040)  Acc@5: 87.5000 (90.9316)  time: 0.3603  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [3260/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.4406  Acc@1: 62.5000 (62.0036)  Acc@5: 93.7500 (90.9269)  time: 0.3566  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3270/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.0983  Acc@1: 62.5000 (61.9917)  Acc@5: 93.7500 (90.9240)  time: 0.3571  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3280/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.1632  Acc@1: 62.5000 (61.9914)  Acc@5: 87.5000 (90.9098)  time: 0.3621  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3290/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.1069  Acc@1: 62.5000 (61.9948)  Acc@5: 87.5000 (90.9127)  time: 0.3596  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3300/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.3280  Acc@1: 62.5000 (61.9964)  Acc@5: 93.7500 (90.9194)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3310/4579]  eta: 0:07:28  Lr: 0.001875  Loss: 0.5153  Acc@1: 62.5000 (62.0054)  Acc@5: 93.7500 (90.9166)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3320/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.7341  Acc@1: 68.7500 (62.0295)  Acc@5: 93.7500 (90.9195)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3330/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.3567  Acc@1: 68.7500 (62.0347)  Acc@5: 93.7500 (90.9149)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3340/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.3932  Acc@1: 68.7500 (62.0454)  Acc@5: 93.7500 (90.9178)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3350/4579]  eta: 0:07:13  Lr: 0.001875  Loss: 0.1264  Acc@1: 62.5000 (62.0524)  Acc@5: 93.7500 (90.9244)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:10  Lr: 0.001875  Loss: 0.2118  Acc@1: 62.5000 (62.0463)  Acc@5: 93.7500 (90.9123)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3370/4579]  eta: 0:07:06  Lr: 0.001875  Loss: 0.1662  Acc@1: 62.5000 (62.0643)  Acc@5: 87.5000 (90.9115)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3380/4579]  eta: 0:07:03  Lr: 0.001875  Loss: -0.5585  Acc@1: 62.5000 (62.0545)  Acc@5: 87.5000 (90.8884)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3390/4579]  eta: 0:06:59  Lr: 0.001875  Loss: 0.2044  Acc@1: 56.2500 (62.0448)  Acc@5: 87.5000 (90.8803)  time: 0.3533  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [3400/4579]  eta: 0:06:56  Lr: 0.001875  Loss: 0.2638  Acc@1: 62.5000 (62.0498)  Acc@5: 87.5000 (90.8814)  time: 0.3571  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [3410/4579]  eta: 0:06:52  Lr: 0.001875  Loss: -0.4075  Acc@1: 62.5000 (62.0419)  Acc@5: 87.5000 (90.8751)  time: 0.3573  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [3420/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.2265  Acc@1: 62.5000 (62.0360)  Acc@5: 93.7500 (90.8799)  time: 0.3607  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [3430/4579]  eta: 0:06:45  Lr: 0.001875  Loss: -0.1217  Acc@1: 56.2500 (62.0318)  Acc@5: 93.7500 (90.8809)  time: 0.3619  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3440/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.2537  Acc@1: 56.2500 (62.0314)  Acc@5: 93.7500 (90.8711)  time: 0.3579  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3450/4579]  eta: 0:06:38  Lr: 0.001875  Loss: -0.2849  Acc@1: 56.2500 (62.0382)  Acc@5: 87.5000 (90.8704)  time: 0.3575  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3460/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.2143  Acc@1: 56.2500 (62.0269)  Acc@5: 93.7500 (90.8733)  time: 0.3567  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [3470/4579]  eta: 0:06:31  Lr: 0.001875  Loss: 0.3643  Acc@1: 56.2500 (62.0030)  Acc@5: 87.5000 (90.8582)  time: 0.3592  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3480/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.0131  Acc@1: 50.0000 (61.9775)  Acc@5: 87.5000 (90.8485)  time: 0.3565  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3490/4579]  eta: 0:06:24  Lr: 0.001875  Loss: -0.4450  Acc@1: 62.5000 (61.9898)  Acc@5: 93.7500 (90.8551)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3500/4579]  eta: 0:06:21  Lr: 0.001875  Loss: 0.1843  Acc@1: 62.5000 (61.9627)  Acc@5: 93.7500 (90.8455)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3510/4579]  eta: 0:06:17  Lr: 0.001875  Loss: 0.3533  Acc@1: 56.2500 (61.9588)  Acc@5: 93.7500 (90.8466)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:13  Lr: 0.001875  Loss: 0.2088  Acc@1: 56.2500 (61.9604)  Acc@5: 93.7500 (90.8460)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:10  Lr: 0.001875  Loss: -0.4679  Acc@1: 62.5000 (61.9619)  Acc@5: 93.7500 (90.8471)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3540/4579]  eta: 0:06:06  Lr: 0.001875  Loss: -0.0534  Acc@1: 62.5000 (61.9793)  Acc@5: 93.7500 (90.8571)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3550/4579]  eta: 0:06:03  Lr: 0.001875  Loss: -0.3480  Acc@1: 62.5000 (61.9755)  Acc@5: 93.7500 (90.8582)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3560/4579]  eta: 0:05:59  Lr: 0.001875  Loss: 0.0486  Acc@1: 62.5000 (61.9910)  Acc@5: 93.7500 (90.8558)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3570/4579]  eta: 0:05:56  Lr: 0.001875  Loss: -0.2937  Acc@1: 68.7500 (62.0047)  Acc@5: 87.5000 (90.8534)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3580/4579]  eta: 0:05:52  Lr: 0.001875  Loss: -0.0807  Acc@1: 62.5000 (62.0131)  Acc@5: 87.5000 (90.8493)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3590/4579]  eta: 0:05:49  Lr: 0.001875  Loss: -0.0689  Acc@1: 62.5000 (62.0127)  Acc@5: 87.5000 (90.8452)  time: 0.3528  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3600/4579]  eta: 0:05:45  Lr: 0.001875  Loss: 0.2159  Acc@1: 56.2500 (61.9967)  Acc@5: 87.5000 (90.8446)  time: 0.3548  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3610/4579]  eta: 0:05:42  Lr: 0.001875  Loss: -0.3183  Acc@1: 62.5000 (62.0084)  Acc@5: 93.7500 (90.8388)  time: 0.3572  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3620/4579]  eta: 0:05:38  Lr: 0.001875  Loss: 0.0488  Acc@1: 62.5000 (61.9977)  Acc@5: 93.7500 (90.8433)  time: 0.3600  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3630/4579]  eta: 0:05:35  Lr: 0.001875  Loss: -0.1725  Acc@1: 56.2500 (61.9905)  Acc@5: 93.7500 (90.8427)  time: 0.3580  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3640/4579]  eta: 0:05:31  Lr: 0.001875  Loss: -0.5025  Acc@1: 62.5000 (62.0056)  Acc@5: 93.7500 (90.8439)  time: 0.3562  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [3650/4579]  eta: 0:05:28  Lr: 0.001875  Loss: -0.3160  Acc@1: 68.7500 (62.0190)  Acc@5: 93.7500 (90.8535)  time: 0.3558  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3660/4579]  eta: 0:05:24  Lr: 0.001875  Loss: 0.6598  Acc@1: 62.5000 (62.0066)  Acc@5: 93.7500 (90.8410)  time: 0.3581  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:21  Lr: 0.001875  Loss: -0.3418  Acc@1: 56.2500 (62.0131)  Acc@5: 87.5000 (90.8353)  time: 0.3549  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:17  Lr: 0.001875  Loss: -0.0998  Acc@1: 62.5000 (62.0127)  Acc@5: 87.5000 (90.8347)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:13  Lr: 0.001875  Loss: -0.2123  Acc@1: 68.7500 (62.0157)  Acc@5: 93.7500 (90.8443)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:10  Lr: 0.001875  Loss: -0.5176  Acc@1: 62.5000 (62.0187)  Acc@5: 93.7500 (90.8403)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3710/4579]  eta: 0:05:06  Lr: 0.001875  Loss: -0.1900  Acc@1: 62.5000 (62.0301)  Acc@5: 93.7500 (90.8431)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3720/4579]  eta: 0:05:03  Lr: 0.001875  Loss: -0.0202  Acc@1: 68.7500 (62.0314)  Acc@5: 93.7500 (90.8375)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3730/4579]  eta: 0:04:59  Lr: 0.001875  Loss: -0.1101  Acc@1: 68.7500 (62.0360)  Acc@5: 93.7500 (90.8403)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3740/4579]  eta: 0:04:56  Lr: 0.001875  Loss: -0.4140  Acc@1: 62.5000 (62.0322)  Acc@5: 93.7500 (90.8363)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3750/4579]  eta: 0:04:52  Lr: 0.001875  Loss: -0.2259  Acc@1: 68.7500 (62.0501)  Acc@5: 93.7500 (90.8458)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3760/4579]  eta: 0:04:49  Lr: 0.001875  Loss: 0.1810  Acc@1: 68.7500 (62.0679)  Acc@5: 93.7500 (90.8452)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3770/4579]  eta: 0:04:45  Lr: 0.001875  Loss: -0.3637  Acc@1: 62.5000 (62.0707)  Acc@5: 93.7500 (90.8479)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3780/4579]  eta: 0:04:42  Lr: 0.001875  Loss: -0.4532  Acc@1: 62.5000 (62.0636)  Acc@5: 93.7500 (90.8556)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3790/4579]  eta: 0:04:38  Lr: 0.001875  Loss: -0.1452  Acc@1: 62.5000 (62.0631)  Acc@5: 93.7500 (90.8599)  time: 0.3538  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3800/4579]  eta: 0:04:35  Lr: 0.001875  Loss: -0.0452  Acc@1: 62.5000 (62.0544)  Acc@5: 93.7500 (90.8692)  time: 0.3538  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3810/4579]  eta: 0:04:31  Lr: 0.001875  Loss: -0.6176  Acc@1: 62.5000 (62.0457)  Acc@5: 93.7500 (90.8521)  time: 0.3592  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:27  Lr: 0.001875  Loss: -0.0991  Acc@1: 62.5000 (62.0584)  Acc@5: 93.7500 (90.8597)  time: 0.3638  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:24  Lr: 0.001875  Loss: 0.0585  Acc@1: 68.7500 (62.0611)  Acc@5: 87.5000 (90.8510)  time: 0.3580  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:20  Lr: 0.001875  Loss: -0.1299  Acc@1: 62.5000 (62.0525)  Acc@5: 87.5000 (90.8487)  time: 0.3540  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:17  Lr: 0.001875  Loss: 0.1515  Acc@1: 62.5000 (62.0699)  Acc@5: 87.5000 (90.8482)  time: 0.3557  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:13  Lr: 0.001875  Loss: 0.2880  Acc@1: 68.7500 (62.0840)  Acc@5: 87.5000 (90.8460)  time: 0.3589  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:10  Lr: 0.001875  Loss: -0.0937  Acc@1: 68.7500 (62.1044)  Acc@5: 93.7500 (90.8535)  time: 0.3548  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:06  Lr: 0.001875  Loss: -0.0160  Acc@1: 68.7500 (62.1248)  Acc@5: 93.7500 (90.8658)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3890/4579]  eta: 0:04:03  Lr: 0.001875  Loss: -0.2737  Acc@1: 68.7500 (62.1273)  Acc@5: 93.7500 (90.8603)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3900/4579]  eta: 0:03:59  Lr: 0.001875  Loss: -0.1912  Acc@1: 62.5000 (62.1123)  Acc@5: 87.5000 (90.8645)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3910/4579]  eta: 0:03:56  Lr: 0.001875  Loss: -0.1810  Acc@1: 62.5000 (62.1181)  Acc@5: 93.7500 (90.8671)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3920/4579]  eta: 0:03:52  Lr: 0.001875  Loss: -0.1132  Acc@1: 62.5000 (62.1174)  Acc@5: 93.7500 (90.8697)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3930/4579]  eta: 0:03:49  Lr: 0.001875  Loss: -0.3667  Acc@1: 62.5000 (62.1136)  Acc@5: 93.7500 (90.8675)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3940/4579]  eta: 0:03:45  Lr: 0.001875  Loss: -0.5275  Acc@1: 62.5000 (62.1241)  Acc@5: 93.7500 (90.8716)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3950/4579]  eta: 0:03:42  Lr: 0.001875  Loss: -0.2891  Acc@1: 68.7500 (62.1330)  Acc@5: 93.7500 (90.8726)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3960/4579]  eta: 0:03:38  Lr: 0.001875  Loss: -0.0538  Acc@1: 62.5000 (62.1324)  Acc@5: 93.7500 (90.8672)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5748  Acc@1: 68.7500 (62.1537)  Acc@5: 93.7500 (90.8745)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:31  Lr: 0.001875  Loss: -0.4118  Acc@1: 68.7500 (62.1483)  Acc@5: 93.7500 (90.8723)  time: 0.3586  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:27  Lr: 0.001875  Loss: -0.0512  Acc@1: 56.2500 (62.1429)  Acc@5: 93.7500 (90.8732)  time: 0.3566  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:24  Lr: 0.001875  Loss: -0.7499  Acc@1: 56.2500 (62.1454)  Acc@5: 93.7500 (90.8804)  time: 0.3580  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:20  Lr: 0.001875  Loss: 0.0847  Acc@1: 62.5000 (62.1572)  Acc@5: 93.7500 (90.8751)  time: 0.3619  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:17  Lr: 0.001875  Loss: 0.2771  Acc@1: 62.5000 (62.1518)  Acc@5: 93.7500 (90.8822)  time: 0.3603  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:13  Lr: 0.001875  Loss: -0.3200  Acc@1: 62.5000 (62.1697)  Acc@5: 93.7500 (90.8847)  time: 0.3572  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:10  Lr: 0.001875  Loss: -0.2383  Acc@1: 62.5000 (62.1690)  Acc@5: 93.7500 (90.8841)  time: 0.3594  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:06  Lr: 0.001875  Loss: -0.4027  Acc@1: 62.5000 (62.1806)  Acc@5: 93.7500 (90.8865)  time: 0.3581  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4060/4579]  eta: 0:03:03  Lr: 0.001875  Loss: -0.1775  Acc@1: 68.7500 (62.1907)  Acc@5: 93.7500 (90.8920)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4070/4579]  eta: 0:02:59  Lr: 0.001875  Loss: -0.2274  Acc@1: 62.5000 (62.1883)  Acc@5: 93.7500 (90.8975)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4080/4579]  eta: 0:02:56  Lr: 0.001875  Loss: -0.3424  Acc@1: 62.5000 (62.1952)  Acc@5: 93.7500 (90.8984)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4090/4579]  eta: 0:02:52  Lr: 0.001875  Loss: 0.0185  Acc@1: 62.5000 (62.2006)  Acc@5: 93.7500 (90.9008)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4100/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 0.0940  Acc@1: 62.5000 (62.2043)  Acc@5: 93.7500 (90.9001)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4110/4579]  eta: 0:02:45  Lr: 0.001875  Loss: -0.0923  Acc@1: 62.5000 (62.2127)  Acc@5: 87.5000 (90.8979)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4120/4579]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6642  Acc@1: 62.5000 (62.2179)  Acc@5: 93.7500 (90.9018)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:38  Lr: 0.001875  Loss: 0.2177  Acc@1: 62.5000 (62.2156)  Acc@5: 93.7500 (90.9026)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:34  Lr: 0.001875  Loss: -0.2908  Acc@1: 68.7500 (62.2374)  Acc@5: 93.7500 (90.9065)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:31  Lr: 0.001875  Loss: -0.3426  Acc@1: 62.5000 (62.2184)  Acc@5: 93.7500 (90.9073)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:27  Lr: 0.001875  Loss: -0.5395  Acc@1: 56.2500 (62.2311)  Acc@5: 93.7500 (90.9081)  time: 0.3573  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:24  Lr: 0.001875  Loss: -0.1904  Acc@1: 62.5000 (62.2303)  Acc@5: 93.7500 (90.9120)  time: 0.3596  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:20  Lr: 0.001875  Loss: -0.2277  Acc@1: 62.5000 (62.2444)  Acc@5: 93.7500 (90.9098)  time: 0.3602  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:17  Lr: 0.001875  Loss: -0.2055  Acc@1: 62.5000 (62.2524)  Acc@5: 87.5000 (90.9121)  time: 0.3606  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:13  Lr: 0.001875  Loss: -0.0336  Acc@1: 62.5000 (62.2486)  Acc@5: 93.7500 (90.9114)  time: 0.3611  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:10  Lr: 0.001875  Loss: -0.1246  Acc@1: 56.2500 (62.2328)  Acc@5: 87.5000 (90.9048)  time: 0.3569  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:06  Lr: 0.001875  Loss: -0.2924  Acc@1: 56.2500 (62.2438)  Acc@5: 93.7500 (90.9145)  time: 0.3559  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:03  Lr: 0.001875  Loss: -0.3064  Acc@1: 68.7500 (62.2696)  Acc@5: 93.7500 (90.9153)  time: 0.3563  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4240/4579]  eta: 0:01:59  Lr: 0.001875  Loss: -0.1363  Acc@1: 62.5000 (62.2642)  Acc@5: 93.7500 (90.9116)  time: 0.3562  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4250/4579]  eta: 0:01:56  Lr: 0.001875  Loss: 0.0960  Acc@1: 62.5000 (62.2633)  Acc@5: 87.5000 (90.9051)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4260/4579]  eta: 0:01:52  Lr: 0.001875  Loss: -0.1258  Acc@1: 56.2500 (62.2565)  Acc@5: 87.5000 (90.9044)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4270/4579]  eta: 0:01:49  Lr: 0.001875  Loss: 0.0160  Acc@1: 56.2500 (62.2527)  Acc@5: 87.5000 (90.9082)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:45  Lr: 0.001875  Loss: -0.4506  Acc@1: 62.5000 (62.2577)  Acc@5: 87.5000 (90.9031)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:42  Lr: 0.001875  Loss: -0.4526  Acc@1: 62.5000 (62.2466)  Acc@5: 87.5000 (90.9025)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:38  Lr: 0.001875  Loss: -0.3922  Acc@1: 62.5000 (62.2472)  Acc@5: 87.5000 (90.8989)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6849  Acc@1: 56.2500 (62.2405)  Acc@5: 87.5000 (90.8997)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:31  Lr: 0.001875  Loss: -0.4468  Acc@1: 62.5000 (62.2440)  Acc@5: 87.5000 (90.8962)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1129  Acc@1: 62.5000 (62.2460)  Acc@5: 87.5000 (90.8884)  time: 0.3489  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5535  Acc@1: 62.5000 (62.2581)  Acc@5: 87.5000 (90.8906)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2114  Acc@1: 62.5000 (62.2644)  Acc@5: 93.7500 (90.8943)  time: 0.3530  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:17  Lr: 0.001875  Loss: 0.0305  Acc@1: 62.5000 (62.2549)  Acc@5: 87.5000 (90.8880)  time: 0.3515  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: 0.1051  Acc@1: 62.5000 (62.2684)  Acc@5: 93.7500 (90.8945)  time: 0.3560  data: 0.0029  max mem: 2500
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3852  Acc@1: 62.5000 (62.2632)  Acc@5: 93.7500 (90.9010)  time: 0.3605  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: 0.1855  Acc@1: 62.5000 (62.2651)  Acc@5: 93.7500 (90.9018)  time: 0.3651  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4087  Acc@1: 62.5000 (62.2671)  Acc@5: 93.7500 (90.9026)  time: 0.3635  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.1801  Acc@1: 62.5000 (62.2719)  Acc@5: 93.7500 (90.8992)  time: 0.3567  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4420/4579]  eta: 0:00:56  Lr: 0.001875  Loss: -0.6879  Acc@1: 68.7500 (62.2795)  Acc@5: 93.7500 (90.9127)  time: 0.3576  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0623  Acc@1: 68.7500 (62.2842)  Acc@5: 93.7500 (90.9120)  time: 0.3561  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:49  Lr: 0.001875  Loss: -0.7125  Acc@1: 68.7500 (62.2973)  Acc@5: 93.7500 (90.9128)  time: 0.3520  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.3084  Acc@1: 68.7500 (62.3104)  Acc@5: 93.7500 (90.9108)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0052  Acc@1: 68.7500 (62.3305)  Acc@5: 93.7500 (90.9171)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5526  Acc@1: 68.7500 (62.3420)  Acc@5: 93.7500 (90.9262)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1112  Acc@1: 68.7500 (62.3535)  Acc@5: 93.7500 (90.9270)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2857  Acc@1: 68.7500 (62.3650)  Acc@5: 93.7500 (90.9193)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.1689  Acc@1: 62.5000 (62.3584)  Acc@5: 87.5000 (90.9145)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1520  Acc@1: 62.5000 (62.3642)  Acc@5: 87.5000 (90.9180)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0544  Acc@1: 62.5000 (62.3645)  Acc@5: 93.7500 (90.9146)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2894  Acc@1: 62.5000 (62.3772)  Acc@5: 87.5000 (90.9085)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0839  Acc@1: 62.5000 (62.3816)  Acc@5: 87.5000 (90.9120)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.4103  Acc@1: 68.7500 (62.3956)  Acc@5: 93.7500 (90.9113)  time: 0.3553  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.5108  Acc@1: 62.5000 (62.3890)  Acc@5: 87.5000 (90.9052)  time: 0.3554  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.1255  Acc@1: 62.5000 (62.3961)  Acc@5: 87.5000 (90.9046)  time: 0.3592  data: 0.0029  max mem: 2500
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4856  Acc@1: 66.6667 (62.4077)  Acc@5: 93.7500 (90.9087)  time: 0.3511  data: 0.0022  max mem: 2500
Train: Epoch[2/5] Total time: 0:26:58 (0.3534 s / it)
{0: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4856  Acc@1: 66.6667 (62.4077)  Acc@5: 93.7500 (90.9087)
Train: Epoch[3/5]  [   0/4579]  eta: 1:51:13  Lr: 0.001875  Loss: 0.2308  Acc@1: 56.2500 (56.2500)  Acc@5: 81.2500 (81.2500)  time: 1.4574  data: 1.0892  max mem: 2500
Train: Epoch[3/5]  [  10/4579]  eta: 0:34:47  Lr: 0.001875  Loss: -0.4319  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.3182)  time: 0.4570  data: 0.1001  max mem: 2500
Train: Epoch[3/5]  [  20/4579]  eta: 0:30:56  Lr: 0.001875  Loss: -0.0607  Acc@1: 68.7500 (67.2619)  Acc@5: 93.7500 (90.4762)  time: 0.3547  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [  30/4579]  eta: 0:29:41  Lr: 0.001875  Loss: 0.0970  Acc@1: 68.7500 (67.1371)  Acc@5: 87.5000 (90.5242)  time: 0.3555  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [  40/4579]  eta: 0:28:50  Lr: 0.001875  Loss: -0.8537  Acc@1: 62.5000 (66.9207)  Acc@5: 93.7500 (90.7012)  time: 0.3541  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  50/4579]  eta: 0:28:21  Lr: 0.001875  Loss: -0.0343  Acc@1: 62.5000 (64.5833)  Acc@5: 87.5000 (90.4412)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [  60/4579]  eta: 0:27:59  Lr: 0.001875  Loss: -0.1591  Acc@1: 62.5000 (64.9590)  Acc@5: 93.7500 (91.1885)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  70/4579]  eta: 0:27:42  Lr: 0.001875  Loss: -0.1029  Acc@1: 62.5000 (63.6444)  Acc@5: 87.5000 (90.7570)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  80/4579]  eta: 0:27:27  Lr: 0.001875  Loss: -0.6094  Acc@1: 56.2500 (63.6574)  Acc@5: 87.5000 (90.8179)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  90/4579]  eta: 0:27:15  Lr: 0.001875  Loss: -0.2907  Acc@1: 62.5000 (63.3242)  Acc@5: 87.5000 (90.6593)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 100/4579]  eta: 0:27:04  Lr: 0.001875  Loss: -0.5096  Acc@1: 62.5000 (63.4901)  Acc@5: 93.7500 (91.0891)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 110/4579]  eta: 0:26:54  Lr: 0.001875  Loss: -0.2726  Acc@1: 68.7500 (63.6824)  Acc@5: 93.7500 (91.2162)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 120/4579]  eta: 0:26:46  Lr: 0.001875  Loss: -0.1379  Acc@1: 68.7500 (63.8946)  Acc@5: 93.7500 (91.4256)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 130/4579]  eta: 0:26:38  Lr: 0.001875  Loss: -0.3682  Acc@1: 62.5000 (63.8359)  Acc@5: 93.7500 (91.2691)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 140/4579]  eta: 0:26:31  Lr: 0.001875  Loss: -0.2089  Acc@1: 62.5000 (63.9184)  Acc@5: 93.7500 (91.4007)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 150/4579]  eta: 0:26:29  Lr: 0.001875  Loss: -0.5437  Acc@1: 62.5000 (64.0315)  Acc@5: 93.7500 (91.3079)  time: 0.3553  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [ 160/4579]  eta: 0:26:24  Lr: 0.001875  Loss: -0.0358  Acc@1: 68.7500 (64.2857)  Acc@5: 87.5000 (91.3432)  time: 0.3586  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [ 170/4579]  eta: 0:26:20  Lr: 0.001875  Loss: -0.5403  Acc@1: 68.7500 (64.6199)  Acc@5: 93.7500 (91.4839)  time: 0.3561  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 180/4579]  eta: 0:26:16  Lr: 0.001875  Loss: -0.5698  Acc@1: 68.7500 (64.9171)  Acc@5: 93.7500 (91.5746)  time: 0.3569  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 190/4579]  eta: 0:26:12  Lr: 0.001875  Loss: -0.4973  Acc@1: 62.5000 (64.7251)  Acc@5: 93.7500 (91.4921)  time: 0.3577  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 200/4579]  eta: 0:26:08  Lr: 0.001875  Loss: -0.5492  Acc@1: 62.5000 (64.7077)  Acc@5: 93.7500 (91.7600)  time: 0.3570  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 210/4579]  eta: 0:26:04  Lr: 0.001875  Loss: -0.3887  Acc@1: 68.7500 (64.8697)  Acc@5: 93.7500 (91.8543)  time: 0.3559  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [ 220/4579]  eta: 0:25:59  Lr: 0.001875  Loss: 0.1400  Acc@1: 68.7500 (64.6210)  Acc@5: 93.7500 (91.8835)  time: 0.3533  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [ 230/4579]  eta: 0:25:55  Lr: 0.001875  Loss: -0.6912  Acc@1: 62.5000 (64.6374)  Acc@5: 93.7500 (91.8831)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 240/4579]  eta: 0:25:50  Lr: 0.001875  Loss: -0.3836  Acc@1: 68.7500 (64.9118)  Acc@5: 93.7500 (91.9087)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 250/4579]  eta: 0:25:45  Lr: 0.001875  Loss: -0.0893  Acc@1: 68.7500 (64.6912)  Acc@5: 93.7500 (91.9074)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 260/4579]  eta: 0:25:40  Lr: 0.001875  Loss: -0.7399  Acc@1: 62.5000 (64.7031)  Acc@5: 93.7500 (91.9540)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 270/4579]  eta: 0:25:36  Lr: 0.001875  Loss: 0.1032  Acc@1: 62.5000 (64.6448)  Acc@5: 93.7500 (91.9742)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 280/4579]  eta: 0:25:31  Lr: 0.001875  Loss: -0.3045  Acc@1: 62.5000 (64.5463)  Acc@5: 87.5000 (91.8372)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 290/4579]  eta: 0:25:26  Lr: 0.001875  Loss: -0.2980  Acc@1: 62.5000 (64.5619)  Acc@5: 93.7500 (91.9674)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 300/4579]  eta: 0:25:22  Lr: 0.001875  Loss: -0.2765  Acc@1: 56.2500 (64.3688)  Acc@5: 93.7500 (91.8189)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 310/4579]  eta: 0:25:18  Lr: 0.001875  Loss: 0.2548  Acc@1: 56.2500 (64.1680)  Acc@5: 87.5000 (91.8006)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 320/4579]  eta: 0:25:13  Lr: 0.001875  Loss: -0.0720  Acc@1: 62.5000 (64.2329)  Acc@5: 93.7500 (91.7640)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 330/4579]  eta: 0:25:10  Lr: 0.001875  Loss: -0.1902  Acc@1: 62.5000 (64.1616)  Acc@5: 93.7500 (91.6541)  time: 0.3539  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 340/4579]  eta: 0:25:07  Lr: 0.001875  Loss: 0.2118  Acc@1: 62.5000 (64.0762)  Acc@5: 87.5000 (91.5506)  time: 0.3583  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 350/4579]  eta: 0:25:03  Lr: 0.001875  Loss: -0.1211  Acc@1: 62.5000 (64.0313)  Acc@5: 93.7500 (91.5598)  time: 0.3554  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 360/4579]  eta: 0:24:59  Lr: 0.001875  Loss: -0.1510  Acc@1: 62.5000 (63.9889)  Acc@5: 93.7500 (91.5512)  time: 0.3541  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 370/4579]  eta: 0:24:57  Lr: 0.001875  Loss: -0.2206  Acc@1: 62.5000 (63.8309)  Acc@5: 93.7500 (91.5431)  time: 0.3588  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 380/4579]  eta: 0:24:54  Lr: 0.001875  Loss: -0.3164  Acc@1: 62.5000 (63.9436)  Acc@5: 93.7500 (91.5846)  time: 0.3631  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 390/4579]  eta: 0:24:50  Lr: 0.001875  Loss: -0.4503  Acc@1: 68.7500 (63.9706)  Acc@5: 93.7500 (91.5601)  time: 0.3599  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [ 400/4579]  eta: 0:24:47  Lr: 0.001875  Loss: 0.3324  Acc@1: 68.7500 (64.0430)  Acc@5: 93.7500 (91.5835)  time: 0.3574  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 410/4579]  eta: 0:24:43  Lr: 0.001875  Loss: -0.4365  Acc@1: 68.7500 (64.1575)  Acc@5: 93.7500 (91.6667)  time: 0.3566  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 420/4579]  eta: 0:24:40  Lr: 0.001875  Loss: -0.2644  Acc@1: 68.7500 (64.1479)  Acc@5: 93.7500 (91.7013)  time: 0.3551  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 430/4579]  eta: 0:24:36  Lr: 0.001875  Loss: -0.3010  Acc@1: 68.7500 (64.1821)  Acc@5: 93.7500 (91.7198)  time: 0.3537  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 440/4579]  eta: 0:24:32  Lr: 0.001875  Loss: -0.2468  Acc@1: 62.5000 (64.1582)  Acc@5: 93.7500 (91.6950)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 450/4579]  eta: 0:24:28  Lr: 0.001875  Loss: -0.3729  Acc@1: 68.7500 (64.1907)  Acc@5: 93.7500 (91.6990)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 460/4579]  eta: 0:24:24  Lr: 0.001875  Loss: 0.2305  Acc@1: 68.7500 (64.1133)  Acc@5: 93.7500 (91.7164)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 470/4579]  eta: 0:24:20  Lr: 0.001875  Loss: 0.0903  Acc@1: 62.5000 (64.0260)  Acc@5: 93.7500 (91.7463)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 480/4579]  eta: 0:24:16  Lr: 0.001875  Loss: -0.2646  Acc@1: 62.5000 (64.0463)  Acc@5: 93.7500 (91.6970)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 490/4579]  eta: 0:24:12  Lr: 0.001875  Loss: 0.3612  Acc@1: 62.5000 (64.0657)  Acc@5: 93.7500 (91.7515)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 500/4579]  eta: 0:24:08  Lr: 0.001875  Loss: -0.1312  Acc@1: 62.5000 (64.0968)  Acc@5: 93.7500 (91.7540)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 510/4579]  eta: 0:24:04  Lr: 0.001875  Loss: 0.0923  Acc@1: 62.5000 (64.0900)  Acc@5: 93.7500 (91.7931)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 520/4579]  eta: 0:24:00  Lr: 0.001875  Loss: -0.0064  Acc@1: 62.5000 (64.1075)  Acc@5: 93.7500 (91.7346)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 530/4579]  eta: 0:23:56  Lr: 0.001875  Loss: -0.2562  Acc@1: 62.5000 (64.1361)  Acc@5: 87.5000 (91.7608)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 540/4579]  eta: 0:23:53  Lr: 0.001875  Loss: -0.2716  Acc@1: 62.5000 (64.2098)  Acc@5: 93.7500 (91.8091)  time: 0.3515  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 550/4579]  eta: 0:23:49  Lr: 0.001875  Loss: -0.2785  Acc@1: 68.7500 (64.2015)  Acc@5: 87.5000 (91.7650)  time: 0.3530  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 560/4579]  eta: 0:23:45  Lr: 0.001875  Loss: -0.5786  Acc@1: 62.5000 (64.1266)  Acc@5: 87.5000 (91.7447)  time: 0.3549  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 570/4579]  eta: 0:23:42  Lr: 0.001875  Loss: -0.7060  Acc@1: 62.5000 (64.1419)  Acc@5: 93.7500 (91.7579)  time: 0.3580  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 580/4579]  eta: 0:23:39  Lr: 0.001875  Loss: -0.1802  Acc@1: 62.5000 (64.0383)  Acc@5: 93.7500 (91.7276)  time: 0.3601  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 590/4579]  eta: 0:23:36  Lr: 0.001875  Loss: -0.3807  Acc@1: 62.5000 (63.9700)  Acc@5: 93.7500 (91.7301)  time: 0.3610  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 600/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 0.3017  Acc@1: 62.5000 (63.9559)  Acc@5: 93.7500 (91.7221)  time: 0.3587  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 610/4579]  eta: 0:23:29  Lr: 0.001875  Loss: -0.2057  Acc@1: 62.5000 (63.9014)  Acc@5: 93.7500 (91.6735)  time: 0.3559  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 620/4579]  eta: 0:23:26  Lr: 0.001875  Loss: 0.0247  Acc@1: 62.5000 (63.8990)  Acc@5: 93.7500 (91.6667)  time: 0.3575  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [ 630/4579]  eta: 0:23:22  Lr: 0.001875  Loss: -0.1671  Acc@1: 62.5000 (63.9461)  Acc@5: 93.7500 (91.6997)  time: 0.3570  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [ 640/4579]  eta: 0:23:18  Lr: 0.001875  Loss: -0.3812  Acc@1: 62.5000 (63.9626)  Acc@5: 93.7500 (91.6439)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 650/4579]  eta: 0:23:14  Lr: 0.001875  Loss: -0.3221  Acc@1: 68.7500 (64.1129)  Acc@5: 87.5000 (91.5995)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 660/4579]  eta: 0:23:11  Lr: 0.001875  Loss: -0.5063  Acc@1: 68.7500 (64.1547)  Acc@5: 93.7500 (91.6036)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 670/4579]  eta: 0:23:07  Lr: 0.001875  Loss: -0.1685  Acc@1: 62.5000 (64.1487)  Acc@5: 93.7500 (91.5425)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 680/4579]  eta: 0:23:03  Lr: 0.001875  Loss: -0.4532  Acc@1: 62.5000 (64.1979)  Acc@5: 87.5000 (91.5657)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 690/4579]  eta: 0:22:59  Lr: 0.001875  Loss: -0.5580  Acc@1: 62.5000 (64.1914)  Acc@5: 93.7500 (91.5431)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 700/4579]  eta: 0:22:55  Lr: 0.001875  Loss: -0.4363  Acc@1: 62.5000 (64.1673)  Acc@5: 93.7500 (91.5478)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 710/4579]  eta: 0:22:52  Lr: 0.001875  Loss: -0.1888  Acc@1: 68.7500 (64.2053)  Acc@5: 93.7500 (91.5612)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 720/4579]  eta: 0:22:48  Lr: 0.001875  Loss: -0.1672  Acc@1: 68.7500 (64.2510)  Acc@5: 93.7500 (91.5915)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 730/4579]  eta: 0:22:44  Lr: 0.001875  Loss: -0.1089  Acc@1: 68.7500 (64.2100)  Acc@5: 93.7500 (91.6211)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 740/4579]  eta: 0:22:40  Lr: 0.001875  Loss: -0.3793  Acc@1: 68.7500 (64.2713)  Acc@5: 93.7500 (91.6582)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 750/4579]  eta: 0:22:36  Lr: 0.001875  Loss: -0.2488  Acc@1: 68.7500 (64.2477)  Acc@5: 93.7500 (91.6611)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 760/4579]  eta: 0:22:33  Lr: 0.001875  Loss: -0.2030  Acc@1: 56.2500 (64.1015)  Acc@5: 87.5000 (91.5900)  time: 0.3565  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 770/4579]  eta: 0:22:30  Lr: 0.001875  Loss: -0.2215  Acc@1: 56.2500 (64.0807)  Acc@5: 87.5000 (91.5532)  time: 0.3602  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 780/4579]  eta: 0:22:26  Lr: 0.001875  Loss: -0.3689  Acc@1: 56.2500 (64.0205)  Acc@5: 93.7500 (91.5893)  time: 0.3567  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 790/4579]  eta: 0:22:23  Lr: 0.001875  Loss: -0.2640  Acc@1: 62.5000 (64.0408)  Acc@5: 93.7500 (91.5929)  time: 0.3602  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 800/4579]  eta: 0:22:20  Lr: 0.001875  Loss: -0.3365  Acc@1: 62.5000 (64.0762)  Acc@5: 93.7500 (91.5808)  time: 0.3631  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 810/4579]  eta: 0:22:17  Lr: 0.001875  Loss: -0.3925  Acc@1: 62.5000 (64.0336)  Acc@5: 87.5000 (91.5768)  time: 0.3588  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 820/4579]  eta: 0:22:13  Lr: 0.001875  Loss: -0.3175  Acc@1: 62.5000 (63.9769)  Acc@5: 93.7500 (91.6261)  time: 0.3593  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [ 830/4579]  eta: 0:22:10  Lr: 0.001875  Loss: 0.3063  Acc@1: 62.5000 (63.9967)  Acc@5: 93.7500 (91.6667)  time: 0.3574  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [ 840/4579]  eta: 0:22:06  Lr: 0.001875  Loss: 0.1008  Acc@1: 68.7500 (64.0012)  Acc@5: 93.7500 (91.6840)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 850/4579]  eta: 0:22:02  Lr: 0.001875  Loss: -0.3494  Acc@1: 68.7500 (64.0570)  Acc@5: 93.7500 (91.6789)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 860/4579]  eta: 0:21:59  Lr: 0.001875  Loss: -0.0026  Acc@1: 62.5000 (64.0607)  Acc@5: 93.7500 (91.6884)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 870/4579]  eta: 0:21:55  Lr: 0.001875  Loss: -0.0261  Acc@1: 62.5000 (64.0141)  Acc@5: 93.7500 (91.6547)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 880/4579]  eta: 0:21:51  Lr: 0.001875  Loss: -0.3126  Acc@1: 62.5000 (64.0182)  Acc@5: 87.5000 (91.6501)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 890/4579]  eta: 0:21:47  Lr: 0.001875  Loss: 0.0466  Acc@1: 62.5000 (64.0502)  Acc@5: 93.7500 (91.6597)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 900/4579]  eta: 0:21:43  Lr: 0.001875  Loss: -0.3262  Acc@1: 68.7500 (64.1024)  Acc@5: 93.7500 (91.6690)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 910/4579]  eta: 0:21:40  Lr: 0.001875  Loss: -0.5881  Acc@1: 62.5000 (64.0505)  Acc@5: 87.5000 (91.6369)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 920/4579]  eta: 0:21:36  Lr: 0.001875  Loss: -0.4526  Acc@1: 56.2500 (63.9929)  Acc@5: 87.5000 (91.6124)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 930/4579]  eta: 0:21:32  Lr: 0.001875  Loss: -0.5595  Acc@1: 62.5000 (63.9970)  Acc@5: 93.7500 (91.6286)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 940/4579]  eta: 0:21:29  Lr: 0.001875  Loss: 0.1110  Acc@1: 56.2500 (63.9479)  Acc@5: 93.7500 (91.5914)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 950/4579]  eta: 0:21:25  Lr: 0.001875  Loss: -0.0794  Acc@1: 62.5000 (63.9393)  Acc@5: 87.5000 (91.5549)  time: 0.3578  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [ 960/4579]  eta: 0:21:22  Lr: 0.001875  Loss: 0.0710  Acc@1: 62.5000 (63.9243)  Acc@5: 87.5000 (91.5713)  time: 0.3568  data: 0.0038  max mem: 2500
Train: Epoch[3/5]  [ 970/4579]  eta: 0:21:18  Lr: 0.001875  Loss: -0.1488  Acc@1: 62.5000 (63.9611)  Acc@5: 93.7500 (91.6195)  time: 0.3573  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 980/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.2352  Acc@1: 68.7500 (63.9717)  Acc@5: 93.7500 (91.6284)  time: 0.3588  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 990/4579]  eta: 0:21:12  Lr: 0.001875  Loss: -0.6449  Acc@1: 62.5000 (63.9442)  Acc@5: 87.5000 (91.6120)  time: 0.3586  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1000/4579]  eta: 0:21:08  Lr: 0.001875  Loss: -0.3820  Acc@1: 56.2500 (63.9423)  Acc@5: 87.5000 (91.5772)  time: 0.3563  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1010/4579]  eta: 0:21:05  Lr: 0.001875  Loss: -0.4913  Acc@1: 56.2500 (63.9280)  Acc@5: 93.7500 (91.5801)  time: 0.3555  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1020/4579]  eta: 0:21:01  Lr: 0.001875  Loss: -0.0759  Acc@1: 56.2500 (63.8896)  Acc@5: 93.7500 (91.6136)  time: 0.3587  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [1030/4579]  eta: 0:20:58  Lr: 0.001875  Loss: -0.4232  Acc@1: 62.5000 (63.8700)  Acc@5: 93.7500 (91.6343)  time: 0.3543  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [1040/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.0229  Acc@1: 62.5000 (63.8689)  Acc@5: 93.7500 (91.6306)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1050/4579]  eta: 0:20:50  Lr: 0.001875  Loss: -0.2080  Acc@1: 62.5000 (63.8856)  Acc@5: 93.7500 (91.6330)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1060/4579]  eta: 0:20:46  Lr: 0.001875  Loss: -0.4537  Acc@1: 62.5000 (63.8961)  Acc@5: 93.7500 (91.6706)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1070/4579]  eta: 0:20:43  Lr: 0.001875  Loss: 0.6889  Acc@1: 62.5000 (63.8831)  Acc@5: 93.7500 (91.6900)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1080/4579]  eta: 0:20:39  Lr: 0.001875  Loss: -0.1138  Acc@1: 62.5000 (63.8818)  Acc@5: 93.7500 (91.6975)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1090/4579]  eta: 0:20:35  Lr: 0.001875  Loss: -0.7783  Acc@1: 62.5000 (63.8921)  Acc@5: 93.7500 (91.7220)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1100/4579]  eta: 0:20:32  Lr: 0.001875  Loss: -0.1214  Acc@1: 62.5000 (63.8794)  Acc@5: 93.7500 (91.7461)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1110/4579]  eta: 0:20:28  Lr: 0.001875  Loss: 0.0419  Acc@1: 62.5000 (63.8558)  Acc@5: 93.7500 (91.7360)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1120/4579]  eta: 0:20:24  Lr: 0.001875  Loss: -0.2937  Acc@1: 62.5000 (63.8827)  Acc@5: 87.5000 (91.6871)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1130/4579]  eta: 0:20:21  Lr: 0.001875  Loss: -0.3205  Acc@1: 62.5000 (63.8815)  Acc@5: 93.7500 (91.6943)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1140/4579]  eta: 0:20:17  Lr: 0.001875  Loss: -0.6421  Acc@1: 68.7500 (63.9297)  Acc@5: 93.7500 (91.7123)  time: 0.3569  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1150/4579]  eta: 0:20:14  Lr: 0.001875  Loss: -0.4616  Acc@1: 68.7500 (63.9390)  Acc@5: 93.7500 (91.7029)  time: 0.3578  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [1160/4579]  eta: 0:20:10  Lr: 0.001875  Loss: -0.1448  Acc@1: 56.2500 (63.8781)  Acc@5: 93.7500 (91.7205)  time: 0.3547  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [1170/4579]  eta: 0:20:07  Lr: 0.001875  Loss: -0.5378  Acc@1: 62.5000 (63.8717)  Acc@5: 93.7500 (91.6951)  time: 0.3585  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1180/4579]  eta: 0:20:04  Lr: 0.001875  Loss: -0.5503  Acc@1: 62.5000 (63.9448)  Acc@5: 93.7500 (91.7072)  time: 0.3636  data: 0.0039  max mem: 2500
Train: Epoch[3/5]  [1190/4579]  eta: 0:20:00  Lr: 0.001875  Loss: -0.2049  Acc@1: 68.7500 (63.9746)  Acc@5: 93.7500 (91.7191)  time: 0.3611  data: 0.0051  max mem: 2500
Train: Epoch[3/5]  [1200/4579]  eta: 0:19:57  Lr: 0.001875  Loss: -0.3288  Acc@1: 62.5000 (63.9675)  Acc@5: 93.7500 (91.7308)  time: 0.3567  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [1210/4579]  eta: 0:19:53  Lr: 0.001875  Loss: -0.7196  Acc@1: 62.5000 (63.9399)  Acc@5: 93.7500 (91.7166)  time: 0.3574  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [1220/4579]  eta: 0:19:50  Lr: 0.001875  Loss: 0.2343  Acc@1: 62.5000 (63.9537)  Acc@5: 93.7500 (91.7127)  time: 0.3536  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1230/4579]  eta: 0:19:46  Lr: 0.001875  Loss: -0.2932  Acc@1: 68.7500 (63.9673)  Acc@5: 87.5000 (91.6988)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1240/4579]  eta: 0:19:42  Lr: 0.001875  Loss: -0.4423  Acc@1: 68.7500 (63.9756)  Acc@5: 87.5000 (91.7002)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1250/4579]  eta: 0:19:39  Lr: 0.001875  Loss: -0.4920  Acc@1: 68.7500 (63.9888)  Acc@5: 87.5000 (91.6867)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1260/4579]  eta: 0:19:35  Lr: 0.001875  Loss: 0.0748  Acc@1: 68.7500 (63.9919)  Acc@5: 87.5000 (91.6683)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1270/4579]  eta: 0:19:31  Lr: 0.001875  Loss: 0.1749  Acc@1: 62.5000 (63.9851)  Acc@5: 93.7500 (91.6650)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1280/4579]  eta: 0:19:28  Lr: 0.001875  Loss: -0.2370  Acc@1: 68.7500 (64.0125)  Acc@5: 93.7500 (91.6618)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1290/4579]  eta: 0:19:24  Lr: 0.001875  Loss: 0.0065  Acc@1: 68.7500 (64.0250)  Acc@5: 93.7500 (91.6489)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1300/4579]  eta: 0:19:20  Lr: 0.001875  Loss: 0.0484  Acc@1: 62.5000 (64.0133)  Acc@5: 87.5000 (91.6458)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1310/4579]  eta: 0:19:17  Lr: 0.001875  Loss: 0.4644  Acc@1: 56.2500 (63.9779)  Acc@5: 93.7500 (91.6428)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1320/4579]  eta: 0:19:13  Lr: 0.001875  Loss: -0.3031  Acc@1: 56.2500 (63.9194)  Acc@5: 87.5000 (91.6020)  time: 0.3511  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1330/4579]  eta: 0:19:10  Lr: 0.001875  Loss: -0.2835  Acc@1: 56.2500 (63.9134)  Acc@5: 87.5000 (91.5947)  time: 0.3541  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1340/4579]  eta: 0:19:06  Lr: 0.001875  Loss: -0.2441  Acc@1: 62.5000 (63.8889)  Acc@5: 87.5000 (91.5874)  time: 0.3550  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1350/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.2103  Acc@1: 62.5000 (63.9064)  Acc@5: 93.7500 (91.6219)  time: 0.3570  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1360/4579]  eta: 0:18:59  Lr: 0.001875  Loss: -0.2895  Acc@1: 62.5000 (63.9052)  Acc@5: 93.7500 (91.6008)  time: 0.3586  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1370/4579]  eta: 0:18:56  Lr: 0.001875  Loss: -0.2128  Acc@1: 62.5000 (63.8950)  Acc@5: 87.5000 (91.5937)  time: 0.3605  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [1380/4579]  eta: 0:18:53  Lr: 0.001875  Loss: -0.1231  Acc@1: 62.5000 (63.9030)  Acc@5: 93.7500 (91.6229)  time: 0.3629  data: 0.0050  max mem: 2500
Train: Epoch[3/5]  [1390/4579]  eta: 0:18:49  Lr: 0.001875  Loss: -0.3282  Acc@1: 62.5000 (63.8974)  Acc@5: 100.0000 (91.6517)  time: 0.3598  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [1400/4579]  eta: 0:18:46  Lr: 0.001875  Loss: -0.2461  Acc@1: 62.5000 (63.8606)  Acc@5: 93.7500 (91.6176)  time: 0.3557  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1410/4579]  eta: 0:18:42  Lr: 0.001875  Loss: -0.0352  Acc@1: 62.5000 (63.8687)  Acc@5: 87.5000 (91.6106)  time: 0.3556  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [1420/4579]  eta: 0:18:38  Lr: 0.001875  Loss: 0.0023  Acc@1: 62.5000 (63.8459)  Acc@5: 87.5000 (91.6036)  time: 0.3540  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [1430/4579]  eta: 0:18:35  Lr: 0.001875  Loss: -0.4190  Acc@1: 62.5000 (63.8627)  Acc@5: 93.7500 (91.6186)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1440/4579]  eta: 0:18:31  Lr: 0.001875  Loss: 0.1705  Acc@1: 62.5000 (63.8532)  Acc@5: 93.7500 (91.6247)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1450/4579]  eta: 0:18:28  Lr: 0.001875  Loss: 0.0283  Acc@1: 62.5000 (63.8525)  Acc@5: 93.7500 (91.6135)  time: 0.3528  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1460/4579]  eta: 0:18:24  Lr: 0.001875  Loss: -0.5139  Acc@1: 62.5000 (63.8475)  Acc@5: 93.7500 (91.6068)  time: 0.3539  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1470/4579]  eta: 0:18:20  Lr: 0.001875  Loss: -0.4404  Acc@1: 62.5000 (63.8596)  Acc@5: 93.7500 (91.6044)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1480/4579]  eta: 0:18:17  Lr: 0.001875  Loss: -0.0048  Acc@1: 62.5000 (63.8336)  Acc@5: 93.7500 (91.6188)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1490/4579]  eta: 0:18:13  Lr: 0.001875  Loss: -0.2477  Acc@1: 62.5000 (63.8456)  Acc@5: 93.7500 (91.6247)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1500/4579]  eta: 0:18:09  Lr: 0.001875  Loss: -0.3688  Acc@1: 62.5000 (63.8200)  Acc@5: 93.7500 (91.6306)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1510/4579]  eta: 0:18:06  Lr: 0.001875  Loss: -0.2374  Acc@1: 62.5000 (63.8195)  Acc@5: 93.7500 (91.6281)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1520/4579]  eta: 0:18:02  Lr: 0.001875  Loss: -0.8036  Acc@1: 62.5000 (63.8601)  Acc@5: 93.7500 (91.6256)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1530/4579]  eta: 0:17:59  Lr: 0.001875  Loss: -0.1868  Acc@1: 68.7500 (63.9002)  Acc@5: 93.7500 (91.6150)  time: 0.3587  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [1540/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.1293  Acc@1: 62.5000 (63.8587)  Acc@5: 87.5000 (91.6004)  time: 0.3630  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [1550/4579]  eta: 0:17:52  Lr: 0.001875  Loss: -0.3576  Acc@1: 56.2500 (63.8661)  Acc@5: 93.7500 (91.6103)  time: 0.3610  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [1560/4579]  eta: 0:17:49  Lr: 0.001875  Loss: -0.7317  Acc@1: 68.7500 (63.8813)  Acc@5: 93.7500 (91.6320)  time: 0.3589  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1570/4579]  eta: 0:17:45  Lr: 0.001875  Loss: -0.0335  Acc@1: 68.7500 (63.8884)  Acc@5: 93.7500 (91.6256)  time: 0.3599  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1580/4579]  eta: 0:17:42  Lr: 0.001875  Loss: 0.1968  Acc@1: 62.5000 (63.8757)  Acc@5: 93.7500 (91.6390)  time: 0.3581  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [1590/4579]  eta: 0:17:38  Lr: 0.001875  Loss: -0.2703  Acc@1: 62.5000 (63.8946)  Acc@5: 93.7500 (91.6287)  time: 0.3585  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1600/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.1539  Acc@1: 68.7500 (63.8819)  Acc@5: 87.5000 (91.6068)  time: 0.3575  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1610/4579]  eta: 0:17:31  Lr: 0.001875  Loss: -0.2258  Acc@1: 62.5000 (63.8540)  Acc@5: 87.5000 (91.5891)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1620/4579]  eta: 0:17:28  Lr: 0.001875  Loss: -0.2663  Acc@1: 62.5000 (63.8533)  Acc@5: 87.5000 (91.5870)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1630/4579]  eta: 0:17:24  Lr: 0.001875  Loss: 0.0843  Acc@1: 62.5000 (63.8259)  Acc@5: 93.7500 (91.5887)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1640/4579]  eta: 0:17:20  Lr: 0.001875  Loss: -0.2386  Acc@1: 62.5000 (63.8521)  Acc@5: 93.7500 (91.5829)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1650/4579]  eta: 0:17:17  Lr: 0.001875  Loss: -0.0512  Acc@1: 62.5000 (63.8439)  Acc@5: 93.7500 (91.5922)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1660/4579]  eta: 0:17:13  Lr: 0.001875  Loss: -0.1398  Acc@1: 68.7500 (63.8772)  Acc@5: 93.7500 (91.5939)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1670/4579]  eta: 0:17:10  Lr: 0.001875  Loss: -0.1226  Acc@1: 68.7500 (63.8914)  Acc@5: 93.7500 (91.5806)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1680/4579]  eta: 0:17:06  Lr: 0.001875  Loss: -0.7115  Acc@1: 68.7500 (63.9054)  Acc@5: 93.7500 (91.5712)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1690/4579]  eta: 0:17:02  Lr: 0.001875  Loss: -0.3545  Acc@1: 62.5000 (63.8786)  Acc@5: 93.7500 (91.5730)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1700/4579]  eta: 0:16:59  Lr: 0.001875  Loss: -0.9577  Acc@1: 62.5000 (63.9036)  Acc@5: 93.7500 (91.5785)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1710/4579]  eta: 0:16:55  Lr: 0.001875  Loss: -0.7018  Acc@1: 68.7500 (63.9173)  Acc@5: 93.7500 (91.5656)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1720/4579]  eta: 0:16:52  Lr: 0.001875  Loss: 0.1280  Acc@1: 62.5000 (63.9272)  Acc@5: 93.7500 (91.5601)  time: 0.3550  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [1730/4579]  eta: 0:16:48  Lr: 0.001875  Loss: 0.0498  Acc@1: 62.5000 (63.9262)  Acc@5: 93.7500 (91.5728)  time: 0.3593  data: 0.0041  max mem: 2500
Train: Epoch[3/5]  [1740/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.2524  Acc@1: 62.5000 (63.9503)  Acc@5: 93.7500 (91.5494)  time: 0.3613  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [1750/4579]  eta: 0:16:41  Lr: 0.001875  Loss: -0.2564  Acc@1: 62.5000 (63.9313)  Acc@5: 93.7500 (91.5405)  time: 0.3598  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1760/4579]  eta: 0:16:38  Lr: 0.001875  Loss: -0.2636  Acc@1: 62.5000 (63.9516)  Acc@5: 93.7500 (91.5460)  time: 0.3573  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [1770/4579]  eta: 0:16:34  Lr: 0.001875  Loss: -0.0564  Acc@1: 62.5000 (63.9469)  Acc@5: 93.7500 (91.5302)  time: 0.3558  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [1780/4579]  eta: 0:16:31  Lr: 0.001875  Loss: 0.3716  Acc@1: 62.5000 (63.9493)  Acc@5: 93.7500 (91.5286)  time: 0.3680  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [1790/4579]  eta: 0:16:28  Lr: 0.001875  Loss: 0.0008  Acc@1: 62.5000 (63.9692)  Acc@5: 93.7500 (91.5341)  time: 0.3649  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1800/4579]  eta: 0:16:24  Lr: 0.001875  Loss: -0.3588  Acc@1: 68.7500 (63.9749)  Acc@5: 93.7500 (91.5221)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1810/4579]  eta: 0:16:20  Lr: 0.001875  Loss: -0.1252  Acc@1: 62.5000 (63.9702)  Acc@5: 93.7500 (91.5171)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1820/4579]  eta: 0:16:17  Lr: 0.001875  Loss: 0.4413  Acc@1: 62.5000 (63.9244)  Acc@5: 87.5000 (91.5225)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1830/4579]  eta: 0:16:13  Lr: 0.001875  Loss: -0.6152  Acc@1: 62.5000 (63.9814)  Acc@5: 93.7500 (91.5176)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1840/4579]  eta: 0:16:09  Lr: 0.001875  Loss: 0.2691  Acc@1: 62.5000 (63.9632)  Acc@5: 87.5000 (91.4924)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1850/4579]  eta: 0:16:06  Lr: 0.001875  Loss: 0.0110  Acc@1: 62.5000 (63.9654)  Acc@5: 87.5000 (91.5046)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1860/4579]  eta: 0:16:02  Lr: 0.001875  Loss: -0.3321  Acc@1: 68.7500 (63.9979)  Acc@5: 93.7500 (91.4931)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1870/4579]  eta: 0:15:59  Lr: 0.001875  Loss: -0.2619  Acc@1: 62.5000 (63.9798)  Acc@5: 87.5000 (91.4785)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1880/4579]  eta: 0:15:55  Lr: 0.001875  Loss: 0.4052  Acc@1: 62.5000 (63.9753)  Acc@5: 93.7500 (91.4806)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1890/4579]  eta: 0:15:52  Lr: 0.001875  Loss: -0.2756  Acc@1: 62.5000 (63.9510)  Acc@5: 93.7500 (91.4860)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1900/4579]  eta: 0:15:48  Lr: 0.001875  Loss: -0.1182  Acc@1: 62.5000 (63.9499)  Acc@5: 93.7500 (91.4880)  time: 0.3562  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1910/4579]  eta: 0:15:45  Lr: 0.001875  Loss: -0.3010  Acc@1: 62.5000 (63.9685)  Acc@5: 93.7500 (91.4835)  time: 0.3557  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [1920/4579]  eta: 0:15:41  Lr: 0.001875  Loss: -0.0699  Acc@1: 62.5000 (63.9738)  Acc@5: 93.7500 (91.4856)  time: 0.3599  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [1930/4579]  eta: 0:15:38  Lr: 0.001875  Loss: 0.1294  Acc@1: 68.7500 (63.9921)  Acc@5: 93.7500 (91.4843)  time: 0.3641  data: 0.0031  max mem: 2500
Train: Epoch[3/5]  [1940/4579]  eta: 0:15:34  Lr: 0.001875  Loss: -0.3902  Acc@1: 68.7500 (64.0037)  Acc@5: 93.7500 (91.4799)  time: 0.3592  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1950/4579]  eta: 0:15:31  Lr: 0.001875  Loss: -0.4602  Acc@1: 68.7500 (63.9928)  Acc@5: 93.7500 (91.4755)  time: 0.3567  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [1960/4579]  eta: 0:15:27  Lr: 0.001875  Loss: 0.3820  Acc@1: 62.5000 (63.9757)  Acc@5: 93.7500 (91.4648)  time: 0.3579  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [1970/4579]  eta: 0:15:24  Lr: 0.001875  Loss: -0.0053  Acc@1: 62.5000 (63.9840)  Acc@5: 93.7500 (91.4701)  time: 0.3568  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1980/4579]  eta: 0:15:20  Lr: 0.001875  Loss: -0.4959  Acc@1: 68.7500 (63.9955)  Acc@5: 93.7500 (91.4879)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1990/4579]  eta: 0:15:16  Lr: 0.001875  Loss: -0.0841  Acc@1: 62.5000 (63.9785)  Acc@5: 93.7500 (91.4930)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2000/4579]  eta: 0:15:13  Lr: 0.001875  Loss: 1.0581  Acc@1: 62.5000 (63.9868)  Acc@5: 93.7500 (91.4886)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2010/4579]  eta: 0:15:09  Lr: 0.001875  Loss: -0.2046  Acc@1: 62.5000 (63.9825)  Acc@5: 93.7500 (91.4874)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2020/4579]  eta: 0:15:06  Lr: 0.001875  Loss: -0.3068  Acc@1: 62.5000 (63.9720)  Acc@5: 93.7500 (91.4863)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2030/4579]  eta: 0:15:02  Lr: 0.001875  Loss: -0.2638  Acc@1: 68.7500 (63.9894)  Acc@5: 93.7500 (91.4882)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2040/4579]  eta: 0:14:58  Lr: 0.001875  Loss: -0.2196  Acc@1: 68.7500 (63.9882)  Acc@5: 93.7500 (91.4870)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2050/4579]  eta: 0:14:55  Lr: 0.001875  Loss: -0.8013  Acc@1: 62.5000 (63.9871)  Acc@5: 93.7500 (91.4767)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2060/4579]  eta: 0:14:51  Lr: 0.001875  Loss: -0.4217  Acc@1: 62.5000 (63.9859)  Acc@5: 87.5000 (91.4726)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2070/4579]  eta: 0:14:48  Lr: 0.001875  Loss: -0.3418  Acc@1: 68.7500 (64.0180)  Acc@5: 93.7500 (91.4806)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2080/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 0.0384  Acc@1: 68.7500 (64.0167)  Acc@5: 87.5000 (91.4644)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2090/4579]  eta: 0:14:41  Lr: 0.001875  Loss: 0.1184  Acc@1: 62.5000 (64.0304)  Acc@5: 87.5000 (91.4694)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2100/4579]  eta: 0:14:37  Lr: 0.001875  Loss: -0.5050  Acc@1: 62.5000 (64.0439)  Acc@5: 93.7500 (91.4683)  time: 0.3571  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2110/4579]  eta: 0:14:34  Lr: 0.001875  Loss: -0.2754  Acc@1: 62.5000 (64.0514)  Acc@5: 93.7500 (91.4880)  time: 0.3618  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2120/4579]  eta: 0:14:30  Lr: 0.001875  Loss: -0.2018  Acc@1: 62.5000 (64.0500)  Acc@5: 93.7500 (91.4722)  time: 0.3674  data: 0.0049  max mem: 2500
Train: Epoch[3/5]  [2130/4579]  eta: 0:14:27  Lr: 0.001875  Loss: -0.0755  Acc@1: 62.5000 (64.0368)  Acc@5: 87.5000 (91.4653)  time: 0.3637  data: 0.0055  max mem: 2500
Train: Epoch[3/5]  [2140/4579]  eta: 0:14:23  Lr: 0.001875  Loss: -0.7994  Acc@1: 62.5000 (64.0559)  Acc@5: 93.7500 (91.4672)  time: 0.3610  data: 0.0061  max mem: 2500
Train: Epoch[3/5]  [2150/4579]  eta: 0:14:20  Lr: 0.001875  Loss: 0.0497  Acc@1: 62.5000 (64.0487)  Acc@5: 87.5000 (91.4662)  time: 0.3625  data: 0.0062  max mem: 2500
Train: Epoch[3/5]  [2160/4579]  eta: 0:14:16  Lr: 0.001875  Loss: -0.3297  Acc@1: 62.5000 (64.0444)  Acc@5: 93.7500 (91.4739)  time: 0.3590  data: 0.0038  max mem: 2500
Train: Epoch[3/5]  [2170/4579]  eta: 0:14:13  Lr: 0.001875  Loss: -0.3715  Acc@1: 68.7500 (64.0719)  Acc@5: 93.7500 (91.4843)  time: 0.3539  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [2180/4579]  eta: 0:14:09  Lr: 0.001875  Loss: -0.1846  Acc@1: 62.5000 (64.0589)  Acc@5: 93.7500 (91.4747)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2190/4579]  eta: 0:14:06  Lr: 0.001875  Loss: -0.4541  Acc@1: 62.5000 (64.0689)  Acc@5: 87.5000 (91.4765)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2200/4579]  eta: 0:14:02  Lr: 0.001875  Loss: -0.0457  Acc@1: 62.5000 (64.0675)  Acc@5: 87.5000 (91.4669)  time: 0.3497  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2210/4579]  eta: 0:13:59  Lr: 0.001875  Loss: -0.5491  Acc@1: 62.5000 (64.0858)  Acc@5: 93.7500 (91.4744)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2220/4579]  eta: 0:13:55  Lr: 0.001875  Loss: -0.1938  Acc@1: 68.7500 (64.1124)  Acc@5: 93.7500 (91.4819)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2230/4579]  eta: 0:13:51  Lr: 0.001875  Loss: -0.4351  Acc@1: 62.5000 (64.0996)  Acc@5: 93.7500 (91.4920)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2240/4579]  eta: 0:13:48  Lr: 0.001875  Loss: 0.4774  Acc@1: 62.5000 (64.1008)  Acc@5: 93.7500 (91.4965)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2250/4579]  eta: 0:13:44  Lr: 0.001875  Loss: -0.0142  Acc@1: 62.5000 (64.1021)  Acc@5: 93.7500 (91.4982)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2260/4579]  eta: 0:13:41  Lr: 0.001875  Loss: -0.5815  Acc@1: 62.5000 (64.1005)  Acc@5: 93.7500 (91.5082)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2270/4579]  eta: 0:13:37  Lr: 0.001875  Loss: -0.0040  Acc@1: 62.5000 (64.0742)  Acc@5: 93.7500 (91.5015)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2280/4579]  eta: 0:13:34  Lr: 0.001875  Loss: -0.0052  Acc@1: 62.5000 (64.0700)  Acc@5: 87.5000 (91.4950)  time: 0.3557  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [2290/4579]  eta: 0:13:30  Lr: 0.001875  Loss: 0.0073  Acc@1: 62.5000 (64.0659)  Acc@5: 93.7500 (91.4993)  time: 0.3572  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [2300/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.6547  Acc@1: 68.7500 (64.0781)  Acc@5: 93.7500 (91.4955)  time: 0.3569  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2310/4579]  eta: 0:13:23  Lr: 0.001875  Loss: -0.8434  Acc@1: 68.7500 (64.0821)  Acc@5: 93.7500 (91.4972)  time: 0.3588  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2320/4579]  eta: 0:13:19  Lr: 0.001875  Loss: -0.2331  Acc@1: 62.5000 (64.0753)  Acc@5: 93.7500 (91.5096)  time: 0.3563  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2330/4579]  eta: 0:13:16  Lr: 0.001875  Loss: -0.2732  Acc@1: 62.5000 (64.0632)  Acc@5: 87.5000 (91.5058)  time: 0.3549  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2340/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.4373  Acc@1: 62.5000 (64.0779)  Acc@5: 87.5000 (91.4833)  time: 0.3547  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2350/4579]  eta: 0:13:09  Lr: 0.001875  Loss: 0.3240  Acc@1: 68.7500 (64.0977)  Acc@5: 87.5000 (91.4903)  time: 0.3539  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2360/4579]  eta: 0:13:05  Lr: 0.001875  Loss: 0.4844  Acc@1: 68.7500 (64.1068)  Acc@5: 93.7500 (91.4787)  time: 0.3524  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2370/4579]  eta: 0:13:02  Lr: 0.001875  Loss: -0.2995  Acc@1: 68.7500 (64.1370)  Acc@5: 93.7500 (91.4804)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2380/4579]  eta: 0:12:58  Lr: 0.001875  Loss: 0.0696  Acc@1: 62.5000 (64.1091)  Acc@5: 93.7500 (91.4742)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2390/4579]  eta: 0:12:55  Lr: 0.001875  Loss: -0.3451  Acc@1: 56.2500 (64.0893)  Acc@5: 87.5000 (91.4732)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2400/4579]  eta: 0:12:51  Lr: 0.001875  Loss: -0.2526  Acc@1: 62.5000 (64.0983)  Acc@5: 93.7500 (91.4671)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2410/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.0962  Acc@1: 62.5000 (64.0787)  Acc@5: 93.7500 (91.4688)  time: 0.3504  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2420/4579]  eta: 0:12:44  Lr: 0.001875  Loss: 0.0909  Acc@1: 62.5000 (64.0644)  Acc@5: 93.7500 (91.4653)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2430/4579]  eta: 0:12:40  Lr: 0.001875  Loss: -0.1528  Acc@1: 62.5000 (64.0760)  Acc@5: 93.7500 (91.4670)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2440/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.0229  Acc@1: 62.5000 (64.0926)  Acc@5: 93.7500 (91.4712)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2450/4579]  eta: 0:12:33  Lr: 0.001875  Loss: 0.0144  Acc@1: 62.5000 (64.1039)  Acc@5: 93.7500 (91.4729)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2460/4579]  eta: 0:12:29  Lr: 0.001875  Loss: -0.4439  Acc@1: 62.5000 (64.1025)  Acc@5: 93.7500 (91.4720)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2470/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.1065  Acc@1: 62.5000 (64.0935)  Acc@5: 93.7500 (91.4736)  time: 0.3560  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2480/4579]  eta: 0:12:22  Lr: 0.001875  Loss: 0.0608  Acc@1: 62.5000 (64.0971)  Acc@5: 87.5000 (91.4601)  time: 0.3563  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2490/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.3004  Acc@1: 62.5000 (64.0957)  Acc@5: 87.5000 (91.4517)  time: 0.3529  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2500/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 0.2557  Acc@1: 68.7500 (64.0994)  Acc@5: 93.7500 (91.4434)  time: 0.3556  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2510/4579]  eta: 0:12:12  Lr: 0.001875  Loss: 0.0836  Acc@1: 62.5000 (64.0805)  Acc@5: 93.7500 (91.4501)  time: 0.3621  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2520/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 0.1138  Acc@1: 62.5000 (64.0916)  Acc@5: 93.7500 (91.4667)  time: 0.3621  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [2530/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.3077  Acc@1: 68.7500 (64.1026)  Acc@5: 93.7500 (91.4782)  time: 0.3630  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2540/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 0.6868  Acc@1: 68.7500 (64.1111)  Acc@5: 93.7500 (91.4797)  time: 0.3590  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2550/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.2190  Acc@1: 62.5000 (64.1023)  Acc@5: 93.7500 (91.4788)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2560/4579]  eta: 0:11:55  Lr: 0.001875  Loss: -0.2475  Acc@1: 62.5000 (64.1034)  Acc@5: 93.7500 (91.4682)  time: 0.3670  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2570/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.2492  Acc@1: 68.7500 (64.1287)  Acc@5: 93.7500 (91.4843)  time: 0.5653  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2580/4579]  eta: 0:11:53  Lr: 0.001875  Loss: -0.2607  Acc@1: 62.5000 (64.1152)  Acc@5: 87.5000 (91.4641)  time: 0.7253  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2590/4579]  eta: 0:11:53  Lr: 0.001875  Loss: -0.1472  Acc@1: 62.5000 (64.1186)  Acc@5: 87.5000 (91.4729)  time: 0.7260  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2600/4579]  eta: 0:11:50  Lr: 0.001875  Loss: -0.9305  Acc@1: 68.7500 (64.1652)  Acc@5: 93.7500 (91.4768)  time: 0.5883  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2610/4579]  eta: 0:11:47  Lr: 0.001875  Loss: 0.3027  Acc@1: 68.7500 (64.1541)  Acc@5: 93.7500 (91.4760)  time: 0.4662  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2620/4579]  eta: 0:11:46  Lr: 0.001875  Loss: -0.5528  Acc@1: 62.5000 (64.1740)  Acc@5: 93.7500 (91.4703)  time: 0.6259  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2630/4579]  eta: 0:11:45  Lr: 0.001875  Loss: -0.4270  Acc@1: 68.7500 (64.1819)  Acc@5: 93.7500 (91.4671)  time: 0.7182  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2640/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.4213  Acc@1: 62.5000 (64.1542)  Acc@5: 93.7500 (91.4521)  time: 0.6968  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2650/4579]  eta: 0:11:43  Lr: 0.001875  Loss: 0.3182  Acc@1: 62.5000 (64.1715)  Acc@5: 87.5000 (91.4419)  time: 0.7222  data: 0.0044  max mem: 2500
Train: Epoch[3/5]  [2660/4579]  eta: 0:11:40  Lr: 0.001875  Loss: -0.3807  Acc@1: 68.7500 (64.1629)  Acc@5: 93.7500 (91.4365)  time: 0.5940  data: 0.0055  max mem: 2500
Train: Epoch[3/5]  [2670/4579]  eta: 0:11:38  Lr: 0.001875  Loss: -0.6535  Acc@1: 68.7500 (64.1848)  Acc@5: 93.7500 (91.4498)  time: 0.4985  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [2680/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.0312  Acc@1: 68.7500 (64.1831)  Acc@5: 93.7500 (91.4491)  time: 0.6468  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2690/4579]  eta: 0:11:36  Lr: 0.001875  Loss: -0.7305  Acc@1: 68.7500 (64.1862)  Acc@5: 93.7500 (91.4600)  time: 0.7213  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2700/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.3774  Acc@1: 68.7500 (64.2100)  Acc@5: 93.7500 (91.4592)  time: 0.6914  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2710/4579]  eta: 0:11:33  Lr: 0.001875  Loss: -0.5451  Acc@1: 68.7500 (64.2060)  Acc@5: 93.7500 (91.4607)  time: 0.7142  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2720/4579]  eta: 0:11:31  Lr: 0.001875  Loss: -0.1743  Acc@1: 62.5000 (64.2020)  Acc@5: 93.7500 (91.4622)  time: 0.7195  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2730/4579]  eta: 0:11:29  Lr: 0.001875  Loss: -0.0788  Acc@1: 62.5000 (64.1981)  Acc@5: 93.7500 (91.4660)  time: 0.6274  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2740/4579]  eta: 0:11:25  Lr: 0.001875  Loss: -0.4692  Acc@1: 62.5000 (64.1873)  Acc@5: 87.5000 (91.4584)  time: 0.4664  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2750/4579]  eta: 0:11:24  Lr: 0.001875  Loss: 0.1534  Acc@1: 62.5000 (64.1835)  Acc@5: 87.5000 (91.4440)  time: 0.5609  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2760/4579]  eta: 0:11:22  Lr: 0.001875  Loss: 0.5712  Acc@1: 62.5000 (64.1661)  Acc@5: 87.5000 (91.4456)  time: 0.7224  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2770/4579]  eta: 0:11:21  Lr: 0.001875  Loss: 0.0265  Acc@1: 62.5000 (64.1736)  Acc@5: 87.5000 (91.4359)  time: 0.7131  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [2780/4579]  eta: 0:11:18  Lr: 0.001875  Loss: 0.0032  Acc@1: 62.5000 (64.1653)  Acc@5: 87.5000 (91.4374)  time: 0.6052  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2790/4579]  eta: 0:11:14  Lr: 0.001875  Loss: 0.0383  Acc@1: 62.5000 (64.1638)  Acc@5: 87.5000 (91.4233)  time: 0.4148  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2800/4579]  eta: 0:11:10  Lr: 0.001875  Loss: -0.1464  Acc@1: 62.5000 (64.1735)  Acc@5: 87.5000 (91.4227)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2810/4579]  eta: 0:11:06  Lr: 0.001875  Loss: -0.4280  Acc@1: 68.7500 (64.1876)  Acc@5: 93.7500 (91.4332)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2820/4579]  eta: 0:11:02  Lr: 0.001875  Loss: -0.1725  Acc@1: 68.7500 (64.1772)  Acc@5: 93.7500 (91.4259)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2830/4579]  eta: 0:10:58  Lr: 0.001875  Loss: 0.3821  Acc@1: 68.7500 (64.1779)  Acc@5: 87.5000 (91.4231)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2840/4579]  eta: 0:10:54  Lr: 0.001875  Loss: -0.7545  Acc@1: 68.7500 (64.1873)  Acc@5: 93.7500 (91.4181)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2850/4579]  eta: 0:10:50  Lr: 0.001875  Loss: -0.4309  Acc@1: 68.7500 (64.2033)  Acc@5: 93.7500 (91.4153)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2860/4579]  eta: 0:10:46  Lr: 0.001875  Loss: -0.4830  Acc@1: 68.7500 (64.2214)  Acc@5: 93.7500 (91.4278)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2870/4579]  eta: 0:10:42  Lr: 0.001875  Loss: -0.1436  Acc@1: 68.7500 (64.2285)  Acc@5: 93.7500 (91.4316)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2880/4579]  eta: 0:10:39  Lr: 0.001875  Loss: -0.5532  Acc@1: 68.7500 (64.2355)  Acc@5: 87.5000 (91.4201)  time: 0.3601  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2890/4579]  eta: 0:10:35  Lr: 0.001875  Loss: -0.2401  Acc@1: 68.7500 (64.2468)  Acc@5: 87.5000 (91.4108)  time: 0.3605  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2900/4579]  eta: 0:10:31  Lr: 0.001875  Loss: -0.0167  Acc@1: 68.7500 (64.2537)  Acc@5: 93.7500 (91.4146)  time: 0.3536  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [2910/4579]  eta: 0:10:27  Lr: 0.001875  Loss: -0.1838  Acc@1: 62.5000 (64.2412)  Acc@5: 93.7500 (91.4119)  time: 0.3599  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [2920/4579]  eta: 0:10:24  Lr: 0.001875  Loss: 0.0648  Acc@1: 56.2500 (64.2310)  Acc@5: 93.7500 (91.4178)  time: 0.4629  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2930/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.3460  Acc@1: 56.2500 (64.2208)  Acc@5: 93.7500 (91.4150)  time: 0.6510  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2940/4579]  eta: 0:10:21  Lr: 0.001875  Loss: -0.1351  Acc@1: 68.7500 (64.2299)  Acc@5: 87.5000 (91.4124)  time: 0.7264  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2950/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.2936  Acc@1: 68.7500 (64.2494)  Acc@5: 93.7500 (91.4224)  time: 0.6763  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2960/4579]  eta: 0:10:15  Lr: 0.001875  Loss: -0.0968  Acc@1: 62.5000 (64.2541)  Acc@5: 93.7500 (91.4324)  time: 0.5184  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2970/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.0048  Acc@1: 62.5000 (64.2545)  Acc@5: 93.7500 (91.4318)  time: 0.5726  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2980/4579]  eta: 0:10:11  Lr: 0.001875  Loss: 0.1778  Acc@1: 62.5000 (64.2507)  Acc@5: 93.7500 (91.4374)  time: 0.7293  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2990/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.0300  Acc@1: 62.5000 (64.2511)  Acc@5: 93.7500 (91.4368)  time: 0.7229  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3000/4579]  eta: 0:10:06  Lr: 0.001875  Loss: 0.6730  Acc@1: 62.5000 (64.2661)  Acc@5: 93.7500 (91.4404)  time: 0.7012  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3010/4579]  eta: 0:10:04  Lr: 0.001875  Loss: 0.5260  Acc@1: 68.7500 (64.2789)  Acc@5: 93.7500 (91.4335)  time: 0.6179  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3020/4579]  eta: 0:10:00  Lr: 0.001875  Loss: -0.9129  Acc@1: 68.7500 (64.3020)  Acc@5: 93.7500 (91.4474)  time: 0.4689  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3030/4579]  eta: 0:09:58  Lr: 0.001875  Loss: 0.0662  Acc@1: 62.5000 (64.2919)  Acc@5: 93.7500 (91.4323)  time: 0.5573  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3040/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.3819  Acc@1: 62.5000 (64.2963)  Acc@5: 87.5000 (91.4296)  time: 0.7235  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3050/4579]  eta: 0:09:53  Lr: 0.001875  Loss: -0.1580  Acc@1: 68.7500 (64.2843)  Acc@5: 93.7500 (91.4434)  time: 0.7238  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3060/4579]  eta: 0:09:51  Lr: 0.001875  Loss: -0.3597  Acc@1: 62.5000 (64.2723)  Acc@5: 93.7500 (91.4407)  time: 0.7226  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3070/4579]  eta: 0:09:49  Lr: 0.001875  Loss: 0.3751  Acc@1: 62.5000 (64.2808)  Acc@5: 93.7500 (91.4340)  time: 0.7040  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3080/4579]  eta: 0:09:46  Lr: 0.001875  Loss: -0.3404  Acc@1: 75.0000 (64.3237)  Acc@5: 93.7500 (91.4435)  time: 0.6998  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3090/4579]  eta: 0:09:42  Lr: 0.001875  Loss: -0.9150  Acc@1: 75.0000 (64.3319)  Acc@5: 93.7500 (91.4409)  time: 0.5204  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3100/4579]  eta: 0:09:39  Lr: 0.001875  Loss: -0.3218  Acc@1: 62.5000 (64.3159)  Acc@5: 93.7500 (91.4403)  time: 0.4427  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3110/4579]  eta: 0:09:37  Lr: 0.001875  Loss: -0.6247  Acc@1: 62.5000 (64.3302)  Acc@5: 93.7500 (91.4577)  time: 0.6371  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3120/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.8009  Acc@1: 62.5000 (64.3203)  Acc@5: 93.7500 (91.4571)  time: 0.6855  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [3130/4579]  eta: 0:09:31  Lr: 0.001875  Loss: 0.1608  Acc@1: 62.5000 (64.3145)  Acc@5: 93.7500 (91.4664)  time: 0.6880  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3140/4579]  eta: 0:09:29  Lr: 0.001875  Loss: -0.7407  Acc@1: 68.7500 (64.3247)  Acc@5: 93.7500 (91.4637)  time: 0.7153  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3150/4579]  eta: 0:09:26  Lr: 0.001875  Loss: -0.4944  Acc@1: 68.7500 (64.3288)  Acc@5: 93.7500 (91.4650)  time: 0.6946  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3160/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.0885  Acc@1: 68.7500 (64.3250)  Acc@5: 93.7500 (91.4663)  time: 0.6947  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3170/4579]  eta: 0:09:21  Lr: 0.001875  Loss: -0.6351  Acc@1: 62.5000 (64.3192)  Acc@5: 93.7500 (91.4637)  time: 0.7144  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3180/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.3844  Acc@1: 62.5000 (64.3273)  Acc@5: 93.7500 (91.4532)  time: 0.5639  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3190/4579]  eta: 0:09:14  Lr: 0.001875  Loss: -0.8423  Acc@1: 68.7500 (64.3490)  Acc@5: 93.7500 (91.4564)  time: 0.4614  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3200/4579]  eta: 0:09:10  Lr: 0.001875  Loss: -0.6579  Acc@1: 68.7500 (64.3451)  Acc@5: 93.7500 (91.4636)  time: 0.4954  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3210/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.2115  Acc@1: 62.5000 (64.3394)  Acc@5: 93.7500 (91.4629)  time: 0.4079  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [3220/4579]  eta: 0:09:02  Lr: 0.001875  Loss: -0.6262  Acc@1: 62.5000 (64.3492)  Acc@5: 93.7500 (91.4700)  time: 0.3576  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [3230/4579]  eta: 0:08:58  Lr: 0.001875  Loss: -0.1821  Acc@1: 75.0000 (64.3589)  Acc@5: 93.7500 (91.4713)  time: 0.3587  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3240/4579]  eta: 0:08:53  Lr: 0.001875  Loss: -0.0663  Acc@1: 68.7500 (64.3706)  Acc@5: 93.7500 (91.4725)  time: 0.3636  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3250/4579]  eta: 0:08:49  Lr: 0.001875  Loss: -0.2484  Acc@1: 68.7500 (64.3860)  Acc@5: 93.7500 (91.4815)  time: 0.3592  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3260/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.4394  Acc@1: 62.5000 (64.3859)  Acc@5: 93.7500 (91.4769)  time: 0.3555  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3270/4579]  eta: 0:08:41  Lr: 0.001875  Loss: -0.1076  Acc@1: 62.5000 (64.3935)  Acc@5: 93.7500 (91.4801)  time: 0.3567  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3280/4579]  eta: 0:08:37  Lr: 0.001875  Loss: -0.3386  Acc@1: 68.7500 (64.3954)  Acc@5: 93.7500 (91.4813)  time: 0.3560  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3290/4579]  eta: 0:08:33  Lr: 0.001875  Loss: 0.0268  Acc@1: 68.7500 (64.4048)  Acc@5: 93.7500 (91.4730)  time: 0.3570  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3300/4579]  eta: 0:08:28  Lr: 0.001875  Loss: -0.3459  Acc@1: 68.7500 (64.4237)  Acc@5: 93.7500 (91.4817)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3310/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.5052  Acc@1: 68.7500 (64.4027)  Acc@5: 93.7500 (91.4773)  time: 0.3551  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3320/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.3068  Acc@1: 62.5000 (64.4045)  Acc@5: 93.7500 (91.4822)  time: 0.3579  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3330/4579]  eta: 0:08:16  Lr: 0.001875  Loss: 0.0230  Acc@1: 68.7500 (64.4026)  Acc@5: 87.5000 (91.4647)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3340/4579]  eta: 0:08:12  Lr: 0.001875  Loss: -0.1697  Acc@1: 68.7500 (64.4119)  Acc@5: 87.5000 (91.4640)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3350/4579]  eta: 0:08:08  Lr: 0.001875  Loss: -0.2046  Acc@1: 68.7500 (64.4080)  Acc@5: 93.7500 (91.4708)  time: 0.4466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3360/4579]  eta: 0:08:06  Lr: 0.001875  Loss: 0.2627  Acc@1: 68.7500 (64.3949)  Acc@5: 87.5000 (91.4609)  time: 0.6453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3370/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.2555  Acc@1: 68.7500 (64.4208)  Acc@5: 87.5000 (91.4621)  time: 0.7270  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [3380/4579]  eta: 0:08:00  Lr: 0.001875  Loss: 0.1220  Acc@1: 62.5000 (64.4077)  Acc@5: 93.7500 (91.4689)  time: 0.6777  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [3390/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.1424  Acc@1: 62.5000 (64.4132)  Acc@5: 93.7500 (91.4738)  time: 0.5033  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3400/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.1520  Acc@1: 68.7500 (64.4057)  Acc@5: 93.7500 (91.4786)  time: 0.4984  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3410/4579]  eta: 0:07:50  Lr: 0.001875  Loss: -0.1717  Acc@1: 68.7500 (64.4111)  Acc@5: 93.7500 (91.4706)  time: 0.6955  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [3420/4579]  eta: 0:07:47  Lr: 0.001875  Loss: -0.1003  Acc@1: 68.7500 (64.4165)  Acc@5: 87.5000 (91.4773)  time: 0.7162  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [3430/4579]  eta: 0:07:43  Lr: 0.001875  Loss: -0.5252  Acc@1: 68.7500 (64.4236)  Acc@5: 93.7500 (91.4803)  time: 0.6917  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3440/4579]  eta: 0:07:40  Lr: 0.001875  Loss: 0.2952  Acc@1: 68.7500 (64.4308)  Acc@5: 87.5000 (91.4760)  time: 0.7033  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3450/4579]  eta: 0:07:36  Lr: 0.001875  Loss: -0.2661  Acc@1: 68.7500 (64.4415)  Acc@5: 93.7500 (91.4898)  time: 0.5275  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3460/4579]  eta: 0:07:33  Lr: 0.001875  Loss: -0.2819  Acc@1: 68.7500 (64.4503)  Acc@5: 93.7500 (91.4891)  time: 0.4757  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3470/4579]  eta: 0:07:30  Lr: 0.001875  Loss: -0.0390  Acc@1: 62.5000 (64.4339)  Acc@5: 87.5000 (91.4848)  time: 0.6718  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3480/4579]  eta: 0:07:27  Lr: 0.001875  Loss: -0.3883  Acc@1: 62.5000 (64.4463)  Acc@5: 93.7500 (91.4877)  time: 0.7241  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3490/4579]  eta: 0:07:23  Lr: 0.001875  Loss: -0.7376  Acc@1: 62.5000 (64.4532)  Acc@5: 93.7500 (91.4906)  time: 0.6900  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3500/4579]  eta: 0:07:20  Lr: 0.001875  Loss: 0.1737  Acc@1: 62.5000 (64.4352)  Acc@5: 87.5000 (91.4649)  time: 0.7106  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3510/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.2139  Acc@1: 62.5000 (64.4564)  Acc@5: 87.5000 (91.4732)  time: 0.7044  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3520/4579]  eta: 0:07:13  Lr: 0.001875  Loss: -0.3132  Acc@1: 68.7500 (64.4703)  Acc@5: 93.7500 (91.4779)  time: 0.6000  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [3530/4579]  eta: 0:07:09  Lr: 0.001875  Loss: -0.3941  Acc@1: 62.5000 (64.4647)  Acc@5: 93.7500 (91.4702)  time: 0.4762  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [3540/4579]  eta: 0:07:06  Lr: 0.001875  Loss: -0.1812  Acc@1: 68.7500 (64.4627)  Acc@5: 93.7500 (91.4784)  time: 0.5795  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3550/4579]  eta: 0:07:03  Lr: 0.001875  Loss: 0.1648  Acc@1: 68.7500 (64.4537)  Acc@5: 93.7500 (91.4795)  time: 0.6606  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3560/4579]  eta: 0:06:58  Lr: 0.001875  Loss: -0.1913  Acc@1: 62.5000 (64.4605)  Acc@5: 93.7500 (91.4841)  time: 0.4640  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3570/4579]  eta: 0:06:54  Lr: 0.001875  Loss: -0.0370  Acc@1: 62.5000 (64.4515)  Acc@5: 87.5000 (91.4730)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3580/4579]  eta: 0:06:50  Lr: 0.001875  Loss: -0.1633  Acc@1: 62.5000 (64.4565)  Acc@5: 87.5000 (91.4811)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3590/4579]  eta: 0:06:45  Lr: 0.001875  Loss: 0.0628  Acc@1: 68.7500 (64.4667)  Acc@5: 93.7500 (91.4891)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3600/4579]  eta: 0:06:41  Lr: 0.001875  Loss: -0.1412  Acc@1: 68.7500 (64.4804)  Acc@5: 93.7500 (91.4833)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3610/4579]  eta: 0:06:37  Lr: 0.001875  Loss: 0.1525  Acc@1: 68.7500 (64.4870)  Acc@5: 87.5000 (91.4826)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3620/4579]  eta: 0:06:33  Lr: 0.001875  Loss: 0.0734  Acc@1: 62.5000 (64.4936)  Acc@5: 87.5000 (91.4906)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3630/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.6103  Acc@1: 62.5000 (64.5036)  Acc@5: 93.7500 (91.4899)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3640/4579]  eta: 0:06:24  Lr: 0.001875  Loss: 0.8043  Acc@1: 68.7500 (64.5204)  Acc@5: 93.7500 (91.4944)  time: 0.3533  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3650/4579]  eta: 0:06:20  Lr: 0.001875  Loss: -0.4617  Acc@1: 68.7500 (64.5097)  Acc@5: 93.7500 (91.4955)  time: 0.3564  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3660/4579]  eta: 0:06:16  Lr: 0.001875  Loss: -0.5676  Acc@1: 62.5000 (64.5145)  Acc@5: 93.7500 (91.4931)  time: 0.3596  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3670/4579]  eta: 0:06:12  Lr: 0.001875  Loss: 0.5012  Acc@1: 62.5000 (64.4920)  Acc@5: 87.5000 (91.4805)  time: 0.3604  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [3680/4579]  eta: 0:06:07  Lr: 0.001875  Loss: 0.0183  Acc@1: 62.5000 (64.5001)  Acc@5: 87.5000 (91.4867)  time: 0.3604  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [3690/4579]  eta: 0:06:03  Lr: 0.001875  Loss: -0.2703  Acc@1: 68.7500 (64.5100)  Acc@5: 93.7500 (91.4962)  time: 0.3575  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:59  Lr: 0.001875  Loss: 0.1058  Acc@1: 62.5000 (64.5062)  Acc@5: 93.7500 (91.5006)  time: 0.3555  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3710/4579]  eta: 0:05:55  Lr: 0.001875  Loss: -0.7843  Acc@1: 56.2500 (64.4890)  Acc@5: 93.7500 (91.5033)  time: 0.3558  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3720/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.3811  Acc@1: 62.5000 (64.4803)  Acc@5: 93.7500 (91.4993)  time: 0.3548  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3730/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.6268  Acc@1: 62.5000 (64.4834)  Acc@5: 93.7500 (91.5070)  time: 0.3568  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3740/4579]  eta: 0:05:42  Lr: 0.001875  Loss: 0.4352  Acc@1: 62.5000 (64.4580)  Acc@5: 93.7500 (91.5013)  time: 0.3605  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3750/4579]  eta: 0:05:38  Lr: 0.001875  Loss: -0.8582  Acc@1: 62.5000 (64.4728)  Acc@5: 93.7500 (91.5073)  time: 0.3565  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3760/4579]  eta: 0:05:34  Lr: 0.001875  Loss: -0.5090  Acc@1: 62.5000 (64.4676)  Acc@5: 93.7500 (91.5132)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3770/4579]  eta: 0:05:30  Lr: 0.001875  Loss: -0.0842  Acc@1: 62.5000 (64.4773)  Acc@5: 93.7500 (91.5241)  time: 0.4288  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3780/4579]  eta: 0:05:26  Lr: 0.001875  Loss: -0.0456  Acc@1: 62.5000 (64.4671)  Acc@5: 93.7500 (91.5201)  time: 0.6282  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3790/4579]  eta: 0:05:23  Lr: 0.001875  Loss: -0.0804  Acc@1: 62.5000 (64.4718)  Acc@5: 87.5000 (91.5194)  time: 0.7237  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3800/4579]  eta: 0:05:19  Lr: 0.001875  Loss: -0.5812  Acc@1: 68.7500 (64.4781)  Acc@5: 93.7500 (91.5285)  time: 0.6981  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3810/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.3682  Acc@1: 68.7500 (64.4860)  Acc@5: 93.7500 (91.5327)  time: 0.5263  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3820/4579]  eta: 0:05:12  Lr: 0.001875  Loss: 0.2919  Acc@1: 68.7500 (64.4825)  Acc@5: 93.7500 (91.5287)  time: 0.4900  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3830/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.5570  Acc@1: 68.7500 (64.4903)  Acc@5: 93.7500 (91.5459)  time: 0.6918  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3840/4579]  eta: 0:05:05  Lr: 0.001875  Loss: -0.1093  Acc@1: 62.5000 (64.4705)  Acc@5: 93.7500 (91.5419)  time: 0.7287  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3850/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.2773  Acc@1: 56.2500 (64.4654)  Acc@5: 87.5000 (91.5428)  time: 0.6937  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:57  Lr: 0.001875  Loss: 0.2584  Acc@1: 62.5000 (64.4716)  Acc@5: 93.7500 (91.5420)  time: 0.6987  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:53  Lr: 0.001875  Loss: -0.1320  Acc@1: 68.7500 (64.4698)  Acc@5: 93.7500 (91.5364)  time: 0.5298  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:49  Lr: 0.001875  Loss: -0.3327  Acc@1: 62.5000 (64.4711)  Acc@5: 93.7500 (91.5405)  time: 0.5075  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3890/4579]  eta: 0:04:46  Lr: 0.001875  Loss: -0.8325  Acc@1: 62.5000 (64.4821)  Acc@5: 93.7500 (91.5382)  time: 0.7050  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3900/4579]  eta: 0:04:42  Lr: 0.001875  Loss: -0.6270  Acc@1: 68.7500 (64.5027)  Acc@5: 93.7500 (91.5422)  time: 0.7259  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3910/4579]  eta: 0:04:38  Lr: 0.001875  Loss: 0.4718  Acc@1: 68.7500 (64.5040)  Acc@5: 93.7500 (91.5479)  time: 0.6927  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3920/4579]  eta: 0:04:35  Lr: 0.001875  Loss: -0.5438  Acc@1: 68.7500 (64.4989)  Acc@5: 93.7500 (91.5487)  time: 0.6851  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3930/4579]  eta: 0:04:31  Lr: 0.001875  Loss: 0.1365  Acc@1: 68.7500 (64.5033)  Acc@5: 93.7500 (91.5511)  time: 0.7215  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3940/4579]  eta: 0:04:27  Lr: 0.001875  Loss: -0.3176  Acc@1: 62.5000 (64.5014)  Acc@5: 93.7500 (91.5520)  time: 0.5953  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [3950/4579]  eta: 0:04:23  Lr: 0.001875  Loss: -0.5152  Acc@1: 68.7500 (64.5201)  Acc@5: 93.7500 (91.5544)  time: 0.4528  data: 0.0037  max mem: 2500
Train: Epoch[3/5]  [3960/4579]  eta: 0:04:19  Lr: 0.001875  Loss: 0.1881  Acc@1: 68.7500 (64.5150)  Acc@5: 93.7500 (91.5520)  time: 0.6029  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3970/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 0.0207  Acc@1: 62.5000 (64.5209)  Acc@5: 93.7500 (91.5560)  time: 0.6086  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3980/4579]  eta: 0:04:11  Lr: 0.001875  Loss: -0.2981  Acc@1: 68.7500 (64.5221)  Acc@5: 87.5000 (91.5489)  time: 0.4141  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3990/4579]  eta: 0:04:06  Lr: 0.001875  Loss: -0.2239  Acc@1: 68.7500 (64.5170)  Acc@5: 87.5000 (91.5403)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4000/4579]  eta: 0:04:02  Lr: 0.001875  Loss: 0.3909  Acc@1: 68.7500 (64.5261)  Acc@5: 87.5000 (91.5318)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.0123  Acc@1: 68.7500 (64.5226)  Acc@5: 93.7500 (91.5327)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.1097  Acc@1: 62.5000 (64.5424)  Acc@5: 93.7500 (91.5366)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:49  Lr: 0.001875  Loss: 0.3017  Acc@1: 62.5000 (64.5358)  Acc@5: 93.7500 (91.5390)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:45  Lr: 0.001875  Loss: -0.1679  Acc@1: 62.5000 (64.5385)  Acc@5: 93.7500 (91.5460)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:41  Lr: 0.001875  Loss: 0.0092  Acc@1: 62.5000 (64.5442)  Acc@5: 93.7500 (91.5530)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4060/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.2553  Acc@1: 62.5000 (64.5377)  Acc@5: 93.7500 (91.5492)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4070/4579]  eta: 0:03:32  Lr: 0.001875  Loss: 0.2240  Acc@1: 56.2500 (64.5127)  Acc@5: 93.7500 (91.5531)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4080/4579]  eta: 0:03:28  Lr: 0.001875  Loss: -0.0818  Acc@1: 56.2500 (64.5108)  Acc@5: 93.7500 (91.5538)  time: 0.3594  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [4090/4579]  eta: 0:03:24  Lr: 0.001875  Loss: -0.1531  Acc@1: 68.7500 (64.5212)  Acc@5: 93.7500 (91.5516)  time: 0.3692  data: 0.0042  max mem: 2500
Train: Epoch[3/5]  [4100/4579]  eta: 0:03:20  Lr: 0.001875  Loss: -0.1814  Acc@1: 68.7500 (64.5254)  Acc@5: 93.7500 (91.5539)  time: 0.3636  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4110/4579]  eta: 0:03:15  Lr: 0.001875  Loss: -0.0008  Acc@1: 68.7500 (64.5327)  Acc@5: 93.7500 (91.5532)  time: 0.3569  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4120/4579]  eta: 0:03:11  Lr: 0.001875  Loss: -0.5428  Acc@1: 68.7500 (64.5444)  Acc@5: 93.7500 (91.5570)  time: 0.3580  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [4130/4579]  eta: 0:03:07  Lr: 0.001875  Loss: -0.4513  Acc@1: 62.5000 (64.5349)  Acc@5: 93.7500 (91.5562)  time: 0.3568  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4140/4579]  eta: 0:03:03  Lr: 0.001875  Loss: -0.0480  Acc@1: 62.5000 (64.5436)  Acc@5: 93.7500 (91.5585)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:58  Lr: 0.001875  Loss: -0.7603  Acc@1: 68.7500 (64.5567)  Acc@5: 93.7500 (91.5623)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.0832  Acc@1: 68.7500 (64.5713)  Acc@5: 93.7500 (91.5675)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:50  Lr: 0.001875  Loss: -0.1376  Acc@1: 68.7500 (64.5693)  Acc@5: 93.7500 (91.5638)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:46  Lr: 0.001875  Loss: -0.3061  Acc@1: 68.7500 (64.5779)  Acc@5: 87.5000 (91.5645)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:41  Lr: 0.001875  Loss: -0.5712  Acc@1: 68.7500 (64.5818)  Acc@5: 87.5000 (91.5608)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4113  Acc@1: 62.5000 (64.5843)  Acc@5: 87.5000 (91.5556)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1470  Acc@1: 62.5000 (64.5764)  Acc@5: 87.5000 (91.5534)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.0782  Acc@1: 62.5000 (64.5907)  Acc@5: 93.7500 (91.5601)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.4356  Acc@1: 68.7500 (64.5932)  Acc@5: 93.7500 (91.5638)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4240/4579]  eta: 0:02:20  Lr: 0.001875  Loss: 0.2003  Acc@1: 68.7500 (64.5971)  Acc@5: 93.7500 (91.5645)  time: 0.3583  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [4250/4579]  eta: 0:02:16  Lr: 0.001875  Loss: -0.1062  Acc@1: 68.7500 (64.5907)  Acc@5: 93.7500 (91.5711)  time: 0.3642  data: 0.0053  max mem: 2500
Train: Epoch[3/5]  [4260/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.5408  Acc@1: 62.5000 (64.5990)  Acc@5: 93.7500 (91.5718)  time: 0.3628  data: 0.0059  max mem: 2500
Train: Epoch[3/5]  [4270/4579]  eta: 0:02:08  Lr: 0.001875  Loss: 0.0669  Acc@1: 62.5000 (64.5999)  Acc@5: 93.7500 (91.5696)  time: 0.3638  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [4280/4579]  eta: 0:02:04  Lr: 0.001875  Loss: -0.0342  Acc@1: 62.5000 (64.5994)  Acc@5: 93.7500 (91.5659)  time: 0.3621  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6373  Acc@1: 62.5000 (64.6032)  Acc@5: 93.7500 (91.5667)  time: 0.3562  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4020  Acc@1: 68.7500 (64.6114)  Acc@5: 93.7500 (91.5804)  time: 0.3545  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:51  Lr: 0.001875  Loss: 0.1153  Acc@1: 62.5000 (64.6065)  Acc@5: 100.0000 (91.5884)  time: 0.3585  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:47  Lr: 0.001875  Loss: -0.2827  Acc@1: 62.5000 (64.6074)  Acc@5: 93.7500 (91.5876)  time: 0.3557  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:43  Lr: 0.001875  Loss: -0.1694  Acc@1: 62.5000 (64.5997)  Acc@5: 93.7500 (91.5868)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:38  Lr: 0.001875  Loss: -0.0278  Acc@1: 62.5000 (64.6064)  Acc@5: 93.7500 (91.5889)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.2489  Acc@1: 62.5000 (64.5929)  Acc@5: 93.7500 (91.5838)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.2876  Acc@1: 62.5000 (64.5953)  Acc@5: 93.7500 (91.5831)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:26  Lr: 0.001875  Loss: -0.4661  Acc@1: 62.5000 (64.5733)  Acc@5: 93.7500 (91.5823)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:22  Lr: 0.001875  Loss: -0.2597  Acc@1: 62.5000 (64.5743)  Acc@5: 87.5000 (91.5787)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:18  Lr: 0.001875  Loss: 0.0161  Acc@1: 62.5000 (64.5767)  Acc@5: 87.5000 (91.5751)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.2029  Acc@1: 62.5000 (64.5805)  Acc@5: 93.7500 (91.5729)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4410/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.6115  Acc@1: 62.5000 (64.5758)  Acc@5: 93.7500 (91.5736)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4420/4579]  eta: 0:01:05  Lr: 0.001875  Loss: -0.4881  Acc@1: 62.5000 (64.5668)  Acc@5: 93.7500 (91.5771)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4430/4579]  eta: 0:01:01  Lr: 0.001875  Loss: -0.3207  Acc@1: 62.5000 (64.5608)  Acc@5: 93.7500 (91.5665)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:57  Lr: 0.001875  Loss: -0.1658  Acc@1: 68.7500 (64.5716)  Acc@5: 93.7500 (91.5686)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:53  Lr: 0.001875  Loss: 0.3016  Acc@1: 68.7500 (64.5712)  Acc@5: 93.7500 (91.5679)  time: 0.3549  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:49  Lr: 0.001875  Loss: -0.3412  Acc@1: 62.5000 (64.5735)  Acc@5: 93.7500 (91.5672)  time: 0.3601  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:44  Lr: 0.001875  Loss: -0.4265  Acc@1: 68.7500 (64.5913)  Acc@5: 93.7500 (91.5763)  time: 0.3565  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7660  Acc@1: 68.7500 (64.5991)  Acc@5: 93.7500 (91.5769)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:36  Lr: 0.001875  Loss: -0.2776  Acc@1: 62.5000 (64.5903)  Acc@5: 93.7500 (91.5790)  time: 0.3525  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:32  Lr: 0.001875  Loss: -0.5425  Acc@1: 62.5000 (64.5870)  Acc@5: 93.7500 (91.5810)  time: 0.3538  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3086  Acc@1: 62.5000 (64.5838)  Acc@5: 93.7500 (91.5775)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8359  Acc@1: 62.5000 (64.5985)  Acc@5: 93.7500 (91.5810)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.3867  Acc@1: 68.7500 (64.6132)  Acc@5: 93.7500 (91.5871)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:16  Lr: 0.001875  Loss: -0.5831  Acc@1: 68.7500 (64.6320)  Acc@5: 93.7500 (91.5864)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1462  Acc@1: 68.7500 (64.6218)  Acc@5: 87.5000 (91.5815)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0543  Acc@1: 62.5000 (64.6212)  Acc@5: 87.5000 (91.5767)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5444  Acc@1: 62.5000 (64.6152)  Acc@5: 93.7500 (91.5814)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9506  Acc@1: 56.2500 (64.6123)  Acc@5: 93.7500 (91.5831)  time: 0.3402  data: 0.0007  max mem: 2500
Train: Epoch[3/5] Total time: 0:31:21 (0.4109 s / it)
{0: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.9506  Acc@1: 56.2500 (64.6123)  Acc@5: 93.7500 (91.5831)
Train: Epoch[4/5]  [   0/4579]  eta: 0:49:10  Lr: 0.001875  Loss: -0.3224  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.6444  data: 0.2989  max mem: 2500
Train: Epoch[4/5]  [  10/4579]  eta: 0:28:28  Lr: 0.001875  Loss: 0.0391  Acc@1: 68.7500 (64.7727)  Acc@5: 93.7500 (92.0455)  time: 0.3738  data: 0.0275  max mem: 2500
Train: Epoch[4/5]  [  20/4579]  eta: 0:27:37  Lr: 0.001875  Loss: -0.5764  Acc@1: 68.7500 (66.0714)  Acc@5: 93.7500 (92.5595)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  30/4579]  eta: 0:27:22  Lr: 0.001875  Loss: 0.0205  Acc@1: 68.7500 (66.7339)  Acc@5: 87.5000 (91.7339)  time: 0.3542  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [  40/4579]  eta: 0:27:14  Lr: 0.001875  Loss: 0.2101  Acc@1: 68.7500 (65.8537)  Acc@5: 87.5000 (91.1585)  time: 0.3566  data: 0.0035  max mem: 2500
Train: Epoch[4/5]  [  50/4579]  eta: 0:27:07  Lr: 0.001875  Loss: -0.6284  Acc@1: 68.7500 (66.7892)  Acc@5: 93.7500 (91.9118)  time: 0.3568  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [  60/4579]  eta: 0:27:09  Lr: 0.001875  Loss: 0.0631  Acc@1: 68.7500 (66.5984)  Acc@5: 93.7500 (91.5984)  time: 0.3619  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [  70/4579]  eta: 0:27:09  Lr: 0.001875  Loss: -0.5483  Acc@1: 62.5000 (66.2852)  Acc@5: 87.5000 (91.3732)  time: 0.3664  data: 0.0032  max mem: 2500
Train: Epoch[4/5]  [  80/4579]  eta: 0:27:05  Lr: 0.001875  Loss: 0.4250  Acc@1: 62.5000 (66.2809)  Acc@5: 87.5000 (91.2809)  time: 0.3631  data: 0.0046  max mem: 2500
Train: Epoch[4/5]  [  90/4579]  eta: 0:27:01  Lr: 0.001875  Loss: -0.1650  Acc@1: 62.5000 (66.2088)  Acc@5: 93.7500 (91.5522)  time: 0.3604  data: 0.0044  max mem: 2500
Train: Epoch[4/5]  [ 100/4579]  eta: 0:26:55  Lr: 0.001875  Loss: -0.1205  Acc@1: 68.7500 (66.3985)  Acc@5: 93.7500 (91.4604)  time: 0.3584  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 110/4579]  eta: 0:26:48  Lr: 0.001875  Loss: 0.0099  Acc@1: 68.7500 (66.8919)  Acc@5: 93.7500 (91.4977)  time: 0.3543  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 120/4579]  eta: 0:26:40  Lr: 0.001875  Loss: -0.1874  Acc@1: 62.5000 (66.0124)  Acc@5: 93.7500 (91.4773)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 130/4579]  eta: 0:26:34  Lr: 0.001875  Loss: -0.5733  Acc@1: 62.5000 (66.2691)  Acc@5: 93.7500 (91.8893)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 140/4579]  eta: 0:26:28  Lr: 0.001875  Loss: -0.4717  Acc@1: 68.7500 (66.3564)  Acc@5: 93.7500 (91.9326)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 150/4579]  eta: 0:26:22  Lr: 0.001875  Loss: -0.3264  Acc@1: 68.7500 (66.5977)  Acc@5: 93.7500 (91.9288)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 160/4579]  eta: 0:26:17  Lr: 0.001875  Loss: -0.1785  Acc@1: 68.7500 (66.6537)  Acc@5: 87.5000 (91.8866)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 170/4579]  eta: 0:26:11  Lr: 0.001875  Loss: -0.0161  Acc@1: 62.5000 (66.4108)  Acc@5: 87.5000 (91.6667)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 180/4579]  eta: 0:26:06  Lr: 0.001875  Loss: -0.2729  Acc@1: 62.5000 (66.3329)  Acc@5: 93.7500 (91.7472)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 190/4579]  eta: 0:26:00  Lr: 0.001875  Loss: 0.0988  Acc@1: 62.5000 (66.3285)  Acc@5: 93.7500 (91.8194)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 200/4579]  eta: 0:25:56  Lr: 0.001875  Loss: 0.1708  Acc@1: 62.5000 (66.2624)  Acc@5: 93.7500 (91.8532)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 210/4579]  eta: 0:25:52  Lr: 0.001875  Loss: -0.2999  Acc@1: 62.5000 (66.1434)  Acc@5: 93.7500 (92.0320)  time: 0.3538  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 220/4579]  eta: 0:25:50  Lr: 0.001875  Loss: 0.6230  Acc@1: 62.5000 (65.9785)  Acc@5: 93.7500 (91.9966)  time: 0.3565  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 230/4579]  eta: 0:25:46  Lr: 0.001875  Loss: -0.0978  Acc@1: 62.5000 (65.7738)  Acc@5: 87.5000 (92.0184)  time: 0.3563  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 240/4579]  eta: 0:25:42  Lr: 0.001875  Loss: -0.2182  Acc@1: 68.7500 (65.9751)  Acc@5: 93.7500 (92.0384)  time: 0.3547  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 250/4579]  eta: 0:25:40  Lr: 0.001875  Loss: 0.5647  Acc@1: 68.7500 (65.8367)  Acc@5: 93.7500 (91.9323)  time: 0.3595  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 260/4579]  eta: 0:25:37  Lr: 0.001875  Loss: -0.4326  Acc@1: 68.7500 (65.9004)  Acc@5: 93.7500 (92.0259)  time: 0.3621  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 270/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 0.7775  Acc@1: 62.5000 (65.7980)  Acc@5: 93.7500 (91.8589)  time: 0.3578  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [ 280/4579]  eta: 0:25:30  Lr: 0.001875  Loss: -0.5561  Acc@1: 68.7500 (65.9698)  Acc@5: 93.7500 (91.9484)  time: 0.3551  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 290/4579]  eta: 0:25:27  Lr: 0.001875  Loss: 0.0337  Acc@1: 68.7500 (65.9794)  Acc@5: 93.7500 (91.8814)  time: 0.3573  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 300/4579]  eta: 0:25:24  Lr: 0.001875  Loss: 0.0120  Acc@1: 68.7500 (65.9468)  Acc@5: 93.7500 (91.9228)  time: 0.3604  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 310/4579]  eta: 0:25:20  Lr: 0.001875  Loss: -0.2536  Acc@1: 62.5000 (65.8561)  Acc@5: 87.5000 (91.6801)  time: 0.3562  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 320/4579]  eta: 0:25:15  Lr: 0.001875  Loss: -0.2435  Acc@1: 68.7500 (66.0241)  Acc@5: 87.5000 (91.7251)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 330/4579]  eta: 0:25:11  Lr: 0.001875  Loss: -0.0393  Acc@1: 68.7500 (65.8233)  Acc@5: 93.7500 (91.5219)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 340/4579]  eta: 0:25:06  Lr: 0.001875  Loss: -0.0562  Acc@1: 62.5000 (65.8541)  Acc@5: 87.5000 (91.4956)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 350/4579]  eta: 0:25:02  Lr: 0.001875  Loss: -0.4429  Acc@1: 68.7500 (65.9900)  Acc@5: 87.5000 (91.4708)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 360/4579]  eta: 0:24:58  Lr: 0.001875  Loss: -0.0343  Acc@1: 68.7500 (65.9799)  Acc@5: 87.5000 (91.3435)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 370/4579]  eta: 0:24:54  Lr: 0.001875  Loss: -0.2178  Acc@1: 62.5000 (66.0209)  Acc@5: 87.5000 (91.2230)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 380/4579]  eta: 0:24:49  Lr: 0.001875  Loss: -0.0484  Acc@1: 62.5000 (65.8957)  Acc@5: 87.5000 (91.2402)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 390/4579]  eta: 0:24:45  Lr: 0.001875  Loss: -0.2722  Acc@1: 62.5000 (65.7609)  Acc@5: 87.5000 (91.1605)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 400/4579]  eta: 0:24:41  Lr: 0.001875  Loss: -0.1915  Acc@1: 62.5000 (65.6484)  Acc@5: 87.5000 (91.1160)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 410/4579]  eta: 0:24:38  Lr: 0.001875  Loss: -0.4237  Acc@1: 68.7500 (65.7543)  Acc@5: 93.7500 (91.1953)  time: 0.3534  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 420/4579]  eta: 0:24:35  Lr: 0.001875  Loss: -0.5935  Acc@1: 68.7500 (65.8848)  Acc@5: 93.7500 (91.3005)  time: 0.3597  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [ 430/4579]  eta: 0:24:31  Lr: 0.001875  Loss: -0.1827  Acc@1: 68.7500 (65.9368)  Acc@5: 93.7500 (91.3138)  time: 0.3557  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [ 440/4579]  eta: 0:24:28  Lr: 0.001875  Loss: -0.7383  Acc@1: 68.7500 (66.0431)  Acc@5: 93.7500 (91.4399)  time: 0.3590  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [ 450/4579]  eta: 0:24:25  Lr: 0.001875  Loss: 0.0069  Acc@1: 62.5000 (65.8537)  Acc@5: 93.7500 (91.4080)  time: 0.3619  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [ 460/4579]  eta: 0:24:22  Lr: 0.001875  Loss: -0.5541  Acc@1: 62.5000 (65.8623)  Acc@5: 93.7500 (91.4723)  time: 0.3579  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 470/4579]  eta: 0:24:18  Lr: 0.001875  Loss: 0.1218  Acc@1: 62.5000 (65.6582)  Acc@5: 93.7500 (91.4411)  time: 0.3555  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [ 480/4579]  eta: 0:24:14  Lr: 0.001875  Loss: -0.0631  Acc@1: 56.2500 (65.6055)  Acc@5: 93.7500 (91.4371)  time: 0.3535  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [ 490/4579]  eta: 0:24:11  Lr: 0.001875  Loss: 0.0214  Acc@1: 56.2500 (65.4022)  Acc@5: 93.7500 (91.4078)  time: 0.3568  data: 0.0034  max mem: 2500
Train: Epoch[4/5]  [ 500/4579]  eta: 0:24:07  Lr: 0.001875  Loss: -0.2568  Acc@1: 56.2500 (65.2445)  Acc@5: 87.5000 (91.3423)  time: 0.3562  data: 0.0032  max mem: 2500
Train: Epoch[4/5]  [ 510/4579]  eta: 0:24:03  Lr: 0.001875  Loss: -0.2325  Acc@1: 62.5000 (65.1786)  Acc@5: 87.5000 (91.3283)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 520/4579]  eta: 0:23:59  Lr: 0.001875  Loss: -0.0350  Acc@1: 62.5000 (65.2111)  Acc@5: 93.7500 (91.3868)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 530/4579]  eta: 0:23:55  Lr: 0.001875  Loss: -0.6902  Acc@1: 62.5000 (65.2072)  Acc@5: 93.7500 (91.4077)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 540/4579]  eta: 0:23:51  Lr: 0.001875  Loss: -0.6399  Acc@1: 62.5000 (65.1802)  Acc@5: 93.7500 (91.4048)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 550/4579]  eta: 0:23:47  Lr: 0.001875  Loss: -0.7258  Acc@1: 62.5000 (65.1996)  Acc@5: 93.7500 (91.4247)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 560/4579]  eta: 0:23:43  Lr: 0.001875  Loss: -0.3012  Acc@1: 62.5000 (65.1961)  Acc@5: 93.7500 (91.4661)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 570/4579]  eta: 0:23:39  Lr: 0.001875  Loss: -0.1297  Acc@1: 62.5000 (65.1489)  Acc@5: 93.7500 (91.4733)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 580/4579]  eta: 0:23:35  Lr: 0.001875  Loss: -0.1911  Acc@1: 56.2500 (65.1248)  Acc@5: 93.7500 (91.5232)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 590/4579]  eta: 0:23:31  Lr: 0.001875  Loss: -0.2908  Acc@1: 62.5000 (65.0486)  Acc@5: 93.7500 (91.4763)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 600/4579]  eta: 0:23:28  Lr: 0.001875  Loss: -0.6748  Acc@1: 62.5000 (65.0478)  Acc@5: 93.7500 (91.5349)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 610/4579]  eta: 0:23:25  Lr: 0.001875  Loss: 0.0978  Acc@1: 62.5000 (65.0982)  Acc@5: 93.7500 (91.5610)  time: 0.3583  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [ 620/4579]  eta: 0:23:22  Lr: 0.001875  Loss: -0.0531  Acc@1: 62.5000 (65.0362)  Acc@5: 93.7500 (91.5056)  time: 0.3615  data: 0.0051  max mem: 2500
Train: Epoch[4/5]  [ 630/4579]  eta: 0:23:19  Lr: 0.001875  Loss: -0.5343  Acc@1: 68.7500 (65.1050)  Acc@5: 93.7500 (91.5412)  time: 0.3655  data: 0.0042  max mem: 2500
Train: Epoch[4/5]  [ 640/4579]  eta: 0:23:16  Lr: 0.001875  Loss: -0.2435  Acc@1: 68.7500 (65.0644)  Acc@5: 93.7500 (91.5464)  time: 0.3634  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 650/4579]  eta: 0:23:12  Lr: 0.001875  Loss: -0.3572  Acc@1: 62.5000 (65.0730)  Acc@5: 87.5000 (91.5227)  time: 0.3559  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 660/4579]  eta: 0:23:09  Lr: 0.001875  Loss: -0.2676  Acc@1: 68.7500 (65.1664)  Acc@5: 93.7500 (91.5469)  time: 0.3557  data: 0.0035  max mem: 2500
Train: Epoch[4/5]  [ 670/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 0.0330  Acc@1: 68.7500 (65.1919)  Acc@5: 93.7500 (91.5518)  time: 0.3589  data: 0.0055  max mem: 2500
Train: Epoch[4/5]  [ 680/4579]  eta: 0:23:03  Lr: 0.001875  Loss: 0.1177  Acc@1: 68.7500 (65.1707)  Acc@5: 93.7500 (91.5382)  time: 0.3617  data: 0.0034  max mem: 2500
Train: Epoch[4/5]  [ 690/4579]  eta: 0:23:00  Lr: 0.001875  Loss: -0.3960  Acc@1: 62.5000 (65.1773)  Acc@5: 93.7500 (91.5250)  time: 0.3618  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 700/4579]  eta: 0:22:56  Lr: 0.001875  Loss: -0.1148  Acc@1: 62.5000 (65.1569)  Acc@5: 93.7500 (91.5389)  time: 0.3553  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 710/4579]  eta: 0:22:52  Lr: 0.001875  Loss: 0.2708  Acc@1: 62.5000 (65.1371)  Acc@5: 93.7500 (91.5524)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 720/4579]  eta: 0:22:48  Lr: 0.001875  Loss: -0.7630  Acc@1: 62.5000 (65.1612)  Acc@5: 87.5000 (91.5395)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 730/4579]  eta: 0:22:44  Lr: 0.001875  Loss: 0.2946  Acc@1: 62.5000 (65.2103)  Acc@5: 87.5000 (91.5527)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 740/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.4942  Acc@1: 68.7500 (65.1738)  Acc@5: 93.7500 (91.5908)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 750/4579]  eta: 0:22:37  Lr: 0.001875  Loss: 0.3834  Acc@1: 62.5000 (65.1381)  Acc@5: 93.7500 (91.5696)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 760/4579]  eta: 0:22:33  Lr: 0.001875  Loss: 0.1190  Acc@1: 62.5000 (65.1445)  Acc@5: 93.7500 (91.6147)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 770/4579]  eta: 0:22:29  Lr: 0.001875  Loss: -0.3942  Acc@1: 68.7500 (65.0940)  Acc@5: 93.7500 (91.6099)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 780/4579]  eta: 0:22:25  Lr: 0.001875  Loss: 0.3258  Acc@1: 62.5000 (65.0048)  Acc@5: 93.7500 (91.6053)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 790/4579]  eta: 0:22:21  Lr: 0.001875  Loss: -0.3029  Acc@1: 62.5000 (65.0917)  Acc@5: 93.7500 (91.5929)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 800/4579]  eta: 0:22:18  Lr: 0.001875  Loss: -0.3048  Acc@1: 68.7500 (65.1061)  Acc@5: 87.5000 (91.5574)  time: 0.3507  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 810/4579]  eta: 0:22:14  Lr: 0.001875  Loss: -0.5550  Acc@1: 68.7500 (65.1356)  Acc@5: 87.5000 (91.5074)  time: 0.3551  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 820/4579]  eta: 0:22:11  Lr: 0.001875  Loss: -0.5394  Acc@1: 68.7500 (65.2025)  Acc@5: 93.7500 (91.5195)  time: 0.3562  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 830/4579]  eta: 0:22:07  Lr: 0.001875  Loss: -0.3080  Acc@1: 62.5000 (65.1850)  Acc@5: 93.7500 (91.5313)  time: 0.3571  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 840/4579]  eta: 0:22:04  Lr: 0.001875  Loss: -0.9913  Acc@1: 62.5000 (65.2497)  Acc@5: 93.7500 (91.5502)  time: 0.3617  data: 0.0048  max mem: 2500
Train: Epoch[4/5]  [ 850/4579]  eta: 0:22:01  Lr: 0.001875  Loss: -0.1865  Acc@1: 62.5000 (65.2174)  Acc@5: 93.7500 (91.5394)  time: 0.3615  data: 0.0049  max mem: 2500
Train: Epoch[4/5]  [ 860/4579]  eta: 0:21:57  Lr: 0.001875  Loss: -0.3106  Acc@1: 62.5000 (65.2947)  Acc@5: 93.7500 (91.5723)  time: 0.3565  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [ 870/4579]  eta: 0:21:54  Lr: 0.001875  Loss: -0.2617  Acc@1: 68.7500 (65.3703)  Acc@5: 93.7500 (91.6188)  time: 0.3568  data: 0.0035  max mem: 2500
Train: Epoch[4/5]  [ 880/4579]  eta: 0:21:51  Lr: 0.001875  Loss: -0.3883  Acc@1: 62.5000 (65.3164)  Acc@5: 93.7500 (91.5792)  time: 0.3589  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [ 890/4579]  eta: 0:21:47  Lr: 0.001875  Loss: 0.3254  Acc@1: 56.2500 (65.2918)  Acc@5: 93.7500 (91.5825)  time: 0.3594  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 900/4579]  eta: 0:21:44  Lr: 0.001875  Loss: 0.0348  Acc@1: 68.7500 (65.3233)  Acc@5: 93.7500 (91.5996)  time: 0.3544  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 910/4579]  eta: 0:21:40  Lr: 0.001875  Loss: -0.6970  Acc@1: 68.7500 (65.3883)  Acc@5: 93.7500 (91.6164)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 920/4579]  eta: 0:21:36  Lr: 0.001875  Loss: -0.1868  Acc@1: 68.7500 (65.4180)  Acc@5: 93.7500 (91.6056)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 930/4579]  eta: 0:21:32  Lr: 0.001875  Loss: -0.4307  Acc@1: 68.7500 (65.3800)  Acc@5: 93.7500 (91.6219)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 940/4579]  eta: 0:21:29  Lr: 0.001875  Loss: -0.3622  Acc@1: 68.7500 (65.4224)  Acc@5: 93.7500 (91.6312)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 950/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 0.1729  Acc@1: 62.5000 (65.3588)  Acc@5: 93.7500 (91.6404)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 960/4579]  eta: 0:21:21  Lr: 0.001875  Loss: -0.2686  Acc@1: 62.5000 (65.3811)  Acc@5: 93.7500 (91.6363)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 970/4579]  eta: 0:21:17  Lr: 0.001875  Loss: -0.2712  Acc@1: 62.5000 (65.3772)  Acc@5: 93.7500 (91.6323)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 980/4579]  eta: 0:21:14  Lr: 0.001875  Loss: -0.4637  Acc@1: 62.5000 (65.3606)  Acc@5: 93.7500 (91.6221)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 990/4579]  eta: 0:21:10  Lr: 0.001875  Loss: -0.5609  Acc@1: 62.5000 (65.3948)  Acc@5: 87.5000 (91.6057)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1000/4579]  eta: 0:21:07  Lr: 0.001875  Loss: 0.3122  Acc@1: 62.5000 (65.3284)  Acc@5: 87.5000 (91.5772)  time: 0.3542  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1010/4579]  eta: 0:21:03  Lr: 0.001875  Loss: 0.1247  Acc@1: 56.2500 (65.2634)  Acc@5: 87.5000 (91.5554)  time: 0.3647  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [1020/4579]  eta: 0:21:00  Lr: 0.001875  Loss: -0.3230  Acc@1: 62.5000 (65.2853)  Acc@5: 87.5000 (91.5646)  time: 0.3650  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [1030/4579]  eta: 0:20:57  Lr: 0.001875  Loss: -0.2335  Acc@1: 68.7500 (65.3310)  Acc@5: 93.7500 (91.5858)  time: 0.3643  data: 0.0036  max mem: 2500
Train: Epoch[4/5]  [1040/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.1048  Acc@1: 62.5000 (65.2918)  Acc@5: 87.5000 (91.5466)  time: 0.3629  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1050/4579]  eta: 0:20:50  Lr: 0.001875  Loss: 0.3270  Acc@1: 56.2500 (65.2355)  Acc@5: 87.5000 (91.5140)  time: 0.3602  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1060/4579]  eta: 0:20:47  Lr: 0.001875  Loss: -0.3470  Acc@1: 62.5000 (65.2686)  Acc@5: 93.7500 (91.5410)  time: 0.3603  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1070/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.3694  Acc@1: 68.7500 (65.2486)  Acc@5: 93.7500 (91.5675)  time: 0.3576  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1080/4579]  eta: 0:20:40  Lr: 0.001875  Loss: -0.4209  Acc@1: 62.5000 (65.2405)  Acc@5: 93.7500 (91.5703)  time: 0.3561  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1090/4579]  eta: 0:20:36  Lr: 0.001875  Loss: -0.3765  Acc@1: 62.5000 (65.1810)  Acc@5: 87.5000 (91.5215)  time: 0.3516  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1100/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.6256  Acc@1: 62.5000 (65.1907)  Acc@5: 87.5000 (91.5588)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1110/4579]  eta: 0:20:29  Lr: 0.001875  Loss: -0.3185  Acc@1: 68.7500 (65.2115)  Acc@5: 93.7500 (91.5223)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1120/4579]  eta: 0:20:25  Lr: 0.001875  Loss: -0.1171  Acc@1: 68.7500 (65.2319)  Acc@5: 93.7500 (91.5589)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1130/4579]  eta: 0:20:21  Lr: 0.001875  Loss: -0.2189  Acc@1: 62.5000 (65.1967)  Acc@5: 93.7500 (91.5617)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1140/4579]  eta: 0:20:18  Lr: 0.001875  Loss: -0.2077  Acc@1: 62.5000 (65.1731)  Acc@5: 87.5000 (91.5370)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1150/4579]  eta: 0:20:14  Lr: 0.001875  Loss: -0.5012  Acc@1: 62.5000 (65.1770)  Acc@5: 93.7500 (91.5291)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1160/4579]  eta: 0:20:10  Lr: 0.001875  Loss: 0.4562  Acc@1: 56.2500 (65.1378)  Acc@5: 93.7500 (91.5159)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1170/4579]  eta: 0:20:07  Lr: 0.001875  Loss: -0.3520  Acc@1: 56.2500 (65.0779)  Acc@5: 87.5000 (91.4923)  time: 0.3485  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1180/4579]  eta: 0:20:03  Lr: 0.001875  Loss: 0.0838  Acc@1: 56.2500 (65.0826)  Acc@5: 87.5000 (91.4850)  time: 0.3523  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1190/4579]  eta: 0:20:00  Lr: 0.001875  Loss: 0.0717  Acc@1: 68.7500 (65.1186)  Acc@5: 93.7500 (91.5145)  time: 0.3545  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1200/4579]  eta: 0:19:56  Lr: 0.001875  Loss: -0.3041  Acc@1: 68.7500 (65.1592)  Acc@5: 93.7500 (91.5383)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1210/4579]  eta: 0:19:53  Lr: 0.001875  Loss: -0.3863  Acc@1: 68.7500 (65.1579)  Acc@5: 93.7500 (91.5514)  time: 0.3565  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1220/4579]  eta: 0:19:49  Lr: 0.001875  Loss: -0.3641  Acc@1: 62.5000 (65.1515)  Acc@5: 93.7500 (91.5285)  time: 0.3597  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [1230/4579]  eta: 0:19:46  Lr: 0.001875  Loss: -0.8782  Acc@1: 62.5000 (65.1757)  Acc@5: 93.7500 (91.5719)  time: 0.3577  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1240/4579]  eta: 0:19:42  Lr: 0.001875  Loss: -0.0089  Acc@1: 62.5000 (65.1591)  Acc@5: 93.7500 (91.5945)  time: 0.3590  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1250/4579]  eta: 0:19:39  Lr: 0.001875  Loss: -0.0008  Acc@1: 62.5000 (65.1329)  Acc@5: 93.7500 (91.6267)  time: 0.3608  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [1260/4579]  eta: 0:19:36  Lr: 0.001875  Loss: 0.0556  Acc@1: 62.5000 (65.1467)  Acc@5: 93.7500 (91.6435)  time: 0.3656  data: 0.0042  max mem: 2500
Train: Epoch[4/5]  [1270/4579]  eta: 0:19:32  Lr: 0.001875  Loss: -0.1668  Acc@1: 68.7500 (65.1800)  Acc@5: 93.7500 (91.6454)  time: 0.3600  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [1280/4579]  eta: 0:19:28  Lr: 0.001875  Loss: 0.5591  Acc@1: 68.7500 (65.1883)  Acc@5: 93.7500 (91.6374)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1290/4579]  eta: 0:19:25  Lr: 0.001875  Loss: -0.2172  Acc@1: 62.5000 (65.1772)  Acc@5: 87.5000 (91.6150)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1300/4579]  eta: 0:19:21  Lr: 0.001875  Loss: -0.2724  Acc@1: 68.7500 (65.2095)  Acc@5: 87.5000 (91.6122)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1310/4579]  eta: 0:19:18  Lr: 0.001875  Loss: -0.4320  Acc@1: 68.7500 (65.2269)  Acc@5: 93.7500 (91.6142)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1320/4579]  eta: 0:19:14  Lr: 0.001875  Loss: -0.5244  Acc@1: 68.7500 (65.2583)  Acc@5: 93.7500 (91.6162)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1330/4579]  eta: 0:19:10  Lr: 0.001875  Loss: 0.1300  Acc@1: 68.7500 (65.2423)  Acc@5: 93.7500 (91.6228)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1340/4579]  eta: 0:19:07  Lr: 0.001875  Loss: 0.3793  Acc@1: 56.2500 (65.2079)  Acc@5: 93.7500 (91.6247)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1350/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.1399  Acc@1: 62.5000 (65.2295)  Acc@5: 93.7500 (91.6266)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1360/4579]  eta: 0:18:59  Lr: 0.001875  Loss: -0.1282  Acc@1: 62.5000 (65.2048)  Acc@5: 93.7500 (91.6238)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1370/4579]  eta: 0:18:56  Lr: 0.001875  Loss: 0.0444  Acc@1: 62.5000 (65.2079)  Acc@5: 87.5000 (91.6028)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1380/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.5704  Acc@1: 62.5000 (65.2018)  Acc@5: 93.7500 (91.6048)  time: 0.3517  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1390/4579]  eta: 0:18:48  Lr: 0.001875  Loss: -0.4389  Acc@1: 62.5000 (65.1734)  Acc@5: 93.7500 (91.6113)  time: 0.3541  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1400/4579]  eta: 0:18:45  Lr: 0.001875  Loss: 0.5051  Acc@1: 62.5000 (65.1588)  Acc@5: 93.7500 (91.6087)  time: 0.3570  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1410/4579]  eta: 0:18:42  Lr: 0.001875  Loss: -0.0911  Acc@1: 62.5000 (65.1400)  Acc@5: 93.7500 (91.6283)  time: 0.3582  data: 0.0037  max mem: 2500
Train: Epoch[4/5]  [1420/4579]  eta: 0:18:38  Lr: 0.001875  Loss: -0.2538  Acc@1: 56.2500 (65.1082)  Acc@5: 93.7500 (91.6080)  time: 0.3580  data: 0.0034  max mem: 2500
Train: Epoch[4/5]  [1430/4579]  eta: 0:18:35  Lr: 0.001875  Loss: -0.6106  Acc@1: 68.7500 (65.1555)  Acc@5: 93.7500 (91.6361)  time: 0.3596  data: 0.0041  max mem: 2500
Train: Epoch[4/5]  [1440/4579]  eta: 0:18:31  Lr: 0.001875  Loss: -0.4100  Acc@1: 68.7500 (65.1978)  Acc@5: 93.7500 (91.6378)  time: 0.3598  data: 0.0041  max mem: 2500
Train: Epoch[4/5]  [1450/4579]  eta: 0:18:28  Lr: 0.001875  Loss: 0.3322  Acc@1: 68.7500 (65.1620)  Acc@5: 87.5000 (91.6049)  time: 0.3586  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [1460/4579]  eta: 0:18:24  Lr: 0.001875  Loss: -0.3641  Acc@1: 68.7500 (65.1908)  Acc@5: 93.7500 (91.6282)  time: 0.3553  data: 0.0029  max mem: 2500
Train: Epoch[4/5]  [1470/4579]  eta: 0:18:21  Lr: 0.001875  Loss: 0.0202  Acc@1: 68.7500 (65.1428)  Acc@5: 93.7500 (91.6171)  time: 0.3511  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1480/4579]  eta: 0:18:17  Lr: 0.001875  Loss: -0.4999  Acc@1: 56.2500 (65.0912)  Acc@5: 93.7500 (91.6188)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1490/4579]  eta: 0:18:13  Lr: 0.001875  Loss: -0.8279  Acc@1: 62.5000 (65.0864)  Acc@5: 93.7500 (91.6038)  time: 0.3530  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1500/4579]  eta: 0:18:10  Lr: 0.001875  Loss: -0.3201  Acc@1: 68.7500 (65.0774)  Acc@5: 93.7500 (91.6056)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1510/4579]  eta: 0:18:06  Lr: 0.001875  Loss: 0.0178  Acc@1: 62.5000 (65.0687)  Acc@5: 93.7500 (91.5950)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1520/4579]  eta: 0:18:03  Lr: 0.001875  Loss: 0.0122  Acc@1: 62.5000 (65.0764)  Acc@5: 93.7500 (91.5927)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1530/4579]  eta: 0:17:59  Lr: 0.001875  Loss: -0.2571  Acc@1: 62.5000 (65.0351)  Acc@5: 93.7500 (91.5864)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1540/4579]  eta: 0:17:55  Lr: 0.001875  Loss: -0.6376  Acc@1: 62.5000 (65.0714)  Acc@5: 93.7500 (91.6126)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1550/4579]  eta: 0:17:52  Lr: 0.001875  Loss: 0.3027  Acc@1: 68.7500 (65.0548)  Acc@5: 93.7500 (91.6143)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1560/4579]  eta: 0:17:48  Lr: 0.001875  Loss: 0.4899  Acc@1: 62.5000 (65.0144)  Acc@5: 87.5000 (91.5959)  time: 0.3602  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1570/4579]  eta: 0:17:45  Lr: 0.001875  Loss: -0.3329  Acc@1: 62.5000 (64.9984)  Acc@5: 93.7500 (91.6057)  time: 0.3589  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1580/4579]  eta: 0:17:41  Lr: 0.001875  Loss: -0.9816  Acc@1: 68.7500 (65.0577)  Acc@5: 93.7500 (91.6350)  time: 0.3537  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [1590/4579]  eta: 0:17:38  Lr: 0.001875  Loss: 0.0155  Acc@1: 75.0000 (65.0574)  Acc@5: 93.7500 (91.6130)  time: 0.3744  data: 0.0033  max mem: 2500
Train: Epoch[4/5]  [1600/4579]  eta: 0:17:37  Lr: 0.001875  Loss: -0.2039  Acc@1: 62.5000 (65.0492)  Acc@5: 87.5000 (91.6029)  time: 0.4419  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1610/4579]  eta: 0:17:34  Lr: 0.001875  Loss: -0.1745  Acc@1: 68.7500 (65.0760)  Acc@5: 93.7500 (91.6201)  time: 0.4229  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1620/4579]  eta: 0:17:30  Lr: 0.001875  Loss: -0.6805  Acc@1: 68.7500 (65.0756)  Acc@5: 93.7500 (91.6063)  time: 0.3554  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1630/4579]  eta: 0:17:27  Lr: 0.001875  Loss: 0.3205  Acc@1: 68.7500 (65.0904)  Acc@5: 93.7500 (91.6117)  time: 0.3587  data: 0.0038  max mem: 2500
Train: Epoch[4/5]  [1640/4579]  eta: 0:17:23  Lr: 0.001875  Loss: -0.5259  Acc@1: 68.7500 (65.0556)  Acc@5: 93.7500 (91.5829)  time: 0.3577  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [1650/4579]  eta: 0:17:20  Lr: 0.001875  Loss: -0.4346  Acc@1: 56.2500 (65.0250)  Acc@5: 93.7500 (91.5809)  time: 0.3560  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1660/4579]  eta: 0:17:16  Lr: 0.001875  Loss: -0.0064  Acc@1: 62.5000 (65.0399)  Acc@5: 87.5000 (91.5713)  time: 0.3541  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1670/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 0.3958  Acc@1: 68.7500 (65.0546)  Acc@5: 87.5000 (91.5582)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1680/4579]  eta: 0:17:09  Lr: 0.001875  Loss: 0.2825  Acc@1: 62.5000 (65.0208)  Acc@5: 87.5000 (91.5564)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1690/4579]  eta: 0:17:05  Lr: 0.001875  Loss: -0.9424  Acc@1: 62.5000 (65.0207)  Acc@5: 87.5000 (91.5509)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1700/4579]  eta: 0:17:02  Lr: 0.001875  Loss: -0.4497  Acc@1: 68.7500 (65.0573)  Acc@5: 93.7500 (91.5638)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1710/4579]  eta: 0:16:58  Lr: 0.001875  Loss: -0.2665  Acc@1: 68.7500 (65.0972)  Acc@5: 93.7500 (91.5766)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1720/4579]  eta: 0:16:54  Lr: 0.001875  Loss: 0.0945  Acc@1: 68.7500 (65.1365)  Acc@5: 93.7500 (91.5892)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1730/4579]  eta: 0:16:51  Lr: 0.001875  Loss: -0.3417  Acc@1: 68.7500 (65.1791)  Acc@5: 93.7500 (91.6089)  time: 0.3533  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1740/4579]  eta: 0:16:47  Lr: 0.001875  Loss: -0.1148  Acc@1: 68.7500 (65.1924)  Acc@5: 93.7500 (91.6068)  time: 0.3593  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1750/4579]  eta: 0:16:44  Lr: 0.001875  Loss: -0.7350  Acc@1: 68.7500 (65.1842)  Acc@5: 87.5000 (91.6048)  time: 0.3533  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1760/4579]  eta: 0:16:40  Lr: 0.001875  Loss: 0.0820  Acc@1: 62.5000 (65.1938)  Acc@5: 87.5000 (91.5886)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1770/4579]  eta: 0:16:38  Lr: 0.001875  Loss: -0.0193  Acc@1: 68.7500 (65.1892)  Acc@5: 87.5000 (91.5902)  time: 0.3975  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1780/4579]  eta: 0:16:41  Lr: 0.001875  Loss: -0.1285  Acc@1: 68.7500 (65.2302)  Acc@5: 93.7500 (91.5883)  time: 0.5973  data: 0.0035  max mem: 2500
Train: Epoch[4/5]  [1790/4579]  eta: 0:16:43  Lr: 0.001875  Loss: 0.1324  Acc@1: 62.5000 (65.2115)  Acc@5: 93.7500 (91.5899)  time: 0.7476  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1800/4579]  eta: 0:16:45  Lr: 0.001875  Loss: 0.0451  Acc@1: 62.5000 (65.1929)  Acc@5: 87.5000 (91.5672)  time: 0.7428  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1810/4579]  eta: 0:16:43  Lr: 0.001875  Loss: 0.2419  Acc@1: 62.5000 (65.1815)  Acc@5: 87.5000 (91.5551)  time: 0.5995  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1820/4579]  eta: 0:16:39  Lr: 0.001875  Loss: 0.6437  Acc@1: 62.5000 (65.1634)  Acc@5: 93.7500 (91.5431)  time: 0.4083  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1830/4579]  eta: 0:16:36  Lr: 0.001875  Loss: 0.1442  Acc@1: 56.2500 (65.1557)  Acc@5: 87.5000 (91.5347)  time: 0.3547  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1840/4579]  eta: 0:16:32  Lr: 0.001875  Loss: 0.0382  Acc@1: 62.5000 (65.1344)  Acc@5: 93.7500 (91.5399)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1850/4579]  eta: 0:16:28  Lr: 0.001875  Loss: -0.1218  Acc@1: 62.5000 (65.1371)  Acc@5: 93.7500 (91.5620)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1860/4579]  eta: 0:16:25  Lr: 0.001875  Loss: -0.1228  Acc@1: 68.7500 (65.1531)  Acc@5: 93.7500 (91.5738)  time: 0.3622  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1870/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.3836  Acc@1: 68.7500 (65.1590)  Acc@5: 93.7500 (91.5754)  time: 0.3624  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1880/4579]  eta: 0:16:17  Lr: 0.001875  Loss: -0.7217  Acc@1: 62.5000 (65.1415)  Acc@5: 93.7500 (91.5936)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1890/4579]  eta: 0:16:15  Lr: 0.001875  Loss: 0.0138  Acc@1: 56.2500 (65.1210)  Acc@5: 93.7500 (91.5851)  time: 0.4162  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1900/4579]  eta: 0:16:14  Lr: 0.001875  Loss: -0.0548  Acc@1: 62.5000 (65.1236)  Acc@5: 93.7500 (91.5867)  time: 0.5091  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1910/4579]  eta: 0:16:10  Lr: 0.001875  Loss: -0.4254  Acc@1: 68.7500 (65.1197)  Acc@5: 93.7500 (91.5849)  time: 0.4413  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1920/4579]  eta: 0:16:06  Lr: 0.001875  Loss: -0.3493  Acc@1: 62.5000 (65.1191)  Acc@5: 93.7500 (91.5897)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1930/4579]  eta: 0:16:02  Lr: 0.001875  Loss: -0.5120  Acc@1: 68.7500 (65.1152)  Acc@5: 93.7500 (91.5911)  time: 0.3531  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1940/4579]  eta: 0:15:59  Lr: 0.001875  Loss: 0.0423  Acc@1: 62.5000 (65.0953)  Acc@5: 93.7500 (91.5894)  time: 0.3544  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1950/4579]  eta: 0:15:55  Lr: 0.001875  Loss: 0.0879  Acc@1: 62.5000 (65.0852)  Acc@5: 93.7500 (91.5973)  time: 0.3574  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1960/4579]  eta: 0:15:51  Lr: 0.001875  Loss: -0.1860  Acc@1: 62.5000 (65.0880)  Acc@5: 93.7500 (91.5955)  time: 0.3590  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [1970/4579]  eta: 0:15:48  Lr: 0.001875  Loss: 0.1354  Acc@1: 62.5000 (65.0685)  Acc@5: 87.5000 (91.5937)  time: 0.3591  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [1980/4579]  eta: 0:15:44  Lr: 0.001875  Loss: -0.4737  Acc@1: 56.2500 (65.0366)  Acc@5: 93.7500 (91.6046)  time: 0.3602  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1990/4579]  eta: 0:15:40  Lr: 0.001875  Loss: -0.4698  Acc@1: 62.5000 (65.0364)  Acc@5: 93.7500 (91.5997)  time: 0.3654  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2000/4579]  eta: 0:15:37  Lr: 0.001875  Loss: 0.1348  Acc@1: 68.7500 (65.0394)  Acc@5: 93.7500 (91.6042)  time: 0.3612  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2010/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.4586  Acc@1: 68.7500 (65.0205)  Acc@5: 93.7500 (91.6024)  time: 0.3547  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2020/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.3735  Acc@1: 62.5000 (65.0019)  Acc@5: 93.7500 (91.6007)  time: 0.3622  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2030/4579]  eta: 0:15:30  Lr: 0.001875  Loss: -0.6349  Acc@1: 62.5000 (65.0111)  Acc@5: 93.7500 (91.5928)  time: 0.5557  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2040/4579]  eta: 0:15:30  Lr: 0.001875  Loss: -0.6034  Acc@1: 68.7500 (65.0447)  Acc@5: 93.7500 (91.5942)  time: 0.6828  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2050/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 0.0206  Acc@1: 75.0000 (65.0689)  Acc@5: 93.7500 (91.5986)  time: 0.4852  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2060/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.4799  Acc@1: 68.7500 (65.0746)  Acc@5: 93.7500 (91.6030)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2070/4579]  eta: 0:15:18  Lr: 0.001875  Loss: -0.0469  Acc@1: 68.7500 (65.0803)  Acc@5: 93.7500 (91.6134)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2080/4579]  eta: 0:15:14  Lr: 0.001875  Loss: 0.0511  Acc@1: 68.7500 (65.0739)  Acc@5: 93.7500 (91.6146)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2090/4579]  eta: 0:15:11  Lr: 0.001875  Loss: -0.3068  Acc@1: 62.5000 (65.0526)  Acc@5: 93.7500 (91.6218)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2100/4579]  eta: 0:15:07  Lr: 0.001875  Loss: 0.6876  Acc@1: 62.5000 (65.0434)  Acc@5: 93.7500 (91.6379)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2110/4579]  eta: 0:15:03  Lr: 0.001875  Loss: -0.4364  Acc@1: 62.5000 (65.0195)  Acc@5: 93.7500 (91.6302)  time: 0.3505  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2120/4579]  eta: 0:14:59  Lr: 0.001875  Loss: -0.3519  Acc@1: 62.5000 (65.0607)  Acc@5: 93.7500 (91.6313)  time: 0.3532  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [2130/4579]  eta: 0:14:55  Lr: 0.001875  Loss: -0.1576  Acc@1: 75.0000 (65.0809)  Acc@5: 93.7500 (91.6324)  time: 0.3517  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2140/4579]  eta: 0:14:52  Lr: 0.001875  Loss: -0.6377  Acc@1: 68.7500 (65.0981)  Acc@5: 93.7500 (91.6365)  time: 0.3545  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2150/4579]  eta: 0:14:48  Lr: 0.001875  Loss: -0.1438  Acc@1: 68.7500 (65.1209)  Acc@5: 87.5000 (91.6289)  time: 0.3567  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2160/4579]  eta: 0:14:44  Lr: 0.001875  Loss: -0.0582  Acc@1: 68.7500 (65.1348)  Acc@5: 93.7500 (91.6474)  time: 0.3540  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2170/4579]  eta: 0:14:40  Lr: 0.001875  Loss: 0.0099  Acc@1: 62.5000 (65.1054)  Acc@5: 93.7500 (91.6283)  time: 0.3534  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2180/4579]  eta: 0:14:36  Lr: 0.001875  Loss: 0.0423  Acc@1: 62.5000 (65.1049)  Acc@5: 87.5000 (91.6180)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2190/4579]  eta: 0:14:33  Lr: 0.001875  Loss: -0.0038  Acc@1: 62.5000 (65.1158)  Acc@5: 87.5000 (91.6277)  time: 0.3558  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2200/4579]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5946  Acc@1: 62.5000 (65.1068)  Acc@5: 93.7500 (91.6203)  time: 0.3544  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2210/4579]  eta: 0:14:25  Lr: 0.001875  Loss: -0.1057  Acc@1: 68.7500 (65.1430)  Acc@5: 93.7500 (91.6214)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2220/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.6715  Acc@1: 75.0000 (65.1874)  Acc@5: 93.7500 (91.6282)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2230/4579]  eta: 0:14:17  Lr: 0.001875  Loss: -0.4511  Acc@1: 68.7500 (65.1894)  Acc@5: 93.7500 (91.6293)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2240/4579]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5598  Acc@1: 62.5000 (65.1718)  Acc@5: 93.7500 (91.6276)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2250/4579]  eta: 0:14:10  Lr: 0.001875  Loss: -0.4478  Acc@1: 62.5000 (65.1572)  Acc@5: 93.7500 (91.6259)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2260/4579]  eta: 0:14:06  Lr: 0.001875  Loss: -0.0714  Acc@1: 62.5000 (65.1565)  Acc@5: 87.5000 (91.6132)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2270/4579]  eta: 0:14:02  Lr: 0.001875  Loss: -0.3936  Acc@1: 62.5000 (65.1723)  Acc@5: 87.5000 (91.6226)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2280/4579]  eta: 0:13:58  Lr: 0.001875  Loss: -0.2815  Acc@1: 68.7500 (65.1907)  Acc@5: 93.7500 (91.6402)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2290/4579]  eta: 0:13:55  Lr: 0.001875  Loss: -0.3485  Acc@1: 68.7500 (65.2035)  Acc@5: 93.7500 (91.6521)  time: 0.3570  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2300/4579]  eta: 0:13:51  Lr: 0.001875  Loss: -0.1218  Acc@1: 68.7500 (65.1972)  Acc@5: 93.7500 (91.6667)  time: 0.3583  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2310/4579]  eta: 0:13:47  Lr: 0.001875  Loss: -0.4582  Acc@1: 62.5000 (65.1909)  Acc@5: 93.7500 (91.6595)  time: 0.3540  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2320/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4492  Acc@1: 68.7500 (65.2090)  Acc@5: 93.7500 (91.6604)  time: 0.3608  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2330/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6445  Acc@1: 62.5000 (65.2161)  Acc@5: 93.7500 (91.6533)  time: 0.5362  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2340/4579]  eta: 0:13:41  Lr: 0.001875  Loss: -0.5731  Acc@1: 62.5000 (65.2285)  Acc@5: 93.7500 (91.6515)  time: 0.6347  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2350/4579]  eta: 0:13:38  Lr: 0.001875  Loss: 0.4367  Acc@1: 68.7500 (65.2409)  Acc@5: 93.7500 (91.6605)  time: 0.4580  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2360/4579]  eta: 0:13:34  Lr: 0.001875  Loss: 0.1960  Acc@1: 62.5000 (65.2425)  Acc@5: 93.7500 (91.6720)  time: 0.3554  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [2370/4579]  eta: 0:13:30  Lr: 0.001875  Loss: -0.5540  Acc@1: 62.5000 (65.2415)  Acc@5: 93.7500 (91.6675)  time: 0.3558  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [2380/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.5086  Acc@1: 62.5000 (65.2588)  Acc@5: 93.7500 (91.6737)  time: 0.3523  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2390/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.1559  Acc@1: 68.7500 (65.2630)  Acc@5: 93.7500 (91.6850)  time: 0.3507  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2400/4579]  eta: 0:13:19  Lr: 0.001875  Loss: -0.6911  Acc@1: 75.0000 (65.2905)  Acc@5: 93.7500 (91.6884)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2410/4579]  eta: 0:13:15  Lr: 0.001875  Loss: 0.3765  Acc@1: 62.5000 (65.2867)  Acc@5: 87.5000 (91.6684)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2420/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.0718  Acc@1: 68.7500 (65.3165)  Acc@5: 87.5000 (91.6744)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2430/4579]  eta: 0:13:07  Lr: 0.001875  Loss: -0.5380  Acc@1: 68.7500 (65.3281)  Acc@5: 93.7500 (91.6778)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2440/4579]  eta: 0:13:03  Lr: 0.001875  Loss: -0.2207  Acc@1: 62.5000 (65.2960)  Acc@5: 93.7500 (91.6735)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2450/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.4409  Acc@1: 62.5000 (65.2999)  Acc@5: 87.5000 (91.6743)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2460/4579]  eta: 0:12:56  Lr: 0.001875  Loss: -0.1442  Acc@1: 62.5000 (65.2885)  Acc@5: 87.5000 (91.6777)  time: 0.3583  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2470/4579]  eta: 0:12:52  Lr: 0.001875  Loss: -0.7748  Acc@1: 62.5000 (65.3076)  Acc@5: 93.7500 (91.6861)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2480/4579]  eta: 0:12:48  Lr: 0.001875  Loss: -0.8025  Acc@1: 62.5000 (65.2937)  Acc@5: 93.7500 (91.6843)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2490/4579]  eta: 0:12:45  Lr: 0.001875  Loss: -0.5927  Acc@1: 62.5000 (65.3227)  Acc@5: 93.7500 (91.6876)  time: 0.3962  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2500/4579]  eta: 0:12:45  Lr: 0.001875  Loss: -0.4617  Acc@1: 68.7500 (65.3264)  Acc@5: 93.7500 (91.6883)  time: 0.5949  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2510/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.1932  Acc@1: 62.5000 (65.3126)  Acc@5: 93.7500 (91.6791)  time: 0.7495  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2520/4579]  eta: 0:12:43  Lr: 0.001875  Loss: 0.0779  Acc@1: 62.5000 (65.3114)  Acc@5: 87.5000 (91.6675)  time: 0.7495  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2530/4579]  eta: 0:12:43  Lr: 0.001875  Loss: 0.3908  Acc@1: 62.5000 (65.2904)  Acc@5: 93.7500 (91.6757)  time: 0.7480  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [2540/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.0768  Acc@1: 62.5000 (65.2893)  Acc@5: 93.7500 (91.6790)  time: 0.7487  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2550/4579]  eta: 0:12:41  Lr: 0.001875  Loss: -0.2827  Acc@1: 62.5000 (65.3151)  Acc@5: 93.7500 (91.6797)  time: 0.7460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2560/4579]  eta: 0:12:40  Lr: 0.001875  Loss: -0.5978  Acc@1: 62.5000 (65.3016)  Acc@5: 93.7500 (91.6878)  time: 0.7439  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2570/4579]  eta: 0:12:40  Lr: 0.001875  Loss: -0.2591  Acc@1: 62.5000 (65.3126)  Acc@5: 93.7500 (91.6910)  time: 0.7443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2580/4579]  eta: 0:12:39  Lr: 0.001875  Loss: -0.7648  Acc@1: 68.7500 (65.3235)  Acc@5: 93.7500 (91.6941)  time: 0.7438  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2590/4579]  eta: 0:12:38  Lr: 0.001875  Loss: -0.2420  Acc@1: 68.7500 (65.3343)  Acc@5: 93.7500 (91.6996)  time: 0.7407  data: 0.0039  max mem: 2500
Train: Epoch[4/5]  [2600/4579]  eta: 0:12:36  Lr: 0.001875  Loss: -0.2660  Acc@1: 68.7500 (65.3330)  Acc@5: 93.7500 (91.6931)  time: 0.7376  data: 0.0040  max mem: 2500
Train: Epoch[4/5]  [2610/4579]  eta: 0:12:35  Lr: 0.001875  Loss: -0.5276  Acc@1: 62.5000 (65.3150)  Acc@5: 93.7500 (91.6962)  time: 0.7372  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2620/4579]  eta: 0:12:34  Lr: 0.001875  Loss: 0.4109  Acc@1: 62.5000 (65.2924)  Acc@5: 93.7500 (91.6969)  time: 0.7392  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2630/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.0318  Acc@1: 68.7500 (65.3126)  Acc@5: 93.7500 (91.7047)  time: 0.7430  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2640/4579]  eta: 0:12:32  Lr: 0.001875  Loss: -0.6872  Acc@1: 68.7500 (65.3114)  Acc@5: 93.7500 (91.7077)  time: 0.7436  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2650/4579]  eta: 0:12:30  Lr: 0.001875  Loss: -0.3512  Acc@1: 68.7500 (65.3268)  Acc@5: 93.7500 (91.7107)  time: 0.7404  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2660/4579]  eta: 0:12:29  Lr: 0.001875  Loss: -0.3427  Acc@1: 68.7500 (65.3302)  Acc@5: 93.7500 (91.7089)  time: 0.7387  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2670/4579]  eta: 0:12:28  Lr: 0.001875  Loss: -0.1344  Acc@1: 68.7500 (65.3243)  Acc@5: 93.7500 (91.7283)  time: 0.7384  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2680/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.4685  Acc@1: 62.5000 (65.3208)  Acc@5: 93.7500 (91.7288)  time: 0.7381  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [2690/4579]  eta: 0:12:25  Lr: 0.001875  Loss: -0.5706  Acc@1: 62.5000 (65.3266)  Acc@5: 93.7500 (91.7224)  time: 0.7369  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2700/4579]  eta: 0:12:23  Lr: 0.001875  Loss: -0.3714  Acc@1: 68.7500 (65.3253)  Acc@5: 93.7500 (91.7160)  time: 0.7334  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2710/4579]  eta: 0:12:21  Lr: 0.001875  Loss: -0.1824  Acc@1: 62.5000 (65.3311)  Acc@5: 93.7500 (91.7143)  time: 0.7325  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2720/4579]  eta: 0:12:20  Lr: 0.001875  Loss: 0.1687  Acc@1: 62.5000 (65.3161)  Acc@5: 87.5000 (91.6942)  time: 0.7346  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2730/4579]  eta: 0:12:18  Lr: 0.001875  Loss: -0.4869  Acc@1: 62.5000 (65.2829)  Acc@5: 87.5000 (91.6857)  time: 0.7320  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2740/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.2439  Acc@1: 62.5000 (65.2955)  Acc@5: 87.5000 (91.6841)  time: 0.7309  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2750/4579]  eta: 0:12:14  Lr: 0.001875  Loss: 0.0297  Acc@1: 68.7500 (65.2876)  Acc@5: 87.5000 (91.6803)  time: 0.7329  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2760/4579]  eta: 0:12:12  Lr: 0.001875  Loss: 0.1294  Acc@1: 62.5000 (65.3024)  Acc@5: 93.7500 (91.6923)  time: 0.7254  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2770/4579]  eta: 0:12:11  Lr: 0.001875  Loss: -0.3838  Acc@1: 68.7500 (65.2991)  Acc@5: 93.7500 (91.6997)  time: 0.7239  data: 0.0029  max mem: 2500
Train: Epoch[4/5]  [2780/4579]  eta: 0:12:09  Lr: 0.001875  Loss: -0.4999  Acc@1: 68.7500 (65.3295)  Acc@5: 93.7500 (91.6936)  time: 0.7203  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [2790/4579]  eta: 0:12:06  Lr: 0.001875  Loss: -0.5864  Acc@1: 68.7500 (65.3216)  Acc@5: 87.5000 (91.6831)  time: 0.6796  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2800/4579]  eta: 0:12:04  Lr: 0.001875  Loss: -0.2626  Acc@1: 62.5000 (65.3160)  Acc@5: 93.7500 (91.6838)  time: 0.6868  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2810/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.1152  Acc@1: 68.7500 (65.3215)  Acc@5: 93.7500 (91.6845)  time: 0.7273  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2820/4579]  eta: 0:12:00  Lr: 0.001875  Loss: -0.1762  Acc@1: 68.7500 (65.3204)  Acc@5: 93.7500 (91.6962)  time: 0.7266  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2830/4579]  eta: 0:11:56  Lr: 0.001875  Loss: -0.5139  Acc@1: 68.7500 (65.3259)  Acc@5: 93.7500 (91.6836)  time: 0.6117  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2840/4579]  eta: 0:11:52  Lr: 0.001875  Loss: -0.6054  Acc@1: 68.7500 (65.3269)  Acc@5: 87.5000 (91.6843)  time: 0.4723  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2850/4579]  eta: 0:11:50  Lr: 0.001875  Loss: -0.6292  Acc@1: 68.7500 (65.3499)  Acc@5: 93.7500 (91.6937)  time: 0.5863  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2860/4579]  eta: 0:11:48  Lr: 0.001875  Loss: 0.0010  Acc@1: 62.5000 (65.3334)  Acc@5: 93.7500 (91.6922)  time: 0.7284  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [2870/4579]  eta: 0:11:46  Lr: 0.001875  Loss: 0.4175  Acc@1: 56.2500 (65.3061)  Acc@5: 93.7500 (91.6884)  time: 0.7284  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [2880/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.2975  Acc@1: 62.5000 (65.3224)  Acc@5: 93.7500 (91.6978)  time: 0.7266  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2890/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.9393  Acc@1: 75.0000 (65.3472)  Acc@5: 93.7500 (91.7027)  time: 0.7261  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2900/4579]  eta: 0:11:39  Lr: 0.001875  Loss: -0.0371  Acc@1: 75.0000 (65.3568)  Acc@5: 93.7500 (91.7098)  time: 0.7257  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2910/4579]  eta: 0:11:36  Lr: 0.001875  Loss: 0.3297  Acc@1: 75.0000 (65.3770)  Acc@5: 93.7500 (91.7168)  time: 0.7204  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2920/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.5979  Acc@1: 68.7500 (65.3843)  Acc@5: 93.7500 (91.7109)  time: 0.7181  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2930/4579]  eta: 0:11:31  Lr: 0.001875  Loss: 0.1259  Acc@1: 62.5000 (65.3659)  Acc@5: 87.5000 (91.7093)  time: 0.7209  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [2940/4579]  eta: 0:11:29  Lr: 0.001875  Loss: -0.0147  Acc@1: 62.5000 (65.3753)  Acc@5: 87.5000 (91.7056)  time: 0.7189  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [2950/4579]  eta: 0:11:26  Lr: 0.001875  Loss: -0.5358  Acc@1: 68.7500 (65.3783)  Acc@5: 87.5000 (91.7104)  time: 0.7193  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2960/4579]  eta: 0:11:24  Lr: 0.001875  Loss: -0.8652  Acc@1: 68.7500 (65.3918)  Acc@5: 93.7500 (91.7173)  time: 0.7196  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [2970/4579]  eta: 0:11:21  Lr: 0.001875  Loss: -0.5189  Acc@1: 62.5000 (65.3968)  Acc@5: 93.7500 (91.7179)  time: 0.7124  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [2980/4579]  eta: 0:11:18  Lr: 0.001875  Loss: -0.6097  Acc@1: 62.5000 (65.3849)  Acc@5: 93.7500 (91.7184)  time: 0.7174  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2990/4579]  eta: 0:11:16  Lr: 0.001875  Loss: -0.7546  Acc@1: 62.5000 (65.3795)  Acc@5: 93.7500 (91.7210)  time: 0.7238  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3000/4579]  eta: 0:11:13  Lr: 0.001875  Loss: -0.6080  Acc@1: 68.7500 (65.3907)  Acc@5: 93.7500 (91.7257)  time: 0.7242  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3010/4579]  eta: 0:11:10  Lr: 0.001875  Loss: 0.3265  Acc@1: 68.7500 (65.3998)  Acc@5: 93.7500 (91.7282)  time: 0.7266  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3020/4579]  eta: 0:11:08  Lr: 0.001875  Loss: -0.4987  Acc@1: 68.7500 (65.4233)  Acc@5: 93.7500 (91.7411)  time: 0.7246  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3030/4579]  eta: 0:11:05  Lr: 0.001875  Loss: 0.0513  Acc@1: 68.7500 (65.4363)  Acc@5: 93.7500 (91.7395)  time: 0.7243  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3040/4579]  eta: 0:11:02  Lr: 0.001875  Loss: 0.2103  Acc@1: 62.5000 (65.4349)  Acc@5: 93.7500 (91.7441)  time: 0.7239  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [3050/4579]  eta: 0:10:59  Lr: 0.001875  Loss: -0.9592  Acc@1: 68.7500 (65.4478)  Acc@5: 93.7500 (91.7425)  time: 0.7224  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [3060/4579]  eta: 0:10:56  Lr: 0.001875  Loss: -0.7591  Acc@1: 68.7500 (65.4647)  Acc@5: 93.7500 (91.7429)  time: 0.7167  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3070/4579]  eta: 0:10:53  Lr: 0.001875  Loss: -0.0488  Acc@1: 68.7500 (65.4510)  Acc@5: 93.7500 (91.7413)  time: 0.7174  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3080/4579]  eta: 0:10:50  Lr: 0.001875  Loss: -0.2142  Acc@1: 56.2500 (65.4414)  Acc@5: 93.7500 (91.7478)  time: 0.7224  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3090/4579]  eta: 0:10:48  Lr: 0.001875  Loss: 0.1710  Acc@1: 62.5000 (65.4622)  Acc@5: 93.7500 (91.7401)  time: 0.7207  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3100/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.1466  Acc@1: 68.7500 (65.4567)  Acc@5: 93.7500 (91.7506)  time: 0.7197  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3110/4579]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7685  Acc@1: 62.5000 (65.4552)  Acc@5: 93.7500 (91.7470)  time: 0.7192  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3120/4579]  eta: 0:10:38  Lr: 0.001875  Loss: -0.4921  Acc@1: 62.5000 (65.4678)  Acc@5: 93.7500 (91.7514)  time: 0.7177  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3130/4579]  eta: 0:10:35  Lr: 0.001875  Loss: -0.5363  Acc@1: 68.7500 (65.4863)  Acc@5: 93.7500 (91.7578)  time: 0.7192  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3140/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.4065  Acc@1: 62.5000 (65.4787)  Acc@5: 93.7500 (91.7502)  time: 0.7219  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [3150/4579]  eta: 0:10:29  Lr: 0.001875  Loss: -0.3174  Acc@1: 62.5000 (65.4693)  Acc@5: 93.7500 (91.7427)  time: 0.7127  data: 0.0056  max mem: 2500
Train: Epoch[4/5]  [3160/4579]  eta: 0:10:26  Lr: 0.001875  Loss: 0.0688  Acc@1: 62.5000 (65.4619)  Acc@5: 93.7500 (91.7352)  time: 0.6854  data: 0.0039  max mem: 2500
Train: Epoch[4/5]  [3170/4579]  eta: 0:10:22  Lr: 0.001875  Loss: -0.0539  Acc@1: 62.5000 (65.4545)  Acc@5: 93.7500 (91.7396)  time: 0.6899  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3180/4579]  eta: 0:10:19  Lr: 0.001875  Loss: -0.7435  Acc@1: 62.5000 (65.4393)  Acc@5: 93.7500 (91.7459)  time: 0.7118  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3190/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.6941  Acc@1: 62.5000 (65.4595)  Acc@5: 93.7500 (91.7561)  time: 0.7115  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3200/4579]  eta: 0:10:12  Lr: 0.001875  Loss: -0.6863  Acc@1: 68.7500 (65.4522)  Acc@5: 93.7500 (91.7545)  time: 0.6855  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3210/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.5048  Acc@1: 62.5000 (65.4488)  Acc@5: 87.5000 (91.7452)  time: 0.6860  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3220/4579]  eta: 0:10:06  Lr: 0.001875  Loss: 0.1882  Acc@1: 68.7500 (65.4533)  Acc@5: 87.5000 (91.7417)  time: 0.7122  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3230/4579]  eta: 0:10:03  Lr: 0.001875  Loss: -0.4411  Acc@1: 68.7500 (65.4557)  Acc@5: 93.7500 (91.7421)  time: 0.7131  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [3240/4579]  eta: 0:09:59  Lr: 0.001875  Loss: 0.3895  Acc@1: 62.5000 (65.4312)  Acc@5: 87.5000 (91.7194)  time: 0.6403  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3250/4579]  eta: 0:09:54  Lr: 0.001875  Loss: 0.0017  Acc@1: 62.5000 (65.4337)  Acc@5: 87.5000 (91.7275)  time: 0.4624  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [3260/4579]  eta: 0:09:49  Lr: 0.001875  Loss: 0.0484  Acc@1: 62.5000 (65.4151)  Acc@5: 93.7500 (91.7165)  time: 0.3951  data: 0.0033  max mem: 2500
Train: Epoch[4/5]  [3270/4579]  eta: 0:09:45  Lr: 0.001875  Loss: 0.0010  Acc@1: 56.2500 (65.4024)  Acc@5: 87.5000 (91.7132)  time: 0.4728  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3280/4579]  eta: 0:09:40  Lr: 0.001875  Loss: -0.2357  Acc@1: 62.5000 (65.4031)  Acc@5: 93.7500 (91.7175)  time: 0.4312  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3290/4579]  eta: 0:09:35  Lr: 0.001875  Loss: -0.1013  Acc@1: 62.5000 (65.3981)  Acc@5: 93.7500 (91.7141)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3300/4579]  eta: 0:09:30  Lr: 0.001875  Loss: -0.2386  Acc@1: 68.7500 (65.4082)  Acc@5: 93.7500 (91.7222)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3310/4579]  eta: 0:09:26  Lr: 0.001875  Loss: -0.1019  Acc@1: 68.7500 (65.4145)  Acc@5: 93.7500 (91.7246)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3320/4579]  eta: 0:09:21  Lr: 0.001875  Loss: -0.3202  Acc@1: 68.7500 (65.4227)  Acc@5: 93.7500 (91.7250)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3330/4579]  eta: 0:09:16  Lr: 0.001875  Loss: -0.0634  Acc@1: 68.7500 (65.4252)  Acc@5: 87.5000 (91.7161)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3340/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.2286  Acc@1: 68.7500 (65.4370)  Acc@5: 87.5000 (91.7222)  time: 0.3578  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3350/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.3107  Acc@1: 68.7500 (65.4338)  Acc@5: 87.5000 (91.7170)  time: 0.3588  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3360/4579]  eta: 0:09:02  Lr: 0.001875  Loss: -0.0334  Acc@1: 68.7500 (65.4381)  Acc@5: 87.5000 (91.7082)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3370/4579]  eta: 0:08:57  Lr: 0.001875  Loss: 0.4373  Acc@1: 68.7500 (65.4368)  Acc@5: 93.7500 (91.7087)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3380/4579]  eta: 0:08:53  Lr: 0.001875  Loss: -0.5807  Acc@1: 68.7500 (65.4318)  Acc@5: 93.7500 (91.7092)  time: 0.4829  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3390/4579]  eta: 0:08:50  Lr: 0.001875  Loss: 0.1983  Acc@1: 68.7500 (65.4398)  Acc@5: 93.7500 (91.7152)  time: 0.6765  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [3400/4579]  eta: 0:08:46  Lr: 0.001875  Loss: 0.0274  Acc@1: 62.5000 (65.4274)  Acc@5: 93.7500 (91.7120)  time: 0.7446  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [3410/4579]  eta: 0:08:43  Lr: 0.001875  Loss: -0.4162  Acc@1: 62.5000 (65.4225)  Acc@5: 93.7500 (91.7216)  time: 0.7452  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3420/4579]  eta: 0:08:39  Lr: 0.001875  Loss: -0.2506  Acc@1: 68.7500 (65.4323)  Acc@5: 93.7500 (91.7276)  time: 0.7464  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3430/4579]  eta: 0:08:36  Lr: 0.001875  Loss: -0.3033  Acc@1: 68.7500 (65.4182)  Acc@5: 93.7500 (91.7207)  time: 0.7481  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3440/4579]  eta: 0:08:32  Lr: 0.001875  Loss: -0.3554  Acc@1: 68.7500 (65.4207)  Acc@5: 93.7500 (91.7248)  time: 0.7464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3450/4579]  eta: 0:08:29  Lr: 0.001875  Loss: 0.1733  Acc@1: 62.5000 (65.4176)  Acc@5: 93.7500 (91.7234)  time: 0.7442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3460/4579]  eta: 0:08:25  Lr: 0.001875  Loss: -0.4897  Acc@1: 62.5000 (65.4146)  Acc@5: 87.5000 (91.7220)  time: 0.7434  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3470/4579]  eta: 0:08:21  Lr: 0.001875  Loss: 0.4052  Acc@1: 62.5000 (65.3936)  Acc@5: 93.7500 (91.7225)  time: 0.7394  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3480/4579]  eta: 0:08:18  Lr: 0.001875  Loss: -0.4766  Acc@1: 62.5000 (65.4015)  Acc@5: 87.5000 (91.7175)  time: 0.7382  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [3490/4579]  eta: 0:08:14  Lr: 0.001875  Loss: 0.4047  Acc@1: 62.5000 (65.4146)  Acc@5: 87.5000 (91.7216)  time: 0.7418  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [3500/4579]  eta: 0:08:11  Lr: 0.001875  Loss: -0.1634  Acc@1: 68.7500 (65.4331)  Acc@5: 93.7500 (91.7291)  time: 0.7416  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3510/4579]  eta: 0:08:07  Lr: 0.001875  Loss: 0.0245  Acc@1: 68.7500 (65.4425)  Acc@5: 93.7500 (91.7331)  time: 0.7419  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3520/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6047  Acc@1: 68.7500 (65.4466)  Acc@5: 93.7500 (91.7389)  time: 0.7429  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3530/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6002  Acc@1: 68.7500 (65.4560)  Acc@5: 93.7500 (91.7428)  time: 0.7402  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3540/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 0.0765  Acc@1: 62.5000 (65.4458)  Acc@5: 93.7500 (91.7308)  time: 0.7420  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3550/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.6299  Acc@1: 68.7500 (65.4657)  Acc@5: 93.7500 (91.7470)  time: 0.7414  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3560/4579]  eta: 0:07:48  Lr: 0.001875  Loss: -0.3348  Acc@1: 68.7500 (65.4644)  Acc@5: 93.7500 (91.7386)  time: 0.7351  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [3570/4579]  eta: 0:07:44  Lr: 0.001875  Loss: -0.3279  Acc@1: 62.5000 (65.4631)  Acc@5: 87.5000 (91.7338)  time: 0.7329  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [3580/4579]  eta: 0:07:40  Lr: 0.001875  Loss: -0.7190  Acc@1: 68.7500 (65.4723)  Acc@5: 93.7500 (91.7446)  time: 0.7323  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3590/4579]  eta: 0:07:37  Lr: 0.001875  Loss: -0.5050  Acc@1: 68.7500 (65.4971)  Acc@5: 93.7500 (91.7502)  time: 0.7334  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3600/4579]  eta: 0:07:33  Lr: 0.001875  Loss: -0.1044  Acc@1: 62.5000 (65.4801)  Acc@5: 93.7500 (91.7471)  time: 0.7319  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3610/4579]  eta: 0:07:29  Lr: 0.001875  Loss: -0.3273  Acc@1: 62.5000 (65.4822)  Acc@5: 93.7500 (91.7509)  time: 0.7326  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3620/4579]  eta: 0:07:25  Lr: 0.001875  Loss: -0.8726  Acc@1: 68.7500 (65.4878)  Acc@5: 93.7500 (91.7581)  time: 0.7329  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3630/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.7850  Acc@1: 62.5000 (65.4899)  Acc@5: 93.7500 (91.7619)  time: 0.7298  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3640/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.1893  Acc@1: 68.7500 (65.5126)  Acc@5: 93.7500 (91.7691)  time: 0.7296  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3650/4579]  eta: 0:07:13  Lr: 0.001875  Loss: 0.0511  Acc@1: 68.7500 (65.5026)  Acc@5: 93.7500 (91.7660)  time: 0.7302  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3660/4579]  eta: 0:07:09  Lr: 0.001875  Loss: -0.2848  Acc@1: 62.5000 (65.5132)  Acc@5: 93.7500 (91.7697)  time: 0.7282  data: 0.0037  max mem: 2500
Train: Epoch[4/5]  [3670/4579]  eta: 0:07:05  Lr: 0.001875  Loss: -0.0111  Acc@1: 68.7500 (65.5254)  Acc@5: 93.7500 (91.7665)  time: 0.6974  data: 0.0032  max mem: 2500
Train: Epoch[4/5]  [3680/4579]  eta: 0:07:01  Lr: 0.001875  Loss: -0.6605  Acc@1: 68.7500 (65.5376)  Acc@5: 93.7500 (91.7685)  time: 0.6709  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3690/4579]  eta: 0:06:57  Lr: 0.001875  Loss: -0.1441  Acc@1: 68.7500 (65.5412)  Acc@5: 93.7500 (91.7790)  time: 0.7019  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [3700/4579]  eta: 0:06:52  Lr: 0.001875  Loss: -0.4218  Acc@1: 68.7500 (65.5532)  Acc@5: 93.7500 (91.7809)  time: 0.7264  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3710/4579]  eta: 0:06:48  Lr: 0.001875  Loss: 0.2327  Acc@1: 68.7500 (65.5484)  Acc@5: 93.7500 (91.7829)  time: 0.7251  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3720/4579]  eta: 0:06:43  Lr: 0.001875  Loss: -0.1126  Acc@1: 68.7500 (65.5536)  Acc@5: 93.7500 (91.7831)  time: 0.5521  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3730/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.0633  Acc@1: 62.5000 (65.5371)  Acc@5: 93.7500 (91.7834)  time: 0.4144  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3740/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.7725  Acc@1: 62.5000 (65.5373)  Acc@5: 93.7500 (91.7920)  time: 0.5907  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3750/4579]  eta: 0:06:30  Lr: 0.001875  Loss: -0.1387  Acc@1: 62.5000 (65.5275)  Acc@5: 93.7500 (91.7955)  time: 0.7246  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3760/4579]  eta: 0:06:26  Lr: 0.001875  Loss: -0.1491  Acc@1: 68.7500 (65.5278)  Acc@5: 93.7500 (91.7858)  time: 0.7201  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3770/4579]  eta: 0:06:22  Lr: 0.001875  Loss: -0.3430  Acc@1: 68.7500 (65.5446)  Acc@5: 87.5000 (91.7893)  time: 0.7227  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [3780/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.4267  Acc@1: 68.7500 (65.5481)  Acc@5: 93.7500 (91.7978)  time: 0.7275  data: 0.0035  max mem: 2500
Train: Epoch[4/5]  [3790/4579]  eta: 0:06:14  Lr: 0.001875  Loss: -0.2884  Acc@1: 68.7500 (65.5450)  Acc@5: 93.7500 (91.8063)  time: 0.7191  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [3800/4579]  eta: 0:06:09  Lr: 0.001875  Loss: 0.4589  Acc@1: 68.7500 (65.5600)  Acc@5: 93.7500 (91.8064)  time: 0.7135  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3810/4579]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5941  Acc@1: 68.7500 (65.5750)  Acc@5: 93.7500 (91.8165)  time: 0.7207  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3820/4579]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4082  Acc@1: 75.0000 (65.5817)  Acc@5: 93.7500 (91.8133)  time: 0.7225  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3830/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.3538  Acc@1: 68.7500 (65.5703)  Acc@5: 87.5000 (91.8102)  time: 0.7198  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3840/4579]  eta: 0:05:52  Lr: 0.001875  Loss: -0.4676  Acc@1: 68.7500 (65.5705)  Acc@5: 87.5000 (91.8088)  time: 0.7183  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3850/4579]  eta: 0:05:48  Lr: 0.001875  Loss: -0.6440  Acc@1: 68.7500 (65.5917)  Acc@5: 93.7500 (91.8138)  time: 0.7180  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3860/4579]  eta: 0:05:44  Lr: 0.001875  Loss: -0.1937  Acc@1: 68.7500 (65.5870)  Acc@5: 93.7500 (91.8043)  time: 0.7157  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3870/4579]  eta: 0:05:39  Lr: 0.001875  Loss: -0.0650  Acc@1: 68.7500 (65.5984)  Acc@5: 87.5000 (91.8012)  time: 0.7167  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3880/4579]  eta: 0:05:35  Lr: 0.001875  Loss: 0.4569  Acc@1: 68.7500 (65.6097)  Acc@5: 93.7500 (91.7998)  time: 0.7194  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3890/4579]  eta: 0:05:31  Lr: 0.001875  Loss: -0.2878  Acc@1: 68.7500 (65.6194)  Acc@5: 93.7500 (91.8032)  time: 0.7175  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [3900/4579]  eta: 0:05:26  Lr: 0.001875  Loss: -0.0520  Acc@1: 68.7500 (65.6210)  Acc@5: 93.7500 (91.8082)  time: 0.7168  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3910/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.2934  Acc@1: 68.7500 (65.6370)  Acc@5: 93.7500 (91.8148)  time: 0.7193  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3920/4579]  eta: 0:05:17  Lr: 0.001875  Loss: -0.6564  Acc@1: 68.7500 (65.6354)  Acc@5: 93.7500 (91.8149)  time: 0.7199  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3930/4579]  eta: 0:05:13  Lr: 0.001875  Loss: -0.5639  Acc@1: 68.7500 (65.6353)  Acc@5: 93.7500 (91.8151)  time: 0.7188  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3940/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.6735  Acc@1: 62.5000 (65.6401)  Acc@5: 93.7500 (91.8168)  time: 0.7139  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3950/4579]  eta: 0:05:04  Lr: 0.001875  Loss: 0.3803  Acc@1: 68.7500 (65.6448)  Acc@5: 93.7500 (91.8075)  time: 0.7145  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3960/4579]  eta: 0:05:00  Lr: 0.001875  Loss: -0.4167  Acc@1: 62.5000 (65.6463)  Acc@5: 93.7500 (91.8171)  time: 0.7235  data: 0.0039  max mem: 2500
Train: Epoch[4/5]  [3970/4579]  eta: 0:04:55  Lr: 0.001875  Loss: -0.0499  Acc@1: 62.5000 (65.6494)  Acc@5: 93.7500 (91.8235)  time: 0.7225  data: 0.0041  max mem: 2500
Train: Epoch[4/5]  [3980/4579]  eta: 0:04:51  Lr: 0.001875  Loss: 0.1516  Acc@1: 68.7500 (65.6556)  Acc@5: 93.7500 (91.8268)  time: 0.7132  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [3990/4579]  eta: 0:04:46  Lr: 0.001875  Loss: -0.5240  Acc@1: 62.5000 (65.6477)  Acc@5: 93.7500 (91.8238)  time: 0.7161  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [4000/4579]  eta: 0:04:41  Lr: 0.001875  Loss: 0.0298  Acc@1: 62.5000 (65.6367)  Acc@5: 93.7500 (91.8270)  time: 0.7197  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4010/4579]  eta: 0:04:37  Lr: 0.001875  Loss: -0.3356  Acc@1: 62.5000 (65.6336)  Acc@5: 93.7500 (91.8256)  time: 0.7121  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4020/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.3999  Acc@1: 62.5000 (65.6351)  Acc@5: 93.7500 (91.8351)  time: 0.7162  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4030/4579]  eta: 0:04:28  Lr: 0.001875  Loss: -0.4976  Acc@1: 68.7500 (65.6537)  Acc@5: 93.7500 (91.8445)  time: 0.7189  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4040/4579]  eta: 0:04:23  Lr: 0.001875  Loss: 0.2784  Acc@1: 62.5000 (65.6459)  Acc@5: 93.7500 (91.8383)  time: 0.7164  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4050/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.1567  Acc@1: 62.5000 (65.6458)  Acc@5: 87.5000 (91.8307)  time: 0.6751  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4060/4579]  eta: 0:04:14  Lr: 0.001875  Loss: 0.0514  Acc@1: 68.7500 (65.6504)  Acc@5: 87.5000 (91.8231)  time: 0.6672  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [4070/4579]  eta: 0:04:09  Lr: 0.001875  Loss: 0.3913  Acc@1: 62.5000 (65.6427)  Acc@5: 93.7500 (91.8171)  time: 0.7073  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4080/4579]  eta: 0:04:05  Lr: 0.001875  Loss: 0.2897  Acc@1: 62.5000 (65.6457)  Acc@5: 93.7500 (91.8280)  time: 0.7126  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4090/4579]  eta: 0:04:00  Lr: 0.001875  Loss: -0.1559  Acc@1: 68.7500 (65.6517)  Acc@5: 93.7500 (91.8312)  time: 0.6905  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [4100/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.5510  Acc@1: 62.5000 (65.6578)  Acc@5: 93.7500 (91.8328)  time: 0.6894  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4110/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.2541  Acc@1: 62.5000 (65.6592)  Acc@5: 87.5000 (91.8238)  time: 0.7125  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4120/4579]  eta: 0:03:46  Lr: 0.001875  Loss: -0.8949  Acc@1: 62.5000 (65.6606)  Acc@5: 87.5000 (91.8254)  time: 0.7115  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4130/4579]  eta: 0:03:41  Lr: 0.001875  Loss: 0.1667  Acc@1: 62.5000 (65.6621)  Acc@5: 93.7500 (91.8180)  time: 0.6670  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4140/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.2941  Acc@1: 62.5000 (65.6635)  Acc@5: 93.7500 (91.8241)  time: 0.4863  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4150/4579]  eta: 0:03:31  Lr: 0.001875  Loss: -0.0888  Acc@1: 68.7500 (65.6649)  Acc@5: 93.7500 (91.8212)  time: 0.4626  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4160/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.3718  Acc@1: 68.7500 (65.6573)  Acc@5: 87.5000 (91.8229)  time: 0.6510  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4170/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.3172  Acc@1: 62.5000 (65.6572)  Acc@5: 87.5000 (91.8230)  time: 0.7175  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [4180/4579]  eta: 0:03:17  Lr: 0.001875  Loss: -0.4911  Acc@1: 68.7500 (65.6661)  Acc@5: 93.7500 (91.8291)  time: 0.7168  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4190/4579]  eta: 0:03:12  Lr: 0.001875  Loss: -0.6074  Acc@1: 62.5000 (65.6615)  Acc@5: 93.7500 (91.8277)  time: 0.7160  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4200/4579]  eta: 0:03:08  Lr: 0.001875  Loss: -0.2925  Acc@1: 62.5000 (65.6614)  Acc@5: 93.7500 (91.8278)  time: 0.7145  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4210/4579]  eta: 0:03:03  Lr: 0.001875  Loss: -0.4860  Acc@1: 62.5000 (65.6480)  Acc@5: 93.7500 (91.8235)  time: 0.7202  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:58  Lr: 0.001875  Loss: 0.1686  Acc@1: 62.5000 (65.6450)  Acc@5: 93.7500 (91.8192)  time: 0.7166  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:53  Lr: 0.001875  Loss: -0.3895  Acc@1: 62.5000 (65.6479)  Acc@5: 93.7500 (91.8193)  time: 0.7177  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4240/4579]  eta: 0:02:48  Lr: 0.001875  Loss: -0.0300  Acc@1: 62.5000 (65.6390)  Acc@5: 93.7500 (91.8180)  time: 0.7140  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4250/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.1683  Acc@1: 62.5000 (65.6404)  Acc@5: 93.7500 (91.8225)  time: 0.7143  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4260/4579]  eta: 0:02:39  Lr: 0.001875  Loss: -0.2358  Acc@1: 62.5000 (65.6375)  Acc@5: 93.7500 (91.8241)  time: 0.7152  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4270/4579]  eta: 0:02:34  Lr: 0.001875  Loss: -0.3423  Acc@1: 62.5000 (65.6374)  Acc@5: 93.7500 (91.8184)  time: 0.7134  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4280/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.3318  Acc@1: 62.5000 (65.6359)  Acc@5: 87.5000 (91.8200)  time: 0.7170  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4290/4579]  eta: 0:02:24  Lr: 0.001875  Loss: -0.0977  Acc@1: 62.5000 (65.6316)  Acc@5: 87.5000 (91.8113)  time: 0.7185  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4300/4579]  eta: 0:02:19  Lr: 0.001875  Loss: 0.2085  Acc@1: 62.5000 (65.6359)  Acc@5: 87.5000 (91.8100)  time: 0.7147  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4310/4579]  eta: 0:02:14  Lr: 0.001875  Loss: -0.1472  Acc@1: 62.5000 (65.6228)  Acc@5: 87.5000 (91.8044)  time: 0.7113  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4320/4579]  eta: 0:02:10  Lr: 0.001875  Loss: -0.5331  Acc@1: 62.5000 (65.6257)  Acc@5: 87.5000 (91.8002)  time: 0.7180  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4330/4579]  eta: 0:02:05  Lr: 0.001875  Loss: 0.2664  Acc@1: 68.7500 (65.6243)  Acc@5: 87.5000 (91.7961)  time: 0.7210  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4340/4579]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0822  Acc@1: 62.5000 (65.6214)  Acc@5: 93.7500 (91.7948)  time: 0.7203  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:55  Lr: 0.001875  Loss: 0.0918  Acc@1: 68.7500 (65.6286)  Acc@5: 93.7500 (91.8036)  time: 0.7153  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.0847  Acc@1: 68.7500 (65.6257)  Acc@5: 93.7500 (91.8023)  time: 0.7162  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:45  Lr: 0.001875  Loss: -0.3554  Acc@1: 62.5000 (65.6229)  Acc@5: 93.7500 (91.8011)  time: 0.6987  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:40  Lr: 0.001875  Loss: -0.4986  Acc@1: 68.7500 (65.6314)  Acc@5: 93.7500 (91.7984)  time: 0.6919  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5536  Acc@1: 68.7500 (65.6385)  Acc@5: 93.7500 (91.8000)  time: 0.7167  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.7982  Acc@1: 68.7500 (65.6371)  Acc@5: 93.7500 (91.7959)  time: 0.7246  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4410/4579]  eta: 0:01:25  Lr: 0.001875  Loss: -0.0895  Acc@1: 62.5000 (65.6300)  Acc@5: 93.7500 (91.7975)  time: 0.7228  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4420/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.4241  Acc@1: 62.5000 (65.6257)  Acc@5: 93.7500 (91.7977)  time: 0.7193  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4430/4579]  eta: 0:01:15  Lr: 0.001875  Loss: 0.0840  Acc@1: 62.5000 (65.6285)  Acc@5: 93.7500 (91.7964)  time: 0.7078  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4440/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.0241  Acc@1: 62.5000 (65.6187)  Acc@5: 93.7500 (91.7952)  time: 0.7013  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4450/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 0.1530  Acc@1: 62.5000 (65.6173)  Acc@5: 87.5000 (91.7926)  time: 0.7032  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4460/4579]  eta: 0:01:00  Lr: 0.001875  Loss: -0.1740  Acc@1: 68.7500 (65.6355)  Acc@5: 93.7500 (91.7970)  time: 0.7152  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.3644  Acc@1: 68.7500 (65.6397)  Acc@5: 93.7500 (91.7999)  time: 0.6720  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6748  Acc@1: 68.7500 (65.6592)  Acc@5: 93.7500 (91.8057)  time: 0.6642  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.0903  Acc@1: 68.7500 (65.6661)  Acc@5: 93.7500 (91.8031)  time: 0.7132  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3277  Acc@1: 68.7500 (65.6701)  Acc@5: 87.5000 (91.8018)  time: 0.7129  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:35  Lr: 0.001875  Loss: -0.3225  Acc@1: 68.7500 (65.6659)  Acc@5: 93.7500 (91.8048)  time: 0.6868  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:30  Lr: 0.001875  Loss: -0.0181  Acc@1: 68.7500 (65.6699)  Acc@5: 87.5000 (91.8008)  time: 0.6879  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:25  Lr: 0.001875  Loss: 0.0024  Acc@1: 68.7500 (65.6740)  Acc@5: 87.5000 (91.7954)  time: 0.6045  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:19  Lr: 0.001875  Loss: -0.4621  Acc@1: 68.7500 (65.6752)  Acc@5: 93.7500 (91.7956)  time: 0.4276  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:14  Lr: 0.001875  Loss: -0.0048  Acc@1: 68.7500 (65.6820)  Acc@5: 93.7500 (91.7903)  time: 0.3594  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:09  Lr: 0.001875  Loss: -0.1156  Acc@1: 68.7500 (65.6860)  Acc@5: 93.7500 (91.7891)  time: 0.3590  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:04  Lr: 0.001875  Loss: 0.5032  Acc@1: 62.5000 (65.6776)  Acc@5: 93.7500 (91.7906)  time: 0.3644  data: 0.0051  max mem: 2500
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1819  Acc@1: 62.5000 (65.6715)  Acc@5: 88.8889 (91.7810)  time: 0.3562  data: 0.0049  max mem: 2500
Train: Epoch[4/5] Total time: 0:38:54 (0.5098 s / it)
{0: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1819  Acc@1: 62.5000 (65.6715)  Acc@5: 88.8889 (91.7810)
Train: Epoch[5/5]  [   0/4579]  eta: 1:14:10  Lr: 0.001875  Loss: -0.3332  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.9718  data: 0.6146  max mem: 2500
Train: Epoch[5/5]  [  10/4579]  eta: 0:31:27  Lr: 0.001875  Loss: -0.5184  Acc@1: 62.5000 (61.3636)  Acc@5: 93.7500 (90.9091)  time: 0.4132  data: 0.0575  max mem: 2500
Train: Epoch[5/5]  [  20/4579]  eta: 0:29:16  Lr: 0.001875  Loss: 0.1218  Acc@1: 56.2500 (61.9048)  Acc@5: 93.7500 (91.3690)  time: 0.3559  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [  30/4579]  eta: 0:28:38  Lr: 0.001875  Loss: -0.4987  Acc@1: 62.5000 (63.5081)  Acc@5: 93.7500 (91.7339)  time: 0.3582  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [  40/4579]  eta: 0:28:34  Lr: 0.001875  Loss: -0.5458  Acc@1: 68.7500 (65.3963)  Acc@5: 93.7500 (91.9207)  time: 0.3701  data: 0.0026  max mem: 2500
Train: Epoch[5/5]  [  50/4579]  eta: 0:28:06  Lr: 0.001875  Loss: -0.6175  Acc@1: 68.7500 (66.4216)  Acc@5: 93.7500 (92.4020)  time: 0.3643  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [  60/4579]  eta: 0:27:52  Lr: 0.001875  Loss: 0.0479  Acc@1: 68.7500 (66.3934)  Acc@5: 93.7500 (92.1107)  time: 0.3545  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [  70/4579]  eta: 0:31:07  Lr: 0.001875  Loss: -0.0253  Acc@1: 68.7500 (66.2852)  Acc@5: 93.7500 (91.9894)  time: 0.5204  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [  80/4579]  eta: 0:34:05  Lr: 0.001875  Loss: -0.4470  Acc@1: 68.7500 (66.8981)  Acc@5: 93.7500 (92.2068)  time: 0.7123  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [  90/4579]  eta: 0:36:26  Lr: 0.001875  Loss: -0.2086  Acc@1: 68.7500 (66.3462)  Acc@5: 93.7500 (92.3764)  time: 0.7457  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 100/4579]  eta: 0:38:15  Lr: 0.001875  Loss: -0.0132  Acc@1: 62.5000 (66.4604)  Acc@5: 93.7500 (92.2030)  time: 0.7466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 110/4579]  eta: 0:39:45  Lr: 0.001875  Loss: -0.6657  Acc@1: 75.0000 (67.0045)  Acc@5: 93.7500 (92.2860)  time: 0.7467  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 120/4579]  eta: 0:40:59  Lr: 0.001875  Loss: -0.4262  Acc@1: 68.7500 (66.8905)  Acc@5: 93.7500 (92.2521)  time: 0.7494  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 130/4579]  eta: 0:42:03  Lr: 0.001875  Loss: -0.3052  Acc@1: 62.5000 (66.5076)  Acc@5: 93.7500 (91.9847)  time: 0.7521  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [ 140/4579]  eta: 0:42:56  Lr: 0.001875  Loss: -0.1175  Acc@1: 62.5000 (66.4450)  Acc@5: 93.7500 (92.1099)  time: 0.7542  data: 0.0041  max mem: 2500
Train: Epoch[5/5]  [ 150/4579]  eta: 0:43:38  Lr: 0.001875  Loss: 0.4452  Acc@1: 56.2500 (66.0596)  Acc@5: 93.7500 (92.1772)  time: 0.7485  data: 0.0034  max mem: 2500
Train: Epoch[5/5]  [ 160/4579]  eta: 0:44:13  Lr: 0.001875  Loss: -0.4018  Acc@1: 62.5000 (66.0326)  Acc@5: 93.7500 (92.1196)  time: 0.7428  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 170/4579]  eta: 0:44:45  Lr: 0.001875  Loss: -0.5029  Acc@1: 62.5000 (66.2646)  Acc@5: 93.7500 (92.1053)  time: 0.7438  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 180/4579]  eta: 0:45:10  Lr: 0.001875  Loss: 0.1920  Acc@1: 62.5000 (66.0221)  Acc@5: 87.5000 (91.8508)  time: 0.7417  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 190/4579]  eta: 0:45:33  Lr: 0.001875  Loss: 0.5742  Acc@1: 62.5000 (66.0995)  Acc@5: 87.5000 (91.8848)  time: 0.7404  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 200/4579]  eta: 0:45:53  Lr: 0.001875  Loss: -0.1552  Acc@1: 62.5000 (65.9515)  Acc@5: 93.7500 (91.7910)  time: 0.7427  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 210/4579]  eta: 0:46:10  Lr: 0.001875  Loss: 0.1213  Acc@1: 62.5000 (65.7879)  Acc@5: 93.7500 (91.7358)  time: 0.7419  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 220/4579]  eta: 0:46:25  Lr: 0.001875  Loss: -0.3192  Acc@1: 62.5000 (65.7240)  Acc@5: 87.5000 (91.6572)  time: 0.7424  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 230/4579]  eta: 0:46:38  Lr: 0.001875  Loss: 0.2229  Acc@1: 62.5000 (65.7738)  Acc@5: 93.7500 (91.6667)  time: 0.7436  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 240/4579]  eta: 0:46:48  Lr: 0.001875  Loss: -0.4079  Acc@1: 68.7500 (65.9232)  Acc@5: 93.7500 (91.6494)  time: 0.7391  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 250/4579]  eta: 0:46:57  Lr: 0.001875  Loss: -0.3521  Acc@1: 68.7500 (66.1604)  Acc@5: 93.7500 (91.8078)  time: 0.7364  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 260/4579]  eta: 0:47:04  Lr: 0.001875  Loss: -0.3582  Acc@1: 68.7500 (66.2356)  Acc@5: 93.7500 (91.8103)  time: 0.7356  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 270/4579]  eta: 0:47:11  Lr: 0.001875  Loss: -0.6856  Acc@1: 68.7500 (66.3745)  Acc@5: 93.7500 (91.8589)  time: 0.7334  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 280/4579]  eta: 0:47:16  Lr: 0.001875  Loss: -0.3418  Acc@1: 68.7500 (66.2811)  Acc@5: 93.7500 (91.7927)  time: 0.7344  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 290/4579]  eta: 0:47:20  Lr: 0.001875  Loss: -0.5284  Acc@1: 62.5000 (66.2586)  Acc@5: 93.7500 (91.8600)  time: 0.7347  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 300/4579]  eta: 0:47:25  Lr: 0.001875  Loss: -0.2113  Acc@1: 68.7500 (66.4452)  Acc@5: 93.7500 (92.0266)  time: 0.7366  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 310/4579]  eta: 0:47:26  Lr: 0.001875  Loss: -0.5117  Acc@1: 68.7500 (66.5394)  Acc@5: 93.7500 (92.0016)  time: 0.7322  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 320/4579]  eta: 0:47:28  Lr: 0.001875  Loss: -0.0795  Acc@1: 68.7500 (66.5693)  Acc@5: 87.5000 (91.8808)  time: 0.7293  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 330/4579]  eta: 0:47:30  Lr: 0.001875  Loss: 0.2282  Acc@1: 68.7500 (66.5030)  Acc@5: 87.5000 (91.8618)  time: 0.7341  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 340/4579]  eta: 0:47:30  Lr: 0.001875  Loss: -0.7525  Acc@1: 62.5000 (66.3490)  Acc@5: 93.7500 (91.8255)  time: 0.7295  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [ 350/4579]  eta: 0:47:31  Lr: 0.001875  Loss: -0.0704  Acc@1: 62.5000 (66.2393)  Acc@5: 93.7500 (91.7913)  time: 0.7287  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 360/4579]  eta: 0:47:24  Lr: 0.001875  Loss: -0.2625  Acc@1: 68.7500 (66.2569)  Acc@5: 93.7500 (91.7071)  time: 0.7036  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 370/4579]  eta: 0:47:23  Lr: 0.001875  Loss: -0.2428  Acc@1: 62.5000 (66.0377)  Acc@5: 87.5000 (91.6779)  time: 0.6982  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 380/4579]  eta: 0:47:21  Lr: 0.001875  Loss: -0.0976  Acc@1: 62.5000 (66.1089)  Acc@5: 93.7500 (91.6831)  time: 0.7222  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 390/4579]  eta: 0:47:19  Lr: 0.001875  Loss: -0.1444  Acc@1: 62.5000 (65.8728)  Acc@5: 93.7500 (91.6560)  time: 0.7234  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 400/4579]  eta: 0:47:04  Lr: 0.001875  Loss: -0.9983  Acc@1: 62.5000 (65.9133)  Acc@5: 93.7500 (91.6771)  time: 0.6593  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 410/4579]  eta: 0:46:25  Lr: 0.001875  Loss: -0.0815  Acc@1: 68.7500 (65.9672)  Acc@5: 93.7500 (91.6058)  time: 0.4749  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 420/4579]  eta: 0:46:11  Lr: 0.001875  Loss: -0.5721  Acc@1: 68.7500 (65.9293)  Acc@5: 87.5000 (91.5677)  time: 0.4765  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 430/4579]  eta: 0:46:10  Lr: 0.001875  Loss: -0.6624  Acc@1: 68.7500 (66.0818)  Acc@5: 93.7500 (91.5748)  time: 0.6638  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 440/4579]  eta: 0:46:09  Lr: 0.001875  Loss: -0.0195  Acc@1: 68.7500 (66.0431)  Acc@5: 93.7500 (91.5816)  time: 0.7278  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 450/4579]  eta: 0:46:07  Lr: 0.001875  Loss: -0.5828  Acc@1: 68.7500 (66.2278)  Acc@5: 93.7500 (91.6574)  time: 0.7241  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 460/4579]  eta: 0:46:06  Lr: 0.001875  Loss: -0.4123  Acc@1: 68.7500 (66.2419)  Acc@5: 93.7500 (91.6486)  time: 0.7254  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 470/4579]  eta: 0:46:04  Lr: 0.001875  Loss: -0.3881  Acc@1: 62.5000 (66.2022)  Acc@5: 93.7500 (91.6269)  time: 0.7272  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 480/4579]  eta: 0:46:01  Lr: 0.001875  Loss: 0.2175  Acc@1: 62.5000 (66.1512)  Acc@5: 93.7500 (91.6450)  time: 0.7248  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 490/4579]  eta: 0:45:59  Lr: 0.001875  Loss: 0.0712  Acc@1: 62.5000 (66.1278)  Acc@5: 93.7500 (91.6242)  time: 0.7209  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 500/4579]  eta: 0:45:56  Lr: 0.001875  Loss: -0.2456  Acc@1: 68.7500 (66.0679)  Acc@5: 87.5000 (91.5793)  time: 0.7208  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 510/4579]  eta: 0:45:53  Lr: 0.001875  Loss: -0.1654  Acc@1: 56.2500 (65.8880)  Acc@5: 87.5000 (91.5362)  time: 0.7240  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 520/4579]  eta: 0:45:50  Lr: 0.001875  Loss: -0.3404  Acc@1: 56.2500 (65.8229)  Acc@5: 93.7500 (91.5787)  time: 0.7239  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 530/4579]  eta: 0:45:46  Lr: 0.001875  Loss: 0.2681  Acc@1: 56.2500 (65.7721)  Acc@5: 93.7500 (91.5607)  time: 0.7220  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 540/4579]  eta: 0:45:42  Lr: 0.001875  Loss: -0.3190  Acc@1: 56.2500 (65.6192)  Acc@5: 87.5000 (91.5434)  time: 0.7188  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 550/4579]  eta: 0:45:38  Lr: 0.001875  Loss: -0.5039  Acc@1: 62.5000 (65.5966)  Acc@5: 87.5000 (91.5608)  time: 0.7174  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 560/4579]  eta: 0:45:34  Lr: 0.001875  Loss: -0.3536  Acc@1: 68.7500 (65.6306)  Acc@5: 93.7500 (91.5998)  time: 0.7155  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 570/4579]  eta: 0:45:30  Lr: 0.001875  Loss: -0.1941  Acc@1: 62.5000 (65.5867)  Acc@5: 93.7500 (91.6265)  time: 0.7166  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 580/4579]  eta: 0:45:26  Lr: 0.001875  Loss: -0.5334  Acc@1: 62.5000 (65.5228)  Acc@5: 93.7500 (91.6201)  time: 0.7201  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 590/4579]  eta: 0:45:21  Lr: 0.001875  Loss: -0.1699  Acc@1: 56.2500 (65.3342)  Acc@5: 93.7500 (91.5926)  time: 0.7179  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 600/4579]  eta: 0:45:17  Lr: 0.001875  Loss: -0.3802  Acc@1: 56.2500 (65.3702)  Acc@5: 93.7500 (91.5245)  time: 0.7168  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 610/4579]  eta: 0:45:12  Lr: 0.001875  Loss: -0.3875  Acc@1: 68.7500 (65.3642)  Acc@5: 87.5000 (91.5098)  time: 0.7188  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 620/4579]  eta: 0:45:08  Lr: 0.001875  Loss: -0.7372  Acc@1: 62.5000 (65.3885)  Acc@5: 93.7500 (91.5258)  time: 0.7220  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 630/4579]  eta: 0:45:04  Lr: 0.001875  Loss: -0.1968  Acc@1: 68.7500 (65.3724)  Acc@5: 93.7500 (91.5313)  time: 0.7225  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 640/4579]  eta: 0:44:59  Lr: 0.001875  Loss: 0.1954  Acc@1: 68.7500 (65.4641)  Acc@5: 93.7500 (91.5757)  time: 0.7188  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 650/4579]  eta: 0:44:54  Lr: 0.001875  Loss: -0.2814  Acc@1: 75.0000 (65.5338)  Acc@5: 93.7500 (91.6091)  time: 0.7188  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 660/4579]  eta: 0:44:50  Lr: 0.001875  Loss: -0.3478  Acc@1: 68.7500 (65.5352)  Acc@5: 93.7500 (91.5847)  time: 0.7242  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 670/4579]  eta: 0:44:44  Lr: 0.001875  Loss: -0.2523  Acc@1: 68.7500 (65.6297)  Acc@5: 93.7500 (91.5984)  time: 0.7209  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 680/4579]  eta: 0:44:39  Lr: 0.001875  Loss: -0.5460  Acc@1: 68.7500 (65.6296)  Acc@5: 93.7500 (91.5565)  time: 0.7182  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 690/4579]  eta: 0:44:34  Lr: 0.001875  Loss: -0.1187  Acc@1: 62.5000 (65.5843)  Acc@5: 87.5000 (91.4797)  time: 0.7203  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 700/4579]  eta: 0:44:29  Lr: 0.001875  Loss: -0.0255  Acc@1: 62.5000 (65.5938)  Acc@5: 87.5000 (91.5121)  time: 0.7127  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 710/4579]  eta: 0:44:23  Lr: 0.001875  Loss: -0.4438  Acc@1: 62.5000 (65.5503)  Acc@5: 93.7500 (91.5172)  time: 0.7078  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 720/4579]  eta: 0:44:17  Lr: 0.001875  Loss: 0.0173  Acc@1: 62.5000 (65.5340)  Acc@5: 93.7500 (91.5222)  time: 0.7094  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 730/4579]  eta: 0:44:08  Lr: 0.001875  Loss: 0.0199  Acc@1: 62.5000 (65.5523)  Acc@5: 93.7500 (91.5185)  time: 0.6800  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 740/4579]  eta: 0:44:03  Lr: 0.001875  Loss: -0.5257  Acc@1: 68.7500 (65.6461)  Acc@5: 93.7500 (91.5570)  time: 0.6824  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 750/4579]  eta: 0:43:57  Lr: 0.001875  Loss: -0.1992  Acc@1: 68.7500 (65.6625)  Acc@5: 93.7500 (91.5779)  time: 0.7138  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 760/4579]  eta: 0:43:51  Lr: 0.001875  Loss: 0.0863  Acc@1: 62.5000 (65.6784)  Acc@5: 93.7500 (91.5900)  time: 0.7117  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 770/4579]  eta: 0:43:43  Lr: 0.001875  Loss: -0.6634  Acc@1: 62.5000 (65.6939)  Acc@5: 93.7500 (91.6099)  time: 0.6910  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 780/4579]  eta: 0:43:37  Lr: 0.001875  Loss: 0.2567  Acc@1: 68.7500 (65.7730)  Acc@5: 93.7500 (91.6213)  time: 0.6810  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 790/4579]  eta: 0:43:31  Lr: 0.001875  Loss: -0.1432  Acc@1: 68.7500 (65.7396)  Acc@5: 93.7500 (91.6008)  time: 0.7002  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 800/4579]  eta: 0:43:25  Lr: 0.001875  Loss: 0.2995  Acc@1: 62.5000 (65.7303)  Acc@5: 93.7500 (91.6120)  time: 0.7103  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 810/4579]  eta: 0:43:19  Lr: 0.001875  Loss: -0.0625  Acc@1: 62.5000 (65.6751)  Acc@5: 93.7500 (91.5845)  time: 0.7118  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 820/4579]  eta: 0:43:00  Lr: 0.001875  Loss: -0.9722  Acc@1: 62.5000 (65.6897)  Acc@5: 87.5000 (91.5347)  time: 0.5728  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 830/4579]  eta: 0:42:38  Lr: 0.001875  Loss: -0.5928  Acc@1: 68.7500 (65.7040)  Acc@5: 93.7500 (91.5539)  time: 0.3913  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 840/4579]  eta: 0:42:26  Lr: 0.001875  Loss: -0.8127  Acc@1: 68.7500 (65.7105)  Acc@5: 93.7500 (91.5354)  time: 0.4544  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 850/4579]  eta: 0:42:21  Lr: 0.001875  Loss: -0.5534  Acc@1: 68.7500 (65.7462)  Acc@5: 93.7500 (91.5687)  time: 0.6349  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 860/4579]  eta: 0:42:14  Lr: 0.001875  Loss: -0.4456  Acc@1: 68.7500 (65.7883)  Acc@5: 93.7500 (91.6086)  time: 0.7030  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 870/4579]  eta: 0:42:09  Lr: 0.001875  Loss: -0.4158  Acc@1: 62.5000 (65.7147)  Acc@5: 93.7500 (91.6260)  time: 0.7104  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 880/4579]  eta: 0:42:04  Lr: 0.001875  Loss: 0.6122  Acc@1: 56.2500 (65.6285)  Acc@5: 93.7500 (91.5792)  time: 0.7221  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 890/4579]  eta: 0:41:59  Lr: 0.001875  Loss: -0.6759  Acc@1: 62.5000 (65.6987)  Acc@5: 87.5000 (91.5544)  time: 0.7197  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 900/4579]  eta: 0:41:54  Lr: 0.001875  Loss: 0.3681  Acc@1: 62.5000 (65.6215)  Acc@5: 87.5000 (91.5302)  time: 0.7220  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 910/4579]  eta: 0:41:48  Lr: 0.001875  Loss: -0.4660  Acc@1: 68.7500 (65.6833)  Acc@5: 93.7500 (91.5889)  time: 0.7199  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 920/4579]  eta: 0:41:43  Lr: 0.001875  Loss: -0.1239  Acc@1: 68.7500 (65.6623)  Acc@5: 93.7500 (91.5852)  time: 0.7211  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 930/4579]  eta: 0:41:38  Lr: 0.001875  Loss: -0.3557  Acc@1: 68.7500 (65.7626)  Acc@5: 93.7500 (91.6152)  time: 0.7241  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 940/4579]  eta: 0:41:33  Lr: 0.001875  Loss: -0.0022  Acc@1: 68.7500 (65.7279)  Acc@5: 93.7500 (91.6113)  time: 0.7264  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 950/4579]  eta: 0:41:27  Lr: 0.001875  Loss: 0.3227  Acc@1: 62.5000 (65.6940)  Acc@5: 87.5000 (91.5878)  time: 0.7202  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 960/4579]  eta: 0:41:21  Lr: 0.001875  Loss: -0.8600  Acc@1: 68.7500 (65.7323)  Acc@5: 93.7500 (91.6103)  time: 0.7169  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 970/4579]  eta: 0:41:16  Lr: 0.001875  Loss: -0.6317  Acc@1: 62.5000 (65.7119)  Acc@5: 93.7500 (91.5551)  time: 0.7226  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 980/4579]  eta: 0:41:10  Lr: 0.001875  Loss: -0.4951  Acc@1: 62.5000 (65.7238)  Acc@5: 93.7500 (91.5711)  time: 0.7218  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 990/4579]  eta: 0:41:05  Lr: 0.001875  Loss: -0.1220  Acc@1: 62.5000 (65.6975)  Acc@5: 93.7500 (91.5616)  time: 0.7208  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1000/4579]  eta: 0:40:59  Lr: 0.001875  Loss: -0.2540  Acc@1: 62.5000 (65.6968)  Acc@5: 93.7500 (91.5522)  time: 0.7211  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1010/4579]  eta: 0:40:53  Lr: 0.001875  Loss: -0.1755  Acc@1: 68.7500 (65.7208)  Acc@5: 93.7500 (91.5492)  time: 0.7137  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1020/4579]  eta: 0:40:46  Lr: 0.001875  Loss: -0.4336  Acc@1: 62.5000 (65.7138)  Acc@5: 93.7500 (91.5646)  time: 0.7043  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1030/4579]  eta: 0:40:41  Lr: 0.001875  Loss: 0.0150  Acc@1: 62.5000 (65.7068)  Acc@5: 93.7500 (91.5616)  time: 0.7133  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1040/4579]  eta: 0:40:35  Lr: 0.001875  Loss: 0.2309  Acc@1: 62.5000 (65.6700)  Acc@5: 87.5000 (91.5286)  time: 0.7198  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1050/4579]  eta: 0:40:29  Lr: 0.001875  Loss: -0.7778  Acc@1: 62.5000 (65.6696)  Acc@5: 87.5000 (91.5319)  time: 0.7142  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1060/4579]  eta: 0:40:23  Lr: 0.001875  Loss: 0.0862  Acc@1: 68.7500 (65.7104)  Acc@5: 93.7500 (91.5528)  time: 0.7177  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1070/4579]  eta: 0:40:16  Lr: 0.001875  Loss: -0.4814  Acc@1: 68.7500 (65.7972)  Acc@5: 93.7500 (91.5850)  time: 0.7085  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1080/4579]  eta: 0:40:10  Lr: 0.001875  Loss: -0.2385  Acc@1: 68.7500 (65.8534)  Acc@5: 93.7500 (91.5819)  time: 0.7067  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1090/4579]  eta: 0:40:04  Lr: 0.001875  Loss: -0.5171  Acc@1: 68.7500 (65.8570)  Acc@5: 93.7500 (91.5788)  time: 0.7147  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1100/4579]  eta: 0:39:58  Lr: 0.001875  Loss: -0.3758  Acc@1: 68.7500 (65.8776)  Acc@5: 93.7500 (91.5588)  time: 0.7099  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1110/4579]  eta: 0:39:52  Lr: 0.001875  Loss: -0.2372  Acc@1: 68.7500 (65.9653)  Acc@5: 93.7500 (91.5729)  time: 0.7123  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1120/4579]  eta: 0:39:45  Lr: 0.001875  Loss: -0.6398  Acc@1: 68.7500 (65.9846)  Acc@5: 93.7500 (91.5979)  time: 0.7085  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1130/4579]  eta: 0:39:39  Lr: 0.001875  Loss: 0.0327  Acc@1: 62.5000 (65.9427)  Acc@5: 93.7500 (91.6169)  time: 0.7036  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1140/4579]  eta: 0:39:33  Lr: 0.001875  Loss: -0.4657  Acc@1: 68.7500 (66.0167)  Acc@5: 93.7500 (91.6521)  time: 0.7074  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [1150/4579]  eta: 0:39:26  Lr: 0.001875  Loss: -0.5438  Acc@1: 68.7500 (66.0132)  Acc@5: 93.7500 (91.6594)  time: 0.7101  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1160/4579]  eta: 0:39:18  Lr: 0.001875  Loss: -0.0873  Acc@1: 62.5000 (65.9292)  Acc@5: 87.5000 (91.6398)  time: 0.6723  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1170/4579]  eta: 0:39:12  Lr: 0.001875  Loss: -0.4653  Acc@1: 62.5000 (65.9372)  Acc@5: 87.5000 (91.6364)  time: 0.6746  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1180/4579]  eta: 0:39:05  Lr: 0.001875  Loss: -0.5570  Acc@1: 68.7500 (66.0087)  Acc@5: 93.7500 (91.6543)  time: 0.7147  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1190/4579]  eta: 0:38:59  Lr: 0.001875  Loss: -0.0346  Acc@1: 62.5000 (65.9477)  Acc@5: 93.7500 (91.6719)  time: 0.7147  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1200/4579]  eta: 0:38:52  Lr: 0.001875  Loss: -0.3148  Acc@1: 62.5000 (65.9763)  Acc@5: 93.7500 (91.6840)  time: 0.6964  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1210/4579]  eta: 0:38:46  Lr: 0.001875  Loss: 0.4834  Acc@1: 68.7500 (65.9579)  Acc@5: 93.7500 (91.6908)  time: 0.6955  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1220/4579]  eta: 0:38:39  Lr: 0.001875  Loss: -0.1429  Acc@1: 62.5000 (65.9500)  Acc@5: 87.5000 (91.6462)  time: 0.7100  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1230/4579]  eta: 0:38:33  Lr: 0.001875  Loss: -0.2822  Acc@1: 68.7500 (65.9728)  Acc@5: 87.5000 (91.6684)  time: 0.7045  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1240/4579]  eta: 0:38:26  Lr: 0.001875  Loss: -0.5218  Acc@1: 68.7500 (66.0002)  Acc@5: 93.7500 (91.6851)  time: 0.6973  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1250/4579]  eta: 0:38:18  Lr: 0.001875  Loss: -0.7214  Acc@1: 68.7500 (65.9572)  Acc@5: 93.7500 (91.6617)  time: 0.6823  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1260/4579]  eta: 0:38:12  Lr: 0.001875  Loss: -0.7190  Acc@1: 62.5000 (65.9843)  Acc@5: 93.7500 (91.6782)  time: 0.6936  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1270/4579]  eta: 0:38:06  Lr: 0.001875  Loss: -0.4258  Acc@1: 68.7500 (65.9913)  Acc@5: 93.7500 (91.6945)  time: 0.7144  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1280/4579]  eta: 0:38:00  Lr: 0.001875  Loss: -0.4564  Acc@1: 68.7500 (65.9543)  Acc@5: 93.7500 (91.6959)  time: 0.7148  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1290/4579]  eta: 0:37:49  Lr: 0.001875  Loss: -0.1312  Acc@1: 68.7500 (65.9857)  Acc@5: 93.7500 (91.7167)  time: 0.6348  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1300/4579]  eta: 0:37:37  Lr: 0.001875  Loss: 0.3871  Acc@1: 75.0000 (66.0261)  Acc@5: 93.7500 (91.7419)  time: 0.5225  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1310/4579]  eta: 0:37:31  Lr: 0.001875  Loss: -0.5813  Acc@1: 75.0000 (66.0612)  Acc@5: 93.7500 (91.7429)  time: 0.5948  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1320/4579]  eta: 0:37:16  Lr: 0.001875  Loss: -0.4653  Acc@1: 68.7500 (66.0579)  Acc@5: 93.7500 (91.7487)  time: 0.5362  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/4579]  eta: 0:37:01  Lr: 0.001875  Loss: -0.1871  Acc@1: 68.7500 (66.0594)  Acc@5: 93.7500 (91.7496)  time: 0.3639  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1340/4579]  eta: 0:36:46  Lr: 0.001875  Loss: -0.1957  Acc@1: 68.7500 (66.0561)  Acc@5: 87.5000 (91.7412)  time: 0.3550  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1350/4579]  eta: 0:36:31  Lr: 0.001875  Loss: -0.1288  Acc@1: 62.5000 (66.0344)  Acc@5: 93.7500 (91.7376)  time: 0.3535  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1360/4579]  eta: 0:36:17  Lr: 0.001875  Loss: -0.8898  Acc@1: 68.7500 (66.0819)  Acc@5: 93.7500 (91.7662)  time: 0.3554  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1370/4579]  eta: 0:36:03  Lr: 0.001875  Loss: -0.3106  Acc@1: 68.7500 (66.0786)  Acc@5: 93.7500 (91.7533)  time: 0.3591  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1380/4579]  eta: 0:35:49  Lr: 0.001875  Loss: -0.2949  Acc@1: 68.7500 (66.1477)  Acc@5: 93.7500 (91.7768)  time: 0.3571  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1390/4579]  eta: 0:35:35  Lr: 0.001875  Loss: -0.6775  Acc@1: 68.7500 (66.1350)  Acc@5: 93.7500 (91.7730)  time: 0.3568  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [1400/4579]  eta: 0:35:21  Lr: 0.001875  Loss: -0.4466  Acc@1: 62.5000 (66.1358)  Acc@5: 93.7500 (91.7737)  time: 0.3555  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [1410/4579]  eta: 0:35:08  Lr: 0.001875  Loss: -0.1810  Acc@1: 62.5000 (66.1366)  Acc@5: 93.7500 (91.7745)  time: 0.3580  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1420/4579]  eta: 0:34:54  Lr: 0.001875  Loss: -0.1009  Acc@1: 68.7500 (66.1330)  Acc@5: 93.7500 (91.7488)  time: 0.3562  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1430/4579]  eta: 0:34:41  Lr: 0.001875  Loss: -0.4573  Acc@1: 62.5000 (66.1032)  Acc@5: 93.7500 (91.7540)  time: 0.3612  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1440/4579]  eta: 0:34:28  Lr: 0.001875  Loss: -0.4541  Acc@1: 62.5000 (66.1476)  Acc@5: 93.7500 (91.7809)  time: 0.3635  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1450/4579]  eta: 0:34:14  Lr: 0.001875  Loss: -0.5897  Acc@1: 68.7500 (66.1613)  Acc@5: 93.7500 (91.7945)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1460/4579]  eta: 0:34:02  Lr: 0.001875  Loss: 0.0782  Acc@1: 62.5000 (66.1405)  Acc@5: 93.7500 (91.7822)  time: 0.3712  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1470/4579]  eta: 0:33:58  Lr: 0.001875  Loss: -0.4192  Acc@1: 62.5000 (66.1115)  Acc@5: 93.7500 (91.7701)  time: 0.5711  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1480/4579]  eta: 0:33:53  Lr: 0.001875  Loss: -0.7057  Acc@1: 68.7500 (66.1884)  Acc@5: 93.7500 (91.7876)  time: 0.7489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1490/4579]  eta: 0:33:48  Lr: 0.001875  Loss: -0.4600  Acc@1: 75.0000 (66.1972)  Acc@5: 93.7500 (91.7840)  time: 0.7479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1500/4579]  eta: 0:33:44  Lr: 0.001875  Loss: -0.4603  Acc@1: 68.7500 (66.2017)  Acc@5: 93.7500 (91.7888)  time: 0.7488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1510/4579]  eta: 0:33:39  Lr: 0.001875  Loss: -0.3571  Acc@1: 62.5000 (66.1772)  Acc@5: 93.7500 (91.8018)  time: 0.7490  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1520/4579]  eta: 0:33:34  Lr: 0.001875  Loss: 0.2776  Acc@1: 62.5000 (66.1941)  Acc@5: 93.7500 (91.7982)  time: 0.7452  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1530/4579]  eta: 0:33:29  Lr: 0.001875  Loss: -0.2481  Acc@1: 68.7500 (66.2067)  Acc@5: 93.7500 (91.8109)  time: 0.7402  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1540/4579]  eta: 0:33:24  Lr: 0.001875  Loss: -0.6081  Acc@1: 75.0000 (66.2516)  Acc@5: 93.7500 (91.8194)  time: 0.7405  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1550/4579]  eta: 0:33:19  Lr: 0.001875  Loss: -0.3014  Acc@1: 75.0000 (66.2637)  Acc@5: 93.7500 (91.8319)  time: 0.7446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1560/4579]  eta: 0:33:14  Lr: 0.001875  Loss: 0.0124  Acc@1: 62.5000 (66.2276)  Acc@5: 93.7500 (91.8121)  time: 0.7446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1570/4579]  eta: 0:33:09  Lr: 0.001875  Loss: -0.0041  Acc@1: 62.5000 (66.1800)  Acc@5: 87.5000 (91.8046)  time: 0.7431  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1580/4579]  eta: 0:33:04  Lr: 0.001875  Loss: -0.2295  Acc@1: 62.5000 (66.1725)  Acc@5: 93.7500 (91.8129)  time: 0.7437  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1590/4579]  eta: 0:32:59  Lr: 0.001875  Loss: 0.1380  Acc@1: 62.5000 (66.1023)  Acc@5: 93.7500 (91.8094)  time: 0.7415  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1600/4579]  eta: 0:32:54  Lr: 0.001875  Loss: 0.2106  Acc@1: 62.5000 (66.0876)  Acc@5: 87.5000 (91.7942)  time: 0.7412  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1610/4579]  eta: 0:32:49  Lr: 0.001875  Loss: -0.4064  Acc@1: 62.5000 (66.0925)  Acc@5: 93.7500 (91.8180)  time: 0.7398  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1620/4579]  eta: 0:32:43  Lr: 0.001875  Loss: -0.4199  Acc@1: 68.7500 (66.0973)  Acc@5: 93.7500 (91.8145)  time: 0.7379  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1630/4579]  eta: 0:32:38  Lr: 0.001875  Loss: 0.2600  Acc@1: 62.5000 (66.0714)  Acc@5: 93.7500 (91.8072)  time: 0.7383  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1640/4579]  eta: 0:32:33  Lr: 0.001875  Loss: -0.5878  Acc@1: 62.5000 (66.0763)  Acc@5: 93.7500 (91.8190)  time: 0.7354  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1650/4579]  eta: 0:32:27  Lr: 0.001875  Loss: -0.7010  Acc@1: 68.7500 (66.1114)  Acc@5: 93.7500 (91.8459)  time: 0.7336  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1660/4579]  eta: 0:32:22  Lr: 0.001875  Loss: 0.0718  Acc@1: 68.7500 (66.1010)  Acc@5: 93.7500 (91.8423)  time: 0.7334  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1670/4579]  eta: 0:32:16  Lr: 0.001875  Loss: -0.5207  Acc@1: 68.7500 (66.1094)  Acc@5: 93.7500 (91.8350)  time: 0.7341  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1680/4579]  eta: 0:32:11  Lr: 0.001875  Loss: -0.5605  Acc@1: 68.7500 (66.1214)  Acc@5: 93.7500 (91.8612)  time: 0.7318  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1690/4579]  eta: 0:32:05  Lr: 0.001875  Loss: -0.1020  Acc@1: 68.7500 (66.1073)  Acc@5: 93.7500 (91.8650)  time: 0.7318  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1700/4579]  eta: 0:32:00  Lr: 0.001875  Loss: -0.3535  Acc@1: 62.5000 (66.1008)  Acc@5: 93.7500 (91.8724)  time: 0.7319  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1710/4579]  eta: 0:31:54  Lr: 0.001875  Loss: -0.4730  Acc@1: 68.7500 (66.1127)  Acc@5: 93.7500 (91.8724)  time: 0.7290  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1720/4579]  eta: 0:31:48  Lr: 0.001875  Loss: -0.1908  Acc@1: 62.5000 (66.1026)  Acc@5: 93.7500 (91.8906)  time: 0.7303  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1730/4579]  eta: 0:31:43  Lr: 0.001875  Loss: 0.2719  Acc@1: 62.5000 (66.0709)  Acc@5: 87.5000 (91.8580)  time: 0.7282  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1740/4579]  eta: 0:31:37  Lr: 0.001875  Loss: -0.0136  Acc@1: 62.5000 (66.0863)  Acc@5: 87.5000 (91.8617)  time: 0.7279  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1750/4579]  eta: 0:31:31  Lr: 0.001875  Loss: -0.5100  Acc@1: 68.7500 (66.1015)  Acc@5: 93.7500 (91.8618)  time: 0.7325  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1760/4579]  eta: 0:31:25  Lr: 0.001875  Loss: -0.3478  Acc@1: 68.7500 (66.0988)  Acc@5: 93.7500 (91.8619)  time: 0.7058  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1770/4579]  eta: 0:31:19  Lr: 0.001875  Loss: -0.3789  Acc@1: 68.7500 (66.0820)  Acc@5: 93.7500 (91.8725)  time: 0.7030  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1780/4579]  eta: 0:31:13  Lr: 0.001875  Loss: -0.1796  Acc@1: 68.7500 (66.1040)  Acc@5: 93.7500 (91.8901)  time: 0.7253  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1790/4579]  eta: 0:31:07  Lr: 0.001875  Loss: -0.2930  Acc@1: 68.7500 (66.0839)  Acc@5: 93.7500 (91.8935)  time: 0.7245  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1800/4579]  eta: 0:30:58  Lr: 0.001875  Loss: 0.0030  Acc@1: 62.5000 (66.0779)  Acc@5: 93.7500 (91.9073)  time: 0.6149  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1810/4579]  eta: 0:30:48  Lr: 0.001875  Loss: -0.2983  Acc@1: 62.5000 (66.0581)  Acc@5: 93.7500 (91.9105)  time: 0.4837  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1820/4579]  eta: 0:30:43  Lr: 0.001875  Loss: -0.2154  Acc@1: 68.7500 (66.0832)  Acc@5: 93.7500 (91.9172)  time: 0.5947  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1830/4579]  eta: 0:30:37  Lr: 0.001875  Loss: -0.0906  Acc@1: 68.7500 (66.0943)  Acc@5: 93.7500 (91.9067)  time: 0.7253  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1840/4579]  eta: 0:30:31  Lr: 0.001875  Loss: -0.4344  Acc@1: 68.7500 (66.1122)  Acc@5: 93.7500 (91.8964)  time: 0.7262  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1850/4579]  eta: 0:30:25  Lr: 0.001875  Loss: -0.2605  Acc@1: 62.5000 (66.0758)  Acc@5: 93.7500 (91.8861)  time: 0.7225  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1860/4579]  eta: 0:30:19  Lr: 0.001875  Loss: -0.4801  Acc@1: 62.5000 (66.1103)  Acc@5: 93.7500 (91.8928)  time: 0.7241  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1870/4579]  eta: 0:30:13  Lr: 0.001875  Loss: -0.2573  Acc@1: 68.7500 (66.1277)  Acc@5: 93.7500 (91.9161)  time: 0.7282  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1880/4579]  eta: 0:30:07  Lr: 0.001875  Loss: -0.7779  Acc@1: 68.7500 (66.1317)  Acc@5: 93.7500 (91.9258)  time: 0.7231  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1890/4579]  eta: 0:30:01  Lr: 0.001875  Loss: -0.1957  Acc@1: 62.5000 (66.1191)  Acc@5: 93.7500 (91.9355)  time: 0.7235  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1900/4579]  eta: 0:29:56  Lr: 0.001875  Loss: -0.3637  Acc@1: 62.5000 (66.1330)  Acc@5: 93.7500 (91.9483)  time: 0.7291  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1910/4579]  eta: 0:29:50  Lr: 0.001875  Loss: -0.5601  Acc@1: 68.7500 (66.1336)  Acc@5: 93.7500 (91.9414)  time: 0.7260  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1920/4579]  eta: 0:29:43  Lr: 0.001875  Loss: 0.3495  Acc@1: 68.7500 (66.1439)  Acc@5: 87.5000 (91.9345)  time: 0.7162  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1930/4579]  eta: 0:29:37  Lr: 0.001875  Loss: -0.5347  Acc@1: 68.7500 (66.1315)  Acc@5: 93.7500 (91.9375)  time: 0.7195  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1940/4579]  eta: 0:29:31  Lr: 0.001875  Loss: -0.2333  Acc@1: 62.5000 (66.1225)  Acc@5: 93.7500 (91.9532)  time: 0.7228  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1950/4579]  eta: 0:29:25  Lr: 0.001875  Loss: -0.4240  Acc@1: 62.5000 (66.1231)  Acc@5: 93.7500 (91.9625)  time: 0.7178  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1960/4579]  eta: 0:29:19  Lr: 0.001875  Loss: -0.2399  Acc@1: 68.7500 (66.1397)  Acc@5: 93.7500 (91.9716)  time: 0.7177  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1970/4579]  eta: 0:29:13  Lr: 0.001875  Loss: -0.6197  Acc@1: 68.7500 (66.1466)  Acc@5: 93.7500 (91.9806)  time: 0.7169  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1980/4579]  eta: 0:29:07  Lr: 0.001875  Loss: -0.3512  Acc@1: 68.7500 (66.1471)  Acc@5: 93.7500 (91.9738)  time: 0.7173  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1990/4579]  eta: 0:29:01  Lr: 0.001875  Loss: -0.5416  Acc@1: 68.7500 (66.1571)  Acc@5: 93.7500 (91.9795)  time: 0.7191  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2000/4579]  eta: 0:28:55  Lr: 0.001875  Loss: -0.3105  Acc@1: 62.5000 (66.1388)  Acc@5: 93.7500 (91.9821)  time: 0.7192  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2010/4579]  eta: 0:28:49  Lr: 0.001875  Loss: -0.0514  Acc@1: 68.7500 (66.1704)  Acc@5: 93.7500 (91.9909)  time: 0.7191  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2020/4579]  eta: 0:28:42  Lr: 0.001875  Loss: -0.6436  Acc@1: 68.7500 (66.1863)  Acc@5: 93.7500 (92.0027)  time: 0.7193  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2030/4579]  eta: 0:28:36  Lr: 0.001875  Loss: -0.1604  Acc@1: 68.7500 (66.1774)  Acc@5: 93.7500 (92.0206)  time: 0.7210  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2040/4579]  eta: 0:28:30  Lr: 0.001875  Loss: 0.0604  Acc@1: 68.7500 (66.2175)  Acc@5: 93.7500 (92.0321)  time: 0.7211  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2050/4579]  eta: 0:28:24  Lr: 0.001875  Loss: -0.6165  Acc@1: 68.7500 (66.1994)  Acc@5: 93.7500 (92.0405)  time: 0.7203  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2060/4579]  eta: 0:28:18  Lr: 0.001875  Loss: -0.4888  Acc@1: 62.5000 (66.1997)  Acc@5: 93.7500 (92.0457)  time: 0.7199  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2070/4579]  eta: 0:28:12  Lr: 0.001875  Loss: -0.5236  Acc@1: 62.5000 (66.1939)  Acc@5: 93.7500 (92.0359)  time: 0.7183  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2080/4579]  eta: 0:28:05  Lr: 0.001875  Loss: -0.2794  Acc@1: 62.5000 (66.1941)  Acc@5: 93.7500 (92.0531)  time: 0.7187  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2090/4579]  eta: 0:27:59  Lr: 0.001875  Loss: -0.7130  Acc@1: 68.7500 (66.2093)  Acc@5: 93.7500 (92.0493)  time: 0.7116  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2100/4579]  eta: 0:27:53  Lr: 0.001875  Loss: -0.3029  Acc@1: 68.7500 (66.2214)  Acc@5: 93.7500 (92.0663)  time: 0.7080  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2110/4579]  eta: 0:27:46  Lr: 0.001875  Loss: 1.1395  Acc@1: 68.7500 (66.1949)  Acc@5: 93.7500 (92.0506)  time: 0.7151  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2120/4579]  eta: 0:27:40  Lr: 0.001875  Loss: -0.5300  Acc@1: 68.7500 (66.2188)  Acc@5: 93.7500 (92.0556)  time: 0.6902  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2130/4579]  eta: 0:27:33  Lr: 0.001875  Loss: 0.2365  Acc@1: 68.7500 (66.2013)  Acc@5: 93.7500 (92.0607)  time: 0.6759  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2140/4579]  eta: 0:27:27  Lr: 0.001875  Loss: -0.5485  Acc@1: 62.5000 (66.1986)  Acc@5: 87.5000 (92.0364)  time: 0.7038  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2150/4579]  eta: 0:27:20  Lr: 0.001875  Loss: 0.0024  Acc@1: 68.7500 (66.1930)  Acc@5: 87.5000 (92.0328)  time: 0.7144  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2160/4579]  eta: 0:27:14  Lr: 0.001875  Loss: -0.5622  Acc@1: 62.5000 (66.1904)  Acc@5: 93.7500 (92.0407)  time: 0.7091  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2170/4579]  eta: 0:27:07  Lr: 0.001875  Loss: -0.0689  Acc@1: 68.7500 (66.1993)  Acc@5: 93.7500 (92.0400)  time: 0.6897  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2180/4579]  eta: 0:27:01  Lr: 0.001875  Loss: -0.0822  Acc@1: 68.7500 (66.1824)  Acc@5: 87.5000 (92.0392)  time: 0.6908  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2190/4579]  eta: 0:26:54  Lr: 0.001875  Loss: 0.1765  Acc@1: 62.5000 (66.1741)  Acc@5: 93.7500 (92.0413)  time: 0.7116  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2200/4579]  eta: 0:26:48  Lr: 0.001875  Loss: 0.0088  Acc@1: 62.5000 (66.1716)  Acc@5: 93.7500 (92.0405)  time: 0.7122  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2210/4579]  eta: 0:26:40  Lr: 0.001875  Loss: -0.2032  Acc@1: 62.5000 (66.1465)  Acc@5: 87.5000 (92.0341)  time: 0.6240  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2220/4579]  eta: 0:26:30  Lr: 0.001875  Loss: -0.1794  Acc@1: 62.5000 (66.1442)  Acc@5: 87.5000 (92.0334)  time: 0.4618  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2230/4579]  eta: 0:26:22  Lr: 0.001875  Loss: -0.4843  Acc@1: 68.7500 (66.1419)  Acc@5: 87.5000 (92.0215)  time: 0.4808  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2240/4579]  eta: 0:26:12  Lr: 0.001875  Loss: -0.5139  Acc@1: 62.5000 (66.1423)  Acc@5: 87.5000 (92.0320)  time: 0.4615  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2250/4579]  eta: 0:26:02  Lr: 0.001875  Loss: 0.6942  Acc@1: 62.5000 (66.1151)  Acc@5: 93.7500 (92.0174)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2260/4579]  eta: 0:25:52  Lr: 0.001875  Loss: -0.6883  Acc@1: 62.5000 (66.1295)  Acc@5: 93.7500 (92.0223)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2270/4579]  eta: 0:25:42  Lr: 0.001875  Loss: -0.1043  Acc@1: 62.5000 (66.1328)  Acc@5: 93.7500 (92.0217)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2280/4579]  eta: 0:25:32  Lr: 0.001875  Loss: -0.2678  Acc@1: 62.5000 (66.1141)  Acc@5: 93.7500 (92.0210)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2290/4579]  eta: 0:25:22  Lr: 0.001875  Loss: 0.0541  Acc@1: 62.5000 (66.0874)  Acc@5: 87.5000 (92.0095)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2300/4579]  eta: 0:25:13  Lr: 0.001875  Loss: 0.2577  Acc@1: 62.5000 (66.0745)  Acc@5: 87.5000 (92.0035)  time: 0.3608  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2310/4579]  eta: 0:25:03  Lr: 0.001875  Loss: -0.6832  Acc@1: 68.7500 (66.0942)  Acc@5: 93.7500 (92.0083)  time: 0.3578  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2320/4579]  eta: 0:24:53  Lr: 0.001875  Loss: -0.8115  Acc@1: 75.0000 (66.1137)  Acc@5: 93.7500 (92.0158)  time: 0.3526  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2330/4579]  eta: 0:24:47  Lr: 0.001875  Loss: -0.4413  Acc@1: 68.7500 (66.1090)  Acc@5: 93.7500 (92.0125)  time: 0.5154  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2340/4579]  eta: 0:24:41  Lr: 0.001875  Loss: 0.0626  Acc@1: 68.7500 (66.1283)  Acc@5: 93.7500 (92.0200)  time: 0.7058  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2350/4579]  eta: 0:24:35  Lr: 0.001875  Loss: -0.6033  Acc@1: 68.7500 (66.1261)  Acc@5: 93.7500 (92.0114)  time: 0.7371  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2360/4579]  eta: 0:24:29  Lr: 0.001875  Loss: -0.5947  Acc@1: 68.7500 (66.1505)  Acc@5: 93.7500 (92.0134)  time: 0.7416  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2370/4579]  eta: 0:24:23  Lr: 0.001875  Loss: -0.3743  Acc@1: 68.7500 (66.1641)  Acc@5: 93.7500 (92.0050)  time: 0.7446  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2380/4579]  eta: 0:24:18  Lr: 0.001875  Loss: -0.7679  Acc@1: 62.5000 (66.1513)  Acc@5: 93.7500 (91.9939)  time: 0.7480  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2390/4579]  eta: 0:24:12  Lr: 0.001875  Loss: -0.4030  Acc@1: 62.5000 (66.1413)  Acc@5: 93.7500 (91.9960)  time: 0.7478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2400/4579]  eta: 0:24:06  Lr: 0.001875  Loss: -0.5881  Acc@1: 68.7500 (66.1521)  Acc@5: 93.7500 (91.9955)  time: 0.7464  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2410/4579]  eta: 0:24:00  Lr: 0.001875  Loss: -0.7586  Acc@1: 68.7500 (66.1473)  Acc@5: 87.5000 (91.9976)  time: 0.7442  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2420/4579]  eta: 0:23:54  Lr: 0.001875  Loss: -0.7624  Acc@1: 62.5000 (66.1478)  Acc@5: 93.7500 (91.9971)  time: 0.7420  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2430/4579]  eta: 0:23:48  Lr: 0.001875  Loss: -0.3189  Acc@1: 62.5000 (66.1636)  Acc@5: 93.7500 (92.0069)  time: 0.7445  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2440/4579]  eta: 0:23:42  Lr: 0.001875  Loss: -0.5291  Acc@1: 68.7500 (66.1921)  Acc@5: 93.7500 (92.0115)  time: 0.7392  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2450/4579]  eta: 0:23:36  Lr: 0.001875  Loss: -0.4809  Acc@1: 68.7500 (66.1847)  Acc@5: 93.7500 (92.0084)  time: 0.7337  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2460/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.4796  Acc@1: 68.7500 (66.2002)  Acc@5: 93.7500 (92.0281)  time: 0.7340  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2470/4579]  eta: 0:23:24  Lr: 0.001875  Loss: -0.3448  Acc@1: 68.7500 (66.2030)  Acc@5: 93.7500 (92.0351)  time: 0.7392  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2480/4579]  eta: 0:23:18  Lr: 0.001875  Loss: -0.8378  Acc@1: 68.7500 (66.2082)  Acc@5: 93.7500 (92.0370)  time: 0.7429  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2490/4579]  eta: 0:23:12  Lr: 0.001875  Loss: -0.2912  Acc@1: 68.7500 (66.2234)  Acc@5: 93.7500 (92.0464)  time: 0.7418  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2500/4579]  eta: 0:23:06  Lr: 0.001875  Loss: -0.7647  Acc@1: 68.7500 (66.2410)  Acc@5: 93.7500 (92.0407)  time: 0.7401  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2510/4579]  eta: 0:23:00  Lr: 0.001875  Loss: 0.3945  Acc@1: 68.7500 (66.2460)  Acc@5: 93.7500 (92.0550)  time: 0.7355  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2520/4579]  eta: 0:22:53  Lr: 0.001875  Loss: -0.1910  Acc@1: 68.7500 (66.2683)  Acc@5: 93.7500 (92.0642)  time: 0.7262  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2530/4579]  eta: 0:22:47  Lr: 0.001875  Loss: -0.2602  Acc@1: 68.7500 (66.2535)  Acc@5: 93.7500 (92.0609)  time: 0.7229  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2540/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.0952  Acc@1: 68.7500 (66.2682)  Acc@5: 93.7500 (92.0528)  time: 0.7259  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2550/4579]  eta: 0:22:35  Lr: 0.001875  Loss: -0.3880  Acc@1: 68.7500 (66.2681)  Acc@5: 93.7500 (92.0619)  time: 0.7224  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2560/4579]  eta: 0:22:29  Lr: 0.001875  Loss: -0.2419  Acc@1: 62.5000 (66.2607)  Acc@5: 93.7500 (92.0710)  time: 0.7263  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [2570/4579]  eta: 0:22:22  Lr: 0.001875  Loss: -0.5152  Acc@1: 68.7500 (66.2656)  Acc@5: 93.7500 (92.0653)  time: 0.7338  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [2580/4579]  eta: 0:22:16  Lr: 0.001875  Loss: -0.5963  Acc@1: 68.7500 (66.2921)  Acc@5: 93.7500 (92.0743)  time: 0.7357  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2590/4579]  eta: 0:22:10  Lr: 0.001875  Loss: -0.5404  Acc@1: 68.7500 (66.2703)  Acc@5: 93.7500 (92.0518)  time: 0.7351  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2600/4579]  eta: 0:22:04  Lr: 0.001875  Loss: -0.1217  Acc@1: 62.5000 (66.2606)  Acc@5: 87.5000 (92.0415)  time: 0.7291  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2610/4579]  eta: 0:21:55  Lr: 0.001875  Loss: -0.0772  Acc@1: 62.5000 (66.2462)  Acc@5: 87.5000 (92.0505)  time: 0.5384  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2620/4579]  eta: 0:21:46  Lr: 0.001875  Loss: -0.6302  Acc@1: 62.5000 (66.2486)  Acc@5: 93.7500 (92.0474)  time: 0.3529  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2630/4579]  eta: 0:21:37  Lr: 0.001875  Loss: -0.6609  Acc@1: 75.0000 (66.2795)  Acc@5: 93.7500 (92.0658)  time: 0.3518  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2640/4579]  eta: 0:21:28  Lr: 0.001875  Loss: -0.0543  Acc@1: 75.0000 (66.2935)  Acc@5: 93.7500 (92.0721)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2650/4579]  eta: 0:21:19  Lr: 0.001875  Loss: -0.3494  Acc@1: 68.7500 (66.3052)  Acc@5: 93.7500 (92.0737)  time: 0.3575  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2660/4579]  eta: 0:21:10  Lr: 0.001875  Loss: -0.4112  Acc@1: 68.7500 (66.3050)  Acc@5: 93.7500 (92.0777)  time: 0.3588  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2670/4579]  eta: 0:21:01  Lr: 0.001875  Loss: -0.8557  Acc@1: 68.7500 (66.3211)  Acc@5: 93.7500 (92.0933)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2680/4579]  eta: 0:20:52  Lr: 0.001875  Loss: -0.3817  Acc@1: 68.7500 (66.3092)  Acc@5: 93.7500 (92.0878)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2690/4579]  eta: 0:20:44  Lr: 0.001875  Loss: 0.2039  Acc@1: 62.5000 (66.3160)  Acc@5: 93.7500 (92.0847)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2700/4579]  eta: 0:20:35  Lr: 0.001875  Loss: -0.4722  Acc@1: 68.7500 (66.3227)  Acc@5: 93.7500 (92.0863)  time: 0.3567  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2710/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.1282  Acc@1: 68.7500 (66.3385)  Acc@5: 93.7500 (92.0924)  time: 0.3552  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2720/4579]  eta: 0:20:18  Lr: 0.001875  Loss: -0.2275  Acc@1: 68.7500 (66.3612)  Acc@5: 93.7500 (92.1077)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2730/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.2151  Acc@1: 68.7500 (66.3585)  Acc@5: 93.7500 (92.1045)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2740/4579]  eta: 0:20:00  Lr: 0.001875  Loss: -0.6265  Acc@1: 68.7500 (66.3718)  Acc@5: 93.7500 (92.1128)  time: 0.3526  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2750/4579]  eta: 0:19:52  Lr: 0.001875  Loss: -0.3176  Acc@1: 68.7500 (66.3804)  Acc@5: 93.7500 (92.0983)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2760/4579]  eta: 0:19:43  Lr: 0.001875  Loss: -0.4580  Acc@1: 62.5000 (66.3596)  Acc@5: 93.7500 (92.0975)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2770/4579]  eta: 0:19:35  Lr: 0.001875  Loss: -0.7317  Acc@1: 62.5000 (66.3637)  Acc@5: 93.7500 (92.1057)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2780/4579]  eta: 0:19:26  Lr: 0.001875  Loss: -0.3796  Acc@1: 68.7500 (66.3655)  Acc@5: 93.7500 (92.1004)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2790/4579]  eta: 0:19:18  Lr: 0.001875  Loss: 0.0546  Acc@1: 68.7500 (66.3539)  Acc@5: 93.7500 (92.1086)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2800/4579]  eta: 0:19:10  Lr: 0.001875  Loss: -0.2399  Acc@1: 68.7500 (66.3513)  Acc@5: 93.7500 (92.1033)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2810/4579]  eta: 0:19:01  Lr: 0.001875  Loss: 0.5935  Acc@1: 62.5000 (66.3487)  Acc@5: 93.7500 (92.0958)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2820/4579]  eta: 0:18:53  Lr: 0.001875  Loss: -0.0376  Acc@1: 62.5000 (66.3572)  Acc@5: 93.7500 (92.1039)  time: 0.3520  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2830/4579]  eta: 0:18:45  Lr: 0.001875  Loss: 0.0032  Acc@1: 62.5000 (66.3569)  Acc@5: 93.7500 (92.1031)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2840/4579]  eta: 0:18:37  Lr: 0.001875  Loss: -0.4534  Acc@1: 62.5000 (66.3499)  Acc@5: 93.7500 (92.1001)  time: 0.3547  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2850/4579]  eta: 0:18:28  Lr: 0.001875  Loss: -0.6654  Acc@1: 62.5000 (66.3473)  Acc@5: 93.7500 (92.1058)  time: 0.3581  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2860/4579]  eta: 0:18:20  Lr: 0.001875  Loss: -0.4854  Acc@1: 56.2500 (66.3317)  Acc@5: 93.7500 (92.1050)  time: 0.3560  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2870/4579]  eta: 0:18:12  Lr: 0.001875  Loss: -0.0318  Acc@1: 62.5000 (66.3249)  Acc@5: 93.7500 (92.0999)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2880/4579]  eta: 0:18:04  Lr: 0.001875  Loss: -0.0386  Acc@1: 62.5000 (66.3181)  Acc@5: 93.7500 (92.0969)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2890/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.3744  Acc@1: 68.7500 (66.3309)  Acc@5: 93.7500 (92.0962)  time: 0.3535  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [2900/4579]  eta: 0:17:48  Lr: 0.001875  Loss: -0.6954  Acc@1: 68.7500 (66.3564)  Acc@5: 93.7500 (92.1105)  time: 0.3532  data: 0.0023  max mem: 2500
Train: Epoch[5/5]  [2910/4579]  eta: 0:17:40  Lr: 0.001875  Loss: -0.6102  Acc@1: 68.7500 (66.3582)  Acc@5: 93.7500 (92.1183)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2920/4579]  eta: 0:17:32  Lr: 0.001875  Loss: -0.5942  Acc@1: 68.7500 (66.3643)  Acc@5: 93.7500 (92.1217)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2930/4579]  eta: 0:17:24  Lr: 0.001875  Loss: -0.6085  Acc@1: 62.5000 (66.3511)  Acc@5: 93.7500 (92.1273)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2940/4579]  eta: 0:17:16  Lr: 0.001875  Loss: -0.0167  Acc@1: 56.2500 (66.3380)  Acc@5: 93.7500 (92.1307)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2950/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.2024  Acc@1: 62.5000 (66.3271)  Acc@5: 93.7500 (92.1319)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2960/4579]  eta: 0:17:00  Lr: 0.001875  Loss: 0.5793  Acc@1: 62.5000 (66.2994)  Acc@5: 93.7500 (92.1247)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2970/4579]  eta: 0:16:53  Lr: 0.001875  Loss: -0.3496  Acc@1: 62.5000 (66.3097)  Acc@5: 93.7500 (92.1344)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2980/4579]  eta: 0:16:45  Lr: 0.001875  Loss: 0.0691  Acc@1: 68.7500 (66.3158)  Acc@5: 93.7500 (92.1356)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2990/4579]  eta: 0:16:37  Lr: 0.001875  Loss: -0.1390  Acc@1: 62.5000 (66.2968)  Acc@5: 93.7500 (92.1285)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3000/4579]  eta: 0:16:29  Lr: 0.001875  Loss: -0.2530  Acc@1: 62.5000 (66.2904)  Acc@5: 93.7500 (92.1235)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3010/4579]  eta: 0:16:22  Lr: 0.001875  Loss: -0.6505  Acc@1: 68.7500 (66.3027)  Acc@5: 93.7500 (92.1247)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3020/4579]  eta: 0:16:14  Lr: 0.001875  Loss: -0.3836  Acc@1: 68.7500 (66.3025)  Acc@5: 93.7500 (92.1322)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3030/4579]  eta: 0:16:06  Lr: 0.001875  Loss: 0.0179  Acc@1: 62.5000 (66.2900)  Acc@5: 93.7500 (92.1292)  time: 0.3524  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3040/4579]  eta: 0:15:59  Lr: 0.001875  Loss: 0.1366  Acc@1: 62.5000 (66.2817)  Acc@5: 87.5000 (92.1243)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3050/4579]  eta: 0:15:51  Lr: 0.001875  Loss: 0.0041  Acc@1: 62.5000 (66.2631)  Acc@5: 93.7500 (92.1255)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3060/4579]  eta: 0:15:44  Lr: 0.001875  Loss: -0.2604  Acc@1: 62.5000 (66.2672)  Acc@5: 93.7500 (92.1329)  time: 0.3554  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3070/4579]  eta: 0:15:36  Lr: 0.001875  Loss: -0.5092  Acc@1: 62.5000 (66.2691)  Acc@5: 93.7500 (92.1320)  time: 0.3577  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3080/4579]  eta: 0:15:29  Lr: 0.001875  Loss: 0.3669  Acc@1: 62.5000 (66.2752)  Acc@5: 93.7500 (92.1312)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3090/4579]  eta: 0:15:21  Lr: 0.001875  Loss: -0.4172  Acc@1: 62.5000 (66.2731)  Acc@5: 93.7500 (92.1284)  time: 0.3540  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3100/4579]  eta: 0:15:14  Lr: 0.001875  Loss: -0.0955  Acc@1: 62.5000 (66.2569)  Acc@5: 93.7500 (92.1255)  time: 0.3552  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3110/4579]  eta: 0:15:06  Lr: 0.001875  Loss: 0.1821  Acc@1: 68.7500 (66.2528)  Acc@5: 93.7500 (92.1287)  time: 0.3579  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3120/4579]  eta: 0:14:59  Lr: 0.001875  Loss: -0.0894  Acc@1: 62.5000 (66.2408)  Acc@5: 93.7500 (92.1279)  time: 0.3555  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3130/4579]  eta: 0:14:51  Lr: 0.001875  Loss: 0.1810  Acc@1: 62.5000 (66.2308)  Acc@5: 93.7500 (92.1211)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3140/4579]  eta: 0:14:44  Lr: 0.001875  Loss: -0.3542  Acc@1: 68.7500 (66.2468)  Acc@5: 87.5000 (92.1184)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3150/4579]  eta: 0:14:37  Lr: 0.001875  Loss: -0.2502  Acc@1: 68.7500 (66.2548)  Acc@5: 87.5000 (92.1017)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3160/4579]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5360  Acc@1: 68.7500 (66.2488)  Acc@5: 87.5000 (92.0951)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3170/4579]  eta: 0:14:22  Lr: 0.001875  Loss: 0.1199  Acc@1: 62.5000 (66.2330)  Acc@5: 93.7500 (92.0944)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3180/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.3412  Acc@1: 62.5000 (66.2488)  Acc@5: 93.7500 (92.1035)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3190/4579]  eta: 0:14:08  Lr: 0.001875  Loss: -0.0696  Acc@1: 68.7500 (66.2390)  Acc@5: 93.7500 (92.1028)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3200/4579]  eta: 0:14:00  Lr: 0.001875  Loss: -0.0457  Acc@1: 68.7500 (66.2527)  Acc@5: 93.7500 (92.1099)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3210/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6510  Acc@1: 68.7500 (66.2683)  Acc@5: 93.7500 (92.1189)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3220/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.6636  Acc@1: 68.7500 (66.2760)  Acc@5: 93.7500 (92.1181)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3230/4579]  eta: 0:13:39  Lr: 0.001875  Loss: 0.2520  Acc@1: 62.5000 (66.2604)  Acc@5: 93.7500 (92.1077)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3240/4579]  eta: 0:13:32  Lr: 0.001875  Loss: 0.0484  Acc@1: 68.7500 (66.2701)  Acc@5: 87.5000 (92.1108)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3250/4579]  eta: 0:13:25  Lr: 0.001875  Loss: -0.3778  Acc@1: 68.7500 (66.2623)  Acc@5: 93.7500 (92.1044)  time: 0.3570  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3260/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.3358  Acc@1: 62.5000 (66.2546)  Acc@5: 87.5000 (92.0998)  time: 0.3579  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3270/4579]  eta: 0:13:10  Lr: 0.001875  Loss: -0.4992  Acc@1: 68.7500 (66.2794)  Acc@5: 93.7500 (92.1049)  time: 0.3563  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3280/4579]  eta: 0:13:03  Lr: 0.001875  Loss: -0.3513  Acc@1: 68.7500 (66.2889)  Acc@5: 93.7500 (92.1061)  time: 0.3543  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3290/4579]  eta: 0:12:56  Lr: 0.001875  Loss: -0.3735  Acc@1: 68.7500 (66.2944)  Acc@5: 93.7500 (92.1111)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3300/4579]  eta: 0:12:49  Lr: 0.001875  Loss: -0.7586  Acc@1: 75.0000 (66.3227)  Acc@5: 93.7500 (92.1141)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3310/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.0923  Acc@1: 75.0000 (66.3244)  Acc@5: 93.7500 (92.1134)  time: 0.3548  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3320/4579]  eta: 0:12:35  Lr: 0.001875  Loss: -0.4803  Acc@1: 62.5000 (66.3204)  Acc@5: 93.7500 (92.1221)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3330/4579]  eta: 0:12:29  Lr: 0.001875  Loss: -0.2277  Acc@1: 68.7500 (66.3221)  Acc@5: 93.7500 (92.1195)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3340/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.4542  Acc@1: 68.7500 (66.3274)  Acc@5: 93.7500 (92.1262)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3350/4579]  eta: 0:12:15  Lr: 0.001875  Loss: -0.7759  Acc@1: 75.0000 (66.3533)  Acc@5: 93.7500 (92.1329)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3360/4579]  eta: 0:12:08  Lr: 0.001875  Loss: -0.2650  Acc@1: 68.7500 (66.3512)  Acc@5: 93.7500 (92.1359)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3370/4579]  eta: 0:12:01  Lr: 0.001875  Loss: -0.2414  Acc@1: 62.5000 (66.3268)  Acc@5: 93.7500 (92.1296)  time: 0.3519  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3380/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.3464  Acc@1: 62.5000 (66.3339)  Acc@5: 93.7500 (92.1270)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3390/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.4513  Acc@1: 62.5000 (66.3300)  Acc@5: 93.7500 (92.1244)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3400/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.1859  Acc@1: 62.5000 (66.3316)  Acc@5: 93.7500 (92.1273)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3410/4579]  eta: 0:11:34  Lr: 0.001875  Loss: 0.0437  Acc@1: 68.7500 (66.3460)  Acc@5: 93.7500 (92.1321)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3420/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 0.4228  Acc@1: 68.7500 (66.3348)  Acc@5: 87.5000 (92.1204)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3430/4579]  eta: 0:11:20  Lr: 0.001875  Loss: 0.0795  Acc@1: 68.7500 (66.3418)  Acc@5: 87.5000 (92.1215)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3440/4579]  eta: 0:11:14  Lr: 0.001875  Loss: -0.5353  Acc@1: 68.7500 (66.3524)  Acc@5: 93.7500 (92.1135)  time: 0.3544  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3450/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.1222  Acc@1: 68.7500 (66.3540)  Acc@5: 93.7500 (92.1200)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3460/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.5993  Acc@1: 68.7500 (66.3464)  Acc@5: 93.7500 (92.1247)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3470/4579]  eta: 0:10:53  Lr: 0.001875  Loss: 0.2774  Acc@1: 68.7500 (66.3444)  Acc@5: 93.7500 (92.1276)  time: 0.3539  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3480/4579]  eta: 0:10:47  Lr: 0.001875  Loss: -0.2401  Acc@1: 68.7500 (66.3567)  Acc@5: 93.7500 (92.1305)  time: 0.3544  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3490/4579]  eta: 0:10:40  Lr: 0.001875  Loss: -0.1963  Acc@1: 68.7500 (66.3689)  Acc@5: 93.7500 (92.1333)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3500/4579]  eta: 0:10:34  Lr: 0.001875  Loss: 0.2319  Acc@1: 68.7500 (66.3775)  Acc@5: 93.7500 (92.1326)  time: 0.3544  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3510/4579]  eta: 0:10:27  Lr: 0.001875  Loss: 0.6043  Acc@1: 68.7500 (66.3682)  Acc@5: 87.5000 (92.1176)  time: 0.3571  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3520/4579]  eta: 0:10:20  Lr: 0.001875  Loss: 0.1681  Acc@1: 62.5000 (66.3732)  Acc@5: 87.5000 (92.1045)  time: 0.3560  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3530/4579]  eta: 0:10:14  Lr: 0.001875  Loss: -0.3540  Acc@1: 62.5000 (66.3711)  Acc@5: 93.7500 (92.1021)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3540/4579]  eta: 0:10:07  Lr: 0.001875  Loss: -0.6320  Acc@1: 62.5000 (66.3637)  Acc@5: 93.7500 (92.0909)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3550/4579]  eta: 0:10:01  Lr: 0.001875  Loss: 0.0129  Acc@1: 62.5000 (66.3457)  Acc@5: 87.5000 (92.0744)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3560/4579]  eta: 0:09:54  Lr: 0.001875  Loss: -0.0438  Acc@1: 56.2500 (66.3262)  Acc@5: 87.5000 (92.0756)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3570/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.3833  Acc@1: 68.7500 (66.3505)  Acc@5: 93.7500 (92.0768)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3580/4579]  eta: 0:09:41  Lr: 0.001875  Loss: -0.4893  Acc@1: 75.0000 (66.3572)  Acc@5: 93.7500 (92.0832)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3590/4579]  eta: 0:09:35  Lr: 0.001875  Loss: -0.3267  Acc@1: 62.5000 (66.3412)  Acc@5: 93.7500 (92.0809)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3600/4579]  eta: 0:09:28  Lr: 0.001875  Loss: -0.1823  Acc@1: 68.7500 (66.3479)  Acc@5: 93.7500 (92.0855)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3610/4579]  eta: 0:09:22  Lr: 0.001875  Loss: -0.0758  Acc@1: 75.0000 (66.3528)  Acc@5: 93.7500 (92.0901)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3620/4579]  eta: 0:09:16  Lr: 0.001875  Loss: -0.5588  Acc@1: 68.7500 (66.3560)  Acc@5: 93.7500 (92.0913)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3630/4579]  eta: 0:09:09  Lr: 0.001875  Loss: -0.0524  Acc@1: 62.5000 (66.3643)  Acc@5: 93.7500 (92.0890)  time: 0.3565  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3640/4579]  eta: 0:09:03  Lr: 0.001875  Loss: -0.7724  Acc@1: 62.5000 (66.3657)  Acc@5: 93.7500 (92.0935)  time: 0.3593  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [3650/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.0581  Acc@1: 62.5000 (66.3602)  Acc@5: 93.7500 (92.0963)  time: 0.3532  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3660/4579]  eta: 0:08:50  Lr: 0.001875  Loss: -0.1344  Acc@1: 68.7500 (66.3668)  Acc@5: 93.7500 (92.0940)  time: 0.3517  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3670/4579]  eta: 0:08:44  Lr: 0.001875  Loss: -0.2309  Acc@1: 68.7500 (66.3665)  Acc@5: 93.7500 (92.1054)  time: 0.3544  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3680/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.3978  Acc@1: 68.7500 (66.3678)  Acc@5: 93.7500 (92.1081)  time: 0.3551  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3690/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.0567  Acc@1: 68.7500 (66.3709)  Acc@5: 93.7500 (92.1092)  time: 0.3546  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3700/4579]  eta: 0:08:25  Lr: 0.001875  Loss: 0.0072  Acc@1: 68.7500 (66.3773)  Acc@5: 93.7500 (92.1102)  time: 0.3525  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3710/4579]  eta: 0:08:19  Lr: 0.001875  Loss: -0.3788  Acc@1: 62.5000 (66.3669)  Acc@5: 93.7500 (92.1079)  time: 0.3536  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3720/4579]  eta: 0:08:12  Lr: 0.001875  Loss: -0.1369  Acc@1: 62.5000 (66.3733)  Acc@5: 93.7500 (92.1107)  time: 0.3556  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3730/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.1123  Acc@1: 62.5000 (66.3713)  Acc@5: 93.7500 (92.1150)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3740/4579]  eta: 0:08:00  Lr: 0.001875  Loss: 0.1265  Acc@1: 62.5000 (66.3810)  Acc@5: 93.7500 (92.1161)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3750/4579]  eta: 0:07:54  Lr: 0.001875  Loss: -0.0748  Acc@1: 68.7500 (66.3973)  Acc@5: 93.7500 (92.1188)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3760/4579]  eta: 0:07:48  Lr: 0.001875  Loss: 0.0822  Acc@1: 68.7500 (66.3903)  Acc@5: 93.7500 (92.1131)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3770/4579]  eta: 0:07:41  Lr: 0.001875  Loss: -0.5252  Acc@1: 68.7500 (66.3982)  Acc@5: 93.7500 (92.1175)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3780/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.4377  Acc@1: 68.7500 (66.4027)  Acc@5: 93.7500 (92.1152)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3790/4579]  eta: 0:07:29  Lr: 0.001875  Loss: -0.3228  Acc@1: 62.5000 (66.3924)  Acc@5: 87.5000 (92.1096)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3800/4579]  eta: 0:07:23  Lr: 0.001875  Loss: -0.7108  Acc@1: 68.7500 (66.4102)  Acc@5: 93.7500 (92.1156)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3810/4579]  eta: 0:07:17  Lr: 0.001875  Loss: 0.0249  Acc@1: 68.7500 (66.4081)  Acc@5: 93.7500 (92.1149)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3820/4579]  eta: 0:07:11  Lr: 0.001875  Loss: -0.1282  Acc@1: 62.5000 (66.4077)  Acc@5: 87.5000 (92.1078)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3830/4579]  eta: 0:07:04  Lr: 0.001875  Loss: 0.0579  Acc@1: 62.5000 (66.4073)  Acc@5: 93.7500 (92.1088)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3840/4579]  eta: 0:06:58  Lr: 0.001875  Loss: -0.2624  Acc@1: 62.5000 (66.4150)  Acc@5: 93.7500 (92.1098)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3850/4579]  eta: 0:06:52  Lr: 0.001875  Loss: -0.1607  Acc@1: 62.5000 (66.4032)  Acc@5: 93.7500 (92.1173)  time: 0.3529  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3860/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.3405  Acc@1: 62.5000 (66.4174)  Acc@5: 93.7500 (92.1183)  time: 0.3564  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3870/4579]  eta: 0:06:40  Lr: 0.001875  Loss: -0.4980  Acc@1: 75.0000 (66.4363)  Acc@5: 93.7500 (92.1274)  time: 0.3609  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3880/4579]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6282  Acc@1: 68.7500 (66.4375)  Acc@5: 93.7500 (92.1348)  time: 0.3598  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3890/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.5739  Acc@1: 68.7500 (66.4418)  Acc@5: 93.7500 (92.1421)  time: 0.3550  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3900/4579]  eta: 0:06:22  Lr: 0.001875  Loss: -0.4905  Acc@1: 68.7500 (66.4573)  Acc@5: 93.7500 (92.1494)  time: 0.3579  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3910/4579]  eta: 0:06:16  Lr: 0.001875  Loss: -0.1556  Acc@1: 68.7500 (66.4488)  Acc@5: 93.7500 (92.1471)  time: 0.3603  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3920/4579]  eta: 0:06:10  Lr: 0.001875  Loss: -0.3853  Acc@1: 62.5000 (66.4563)  Acc@5: 93.7500 (92.1512)  time: 0.3545  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3930/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.2032  Acc@1: 68.7500 (66.4700)  Acc@5: 93.7500 (92.1537)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3940/4579]  eta: 0:05:58  Lr: 0.001875  Loss: -0.0753  Acc@1: 68.7500 (66.4584)  Acc@5: 87.5000 (92.1514)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3950/4579]  eta: 0:05:52  Lr: 0.001875  Loss: -0.6970  Acc@1: 68.7500 (66.4737)  Acc@5: 93.7500 (92.1476)  time: 0.3528  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3960/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.3182  Acc@1: 68.7500 (66.4668)  Acc@5: 93.7500 (92.1421)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3970/4579]  eta: 0:05:40  Lr: 0.001875  Loss: -0.7966  Acc@1: 62.5000 (66.4615)  Acc@5: 93.7500 (92.1415)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3980/4579]  eta: 0:05:35  Lr: 0.001875  Loss: 0.1422  Acc@1: 68.7500 (66.4751)  Acc@5: 93.7500 (92.1392)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3990/4579]  eta: 0:05:29  Lr: 0.001875  Loss: 0.2304  Acc@1: 68.7500 (66.4699)  Acc@5: 93.7500 (92.1354)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4000/4579]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4532  Acc@1: 62.5000 (66.4631)  Acc@5: 87.5000 (92.1254)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4010/4579]  eta: 0:05:17  Lr: 0.001875  Loss: -0.4141  Acc@1: 75.0000 (66.4844)  Acc@5: 93.7500 (92.1326)  time: 0.3556  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4020/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.1643  Acc@1: 75.0000 (66.4900)  Acc@5: 93.7500 (92.1335)  time: 0.3616  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4030/4579]  eta: 0:05:05  Lr: 0.001875  Loss: 0.0888  Acc@1: 62.5000 (66.4739)  Acc@5: 87.5000 (92.1297)  time: 0.3563  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4040/4579]  eta: 0:04:59  Lr: 0.001875  Loss: -0.4720  Acc@1: 62.5000 (66.4641)  Acc@5: 93.7500 (92.1338)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4050/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.7333  Acc@1: 68.7500 (66.4805)  Acc@5: 93.7500 (92.1393)  time: 0.4516  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4060/4579]  eta: 0:04:48  Lr: 0.001875  Loss: -0.1261  Acc@1: 68.7500 (66.4784)  Acc@5: 93.7500 (92.1325)  time: 0.6474  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4070/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.4420  Acc@1: 68.7500 (66.4794)  Acc@5: 93.7500 (92.1365)  time: 0.7456  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4080/4579]  eta: 0:04:38  Lr: 0.001875  Loss: -0.4733  Acc@1: 68.7500 (66.4972)  Acc@5: 93.7500 (92.1450)  time: 0.7451  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4090/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.3201  Acc@1: 68.7500 (66.4920)  Acc@5: 93.7500 (92.1321)  time: 0.7464  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4100/4579]  eta: 0:04:27  Lr: 0.001875  Loss: 0.1402  Acc@1: 62.5000 (66.4884)  Acc@5: 87.5000 (92.1269)  time: 0.7471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4110/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 0.1156  Acc@1: 68.7500 (66.4969)  Acc@5: 93.7500 (92.1278)  time: 0.7463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4120/4579]  eta: 0:04:16  Lr: 0.001875  Loss: -0.3770  Acc@1: 68.7500 (66.4993)  Acc@5: 93.7500 (92.1257)  time: 0.7446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4130/4579]  eta: 0:04:11  Lr: 0.001875  Loss: -0.2643  Acc@1: 62.5000 (66.4972)  Acc@5: 93.7500 (92.1296)  time: 0.7406  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4140/4579]  eta: 0:04:06  Lr: 0.001875  Loss: -0.6769  Acc@1: 68.7500 (66.5162)  Acc@5: 93.7500 (92.1290)  time: 0.7369  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4150/4579]  eta: 0:04:00  Lr: 0.001875  Loss: -0.2572  Acc@1: 75.0000 (66.5246)  Acc@5: 93.7500 (92.1269)  time: 0.7335  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4160/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.2523  Acc@1: 68.7500 (66.5285)  Acc@5: 93.7500 (92.1278)  time: 0.7271  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4170/4579]  eta: 0:03:49  Lr: 0.001875  Loss: 0.1521  Acc@1: 62.5000 (66.5158)  Acc@5: 87.5000 (92.1197)  time: 0.7318  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4180/4579]  eta: 0:03:44  Lr: 0.001875  Loss: 0.6948  Acc@1: 56.2500 (66.4913)  Acc@5: 87.5000 (92.1057)  time: 0.7433  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4190/4579]  eta: 0:03:38  Lr: 0.001875  Loss: 0.2625  Acc@1: 68.7500 (66.4967)  Acc@5: 87.5000 (92.0947)  time: 0.7437  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4200/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -0.7034  Acc@1: 68.7500 (66.5035)  Acc@5: 93.7500 (92.1016)  time: 0.7397  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4210/4579]  eta: 0:03:27  Lr: 0.001875  Loss: -0.3684  Acc@1: 68.7500 (66.4985)  Acc@5: 93.7500 (92.1070)  time: 0.7385  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4220/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.0829  Acc@1: 68.7500 (66.4949)  Acc@5: 93.7500 (92.1005)  time: 0.7373  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4230/4579]  eta: 0:03:16  Lr: 0.001875  Loss: -0.1795  Acc@1: 68.7500 (66.5180)  Acc@5: 93.7500 (92.1103)  time: 0.7279  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4240/4579]  eta: 0:03:11  Lr: 0.001875  Loss: -0.2405  Acc@1: 68.7500 (66.5188)  Acc@5: 93.7500 (92.1157)  time: 0.7244  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4250/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.4350  Acc@1: 62.5000 (66.5138)  Acc@5: 93.7500 (92.1151)  time: 0.7330  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [4260/4579]  eta: 0:03:00  Lr: 0.001875  Loss: -0.8480  Acc@1: 68.7500 (66.5263)  Acc@5: 93.7500 (92.1204)  time: 0.7327  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4270/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.6067  Acc@1: 68.7500 (66.5330)  Acc@5: 93.7500 (92.1257)  time: 0.6416  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4280/4579]  eta: 0:02:48  Lr: 0.001875  Loss: 0.5801  Acc@1: 68.7500 (66.5265)  Acc@5: 93.7500 (92.1222)  time: 0.4533  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4290/4579]  eta: 0:02:43  Lr: 0.001875  Loss: -0.4001  Acc@1: 68.7500 (66.5317)  Acc@5: 93.7500 (92.1187)  time: 0.3516  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4300/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.6476  Acc@1: 68.7500 (66.5310)  Acc@5: 93.7500 (92.1152)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4310/4579]  eta: 0:02:31  Lr: 0.001875  Loss: 0.0705  Acc@1: 56.2500 (66.5057)  Acc@5: 93.7500 (92.1031)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4320/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.1829  Acc@1: 56.2500 (66.4994)  Acc@5: 93.7500 (92.1025)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4330/4579]  eta: 0:02:20  Lr: 0.001875  Loss: -0.4876  Acc@1: 68.7500 (66.5118)  Acc@5: 93.7500 (92.1092)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4340/4579]  eta: 0:02:14  Lr: 0.001875  Loss: -0.1121  Acc@1: 68.7500 (66.5054)  Acc@5: 93.7500 (92.1044)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4350/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.8349  Acc@1: 62.5000 (66.5120)  Acc@5: 87.5000 (92.1038)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4360/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.6935  Acc@1: 62.5000 (66.5229)  Acc@5: 93.7500 (92.0990)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:57  Lr: 0.001875  Loss: -0.5732  Acc@1: 62.5000 (66.5251)  Acc@5: 93.7500 (92.1056)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.3635  Acc@1: 75.0000 (66.5373)  Acc@5: 93.7500 (92.1108)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:45  Lr: 0.001875  Loss: -0.2463  Acc@1: 68.7500 (66.5224)  Acc@5: 93.7500 (92.1117)  time: 0.3560  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0011  Acc@1: 62.5000 (66.5204)  Acc@5: 93.7500 (92.1069)  time: 0.3567  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [4410/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5339  Acc@1: 68.7500 (66.5127)  Acc@5: 87.5000 (92.1050)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4420/4579]  eta: 0:01:28  Lr: 0.001875  Loss: 0.0942  Acc@1: 68.7500 (66.5149)  Acc@5: 93.7500 (92.1115)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4430/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0507  Acc@1: 68.7500 (66.5256)  Acc@5: 93.7500 (92.1152)  time: 0.3551  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4440/4579]  eta: 0:01:17  Lr: 0.001875  Loss: 0.2669  Acc@1: 68.7500 (66.5236)  Acc@5: 93.7500 (92.1175)  time: 0.3573  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4450/4579]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0662  Acc@1: 68.7500 (66.5328)  Acc@5: 93.7500 (92.1183)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4460/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.5080  Acc@1: 68.7500 (66.5406)  Acc@5: 93.7500 (92.1234)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4470/4579]  eta: 0:01:00  Lr: 0.001875  Loss: -0.2586  Acc@1: 68.7500 (66.5455)  Acc@5: 87.5000 (92.1131)  time: 0.3566  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:54  Lr: 0.001875  Loss: -0.4243  Acc@1: 68.7500 (66.5588)  Acc@5: 93.7500 (92.1153)  time: 0.3572  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:49  Lr: 0.001875  Loss: -0.3104  Acc@1: 68.7500 (66.5512)  Acc@5: 93.7500 (92.1148)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:43  Lr: 0.001875  Loss: -0.4911  Acc@1: 68.7500 (66.5505)  Acc@5: 93.7500 (92.1184)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5129  Acc@1: 68.7500 (66.5526)  Acc@5: 93.7500 (92.1179)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:32  Lr: 0.001875  Loss: -0.0569  Acc@1: 68.7500 (66.5616)  Acc@5: 93.7500 (92.1187)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8137  Acc@1: 62.5000 (66.5582)  Acc@5: 87.5000 (92.1099)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:21  Lr: 0.001875  Loss: -0.4876  Acc@1: 62.5000 (66.5423)  Acc@5: 87.5000 (92.1025)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:16  Lr: 0.001875  Loss: 0.9217  Acc@1: 62.5000 (66.5431)  Acc@5: 93.7500 (92.1048)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6159  Acc@1: 62.5000 (66.5493)  Acc@5: 93.7500 (92.1015)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:04  Lr: 0.001875  Loss: -0.3442  Acc@1: 68.7500 (66.5486)  Acc@5: 93.7500 (92.0969)  time: 0.3502  data: 0.0023  max mem: 2500
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3315  Acc@1: 68.7500 (66.5575)  Acc@5: 93.7500 (92.0990)  time: 0.3434  data: 0.0023  max mem: 2500
Train: Epoch[5/5] Total time: 0:42:03 (0.5510 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.3315  Acc@1: 68.7500 (66.5575)  Acc@5: 93.7500 (92.0990)
Test: [Task 1]  [   0/1627]  eta: 0:14:14  Loss: 1.1743 (1.1743)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5255  data: 0.3084  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:34  Loss: 0.9123 (0.8739)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.1591)  time: 0.2437  data: 0.0283  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:12  Loss: 0.7907 (0.8648)  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (97.6190)  time: 0.2174  data: 0.0005  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:02  Loss: 0.8897 (0.8723)  Acc@1: 87.5000 (85.0806)  Acc@5: 100.0000 (97.1774)  time: 0.2182  data: 0.0008  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:58  Loss: 0.9190 (0.8739)  Acc@1: 81.2500 (84.2988)  Acc@5: 100.0000 (96.9512)  time: 0.2188  data: 0.0007  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:53  Loss: 0.8423 (0.8573)  Acc@1: 81.2500 (84.5588)  Acc@5: 100.0000 (97.0588)  time: 0.2197  data: 0.0005  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:50  Loss: 0.8945 (0.8676)  Acc@1: 81.2500 (84.8361)  Acc@5: 100.0000 (96.9262)  time: 0.2188  data: 0.0007  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:46  Loss: 0.7426 (0.8614)  Acc@1: 81.2500 (85.1232)  Acc@5: 100.0000 (97.0951)  time: 0.2190  data: 0.0012  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:43  Loss: 0.6639 (0.8446)  Acc@1: 87.5000 (85.2623)  Acc@5: 100.0000 (97.4537)  time: 0.2184  data: 0.0009  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:40  Loss: 0.8329 (0.8618)  Acc@1: 87.5000 (85.0962)  Acc@5: 100.0000 (97.3214)  time: 0.2180  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:38  Loss: 1.0639 (0.8878)  Acc@1: 81.2500 (84.5916)  Acc@5: 93.7500 (96.9059)  time: 0.2187  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:35  Loss: 0.8915 (0.8843)  Acc@1: 81.2500 (84.6284)  Acc@5: 100.0000 (97.0721)  time: 0.2185  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:34  Loss: 0.8162 (0.8825)  Acc@1: 87.5000 (85.0207)  Acc@5: 100.0000 (97.1074)  time: 0.2233  data: 0.0027  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:32  Loss: 0.8547 (0.8885)  Acc@1: 87.5000 (85.0191)  Acc@5: 100.0000 (97.0897)  time: 0.2258  data: 0.0039  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:29  Loss: 0.8547 (0.8879)  Acc@1: 87.5000 (84.9734)  Acc@5: 100.0000 (97.0301)  time: 0.2205  data: 0.0025  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:26  Loss: 0.6951 (0.8785)  Acc@1: 87.5000 (85.0993)  Acc@5: 100.0000 (97.0613)  time: 0.2176  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:24  Loss: 0.6571 (0.8715)  Acc@1: 87.5000 (85.2484)  Acc@5: 100.0000 (97.0497)  time: 0.2178  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:22  Loss: 0.8533 (0.8680)  Acc@1: 87.5000 (85.2339)  Acc@5: 100.0000 (97.1126)  time: 0.2192  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:19  Loss: 0.8824 (0.8730)  Acc@1: 81.2500 (85.2901)  Acc@5: 100.0000 (97.1685)  time: 0.2187  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:17  Loss: 0.8837 (0.8702)  Acc@1: 87.5000 (85.4058)  Acc@5: 100.0000 (97.1859)  time: 0.2179  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:14  Loss: 0.8383 (0.8706)  Acc@1: 87.5000 (85.4789)  Acc@5: 100.0000 (97.2948)  time: 0.2181  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:12  Loss: 0.8383 (0.8722)  Acc@1: 87.5000 (85.5746)  Acc@5: 100.0000 (97.3045)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:09  Loss: 0.7284 (0.8753)  Acc@1: 87.5000 (85.4638)  Acc@5: 100.0000 (97.3133)  time: 0.2174  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:07  Loss: 0.7997 (0.8703)  Acc@1: 87.5000 (85.5790)  Acc@5: 100.0000 (97.3485)  time: 0.2173  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:05  Loss: 0.7877 (0.8662)  Acc@1: 87.5000 (85.7365)  Acc@5: 100.0000 (97.4066)  time: 0.2176  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:03  Loss: 0.7715 (0.8695)  Acc@1: 87.5000 (85.7072)  Acc@5: 100.0000 (97.2859)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:05:00  Loss: 0.8360 (0.8687)  Acc@1: 81.2500 (85.6322)  Acc@5: 100.0000 (97.2941)  time: 0.2201  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:58  Loss: 0.7561 (0.8630)  Acc@1: 81.2500 (85.7011)  Acc@5: 100.0000 (97.3708)  time: 0.2187  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:56  Loss: 0.7020 (0.8642)  Acc@1: 81.2500 (85.5649)  Acc@5: 100.0000 (97.3977)  time: 0.2169  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:53  Loss: 0.8410 (0.8639)  Acc@1: 87.5000 (85.6100)  Acc@5: 100.0000 (97.4012)  time: 0.2173  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:51  Loss: 0.7712 (0.8626)  Acc@1: 87.5000 (85.6105)  Acc@5: 100.0000 (97.3837)  time: 0.2194  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:49  Loss: 0.7928 (0.8647)  Acc@1: 87.5000 (85.6712)  Acc@5: 100.0000 (97.3875)  time: 0.2195  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:47  Loss: 0.8496 (0.8640)  Acc@1: 87.5000 (85.8061)  Acc@5: 100.0000 (97.4104)  time: 0.2176  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:44  Loss: 0.7301 (0.8625)  Acc@1: 87.5000 (85.7628)  Acc@5: 100.0000 (97.4509)  time: 0.2175  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:42  Loss: 0.6661 (0.8626)  Acc@1: 87.5000 (85.7588)  Acc@5: 100.0000 (97.4523)  time: 0.2181  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:40  Loss: 0.8277 (0.8647)  Acc@1: 81.2500 (85.6838)  Acc@5: 100.0000 (97.4181)  time: 0.2209  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:38  Loss: 0.7867 (0.8624)  Acc@1: 81.2500 (85.6302)  Acc@5: 100.0000 (97.4550)  time: 0.2227  data: 0.0026  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:36  Loss: 0.7544 (0.8619)  Acc@1: 87.5000 (85.6469)  Acc@5: 100.0000 (97.4730)  time: 0.2210  data: 0.0017  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:34  Loss: 0.7644 (0.8608)  Acc@1: 87.5000 (85.6791)  Acc@5: 100.0000 (97.4738)  time: 0.2193  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:31  Loss: 0.7931 (0.8625)  Acc@1: 87.5000 (85.7097)  Acc@5: 100.0000 (97.4425)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:29  Loss: 0.7976 (0.8632)  Acc@1: 87.5000 (85.7388)  Acc@5: 100.0000 (97.4127)  time: 0.2191  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:27  Loss: 0.7340 (0.8635)  Acc@1: 87.5000 (85.7816)  Acc@5: 100.0000 (97.3844)  time: 0.2215  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:25  Loss: 0.6837 (0.8627)  Acc@1: 87.5000 (85.7779)  Acc@5: 100.0000 (97.4169)  time: 0.2235  data: 0.0030  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:23  Loss: 0.6837 (0.8602)  Acc@1: 87.5000 (85.8324)  Acc@5: 100.0000 (97.4623)  time: 0.2246  data: 0.0026  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:21  Loss: 0.8912 (0.8607)  Acc@1: 81.2500 (85.7710)  Acc@5: 100.0000 (97.4915)  time: 0.2239  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:18  Loss: 0.9457 (0.8631)  Acc@1: 81.2500 (85.6153)  Acc@5: 100.0000 (97.4917)  time: 0.2204  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:16  Loss: 0.9217 (0.8627)  Acc@1: 81.2500 (85.5613)  Acc@5: 100.0000 (97.5325)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:14  Loss: 0.7072 (0.8602)  Acc@1: 87.5000 (85.5759)  Acc@5: 100.0000 (97.5451)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:12  Loss: 0.7584 (0.8641)  Acc@1: 81.2500 (85.4470)  Acc@5: 100.0000 (97.5442)  time: 0.2210  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:10  Loss: 0.8736 (0.8638)  Acc@1: 81.2500 (85.4379)  Acc@5: 100.0000 (97.5433)  time: 0.2228  data: 0.0027  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:08  Loss: 0.8247 (0.8657)  Acc@1: 81.2500 (85.3917)  Acc@5: 100.0000 (97.5299)  time: 0.2210  data: 0.0019  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:05  Loss: 0.9416 (0.8711)  Acc@1: 81.2500 (85.3229)  Acc@5: 93.7500 (97.4927)  time: 0.2188  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:03  Loss: 1.0726 (0.8779)  Acc@1: 81.2500 (85.2447)  Acc@5: 93.7500 (97.4328)  time: 0.2179  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:04:01  Loss: 0.8473 (0.8750)  Acc@1: 87.5000 (85.3225)  Acc@5: 100.0000 (97.4694)  time: 0.2175  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:59  Loss: 0.8324 (0.8753)  Acc@1: 87.5000 (85.3859)  Acc@5: 100.0000 (97.4469)  time: 0.2182  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:56  Loss: 0.9361 (0.8777)  Acc@1: 87.5000 (85.3902)  Acc@5: 100.0000 (97.4251)  time: 0.2208  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:54  Loss: 1.0166 (0.8795)  Acc@1: 81.2500 (85.3721)  Acc@5: 100.0000 (97.4376)  time: 0.2205  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:52  Loss: 0.8167 (0.8764)  Acc@1: 87.5000 (85.4203)  Acc@5: 100.0000 (97.4387)  time: 0.2184  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:50  Loss: 0.7876 (0.8770)  Acc@1: 87.5000 (85.4346)  Acc@5: 100.0000 (97.4505)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:48  Loss: 0.8292 (0.8752)  Acc@1: 87.5000 (85.5013)  Acc@5: 100.0000 (97.4619)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:46  Loss: 0.7755 (0.8772)  Acc@1: 87.5000 (85.4409)  Acc@5: 100.0000 (97.4938)  time: 0.2276  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:43  Loss: 0.8556 (0.8757)  Acc@1: 87.5000 (85.5667)  Acc@5: 100.0000 (97.4836)  time: 0.2272  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:41  Loss: 0.8193 (0.8778)  Acc@1: 87.5000 (85.5173)  Acc@5: 100.0000 (97.4638)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:39  Loss: 0.7646 (0.8774)  Acc@1: 87.5000 (85.5487)  Acc@5: 100.0000 (97.4643)  time: 0.2186  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:37  Loss: 0.7254 (0.8771)  Acc@1: 87.5000 (85.5597)  Acc@5: 100.0000 (97.4746)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:34  Loss: 0.7553 (0.8761)  Acc@1: 87.5000 (85.5511)  Acc@5: 100.0000 (97.4942)  time: 0.2177  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:32  Loss: 0.7534 (0.8748)  Acc@1: 87.5000 (85.5616)  Acc@5: 100.0000 (97.4943)  time: 0.2173  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:30  Loss: 0.8258 (0.8746)  Acc@1: 87.5000 (85.5440)  Acc@5: 100.0000 (97.5037)  time: 0.2175  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:28  Loss: 0.9056 (0.8740)  Acc@1: 87.5000 (85.5452)  Acc@5: 100.0000 (97.5037)  time: 0.2181  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:26  Loss: 0.8229 (0.8723)  Acc@1: 87.5000 (85.5734)  Acc@5: 100.0000 (97.5398)  time: 0.2209  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:23  Loss: 0.8229 (0.8722)  Acc@1: 87.5000 (85.5831)  Acc@5: 100.0000 (97.5303)  time: 0.2219  data: 0.0019  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:21  Loss: 0.7648 (0.8696)  Acc@1: 87.5000 (85.6628)  Acc@5: 100.0000 (97.5475)  time: 0.2201  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:19  Loss: 0.7289 (0.8685)  Acc@1: 87.5000 (85.6363)  Acc@5: 100.0000 (97.5555)  time: 0.2186  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:17  Loss: 0.8350 (0.8690)  Acc@1: 81.2500 (85.6190)  Acc@5: 100.0000 (97.5547)  time: 0.2178  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:15  Loss: 0.8350 (0.8701)  Acc@1: 81.2500 (85.6022)  Acc@5: 100.0000 (97.5287)  time: 0.2188  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:12  Loss: 0.8528 (0.8693)  Acc@1: 87.5000 (85.6441)  Acc@5: 100.0000 (97.5366)  time: 0.2188  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:10  Loss: 0.9182 (0.8724)  Acc@1: 87.5000 (85.6275)  Acc@5: 100.0000 (97.5033)  time: 0.2216  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:08  Loss: 0.7593 (0.8697)  Acc@1: 93.7500 (85.7166)  Acc@5: 100.0000 (97.5195)  time: 0.2235  data: 0.0024  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:06  Loss: 0.6450 (0.8684)  Acc@1: 93.7500 (85.7634)  Acc@5: 100.0000 (97.5272)  time: 0.2207  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:04  Loss: 0.7015 (0.8701)  Acc@1: 87.5000 (85.7459)  Acc@5: 100.0000 (97.5111)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:03:01  Loss: 0.7476 (0.8688)  Acc@1: 87.5000 (85.7756)  Acc@5: 100.0000 (97.5343)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:59  Loss: 0.7176 (0.8683)  Acc@1: 87.5000 (85.7969)  Acc@5: 100.0000 (97.5416)  time: 0.2206  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:57  Loss: 0.7176 (0.8674)  Acc@1: 87.5000 (85.8252)  Acc@5: 100.0000 (97.5335)  time: 0.2210  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:55  Loss: 0.7004 (0.8666)  Acc@1: 93.7500 (85.8454)  Acc@5: 100.0000 (97.5481)  time: 0.2276  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:53  Loss: 0.6325 (0.8643)  Acc@1: 93.7500 (85.8873)  Acc@5: 100.0000 (97.5699)  time: 0.2292  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:51  Loss: 0.7146 (0.8654)  Acc@1: 87.5000 (85.8475)  Acc@5: 100.0000 (97.5764)  time: 0.2206  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 0.7146 (0.8645)  Acc@1: 87.5000 (85.9030)  Acc@5: 100.0000 (97.5973)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:46  Loss: 0.6750 (0.8631)  Acc@1: 87.5000 (85.8998)  Acc@5: 100.0000 (97.6033)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:44  Loss: 0.8457 (0.8646)  Acc@1: 87.5000 (85.8612)  Acc@5: 100.0000 (97.6163)  time: 0.2213  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:42  Loss: 0.9288 (0.8667)  Acc@1: 87.5000 (85.8726)  Acc@5: 100.0000 (97.6010)  time: 0.2302  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:40  Loss: 0.9288 (0.8665)  Acc@1: 81.2500 (85.8837)  Acc@5: 100.0000 (97.5860)  time: 0.2287  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 0.9369 (0.8681)  Acc@1: 81.2500 (85.8397)  Acc@5: 93.7500 (97.5508)  time: 0.2198  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 0.8170 (0.8674)  Acc@1: 87.5000 (85.8713)  Acc@5: 100.0000 (97.5502)  time: 0.2178  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:33  Loss: 0.7733 (0.8674)  Acc@1: 87.5000 (85.8821)  Acc@5: 93.7500 (97.5295)  time: 0.2171  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:31  Loss: 0.7733 (0.8661)  Acc@1: 87.5000 (85.9192)  Acc@5: 100.0000 (97.5491)  time: 0.2166  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:29  Loss: 0.8751 (0.8668)  Acc@1: 87.5000 (85.8964)  Acc@5: 100.0000 (97.5486)  time: 0.2169  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 0.9016 (0.8665)  Acc@1: 81.2500 (85.8676)  Acc@5: 100.0000 (97.5676)  time: 0.2169  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 0.7679 (0.8656)  Acc@1: 87.5000 (85.8780)  Acc@5: 100.0000 (97.5734)  time: 0.2176  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:22  Loss: 0.7531 (0.8658)  Acc@1: 87.5000 (85.9136)  Acc@5: 100.0000 (97.5599)  time: 0.2174  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:20  Loss: 1.0130 (0.8683)  Acc@1: 87.5000 (85.9107)  Acc@5: 93.7500 (97.5404)  time: 0.2167  data: 0.0003  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 1.0002 (0.8687)  Acc@1: 87.5000 (85.8891)  Acc@5: 93.7500 (97.5212)  time: 0.2167  data: 0.0003  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 0.8671 (0.8683)  Acc@1: 87.5000 (85.8865)  Acc@5: 100.0000 (97.5210)  time: 0.2176  data: 0.0004  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 0.8281 (0.8678)  Acc@1: 87.5000 (85.8839)  Acc@5: 100.0000 (97.5331)  time: 0.2219  data: 0.0017  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:11  Loss: 0.6333 (0.8660)  Acc@1: 87.5000 (85.9239)  Acc@5: 100.0000 (97.5509)  time: 0.2240  data: 0.0032  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:09  Loss: 0.6034 (0.8645)  Acc@1: 87.5000 (85.9450)  Acc@5: 100.0000 (97.5684)  time: 0.2223  data: 0.0027  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 0.7084 (0.8631)  Acc@1: 87.5000 (85.9657)  Acc@5: 100.0000 (97.5678)  time: 0.2195  data: 0.0011  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 0.8162 (0.8638)  Acc@1: 87.5000 (85.9508)  Acc@5: 100.0000 (97.5554)  time: 0.2172  data: 0.0004  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 0.8296 (0.8643)  Acc@1: 87.5000 (85.9711)  Acc@5: 100.0000 (97.5490)  time: 0.2188  data: 0.0006  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:02:00  Loss: 0.7630 (0.8648)  Acc@1: 87.5000 (85.9621)  Acc@5: 100.0000 (97.5428)  time: 0.2211  data: 0.0007  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:58  Loss: 0.8143 (0.8650)  Acc@1: 87.5000 (85.9762)  Acc@5: 100.0000 (97.5424)  time: 0.2240  data: 0.0010  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:56  Loss: 0.7702 (0.8635)  Acc@1: 87.5000 (86.0070)  Acc@5: 100.0000 (97.5477)  time: 0.2242  data: 0.0016  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 0.6626 (0.8634)  Acc@1: 87.5000 (86.0149)  Acc@5: 100.0000 (97.5416)  time: 0.2205  data: 0.0012  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 0.7943 (0.8644)  Acc@1: 81.2500 (85.9779)  Acc@5: 100.0000 (97.5245)  time: 0.2184  data: 0.0006  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 0.7943 (0.8646)  Acc@1: 81.2500 (85.9748)  Acc@5: 100.0000 (97.5188)  time: 0.2187  data: 0.0013  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:47  Loss: 0.8784 (0.8657)  Acc@1: 87.5000 (85.9498)  Acc@5: 100.0000 (97.5186)  time: 0.2194  data: 0.0015  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:45  Loss: 0.9641 (0.8664)  Acc@1: 81.2500 (85.8981)  Acc@5: 100.0000 (97.5239)  time: 0.2246  data: 0.0006  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 0.8558 (0.8654)  Acc@1: 81.2500 (85.9281)  Acc@5: 100.0000 (97.5345)  time: 0.2306  data: 0.0011  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 0.7726 (0.8644)  Acc@1: 93.7500 (85.9468)  Acc@5: 100.0000 (97.5502)  time: 0.2253  data: 0.0012  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 0.8325 (0.8647)  Acc@1: 87.5000 (85.9441)  Acc@5: 100.0000 (97.5603)  time: 0.2207  data: 0.0005  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:36  Loss: 0.8658 (0.8653)  Acc@1: 81.2500 (85.9257)  Acc@5: 100.0000 (97.5703)  time: 0.2196  data: 0.0003  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:34  Loss: 0.8666 (0.8652)  Acc@1: 81.2500 (85.9336)  Acc@5: 100.0000 (97.5645)  time: 0.2172  data: 0.0003  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 0.7416 (0.8659)  Acc@1: 81.2500 (85.8898)  Acc@5: 100.0000 (97.5640)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 0.7162 (0.8651)  Acc@1: 81.2500 (85.8825)  Acc@5: 100.0000 (97.5737)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 0.8706 (0.8657)  Acc@1: 81.2500 (85.8245)  Acc@5: 100.0000 (97.5833)  time: 0.2190  data: 0.0006  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:25  Loss: 0.8706 (0.8655)  Acc@1: 81.2500 (85.8229)  Acc@5: 100.0000 (97.5826)  time: 0.2188  data: 0.0006  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:23  Loss: 0.9259 (0.8658)  Acc@1: 87.5000 (85.8263)  Acc@5: 100.0000 (97.5869)  time: 0.2172  data: 0.0004  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 0.8579 (0.8656)  Acc@1: 87.5000 (85.8297)  Acc@5: 100.0000 (97.5813)  time: 0.2168  data: 0.0003  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 0.8275 (0.8665)  Acc@1: 81.2500 (85.7887)  Acc@5: 100.0000 (97.5708)  time: 0.2170  data: 0.0003  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 0.7402 (0.8650)  Acc@1: 81.2500 (85.7972)  Acc@5: 100.0000 (97.5849)  time: 0.2176  data: 0.0003  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:14  Loss: 0.7797 (0.8653)  Acc@1: 81.2500 (85.7911)  Acc@5: 100.0000 (97.5891)  time: 0.2202  data: 0.0014  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 0.8682 (0.8648)  Acc@1: 87.5000 (85.8186)  Acc@5: 100.0000 (97.5932)  time: 0.2192  data: 0.0014  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 0.5935 (0.8636)  Acc@1: 87.5000 (85.8553)  Acc@5: 100.0000 (97.5877)  time: 0.2161  data: 0.0002  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 0.5866 (0.8621)  Acc@1: 93.7500 (85.8961)  Acc@5: 100.0000 (97.5918)  time: 0.2168  data: 0.0003  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 0.6633 (0.8622)  Acc@1: 93.7500 (85.8988)  Acc@5: 100.0000 (97.5911)  time: 0.2181  data: 0.0005  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:03  Loss: 0.7982 (0.8624)  Acc@1: 87.5000 (85.8641)  Acc@5: 100.0000 (97.5997)  time: 0.2181  data: 0.0006  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 0.7901 (0.8617)  Acc@1: 87.5000 (85.8855)  Acc@5: 100.0000 (97.5944)  time: 0.2200  data: 0.0006  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 0.7608 (0.8612)  Acc@1: 87.5000 (85.9019)  Acc@5: 100.0000 (97.6120)  time: 0.2212  data: 0.0006  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 0.7534 (0.8601)  Acc@1: 87.5000 (85.9181)  Acc@5: 100.0000 (97.6204)  time: 0.2193  data: 0.0005  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 0.7575 (0.8602)  Acc@1: 87.5000 (85.9115)  Acc@5: 100.0000 (97.6150)  time: 0.2189  data: 0.0006  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:52  Loss: 0.9055 (0.8597)  Acc@1: 87.5000 (85.9094)  Acc@5: 100.0000 (97.6276)  time: 0.2204  data: 0.0009  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 0.8135 (0.8602)  Acc@1: 87.5000 (85.8806)  Acc@5: 100.0000 (97.6133)  time: 0.2278  data: 0.0009  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.6863 (0.8597)  Acc@1: 87.5000 (85.9098)  Acc@5: 100.0000 (97.6214)  time: 0.2309  data: 0.0006  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 0.7178 (0.8591)  Acc@1: 87.5000 (85.9210)  Acc@5: 100.0000 (97.6337)  time: 0.2268  data: 0.0014  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 0.9625 (0.8612)  Acc@1: 81.2500 (85.8927)  Acc@5: 100.0000 (97.5978)  time: 0.2234  data: 0.0017  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 0.8942 (0.8608)  Acc@1: 81.2500 (85.8952)  Acc@5: 100.0000 (97.6058)  time: 0.2234  data: 0.0016  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 0.8903 (0.8620)  Acc@1: 81.2500 (85.8675)  Acc@5: 100.0000 (97.6008)  time: 0.2230  data: 0.0012  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 0.9363 (0.8622)  Acc@1: 87.5000 (85.8616)  Acc@5: 100.0000 (97.5873)  time: 0.2192  data: 0.0005  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 0.7939 (0.8626)  Acc@1: 87.5000 (85.8472)  Acc@5: 100.0000 (97.5824)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 0.9037 (0.8628)  Acc@1: 87.5000 (85.8415)  Acc@5: 100.0000 (97.5692)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 0.9054 (0.8633)  Acc@1: 87.5000 (85.8400)  Acc@5: 100.0000 (97.5604)  time: 0.2248  data: 0.0012  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.8738 (0.8636)  Acc@1: 87.5000 (85.8428)  Acc@5: 100.0000 (97.5475)  time: 0.2263  data: 0.0023  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.6781 (0.8635)  Acc@1: 87.5000 (85.8661)  Acc@5: 100.0000 (97.5430)  time: 0.2214  data: 0.0018  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.6618 (0.8623)  Acc@1: 93.7500 (85.8933)  Acc@5: 100.0000 (97.5510)  time: 0.2203  data: 0.0009  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.6618 (0.8617)  Acc@1: 87.5000 (85.8752)  Acc@5: 100.0000 (97.5588)  time: 0.2192  data: 0.0006  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 0.6113 (0.8607)  Acc@1: 93.7500 (85.8980)  Acc@5: 100.0000 (97.5665)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.6136 (0.8600)  Acc@1: 93.7500 (85.9083)  Acc@5: 100.0000 (97.5701)  time: 0.2181  data: 0.0004  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.6136 (0.8592)  Acc@1: 87.5000 (85.9305)  Acc@5: 100.0000 (97.5737)  time: 0.2209  data: 0.0014  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.7600 (0.8591)  Acc@1: 87.5000 (85.9564)  Acc@5: 100.0000 (97.5692)  time: 0.2211  data: 0.0014  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.7700 (0.8595)  Acc@1: 87.5000 (85.9385)  Acc@5: 100.0000 (97.5727)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.7741 (0.8594)  Acc@1: 87.5000 (85.9326)  Acc@5: 100.0000 (97.5801)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 0.8048 (0.8602)  Acc@1: 81.2500 (85.9229)  Acc@5: 100.0000 (97.5874)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.7735 (0.8596)  Acc@1: 87.5000 (85.9404)  Acc@5: 100.0000 (97.5985)  time: 0.2182  data: 0.0004  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.7045 (0.8586)  Acc@1: 93.7500 (85.9732)  Acc@5: 100.0000 (97.5979)  time: 0.2214  data: 0.0004  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.7045 (0.8582)  Acc@1: 93.7500 (85.9865)  Acc@5: 100.0000 (97.6030)  time: 0.2256  data: 0.0003  max mem: 2500
Test: [Task 1] Total time: 0:05:58 (0.2205 s / it)
* Acc@1 85.986 Acc@5 97.603 loss 0.858
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task1]	Acc@1: 85.9865	Acc@5: 97.6030	Loss: 0.8582
Train: Epoch[1/5]  [   0/3750]  eta: 0:51:18  Lr: 0.001875  Loss: 2.3074  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  time: 0.8210  data: 0.4554  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:24:22  Lr: 0.001875  Loss: 1.9673  Acc@1: 18.7500 (21.5909)  Acc@5: 62.5000 (62.5000)  time: 0.3911  data: 0.0417  max mem: 2500
Train: Epoch[1/5]  [  20/3750]  eta: 0:23:03  Lr: 0.001875  Loss: 2.0801  Acc@1: 25.0000 (23.2143)  Acc@5: 62.5000 (64.8810)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:35  Lr: 0.001875  Loss: 1.8202  Acc@1: 31.2500 (29.0323)  Acc@5: 75.0000 (70.1613)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:26  Lr: 0.001875  Loss: 1.8190  Acc@1: 43.7500 (33.5366)  Acc@5: 81.2500 (74.0854)  time: 0.3549  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [  50/3750]  eta: 0:22:18  Lr: 0.001875  Loss: 1.5444  Acc@1: 50.0000 (36.1520)  Acc@5: 87.5000 (76.7157)  time: 0.3580  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [  60/3750]  eta: 0:22:11  Lr: 0.001875  Loss: 1.4030  Acc@1: 50.0000 (39.0369)  Acc@5: 87.5000 (78.7910)  time: 0.3565  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [  70/3750]  eta: 0:22:06  Lr: 0.001875  Loss: 1.6899  Acc@1: 56.2500 (40.8451)  Acc@5: 87.5000 (80.1937)  time: 0.3566  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:58  Lr: 0.001875  Loss: 0.8337  Acc@1: 56.2500 (42.7469)  Acc@5: 93.7500 (81.8673)  time: 0.3542  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:53  Lr: 0.001875  Loss: 1.1473  Acc@1: 56.2500 (44.5055)  Acc@5: 93.7500 (83.0357)  time: 0.3541  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:46  Lr: 0.001875  Loss: 0.8664  Acc@1: 68.7500 (46.2871)  Acc@5: 93.7500 (84.2203)  time: 0.3528  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:42  Lr: 0.001875  Loss: 1.0832  Acc@1: 62.5000 (48.1419)  Acc@5: 93.7500 (84.9099)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:36  Lr: 0.001875  Loss: 0.8074  Acc@1: 62.5000 (49.3285)  Acc@5: 93.7500 (85.5372)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:33  Lr: 0.001875  Loss: 0.8524  Acc@1: 56.2500 (50.1431)  Acc@5: 93.7500 (86.0687)  time: 0.3551  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:28  Lr: 0.001875  Loss: 0.7149  Acc@1: 62.5000 (51.3741)  Acc@5: 93.7500 (86.6578)  time: 0.3549  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:23  Lr: 0.001875  Loss: 0.8925  Acc@1: 68.7500 (52.2351)  Acc@5: 93.7500 (87.0033)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:18  Lr: 0.001875  Loss: 0.5220  Acc@1: 62.5000 (53.0668)  Acc@5: 93.7500 (87.5776)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 170/3750]  eta: 0:21:13  Lr: 0.001875  Loss: 0.7664  Acc@1: 62.5000 (53.5819)  Acc@5: 93.7500 (87.9020)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 180/3750]  eta: 0:21:09  Lr: 0.001875  Loss: 0.4472  Acc@1: 62.5000 (54.3854)  Acc@5: 93.7500 (88.3287)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 190/3750]  eta: 0:21:04  Lr: 0.001875  Loss: 0.7265  Acc@1: 62.5000 (54.5812)  Acc@5: 100.0000 (88.6126)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:59  Lr: 0.001875  Loss: 0.3230  Acc@1: 62.5000 (55.2550)  Acc@5: 93.7500 (88.8993)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:54  Lr: 0.001875  Loss: 0.3282  Acc@1: 68.7500 (55.8649)  Acc@5: 93.7500 (89.2476)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:50  Lr: 0.001875  Loss: 0.5842  Acc@1: 68.7500 (56.2783)  Acc@5: 93.7500 (89.4514)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:46  Lr: 0.001875  Loss: 0.4223  Acc@1: 62.5000 (56.7100)  Acc@5: 93.7500 (89.5563)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:41  Lr: 0.001875  Loss: 0.5057  Acc@1: 62.5000 (57.1317)  Acc@5: 93.7500 (89.7562)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:37  Lr: 0.001875  Loss: 0.1403  Acc@1: 68.7500 (57.6444)  Acc@5: 93.7500 (89.8904)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:33  Lr: 0.001875  Loss: 0.1183  Acc@1: 75.0000 (58.2136)  Acc@5: 93.7500 (90.0862)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.0273  Acc@1: 75.0000 (58.6716)  Acc@5: 93.7500 (90.2906)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:26  Lr: 0.001875  Loss: 0.3497  Acc@1: 68.7500 (58.8746)  Acc@5: 93.7500 (90.4359)  time: 0.3549  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:23  Lr: 0.001875  Loss: 0.1637  Acc@1: 62.5000 (59.1710)  Acc@5: 93.7500 (90.5713)  time: 0.3561  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:19  Lr: 0.001875  Loss: 0.0846  Acc@1: 68.7500 (59.5930)  Acc@5: 93.7500 (90.5523)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.3571  Acc@1: 68.7500 (59.9277)  Acc@5: 93.7500 (90.6953)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:11  Lr: 0.001875  Loss: 0.0861  Acc@1: 68.7500 (60.2220)  Acc@5: 100.0000 (90.9268)  time: 0.3517  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 330/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.0048  Acc@1: 68.7500 (60.4418)  Acc@5: 100.0000 (91.0121)  time: 0.3551  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 340/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.2409  Acc@1: 75.0000 (60.8321)  Acc@5: 93.7500 (91.0924)  time: 0.3536  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 350/3750]  eta: 0:20:01  Lr: 0.001875  Loss: 0.0952  Acc@1: 75.0000 (61.0221)  Acc@5: 93.7500 (91.1681)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:57  Lr: 0.001875  Loss: 0.5472  Acc@1: 68.7500 (61.2535)  Acc@5: 93.7500 (91.1530)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:53  Lr: 0.001875  Loss: 0.2376  Acc@1: 68.7500 (61.6577)  Acc@5: 93.7500 (91.2736)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -0.5252  Acc@1: 75.0000 (61.9915)  Acc@5: 93.7500 (91.3386)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.7802  Acc@1: 75.0000 (62.2602)  Acc@5: 93.7500 (91.3683)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:42  Lr: 0.001875  Loss: 0.0509  Acc@1: 68.7500 (62.5468)  Acc@5: 93.7500 (91.4433)  time: 0.3518  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:38  Lr: 0.001875  Loss: 0.0195  Acc@1: 62.5000 (62.5912)  Acc@5: 93.7500 (91.5602)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.2832  Acc@1: 68.7500 (62.8711)  Acc@5: 93.7500 (91.6568)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.2736  Acc@1: 68.7500 (62.9640)  Acc@5: 93.7500 (91.6763)  time: 0.3525  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.3459  Acc@1: 68.7500 (63.1661)  Acc@5: 93.7500 (91.7092)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.6429  Acc@1: 68.7500 (63.3731)  Acc@5: 93.7500 (91.8237)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.2614  Acc@1: 68.7500 (63.5846)  Acc@5: 93.7500 (91.9197)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.0426  Acc@1: 75.0000 (63.7872)  Acc@5: 93.7500 (91.9055)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:13  Lr: 0.001875  Loss: 0.0254  Acc@1: 81.2500 (64.0982)  Acc@5: 93.7500 (92.0088)  time: 0.3556  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 490/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.0328  Acc@1: 75.0000 (64.2057)  Acc@5: 93.7500 (92.0698)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 500/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.6873  Acc@1: 62.5000 (64.2091)  Acc@5: 93.7500 (92.1158)  time: 0.3572  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 510/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.3849  Acc@1: 68.7500 (64.2979)  Acc@5: 93.7500 (92.1600)  time: 0.3596  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 520/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.5996  Acc@1: 68.7500 (64.5154)  Acc@5: 93.7500 (92.2025)  time: 0.3557  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.4781  Acc@1: 75.0000 (64.7481)  Acc@5: 93.7500 (92.2552)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.1649  Acc@1: 75.0000 (64.9030)  Acc@5: 93.7500 (92.3059)  time: 0.3519  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.6734  Acc@1: 68.7500 (64.9274)  Acc@5: 93.7500 (92.3321)  time: 0.3531  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.6010  Acc@1: 68.7500 (64.9844)  Acc@5: 93.7500 (92.3574)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.6803  Acc@1: 75.0000 (65.1160)  Acc@5: 93.7500 (92.3599)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.0511  Acc@1: 68.7500 (65.1893)  Acc@5: 93.7500 (92.4053)  time: 0.3544  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.5176  Acc@1: 75.0000 (65.3553)  Acc@5: 93.7500 (92.4387)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.6465  Acc@1: 75.0000 (65.4638)  Acc@5: 93.7500 (92.4501)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.6988  Acc@1: 75.0000 (65.5790)  Acc@5: 93.7500 (92.4611)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.6095  Acc@1: 75.0000 (65.6200)  Acc@5: 93.7500 (92.4919)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.3982  Acc@1: 68.7500 (65.6894)  Acc@5: 93.7500 (92.4624)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.2725  Acc@1: 62.5000 (65.6396)  Acc@5: 93.7500 (92.4434)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.5005  Acc@1: 68.7500 (65.7642)  Acc@5: 93.7500 (92.4731)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.4470  Acc@1: 75.0000 (65.9228)  Acc@5: 93.7500 (92.5113)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 670/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.7613  Acc@1: 75.0000 (66.0395)  Acc@5: 100.0000 (92.5671)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 680/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.5043  Acc@1: 68.7500 (66.1344)  Acc@5: 93.7500 (92.5661)  time: 0.3530  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.4516  Acc@1: 68.7500 (66.1451)  Acc@5: 93.7500 (92.5380)  time: 0.3569  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.8235  Acc@1: 68.7500 (66.1912)  Acc@5: 93.7500 (92.5374)  time: 0.3601  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.6923  Acc@1: 68.7500 (66.3326)  Acc@5: 93.7500 (92.5545)  time: 0.3603  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.6079  Acc@1: 75.0000 (66.3662)  Acc@5: 93.7500 (92.5624)  time: 0.3554  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -1.1167  Acc@1: 68.7500 (66.4586)  Acc@5: 93.7500 (92.5872)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.6568  Acc@1: 75.0000 (66.5739)  Acc@5: 93.7500 (92.6366)  time: 0.3557  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.6916  Acc@1: 75.0000 (66.6611)  Acc@5: 93.7500 (92.6182)  time: 0.3595  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -1.1039  Acc@1: 75.0000 (66.7461)  Acc@5: 93.7500 (92.6248)  time: 0.3547  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6187  Acc@1: 68.7500 (66.8531)  Acc@5: 93.7500 (92.6637)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.1407  Acc@1: 75.0000 (66.9254)  Acc@5: 93.7500 (92.6857)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.9812  Acc@1: 68.7500 (66.9722)  Acc@5: 93.7500 (92.6833)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -1.1428  Acc@1: 68.7500 (67.1192)  Acc@5: 93.7500 (92.7356)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.3342  Acc@1: 75.0000 (67.1933)  Acc@5: 93.7500 (92.7250)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -1.0804  Acc@1: 81.2500 (67.3340)  Acc@5: 93.7500 (92.7680)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.8309  Acc@1: 75.0000 (67.3887)  Acc@5: 93.7500 (92.7497)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 840/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.6782  Acc@1: 68.7500 (67.4420)  Acc@5: 93.7500 (92.7616)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 850/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.6780  Acc@1: 68.7500 (67.5162)  Acc@5: 100.0000 (92.8173)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.6346  Acc@1: 75.0000 (67.5668)  Acc@5: 93.7500 (92.8208)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.4733  Acc@1: 75.0000 (67.6091)  Acc@5: 93.7500 (92.8387)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.9617  Acc@1: 75.0000 (67.6788)  Acc@5: 100.0000 (92.8703)  time: 0.3548  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.9104  Acc@1: 75.0000 (67.8171)  Acc@5: 100.0000 (92.9082)  time: 0.3565  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.6019  Acc@1: 75.0000 (67.8968)  Acc@5: 93.7500 (92.9384)  time: 0.3598  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -1.1155  Acc@1: 75.0000 (67.9748)  Acc@5: 93.7500 (92.9679)  time: 0.3596  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.5358  Acc@1: 75.0000 (68.0578)  Acc@5: 93.7500 (93.0171)  time: 0.3545  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.8244  Acc@1: 75.0000 (68.1592)  Acc@5: 93.7500 (93.0317)  time: 0.3558  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.9264  Acc@1: 75.0000 (68.2319)  Acc@5: 93.7500 (93.0460)  time: 0.3576  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.2320  Acc@1: 68.7500 (68.3294)  Acc@5: 100.0000 (93.0731)  time: 0.3572  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.5908  Acc@1: 81.2500 (68.4443)  Acc@5: 93.7500 (93.0931)  time: 0.3554  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.7155  Acc@1: 75.0000 (68.5118)  Acc@5: 93.7500 (93.1063)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.6568  Acc@1: 75.0000 (68.5652)  Acc@5: 93.7500 (93.1193)  time: 0.3556  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.8590  Acc@1: 68.7500 (68.6049)  Acc@5: 93.7500 (93.1382)  time: 0.3571  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1000/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.5328  Acc@1: 75.0000 (68.6501)  Acc@5: 93.7500 (93.1194)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1010/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.8277  Acc@1: 75.0000 (68.6635)  Acc@5: 93.7500 (93.0823)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1020/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.7944  Acc@1: 75.0000 (68.7255)  Acc@5: 93.7500 (93.1134)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1030/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.8953  Acc@1: 75.0000 (68.7803)  Acc@5: 93.7500 (93.1256)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.6003  Acc@1: 75.0000 (68.8581)  Acc@5: 93.7500 (93.1376)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.8239  Acc@1: 75.0000 (68.9106)  Acc@5: 100.0000 (93.1613)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -0.7010  Acc@1: 68.7500 (68.9090)  Acc@5: 93.7500 (93.1845)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.9575  Acc@1: 68.7500 (68.9601)  Acc@5: 93.7500 (93.2131)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -1.1922  Acc@1: 75.0000 (68.9870)  Acc@5: 93.7500 (93.2181)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -1.2472  Acc@1: 75.0000 (69.0651)  Acc@5: 100.0000 (93.2516)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.6366  Acc@1: 75.0000 (69.0963)  Acc@5: 93.7500 (93.2788)  time: 0.3577  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.7726  Acc@1: 75.0000 (69.1775)  Acc@5: 93.7500 (93.3168)  time: 0.3603  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.4599  Acc@1: 75.0000 (69.2741)  Acc@5: 93.7500 (93.3263)  time: 0.3581  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.8494  Acc@1: 81.2500 (69.3413)  Acc@5: 93.7500 (93.3632)  time: 0.3543  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.6831  Acc@1: 75.0000 (69.3690)  Acc@5: 100.0000 (93.3775)  time: 0.3526  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.6266  Acc@1: 68.7500 (69.3636)  Acc@5: 93.7500 (93.4133)  time: 0.3549  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.8761  Acc@1: 75.0000 (69.4283)  Acc@5: 100.0000 (93.4324)  time: 0.3573  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.6737  Acc@1: 81.2500 (69.4865)  Acc@5: 93.7500 (93.4351)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1180/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.7502  Acc@1: 81.2500 (69.5438)  Acc@5: 93.7500 (93.4695)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1190/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.1827  Acc@1: 75.0000 (69.5896)  Acc@5: 100.0000 (93.4824)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1200/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.5817  Acc@1: 81.2500 (69.6711)  Acc@5: 100.0000 (93.5002)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.7672  Acc@1: 75.0000 (69.7100)  Acc@5: 93.7500 (93.4919)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.9729  Acc@1: 75.0000 (69.7584)  Acc@5: 93.7500 (93.5145)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.8061  Acc@1: 75.0000 (69.7807)  Acc@5: 93.7500 (93.5063)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.8322  Acc@1: 75.0000 (69.8378)  Acc@5: 93.7500 (93.5334)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.1118  Acc@1: 75.0000 (69.8441)  Acc@5: 100.0000 (93.5602)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.6684  Acc@1: 75.0000 (69.8999)  Acc@5: 93.7500 (93.5765)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.6977  Acc@1: 75.0000 (69.9203)  Acc@5: 93.7500 (93.5877)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -1.0889  Acc@1: 75.0000 (69.9698)  Acc@5: 93.7500 (93.6085)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.4648  Acc@1: 75.0000 (69.9893)  Acc@5: 100.0000 (93.6290)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.5259  Acc@1: 75.0000 (70.0615)  Acc@5: 93.7500 (93.6395)  time: 0.3544  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.7980  Acc@1: 81.2500 (70.1230)  Acc@5: 93.7500 (93.6499)  time: 0.3538  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.7357  Acc@1: 75.0000 (70.1552)  Acc@5: 93.7500 (93.6696)  time: 0.3551  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.2289  Acc@1: 75.0000 (70.2245)  Acc@5: 93.7500 (93.6796)  time: 0.3547  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.9938  Acc@1: 75.0000 (70.2414)  Acc@5: 93.7500 (93.7081)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1350/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.3551  Acc@1: 68.7500 (70.2581)  Acc@5: 100.0000 (93.7084)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1360/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -0.5775  Acc@1: 68.7500 (70.3068)  Acc@5: 100.0000 (93.7454)  time: 0.3538  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1370/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.8768  Acc@1: 75.0000 (70.3592)  Acc@5: 100.0000 (93.7454)  time: 0.3516  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.8163  Acc@1: 75.0000 (70.3883)  Acc@5: 93.7500 (93.7726)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6962  Acc@1: 75.0000 (70.4080)  Acc@5: 93.7500 (93.7815)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -1.2042  Acc@1: 75.0000 (70.4274)  Acc@5: 93.7500 (93.7857)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.7984  Acc@1: 75.0000 (70.4775)  Acc@5: 93.7500 (93.7987)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.2255  Acc@1: 75.0000 (70.4741)  Acc@5: 93.7500 (93.7984)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.9235  Acc@1: 75.0000 (70.5189)  Acc@5: 93.7500 (93.8068)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.5736  Acc@1: 75.0000 (70.5109)  Acc@5: 93.7500 (93.8107)  time: 0.3522  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.9780  Acc@1: 68.7500 (70.5419)  Acc@5: 93.7500 (93.8232)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.9726  Acc@1: 75.0000 (70.6066)  Acc@5: 100.0000 (93.8484)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -0.9343  Acc@1: 81.2500 (70.6492)  Acc@5: 100.0000 (93.8690)  time: 0.3514  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.6756  Acc@1: 75.0000 (70.6997)  Acc@5: 93.7500 (93.8724)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.4024  Acc@1: 81.2500 (70.7453)  Acc@5: 93.7500 (93.8967)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.5190  Acc@1: 81.2500 (70.7986)  Acc@5: 93.7500 (93.9082)  time: 0.3547  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.8516  Acc@1: 81.2500 (70.8637)  Acc@5: 93.7500 (93.9155)  time: 0.3583  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1520/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.5016  Acc@1: 75.0000 (70.8868)  Acc@5: 93.7500 (93.9308)  time: 0.3556  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1530/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.4821  Acc@1: 75.0000 (70.9299)  Acc@5: 93.7500 (93.9337)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -1.1323  Acc@1: 81.2500 (70.9848)  Acc@5: 93.7500 (93.9528)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.6075  Acc@1: 75.0000 (71.0147)  Acc@5: 93.7500 (93.9595)  time: 0.3551  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -1.0710  Acc@1: 75.0000 (71.0682)  Acc@5: 93.7500 (93.9702)  time: 0.3551  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -1.2832  Acc@1: 75.0000 (71.1092)  Acc@5: 93.7500 (93.9768)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.6419  Acc@1: 75.0000 (71.1022)  Acc@5: 93.7500 (93.9595)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.9567  Acc@1: 75.0000 (71.1384)  Acc@5: 93.7500 (93.9739)  time: 0.3513  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.5429  Acc@1: 75.0000 (71.1391)  Acc@5: 93.7500 (93.9803)  time: 0.3520  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.6651  Acc@1: 75.0000 (71.1631)  Acc@5: 93.7500 (93.9905)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.2743  Acc@1: 75.0000 (71.1636)  Acc@5: 93.7500 (93.9775)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.2615  Acc@1: 75.0000 (71.2025)  Acc@5: 93.7500 (93.9876)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.6274  Acc@1: 75.0000 (71.2371)  Acc@5: 100.0000 (94.0014)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.9994  Acc@1: 81.2500 (71.2788)  Acc@5: 100.0000 (94.0112)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.9435  Acc@1: 75.0000 (71.3125)  Acc@5: 100.0000 (94.0209)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.8530  Acc@1: 75.0000 (71.3420)  Acc@5: 93.7500 (94.0193)  time: 0.3536  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.9083  Acc@1: 75.0000 (71.3526)  Acc@5: 93.7500 (94.0214)  time: 0.3536  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -1.1181  Acc@1: 81.2500 (71.3779)  Acc@5: 100.0000 (94.0420)  time: 0.3542  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1700/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.6527  Acc@1: 81.2500 (71.4286)  Acc@5: 93.7500 (94.0439)  time: 0.3544  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -1.0747  Acc@1: 81.2500 (71.4823)  Acc@5: 100.0000 (94.0495)  time: 0.3585  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.7117  Acc@1: 81.2500 (71.5245)  Acc@5: 100.0000 (94.0587)  time: 0.3577  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.4911  Acc@1: 81.2500 (71.5771)  Acc@5: 93.7500 (94.0786)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -1.0335  Acc@1: 81.2500 (71.6183)  Acc@5: 100.0000 (94.0839)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.7731  Acc@1: 81.2500 (71.6626)  Acc@5: 93.7500 (94.0891)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -1.0285  Acc@1: 75.0000 (71.6709)  Acc@5: 100.0000 (94.1085)  time: 0.3563  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -1.0245  Acc@1: 75.0000 (71.7074)  Acc@5: 100.0000 (94.1170)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -1.0992  Acc@1: 75.0000 (71.7364)  Acc@5: 93.7500 (94.1255)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.6190  Acc@1: 75.0000 (71.7790)  Acc@5: 100.0000 (94.1478)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.9297  Acc@1: 75.0000 (71.8316)  Acc@5: 93.7500 (94.1526)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -1.0607  Acc@1: 81.2500 (71.8595)  Acc@5: 93.7500 (94.1400)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.7652  Acc@1: 75.0000 (71.8836)  Acc@5: 93.7500 (94.1550)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -1.2510  Acc@1: 75.0000 (71.9074)  Acc@5: 93.7500 (94.1630)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.9672  Acc@1: 75.0000 (71.9650)  Acc@5: 100.0000 (94.1845)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -1.0504  Acc@1: 81.2500 (71.9645)  Acc@5: 100.0000 (94.1991)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.4278  Acc@1: 68.7500 (71.9506)  Acc@5: 93.7500 (94.1933)  time: 0.3558  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1870/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.9925  Acc@1: 75.0000 (72.0003)  Acc@5: 93.7500 (94.2076)  time: 0.3570  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -1.0306  Acc@1: 81.2500 (72.0295)  Acc@5: 100.0000 (94.2152)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.5286  Acc@1: 75.0000 (72.0452)  Acc@5: 93.7500 (94.2193)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -1.0796  Acc@1: 81.2500 (72.0969)  Acc@5: 100.0000 (94.2432)  time: 0.3557  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.8837  Acc@1: 81.2500 (72.1088)  Acc@5: 100.0000 (94.2406)  time: 0.3563  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:45  Lr: 0.001875  Loss: 0.0854  Acc@1: 75.0000 (72.1369)  Acc@5: 93.7500 (94.2478)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7023  Acc@1: 81.2500 (72.1517)  Acc@5: 93.7500 (94.2549)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -1.0472  Acc@1: 81.2500 (72.1696)  Acc@5: 93.7500 (94.2459)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -1.1734  Acc@1: 75.0000 (72.1809)  Acc@5: 93.7500 (94.2562)  time: 0.3559  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.6380  Acc@1: 75.0000 (72.2081)  Acc@5: 93.7500 (94.2536)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -0.6916  Acc@1: 81.2500 (72.2539)  Acc@5: 93.7500 (94.2669)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.6071  Acc@1: 81.2500 (72.2836)  Acc@5: 93.7500 (94.2643)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.6197  Acc@1: 75.0000 (72.2658)  Acc@5: 93.7500 (94.2680)  time: 0.3544  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.6799  Acc@1: 68.7500 (72.3107)  Acc@5: 100.0000 (94.2841)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.6743  Acc@1: 81.2500 (72.3458)  Acc@5: 93.7500 (94.2815)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -1.2151  Acc@1: 81.2500 (72.3837)  Acc@5: 93.7500 (94.2881)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2030/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.6260  Acc@1: 75.0000 (72.3904)  Acc@5: 93.7500 (94.2947)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2040/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.3949  Acc@1: 75.0000 (72.4277)  Acc@5: 93.7500 (94.3012)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -1.1853  Acc@1: 81.2500 (72.4647)  Acc@5: 93.7500 (94.3168)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.7247  Acc@1: 75.0000 (72.4436)  Acc@5: 93.7500 (94.3201)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.7174  Acc@1: 75.0000 (72.4499)  Acc@5: 93.7500 (94.3264)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.8315  Acc@1: 75.0000 (72.4712)  Acc@5: 100.0000 (94.3507)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.6546  Acc@1: 75.0000 (72.4623)  Acc@5: 100.0000 (94.3478)  time: 0.3520  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.8918  Acc@1: 75.0000 (72.4625)  Acc@5: 93.7500 (94.3569)  time: 0.3546  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.9054  Acc@1: 75.0000 (72.4953)  Acc@5: 93.7500 (94.3569)  time: 0.3531  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.3293  Acc@1: 75.0000 (72.4982)  Acc@5: 93.7500 (94.3629)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.7536  Acc@1: 75.0000 (72.5305)  Acc@5: 100.0000 (94.3718)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.9259  Acc@1: 81.2500 (72.5596)  Acc@5: 93.7500 (94.3718)  time: 0.3510  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -1.0751  Acc@1: 81.2500 (72.5622)  Acc@5: 93.7500 (94.3747)  time: 0.3525  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.9413  Acc@1: 75.0000 (72.5879)  Acc@5: 93.7500 (94.3892)  time: 0.3515  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -1.1673  Acc@1: 75.0000 (72.6105)  Acc@5: 100.0000 (94.4035)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.5536  Acc@1: 75.0000 (72.6301)  Acc@5: 93.7500 (94.4062)  time: 0.3506  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -1.2530  Acc@1: 75.0000 (72.6495)  Acc@5: 93.7500 (94.4204)  time: 0.3488  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2200/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -1.0321  Acc@1: 75.0000 (72.6886)  Acc@5: 100.0000 (94.4400)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2210/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.7454  Acc@1: 87.5000 (72.7301)  Acc@5: 100.0000 (94.4454)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.8930  Acc@1: 81.2500 (72.7488)  Acc@5: 100.0000 (94.4620)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.8505  Acc@1: 81.2500 (72.7757)  Acc@5: 100.0000 (94.4700)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.7353  Acc@1: 81.2500 (72.8023)  Acc@5: 100.0000 (94.4807)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.9080  Acc@1: 81.2500 (72.8537)  Acc@5: 100.0000 (94.4941)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.6622  Acc@1: 81.2500 (72.8632)  Acc@5: 100.0000 (94.5019)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.5744  Acc@1: 81.2500 (72.8946)  Acc@5: 100.0000 (94.5068)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.6205  Acc@1: 81.2500 (72.9148)  Acc@5: 93.7500 (94.5035)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.8222  Acc@1: 81.2500 (72.9594)  Acc@5: 93.7500 (94.5139)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.9490  Acc@1: 81.2500 (72.9873)  Acc@5: 93.7500 (94.5160)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -1.1088  Acc@1: 81.2500 (73.0230)  Acc@5: 93.7500 (94.5181)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -1.0680  Acc@1: 81.2500 (73.0369)  Acc@5: 93.7500 (94.5255)  time: 0.3521  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.7043  Acc@1: 81.2500 (73.0936)  Acc@5: 100.0000 (94.5410)  time: 0.3510  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.8402  Acc@1: 81.2500 (73.1151)  Acc@5: 100.0000 (94.5483)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.8778  Acc@1: 81.2500 (73.1550)  Acc@5: 93.7500 (94.5555)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.9985  Acc@1: 81.2500 (73.1920)  Acc@5: 100.0000 (94.5627)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -1.1757  Acc@1: 81.2500 (73.2154)  Acc@5: 100.0000 (94.5698)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2380/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.6836  Acc@1: 81.2500 (73.2308)  Acc@5: 93.7500 (94.5716)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -1.0237  Acc@1: 81.2500 (73.2591)  Acc@5: 93.7500 (94.5839)  time: 0.3500  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -1.0267  Acc@1: 81.2500 (73.2820)  Acc@5: 100.0000 (94.5934)  time: 0.3502  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.7494  Acc@1: 81.2500 (73.3124)  Acc@5: 100.0000 (94.6055)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:48  Lr: 0.001875  Loss: 0.3368  Acc@1: 75.0000 (73.2936)  Acc@5: 100.0000 (94.5993)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -1.1712  Acc@1: 75.0000 (73.3212)  Acc@5: 100.0000 (94.6138)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:41  Lr: 0.001875  Loss: 0.1498  Acc@1: 75.0000 (73.3306)  Acc@5: 100.0000 (94.6180)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.8912  Acc@1: 75.0000 (73.3578)  Acc@5: 100.0000 (94.6297)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:34  Lr: 0.001875  Loss: 0.0509  Acc@1: 75.0000 (73.3594)  Acc@5: 93.7500 (94.6287)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.7621  Acc@1: 75.0000 (73.3812)  Acc@5: 100.0000 (94.6429)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.9045  Acc@1: 81.2500 (73.4255)  Acc@5: 100.0000 (94.6493)  time: 0.3537  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.5251  Acc@1: 81.2500 (73.4369)  Acc@5: 93.7500 (94.6533)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.4444  Acc@1: 75.0000 (73.4556)  Acc@5: 93.7500 (94.6596)  time: 0.3524  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -1.1373  Acc@1: 75.0000 (73.4767)  Acc@5: 93.7500 (94.6635)  time: 0.3542  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.8146  Acc@1: 81.2500 (73.5100)  Acc@5: 93.7500 (94.6698)  time: 0.3541  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.7949  Acc@1: 75.0000 (73.5110)  Acc@5: 93.7500 (94.6661)  time: 0.3540  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.0978  Acc@1: 75.0000 (73.5291)  Acc@5: 93.7500 (94.6773)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2550/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.9320  Acc@1: 75.0000 (73.5447)  Acc@5: 100.0000 (94.6761)  time: 0.3557  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.7273  Acc@1: 75.0000 (73.5650)  Acc@5: 100.0000 (94.6847)  time: 0.3559  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.7596  Acc@1: 81.2500 (73.5779)  Acc@5: 100.0000 (94.6811)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.8699  Acc@1: 75.0000 (73.5858)  Acc@5: 93.7500 (94.6799)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -1.0063  Acc@1: 81.2500 (73.6033)  Acc@5: 93.7500 (94.6859)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.9307  Acc@1: 81.2500 (73.6399)  Acc@5: 100.0000 (94.6919)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.6049  Acc@1: 81.2500 (73.6499)  Acc@5: 100.0000 (94.7027)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.8477  Acc@1: 75.0000 (73.6456)  Acc@5: 100.0000 (94.7086)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.2795  Acc@1: 68.7500 (73.6531)  Acc@5: 100.0000 (94.7121)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6053  Acc@1: 75.0000 (73.6676)  Acc@5: 93.7500 (94.7013)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -1.1821  Acc@1: 81.2500 (73.7057)  Acc@5: 93.7500 (94.7095)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -1.3207  Acc@1: 81.2500 (73.7317)  Acc@5: 100.0000 (94.7200)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.8669  Acc@1: 81.2500 (73.7528)  Acc@5: 100.0000 (94.7234)  time: 0.3538  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.5484  Acc@1: 75.0000 (73.7481)  Acc@5: 100.0000 (94.7268)  time: 0.3520  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -1.2895  Acc@1: 75.0000 (73.7644)  Acc@5: 93.7500 (94.7301)  time: 0.3523  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -1.0236  Acc@1: 75.0000 (73.7829)  Acc@5: 93.7500 (94.7357)  time: 0.3545  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.6407  Acc@1: 75.0000 (73.7804)  Acc@5: 93.7500 (94.7367)  time: 0.3550  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.8079  Acc@1: 75.0000 (73.7734)  Acc@5: 93.7500 (94.7308)  time: 0.3548  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.4302  Acc@1: 75.0000 (73.7848)  Acc@5: 93.7500 (94.7409)  time: 0.3551  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.9360  Acc@1: 75.0000 (73.7983)  Acc@5: 93.7500 (94.7373)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.7882  Acc@1: 75.0000 (73.8050)  Acc@5: 93.7500 (94.7451)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -1.1337  Acc@1: 75.0000 (73.8319)  Acc@5: 100.0000 (94.7551)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.8726  Acc@1: 81.2500 (73.8429)  Acc@5: 100.0000 (94.7627)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6350  Acc@1: 75.0000 (73.8493)  Acc@5: 100.0000 (94.7703)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.8517  Acc@1: 75.0000 (73.8624)  Acc@5: 93.7500 (94.7689)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.9917  Acc@1: 81.2500 (73.8799)  Acc@5: 93.7500 (94.7720)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -1.0538  Acc@1: 81.2500 (73.8794)  Acc@5: 93.7500 (94.7750)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.8230  Acc@1: 75.0000 (73.8856)  Acc@5: 93.7500 (94.7802)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.9940  Acc@1: 75.0000 (73.8829)  Acc@5: 93.7500 (94.7788)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -1.2412  Acc@1: 75.0000 (73.8824)  Acc@5: 93.7500 (94.7796)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.6866  Acc@1: 75.0000 (73.9083)  Acc@5: 100.0000 (94.7781)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.9509  Acc@1: 81.2500 (73.9427)  Acc@5: 100.0000 (94.7877)  time: 0.3556  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.9148  Acc@1: 81.2500 (73.9572)  Acc@5: 93.7500 (94.7906)  time: 0.3572  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -1.0690  Acc@1: 81.2500 (73.9739)  Acc@5: 93.7500 (94.7913)  time: 0.3526  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.7569  Acc@1: 81.2500 (73.9796)  Acc@5: 100.0000 (94.7942)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.7813  Acc@1: 81.2500 (73.9982)  Acc@5: 100.0000 (94.8014)  time: 0.3547  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -1.0980  Acc@1: 87.5000 (74.0274)  Acc@5: 100.0000 (94.8128)  time: 0.3567  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.8478  Acc@1: 87.5000 (74.0521)  Acc@5: 100.0000 (94.8177)  time: 0.3525  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.3932  Acc@1: 81.2500 (74.0660)  Acc@5: 93.7500 (94.8162)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.9416  Acc@1: 81.2500 (74.0649)  Acc@5: 100.0000 (94.8274)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -1.0437  Acc@1: 81.2500 (74.0787)  Acc@5: 100.0000 (94.8238)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.6627  Acc@1: 75.0000 (74.0860)  Acc@5: 100.0000 (94.8307)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.9920  Acc@1: 75.0000 (74.0933)  Acc@5: 100.0000 (94.8397)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.4882  Acc@1: 81.2500 (74.0985)  Acc@5: 100.0000 (94.8486)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.9266  Acc@1: 75.0000 (74.1245)  Acc@5: 100.0000 (94.8554)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -1.1006  Acc@1: 75.0000 (74.1232)  Acc@5: 93.7500 (94.8517)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.6072  Acc@1: 75.0000 (74.1178)  Acc@5: 93.7500 (94.8605)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.6931  Acc@1: 75.0000 (74.1207)  Acc@5: 100.0000 (94.8692)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.8850  Acc@1: 75.0000 (74.1216)  Acc@5: 93.7500 (94.8656)  time: 0.3514  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -1.1579  Acc@1: 75.0000 (74.1389)  Acc@5: 93.7500 (94.8742)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.9207  Acc@1: 75.0000 (74.1458)  Acc@5: 93.7500 (94.8746)  time: 0.3585  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -0.8662  Acc@1: 81.2500 (74.1731)  Acc@5: 93.7500 (94.8832)  time: 0.3605  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4678  Acc@1: 81.2500 (74.1880)  Acc@5: 100.0000 (94.8917)  time: 0.3539  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -0.1752  Acc@1: 81.2500 (74.2109)  Acc@5: 100.0000 (94.8982)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6547  Acc@1: 81.2500 (74.2195)  Acc@5: 100.0000 (94.9005)  time: 0.3580  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.8459  Acc@1: 81.2500 (74.2462)  Acc@5: 100.0000 (94.9069)  time: 0.3597  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -1.2489  Acc@1: 81.2500 (74.2547)  Acc@5: 100.0000 (94.9152)  time: 0.3545  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -0.7574  Acc@1: 75.0000 (74.2671)  Acc@5: 100.0000 (94.9255)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.3055  Acc@1: 75.0000 (74.2634)  Acc@5: 100.0000 (94.9277)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -0.8944  Acc@1: 75.0000 (74.2817)  Acc@5: 93.7500 (94.9300)  time: 0.3588  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6727  Acc@1: 75.0000 (74.2780)  Acc@5: 93.7500 (94.9322)  time: 0.3563  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.9047  Acc@1: 75.0000 (74.2783)  Acc@5: 93.7500 (94.9304)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -1.1918  Acc@1: 75.0000 (74.3023)  Acc@5: 100.0000 (94.9424)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -0.8970  Acc@1: 81.2500 (74.3143)  Acc@5: 100.0000 (94.9446)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:17  Lr: 0.001875  Loss: -0.5642  Acc@1: 81.2500 (74.3204)  Acc@5: 93.7500 (94.9448)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -1.2822  Acc@1: 75.0000 (74.3342)  Acc@5: 100.0000 (94.9547)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6395  Acc@1: 81.2500 (74.3655)  Acc@5: 100.0000 (94.9587)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.8297  Acc@1: 75.0000 (74.3655)  Acc@5: 93.7500 (94.9627)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:03  Lr: 0.001875  Loss: -0.6386  Acc@1: 75.0000 (74.3810)  Acc@5: 93.7500 (94.9648)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.3741  Acc@1: 75.0000 (74.4022)  Acc@5: 100.0000 (94.9668)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.9051  Acc@1: 87.5000 (74.4271)  Acc@5: 100.0000 (94.9765)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.9998  Acc@1: 87.5000 (74.4442)  Acc@5: 100.0000 (94.9805)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:49  Lr: 0.001875  Loss: -0.9336  Acc@1: 81.2500 (74.4554)  Acc@5: 93.7500 (94.9805)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7909  Acc@1: 81.2500 (74.4685)  Acc@5: 93.7500 (94.9882)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -1.0492  Acc@1: 81.2500 (74.4815)  Acc@5: 93.7500 (94.9901)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.8195  Acc@1: 81.2500 (74.5134)  Acc@5: 93.7500 (94.9883)  time: 0.3522  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.6597  Acc@1: 81.2500 (74.5224)  Acc@5: 93.7500 (94.9921)  time: 0.3521  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5800  Acc@1: 75.0000 (74.5239)  Acc@5: 93.7500 (94.9883)  time: 0.3567  data: 0.0032  max mem: 2500
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -1.0657  Acc@1: 75.0000 (74.5384)  Acc@5: 93.7500 (94.9940)  time: 0.3583  data: 0.0032  max mem: 2500
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.9760  Acc@1: 75.0000 (74.5398)  Acc@5: 100.0000 (94.9996)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -1.0525  Acc@1: 75.0000 (74.5561)  Acc@5: 100.0000 (94.9996)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.8024  Acc@1: 81.2500 (74.5853)  Acc@5: 100.0000 (95.0052)  time: 0.3536  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -1.3667  Acc@1: 81.2500 (74.5977)  Acc@5: 100.0000 (95.0089)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.7521  Acc@1: 81.2500 (74.6192)  Acc@5: 100.0000 (95.0126)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -1.0896  Acc@1: 81.2500 (74.6295)  Acc@5: 100.0000 (95.0162)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.5250  Acc@1: 75.0000 (74.6490)  Acc@5: 93.7500 (95.0198)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.9965  Acc@1: 75.0000 (74.6592)  Acc@5: 93.7500 (95.0216)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.8982  Acc@1: 81.2500 (74.6839)  Acc@5: 100.0000 (95.0325)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.5016  Acc@1: 81.2500 (74.6958)  Acc@5: 100.0000 (95.0415)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7617  Acc@1: 75.0000 (74.6985)  Acc@5: 100.0000 (95.0469)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.5892  Acc@1: 81.2500 (74.7139)  Acc@5: 100.0000 (95.0485)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -1.0061  Acc@1: 75.0000 (74.7056)  Acc@5: 93.7500 (95.0502)  time: 0.3573  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -1.1401  Acc@1: 75.0000 (74.7173)  Acc@5: 100.0000 (95.0537)  time: 0.3578  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -0.8147  Acc@1: 81.2500 (74.7289)  Acc@5: 93.7500 (95.0463)  time: 0.3537  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -1.2609  Acc@1: 81.2500 (74.7386)  Acc@5: 93.7500 (95.0480)  time: 0.3535  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:28  Lr: 0.001875  Loss: -1.0797  Acc@1: 81.2500 (74.7590)  Acc@5: 100.0000 (95.0586)  time: 0.3586  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -1.2559  Acc@1: 81.2500 (74.7739)  Acc@5: 100.0000 (95.0655)  time: 0.3692  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9741  Acc@1: 81.2500 (74.7976)  Acc@5: 100.0000 (95.0689)  time: 0.3622  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.2455  Acc@1: 75.0000 (74.7858)  Acc@5: 93.7500 (95.0651)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.8126  Acc@1: 68.7500 (74.7988)  Acc@5: 100.0000 (95.0738)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.6321  Acc@1: 75.0000 (74.7958)  Acc@5: 100.0000 (95.0771)  time: 0.3527  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.2844  Acc@1: 75.0000 (74.8069)  Acc@5: 100.0000 (95.0839)  time: 0.3519  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -1.2211  Acc@1: 81.2500 (74.8390)  Acc@5: 100.0000 (95.0942)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.6277  Acc@1: 81.2500 (74.8516)  Acc@5: 100.0000 (95.0991)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -1.0452  Acc@1: 81.2500 (74.8782)  Acc@5: 100.0000 (95.1041)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.3719  Acc@1: 81.2500 (74.8993)  Acc@5: 100.0000 (95.1073)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -1.2359  Acc@1: 81.2500 (74.9187)  Acc@5: 100.0000 (95.1173)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.5782  Acc@1: 81.2500 (74.9206)  Acc@5: 100.0000 (95.1188)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.7285  Acc@1: 81.2500 (74.9277)  Acc@5: 100.0000 (95.1201)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.7619  Acc@1: 81.2500 (74.9382)  Acc@5: 93.7500 (95.1198)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -1.2259  Acc@1: 81.2500 (74.9521)  Acc@5: 93.7500 (95.1212)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.8630  Acc@1: 75.0000 (74.9505)  Acc@5: 93.7500 (95.1209)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0961  Acc@1: 75.0000 (74.9455)  Acc@5: 93.7500 (95.1205)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.2986  Acc@1: 81.2500 (74.9491)  Acc@5: 93.7500 (95.1202)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7861  Acc@1: 81.2500 (74.9644)  Acc@5: 100.0000 (95.1233)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8435  Acc@1: 81.2500 (74.9865)  Acc@5: 100.0000 (95.1297)  time: 0.3533  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6679  Acc@1: 81.2500 (74.9983)  Acc@5: 100.0000 (95.1395)  time: 0.3521  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.1169  Acc@1: 75.0000 (75.0017)  Acc@5: 93.7500 (95.1273)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -1.0684  Acc@1: 75.0000 (75.0117)  Acc@5: 93.7500 (95.1303)  time: 0.3556  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6473  Acc@1: 75.0000 (75.0184)  Acc@5: 93.7500 (95.1266)  time: 0.3566  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3834  Acc@1: 81.2500 (75.0300)  Acc@5: 93.7500 (95.1333)  time: 0.3531  data: 0.0010  max mem: 2500
Train: Epoch[1/5] Total time: 0:22:01 (0.3525 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.3834  Acc@1: 81.2500 (75.0300)  Acc@5: 93.7500 (95.1333)
Train: Epoch[2/5]  [   0/3750]  eta: 0:56:51  Lr: 0.001875  Loss: -1.1063  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.9096  data: 0.5599  max mem: 2500
Train: Epoch[2/5]  [  10/3750]  eta: 0:25:13  Lr: 0.001875  Loss: -0.9240  Acc@1: 81.2500 (79.5455)  Acc@5: 93.7500 (96.0227)  time: 0.4047  data: 0.0523  max mem: 2500
Train: Epoch[2/5]  [  20/3750]  eta: 0:23:34  Lr: 0.001875  Loss: -0.8652  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (96.7262)  time: 0.3528  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:53  Lr: 0.001875  Loss: -0.8992  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (96.3710)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:51  Lr: 0.001875  Loss: -1.0690  Acc@1: 81.2500 (80.9451)  Acc@5: 93.7500 (96.0366)  time: 0.3593  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:34  Lr: 0.001875  Loss: -0.4384  Acc@1: 81.2500 (79.6569)  Acc@5: 93.7500 (95.8333)  time: 0.3611  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [  60/3750]  eta: 0:22:20  Lr: 0.001875  Loss: -0.6630  Acc@1: 75.0000 (79.0984)  Acc@5: 100.0000 (96.2090)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  70/3750]  eta: 0:22:13  Lr: 0.001875  Loss: -1.0156  Acc@1: 81.2500 (79.6655)  Acc@5: 100.0000 (96.1268)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  80/3750]  eta: 0:24:17  Lr: 0.001875  Loss: -0.8128  Acc@1: 81.2500 (79.8611)  Acc@5: 93.7500 (96.2963)  time: 0.4999  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  90/3750]  eta: 0:26:26  Lr: 0.001875  Loss: -0.8545  Acc@1: 81.2500 (79.7390)  Acc@5: 93.7500 (95.9478)  time: 0.6859  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 100/3750]  eta: 0:28:06  Lr: 0.001875  Loss: -0.7276  Acc@1: 81.2500 (79.7649)  Acc@5: 93.7500 (96.1015)  time: 0.7249  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 110/3750]  eta: 0:29:29  Lr: 0.001875  Loss: -0.3869  Acc@1: 81.2500 (79.2793)  Acc@5: 100.0000 (95.9459)  time: 0.7262  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 120/3750]  eta: 0:30:42  Lr: 0.001875  Loss: -0.9272  Acc@1: 75.0000 (79.1322)  Acc@5: 93.7500 (95.8678)  time: 0.7371  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 130/3750]  eta: 0:31:42  Lr: 0.001875  Loss: -1.1519  Acc@1: 75.0000 (78.9122)  Acc@5: 93.7500 (95.9447)  time: 0.7436  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 140/3750]  eta: 0:32:31  Lr: 0.001875  Loss: -0.6428  Acc@1: 75.0000 (78.5018)  Acc@5: 100.0000 (95.8777)  time: 0.7408  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 150/3750]  eta: 0:33:13  Lr: 0.001875  Loss: -0.7172  Acc@1: 75.0000 (78.6838)  Acc@5: 100.0000 (95.9023)  time: 0.7399  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 160/3750]  eta: 0:33:42  Lr: 0.001875  Loss: -1.0639  Acc@1: 81.2500 (78.8043)  Acc@5: 100.0000 (95.9627)  time: 0.7239  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 170/3750]  eta: 0:32:52  Lr: 0.001875  Loss: -0.7697  Acc@1: 81.2500 (78.9839)  Acc@5: 93.7500 (95.9430)  time: 0.5279  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 180/3750]  eta: 0:32:06  Lr: 0.001875  Loss: -1.1591  Acc@1: 81.2500 (78.9710)  Acc@5: 93.7500 (95.8218)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 190/3750]  eta: 0:31:26  Lr: 0.001875  Loss: -1.0474  Acc@1: 81.2500 (79.1885)  Acc@5: 100.0000 (95.8770)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 200/3750]  eta: 0:30:48  Lr: 0.001875  Loss: -1.1541  Acc@1: 81.2500 (79.1978)  Acc@5: 100.0000 (95.9888)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 210/3750]  eta: 0:30:14  Lr: 0.001875  Loss: -1.1543  Acc@1: 81.2500 (79.2358)  Acc@5: 100.0000 (95.9716)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 220/3750]  eta: 0:29:43  Lr: 0.001875  Loss: -1.1283  Acc@1: 81.2500 (79.2704)  Acc@5: 100.0000 (96.0407)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 230/3750]  eta: 0:29:14  Lr: 0.001875  Loss: -0.8547  Acc@1: 81.2500 (79.2478)  Acc@5: 100.0000 (96.1039)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 240/3750]  eta: 0:28:48  Lr: 0.001875  Loss: -0.9662  Acc@1: 75.0000 (79.2272)  Acc@5: 100.0000 (96.0840)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 250/3750]  eta: 0:28:24  Lr: 0.001875  Loss: -0.6504  Acc@1: 81.2500 (79.3078)  Acc@5: 100.0000 (96.1653)  time: 0.3526  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 260/3750]  eta: 0:28:01  Lr: 0.001875  Loss: -0.9784  Acc@1: 75.0000 (79.2146)  Acc@5: 100.0000 (96.1207)  time: 0.3553  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 270/3750]  eta: 0:27:40  Lr: 0.001875  Loss: -1.2310  Acc@1: 75.0000 (79.2897)  Acc@5: 93.7500 (96.1485)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 280/3750]  eta: 0:27:19  Lr: 0.001875  Loss: -0.9909  Acc@1: 81.2500 (79.2482)  Acc@5: 100.0000 (96.1966)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 290/3750]  eta: 0:27:00  Lr: 0.001875  Loss: -0.6422  Acc@1: 81.2500 (79.1881)  Acc@5: 100.0000 (96.1770)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 300/3750]  eta: 0:26:42  Lr: 0.001875  Loss: -1.2375  Acc@1: 81.2500 (79.2566)  Acc@5: 100.0000 (96.1794)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 310/3750]  eta: 0:26:25  Lr: 0.001875  Loss: -1.0962  Acc@1: 81.2500 (79.2805)  Acc@5: 93.7500 (96.2018)  time: 0.3523  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 320/3750]  eta: 0:26:09  Lr: 0.001875  Loss: -0.5943  Acc@1: 81.2500 (79.1667)  Acc@5: 93.7500 (96.1643)  time: 0.3546  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 330/3750]  eta: 0:25:54  Lr: 0.001875  Loss: -0.7613  Acc@1: 81.2500 (79.1541)  Acc@5: 93.7500 (96.0725)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 340/3750]  eta: 0:25:39  Lr: 0.001875  Loss: -0.6647  Acc@1: 75.0000 (79.0872)  Acc@5: 93.7500 (96.0044)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 350/3750]  eta: 0:25:24  Lr: 0.001875  Loss: -0.8497  Acc@1: 75.0000 (78.9886)  Acc@5: 93.7500 (96.0470)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 360/3750]  eta: 0:25:11  Lr: 0.001875  Loss: -0.3894  Acc@1: 75.0000 (78.9474)  Acc@5: 93.7500 (95.9834)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 370/3750]  eta: 0:24:57  Lr: 0.001875  Loss: -1.3433  Acc@1: 75.0000 (78.9084)  Acc@5: 93.7500 (96.0411)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 380/3750]  eta: 0:24:45  Lr: 0.001875  Loss: -1.0400  Acc@1: 81.2500 (78.9862)  Acc@5: 100.0000 (96.0138)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 390/3750]  eta: 0:24:32  Lr: 0.001875  Loss: -1.2897  Acc@1: 81.2500 (79.1880)  Acc@5: 100.0000 (96.0518)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 400/3750]  eta: 0:24:20  Lr: 0.001875  Loss: -1.0834  Acc@1: 81.2500 (79.1926)  Acc@5: 100.0000 (96.0567)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 410/3750]  eta: 0:24:09  Lr: 0.001875  Loss: -0.3841  Acc@1: 75.0000 (79.2579)  Acc@5: 100.0000 (96.0918)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 420/3750]  eta: 0:23:58  Lr: 0.001875  Loss: -0.9780  Acc@1: 75.0000 (79.1568)  Acc@5: 100.0000 (96.0659)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 430/3750]  eta: 0:23:47  Lr: 0.001875  Loss: -0.5192  Acc@1: 75.0000 (79.2053)  Acc@5: 100.0000 (96.0702)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 440/3750]  eta: 0:23:37  Lr: 0.001875  Loss: -1.2528  Acc@1: 81.2500 (79.2375)  Acc@5: 100.0000 (96.0601)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 450/3750]  eta: 0:23:27  Lr: 0.001875  Loss: -0.7342  Acc@1: 81.2500 (79.2822)  Acc@5: 93.7500 (96.0643)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 460/3750]  eta: 0:23:18  Lr: 0.001875  Loss: -1.3146  Acc@1: 81.2500 (79.4062)  Acc@5: 100.0000 (96.0954)  time: 0.3572  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 470/3750]  eta: 0:23:09  Lr: 0.001875  Loss: -1.0448  Acc@1: 81.2500 (79.4055)  Acc@5: 93.7500 (96.0855)  time: 0.3564  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 480/3750]  eta: 0:23:00  Lr: 0.001875  Loss: -0.8767  Acc@1: 81.2500 (79.4699)  Acc@5: 93.7500 (96.1019)  time: 0.3537  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 490/3750]  eta: 0:22:51  Lr: 0.001875  Loss: -0.4861  Acc@1: 81.2500 (79.3661)  Acc@5: 100.0000 (96.0922)  time: 0.3538  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 500/3750]  eta: 0:22:43  Lr: 0.001875  Loss: -1.4194  Acc@1: 81.2500 (79.4286)  Acc@5: 100.0000 (96.1078)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 510/3750]  eta: 0:22:34  Lr: 0.001875  Loss: -0.5064  Acc@1: 81.2500 (79.2686)  Acc@5: 93.7500 (96.0739)  time: 0.3538  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 520/3750]  eta: 0:22:26  Lr: 0.001875  Loss: -0.8218  Acc@1: 81.2500 (79.3186)  Acc@5: 93.7500 (96.0893)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 530/3750]  eta: 0:22:18  Lr: 0.001875  Loss: -0.3877  Acc@1: 81.2500 (79.2961)  Acc@5: 100.0000 (96.0805)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 540/3750]  eta: 0:22:10  Lr: 0.001875  Loss: -1.3235  Acc@1: 75.0000 (79.3091)  Acc@5: 100.0000 (96.1299)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 550/3750]  eta: 0:22:02  Lr: 0.001875  Loss: -0.7057  Acc@1: 81.2500 (79.3557)  Acc@5: 100.0000 (96.1434)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 560/3750]  eta: 0:21:55  Lr: 0.001875  Loss: -0.3088  Acc@1: 81.2500 (79.4118)  Acc@5: 100.0000 (96.1119)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 570/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -1.2632  Acc@1: 81.2500 (79.4111)  Acc@5: 93.7500 (96.1033)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 580/3750]  eta: 0:21:40  Lr: 0.001875  Loss: -0.9292  Acc@1: 75.0000 (79.3567)  Acc@5: 100.0000 (96.1166)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 590/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -1.1371  Acc@1: 75.0000 (79.3253)  Acc@5: 93.7500 (96.0871)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 600/3750]  eta: 0:21:25  Lr: 0.001875  Loss: -0.8582  Acc@1: 81.2500 (79.3677)  Acc@5: 93.7500 (96.0691)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 610/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -1.2431  Acc@1: 81.2500 (79.3065)  Acc@5: 100.0000 (96.0720)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 620/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -1.0598  Acc@1: 75.0000 (79.2673)  Acc@5: 100.0000 (96.0849)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 630/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.9201  Acc@1: 75.0000 (79.2195)  Acc@5: 93.7500 (96.0578)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 640/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -1.0845  Acc@1: 81.2500 (79.3097)  Acc@5: 93.7500 (96.0706)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 650/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.9337  Acc@1: 81.2500 (79.3203)  Acc@5: 100.0000 (96.0733)  time: 0.3545  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 660/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.9317  Acc@1: 81.2500 (79.4157)  Acc@5: 100.0000 (96.0855)  time: 0.3552  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 670/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -1.2070  Acc@1: 87.5000 (79.4244)  Acc@5: 100.0000 (96.1066)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 680/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.5804  Acc@1: 81.2500 (79.3778)  Acc@5: 93.7500 (96.0536)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 690/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.3905  Acc@1: 75.0000 (79.3596)  Acc@5: 93.7500 (96.0384)  time: 0.3543  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 700/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -1.3734  Acc@1: 81.2500 (79.5025)  Acc@5: 100.0000 (96.0592)  time: 0.3524  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 710/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.9059  Acc@1: 87.5000 (79.5534)  Acc@5: 100.0000 (96.0883)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 720/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.6856  Acc@1: 81.2500 (79.5510)  Acc@5: 100.0000 (96.0905)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 730/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.8265  Acc@1: 81.2500 (79.5828)  Acc@5: 93.7500 (96.0756)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 740/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -1.0203  Acc@1: 75.0000 (79.5547)  Acc@5: 93.7500 (96.0526)  time: 0.3553  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 750/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.7395  Acc@1: 75.0000 (79.5356)  Acc@5: 93.7500 (96.0719)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 760/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.8367  Acc@1: 81.2500 (79.5664)  Acc@5: 100.0000 (96.0742)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 770/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.9573  Acc@1: 81.2500 (79.5396)  Acc@5: 93.7500 (96.0846)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 780/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -1.0838  Acc@1: 81.2500 (79.5535)  Acc@5: 100.0000 (96.0867)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 790/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.9020  Acc@1: 81.2500 (79.5354)  Acc@5: 100.0000 (96.0967)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 800/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.9868  Acc@1: 81.2500 (79.5646)  Acc@5: 100.0000 (96.1220)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 810/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.6087  Acc@1: 81.2500 (79.5391)  Acc@5: 100.0000 (96.0851)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 820/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.8758  Acc@1: 81.2500 (79.5295)  Acc@5: 93.7500 (96.0871)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 830/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.8715  Acc@1: 81.2500 (79.5051)  Acc@5: 93.7500 (96.0590)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 840/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.9557  Acc@1: 81.2500 (79.5036)  Acc@5: 93.7500 (96.0835)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 850/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -1.0119  Acc@1: 81.2500 (79.4874)  Acc@5: 100.0000 (96.1002)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 860/3750]  eta: 0:18:49  Lr: 0.001875  Loss: 0.0395  Acc@1: 75.0000 (79.4352)  Acc@5: 100.0000 (96.0801)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 870/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -1.0225  Acc@1: 81.2500 (79.4991)  Acc@5: 100.0000 (96.1036)  time: 0.3527  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 880/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.9485  Acc@1: 81.2500 (79.5332)  Acc@5: 100.0000 (96.1124)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 890/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -1.1905  Acc@1: 81.2500 (79.5384)  Acc@5: 100.0000 (96.1139)  time: 0.3564  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 900/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.5702  Acc@1: 75.0000 (79.4464)  Acc@5: 100.0000 (96.1154)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 910/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.8519  Acc@1: 75.0000 (79.4251)  Acc@5: 93.7500 (96.1238)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 920/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -1.0884  Acc@1: 75.0000 (79.3702)  Acc@5: 93.7500 (96.1183)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 930/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -1.1177  Acc@1: 75.0000 (79.3502)  Acc@5: 93.7500 (96.1063)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 940/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.7848  Acc@1: 75.0000 (79.3239)  Acc@5: 93.7500 (96.1145)  time: 0.3586  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 950/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -1.1498  Acc@1: 81.2500 (79.3441)  Acc@5: 93.7500 (96.0962)  time: 0.3563  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 960/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -1.3628  Acc@1: 81.2500 (79.3900)  Acc@5: 100.0000 (96.1173)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 970/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -1.2514  Acc@1: 87.5000 (79.4477)  Acc@5: 100.0000 (96.1187)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 980/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.9715  Acc@1: 81.2500 (79.4788)  Acc@5: 100.0000 (96.1200)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 990/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.0672  Acc@1: 81.2500 (79.4147)  Acc@5: 93.7500 (96.1087)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1000/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -1.3267  Acc@1: 75.0000 (79.4456)  Acc@5: 93.7500 (96.1164)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1010/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.7541  Acc@1: 81.2500 (79.4572)  Acc@5: 93.7500 (96.0992)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1020/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.8785  Acc@1: 75.0000 (79.4013)  Acc@5: 93.7500 (96.0884)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1030/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -1.0978  Acc@1: 75.0000 (79.4071)  Acc@5: 100.0000 (96.0960)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1040/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.5576  Acc@1: 81.2500 (79.4008)  Acc@5: 93.7500 (96.0555)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1050/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.9459  Acc@1: 81.2500 (79.4303)  Acc@5: 93.7500 (96.0692)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1060/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -1.0173  Acc@1: 87.5000 (79.4710)  Acc@5: 93.7500 (96.0650)  time: 0.3532  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1070/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.7536  Acc@1: 81.2500 (79.4585)  Acc@5: 93.7500 (96.0434)  time: 0.3543  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1080/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.9251  Acc@1: 75.0000 (79.4519)  Acc@5: 93.7500 (96.0280)  time: 0.3554  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [1090/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5070  Acc@1: 75.0000 (79.3882)  Acc@5: 93.7500 (96.0128)  time: 0.3549  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1100/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.7546  Acc@1: 75.0000 (79.3937)  Acc@5: 100.0000 (96.0093)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1110/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -0.7402  Acc@1: 81.2500 (79.3711)  Acc@5: 93.7500 (96.0059)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1120/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.9234  Acc@1: 81.2500 (79.4045)  Acc@5: 100.0000 (96.0192)  time: 0.3552  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1130/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.9072  Acc@1: 81.2500 (79.4209)  Acc@5: 100.0000 (96.0212)  time: 0.3573  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1140/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -1.1028  Acc@1: 81.2500 (79.4205)  Acc@5: 100.0000 (96.0232)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1150/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -1.2217  Acc@1: 81.2500 (79.4581)  Acc@5: 100.0000 (96.0469)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1160/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -1.3349  Acc@1: 81.2500 (79.4681)  Acc@5: 100.0000 (96.0594)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1170/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.7417  Acc@1: 81.2500 (79.4673)  Acc@5: 100.0000 (96.0611)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1180/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.7829  Acc@1: 81.2500 (79.4560)  Acc@5: 93.7500 (96.0468)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1190/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.9963  Acc@1: 81.2500 (79.4815)  Acc@5: 93.7500 (96.0485)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1200/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -1.1307  Acc@1: 81.2500 (79.5015)  Acc@5: 100.0000 (96.0554)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1210/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -1.0336  Acc@1: 81.2500 (79.4849)  Acc@5: 100.0000 (96.0518)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1220/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -1.2579  Acc@1: 81.2500 (79.5352)  Acc@5: 100.0000 (96.0637)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1230/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -1.2511  Acc@1: 81.2500 (79.5695)  Acc@5: 100.0000 (96.0753)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1240/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.7279  Acc@1: 81.2500 (79.5578)  Acc@5: 93.7500 (96.0667)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1250/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -1.4596  Acc@1: 81.2500 (79.5614)  Acc@5: 93.7500 (96.0781)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1260/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -1.1213  Acc@1: 75.0000 (79.5500)  Acc@5: 100.0000 (96.0894)  time: 0.3565  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1270/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.4227  Acc@1: 75.0000 (79.5043)  Acc@5: 100.0000 (96.0956)  time: 0.3570  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1280/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -1.0937  Acc@1: 75.0000 (79.5180)  Acc@5: 100.0000 (96.0968)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1290/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -1.2808  Acc@1: 81.2500 (79.5556)  Acc@5: 100.0000 (96.1174)  time: 0.3529  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1300/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.9085  Acc@1: 81.2500 (79.5638)  Acc@5: 100.0000 (96.1040)  time: 0.3582  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1310/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.7386  Acc@1: 75.0000 (79.5242)  Acc@5: 93.7500 (96.1051)  time: 0.3570  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1320/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.8798  Acc@1: 75.0000 (79.5089)  Acc@5: 93.7500 (96.0967)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1330/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.8507  Acc@1: 81.2500 (79.5173)  Acc@5: 100.0000 (96.0979)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1340/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.9163  Acc@1: 87.5000 (79.5628)  Acc@5: 100.0000 (96.1176)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1350/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.8230  Acc@1: 87.5000 (79.5938)  Acc@5: 100.0000 (96.1186)  time: 0.3556  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1360/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.8215  Acc@1: 81.2500 (79.5876)  Acc@5: 100.0000 (96.1196)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1370/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -1.1425  Acc@1: 81.2500 (79.5906)  Acc@5: 93.7500 (96.1160)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1380/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.4719  Acc@1: 75.0000 (79.5483)  Acc@5: 93.7500 (96.0988)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1390/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.9151  Acc@1: 75.0000 (79.5516)  Acc@5: 93.7500 (96.1134)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1400/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.3279  Acc@1: 75.0000 (79.5414)  Acc@5: 100.0000 (96.1233)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1410/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -1.4370  Acc@1: 81.2500 (79.6155)  Acc@5: 100.0000 (96.1464)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1420/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -1.3386  Acc@1: 87.5000 (79.6226)  Acc@5: 100.0000 (96.1515)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1430/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.7494  Acc@1: 81.2500 (79.6384)  Acc@5: 100.0000 (96.1609)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1440/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.9781  Acc@1: 81.2500 (79.6582)  Acc@5: 100.0000 (96.1702)  time: 0.3532  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [1450/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.8975  Acc@1: 81.2500 (79.6735)  Acc@5: 100.0000 (96.1751)  time: 0.3526  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1460/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.8341  Acc@1: 81.2500 (79.6586)  Acc@5: 100.0000 (96.1713)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1470/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.8368  Acc@1: 75.0000 (79.6524)  Acc@5: 100.0000 (96.1718)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1480/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.6805  Acc@1: 75.0000 (79.6464)  Acc@5: 100.0000 (96.1681)  time: 0.3528  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1490/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -1.1080  Acc@1: 81.2500 (79.6697)  Acc@5: 100.0000 (96.1771)  time: 0.3547  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1500/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -1.1627  Acc@1: 81.2500 (79.7010)  Acc@5: 93.7500 (96.1651)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1510/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.7418  Acc@1: 81.2500 (79.6947)  Acc@5: 93.7500 (96.1698)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1520/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.4997  Acc@1: 81.2500 (79.6967)  Acc@5: 93.7500 (96.1456)  time: 0.3536  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1530/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -1.3645  Acc@1: 81.2500 (79.6865)  Acc@5: 93.7500 (96.1381)  time: 0.3551  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1540/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -1.1218  Acc@1: 81.2500 (79.6966)  Acc@5: 93.7500 (96.1267)  time: 0.3516  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1550/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.9471  Acc@1: 81.2500 (79.6865)  Acc@5: 100.0000 (96.1356)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1560/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.8741  Acc@1: 81.2500 (79.6885)  Acc@5: 100.0000 (96.1483)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1570/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.7371  Acc@1: 81.2500 (79.7064)  Acc@5: 100.0000 (96.1370)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1580/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -1.0061  Acc@1: 81.2500 (79.7162)  Acc@5: 93.7500 (96.1417)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1590/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4646  Acc@1: 81.2500 (79.7062)  Acc@5: 93.7500 (96.1345)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1600/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.8102  Acc@1: 81.2500 (79.6963)  Acc@5: 93.7500 (96.1313)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1610/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -1.3612  Acc@1: 81.2500 (79.7059)  Acc@5: 93.7500 (96.1398)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1620/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.9367  Acc@1: 81.2500 (79.7232)  Acc@5: 100.0000 (96.1366)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1630/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.5482  Acc@1: 75.0000 (79.6789)  Acc@5: 93.7500 (96.1220)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1640/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -1.2590  Acc@1: 81.2500 (79.7037)  Acc@5: 93.7500 (96.1114)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1650/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.8593  Acc@1: 87.5000 (79.6979)  Acc@5: 93.7500 (96.1008)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.3827  Acc@1: 81.2500 (79.6922)  Acc@5: 93.7500 (96.1055)  time: 0.3548  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -1.0644  Acc@1: 81.2500 (79.6978)  Acc@5: 93.7500 (96.0989)  time: 0.3577  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -1.1841  Acc@1: 75.0000 (79.6847)  Acc@5: 100.0000 (96.1035)  time: 0.3565  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1690/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -1.0117  Acc@1: 75.0000 (79.6866)  Acc@5: 100.0000 (96.1007)  time: 0.3534  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1700/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.8622  Acc@1: 81.2500 (79.6921)  Acc@5: 93.7500 (96.0979)  time: 0.3549  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1710/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.9969  Acc@1: 81.2500 (79.7049)  Acc@5: 93.7500 (96.0915)  time: 0.3555  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1720/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.5351  Acc@1: 81.2500 (79.6884)  Acc@5: 93.7500 (96.0924)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1730/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -1.0584  Acc@1: 81.2500 (79.6974)  Acc@5: 93.7500 (96.0861)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1740/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.9858  Acc@1: 75.0000 (79.6776)  Acc@5: 93.7500 (96.0727)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1750/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -1.2609  Acc@1: 75.0000 (79.6688)  Acc@5: 93.7500 (96.0772)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1760/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.3789  Acc@1: 75.0000 (79.6529)  Acc@5: 93.7500 (96.0747)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1770/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -1.1549  Acc@1: 75.0000 (79.6513)  Acc@5: 93.7500 (96.0721)  time: 0.3535  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1780/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.6033  Acc@1: 81.2500 (79.6533)  Acc@5: 93.7500 (96.0661)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1790/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -1.1293  Acc@1: 81.2500 (79.6866)  Acc@5: 100.0000 (96.0811)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1800/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.6649  Acc@1: 81.2500 (79.6918)  Acc@5: 100.0000 (96.0855)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -1.2474  Acc@1: 81.2500 (79.7073)  Acc@5: 100.0000 (96.1002)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.6446  Acc@1: 81.2500 (79.7192)  Acc@5: 100.0000 (96.1113)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -1.1222  Acc@1: 81.2500 (79.7174)  Acc@5: 100.0000 (96.1019)  time: 0.3554  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -1.0790  Acc@1: 81.2500 (79.7393)  Acc@5: 93.7500 (96.0959)  time: 0.3591  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -1.1732  Acc@1: 81.2500 (79.7306)  Acc@5: 93.7500 (96.0764)  time: 0.3569  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1860/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.4738  Acc@1: 75.0000 (79.7085)  Acc@5: 93.7500 (96.0606)  time: 0.3561  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1870/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -1.0468  Acc@1: 75.0000 (79.6733)  Acc@5: 93.7500 (96.0583)  time: 0.3550  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1880/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -1.0549  Acc@1: 75.0000 (79.6717)  Acc@5: 93.7500 (96.0593)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1890/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.7688  Acc@1: 75.0000 (79.6569)  Acc@5: 93.7500 (96.0603)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1900/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.4053  Acc@1: 81.2500 (79.6719)  Acc@5: 93.7500 (96.0580)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1910/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.5636  Acc@1: 81.2500 (79.6540)  Acc@5: 100.0000 (96.0623)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1920/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.7018  Acc@1: 75.0000 (79.6655)  Acc@5: 100.0000 (96.0665)  time: 0.3533  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1930/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.6337  Acc@1: 81.2500 (79.6673)  Acc@5: 100.0000 (96.0707)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1940/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.9422  Acc@1: 81.2500 (79.6947)  Acc@5: 100.0000 (96.0781)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1950/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.7263  Acc@1: 81.2500 (79.7059)  Acc@5: 100.0000 (96.0917)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1960/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.7651  Acc@1: 81.2500 (79.7170)  Acc@5: 100.0000 (96.0894)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.8661  Acc@1: 81.2500 (79.6962)  Acc@5: 100.0000 (96.0902)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.5801  Acc@1: 87.5000 (79.7293)  Acc@5: 100.0000 (96.0941)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.7170  Acc@1: 87.5000 (79.7369)  Acc@5: 100.0000 (96.1043)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.6760  Acc@1: 81.2500 (79.7414)  Acc@5: 100.0000 (96.1176)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7545  Acc@1: 81.2500 (79.7458)  Acc@5: 100.0000 (96.1244)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.8897  Acc@1: 81.2500 (79.7594)  Acc@5: 100.0000 (96.1251)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -1.1168  Acc@1: 87.5000 (79.7790)  Acc@5: 100.0000 (96.1288)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2040/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.0002  Acc@1: 81.2500 (79.7771)  Acc@5: 100.0000 (96.1293)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2050/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.3603  Acc@1: 81.2500 (79.7446)  Acc@5: 93.7500 (96.1208)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2060/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -1.1290  Acc@1: 81.2500 (79.7368)  Acc@5: 93.7500 (96.1245)  time: 0.3541  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2070/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.6076  Acc@1: 81.2500 (79.7230)  Acc@5: 100.0000 (96.1220)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2080/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -1.3248  Acc@1: 81.2500 (79.7363)  Acc@5: 93.7500 (96.1197)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2090/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -1.0017  Acc@1: 81.2500 (79.7166)  Acc@5: 93.7500 (96.1143)  time: 0.3521  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2100/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.9169  Acc@1: 75.0000 (79.7031)  Acc@5: 93.7500 (96.1209)  time: 0.3542  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [2110/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.8700  Acc@1: 81.2500 (79.7223)  Acc@5: 100.0000 (96.1245)  time: 0.3526  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -1.1474  Acc@1: 87.5000 (79.7295)  Acc@5: 100.0000 (96.1280)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.6172  Acc@1: 81.2500 (79.7425)  Acc@5: 100.0000 (96.1315)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.7986  Acc@1: 81.2500 (79.7525)  Acc@5: 100.0000 (96.1350)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.8404  Acc@1: 81.2500 (79.7768)  Acc@5: 93.7500 (96.1326)  time: 0.3519  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.8924  Acc@1: 81.2500 (79.7750)  Acc@5: 93.7500 (96.1389)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.8292  Acc@1: 81.2500 (79.7962)  Acc@5: 100.0000 (96.1395)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.4735  Acc@1: 81.2500 (79.7799)  Acc@5: 93.7500 (96.1314)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.7606  Acc@1: 75.0000 (79.7809)  Acc@5: 93.7500 (96.1291)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -1.1610  Acc@1: 81.2500 (79.7649)  Acc@5: 93.7500 (96.1324)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2210/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -1.0036  Acc@1: 75.0000 (79.7518)  Acc@5: 93.7500 (96.1330)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2220/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.4322  Acc@1: 75.0000 (79.7417)  Acc@5: 93.7500 (96.1279)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2230/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -1.0183  Acc@1: 75.0000 (79.7596)  Acc@5: 100.0000 (96.1340)  time: 0.3560  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2240/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.9956  Acc@1: 81.2500 (79.7719)  Acc@5: 100.0000 (96.1401)  time: 0.3590  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2250/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.6418  Acc@1: 81.2500 (79.7757)  Acc@5: 100.0000 (96.1351)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2260/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.6339  Acc@1: 81.2500 (79.7794)  Acc@5: 100.0000 (96.1494)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2270/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.5119  Acc@1: 81.2500 (79.7831)  Acc@5: 100.0000 (96.1526)  time: 0.3572  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.6126  Acc@1: 81.2500 (79.7731)  Acc@5: 100.0000 (96.1530)  time: 0.3556  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -1.1483  Acc@1: 81.2500 (79.7687)  Acc@5: 100.0000 (96.1562)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -1.0678  Acc@1: 81.2500 (79.7724)  Acc@5: 100.0000 (96.1647)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.4829  Acc@1: 81.2500 (79.7815)  Acc@5: 100.0000 (96.1678)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.6597  Acc@1: 75.0000 (79.7501)  Acc@5: 93.7500 (96.1628)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.7990  Acc@1: 75.0000 (79.7297)  Acc@5: 93.7500 (96.1578)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.9740  Acc@1: 75.0000 (79.7175)  Acc@5: 93.7500 (96.1582)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.8795  Acc@1: 81.2500 (79.7001)  Acc@5: 100.0000 (96.1532)  time: 0.3522  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.8697  Acc@1: 81.2500 (79.6988)  Acc@5: 100.0000 (96.1536)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -1.1032  Acc@1: 81.2500 (79.7053)  Acc@5: 100.0000 (96.1567)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2380/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -1.1136  Acc@1: 81.2500 (79.7249)  Acc@5: 100.0000 (96.1623)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2390/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.1989  Acc@1: 81.2500 (79.7208)  Acc@5: 100.0000 (96.1653)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2400/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.8035  Acc@1: 75.0000 (79.7142)  Acc@5: 100.0000 (96.1683)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2410/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.5057  Acc@1: 81.2500 (79.7257)  Acc@5: 100.0000 (96.1738)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2420/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.6280  Acc@1: 81.2500 (79.7346)  Acc@5: 100.0000 (96.1767)  time: 0.3563  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2430/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.4626  Acc@1: 81.2500 (79.7357)  Acc@5: 100.0000 (96.1770)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.8220  Acc@1: 81.2500 (79.7445)  Acc@5: 100.0000 (96.1850)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.6967  Acc@1: 81.2500 (79.7328)  Acc@5: 100.0000 (96.1903)  time: 0.3577  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.8358  Acc@1: 81.2500 (79.7542)  Acc@5: 100.0000 (96.1906)  time: 0.3588  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.9434  Acc@1: 81.2500 (79.7602)  Acc@5: 100.0000 (96.1959)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -1.1956  Acc@1: 81.2500 (79.7486)  Acc@5: 100.0000 (96.1961)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -1.0295  Acc@1: 81.2500 (79.7596)  Acc@5: 100.0000 (96.2013)  time: 0.3606  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.8937  Acc@1: 81.2500 (79.7681)  Acc@5: 100.0000 (96.2065)  time: 0.3610  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.6520  Acc@1: 81.2500 (79.7566)  Acc@5: 100.0000 (96.2117)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -1.2820  Acc@1: 75.0000 (79.7303)  Acc@5: 100.0000 (96.2044)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.9933  Acc@1: 81.2500 (79.7412)  Acc@5: 93.7500 (96.2070)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.9389  Acc@1: 81.2500 (79.7398)  Acc@5: 93.7500 (96.2072)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2550/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -1.2008  Acc@1: 81.2500 (79.7408)  Acc@5: 100.0000 (96.2196)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2560/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.9476  Acc@1: 81.2500 (79.7589)  Acc@5: 100.0000 (96.2319)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2570/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.8246  Acc@1: 81.2500 (79.7550)  Acc@5: 100.0000 (96.2393)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2580/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.0980  Acc@1: 81.2500 (79.7535)  Acc@5: 100.0000 (96.2418)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2590/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.9891  Acc@1: 81.2500 (79.7593)  Acc@5: 93.7500 (96.2394)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -1.2615  Acc@1: 81.2500 (79.7626)  Acc@5: 93.7500 (96.2322)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -1.0332  Acc@1: 81.2500 (79.7587)  Acc@5: 93.7500 (96.2275)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.7115  Acc@1: 81.2500 (79.7620)  Acc@5: 93.7500 (96.2252)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.7196  Acc@1: 81.2500 (79.7772)  Acc@5: 93.7500 (96.2229)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.6679  Acc@1: 81.2500 (79.7828)  Acc@5: 100.0000 (96.2230)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -1.0613  Acc@1: 81.2500 (79.7812)  Acc@5: 93.7500 (96.2184)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.6237  Acc@1: 81.2500 (79.7797)  Acc@5: 93.7500 (96.2209)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.8390  Acc@1: 81.2500 (79.7665)  Acc@5: 100.0000 (96.2210)  time: 0.3524  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.9519  Acc@1: 81.2500 (79.7604)  Acc@5: 93.7500 (96.2188)  time: 0.3538  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -1.1797  Acc@1: 81.2500 (79.7612)  Acc@5: 100.0000 (96.2189)  time: 0.3533  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.6818  Acc@1: 81.2500 (79.7529)  Acc@5: 100.0000 (96.2144)  time: 0.3515  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -1.1993  Acc@1: 75.0000 (79.7399)  Acc@5: 93.7500 (96.2076)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2720/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -1.2332  Acc@1: 75.0000 (79.7363)  Acc@5: 100.0000 (96.2215)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2730/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.5050  Acc@1: 81.2500 (79.7510)  Acc@5: 100.0000 (96.2148)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2740/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.7745  Acc@1: 81.2500 (79.7656)  Acc@5: 93.7500 (96.2103)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2750/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -1.0468  Acc@1: 81.2500 (79.7755)  Acc@5: 93.7500 (96.2105)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2760/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.7258  Acc@1: 81.2500 (79.7786)  Acc@5: 93.7500 (96.2129)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.5953  Acc@1: 81.2500 (79.7772)  Acc@5: 93.7500 (96.2085)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -1.0127  Acc@1: 81.2500 (79.7555)  Acc@5: 93.7500 (96.1997)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -1.0394  Acc@1: 81.2500 (79.7743)  Acc@5: 93.7500 (96.1998)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.4753  Acc@1: 81.2500 (79.7773)  Acc@5: 93.7500 (96.1956)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.9894  Acc@1: 81.2500 (79.7781)  Acc@5: 93.7500 (96.1980)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.8728  Acc@1: 81.2500 (79.7656)  Acc@5: 93.7500 (96.1937)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.8132  Acc@1: 75.0000 (79.7598)  Acc@5: 100.0000 (96.1983)  time: 0.3570  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -1.0584  Acc@1: 81.2500 (79.7694)  Acc@5: 100.0000 (96.2051)  time: 0.3558  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.7634  Acc@1: 81.2500 (79.7790)  Acc@5: 100.0000 (96.2097)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -1.2817  Acc@1: 81.2500 (79.7929)  Acc@5: 100.0000 (96.2120)  time: 0.3537  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -1.2493  Acc@1: 87.5000 (79.8306)  Acc@5: 100.0000 (96.2187)  time: 0.3565  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -1.1068  Acc@1: 81.2500 (79.8160)  Acc@5: 100.0000 (96.2231)  time: 0.3543  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.8597  Acc@1: 75.0000 (79.8253)  Acc@5: 93.7500 (96.2167)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2900/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -1.2920  Acc@1: 81.2500 (79.8238)  Acc@5: 100.0000 (96.2254)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2910/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.6709  Acc@1: 75.0000 (79.8115)  Acc@5: 100.0000 (96.2169)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2920/3750]  eta: 0:05:01  Lr: 0.001875  Loss: -0.8728  Acc@1: 81.2500 (79.8143)  Acc@5: 93.7500 (96.2128)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.2150  Acc@1: 81.2500 (79.7957)  Acc@5: 93.7500 (96.2022)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -0.8384  Acc@1: 75.0000 (79.7922)  Acc@5: 93.7500 (96.2045)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -1.0945  Acc@1: 81.2500 (79.8013)  Acc@5: 93.7500 (96.2068)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.8468  Acc@1: 81.2500 (79.7872)  Acc@5: 100.0000 (96.2091)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -1.1039  Acc@1: 75.0000 (79.7880)  Acc@5: 100.0000 (96.2092)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.9107  Acc@1: 81.2500 (79.7929)  Acc@5: 100.0000 (96.2177)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -1.2486  Acc@1: 81.2500 (79.7915)  Acc@5: 100.0000 (96.2136)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.0915  Acc@1: 81.2500 (79.7984)  Acc@5: 93.7500 (96.2179)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -1.2231  Acc@1: 87.5000 (79.8198)  Acc@5: 100.0000 (96.2201)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.8785  Acc@1: 81.2500 (79.8184)  Acc@5: 100.0000 (96.2264)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.9098  Acc@1: 81.2500 (79.8334)  Acc@5: 100.0000 (96.2286)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.9583  Acc@1: 81.2500 (79.8195)  Acc@5: 100.0000 (96.2327)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.5427  Acc@1: 81.2500 (79.8406)  Acc@5: 100.0000 (96.2348)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -1.1251  Acc@1: 81.2500 (79.8411)  Acc@5: 100.0000 (96.2410)  time: 0.3542  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3070/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -1.2288  Acc@1: 81.2500 (79.8539)  Acc@5: 100.0000 (96.2431)  time: 0.3534  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3080/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -1.3366  Acc@1: 87.5000 (79.8604)  Acc@5: 100.0000 (96.2390)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.8883  Acc@1: 81.2500 (79.8750)  Acc@5: 93.7500 (96.2411)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -1.1569  Acc@1: 87.5000 (79.8936)  Acc@5: 100.0000 (96.2452)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.8368  Acc@1: 87.5000 (79.9241)  Acc@5: 100.0000 (96.2532)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.5170  Acc@1: 87.5000 (79.9203)  Acc@5: 100.0000 (96.2512)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -1.1812  Acc@1: 81.2500 (79.9166)  Acc@5: 93.7500 (96.2492)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -1.0724  Acc@1: 81.2500 (79.9228)  Acc@5: 100.0000 (96.2552)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -1.0033  Acc@1: 81.2500 (79.9171)  Acc@5: 100.0000 (96.2512)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.9393  Acc@1: 81.2500 (79.9332)  Acc@5: 100.0000 (96.2591)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -1.0282  Acc@1: 87.5000 (79.9452)  Acc@5: 100.0000 (96.2630)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -1.0980  Acc@1: 81.2500 (79.9473)  Acc@5: 100.0000 (96.2669)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.0276  Acc@1: 81.2500 (79.9534)  Acc@5: 100.0000 (96.2708)  time: 0.3555  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -1.0763  Acc@1: 87.5000 (79.9594)  Acc@5: 100.0000 (96.2707)  time: 0.3578  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.7889  Acc@1: 87.5000 (79.9712)  Acc@5: 100.0000 (96.2784)  time: 0.3529  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.9104  Acc@1: 81.2500 (79.9771)  Acc@5: 100.0000 (96.2803)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.7995  Acc@1: 81.2500 (79.9636)  Acc@5: 93.7500 (96.2724)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3240/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.4856  Acc@1: 75.0000 (79.9618)  Acc@5: 93.7500 (96.2704)  time: 0.3560  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3250/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.8057  Acc@1: 81.2500 (79.9523)  Acc@5: 93.7500 (96.2685)  time: 0.3568  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.5845  Acc@1: 81.2500 (79.9525)  Acc@5: 100.0000 (96.2684)  time: 0.3542  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -1.1841  Acc@1: 81.2500 (79.9431)  Acc@5: 93.7500 (96.2626)  time: 0.3579  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -1.0997  Acc@1: 75.0000 (79.9375)  Acc@5: 93.7500 (96.2645)  time: 0.3555  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.9181  Acc@1: 75.0000 (79.9301)  Acc@5: 100.0000 (96.2644)  time: 0.3510  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.9451  Acc@1: 81.2500 (79.9379)  Acc@5: 100.0000 (96.2663)  time: 0.3532  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:39  Lr: 0.001875  Loss: -1.4371  Acc@1: 81.2500 (79.9419)  Acc@5: 100.0000 (96.2625)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -0.7722  Acc@1: 81.2500 (79.9270)  Acc@5: 93.7500 (96.2587)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.8887  Acc@1: 75.0000 (79.9197)  Acc@5: 100.0000 (96.2661)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:28  Lr: 0.001875  Loss: -0.7585  Acc@1: 75.0000 (79.9068)  Acc@5: 93.7500 (96.2586)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.7508  Acc@1: 81.2500 (79.9146)  Acc@5: 93.7500 (96.2623)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:21  Lr: 0.001875  Loss: -1.0844  Acc@1: 81.2500 (79.9260)  Acc@5: 100.0000 (96.2679)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -1.0802  Acc@1: 81.2500 (79.9169)  Acc@5: 100.0000 (96.2641)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.7870  Acc@1: 81.2500 (79.9283)  Acc@5: 93.7500 (96.2622)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.6872  Acc@1: 81.2500 (79.9193)  Acc@5: 93.7500 (96.2585)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.8514  Acc@1: 75.0000 (79.9122)  Acc@5: 93.7500 (96.2548)  time: 0.3514  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3410/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.3619  Acc@1: 81.2500 (79.9088)  Acc@5: 93.7500 (96.2511)  time: 0.3550  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6486  Acc@1: 81.2500 (79.9127)  Acc@5: 93.7500 (96.2511)  time: 0.3557  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -1.0249  Acc@1: 81.2500 (79.9147)  Acc@5: 100.0000 (96.2529)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -1.1586  Acc@1: 87.5000 (79.9386)  Acc@5: 100.0000 (96.2565)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9200  Acc@1: 81.2500 (79.9388)  Acc@5: 100.0000 (96.2638)  time: 0.3552  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -1.1086  Acc@1: 81.2500 (79.9516)  Acc@5: 100.0000 (96.2691)  time: 0.3579  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9456  Acc@1: 81.2500 (79.9499)  Acc@5: 100.0000 (96.2691)  time: 0.3551  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -1.0531  Acc@1: 81.2500 (79.9537)  Acc@5: 93.7500 (96.2636)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -1.3057  Acc@1: 81.2500 (79.9771)  Acc@5: 100.0000 (96.2708)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.0094  Acc@1: 87.5000 (79.9789)  Acc@5: 100.0000 (96.2725)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.5413  Acc@1: 81.2500 (79.9968)  Acc@5: 100.0000 (96.2760)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.4593  Acc@1: 81.2500 (79.9720)  Acc@5: 93.7500 (96.2759)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:19  Lr: 0.001875  Loss: -1.1601  Acc@1: 75.0000 (79.9756)  Acc@5: 93.7500 (96.2741)  time: 0.3513  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:15  Lr: 0.001875  Loss: -1.2025  Acc@1: 81.2500 (79.9827)  Acc@5: 100.0000 (96.2793)  time: 0.3505  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -1.2622  Acc@1: 87.5000 (79.9863)  Acc@5: 100.0000 (96.2775)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:08  Lr: 0.001875  Loss: -1.2644  Acc@1: 87.5000 (79.9881)  Acc@5: 100.0000 (96.2809)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:05  Lr: 0.001875  Loss: -0.8334  Acc@1: 81.2500 (79.9846)  Acc@5: 100.0000 (96.2878)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3580/3750]  eta: 0:01:01  Lr: 0.001875  Loss: -1.1433  Acc@1: 81.2500 (79.9969)  Acc@5: 100.0000 (96.2842)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7209  Acc@1: 81.2500 (79.9847)  Acc@5: 93.7500 (96.2859)  time: 0.3564  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:54  Lr: 0.001875  Loss: -0.9494  Acc@1: 75.0000 (79.9778)  Acc@5: 100.0000 (96.2892)  time: 0.3544  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7799  Acc@1: 81.2500 (79.9882)  Acc@5: 100.0000 (96.2978)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:46  Lr: 0.001875  Loss: -0.7972  Acc@1: 81.2500 (79.9865)  Acc@5: 100.0000 (96.2959)  time: 0.3557  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:43  Lr: 0.001875  Loss: -0.7005  Acc@1: 81.2500 (79.9780)  Acc@5: 100.0000 (96.2975)  time: 0.3572  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:39  Lr: 0.001875  Loss: -0.7913  Acc@1: 81.2500 (79.9780)  Acc@5: 93.7500 (96.2974)  time: 0.3555  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:36  Lr: 0.001875  Loss: -1.1278  Acc@1: 81.2500 (79.9764)  Acc@5: 93.7500 (96.2990)  time: 0.3536  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:32  Lr: 0.001875  Loss: -1.1231  Acc@1: 81.2500 (79.9662)  Acc@5: 93.7500 (96.2971)  time: 0.3540  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.7412  Acc@1: 81.2500 (79.9816)  Acc@5: 100.0000 (96.2987)  time: 0.3538  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:25  Lr: 0.001875  Loss: -0.7308  Acc@1: 81.2500 (79.9935)  Acc@5: 100.0000 (96.3003)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -1.3090  Acc@1: 81.2500 (80.0020)  Acc@5: 100.0000 (96.3035)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:18  Lr: 0.001875  Loss: -0.9387  Acc@1: 81.2500 (79.9953)  Acc@5: 100.0000 (96.2983)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8149  Acc@1: 75.0000 (79.9818)  Acc@5: 93.7500 (96.2914)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6821  Acc@1: 75.0000 (79.9751)  Acc@5: 93.7500 (96.2964)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9854  Acc@1: 81.2500 (79.9936)  Acc@5: 100.0000 (96.3046)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.8399  Acc@1: 81.2500 (79.9903)  Acc@5: 100.0000 (96.3061)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.1144  Acc@1: 81.2500 (79.9983)  Acc@5: 93.7500 (96.3033)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5] Total time: 0:22:33 (0.3610 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.1144  Acc@1: 81.2500 (79.9983)  Acc@5: 93.7500 (96.3033)
Train: Epoch[3/5]  [   0/3750]  eta: 0:44:03  Lr: 0.001875  Loss: -0.7864  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7049  data: 0.3552  max mem: 2500
Train: Epoch[3/5]  [  10/3750]  eta: 0:23:45  Lr: 0.001875  Loss: -1.3541  Acc@1: 81.2500 (80.6818)  Acc@5: 93.7500 (96.0227)  time: 0.3812  data: 0.0326  max mem: 2500
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:47  Lr: 0.001875  Loss: -0.7054  Acc@1: 75.0000 (79.4643)  Acc@5: 93.7500 (95.5357)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:26  Lr: 0.001875  Loss: -1.0807  Acc@1: 75.0000 (78.4274)  Acc@5: 93.7500 (95.5645)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:17  Lr: 0.001875  Loss: -1.1228  Acc@1: 75.0000 (77.8963)  Acc@5: 93.7500 (95.5793)  time: 0.3544  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  50/3750]  eta: 0:22:08  Lr: 0.001875  Loss: -0.8142  Acc@1: 81.2500 (79.0441)  Acc@5: 93.7500 (95.7108)  time: 0.3546  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  60/3750]  eta: 0:22:03  Lr: 0.001875  Loss: -0.8815  Acc@1: 81.2500 (79.5082)  Acc@5: 93.7500 (95.6967)  time: 0.3546  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -1.3840  Acc@1: 81.2500 (80.5458)  Acc@5: 100.0000 (95.9507)  time: 0.3559  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -0.9498  Acc@1: 81.2500 (80.6327)  Acc@5: 100.0000 (95.9877)  time: 0.3562  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -0.8638  Acc@1: 81.2500 (80.7692)  Acc@5: 100.0000 (96.2912)  time: 0.3540  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:41  Lr: 0.001875  Loss: -0.8414  Acc@1: 81.2500 (81.4356)  Acc@5: 100.0000 (96.3490)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -1.1239  Acc@1: 87.5000 (81.7568)  Acc@5: 100.0000 (96.4527)  time: 0.3531  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -1.3248  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (96.4360)  time: 0.3550  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.9700  Acc@1: 87.5000 (82.0611)  Acc@5: 100.0000 (96.5172)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -1.1839  Acc@1: 87.5000 (81.9149)  Acc@5: 100.0000 (96.6755)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -0.8987  Acc@1: 81.2500 (81.9950)  Acc@5: 100.0000 (96.5232)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -1.1471  Acc@1: 87.5000 (82.1040)  Acc@5: 93.7500 (96.5062)  time: 0.3535  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 170/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.4316  Acc@1: 81.2500 (81.9810)  Acc@5: 93.7500 (96.4181)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 180/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -1.0008  Acc@1: 81.2500 (82.1133)  Acc@5: 93.7500 (96.4088)  time: 0.3505  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 190/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.8516  Acc@1: 81.2500 (82.0026)  Acc@5: 93.7500 (96.3351)  time: 0.3516  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.8233  Acc@1: 75.0000 (81.8097)  Acc@5: 93.7500 (96.3930)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.7190  Acc@1: 75.0000 (81.6647)  Acc@5: 93.7500 (96.2974)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -1.2182  Acc@1: 81.2500 (81.6176)  Acc@5: 93.7500 (96.2387)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -1.0194  Acc@1: 81.2500 (81.3582)  Acc@5: 93.7500 (96.1310)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -1.2036  Acc@1: 81.2500 (81.3537)  Acc@5: 93.7500 (96.1359)  time: 0.3555  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -1.1655  Acc@1: 81.2500 (81.4990)  Acc@5: 93.7500 (96.1155)  time: 0.3536  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -1.0383  Acc@1: 81.2500 (81.4655)  Acc@5: 93.7500 (96.1686)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.4945  Acc@1: 81.2500 (81.4114)  Acc@5: 93.7500 (96.1485)  time: 0.3562  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -1.0328  Acc@1: 81.2500 (81.3835)  Acc@5: 93.7500 (96.1744)  time: 0.3561  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.7613  Acc@1: 81.2500 (81.3789)  Acc@5: 100.0000 (96.2199)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.9896  Acc@1: 81.2500 (81.3953)  Acc@5: 100.0000 (96.2625)  time: 0.3552  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -1.0040  Acc@1: 81.2500 (81.4108)  Acc@5: 100.0000 (96.2621)  time: 0.3571  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 320/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -1.4033  Acc@1: 81.2500 (81.4252)  Acc@5: 100.0000 (96.3006)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 330/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.6318  Acc@1: 75.0000 (81.2500)  Acc@5: 93.7500 (96.2047)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 340/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -1.2020  Acc@1: 75.0000 (81.2500)  Acc@5: 93.7500 (96.2243)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 350/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -1.1206  Acc@1: 81.2500 (81.1610)  Acc@5: 100.0000 (96.2429)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.6955  Acc@1: 81.2500 (81.2154)  Acc@5: 93.7500 (96.2258)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -1.0257  Acc@1: 81.2500 (81.3005)  Acc@5: 100.0000 (96.2770)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.5291  Acc@1: 81.2500 (81.1844)  Acc@5: 100.0000 (96.3091)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.7956  Acc@1: 75.0000 (81.0582)  Acc@5: 93.7500 (96.2116)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.9188  Acc@1: 75.0000 (80.9850)  Acc@5: 93.7500 (96.1502)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.7281  Acc@1: 81.2500 (80.8850)  Acc@5: 93.7500 (96.1527)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.6189  Acc@1: 81.2500 (80.8343)  Acc@5: 93.7500 (96.1253)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.7380  Acc@1: 81.2500 (80.8440)  Acc@5: 93.7500 (96.1572)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -1.0639  Acc@1: 81.2500 (80.9807)  Acc@5: 100.0000 (96.1735)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.9832  Acc@1: 81.2500 (81.0006)  Acc@5: 100.0000 (96.2167)  time: 0.3530  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -1.0390  Acc@1: 81.2500 (81.0602)  Acc@5: 100.0000 (96.2175)  time: 0.3534  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -1.2646  Acc@1: 81.2500 (80.9979)  Acc@5: 100.0000 (96.2580)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.7414  Acc@1: 81.2500 (81.0681)  Acc@5: 100.0000 (96.2708)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 490/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -1.3055  Acc@1: 87.5000 (81.1864)  Acc@5: 93.7500 (96.2704)  time: 0.3567  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 500/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.8824  Acc@1: 81.2500 (81.1751)  Acc@5: 100.0000 (96.2824)  time: 0.3580  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 510/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.8135  Acc@1: 81.2500 (81.0543)  Acc@5: 93.7500 (96.2696)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 520/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -1.0894  Acc@1: 75.0000 (80.9741)  Acc@5: 93.7500 (96.2452)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.8485  Acc@1: 81.2500 (81.0617)  Acc@5: 100.0000 (96.3041)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -1.2577  Acc@1: 87.5000 (81.0305)  Acc@5: 100.0000 (96.3147)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.9019  Acc@1: 81.2500 (81.0345)  Acc@5: 93.7500 (96.2908)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -1.0995  Acc@1: 81.2500 (81.0049)  Acc@5: 93.7500 (96.2455)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.4683  Acc@1: 81.2500 (81.0201)  Acc@5: 93.7500 (96.2347)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -1.0937  Acc@1: 81.2500 (81.0241)  Acc@5: 93.7500 (96.1919)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -1.1349  Acc@1: 81.2500 (81.0279)  Acc@5: 100.0000 (96.2246)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.4252  Acc@1: 81.2500 (81.0420)  Acc@5: 100.0000 (96.2250)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.9064  Acc@1: 81.2500 (81.0147)  Acc@5: 100.0000 (96.2561)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -1.2349  Acc@1: 81.2500 (81.0185)  Acc@5: 100.0000 (96.2963)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.9255  Acc@1: 87.5000 (81.0519)  Acc@5: 100.0000 (96.2956)  time: 0.3545  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.6760  Acc@1: 81.2500 (81.0452)  Acc@5: 93.7500 (96.2656)  time: 0.3536  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -1.0958  Acc@1: 81.2500 (81.0388)  Acc@5: 100.0000 (96.2654)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 660/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.8164  Acc@1: 81.2500 (81.0420)  Acc@5: 100.0000 (96.2746)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 670/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.7926  Acc@1: 81.2500 (80.9985)  Acc@5: 93.7500 (96.2742)  time: 0.3590  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 680/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -1.1456  Acc@1: 75.0000 (80.9380)  Acc@5: 93.7500 (96.2647)  time: 0.3568  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -1.1053  Acc@1: 75.0000 (80.9425)  Acc@5: 93.7500 (96.2645)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -1.4751  Acc@1: 81.2500 (80.9914)  Acc@5: 93.7500 (96.2553)  time: 0.3552  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.8991  Acc@1: 81.2500 (80.9335)  Acc@5: 93.7500 (96.2553)  time: 0.3618  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.5880  Acc@1: 81.2500 (80.9553)  Acc@5: 93.7500 (96.2552)  time: 0.3604  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -1.0903  Acc@1: 81.2500 (80.9337)  Acc@5: 100.0000 (96.2466)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -0.8492  Acc@1: 81.2500 (80.8789)  Acc@5: 93.7500 (96.2045)  time: 0.3542  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -1.1919  Acc@1: 81.2500 (80.9504)  Acc@5: 100.0000 (96.2467)  time: 0.3553  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -1.1795  Acc@1: 81.2500 (80.9543)  Acc@5: 100.0000 (96.2467)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -1.1069  Acc@1: 81.2500 (81.0149)  Acc@5: 100.0000 (96.2630)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -1.2357  Acc@1: 87.5000 (81.0739)  Acc@5: 100.0000 (96.2788)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.7009  Acc@1: 81.2500 (81.0920)  Acc@5: 100.0000 (96.2863)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.9727  Acc@1: 81.2500 (81.0393)  Acc@5: 93.7500 (96.2781)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.4784  Acc@1: 81.2500 (81.0573)  Acc@5: 100.0000 (96.2932)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -1.0731  Acc@1: 87.5000 (81.0749)  Acc@5: 93.7500 (96.2698)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 830/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.6230  Acc@1: 81.2500 (81.0545)  Acc@5: 93.7500 (96.2846)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 840/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.4588  Acc@1: 75.0000 (80.9973)  Acc@5: 93.7500 (96.2768)  time: 0.3545  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [ 850/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.6336  Acc@1: 81.2500 (81.0297)  Acc@5: 93.7500 (96.2911)  time: 0.3567  data: 0.0033  max mem: 2500
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.9016  Acc@1: 81.2500 (81.0177)  Acc@5: 100.0000 (96.2979)  time: 0.3574  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.9041  Acc@1: 81.2500 (81.0132)  Acc@5: 100.0000 (96.3117)  time: 0.3537  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.8765  Acc@1: 75.0000 (80.9662)  Acc@5: 100.0000 (96.3039)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -0.9032  Acc@1: 75.0000 (80.9343)  Acc@5: 93.7500 (96.2893)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.3223  Acc@1: 81.2500 (80.9587)  Acc@5: 100.0000 (96.3166)  time: 0.3583  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -1.0580  Acc@1: 81.2500 (80.9619)  Acc@5: 100.0000 (96.3021)  time: 0.3552  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -1.0443  Acc@1: 81.2500 (80.9650)  Acc@5: 93.7500 (96.3016)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -1.3256  Acc@1: 81.2500 (80.9211)  Acc@5: 100.0000 (96.3144)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -1.0580  Acc@1: 75.0000 (80.9046)  Acc@5: 100.0000 (96.3138)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -0.7414  Acc@1: 81.2500 (80.9148)  Acc@5: 100.0000 (96.3065)  time: 0.3506  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.8170  Acc@1: 81.2500 (80.9443)  Acc@5: 93.7500 (96.3059)  time: 0.3518  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -1.3450  Acc@1: 81.2500 (80.9475)  Acc@5: 100.0000 (96.3118)  time: 0.3510  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -1.2319  Acc@1: 81.2500 (80.9314)  Acc@5: 100.0000 (96.3175)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.9125  Acc@1: 81.2500 (80.9662)  Acc@5: 100.0000 (96.3295)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1000/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -1.0565  Acc@1: 81.2500 (80.9253)  Acc@5: 100.0000 (96.3224)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1010/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.7648  Acc@1: 81.2500 (80.8976)  Acc@5: 93.7500 (96.3093)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1020/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.6131  Acc@1: 81.2500 (80.9317)  Acc@5: 100.0000 (96.3271)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -1.0598  Acc@1: 81.2500 (80.9469)  Acc@5: 100.0000 (96.3264)  time: 0.3546  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.8775  Acc@1: 81.2500 (80.9318)  Acc@5: 93.7500 (96.3196)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.8655  Acc@1: 81.2500 (80.9110)  Acc@5: 93.7500 (96.3130)  time: 0.3544  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -1.2065  Acc@1: 81.2500 (80.8730)  Acc@5: 100.0000 (96.3301)  time: 0.3561  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -1.0729  Acc@1: 81.2500 (80.8765)  Acc@5: 100.0000 (96.3235)  time: 0.3545  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.9763  Acc@1: 81.2500 (80.8742)  Acc@5: 93.7500 (96.3344)  time: 0.3531  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -1.1533  Acc@1: 81.2500 (80.8776)  Acc@5: 100.0000 (96.3279)  time: 0.3524  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.9900  Acc@1: 81.2500 (80.8867)  Acc@5: 100.0000 (96.3499)  time: 0.3545  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.9923  Acc@1: 81.2500 (80.9012)  Acc@5: 100.0000 (96.3659)  time: 0.3537  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.6482  Acc@1: 81.2500 (80.9099)  Acc@5: 100.0000 (96.3704)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.5911  Acc@1: 81.2500 (80.9129)  Acc@5: 100.0000 (96.3804)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -1.0088  Acc@1: 81.2500 (80.9104)  Acc@5: 100.0000 (96.3957)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -1.1669  Acc@1: 81.2500 (80.8916)  Acc@5: 100.0000 (96.3944)  time: 0.3542  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -1.1711  Acc@1: 75.0000 (80.8839)  Acc@5: 100.0000 (96.3932)  time: 0.3532  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1170/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.7428  Acc@1: 81.2500 (80.8924)  Acc@5: 93.7500 (96.3866)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1180/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -1.1933  Acc@1: 81.2500 (80.9060)  Acc@5: 93.7500 (96.3961)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1190/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -1.2274  Acc@1: 81.2500 (80.8984)  Acc@5: 100.0000 (96.3948)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -1.2969  Acc@1: 87.5000 (80.9430)  Acc@5: 100.0000 (96.3988)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.8688  Acc@1: 87.5000 (80.9249)  Acc@5: 100.0000 (96.4182)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -1.3275  Acc@1: 81.2500 (80.9429)  Acc@5: 100.0000 (96.4271)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -1.1223  Acc@1: 81.2500 (80.9251)  Acc@5: 100.0000 (96.4206)  time: 0.3517  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -1.2627  Acc@1: 81.2500 (80.9226)  Acc@5: 100.0000 (96.4192)  time: 0.3554  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.9274  Acc@1: 81.2500 (80.8953)  Acc@5: 93.7500 (96.4029)  time: 0.3559  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -1.1840  Acc@1: 81.2500 (80.9080)  Acc@5: 100.0000 (96.4215)  time: 0.3548  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -1.1082  Acc@1: 81.2500 (80.9107)  Acc@5: 100.0000 (96.4300)  time: 0.3548  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -1.1448  Acc@1: 81.2500 (80.9036)  Acc@5: 100.0000 (96.4335)  time: 0.3551  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.8574  Acc@1: 81.2500 (80.8918)  Acc@5: 100.0000 (96.4272)  time: 0.3601  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -1.1488  Acc@1: 81.2500 (80.8753)  Acc@5: 100.0000 (96.4354)  time: 0.3589  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.8271  Acc@1: 87.5000 (80.9068)  Acc@5: 100.0000 (96.4436)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.6748  Acc@1: 87.5000 (80.9141)  Acc@5: 100.0000 (96.4374)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.6901  Acc@1: 87.5000 (80.9260)  Acc@5: 93.7500 (96.4313)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1340/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -1.1672  Acc@1: 87.5000 (80.9471)  Acc@5: 93.7500 (96.4252)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1350/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.5961  Acc@1: 87.5000 (80.9771)  Acc@5: 93.7500 (96.4286)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1360/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.5621  Acc@1: 87.5000 (80.9882)  Acc@5: 100.0000 (96.4319)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.7520  Acc@1: 81.2500 (81.0221)  Acc@5: 100.0000 (96.4396)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.7975  Acc@1: 81.2500 (81.0282)  Acc@5: 93.7500 (96.4247)  time: 0.3499  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -1.1611  Acc@1: 81.2500 (81.0478)  Acc@5: 93.7500 (96.4324)  time: 0.3495  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -1.0007  Acc@1: 75.0000 (81.0091)  Acc@5: 100.0000 (96.4267)  time: 0.3505  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.9917  Acc@1: 81.2500 (81.0064)  Acc@5: 93.7500 (96.4298)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.9437  Acc@1: 81.2500 (81.0037)  Acc@5: 100.0000 (96.4418)  time: 0.3543  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.8870  Acc@1: 81.2500 (81.0491)  Acc@5: 100.0000 (96.4448)  time: 0.3545  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -1.0918  Acc@1: 87.5000 (81.0505)  Acc@5: 100.0000 (96.4521)  time: 0.3541  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.8441  Acc@1: 81.2500 (81.0562)  Acc@5: 100.0000 (96.4550)  time: 0.3539  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.9956  Acc@1: 81.2500 (81.0618)  Acc@5: 100.0000 (96.4579)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.1824  Acc@1: 81.2500 (81.0673)  Acc@5: 100.0000 (96.4650)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -1.1260  Acc@1: 81.2500 (81.0812)  Acc@5: 100.0000 (96.4762)  time: 0.3574  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -1.0266  Acc@1: 81.2500 (81.0656)  Acc@5: 100.0000 (96.4747)  time: 0.3587  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.9819  Acc@1: 81.2500 (81.0751)  Acc@5: 100.0000 (96.4690)  time: 0.3542  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1510/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -1.3601  Acc@1: 81.2500 (81.0804)  Acc@5: 100.0000 (96.4593)  time: 0.3669  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1520/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.6670  Acc@1: 81.2500 (81.0897)  Acc@5: 100.0000 (96.4620)  time: 0.3646  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1530/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.6558  Acc@1: 81.2500 (81.1030)  Acc@5: 93.7500 (96.4566)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.7086  Acc@1: 81.2500 (81.1080)  Acc@5: 93.7500 (96.4633)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -1.2901  Acc@1: 81.2500 (81.1130)  Acc@5: 100.0000 (96.4499)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.9595  Acc@1: 81.2500 (81.0898)  Acc@5: 93.7500 (96.4446)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.6414  Acc@1: 81.2500 (81.0948)  Acc@5: 93.7500 (96.4394)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.9926  Acc@1: 81.2500 (81.1235)  Acc@5: 100.0000 (96.4540)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.5928  Acc@1: 81.2500 (81.1047)  Acc@5: 100.0000 (96.4527)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.8807  Acc@1: 81.2500 (81.1017)  Acc@5: 93.7500 (96.4436)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -1.2375  Acc@1: 81.2500 (81.0987)  Acc@5: 93.7500 (96.4308)  time: 0.3544  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.7862  Acc@1: 81.2500 (81.0958)  Acc@5: 93.7500 (96.4335)  time: 0.3574  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.6288  Acc@1: 81.2500 (81.0661)  Acc@5: 93.7500 (96.4171)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -1.0976  Acc@1: 81.2500 (81.0520)  Acc@5: 93.7500 (96.4199)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -1.0345  Acc@1: 81.2500 (81.0456)  Acc@5: 100.0000 (96.4188)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.7917  Acc@1: 81.2500 (81.0581)  Acc@5: 100.0000 (96.4253)  time: 0.3561  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.9010  Acc@1: 81.2500 (81.0405)  Acc@5: 100.0000 (96.4355)  time: 0.3553  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -1.1658  Acc@1: 81.2500 (81.0827)  Acc@5: 100.0000 (96.4493)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1690/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.9505  Acc@1: 87.5000 (81.0874)  Acc@5: 100.0000 (96.4555)  time: 0.3627  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1700/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.8234  Acc@1: 81.2500 (81.0847)  Acc@5: 93.7500 (96.4286)  time: 0.3644  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.7084  Acc@1: 81.2500 (81.1112)  Acc@5: 93.7500 (96.4275)  time: 0.3533  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -1.3986  Acc@1: 81.2500 (81.1265)  Acc@5: 100.0000 (96.4265)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -1.0233  Acc@1: 81.2500 (81.1308)  Acc@5: 100.0000 (96.4255)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.5921  Acc@1: 81.2500 (81.1136)  Acc@5: 100.0000 (96.4281)  time: 0.3990  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.7678  Acc@1: 75.0000 (81.0894)  Acc@5: 100.0000 (96.4270)  time: 0.5999  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.7182  Acc@1: 81.2500 (81.1080)  Acc@5: 100.0000 (96.4260)  time: 0.7547  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -1.0425  Acc@1: 87.5000 (81.1194)  Acc@5: 100.0000 (96.4321)  time: 0.7548  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.5389  Acc@1: 81.2500 (81.0956)  Acc@5: 93.7500 (96.4241)  time: 0.7232  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.5809  Acc@1: 81.2500 (81.1244)  Acc@5: 93.7500 (96.4301)  time: 0.5216  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.5553  Acc@1: 81.2500 (81.1355)  Acc@5: 100.0000 (96.4360)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.8434  Acc@1: 81.2500 (81.1568)  Acc@5: 100.0000 (96.4419)  time: 0.3538  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.7196  Acc@1: 81.2500 (81.1676)  Acc@5: 100.0000 (96.4511)  time: 0.3555  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -1.1638  Acc@1: 81.2500 (81.1647)  Acc@5: 100.0000 (96.4569)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -1.0942  Acc@1: 81.2500 (81.1719)  Acc@5: 93.7500 (96.4557)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -1.2882  Acc@1: 81.2500 (81.1960)  Acc@5: 100.0000 (96.4749)  time: 0.3555  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1860/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.9359  Acc@1: 81.2500 (81.1795)  Acc@5: 100.0000 (96.4703)  time: 0.3554  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1870/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.7968  Acc@1: 81.2500 (81.1765)  Acc@5: 100.0000 (96.4825)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1880/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -1.0118  Acc@1: 81.2500 (81.1603)  Acc@5: 100.0000 (96.4746)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1890/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.7369  Acc@1: 81.2500 (81.1707)  Acc@5: 100.0000 (96.4701)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1900/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.3815  Acc@1: 81.2500 (81.1448)  Acc@5: 100.0000 (96.4525)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1910/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.9776  Acc@1: 81.2500 (81.1388)  Acc@5: 93.7500 (96.4449)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1920/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -1.1079  Acc@1: 81.2500 (81.1134)  Acc@5: 100.0000 (96.4537)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.9026  Acc@1: 81.2500 (81.1238)  Acc@5: 100.0000 (96.4494)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -1.3003  Acc@1: 81.2500 (81.1405)  Acc@5: 93.7500 (96.4484)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -1.1520  Acc@1: 87.5000 (81.1539)  Acc@5: 93.7500 (96.4409)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -1.1478  Acc@1: 81.2500 (81.1608)  Acc@5: 93.7500 (96.4431)  time: 0.3523  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.5902  Acc@1: 81.2500 (81.1517)  Acc@5: 100.0000 (96.4453)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.4320  Acc@1: 81.2500 (81.1396)  Acc@5: 93.7500 (96.4286)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.9573  Acc@1: 75.0000 (81.1370)  Acc@5: 93.7500 (96.4214)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.9633  Acc@1: 81.2500 (81.1407)  Acc@5: 93.7500 (96.4174)  time: 0.3603  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -1.2104  Acc@1: 81.2500 (81.1226)  Acc@5: 100.0000 (96.4228)  time: 0.3581  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -1.0048  Acc@1: 81.2500 (81.1201)  Acc@5: 100.0000 (96.4158)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2030/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.8359  Acc@1: 81.2500 (81.1331)  Acc@5: 100.0000 (96.4242)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2040/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.9863  Acc@1: 81.2500 (81.1244)  Acc@5: 100.0000 (96.4233)  time: 0.3579  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2050/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.5758  Acc@1: 81.2500 (81.1312)  Acc@5: 100.0000 (96.4316)  time: 0.3568  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2060/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -0.8249  Acc@1: 87.5000 (81.1439)  Acc@5: 100.0000 (96.4338)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2070/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -1.0216  Acc@1: 87.5000 (81.1504)  Acc@5: 100.0000 (96.4329)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2080/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -1.0706  Acc@1: 81.2500 (81.1449)  Acc@5: 100.0000 (96.4350)  time: 0.3529  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.8799  Acc@1: 81.2500 (81.1544)  Acc@5: 100.0000 (96.4371)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.5808  Acc@1: 81.2500 (81.1310)  Acc@5: 93.7500 (96.4332)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.7139  Acc@1: 81.2500 (81.1197)  Acc@5: 93.7500 (96.4205)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -1.3493  Acc@1: 81.2500 (81.1262)  Acc@5: 93.7500 (96.4227)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.4766  Acc@1: 81.2500 (81.1239)  Acc@5: 100.0000 (96.4189)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.8667  Acc@1: 81.2500 (81.1216)  Acc@5: 93.7500 (96.4123)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.8137  Acc@1: 81.2500 (81.1454)  Acc@5: 100.0000 (96.4174)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.7524  Acc@1: 81.2500 (81.1575)  Acc@5: 100.0000 (96.4166)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.9409  Acc@1: 87.5000 (81.1751)  Acc@5: 100.0000 (96.4216)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -1.0332  Acc@1: 87.5000 (81.1984)  Acc@5: 100.0000 (96.4237)  time: 0.3575  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -1.0436  Acc@1: 81.2500 (81.2044)  Acc@5: 100.0000 (96.4172)  time: 0.3579  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2200/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -1.3577  Acc@1: 81.2500 (81.2017)  Acc@5: 93.7500 (96.4164)  time: 0.3546  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2210/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.7636  Acc@1: 81.2500 (81.1991)  Acc@5: 93.7500 (96.4043)  time: 0.3531  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2220/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.7575  Acc@1: 81.2500 (81.1881)  Acc@5: 93.7500 (96.4093)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2230/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -1.3894  Acc@1: 81.2500 (81.1940)  Acc@5: 100.0000 (96.4142)  time: 0.3556  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2240/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.4306  Acc@1: 75.0000 (81.1691)  Acc@5: 93.7500 (96.4023)  time: 0.3538  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2250/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.8371  Acc@1: 75.0000 (81.1612)  Acc@5: 93.7500 (96.3960)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -1.4027  Acc@1: 81.2500 (81.1781)  Acc@5: 100.0000 (96.4092)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.7362  Acc@1: 81.2500 (81.1839)  Acc@5: 100.0000 (96.4140)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.7851  Acc@1: 81.2500 (81.1705)  Acc@5: 100.0000 (96.4133)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.9996  Acc@1: 81.2500 (81.1736)  Acc@5: 100.0000 (96.4208)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.6270  Acc@1: 81.2500 (81.1794)  Acc@5: 100.0000 (96.4200)  time: 0.3548  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -1.0252  Acc@1: 87.5000 (81.1905)  Acc@5: 93.7500 (96.4193)  time: 0.3595  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.8989  Acc@1: 81.2500 (81.1908)  Acc@5: 93.7500 (96.4159)  time: 0.3537  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -1.2267  Acc@1: 81.2500 (81.1856)  Acc@5: 100.0000 (96.4152)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.9688  Acc@1: 81.2500 (81.1859)  Acc@5: 100.0000 (96.4145)  time: 0.4363  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -1.2952  Acc@1: 81.2500 (81.1756)  Acc@5: 100.0000 (96.4191)  time: 0.6380  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -1.1262  Acc@1: 87.5000 (81.1971)  Acc@5: 100.0000 (96.4157)  time: 0.7527  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2370/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -1.1095  Acc@1: 87.5000 (81.2131)  Acc@5: 100.0000 (96.4177)  time: 0.7525  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2380/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.5769  Acc@1: 81.2500 (81.2133)  Acc@5: 100.0000 (96.4248)  time: 0.5799  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2390/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -1.0834  Acc@1: 81.2500 (81.2212)  Acc@5: 100.0000 (96.4345)  time: 0.3778  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2400/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.7949  Acc@1: 81.2500 (81.2214)  Acc@5: 100.0000 (96.4390)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2410/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -1.1481  Acc@1: 81.2500 (81.2111)  Acc@5: 100.0000 (96.4382)  time: 0.3543  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2420/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -1.2488  Acc@1: 81.2500 (81.2190)  Acc@5: 93.7500 (96.4400)  time: 0.3546  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2430/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.9090  Acc@1: 81.2500 (81.2063)  Acc@5: 93.7500 (96.4367)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.9626  Acc@1: 81.2500 (81.1783)  Acc@5: 93.7500 (96.4256)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -1.1407  Acc@1: 81.2500 (81.1710)  Acc@5: 93.7500 (96.4173)  time: 0.3608  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.2724  Acc@1: 81.2500 (81.1586)  Acc@5: 93.7500 (96.4039)  time: 0.3577  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.6180  Acc@1: 81.2500 (81.1488)  Acc@5: 93.7500 (96.4033)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -0.9353  Acc@1: 81.2500 (81.1442)  Acc@5: 93.7500 (96.4027)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.9547  Acc@1: 81.2500 (81.1421)  Acc@5: 93.7500 (96.3970)  time: 0.4747  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -1.0117  Acc@1: 81.2500 (81.1400)  Acc@5: 100.0000 (96.4064)  time: 0.6777  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -1.2418  Acc@1: 81.2500 (81.1554)  Acc@5: 100.0000 (96.4033)  time: 0.7540  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.6202  Acc@1: 87.5000 (81.1682)  Acc@5: 93.7500 (96.4077)  time: 0.7484  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -1.0245  Acc@1: 87.5000 (81.1858)  Acc@5: 93.7500 (96.4071)  time: 0.5500  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.8508  Acc@1: 87.5000 (81.1836)  Acc@5: 93.7500 (96.3941)  time: 0.3548  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2550/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.9924  Acc@1: 81.2500 (81.1716)  Acc@5: 100.0000 (96.4058)  time: 0.3512  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2560/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -1.0517  Acc@1: 75.0000 (81.1573)  Acc@5: 100.0000 (96.4003)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2570/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.9217  Acc@1: 75.0000 (81.1552)  Acc@5: 93.7500 (96.4022)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2580/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.0313  Acc@1: 81.2500 (81.1580)  Acc@5: 100.0000 (96.4089)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2590/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.7604  Acc@1: 81.2500 (81.1463)  Acc@5: 100.0000 (96.4179)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2600/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -1.2569  Acc@1: 81.2500 (81.1515)  Acc@5: 100.0000 (96.4172)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2610/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -1.1482  Acc@1: 81.2500 (81.1590)  Acc@5: 100.0000 (96.4190)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -1.1129  Acc@1: 81.2500 (81.1713)  Acc@5: 93.7500 (96.4160)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -1.1885  Acc@1: 81.2500 (81.1526)  Acc@5: 93.7500 (96.4177)  time: 0.3526  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.4831  Acc@1: 75.0000 (81.1459)  Acc@5: 100.0000 (96.4218)  time: 0.3596  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -1.0997  Acc@1: 81.2500 (81.1581)  Acc@5: 100.0000 (96.4259)  time: 0.3568  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -1.2371  Acc@1: 87.5000 (81.1607)  Acc@5: 100.0000 (96.4323)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.9815  Acc@1: 81.2500 (81.1470)  Acc@5: 100.0000 (96.4316)  time: 0.4299  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -1.2904  Acc@1: 81.2500 (81.1521)  Acc@5: 93.7500 (96.4286)  time: 0.6339  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -1.0723  Acc@1: 87.5000 (81.1664)  Acc@5: 100.0000 (96.4372)  time: 0.7580  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.9739  Acc@1: 87.5000 (81.1690)  Acc@5: 100.0000 (96.4342)  time: 0.7523  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6333  Acc@1: 81.2500 (81.1739)  Acc@5: 93.7500 (96.4358)  time: 0.7487  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2720/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -1.0028  Acc@1: 81.2500 (81.1650)  Acc@5: 100.0000 (96.4420)  time: 0.6623  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2730/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -1.1075  Acc@1: 81.2500 (81.1836)  Acc@5: 100.0000 (96.4436)  time: 0.4622  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2740/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.1308  Acc@1: 81.2500 (81.1862)  Acc@5: 100.0000 (96.4406)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2750/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.9656  Acc@1: 81.2500 (81.1887)  Acc@5: 93.7500 (96.4399)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2760/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.7557  Acc@1: 87.5000 (81.2115)  Acc@5: 100.0000 (96.4483)  time: 0.3493  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2770/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.7411  Acc@1: 87.5000 (81.2274)  Acc@5: 100.0000 (96.4476)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2780/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.9165  Acc@1: 87.5000 (81.2410)  Acc@5: 100.0000 (96.4559)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2790/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.8027  Acc@1: 87.5000 (81.2478)  Acc@5: 100.0000 (96.4462)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -1.1982  Acc@1: 81.2500 (81.2411)  Acc@5: 93.7500 (96.4410)  time: 0.3580  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.6742  Acc@1: 81.2500 (81.2344)  Acc@5: 93.7500 (96.4314)  time: 0.3579  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -1.2519  Acc@1: 81.2500 (81.2345)  Acc@5: 93.7500 (96.4352)  time: 0.3548  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.5198  Acc@1: 81.2500 (81.2191)  Acc@5: 100.0000 (96.4324)  time: 0.3543  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.8584  Acc@1: 75.0000 (81.2060)  Acc@5: 93.7500 (96.4251)  time: 0.3557  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -1.3315  Acc@1: 81.2500 (81.2259)  Acc@5: 100.0000 (96.4355)  time: 0.3556  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.8934  Acc@1: 87.5000 (81.2325)  Acc@5: 100.0000 (96.4348)  time: 0.3529  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -1.0234  Acc@1: 81.2500 (81.2413)  Acc@5: 100.0000 (96.4451)  time: 0.3546  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.7366  Acc@1: 81.2500 (81.2457)  Acc@5: 100.0000 (96.4400)  time: 0.3541  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -0.9793  Acc@1: 87.5000 (81.2565)  Acc@5: 100.0000 (96.4394)  time: 0.3588  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2900/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.7784  Acc@1: 87.5000 (81.2737)  Acc@5: 100.0000 (96.4473)  time: 0.3603  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2910/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.7246  Acc@1: 81.2500 (81.2779)  Acc@5: 100.0000 (96.4510)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2920/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -1.0674  Acc@1: 81.2500 (81.2757)  Acc@5: 93.7500 (96.4439)  time: 0.3559  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2930/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -0.4702  Acc@1: 81.2500 (81.2863)  Acc@5: 93.7500 (96.4475)  time: 0.5452  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2940/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.5255  Acc@1: 81.2500 (81.2904)  Acc@5: 100.0000 (96.4489)  time: 0.7389  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2950/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -1.0829  Acc@1: 81.2500 (81.2945)  Acc@5: 100.0000 (96.4546)  time: 0.7474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2960/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.9478  Acc@1: 81.2500 (81.2859)  Acc@5: 100.0000 (96.4539)  time: 0.7454  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.9472  Acc@1: 81.2500 (81.2773)  Acc@5: 93.7500 (96.4511)  time: 0.7439  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -1.0178  Acc@1: 81.2500 (81.2584)  Acc@5: 100.0000 (96.4546)  time: 0.7453  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -1.0962  Acc@1: 81.2500 (81.2625)  Acc@5: 100.0000 (96.4498)  time: 0.7485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -1.1599  Acc@1: 81.2500 (81.2625)  Acc@5: 93.7500 (96.4512)  time: 0.5722  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.9774  Acc@1: 81.2500 (81.2604)  Acc@5: 100.0000 (96.4464)  time: 0.3716  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.0508  Acc@1: 81.2500 (81.2438)  Acc@5: 93.7500 (96.4416)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.9473  Acc@1: 75.0000 (81.2356)  Acc@5: 93.7500 (96.4430)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.0824  Acc@1: 75.0000 (81.2356)  Acc@5: 93.7500 (96.4424)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.8305  Acc@1: 81.2500 (81.2377)  Acc@5: 93.7500 (96.4335)  time: 0.3606  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.7563  Acc@1: 81.2500 (81.2398)  Acc@5: 93.7500 (96.4350)  time: 0.3599  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3070/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -1.0039  Acc@1: 81.2500 (81.2480)  Acc@5: 100.0000 (96.4344)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3080/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.3954  Acc@1: 81.2500 (81.2439)  Acc@5: 100.0000 (96.4358)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3090/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -1.3084  Acc@1: 81.2500 (81.2419)  Acc@5: 93.7500 (96.4332)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3100/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.0399  Acc@1: 81.2500 (81.2460)  Acc@5: 100.0000 (96.4366)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3110/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.9316  Acc@1: 81.2500 (81.2359)  Acc@5: 93.7500 (96.4280)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3120/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.4923  Acc@1: 75.0000 (81.2220)  Acc@5: 93.7500 (96.4234)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.7565  Acc@1: 75.0000 (81.2081)  Acc@5: 93.7500 (96.4149)  time: 0.3536  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -1.1911  Acc@1: 75.0000 (81.2082)  Acc@5: 93.7500 (96.4124)  time: 0.3536  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.6667  Acc@1: 81.2500 (81.2163)  Acc@5: 100.0000 (96.4158)  time: 0.3535  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -1.0323  Acc@1: 81.2500 (81.2085)  Acc@5: 100.0000 (96.4193)  time: 0.3550  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -1.2780  Acc@1: 81.2500 (81.2224)  Acc@5: 100.0000 (96.4286)  time: 0.3627  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -1.4113  Acc@1: 87.5000 (81.2225)  Acc@5: 100.0000 (96.4339)  time: 0.3656  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.4970  Acc@1: 81.2500 (81.2304)  Acc@5: 100.0000 (96.4314)  time: 0.3575  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -1.0580  Acc@1: 81.2500 (81.2227)  Acc@5: 93.7500 (96.4289)  time: 0.3583  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7627  Acc@1: 75.0000 (81.2033)  Acc@5: 93.7500 (96.4283)  time: 0.5336  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -1.0459  Acc@1: 75.0000 (81.1879)  Acc@5: 93.7500 (96.4219)  time: 0.7270  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -1.0312  Acc@1: 81.2500 (81.1958)  Acc@5: 100.0000 (96.4253)  time: 0.7502  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3240/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.6233  Acc@1: 81.2500 (81.1883)  Acc@5: 100.0000 (96.4247)  time: 0.7504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3250/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.8939  Acc@1: 81.2500 (81.1923)  Acc@5: 93.7500 (96.4223)  time: 0.7503  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3260/3750]  eta: 0:03:10  Lr: 0.001875  Loss: -0.8676  Acc@1: 81.2500 (81.1791)  Acc@5: 93.7500 (96.4217)  time: 0.7502  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3270/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -1.1611  Acc@1: 81.2500 (81.1793)  Acc@5: 93.7500 (96.4212)  time: 0.5806  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [3280/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.8187  Acc@1: 81.2500 (81.1624)  Acc@5: 93.7500 (96.4112)  time: 0.3829  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.8538  Acc@1: 75.0000 (81.1531)  Acc@5: 93.7500 (96.4126)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -1.1139  Acc@1: 81.2500 (81.1629)  Acc@5: 100.0000 (96.4159)  time: 0.3522  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -1.0583  Acc@1: 81.2500 (81.1651)  Acc@5: 100.0000 (96.4097)  time: 0.3543  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -1.0887  Acc@1: 81.2500 (81.1615)  Acc@5: 100.0000 (96.4111)  time: 0.3549  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -1.0978  Acc@1: 81.2500 (81.1468)  Acc@5: 100.0000 (96.4144)  time: 0.3546  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -1.0128  Acc@1: 81.2500 (81.1434)  Acc@5: 100.0000 (96.4157)  time: 0.3537  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -0.7021  Acc@1: 81.2500 (81.1194)  Acc@5: 93.7500 (96.4097)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.8072  Acc@1: 81.2500 (81.1254)  Acc@5: 100.0000 (96.4148)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -1.0746  Acc@1: 81.2500 (81.1165)  Acc@5: 93.7500 (96.4050)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -1.0947  Acc@1: 81.2500 (81.1224)  Acc@5: 93.7500 (96.4045)  time: 0.3591  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.2884  Acc@1: 81.2500 (81.1210)  Acc@5: 100.0000 (96.4041)  time: 0.3616  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.8846  Acc@1: 81.2500 (81.1177)  Acc@5: 100.0000 (96.4018)  time: 0.3556  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3410/3750]  eta: 0:02:11  Lr: 0.001875  Loss: -0.9567  Acc@1: 81.2500 (81.1162)  Acc@5: 100.0000 (96.3995)  time: 0.3512  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3420/3750]  eta: 0:02:07  Lr: 0.001875  Loss: -0.4759  Acc@1: 81.2500 (81.1075)  Acc@5: 100.0000 (96.4009)  time: 0.3983  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3430/3750]  eta: 0:02:04  Lr: 0.001875  Loss: -0.4393  Acc@1: 81.2500 (81.1061)  Acc@5: 100.0000 (96.4023)  time: 0.6024  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3440/3750]  eta: 0:02:00  Lr: 0.001875  Loss: -1.1325  Acc@1: 81.2500 (81.1029)  Acc@5: 100.0000 (96.4055)  time: 0.7578  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:57  Lr: 0.001875  Loss: -0.9415  Acc@1: 75.0000 (81.0852)  Acc@5: 100.0000 (96.4068)  time: 0.7546  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:53  Lr: 0.001875  Loss: -0.7909  Acc@1: 81.2500 (81.0875)  Acc@5: 100.0000 (96.4154)  time: 0.7503  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6693  Acc@1: 81.2500 (81.0915)  Acc@5: 100.0000 (96.4167)  time: 0.7531  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:46  Lr: 0.001875  Loss: -0.9271  Acc@1: 87.5000 (81.1028)  Acc@5: 100.0000 (96.4163)  time: 0.7522  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -1.0912  Acc@1: 87.5000 (81.1014)  Acc@5: 100.0000 (96.4194)  time: 0.6580  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.9850  Acc@1: 81.2500 (81.0965)  Acc@5: 100.0000 (96.4225)  time: 0.4585  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.0841  Acc@1: 81.2500 (81.1005)  Acc@5: 100.0000 (96.4220)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.9048  Acc@1: 81.2500 (81.1115)  Acc@5: 93.7500 (96.4232)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.1802  Acc@1: 81.2500 (81.1031)  Acc@5: 100.0000 (96.4210)  time: 0.3491  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:22  Lr: 0.001875  Loss: -1.1512  Acc@1: 81.2500 (81.1053)  Acc@5: 100.0000 (96.4187)  time: 0.3532  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:18  Lr: 0.001875  Loss: -0.6620  Acc@1: 81.2500 (81.1092)  Acc@5: 93.7500 (96.4183)  time: 0.3593  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:14  Lr: 0.001875  Loss: -1.1833  Acc@1: 81.2500 (81.0973)  Acc@5: 100.0000 (96.4195)  time: 0.3554  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -1.1107  Acc@1: 81.2500 (81.1047)  Acc@5: 100.0000 (96.4243)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3580/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.0664  Acc@1: 81.2500 (81.0999)  Acc@5: 100.0000 (96.4169)  time: 0.4480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3590/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.2312  Acc@1: 81.2500 (81.0916)  Acc@5: 93.7500 (96.4164)  time: 0.6484  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0480  Acc@1: 81.2500 (81.1007)  Acc@5: 93.7500 (96.4159)  time: 0.7553  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.8570  Acc@1: 81.2500 (81.1029)  Acc@5: 93.7500 (96.4137)  time: 0.7488  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:51  Lr: 0.001875  Loss: -1.0701  Acc@1: 81.2500 (81.1033)  Acc@5: 93.7500 (96.4116)  time: 0.7446  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9892  Acc@1: 81.2500 (81.1020)  Acc@5: 100.0000 (96.4094)  time: 0.7490  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:43  Lr: 0.001875  Loss: -1.1614  Acc@1: 87.5000 (81.1230)  Acc@5: 100.0000 (96.4124)  time: 0.6727  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:39  Lr: 0.001875  Loss: -0.6570  Acc@1: 87.5000 (81.1267)  Acc@5: 100.0000 (96.4119)  time: 0.4741  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -1.1614  Acc@1: 81.2500 (81.1203)  Acc@5: 100.0000 (96.4132)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0155  Acc@1: 81.2500 (81.1189)  Acc@5: 100.0000 (96.4128)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -1.2528  Acc@1: 81.2500 (81.1278)  Acc@5: 93.7500 (96.4140)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:23  Lr: 0.001875  Loss: -0.9235  Acc@1: 81.2500 (81.1349)  Acc@5: 93.7500 (96.4136)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:19  Lr: 0.001875  Loss: -1.3614  Acc@1: 81.2500 (81.1453)  Acc@5: 100.0000 (96.4182)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:15  Lr: 0.001875  Loss: -1.0300  Acc@1: 81.2500 (81.1574)  Acc@5: 100.0000 (96.4177)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:11  Lr: 0.001875  Loss: -0.9461  Acc@1: 81.2500 (81.1660)  Acc@5: 100.0000 (96.4240)  time: 0.3556  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -1.0260  Acc@1: 87.5000 (81.1796)  Acc@5: 100.0000 (96.4286)  time: 0.3574  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7923  Acc@1: 87.5000 (81.1899)  Acc@5: 100.0000 (96.4348)  time: 0.3554  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6653  Acc@1: 81.2500 (81.1883)  Acc@5: 100.0000 (96.4350)  time: 0.3565  data: 0.0020  max mem: 2500
Train: Epoch[3/5] Total time: 0:24:52 (0.3979 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6653  Acc@1: 81.2500 (81.1883)  Acc@5: 100.0000 (96.4350)
Train: Epoch[4/5]  [   0/3750]  eta: 0:48:23  Lr: 0.001875  Loss: -0.4899  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.7744  data: 0.4265  max mem: 2500
Train: Epoch[4/5]  [  10/3750]  eta: 0:24:22  Lr: 0.001875  Loss: -1.0685  Acc@1: 81.2500 (77.8409)  Acc@5: 93.7500 (94.8864)  time: 0.3911  data: 0.0397  max mem: 2500
Train: Epoch[4/5]  [  20/3750]  eta: 0:23:46  Lr: 0.001875  Loss: -0.7219  Acc@1: 81.2500 (78.2738)  Acc@5: 93.7500 (95.2381)  time: 0.3629  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [  30/3750]  eta: 0:23:06  Lr: 0.001875  Loss: -0.8235  Acc@1: 81.2500 (81.0484)  Acc@5: 93.7500 (95.7661)  time: 0.3628  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:44  Lr: 0.001875  Loss: -0.8586  Acc@1: 81.2500 (81.0976)  Acc@5: 100.0000 (96.3415)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  50/3750]  eta: 0:24:17  Lr: 0.001875  Loss: -1.0868  Acc@1: 81.2500 (80.3922)  Acc@5: 100.0000 (96.0784)  time: 0.4268  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  60/3750]  eta: 0:27:49  Lr: 0.001875  Loss: -0.8832  Acc@1: 81.2500 (80.3279)  Acc@5: 100.0000 (96.5164)  time: 0.6260  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [  70/3750]  eta: 0:30:21  Lr: 0.001875  Loss: -1.3365  Acc@1: 81.2500 (80.8979)  Acc@5: 100.0000 (96.3908)  time: 0.7521  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [  80/3750]  eta: 0:32:09  Lr: 0.001875  Loss: -1.2614  Acc@1: 81.2500 (81.3272)  Acc@5: 100.0000 (96.6049)  time: 0.7495  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  90/3750]  eta: 0:33:33  Lr: 0.001875  Loss: -1.2707  Acc@1: 81.2500 (81.3874)  Acc@5: 100.0000 (96.4973)  time: 0.7469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 100/3750]  eta: 0:34:40  Lr: 0.001875  Loss: -1.2938  Acc@1: 81.2500 (81.4975)  Acc@5: 100.0000 (96.4728)  time: 0.7492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 110/3750]  eta: 0:35:34  Lr: 0.001875  Loss: -1.3023  Acc@1: 81.2500 (81.7005)  Acc@5: 100.0000 (96.7342)  time: 0.7507  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 120/3750]  eta: 0:36:17  Lr: 0.001875  Loss: -0.3229  Acc@1: 81.2500 (81.6116)  Acc@5: 100.0000 (96.6426)  time: 0.7504  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 130/3750]  eta: 0:36:52  Lr: 0.001875  Loss: -1.1476  Acc@1: 81.2500 (81.5840)  Acc@5: 93.7500 (96.6126)  time: 0.7491  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 140/3750]  eta: 0:37:19  Lr: 0.001875  Loss: -1.4007  Acc@1: 87.5000 (81.8706)  Acc@5: 93.7500 (96.6755)  time: 0.7442  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 150/3750]  eta: 0:37:44  Lr: 0.001875  Loss: -1.1084  Acc@1: 81.2500 (81.7881)  Acc@5: 100.0000 (96.7301)  time: 0.7453  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 160/3750]  eta: 0:38:03  Lr: 0.001875  Loss: -1.1255  Acc@1: 81.2500 (81.7935)  Acc@5: 100.0000 (96.7003)  time: 0.7465  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 170/3750]  eta: 0:38:18  Lr: 0.001875  Loss: -1.0726  Acc@1: 81.2500 (81.6520)  Acc@5: 100.0000 (96.6740)  time: 0.7417  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 180/3750]  eta: 0:38:31  Lr: 0.001875  Loss: -1.2999  Acc@1: 81.2500 (81.5953)  Acc@5: 100.0000 (96.6160)  time: 0.7405  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 190/3750]  eta: 0:38:43  Lr: 0.001875  Loss: -0.6913  Acc@1: 81.2500 (81.7081)  Acc@5: 93.7500 (96.5641)  time: 0.7425  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 200/3750]  eta: 0:38:52  Lr: 0.001875  Loss: -1.1337  Acc@1: 87.5000 (81.9341)  Acc@5: 100.0000 (96.6418)  time: 0.7438  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 210/3750]  eta: 0:38:41  Lr: 0.001875  Loss: -0.7172  Acc@1: 87.5000 (82.1090)  Acc@5: 100.0000 (96.6528)  time: 0.6861  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 220/3750]  eta: 0:37:46  Lr: 0.001875  Loss: -0.7541  Acc@1: 87.5000 (82.1267)  Acc@5: 100.0000 (96.6346)  time: 0.4911  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 230/3750]  eta: 0:36:56  Lr: 0.001875  Loss: -1.1689  Acc@1: 87.5000 (82.1158)  Acc@5: 100.0000 (96.6180)  time: 0.3539  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 240/3750]  eta: 0:36:09  Lr: 0.001875  Loss: -1.2303  Acc@1: 87.5000 (82.1577)  Acc@5: 100.0000 (96.6546)  time: 0.3543  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 250/3750]  eta: 0:35:26  Lr: 0.001875  Loss: -0.9545  Acc@1: 81.2500 (82.1962)  Acc@5: 100.0000 (96.7131)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 260/3750]  eta: 0:34:46  Lr: 0.001875  Loss: -0.8096  Acc@1: 81.2500 (82.1121)  Acc@5: 100.0000 (96.7193)  time: 0.3517  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 270/3750]  eta: 0:34:09  Lr: 0.001875  Loss: -0.5009  Acc@1: 81.2500 (81.9419)  Acc@5: 93.7500 (96.6790)  time: 0.3551  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 280/3750]  eta: 0:33:36  Lr: 0.001875  Loss: -0.9352  Acc@1: 81.2500 (82.0062)  Acc@5: 93.7500 (96.6637)  time: 0.3616  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 290/3750]  eta: 0:33:02  Lr: 0.001875  Loss: -1.2676  Acc@1: 81.2500 (81.7655)  Acc@5: 93.7500 (96.5206)  time: 0.3578  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 300/3750]  eta: 0:32:32  Lr: 0.001875  Loss: -0.9774  Acc@1: 81.2500 (81.9560)  Acc@5: 93.7500 (96.5532)  time: 0.3551  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 310/3750]  eta: 0:32:42  Lr: 0.001875  Loss: -0.7504  Acc@1: 81.2500 (81.8931)  Acc@5: 100.0000 (96.5836)  time: 0.5311  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 320/3750]  eta: 0:32:56  Lr: 0.001875  Loss: -1.1998  Acc@1: 81.2500 (81.9899)  Acc@5: 100.0000 (96.5927)  time: 0.7283  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 330/3750]  eta: 0:33:08  Lr: 0.001875  Loss: -1.0485  Acc@1: 87.5000 (82.1186)  Acc@5: 100.0000 (96.6390)  time: 0.7534  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 340/3750]  eta: 0:33:19  Lr: 0.001875  Loss: -1.0869  Acc@1: 87.5000 (82.1298)  Acc@5: 100.0000 (96.6092)  time: 0.7534  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 350/3750]  eta: 0:33:29  Lr: 0.001875  Loss: -0.5207  Acc@1: 81.2500 (82.0513)  Acc@5: 93.7500 (96.6168)  time: 0.7513  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 360/3750]  eta: 0:33:39  Lr: 0.001875  Loss: -1.3328  Acc@1: 81.2500 (82.0637)  Acc@5: 100.0000 (96.6586)  time: 0.7524  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 370/3750]  eta: 0:33:47  Lr: 0.001875  Loss: -0.9063  Acc@1: 81.2500 (82.0923)  Acc@5: 100.0000 (96.6476)  time: 0.7528  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 380/3750]  eta: 0:33:54  Lr: 0.001875  Loss: -1.0460  Acc@1: 81.2500 (82.1522)  Acc@5: 93.7500 (96.6535)  time: 0.7477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 390/3750]  eta: 0:34:00  Lr: 0.001875  Loss: -0.8581  Acc@1: 81.2500 (82.0332)  Acc@5: 100.0000 (96.6592)  time: 0.7470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 400/3750]  eta: 0:34:06  Lr: 0.001875  Loss: -0.9372  Acc@1: 81.2500 (82.0916)  Acc@5: 93.7500 (96.6334)  time: 0.7470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 410/3750]  eta: 0:34:11  Lr: 0.001875  Loss: -0.7122  Acc@1: 81.2500 (82.1168)  Acc@5: 100.0000 (96.6849)  time: 0.7479  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 420/3750]  eta: 0:34:15  Lr: 0.001875  Loss: -0.9371  Acc@1: 81.2500 (82.1556)  Acc@5: 100.0000 (96.7191)  time: 0.7475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 430/3750]  eta: 0:34:19  Lr: 0.001875  Loss: -0.8320  Acc@1: 81.2500 (82.2361)  Acc@5: 93.7500 (96.6647)  time: 0.7461  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 440/3750]  eta: 0:34:22  Lr: 0.001875  Loss: -1.1739  Acc@1: 81.2500 (82.2562)  Acc@5: 100.0000 (96.7120)  time: 0.7432  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 450/3750]  eta: 0:34:24  Lr: 0.001875  Loss: -0.9906  Acc@1: 81.2500 (82.0953)  Acc@5: 100.0000 (96.6463)  time: 0.7403  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 460/3750]  eta: 0:34:26  Lr: 0.001875  Loss: -0.7033  Acc@1: 68.7500 (81.9143)  Acc@5: 93.7500 (96.6242)  time: 0.7401  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 470/3750]  eta: 0:34:28  Lr: 0.001875  Loss: -1.0787  Acc@1: 75.0000 (81.9268)  Acc@5: 100.0000 (96.6428)  time: 0.7427  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 480/3750]  eta: 0:34:29  Lr: 0.001875  Loss: -1.2096  Acc@1: 81.2500 (81.9517)  Acc@5: 100.0000 (96.6346)  time: 0.7423  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 490/3750]  eta: 0:34:30  Lr: 0.001875  Loss: -1.0711  Acc@1: 87.5000 (82.0010)  Acc@5: 93.7500 (96.6268)  time: 0.7383  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 500/3750]  eta: 0:34:30  Lr: 0.001875  Loss: -0.9108  Acc@1: 81.2500 (81.9112)  Acc@5: 93.7500 (96.5569)  time: 0.7379  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 510/3750]  eta: 0:34:30  Lr: 0.001875  Loss: -0.8033  Acc@1: 87.5000 (82.0695)  Acc@5: 93.7500 (96.5631)  time: 0.7375  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 520/3750]  eta: 0:34:30  Lr: 0.001875  Loss: -1.1942  Acc@1: 87.5000 (81.9578)  Acc@5: 93.7500 (96.5331)  time: 0.7377  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 530/3750]  eta: 0:34:29  Lr: 0.001875  Loss: -1.0935  Acc@1: 75.0000 (81.8150)  Acc@5: 100.0000 (96.5749)  time: 0.7361  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 540/3750]  eta: 0:34:28  Lr: 0.001875  Loss: -1.0719  Acc@1: 75.0000 (81.7814)  Acc@5: 100.0000 (96.5342)  time: 0.7345  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 550/3750]  eta: 0:34:27  Lr: 0.001875  Loss: -0.8927  Acc@1: 81.2500 (81.8285)  Acc@5: 100.0000 (96.5404)  time: 0.7387  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 560/3750]  eta: 0:34:26  Lr: 0.001875  Loss: -0.4157  Acc@1: 81.2500 (81.8293)  Acc@5: 100.0000 (96.5352)  time: 0.7385  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 570/3750]  eta: 0:34:24  Lr: 0.001875  Loss: -0.4655  Acc@1: 81.2500 (81.7863)  Acc@5: 100.0000 (96.5412)  time: 0.7334  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 580/3750]  eta: 0:34:16  Lr: 0.001875  Loss: -1.1723  Acc@1: 81.2500 (81.7771)  Acc@5: 100.0000 (96.5469)  time: 0.6777  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 590/3750]  eta: 0:33:54  Lr: 0.001875  Loss: -0.9842  Acc@1: 81.2500 (81.7576)  Acc@5: 100.0000 (96.5525)  time: 0.4897  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 600/3750]  eta: 0:33:32  Lr: 0.001875  Loss: -0.9700  Acc@1: 81.2500 (81.8116)  Acc@5: 100.0000 (96.5786)  time: 0.3540  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 610/3750]  eta: 0:33:11  Lr: 0.001875  Loss: -1.1220  Acc@1: 81.2500 (81.7717)  Acc@5: 100.0000 (96.5937)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 620/3750]  eta: 0:32:51  Lr: 0.001875  Loss: -0.6532  Acc@1: 81.2500 (81.7633)  Acc@5: 100.0000 (96.5781)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 630/3750]  eta: 0:32:31  Lr: 0.001875  Loss: -1.0802  Acc@1: 81.2500 (81.7750)  Acc@5: 100.0000 (96.6026)  time: 0.3559  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 640/3750]  eta: 0:32:11  Lr: 0.001875  Loss: -1.2693  Acc@1: 81.2500 (81.8058)  Acc@5: 100.0000 (96.6166)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 650/3750]  eta: 0:31:52  Lr: 0.001875  Loss: -0.5715  Acc@1: 81.2500 (81.8164)  Acc@5: 100.0000 (96.6302)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 660/3750]  eta: 0:31:34  Lr: 0.001875  Loss: -1.4251  Acc@1: 81.2500 (81.8362)  Acc@5: 100.0000 (96.6339)  time: 0.3567  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 670/3750]  eta: 0:31:16  Lr: 0.001875  Loss: -0.7989  Acc@1: 81.2500 (81.7902)  Acc@5: 93.7500 (96.6095)  time: 0.3575  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 680/3750]  eta: 0:30:58  Lr: 0.001875  Loss: -1.0540  Acc@1: 81.2500 (81.7364)  Acc@5: 93.7500 (96.5859)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 690/3750]  eta: 0:30:41  Lr: 0.001875  Loss: -0.7141  Acc@1: 81.2500 (81.7384)  Acc@5: 100.0000 (96.6082)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 700/3750]  eta: 0:30:24  Lr: 0.001875  Loss: -1.0165  Acc@1: 81.2500 (81.7225)  Acc@5: 93.7500 (96.5763)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 710/3750]  eta: 0:30:08  Lr: 0.001875  Loss: -1.1173  Acc@1: 81.2500 (81.7247)  Acc@5: 93.7500 (96.5629)  time: 0.3596  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 720/3750]  eta: 0:29:52  Lr: 0.001875  Loss: -1.1206  Acc@1: 81.2500 (81.7008)  Acc@5: 100.0000 (96.5586)  time: 0.3583  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 730/3750]  eta: 0:29:36  Lr: 0.001875  Loss: -0.8501  Acc@1: 81.2500 (81.6860)  Acc@5: 93.7500 (96.5287)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 740/3750]  eta: 0:29:21  Lr: 0.001875  Loss: -1.3341  Acc@1: 81.2500 (81.7139)  Acc@5: 93.7500 (96.5334)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 750/3750]  eta: 0:29:06  Lr: 0.001875  Loss: -0.6951  Acc@1: 81.2500 (81.6828)  Acc@5: 93.7500 (96.5296)  time: 0.3541  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 760/3750]  eta: 0:28:51  Lr: 0.001875  Loss: -1.2970  Acc@1: 81.2500 (81.6442)  Acc@5: 100.0000 (96.5506)  time: 0.3521  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 770/3750]  eta: 0:28:36  Lr: 0.001875  Loss: -0.7623  Acc@1: 81.2500 (81.6310)  Acc@5: 100.0000 (96.5548)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 780/3750]  eta: 0:28:22  Lr: 0.001875  Loss: -1.1180  Acc@1: 81.2500 (81.6421)  Acc@5: 100.0000 (96.5669)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 790/3750]  eta: 0:28:08  Lr: 0.001875  Loss: -0.8877  Acc@1: 81.2500 (81.6451)  Acc@5: 100.0000 (96.5787)  time: 0.3494  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 800/3750]  eta: 0:27:54  Lr: 0.001875  Loss: -1.2608  Acc@1: 81.2500 (81.6479)  Acc@5: 100.0000 (96.5902)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 810/3750]  eta: 0:27:40  Lr: 0.001875  Loss: -1.0000  Acc@1: 81.2500 (81.6430)  Acc@5: 100.0000 (96.6168)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 820/3750]  eta: 0:27:27  Lr: 0.001875  Loss: -1.0844  Acc@1: 81.2500 (81.6687)  Acc@5: 100.0000 (96.6124)  time: 0.3519  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 830/3750]  eta: 0:27:14  Lr: 0.001875  Loss: -1.2269  Acc@1: 81.2500 (81.6486)  Acc@5: 100.0000 (96.6381)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 840/3750]  eta: 0:27:01  Lr: 0.001875  Loss: -1.0163  Acc@1: 75.0000 (81.6141)  Acc@5: 100.0000 (96.6632)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 850/3750]  eta: 0:26:49  Lr: 0.001875  Loss: -0.9777  Acc@1: 81.2500 (81.5952)  Acc@5: 100.0000 (96.6730)  time: 0.3545  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 860/3750]  eta: 0:26:37  Lr: 0.001875  Loss: -1.0716  Acc@1: 81.2500 (81.6275)  Acc@5: 100.0000 (96.6463)  time: 0.3569  data: 0.0029  max mem: 2500
Train: Epoch[4/5]  [ 870/3750]  eta: 0:26:24  Lr: 0.001875  Loss: -1.1191  Acc@1: 87.5000 (81.6805)  Acc@5: 93.7500 (96.6490)  time: 0.3540  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 880/3750]  eta: 0:26:12  Lr: 0.001875  Loss: -1.0370  Acc@1: 81.2500 (81.6615)  Acc@5: 93.7500 (96.6302)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 890/3750]  eta: 0:26:01  Lr: 0.001875  Loss: -0.6695  Acc@1: 81.2500 (81.6989)  Acc@5: 93.7500 (96.6330)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 900/3750]  eta: 0:25:49  Lr: 0.001875  Loss: -0.7428  Acc@1: 87.5000 (81.7633)  Acc@5: 100.0000 (96.6565)  time: 0.3570  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 910/3750]  eta: 0:25:38  Lr: 0.001875  Loss: -0.9404  Acc@1: 81.2500 (81.7165)  Acc@5: 100.0000 (96.6726)  time: 0.3541  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 920/3750]  eta: 0:25:27  Lr: 0.001875  Loss: -1.2559  Acc@1: 75.0000 (81.6775)  Acc@5: 100.0000 (96.6545)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 930/3750]  eta: 0:25:16  Lr: 0.001875  Loss: -0.8365  Acc@1: 75.0000 (81.6864)  Acc@5: 93.7500 (96.6233)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 940/3750]  eta: 0:25:05  Lr: 0.001875  Loss: -0.5491  Acc@1: 81.2500 (81.6817)  Acc@5: 93.7500 (96.6259)  time: 0.3529  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 950/3750]  eta: 0:24:54  Lr: 0.001875  Loss: -1.2109  Acc@1: 81.2500 (81.6903)  Acc@5: 100.0000 (96.6351)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 960/3750]  eta: 0:24:43  Lr: 0.001875  Loss: -0.7923  Acc@1: 87.5000 (81.7248)  Acc@5: 100.0000 (96.6441)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 970/3750]  eta: 0:24:33  Lr: 0.001875  Loss: -1.2390  Acc@1: 87.5000 (81.8100)  Acc@5: 100.0000 (96.6529)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 980/3750]  eta: 0:24:22  Lr: 0.001875  Loss: -1.0960  Acc@1: 81.2500 (81.8043)  Acc@5: 100.0000 (96.6552)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 990/3750]  eta: 0:24:12  Lr: 0.001875  Loss: -1.0218  Acc@1: 81.2500 (81.7798)  Acc@5: 100.0000 (96.6700)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1000/3750]  eta: 0:24:02  Lr: 0.001875  Loss: -0.7833  Acc@1: 81.2500 (81.7807)  Acc@5: 100.0000 (96.6846)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1010/3750]  eta: 0:23:52  Lr: 0.001875  Loss: -1.1885  Acc@1: 81.2500 (81.7878)  Acc@5: 100.0000 (96.7050)  time: 0.3513  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1020/3750]  eta: 0:23:42  Lr: 0.001875  Loss: -1.1062  Acc@1: 87.5000 (81.8193)  Acc@5: 100.0000 (96.7067)  time: 0.3547  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1030/3750]  eta: 0:23:33  Lr: 0.001875  Loss: -0.6647  Acc@1: 87.5000 (81.8259)  Acc@5: 100.0000 (96.7144)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1040/3750]  eta: 0:23:23  Lr: 0.001875  Loss: -1.3150  Acc@1: 81.2500 (81.7903)  Acc@5: 100.0000 (96.7279)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1050/3750]  eta: 0:23:14  Lr: 0.001875  Loss: -1.2744  Acc@1: 81.2500 (81.8268)  Acc@5: 100.0000 (96.7293)  time: 0.3565  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1060/3750]  eta: 0:23:05  Lr: 0.001875  Loss: -0.6172  Acc@1: 81.2500 (81.8391)  Acc@5: 100.0000 (96.7366)  time: 0.3549  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1070/3750]  eta: 0:22:55  Lr: 0.001875  Loss: -0.7743  Acc@1: 87.5000 (81.8861)  Acc@5: 100.0000 (96.7437)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1080/3750]  eta: 0:22:46  Lr: 0.001875  Loss: -1.0703  Acc@1: 87.5000 (81.8629)  Acc@5: 100.0000 (96.7565)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1090/3750]  eta: 0:22:37  Lr: 0.001875  Loss: -1.0684  Acc@1: 81.2500 (81.8630)  Acc@5: 93.7500 (96.7232)  time: 0.3532  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [1100/3750]  eta: 0:22:28  Lr: 0.001875  Loss: -0.7191  Acc@1: 81.2500 (81.8120)  Acc@5: 93.7500 (96.7189)  time: 0.3545  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [1110/3750]  eta: 0:22:20  Lr: 0.001875  Loss: -1.2442  Acc@1: 81.2500 (81.8126)  Acc@5: 93.7500 (96.6978)  time: 0.3618  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [1120/3750]  eta: 0:22:11  Lr: 0.001875  Loss: -0.7006  Acc@1: 81.2500 (81.7797)  Acc@5: 100.0000 (96.7105)  time: 0.3649  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1130/3750]  eta: 0:22:03  Lr: 0.001875  Loss: -1.2199  Acc@1: 81.2500 (81.8192)  Acc@5: 100.0000 (96.7286)  time: 0.3569  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1140/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -1.0659  Acc@1: 87.5000 (81.8361)  Acc@5: 100.0000 (96.7463)  time: 0.3561  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1150/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -0.9555  Acc@1: 81.2500 (81.8473)  Acc@5: 100.0000 (96.7474)  time: 0.3729  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1160/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -1.2213  Acc@1: 87.5000 (81.8852)  Acc@5: 100.0000 (96.7700)  time: 0.3696  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1170/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -1.1868  Acc@1: 87.5000 (81.9012)  Acc@5: 100.0000 (96.7709)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1180/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -1.1025  Acc@1: 81.2500 (81.8956)  Acc@5: 100.0000 (96.7665)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1190/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.7623  Acc@1: 75.0000 (81.8797)  Acc@5: 100.0000 (96.7674)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1200/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -1.3888  Acc@1: 81.2500 (81.8641)  Acc@5: 100.0000 (96.7839)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1210/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.8094  Acc@1: 81.2500 (81.8796)  Acc@5: 100.0000 (96.7950)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1220/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.8927  Acc@1: 81.2500 (81.8694)  Acc@5: 100.0000 (96.8008)  time: 0.3539  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1230/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.6465  Acc@1: 81.2500 (81.8440)  Acc@5: 93.7500 (96.7811)  time: 0.3556  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1240/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.7315  Acc@1: 81.2500 (81.8392)  Acc@5: 100.0000 (96.7969)  time: 0.3568  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1250/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.6555  Acc@1: 81.2500 (81.8195)  Acc@5: 100.0000 (96.7976)  time: 0.3558  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1260/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -1.4030  Acc@1: 81.2500 (81.8596)  Acc@5: 100.0000 (96.8180)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1270/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -1.4053  Acc@1: 81.2500 (81.8401)  Acc@5: 100.0000 (96.8283)  time: 0.3535  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1280/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.5382  Acc@1: 81.2500 (81.8404)  Acc@5: 100.0000 (96.8335)  time: 0.3587  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1290/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -1.1596  Acc@1: 81.2500 (81.8406)  Acc@5: 100.0000 (96.8193)  time: 0.3618  data: 0.0033  max mem: 2500
Train: Epoch[4/5]  [1300/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -0.7996  Acc@1: 81.2500 (81.8601)  Acc@5: 93.7500 (96.8198)  time: 0.3613  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [1310/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.5918  Acc@1: 81.2500 (81.8602)  Acc@5: 93.7500 (96.8202)  time: 0.3653  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1320/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.8312  Acc@1: 87.5000 (81.8698)  Acc@5: 93.7500 (96.8111)  time: 0.3602  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1330/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.6636  Acc@1: 87.5000 (81.8651)  Acc@5: 93.7500 (96.8069)  time: 0.3544  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [1340/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -1.1527  Acc@1: 81.2500 (81.8792)  Acc@5: 100.0000 (96.8261)  time: 0.3783  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [1350/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -0.5210  Acc@1: 87.5000 (81.8977)  Acc@5: 100.0000 (96.8264)  time: 0.3746  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1360/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.9517  Acc@1: 81.2500 (81.9021)  Acc@5: 100.0000 (96.8314)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1370/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.8862  Acc@1: 81.2500 (81.8928)  Acc@5: 100.0000 (96.8135)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1380/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -1.0122  Acc@1: 81.2500 (81.8836)  Acc@5: 100.0000 (96.8094)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1390/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -1.0890  Acc@1: 81.2500 (81.8835)  Acc@5: 100.0000 (96.7919)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1400/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -1.1094  Acc@1: 81.2500 (81.8790)  Acc@5: 93.7500 (96.7791)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1410/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.6427  Acc@1: 81.2500 (81.8790)  Acc@5: 93.7500 (96.7576)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1420/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.9539  Acc@1: 81.2500 (81.8526)  Acc@5: 93.7500 (96.7584)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1430/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -1.1496  Acc@1: 75.0000 (81.8353)  Acc@5: 100.0000 (96.7593)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1440/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -1.1614  Acc@1: 75.0000 (81.8095)  Acc@5: 100.0000 (96.7644)  time: 0.3553  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1450/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.5379  Acc@1: 75.0000 (81.8186)  Acc@5: 100.0000 (96.7609)  time: 0.3554  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1460/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.9215  Acc@1: 81.2500 (81.8232)  Acc@5: 100.0000 (96.7659)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1470/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -1.1565  Acc@1: 81.2500 (81.8321)  Acc@5: 100.0000 (96.7667)  time: 0.3568  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1480/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -1.0789  Acc@1: 81.2500 (81.8197)  Acc@5: 100.0000 (96.7463)  time: 0.3626  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1490/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -1.2348  Acc@1: 81.2500 (81.8243)  Acc@5: 100.0000 (96.7430)  time: 0.3574  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1500/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -1.2362  Acc@1: 81.2500 (81.8288)  Acc@5: 100.0000 (96.7480)  time: 0.3525  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1510/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.8808  Acc@1: 81.2500 (81.8291)  Acc@5: 100.0000 (96.7613)  time: 0.3607  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1520/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -0.9661  Acc@1: 81.2500 (81.8253)  Acc@5: 100.0000 (96.7661)  time: 0.3609  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1530/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -1.1983  Acc@1: 87.5000 (81.8664)  Acc@5: 100.0000 (96.7709)  time: 0.3523  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1540/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -1.0512  Acc@1: 87.5000 (81.8705)  Acc@5: 100.0000 (96.7756)  time: 0.3569  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1550/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.5994  Acc@1: 81.2500 (81.8625)  Acc@5: 100.0000 (96.7763)  time: 0.3770  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1560/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -1.3469  Acc@1: 81.2500 (81.8626)  Acc@5: 100.0000 (96.7609)  time: 0.3709  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1570/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6890  Acc@1: 81.2500 (81.8468)  Acc@5: 100.0000 (96.7736)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1580/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.8443  Acc@1: 81.2500 (81.8627)  Acc@5: 100.0000 (96.7861)  time: 0.3531  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1590/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.7339  Acc@1: 87.5000 (81.8785)  Acc@5: 100.0000 (96.7866)  time: 0.3478  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1600/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -1.1039  Acc@1: 87.5000 (81.8980)  Acc@5: 100.0000 (96.7872)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1610/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.9357  Acc@1: 81.2500 (81.8785)  Acc@5: 100.0000 (96.7838)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1620/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.9579  Acc@1: 81.2500 (81.9016)  Acc@5: 100.0000 (96.7921)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1630/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -1.1033  Acc@1: 81.2500 (81.9129)  Acc@5: 100.0000 (96.7926)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1640/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.4445  Acc@1: 81.2500 (81.9165)  Acc@5: 100.0000 (96.7893)  time: 0.3551  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1650/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -1.2730  Acc@1: 81.2500 (81.9314)  Acc@5: 100.0000 (96.8050)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1660/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.9464  Acc@1: 87.5000 (81.9348)  Acc@5: 100.0000 (96.8016)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1670/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.5898  Acc@1: 81.2500 (81.9195)  Acc@5: 93.7500 (96.7834)  time: 0.3567  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1680/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -1.1204  Acc@1: 81.2500 (81.9304)  Acc@5: 93.7500 (96.7839)  time: 0.3576  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1690/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.7515  Acc@1: 81.2500 (81.8931)  Acc@5: 100.0000 (96.8029)  time: 0.3551  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [1700/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -1.2821  Acc@1: 81.2500 (81.9187)  Acc@5: 100.0000 (96.8144)  time: 0.3538  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1710/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.6851  Acc@1: 81.2500 (81.9039)  Acc@5: 100.0000 (96.8220)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1720/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.7930  Acc@1: 81.2500 (81.8928)  Acc@5: 100.0000 (96.8332)  time: 0.3613  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1730/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.8357  Acc@1: 81.2500 (81.9180)  Acc@5: 100.0000 (96.8335)  time: 0.3651  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1740/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.7340  Acc@1: 81.2500 (81.8962)  Acc@5: 93.7500 (96.8086)  time: 0.3543  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1750/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.8703  Acc@1: 81.2500 (81.8925)  Acc@5: 93.7500 (96.7983)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1760/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -1.0385  Acc@1: 87.5000 (81.9101)  Acc@5: 93.7500 (96.7916)  time: 0.3688  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1770/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -1.3388  Acc@1: 87.5000 (81.9382)  Acc@5: 100.0000 (96.8027)  time: 0.3698  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1780/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.8609  Acc@1: 81.2500 (81.9448)  Acc@5: 100.0000 (96.8031)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1790/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -1.1781  Acc@1: 81.2500 (81.9375)  Acc@5: 93.7500 (96.8035)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1800/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.8402  Acc@1: 75.0000 (81.8920)  Acc@5: 93.7500 (96.7865)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1810/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.4615  Acc@1: 75.0000 (81.8919)  Acc@5: 93.7500 (96.7835)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1820/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.7918  Acc@1: 81.2500 (81.8987)  Acc@5: 100.0000 (96.7875)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1830/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.8277  Acc@1: 87.5000 (81.9259)  Acc@5: 100.0000 (96.7880)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1840/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.9866  Acc@1: 81.2500 (81.9188)  Acc@5: 93.7500 (96.7715)  time: 0.3518  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1850/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.4609  Acc@1: 81.2500 (81.8949)  Acc@5: 93.7500 (96.7619)  time: 0.3510  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1860/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -1.1192  Acc@1: 81.2500 (81.8881)  Acc@5: 93.7500 (96.7659)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1870/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -1.1420  Acc@1: 81.2500 (81.9047)  Acc@5: 93.7500 (96.7598)  time: 0.3552  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1880/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.8980  Acc@1: 81.2500 (81.8846)  Acc@5: 100.0000 (96.7703)  time: 0.3554  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1890/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -1.0582  Acc@1: 81.2500 (81.8879)  Acc@5: 100.0000 (96.7742)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1900/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.9993  Acc@1: 81.2500 (81.8977)  Acc@5: 93.7500 (96.7649)  time: 0.3546  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1910/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.9500  Acc@1: 75.0000 (81.8714)  Acc@5: 93.7500 (96.7654)  time: 0.3535  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1920/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -1.0058  Acc@1: 81.2500 (81.8844)  Acc@5: 93.7500 (96.7562)  time: 0.3530  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1930/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.4854  Acc@1: 81.2500 (81.8811)  Acc@5: 100.0000 (96.7666)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1940/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.9212  Acc@1: 75.0000 (81.8521)  Acc@5: 100.0000 (96.7768)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1950/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.9390  Acc@1: 81.2500 (81.8587)  Acc@5: 100.0000 (96.7869)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1960/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.7843  Acc@1: 81.2500 (81.8715)  Acc@5: 100.0000 (96.7905)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1970/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.7484  Acc@1: 81.2500 (81.8715)  Acc@5: 100.0000 (96.7910)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1980/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -1.2534  Acc@1: 87.5000 (81.8936)  Acc@5: 100.0000 (96.7977)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1990/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.6408  Acc@1: 87.5000 (81.9155)  Acc@5: 100.0000 (96.8012)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2000/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -1.1430  Acc@1: 81.2500 (81.8997)  Acc@5: 100.0000 (96.8016)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2010/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.7032  Acc@1: 81.2500 (81.9058)  Acc@5: 100.0000 (96.8082)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2020/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -1.0732  Acc@1: 81.2500 (81.9180)  Acc@5: 100.0000 (96.8147)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2030/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -1.0259  Acc@1: 81.2500 (81.9332)  Acc@5: 100.0000 (96.8181)  time: 0.3595  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2040/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -0.9004  Acc@1: 81.2500 (81.9145)  Acc@5: 100.0000 (96.8214)  time: 0.3621  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2050/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.8626  Acc@1: 81.2500 (81.9143)  Acc@5: 93.7500 (96.8156)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2060/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -1.2286  Acc@1: 81.2500 (81.8990)  Acc@5: 93.7500 (96.8128)  time: 0.3548  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2070/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -1.0943  Acc@1: 81.2500 (81.8898)  Acc@5: 93.7500 (96.8101)  time: 0.4693  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2080/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -1.1904  Acc@1: 81.2500 (81.8927)  Acc@5: 100.0000 (96.8134)  time: 0.6684  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2090/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.5975  Acc@1: 81.2500 (81.8896)  Acc@5: 100.0000 (96.8197)  time: 0.7266  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2100/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.4120  Acc@1: 81.2500 (81.8955)  Acc@5: 100.0000 (96.8200)  time: 0.5254  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2110/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -1.1366  Acc@1: 87.5000 (81.9221)  Acc@5: 100.0000 (96.8291)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2120/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -1.1512  Acc@1: 87.5000 (81.9042)  Acc@5: 100.0000 (96.8323)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2130/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.9604  Acc@1: 81.2500 (81.8894)  Acc@5: 100.0000 (96.8295)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2140/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -1.3014  Acc@1: 81.2500 (81.9039)  Acc@5: 93.7500 (96.8268)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2150/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -1.0921  Acc@1: 81.2500 (81.8892)  Acc@5: 100.0000 (96.8300)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2160/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.8748  Acc@1: 75.0000 (81.8689)  Acc@5: 100.0000 (96.8360)  time: 0.3516  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2170/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.9013  Acc@1: 81.2500 (81.8718)  Acc@5: 100.0000 (96.8448)  time: 0.3502  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2180/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.6094  Acc@1: 81.2500 (81.8862)  Acc@5: 100.0000 (96.8535)  time: 0.3545  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2190/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -1.2100  Acc@1: 87.5000 (81.8918)  Acc@5: 100.0000 (96.8593)  time: 0.3607  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2200/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -1.0232  Acc@1: 81.2500 (81.8747)  Acc@5: 100.0000 (96.8537)  time: 0.3550  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2210/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.7210  Acc@1: 81.2500 (81.8860)  Acc@5: 100.0000 (96.8510)  time: 0.3539  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2220/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.5422  Acc@1: 87.5000 (81.8916)  Acc@5: 100.0000 (96.8426)  time: 0.4901  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2230/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -1.2907  Acc@1: 87.5000 (81.9111)  Acc@5: 100.0000 (96.8428)  time: 0.4879  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2240/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -1.4018  Acc@1: 81.2500 (81.8970)  Acc@5: 100.0000 (96.8401)  time: 0.3556  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2250/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -1.3036  Acc@1: 81.2500 (81.8997)  Acc@5: 100.0000 (96.8458)  time: 0.3541  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2260/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -1.1865  Acc@1: 81.2500 (81.9024)  Acc@5: 100.0000 (96.8487)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2270/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.7657  Acc@1: 81.2500 (81.8692)  Acc@5: 100.0000 (96.8434)  time: 0.3553  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2280/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.8443  Acc@1: 81.2500 (81.8857)  Acc@5: 100.0000 (96.8462)  time: 0.3547  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2290/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -0.8281  Acc@1: 81.2500 (81.8638)  Acc@5: 100.0000 (96.8436)  time: 0.3568  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2300/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.9965  Acc@1: 75.0000 (81.8530)  Acc@5: 100.0000 (96.8383)  time: 0.3551  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2310/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -1.0472  Acc@1: 81.2500 (81.8369)  Acc@5: 100.0000 (96.8385)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2320/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -1.1404  Acc@1: 81.2500 (81.8505)  Acc@5: 100.0000 (96.8333)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2330/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.6859  Acc@1: 81.2500 (81.8345)  Acc@5: 100.0000 (96.8388)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2340/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -1.1111  Acc@1: 81.2500 (81.8320)  Acc@5: 100.0000 (96.8416)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2350/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.7094  Acc@1: 81.2500 (81.8295)  Acc@5: 100.0000 (96.8497)  time: 0.3606  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2360/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.6719  Acc@1: 81.2500 (81.8297)  Acc@5: 100.0000 (96.8525)  time: 0.3607  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2370/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -1.2796  Acc@1: 87.5000 (81.8457)  Acc@5: 100.0000 (96.8605)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2380/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -1.1919  Acc@1: 87.5000 (81.8616)  Acc@5: 100.0000 (96.8579)  time: 0.3653  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2390/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -0.6713  Acc@1: 81.2500 (81.8643)  Acc@5: 100.0000 (96.8606)  time: 0.3662  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2400/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -1.0971  Acc@1: 81.2500 (81.8617)  Acc@5: 100.0000 (96.8633)  time: 0.3497  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2410/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -1.1170  Acc@1: 81.2500 (81.8384)  Acc@5: 93.7500 (96.8504)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2420/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -1.2139  Acc@1: 81.2500 (81.8438)  Acc@5: 93.7500 (96.8531)  time: 0.3523  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2430/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.7034  Acc@1: 81.2500 (81.8413)  Acc@5: 100.0000 (96.8506)  time: 0.3527  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2440/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -1.0669  Acc@1: 81.2500 (81.8466)  Acc@5: 100.0000 (96.8532)  time: 0.3551  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2450/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.9971  Acc@1: 81.2500 (81.8416)  Acc@5: 100.0000 (96.8482)  time: 0.3550  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2460/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -1.0433  Acc@1: 81.2500 (81.8620)  Acc@5: 93.7500 (96.8483)  time: 0.3529  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2470/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -1.2660  Acc@1: 87.5000 (81.8849)  Acc@5: 100.0000 (96.8560)  time: 0.3527  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2480/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -1.3620  Acc@1: 87.5000 (81.8999)  Acc@5: 100.0000 (96.8611)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2490/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.9810  Acc@1: 87.5000 (81.9023)  Acc@5: 100.0000 (96.8587)  time: 0.3584  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2500/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.9464  Acc@1: 81.2500 (81.8997)  Acc@5: 100.0000 (96.8638)  time: 0.3664  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2510/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -1.3902  Acc@1: 81.2500 (81.9096)  Acc@5: 100.0000 (96.8663)  time: 0.3625  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2520/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.9263  Acc@1: 81.2500 (81.8946)  Acc@5: 100.0000 (96.8713)  time: 0.3549  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2530/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.9893  Acc@1: 81.2500 (81.8945)  Acc@5: 100.0000 (96.8738)  time: 0.3856  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2540/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -1.2043  Acc@1: 81.2500 (81.8920)  Acc@5: 100.0000 (96.8713)  time: 0.5681  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2550/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.6942  Acc@1: 81.2500 (81.9017)  Acc@5: 100.0000 (96.8689)  time: 0.7148  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2560/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.6861  Acc@1: 81.2500 (81.8723)  Acc@5: 100.0000 (96.8738)  time: 0.5321  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2570/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -1.1302  Acc@1: 75.0000 (81.8675)  Acc@5: 100.0000 (96.8738)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2580/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.9166  Acc@1: 81.2500 (81.8748)  Acc@5: 100.0000 (96.8762)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2590/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -1.0501  Acc@1: 81.2500 (81.8675)  Acc@5: 100.0000 (96.8738)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2600/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.7762  Acc@1: 81.2500 (81.8724)  Acc@5: 100.0000 (96.8810)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2610/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.8767  Acc@1: 81.2500 (81.8700)  Acc@5: 100.0000 (96.8786)  time: 0.3564  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2620/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.9356  Acc@1: 75.0000 (81.8128)  Acc@5: 93.7500 (96.8667)  time: 0.3548  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2630/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -1.4412  Acc@1: 75.0000 (81.8106)  Acc@5: 93.7500 (96.8572)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2640/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.7463  Acc@1: 81.2500 (81.8180)  Acc@5: 93.7500 (96.8525)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2650/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.7679  Acc@1: 81.2500 (81.8323)  Acc@5: 93.7500 (96.8550)  time: 0.3551  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [2660/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -1.2007  Acc@1: 87.5000 (81.8489)  Acc@5: 100.0000 (96.8597)  time: 0.3540  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2670/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -1.0458  Acc@1: 87.5000 (81.8467)  Acc@5: 100.0000 (96.8668)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2680/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.8650  Acc@1: 87.5000 (81.8515)  Acc@5: 100.0000 (96.8692)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2690/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.8927  Acc@1: 81.2500 (81.8632)  Acc@5: 100.0000 (96.8715)  time: 0.3568  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2700/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -1.1754  Acc@1: 87.5000 (81.8887)  Acc@5: 100.0000 (96.8738)  time: 0.3547  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2710/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6131  Acc@1: 87.5000 (81.9140)  Acc@5: 100.0000 (96.8715)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2720/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.7074  Acc@1: 87.5000 (81.8954)  Acc@5: 100.0000 (96.8647)  time: 0.3537  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2730/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -1.1376  Acc@1: 75.0000 (81.8725)  Acc@5: 93.7500 (96.8601)  time: 0.3596  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2740/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.9523  Acc@1: 81.2500 (81.8771)  Acc@5: 93.7500 (96.8647)  time: 0.3552  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2750/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -1.2407  Acc@1: 81.2500 (81.8521)  Acc@5: 100.0000 (96.8648)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2760/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -1.0634  Acc@1: 75.0000 (81.8589)  Acc@5: 100.0000 (96.8671)  time: 0.4020  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2770/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -1.0838  Acc@1: 81.2500 (81.8590)  Acc@5: 100.0000 (96.8649)  time: 0.4572  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2780/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -1.2012  Acc@1: 81.2500 (81.8770)  Acc@5: 100.0000 (96.8716)  time: 0.4022  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2790/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -1.3519  Acc@1: 81.2500 (81.8815)  Acc@5: 100.0000 (96.8716)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2800/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -1.3164  Acc@1: 87.5000 (81.9038)  Acc@5: 100.0000 (96.8806)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2810/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.4152  Acc@1: 87.5000 (81.8948)  Acc@5: 100.0000 (96.8783)  time: 0.3537  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2820/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.5750  Acc@1: 81.2500 (81.8881)  Acc@5: 100.0000 (96.8805)  time: 0.3548  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2830/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.7706  Acc@1: 87.5000 (81.8991)  Acc@5: 100.0000 (96.8739)  time: 0.3566  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2840/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.1592  Acc@1: 87.5000 (81.9034)  Acc@5: 93.7500 (96.8739)  time: 0.3612  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2850/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.9173  Acc@1: 81.2500 (81.9077)  Acc@5: 100.0000 (96.8695)  time: 0.3590  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2860/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.9203  Acc@1: 81.2500 (81.9185)  Acc@5: 93.7500 (96.8630)  time: 0.3574  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2870/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.9951  Acc@1: 81.2500 (81.9118)  Acc@5: 100.0000 (96.8652)  time: 0.3613  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2880/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.4333  Acc@1: 81.2500 (81.9160)  Acc@5: 100.0000 (96.8587)  time: 0.3581  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2890/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.9005  Acc@1: 81.2500 (81.9288)  Acc@5: 100.0000 (96.8653)  time: 0.3519  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2900/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.7903  Acc@1: 81.2500 (81.9093)  Acc@5: 93.7500 (96.8502)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2910/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -1.4173  Acc@1: 75.0000 (81.8941)  Acc@5: 93.7500 (96.8546)  time: 0.4954  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2920/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.8710  Acc@1: 75.0000 (81.8748)  Acc@5: 100.0000 (96.8483)  time: 0.6983  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2930/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -1.4697  Acc@1: 75.0000 (81.8748)  Acc@5: 100.0000 (96.8547)  time: 0.7567  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2940/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -1.2588  Acc@1: 81.2500 (81.8790)  Acc@5: 100.0000 (96.8633)  time: 0.7527  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2950/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -1.2356  Acc@1: 81.2500 (81.8790)  Acc@5: 100.0000 (96.8697)  time: 0.7530  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2960/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.8422  Acc@1: 81.2500 (81.8727)  Acc@5: 100.0000 (96.8718)  time: 0.7521  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2970/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -1.0245  Acc@1: 75.0000 (81.8643)  Acc@5: 93.7500 (96.8676)  time: 0.6971  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2980/3750]  eta: 0:05:29  Lr: 0.001875  Loss: -0.9788  Acc@1: 75.0000 (81.8559)  Acc@5: 100.0000 (96.8698)  time: 0.4976  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2990/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.9567  Acc@1: 81.2500 (81.8581)  Acc@5: 100.0000 (96.8760)  time: 0.3523  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3000/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.4000  Acc@1: 81.2500 (81.8498)  Acc@5: 100.0000 (96.8740)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3010/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.3954  Acc@1: 81.2500 (81.8520)  Acc@5: 100.0000 (96.8719)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3020/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.9152  Acc@1: 87.5000 (81.8624)  Acc@5: 100.0000 (96.8698)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3030/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.9393  Acc@1: 81.2500 (81.8604)  Acc@5: 100.0000 (96.8760)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3040/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.8217  Acc@1: 81.2500 (81.8727)  Acc@5: 100.0000 (96.8781)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5203  Acc@1: 81.2500 (81.8686)  Acc@5: 100.0000 (96.8863)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.8099  Acc@1: 87.5000 (81.8891)  Acc@5: 100.0000 (96.8883)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3070/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.9536  Acc@1: 87.5000 (81.8992)  Acc@5: 100.0000 (96.8882)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3080/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.8441  Acc@1: 87.5000 (81.9174)  Acc@5: 100.0000 (96.8943)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3090/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.9077  Acc@1: 87.5000 (81.9173)  Acc@5: 100.0000 (96.8942)  time: 0.3592  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3100/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -1.2452  Acc@1: 87.5000 (81.9393)  Acc@5: 100.0000 (96.9002)  time: 0.3584  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3110/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.3505  Acc@1: 87.5000 (81.9532)  Acc@5: 100.0000 (96.9041)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3120/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.9935  Acc@1: 87.5000 (81.9489)  Acc@5: 100.0000 (96.8960)  time: 0.4510  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3130/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.8208  Acc@1: 81.2500 (81.9467)  Acc@5: 93.7500 (96.8980)  time: 0.6079  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3140/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.8801  Acc@1: 81.2500 (81.9365)  Acc@5: 93.7500 (96.8899)  time: 0.5159  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3150/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.6551  Acc@1: 81.2500 (81.9462)  Acc@5: 100.0000 (96.8899)  time: 0.3584  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3160/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -1.1985  Acc@1: 81.2500 (81.9460)  Acc@5: 100.0000 (96.8918)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3170/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5528  Acc@1: 81.2500 (81.9339)  Acc@5: 100.0000 (96.8918)  time: 0.3545  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3180/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -1.0177  Acc@1: 81.2500 (81.9455)  Acc@5: 100.0000 (96.8917)  time: 0.3599  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -1.0864  Acc@1: 87.5000 (81.9571)  Acc@5: 100.0000 (96.8956)  time: 0.3568  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.8688  Acc@1: 81.2500 (81.9666)  Acc@5: 100.0000 (96.8916)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -1.0495  Acc@1: 87.5000 (81.9760)  Acc@5: 100.0000 (96.8915)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.8212  Acc@1: 87.5000 (81.9776)  Acc@5: 100.0000 (96.8857)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.8564  Acc@1: 81.2500 (81.9851)  Acc@5: 100.0000 (96.8934)  time: 0.3617  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3240/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -1.0630  Acc@1: 81.2500 (81.9732)  Acc@5: 100.0000 (96.8914)  time: 0.3613  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3250/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.9843  Acc@1: 81.2500 (81.9748)  Acc@5: 100.0000 (96.8952)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3260/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.8838  Acc@1: 81.2500 (81.9821)  Acc@5: 100.0000 (96.8932)  time: 0.4063  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3270/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.3505  Acc@1: 81.2500 (81.9761)  Acc@5: 93.7500 (96.8932)  time: 0.6080  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3280/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -1.1585  Acc@1: 81.2500 (81.9853)  Acc@5: 100.0000 (96.8988)  time: 0.7494  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3290/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.9032  Acc@1: 81.2500 (81.9850)  Acc@5: 100.0000 (96.8930)  time: 0.7448  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3300/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -1.4132  Acc@1: 81.2500 (81.9865)  Acc@5: 93.7500 (96.8911)  time: 0.7478  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3310/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -1.0695  Acc@1: 81.2500 (81.9900)  Acc@5: 100.0000 (96.8892)  time: 0.7517  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3320/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -1.0729  Acc@1: 81.2500 (82.0009)  Acc@5: 100.0000 (96.8948)  time: 0.7500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3330/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -1.2900  Acc@1: 81.2500 (82.0005)  Acc@5: 100.0000 (96.8891)  time: 0.7467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7080  Acc@1: 81.2500 (81.9871)  Acc@5: 100.0000 (96.8928)  time: 0.7462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -1.3838  Acc@1: 81.2500 (82.0054)  Acc@5: 100.0000 (96.8946)  time: 0.7475  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -1.2818  Acc@1: 87.5000 (82.0143)  Acc@5: 93.7500 (96.8889)  time: 0.7443  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.1972  Acc@1: 87.5000 (82.0157)  Acc@5: 100.0000 (96.8945)  time: 0.7433  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.9001  Acc@1: 81.2500 (82.0227)  Acc@5: 100.0000 (96.8926)  time: 0.7401  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -1.2280  Acc@1: 81.2500 (82.0167)  Acc@5: 100.0000 (96.8944)  time: 0.7379  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:32  Lr: 0.001875  Loss: -0.8280  Acc@1: 81.2500 (82.0310)  Acc@5: 100.0000 (96.8980)  time: 0.7437  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3410/3750]  eta: 0:02:28  Lr: 0.001875  Loss: -0.4950  Acc@1: 81.2500 (82.0196)  Acc@5: 100.0000 (96.8979)  time: 0.6508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3420/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -1.0352  Acc@1: 75.0000 (82.0027)  Acc@5: 93.7500 (96.8924)  time: 0.4587  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3430/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.8003  Acc@1: 81.2500 (81.9987)  Acc@5: 93.7500 (96.8923)  time: 0.3568  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3440/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -1.3106  Acc@1: 81.2500 (82.0038)  Acc@5: 100.0000 (96.8904)  time: 0.3492  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3450/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.6828  Acc@1: 81.2500 (82.0088)  Acc@5: 100.0000 (96.8940)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3460/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -1.0934  Acc@1: 87.5000 (82.0139)  Acc@5: 100.0000 (96.8885)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3470/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.9352  Acc@1: 87.5000 (82.0207)  Acc@5: 93.7500 (96.8867)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:57  Lr: 0.001875  Loss: -1.1087  Acc@1: 81.2500 (82.0185)  Acc@5: 93.7500 (96.8831)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:53  Lr: 0.001875  Loss: -0.8715  Acc@1: 81.2500 (82.0306)  Acc@5: 100.0000 (96.8902)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.2104  Acc@1: 81.2500 (82.0301)  Acc@5: 100.0000 (96.8920)  time: 0.3511  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8122  Acc@1: 81.2500 (82.0297)  Acc@5: 93.7500 (96.8830)  time: 0.3496  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:39  Lr: 0.001875  Loss: -1.0924  Acc@1: 81.2500 (82.0275)  Acc@5: 93.7500 (96.8848)  time: 0.3493  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -0.7903  Acc@1: 81.2500 (82.0412)  Acc@5: 100.0000 (96.8883)  time: 0.3592  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -1.2651  Acc@1: 81.2500 (82.0284)  Acc@5: 100.0000 (96.8865)  time: 0.3648  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.5159  Acc@1: 81.2500 (82.0315)  Acc@5: 100.0000 (96.8882)  time: 0.3570  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:22  Lr: 0.001875  Loss: -0.7152  Acc@1: 87.5000 (82.0345)  Acc@5: 100.0000 (96.8917)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -1.2339  Acc@1: 81.2500 (82.0376)  Acc@5: 100.0000 (96.8864)  time: 0.3597  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3580/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.0887  Acc@1: 81.2500 (82.0284)  Acc@5: 93.7500 (96.8829)  time: 0.5155  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3590/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.9001  Acc@1: 75.0000 (82.0193)  Acc@5: 100.0000 (96.8828)  time: 0.7015  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3600/3750]  eta: 0:01:05  Lr: 0.001875  Loss: -0.7474  Acc@1: 81.2500 (82.0154)  Acc@5: 100.0000 (96.8776)  time: 0.7383  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3610/3750]  eta: 0:01:01  Lr: 0.001875  Loss: -1.3480  Acc@1: 81.2500 (82.0237)  Acc@5: 93.7500 (96.8811)  time: 0.7409  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -1.1170  Acc@1: 87.5000 (82.0371)  Acc@5: 100.0000 (96.8862)  time: 0.7182  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8403  Acc@1: 87.5000 (82.0384)  Acc@5: 100.0000 (96.8862)  time: 0.5218  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.9932  Acc@1: 81.2500 (82.0293)  Acc@5: 93.7500 (96.8810)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5173  Acc@1: 75.0000 (82.0169)  Acc@5: 93.7500 (96.8776)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:39  Lr: 0.001875  Loss: -1.1555  Acc@1: 75.0000 (82.0046)  Acc@5: 93.7500 (96.8741)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.1915  Acc@1: 75.0000 (81.9974)  Acc@5: 100.0000 (96.8741)  time: 0.3499  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:30  Lr: 0.001875  Loss: -0.5156  Acc@1: 81.2500 (81.9971)  Acc@5: 100.0000 (96.8657)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6550  Acc@1: 81.2500 (81.9764)  Acc@5: 93.7500 (96.8589)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.5631  Acc@1: 81.2500 (81.9778)  Acc@5: 100.0000 (96.8606)  time: 0.3559  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0875  Acc@1: 81.2500 (81.9809)  Acc@5: 100.0000 (96.8573)  time: 0.3554  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.2178  Acc@1: 87.5000 (81.9840)  Acc@5: 100.0000 (96.8540)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:08  Lr: 0.001875  Loss: -0.9935  Acc@1: 87.5000 (82.0005)  Acc@5: 100.0000 (96.8608)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: -1.1886  Acc@1: 87.5000 (82.0018)  Acc@5: 100.0000 (96.8625)  time: 0.3550  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9439  Acc@1: 81.2500 (81.9933)  Acc@5: 93.7500 (96.8583)  time: 0.3567  data: 0.0037  max mem: 2500
Train: Epoch[4/5] Total time: 0:27:09 (0.4345 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.9439  Acc@1: 81.2500 (81.9933)  Acc@5: 93.7500 (96.8583)
Train: Epoch[5/5]  [   0/3750]  eta: 0:53:07  Lr: 0.001875  Loss: -0.9404  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.8500  data: 0.5017  max mem: 2500
Train: Epoch[5/5]  [  10/3750]  eta: 0:24:39  Lr: 0.001875  Loss: -0.6785  Acc@1: 75.0000 (76.7045)  Acc@5: 93.7500 (95.4545)  time: 0.3955  data: 0.0461  max mem: 2500
Train: Epoch[5/5]  [  20/3750]  eta: 0:23:22  Lr: 0.001875  Loss: -1.2591  Acc@1: 81.2500 (80.0595)  Acc@5: 93.7500 (95.8333)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:45  Lr: 0.001875  Loss: -1.1082  Acc@1: 87.5000 (81.0484)  Acc@5: 93.7500 (95.5645)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:26  Lr: 0.001875  Loss: -1.0653  Acc@1: 87.5000 (82.0122)  Acc@5: 100.0000 (96.3415)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  50/3750]  eta: 0:22:19  Lr: 0.001875  Loss: -0.6840  Acc@1: 81.2500 (81.6176)  Acc@5: 100.0000 (95.9559)  time: 0.3543  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  60/3750]  eta: 0:22:14  Lr: 0.001875  Loss: -1.2100  Acc@1: 81.2500 (81.5574)  Acc@5: 93.7500 (96.1066)  time: 0.3590  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  70/3750]  eta: 0:22:05  Lr: 0.001875  Loss: -1.1802  Acc@1: 87.5000 (82.3063)  Acc@5: 100.0000 (96.3908)  time: 0.3551  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -1.4149  Acc@1: 87.5000 (82.2531)  Acc@5: 100.0000 (96.5278)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  90/3750]  eta: 0:23:40  Lr: 0.001875  Loss: -0.6832  Acc@1: 81.2500 (82.3489)  Acc@5: 100.0000 (96.7033)  time: 0.4869  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 100/3750]  eta: 0:25:45  Lr: 0.001875  Loss: -1.2043  Acc@1: 81.2500 (82.6114)  Acc@5: 100.0000 (96.7203)  time: 0.6859  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 110/3750]  eta: 0:27:27  Lr: 0.001875  Loss: -0.7876  Acc@1: 81.2500 (82.1509)  Acc@5: 93.7500 (96.6216)  time: 0.7460  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 120/3750]  eta: 0:28:51  Lr: 0.001875  Loss: -1.1700  Acc@1: 81.2500 (82.2314)  Acc@5: 100.0000 (96.7975)  time: 0.7474  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 130/3750]  eta: 0:30:02  Lr: 0.001875  Loss: -0.9113  Acc@1: 81.2500 (82.2996)  Acc@5: 100.0000 (96.7557)  time: 0.7496  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 140/3750]  eta: 0:31:00  Lr: 0.001875  Loss: -1.4895  Acc@1: 87.5000 (82.6684)  Acc@5: 100.0000 (96.7199)  time: 0.7468  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 150/3750]  eta: 0:31:48  Lr: 0.001875  Loss: -1.2323  Acc@1: 87.5000 (82.5745)  Acc@5: 100.0000 (96.7301)  time: 0.7418  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 160/3750]  eta: 0:32:31  Lr: 0.001875  Loss: -1.5219  Acc@1: 81.2500 (82.6087)  Acc@5: 100.0000 (96.8168)  time: 0.7434  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 170/3750]  eta: 0:33:08  Lr: 0.001875  Loss: -1.0229  Acc@1: 81.2500 (82.4196)  Acc@5: 100.0000 (96.8933)  time: 0.7454  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 180/3750]  eta: 0:33:39  Lr: 0.001875  Loss: -1.1141  Acc@1: 81.2500 (82.4586)  Acc@5: 100.0000 (96.9268)  time: 0.7430  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 190/3750]  eta: 0:34:07  Lr: 0.001875  Loss: -1.1696  Acc@1: 87.5000 (82.4280)  Acc@5: 100.0000 (96.9895)  time: 0.7439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 200/3750]  eta: 0:34:31  Lr: 0.001875  Loss: -0.8215  Acc@1: 81.2500 (82.3072)  Acc@5: 100.0000 (97.0149)  time: 0.7459  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 210/3750]  eta: 0:34:52  Lr: 0.001875  Loss: -0.8536  Acc@1: 81.2500 (82.2275)  Acc@5: 100.0000 (96.9787)  time: 0.7445  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 220/3750]  eta: 0:35:10  Lr: 0.001875  Loss: -0.8255  Acc@1: 81.2500 (82.1267)  Acc@5: 93.7500 (96.7477)  time: 0.7423  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 230/3750]  eta: 0:35:27  Lr: 0.001875  Loss: -1.2136  Acc@1: 81.2500 (82.0076)  Acc@5: 93.7500 (96.7803)  time: 0.7431  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 240/3750]  eta: 0:35:40  Lr: 0.001875  Loss: -0.7930  Acc@1: 81.2500 (81.9243)  Acc@5: 100.0000 (96.7583)  time: 0.7399  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 250/3750]  eta: 0:35:51  Lr: 0.001875  Loss: -0.8051  Acc@1: 81.2500 (82.0219)  Acc@5: 100.0000 (96.8127)  time: 0.7346  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 260/3750]  eta: 0:36:01  Lr: 0.001875  Loss: -1.2031  Acc@1: 81.2500 (81.9923)  Acc@5: 100.0000 (96.8870)  time: 0.7364  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 270/3750]  eta: 0:36:10  Lr: 0.001875  Loss: -0.8670  Acc@1: 87.5000 (82.1264)  Acc@5: 100.0000 (96.9096)  time: 0.7379  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 280/3750]  eta: 0:36:18  Lr: 0.001875  Loss: -0.6682  Acc@1: 81.2500 (82.0952)  Acc@5: 100.0000 (96.9306)  time: 0.7351  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 290/3750]  eta: 0:36:00  Lr: 0.001875  Loss: -0.9051  Acc@1: 81.2500 (82.0662)  Acc@5: 100.0000 (96.9287)  time: 0.6337  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 300/3750]  eta: 0:35:22  Lr: 0.001875  Loss: -0.7039  Acc@1: 81.2500 (82.0598)  Acc@5: 93.7500 (96.8439)  time: 0.4404  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 310/3750]  eta: 0:34:46  Lr: 0.001875  Loss: -1.2573  Acc@1: 81.2500 (82.0338)  Acc@5: 93.7500 (96.7846)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 320/3750]  eta: 0:34:13  Lr: 0.001875  Loss: -1.1733  Acc@1: 81.2500 (82.0093)  Acc@5: 100.0000 (96.8069)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 330/3750]  eta: 0:33:41  Lr: 0.001875  Loss: -0.7710  Acc@1: 87.5000 (82.0242)  Acc@5: 100.0000 (96.8089)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 340/3750]  eta: 0:33:11  Lr: 0.001875  Loss: -1.1022  Acc@1: 81.2500 (81.9465)  Acc@5: 100.0000 (96.8475)  time: 0.3508  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 350/3750]  eta: 0:32:44  Lr: 0.001875  Loss: -0.8995  Acc@1: 81.2500 (81.9088)  Acc@5: 100.0000 (96.8305)  time: 0.3554  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 360/3750]  eta: 0:32:18  Lr: 0.001875  Loss: -1.0225  Acc@1: 81.2500 (81.9079)  Acc@5: 93.7500 (96.7971)  time: 0.3601  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 370/3750]  eta: 0:31:52  Lr: 0.001875  Loss: -0.5261  Acc@1: 81.2500 (81.8733)  Acc@5: 100.0000 (96.8329)  time: 0.3568  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 380/3750]  eta: 0:31:27  Lr: 0.001875  Loss: -0.7088  Acc@1: 81.2500 (81.8570)  Acc@5: 100.0000 (96.8176)  time: 0.3526  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 390/3750]  eta: 0:31:04  Lr: 0.001875  Loss: -0.3764  Acc@1: 81.2500 (81.7775)  Acc@5: 100.0000 (96.8191)  time: 0.3528  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 400/3750]  eta: 0:30:43  Lr: 0.001875  Loss: -1.2072  Acc@1: 81.2500 (81.8267)  Acc@5: 100.0000 (96.8204)  time: 0.3641  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 410/3750]  eta: 0:30:22  Lr: 0.001875  Loss: -1.1097  Acc@1: 87.5000 (81.9495)  Acc@5: 100.0000 (96.8522)  time: 0.3640  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 420/3750]  eta: 0:30:01  Lr: 0.001875  Loss: -0.8820  Acc@1: 81.2500 (81.9774)  Acc@5: 100.0000 (96.8973)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 430/3750]  eta: 0:29:41  Lr: 0.001875  Loss: -0.7738  Acc@1: 81.2500 (82.0041)  Acc@5: 100.0000 (96.8968)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 440/3750]  eta: 0:29:21  Lr: 0.001875  Loss: -1.0882  Acc@1: 81.2500 (81.9303)  Acc@5: 100.0000 (96.8537)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 450/3750]  eta: 0:29:03  Lr: 0.001875  Loss: -1.0005  Acc@1: 81.2500 (81.9290)  Acc@5: 93.7500 (96.8126)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 460/3750]  eta: 0:28:45  Lr: 0.001875  Loss: -0.9859  Acc@1: 81.2500 (81.9550)  Acc@5: 93.7500 (96.8411)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 470/3750]  eta: 0:28:27  Lr: 0.001875  Loss: -0.7097  Acc@1: 81.2500 (81.9400)  Acc@5: 100.0000 (96.8020)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 480/3750]  eta: 0:28:10  Lr: 0.001875  Loss: -1.1379  Acc@1: 81.2500 (82.0426)  Acc@5: 100.0000 (96.8425)  time: 0.3490  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 490/3750]  eta: 0:27:54  Lr: 0.001875  Loss: -0.4899  Acc@1: 87.5000 (82.0901)  Acc@5: 100.0000 (96.8814)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 500/3750]  eta: 0:27:38  Lr: 0.001875  Loss: -0.6733  Acc@1: 81.2500 (81.9486)  Acc@5: 100.0000 (96.9062)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 510/3750]  eta: 0:27:24  Lr: 0.001875  Loss: -0.9093  Acc@1: 81.2500 (81.9839)  Acc@5: 100.0000 (96.9300)  time: 0.3534  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 520/3750]  eta: 0:27:10  Lr: 0.001875  Loss: -1.5507  Acc@1: 87.5000 (82.0657)  Acc@5: 100.0000 (96.9050)  time: 0.3603  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 530/3750]  eta: 0:26:55  Lr: 0.001875  Loss: -0.7268  Acc@1: 81.2500 (82.1210)  Acc@5: 100.0000 (96.9397)  time: 0.3573  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 540/3750]  eta: 0:26:42  Lr: 0.001875  Loss: -1.3217  Acc@1: 81.2500 (82.0933)  Acc@5: 100.0000 (96.9501)  time: 0.3592  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 550/3750]  eta: 0:26:51  Lr: 0.001875  Loss: -0.7977  Acc@1: 81.2500 (82.0213)  Acc@5: 93.7500 (96.8580)  time: 0.5522  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 560/3750]  eta: 0:27:00  Lr: 0.001875  Loss: -1.3624  Acc@1: 81.2500 (81.9742)  Acc@5: 93.7500 (96.8694)  time: 0.7420  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 570/3750]  eta: 0:27:08  Lr: 0.001875  Loss: -0.5673  Acc@1: 81.2500 (81.8630)  Acc@5: 100.0000 (96.8805)  time: 0.7459  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 580/3750]  eta: 0:27:11  Lr: 0.001875  Loss: -0.8961  Acc@1: 75.0000 (81.8094)  Acc@5: 100.0000 (96.8911)  time: 0.6987  data: 0.0035  max mem: 2500
Train: Epoch[5/5]  [ 590/3750]  eta: 0:26:57  Lr: 0.001875  Loss: -0.7119  Acc@1: 81.2500 (81.8528)  Acc@5: 100.0000 (96.8697)  time: 0.5012  data: 0.0034  max mem: 2500
Train: Epoch[5/5]  [ 600/3750]  eta: 0:26:43  Lr: 0.001875  Loss: -0.9568  Acc@1: 81.2500 (81.7804)  Acc@5: 100.0000 (96.8906)  time: 0.3524  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 610/3750]  eta: 0:26:30  Lr: 0.001875  Loss: -0.6409  Acc@1: 81.2500 (81.8433)  Acc@5: 100.0000 (96.9210)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 620/3750]  eta: 0:26:17  Lr: 0.001875  Loss: -1.1287  Acc@1: 87.5000 (81.8841)  Acc@5: 100.0000 (96.9404)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 630/3750]  eta: 0:26:05  Lr: 0.001875  Loss: -0.9070  Acc@1: 81.2500 (81.8542)  Acc@5: 93.7500 (96.8899)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 640/3750]  eta: 0:25:52  Lr: 0.001875  Loss: -1.1804  Acc@1: 81.2500 (81.9033)  Acc@5: 93.7500 (96.9091)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 650/3750]  eta: 0:25:40  Lr: 0.001875  Loss: -0.7035  Acc@1: 81.2500 (81.8932)  Acc@5: 100.0000 (96.9182)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 660/3750]  eta: 0:25:28  Lr: 0.001875  Loss: -1.0740  Acc@1: 81.2500 (81.9592)  Acc@5: 100.0000 (96.9175)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 670/3750]  eta: 0:25:17  Lr: 0.001875  Loss: -1.3311  Acc@1: 81.2500 (81.9858)  Acc@5: 100.0000 (96.9169)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 680/3750]  eta: 0:25:05  Lr: 0.001875  Loss: -1.0950  Acc@1: 81.2500 (81.9383)  Acc@5: 93.7500 (96.8888)  time: 0.3521  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 690/3750]  eta: 0:24:54  Lr: 0.001875  Loss: -1.0776  Acc@1: 81.2500 (81.9465)  Acc@5: 93.7500 (96.8976)  time: 0.3537  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 700/3750]  eta: 0:24:44  Lr: 0.001875  Loss: -1.0415  Acc@1: 81.2500 (81.8741)  Acc@5: 93.7500 (96.8616)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 710/3750]  eta: 0:24:33  Lr: 0.001875  Loss: -0.6926  Acc@1: 81.2500 (81.8565)  Acc@5: 93.7500 (96.8530)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 720/3750]  eta: 0:24:23  Lr: 0.001875  Loss: -1.1821  Acc@1: 87.5000 (81.9261)  Acc@5: 100.0000 (96.8707)  time: 0.3572  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 730/3750]  eta: 0:24:13  Lr: 0.001875  Loss: -1.2775  Acc@1: 87.5000 (81.9425)  Acc@5: 100.0000 (96.8536)  time: 0.3569  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 740/3750]  eta: 0:24:03  Lr: 0.001875  Loss: -0.7946  Acc@1: 87.5000 (81.9501)  Acc@5: 100.0000 (96.8708)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 750/3750]  eta: 0:23:53  Lr: 0.001875  Loss: -0.8130  Acc@1: 81.2500 (81.9324)  Acc@5: 100.0000 (96.9041)  time: 0.3525  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 760/3750]  eta: 0:23:43  Lr: 0.001875  Loss: -0.8706  Acc@1: 81.2500 (81.9727)  Acc@5: 100.0000 (96.9284)  time: 0.3576  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [ 770/3750]  eta: 0:23:34  Lr: 0.001875  Loss: -1.2726  Acc@1: 81.2500 (81.9958)  Acc@5: 100.0000 (96.9115)  time: 0.3613  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 780/3750]  eta: 0:23:25  Lr: 0.001875  Loss: -0.7427  Acc@1: 81.2500 (81.9702)  Acc@5: 93.7500 (96.9030)  time: 0.3647  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 790/3750]  eta: 0:23:16  Lr: 0.001875  Loss: -0.7533  Acc@1: 81.2500 (82.0085)  Acc@5: 100.0000 (96.9185)  time: 0.3597  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 800/3750]  eta: 0:23:07  Lr: 0.001875  Loss: -1.2308  Acc@1: 81.2500 (81.9913)  Acc@5: 100.0000 (96.9257)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 810/3750]  eta: 0:22:59  Lr: 0.001875  Loss: -0.6009  Acc@1: 81.2500 (81.9744)  Acc@5: 100.0000 (96.9251)  time: 0.3597  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 820/3750]  eta: 0:23:03  Lr: 0.001875  Loss: -0.8917  Acc@1: 81.2500 (81.9656)  Acc@5: 100.0000 (96.9321)  time: 0.5444  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 830/3750]  eta: 0:23:08  Lr: 0.001875  Loss: -0.8569  Acc@1: 87.5000 (82.0096)  Acc@5: 100.0000 (96.9389)  time: 0.7307  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 840/3750]  eta: 0:23:12  Lr: 0.001875  Loss: -1.2429  Acc@1: 87.5000 (82.0452)  Acc@5: 100.0000 (96.9307)  time: 0.7423  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 850/3750]  eta: 0:23:15  Lr: 0.001875  Loss: -1.3767  Acc@1: 81.2500 (82.0358)  Acc@5: 100.0000 (96.9301)  time: 0.7263  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 860/3750]  eta: 0:23:06  Lr: 0.001875  Loss: -0.9194  Acc@1: 81.2500 (82.0920)  Acc@5: 100.0000 (96.9440)  time: 0.5310  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 870/3750]  eta: 0:22:57  Lr: 0.001875  Loss: -1.2887  Acc@1: 87.5000 (82.1541)  Acc@5: 100.0000 (96.9432)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 880/3750]  eta: 0:22:48  Lr: 0.001875  Loss: -0.8185  Acc@1: 81.2500 (82.1297)  Acc@5: 93.7500 (96.9211)  time: 0.3540  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 890/3750]  eta: 0:22:39  Lr: 0.001875  Loss: -0.8337  Acc@1: 81.2500 (82.1338)  Acc@5: 93.7500 (96.8925)  time: 0.3514  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 900/3750]  eta: 0:22:31  Lr: 0.001875  Loss: -1.0407  Acc@1: 81.2500 (82.1240)  Acc@5: 93.7500 (96.8715)  time: 0.3533  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 910/3750]  eta: 0:22:22  Lr: 0.001875  Loss: -0.4354  Acc@1: 81.2500 (82.1213)  Acc@5: 93.7500 (96.8373)  time: 0.3569  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [ 920/3750]  eta: 0:22:14  Lr: 0.001875  Loss: -1.3117  Acc@1: 81.2500 (82.1050)  Acc@5: 100.0000 (96.8445)  time: 0.3557  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 930/3750]  eta: 0:22:06  Lr: 0.001875  Loss: -1.1700  Acc@1: 81.2500 (82.1093)  Acc@5: 100.0000 (96.8582)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 940/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -1.0372  Acc@1: 81.2500 (82.1201)  Acc@5: 100.0000 (96.8783)  time: 0.3520  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 950/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -1.0804  Acc@1: 81.2500 (82.1307)  Acc@5: 100.0000 (96.9046)  time: 0.3521  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 960/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.9862  Acc@1: 81.2500 (82.1150)  Acc@5: 100.0000 (96.8848)  time: 0.3567  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 970/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.6928  Acc@1: 81.2500 (82.0868)  Acc@5: 93.7500 (96.8782)  time: 0.3555  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 980/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -1.2695  Acc@1: 81.2500 (82.0973)  Acc@5: 100.0000 (96.8782)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 990/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -0.6436  Acc@1: 81.2500 (82.1014)  Acc@5: 100.0000 (96.8782)  time: 0.3514  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1000/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -1.1612  Acc@1: 81.2500 (82.0992)  Acc@5: 100.0000 (96.8844)  time: 0.3512  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1010/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.7903  Acc@1: 81.2500 (82.0908)  Acc@5: 100.0000 (96.8905)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1020/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -1.0691  Acc@1: 81.2500 (82.1192)  Acc@5: 100.0000 (96.8903)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1030/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.9542  Acc@1: 81.2500 (82.0805)  Acc@5: 100.0000 (96.8841)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1040/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.6180  Acc@1: 75.0000 (82.0245)  Acc@5: 100.0000 (96.8840)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1050/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -1.0918  Acc@1: 75.0000 (81.9933)  Acc@5: 100.0000 (96.8839)  time: 0.3540  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1060/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.9971  Acc@1: 81.2500 (82.0276)  Acc@5: 100.0000 (96.9015)  time: 0.3579  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1070/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.7076  Acc@1: 87.5000 (82.0553)  Acc@5: 100.0000 (96.8896)  time: 0.3534  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1080/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -1.3718  Acc@1: 81.2500 (82.0537)  Acc@5: 93.7500 (96.8779)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1090/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.9320  Acc@1: 81.2500 (82.0176)  Acc@5: 93.7500 (96.8779)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1100/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.9471  Acc@1: 81.2500 (82.0107)  Acc@5: 100.0000 (96.9005)  time: 0.3563  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1110/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.9485  Acc@1: 81.2500 (81.9757)  Acc@5: 100.0000 (96.9003)  time: 0.3568  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1120/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.2814  Acc@1: 81.2500 (81.9581)  Acc@5: 100.0000 (96.9057)  time: 0.3534  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1130/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -1.1035  Acc@1: 81.2500 (81.9463)  Acc@5: 100.0000 (96.9109)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1140/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.2723  Acc@1: 81.2500 (81.9402)  Acc@5: 100.0000 (96.9216)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1150/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -1.2069  Acc@1: 87.5000 (81.9831)  Acc@5: 100.0000 (96.9483)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1160/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -1.2753  Acc@1: 87.5000 (81.9875)  Acc@5: 100.0000 (96.9531)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1170/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -1.1421  Acc@1: 81.2500 (81.9812)  Acc@5: 100.0000 (96.9577)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1180/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -1.2626  Acc@1: 87.5000 (82.0332)  Acc@5: 100.0000 (96.9729)  time: 0.3512  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1190/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.7457  Acc@1: 81.2500 (82.0162)  Acc@5: 100.0000 (96.9616)  time: 0.3546  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1200/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -1.1743  Acc@1: 81.2500 (82.0358)  Acc@5: 100.0000 (96.9661)  time: 0.3526  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1210/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.8711  Acc@1: 81.2500 (82.0087)  Acc@5: 100.0000 (96.9550)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1220/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -1.2574  Acc@1: 75.0000 (82.0127)  Acc@5: 100.0000 (96.9646)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1230/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -1.1792  Acc@1: 81.2500 (82.0573)  Acc@5: 100.0000 (96.9639)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1240/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -1.1236  Acc@1: 81.2500 (82.0256)  Acc@5: 100.0000 (96.9732)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1250/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -1.2583  Acc@1: 81.2500 (82.0743)  Acc@5: 100.0000 (96.9774)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1260/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -1.2978  Acc@1: 87.5000 (82.0777)  Acc@5: 100.0000 (96.9816)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1270/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.5962  Acc@1: 81.2500 (82.0909)  Acc@5: 100.0000 (96.9856)  time: 0.3525  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1280/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.9718  Acc@1: 81.2500 (82.1136)  Acc@5: 100.0000 (97.0092)  time: 0.3523  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1290/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -1.1720  Acc@1: 87.5000 (82.0924)  Acc@5: 100.0000 (96.9985)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1300/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.5934  Acc@1: 87.5000 (82.1003)  Acc@5: 100.0000 (97.0023)  time: 0.3559  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1310/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.9422  Acc@1: 81.2500 (82.0986)  Acc@5: 100.0000 (97.0061)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1320/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.9528  Acc@1: 81.2500 (82.1016)  Acc@5: 100.0000 (97.0051)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1330/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -1.2562  Acc@1: 81.2500 (82.0858)  Acc@5: 100.0000 (97.0182)  time: 0.3548  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1340/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -1.2406  Acc@1: 87.5000 (82.1355)  Acc@5: 100.0000 (97.0172)  time: 0.3562  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1350/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -1.2472  Acc@1: 87.5000 (82.1290)  Acc@5: 100.0000 (97.0207)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1360/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -0.3869  Acc@1: 81.2500 (82.1087)  Acc@5: 100.0000 (97.0334)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1370/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -1.0637  Acc@1: 81.2500 (82.1298)  Acc@5: 100.0000 (97.0368)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1380/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -1.1435  Acc@1: 81.2500 (82.1189)  Acc@5: 100.0000 (97.0357)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1390/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -1.0908  Acc@1: 81.2500 (82.1352)  Acc@5: 100.0000 (97.0480)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1400/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.4283  Acc@1: 81.2500 (82.0976)  Acc@5: 100.0000 (97.0378)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1410/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.9236  Acc@1: 81.2500 (82.0872)  Acc@5: 93.7500 (97.0367)  time: 0.3532  data: 0.0026  max mem: 2500
Train: Epoch[5/5]  [1420/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.7062  Acc@1: 81.2500 (82.0857)  Acc@5: 100.0000 (97.0487)  time: 0.3525  data: 0.0026  max mem: 2500
Train: Epoch[5/5]  [1430/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -1.3044  Acc@1: 81.2500 (82.0886)  Acc@5: 100.0000 (97.0475)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1440/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -1.1972  Acc@1: 81.2500 (82.0958)  Acc@5: 100.0000 (97.0507)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1450/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -1.2356  Acc@1: 81.2500 (82.1158)  Acc@5: 100.0000 (97.0581)  time: 0.3532  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1460/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.7347  Acc@1: 81.2500 (82.1141)  Acc@5: 100.0000 (97.0611)  time: 0.3533  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1470/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -1.5099  Acc@1: 81.2500 (82.1338)  Acc@5: 100.0000 (97.0683)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1480/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.8311  Acc@1: 81.2500 (82.1362)  Acc@5: 100.0000 (97.0712)  time: 0.3561  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1490/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -1.0689  Acc@1: 75.0000 (82.1135)  Acc@5: 100.0000 (97.0532)  time: 0.3578  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1500/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -1.0033  Acc@1: 81.2500 (82.1161)  Acc@5: 100.0000 (97.0603)  time: 0.3550  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1510/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.7025  Acc@1: 81.2500 (82.0814)  Acc@5: 100.0000 (97.0425)  time: 0.3566  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1520/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.8400  Acc@1: 81.2500 (82.0595)  Acc@5: 100.0000 (97.0332)  time: 0.3562  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1530/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.6339  Acc@1: 81.2500 (82.0542)  Acc@5: 100.0000 (97.0240)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1540/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.9372  Acc@1: 81.2500 (82.0774)  Acc@5: 100.0000 (97.0271)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1550/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.5307  Acc@1: 87.5000 (82.1083)  Acc@5: 100.0000 (97.0140)  time: 0.3516  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1560/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -1.1382  Acc@1: 87.5000 (82.1308)  Acc@5: 93.7500 (97.0131)  time: 0.3560  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1570/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.6474  Acc@1: 81.2500 (82.1571)  Acc@5: 93.7500 (97.0123)  time: 0.3549  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1580/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -1.0924  Acc@1: 81.2500 (82.1513)  Acc@5: 100.0000 (97.0232)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1590/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -1.3559  Acc@1: 75.0000 (82.1417)  Acc@5: 100.0000 (97.0145)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1600/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.9411  Acc@1: 81.2500 (82.1245)  Acc@5: 93.7500 (97.0019)  time: 0.3520  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1610/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.8271  Acc@1: 81.2500 (82.1151)  Acc@5: 93.7500 (96.9972)  time: 0.3531  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1620/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.8814  Acc@1: 81.2500 (82.1291)  Acc@5: 100.0000 (97.0119)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1630/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.8114  Acc@1: 81.2500 (82.1045)  Acc@5: 100.0000 (97.0302)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1640/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -1.0227  Acc@1: 81.2500 (82.1031)  Acc@5: 100.0000 (97.0331)  time: 0.3511  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1650/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -1.2616  Acc@1: 81.2500 (82.1131)  Acc@5: 100.0000 (97.0359)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1660/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -1.0603  Acc@1: 81.2500 (82.0816)  Acc@5: 100.0000 (97.0349)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1670/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -1.0650  Acc@1: 81.2500 (82.0841)  Acc@5: 93.7500 (97.0227)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1680/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.4231  Acc@1: 81.2500 (82.1126)  Acc@5: 100.0000 (97.0293)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1690/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.5605  Acc@1: 87.5000 (82.1038)  Acc@5: 100.0000 (97.0321)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1700/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.7312  Acc@1: 75.0000 (82.0730)  Acc@5: 100.0000 (97.0312)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1710/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -1.1937  Acc@1: 87.5000 (82.1048)  Acc@5: 100.0000 (97.0302)  time: 0.3549  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1720/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -1.2190  Acc@1: 87.5000 (82.1071)  Acc@5: 100.0000 (97.0366)  time: 0.3578  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1730/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.6473  Acc@1: 81.2500 (82.1057)  Acc@5: 100.0000 (97.0176)  time: 0.3548  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1740/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.8450  Acc@1: 75.0000 (82.0829)  Acc@5: 93.7500 (97.0168)  time: 0.3532  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1750/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -1.2402  Acc@1: 81.2500 (82.0959)  Acc@5: 100.0000 (97.0196)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1760/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.9779  Acc@1: 81.2500 (82.0769)  Acc@5: 93.7500 (97.0045)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1770/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.8038  Acc@1: 81.2500 (82.0723)  Acc@5: 93.7500 (97.0003)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1780/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -1.0227  Acc@1: 81.2500 (82.0747)  Acc@5: 100.0000 (96.9996)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1790/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.9404  Acc@1: 81.2500 (82.0875)  Acc@5: 100.0000 (97.0059)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1800/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.8262  Acc@1: 81.2500 (82.0794)  Acc@5: 100.0000 (97.0051)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1810/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.1553  Acc@1: 87.5000 (82.1024)  Acc@5: 100.0000 (97.0079)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1820/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.9201  Acc@1: 87.5000 (82.1046)  Acc@5: 100.0000 (97.0106)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1830/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.9791  Acc@1: 81.2500 (82.1273)  Acc@5: 100.0000 (97.0201)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1840/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -1.1712  Acc@1: 81.2500 (82.1123)  Acc@5: 100.0000 (97.0091)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1850/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.6609  Acc@1: 81.2500 (82.0840)  Acc@5: 100.0000 (97.0050)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1860/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.9349  Acc@1: 81.2500 (82.0829)  Acc@5: 100.0000 (97.0043)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1870/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -1.0193  Acc@1: 81.2500 (82.0617)  Acc@5: 100.0000 (97.0003)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1880/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.8717  Acc@1: 81.2500 (82.0641)  Acc@5: 93.7500 (96.9930)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1890/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.9948  Acc@1: 81.2500 (82.0796)  Acc@5: 100.0000 (96.9956)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1900/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.5611  Acc@1: 87.5000 (82.0818)  Acc@5: 100.0000 (96.9983)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1910/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.7623  Acc@1: 87.5000 (82.0938)  Acc@5: 93.7500 (96.9911)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1920/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -1.2680  Acc@1: 81.2500 (82.1057)  Acc@5: 100.0000 (97.0003)  time: 0.3542  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1930/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -1.1370  Acc@1: 81.2500 (82.1110)  Acc@5: 100.0000 (96.9996)  time: 0.3530  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1940/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -1.0790  Acc@1: 87.5000 (82.1323)  Acc@5: 100.0000 (97.0054)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1950/3750]  eta: 0:12:15  Lr: 0.001875  Loss: -1.1628  Acc@1: 87.5000 (82.1374)  Acc@5: 100.0000 (97.0144)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1960/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -1.2098  Acc@1: 81.2500 (82.1488)  Acc@5: 100.0000 (97.0073)  time: 0.3543  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1970/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.9769  Acc@1: 81.2500 (82.1569)  Acc@5: 93.7500 (96.9971)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1980/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -1.1851  Acc@1: 87.5000 (82.1618)  Acc@5: 100.0000 (97.0059)  time: 0.3557  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1990/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.7875  Acc@1: 81.2500 (82.1635)  Acc@5: 100.0000 (97.0053)  time: 0.3534  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2000/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -1.1697  Acc@1: 87.5000 (82.1808)  Acc@5: 93.7500 (97.0015)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2010/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.8853  Acc@1: 81.2500 (82.1699)  Acc@5: 100.0000 (97.0071)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2020/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.8510  Acc@1: 81.2500 (82.1778)  Acc@5: 100.0000 (97.0188)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2030/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -1.1353  Acc@1: 87.5000 (82.1978)  Acc@5: 100.0000 (97.0150)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2040/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -1.1530  Acc@1: 87.5000 (82.2177)  Acc@5: 100.0000 (97.0205)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2050/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.9514  Acc@1: 81.2500 (82.2099)  Acc@5: 100.0000 (97.0045)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2060/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.8940  Acc@1: 81.2500 (82.2234)  Acc@5: 93.7500 (97.0039)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2070/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.9792  Acc@1: 87.5000 (82.2248)  Acc@5: 93.7500 (96.9972)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2080/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.4134  Acc@1: 81.2500 (82.2201)  Acc@5: 100.0000 (96.9996)  time: 0.3527  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2090/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -1.2655  Acc@1: 81.2500 (82.2035)  Acc@5: 100.0000 (96.9990)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2100/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.8910  Acc@1: 81.2500 (82.1960)  Acc@5: 100.0000 (97.0014)  time: 0.3512  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2110/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.7510  Acc@1: 81.2500 (82.1885)  Acc@5: 93.7500 (96.9919)  time: 0.3523  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2120/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -1.2991  Acc@1: 81.2500 (82.1841)  Acc@5: 93.7500 (96.9884)  time: 0.3544  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2130/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.6509  Acc@1: 81.2500 (82.1915)  Acc@5: 100.0000 (96.9879)  time: 0.3563  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2140/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.9461  Acc@1: 81.2500 (82.1812)  Acc@5: 100.0000 (96.9845)  time: 0.3596  data: 0.0041  max mem: 2500
Train: Epoch[5/5]  [2150/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.7484  Acc@1: 81.2500 (82.1885)  Acc@5: 100.0000 (96.9840)  time: 0.3569  data: 0.0038  max mem: 2500
Train: Epoch[5/5]  [2160/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.8842  Acc@1: 81.2500 (82.1784)  Acc@5: 100.0000 (96.9806)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2170/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -1.0571  Acc@1: 81.2500 (82.1914)  Acc@5: 100.0000 (96.9830)  time: 0.3534  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2180/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.7130  Acc@1: 81.2500 (82.1727)  Acc@5: 93.7500 (96.9767)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2190/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -1.1775  Acc@1: 81.2500 (82.1714)  Acc@5: 100.0000 (96.9791)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2200/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.7009  Acc@1: 81.2500 (82.1757)  Acc@5: 100.0000 (96.9843)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2210/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.9903  Acc@1: 81.2500 (82.1828)  Acc@5: 100.0000 (96.9838)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2220/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -1.0055  Acc@1: 81.2500 (82.1843)  Acc@5: 100.0000 (96.9862)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2230/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -1.2604  Acc@1: 81.2500 (82.1941)  Acc@5: 100.0000 (96.9885)  time: 0.3470  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2240/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -1.2571  Acc@1: 81.2500 (82.2066)  Acc@5: 100.0000 (96.9935)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2250/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -1.2687  Acc@1: 87.5000 (82.2190)  Acc@5: 100.0000 (96.9902)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2260/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.1491  Acc@1: 87.5000 (82.2203)  Acc@5: 93.7500 (96.9870)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2270/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -1.2167  Acc@1: 87.5000 (82.2325)  Acc@5: 100.0000 (96.9947)  time: 0.3574  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2280/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.5750  Acc@1: 81.2500 (82.2172)  Acc@5: 100.0000 (96.9942)  time: 0.3555  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2290/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.6390  Acc@1: 81.2500 (82.2103)  Acc@5: 100.0000 (96.9937)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2300/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -1.0593  Acc@1: 81.2500 (82.2170)  Acc@5: 100.0000 (97.0013)  time: 0.3527  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [2310/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -1.1854  Acc@1: 81.2500 (82.2182)  Acc@5: 100.0000 (97.0062)  time: 0.3553  data: 0.0039  max mem: 2500
Train: Epoch[5/5]  [2320/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -1.1466  Acc@1: 87.5000 (82.2410)  Acc@5: 100.0000 (97.0056)  time: 0.3560  data: 0.0028  max mem: 2500
Train: Epoch[5/5]  [2330/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -1.1645  Acc@1: 81.2500 (82.2287)  Acc@5: 100.0000 (97.0077)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2340/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -1.0938  Acc@1: 81.2500 (82.2378)  Acc@5: 100.0000 (97.0098)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2350/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.6194  Acc@1: 81.2500 (82.2150)  Acc@5: 93.7500 (97.0013)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2360/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.6355  Acc@1: 81.2500 (82.2295)  Acc@5: 93.7500 (96.9954)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2370/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.6507  Acc@1: 87.5000 (82.2280)  Acc@5: 100.0000 (96.9976)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2380/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -1.3583  Acc@1: 81.2500 (82.2160)  Acc@5: 100.0000 (96.9971)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2390/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -1.3446  Acc@1: 81.2500 (82.2015)  Acc@5: 93.7500 (96.9809)  time: 0.3524  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2400/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.4627  Acc@1: 81.2500 (82.1819)  Acc@5: 93.7500 (96.9830)  time: 0.3508  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2410/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -1.2372  Acc@1: 81.2500 (82.1677)  Acc@5: 100.0000 (96.9878)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2420/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -1.1892  Acc@1: 81.2500 (82.1716)  Acc@5: 100.0000 (96.9899)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2430/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.7486  Acc@1: 81.2500 (82.1755)  Acc@5: 100.0000 (96.9945)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2440/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.3843  Acc@1: 81.2500 (82.1743)  Acc@5: 93.7500 (96.9838)  time: 0.3478  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2450/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -1.0317  Acc@1: 81.2500 (82.1603)  Acc@5: 93.7500 (96.9655)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2460/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -1.4749  Acc@1: 81.2500 (82.1566)  Acc@5: 93.7500 (96.9728)  time: 0.3566  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2470/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -1.3008  Acc@1: 81.2500 (82.1631)  Acc@5: 100.0000 (96.9749)  time: 0.3563  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2480/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.7945  Acc@1: 81.2500 (82.1670)  Acc@5: 100.0000 (96.9795)  time: 0.3554  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2490/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.5525  Acc@1: 81.2500 (82.1482)  Acc@5: 100.0000 (96.9641)  time: 0.3570  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2500/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -1.0558  Acc@1: 81.2500 (82.1521)  Acc@5: 93.7500 (96.9637)  time: 0.3589  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2510/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -1.2528  Acc@1: 87.5000 (82.1660)  Acc@5: 100.0000 (96.9708)  time: 0.3550  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2520/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.8989  Acc@1: 81.2500 (82.1574)  Acc@5: 100.0000 (96.9655)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2530/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -1.2566  Acc@1: 81.2500 (82.1637)  Acc@5: 100.0000 (96.9676)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -1.1609  Acc@1: 81.2500 (82.1601)  Acc@5: 100.0000 (96.9697)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2550/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -1.2357  Acc@1: 87.5000 (82.1957)  Acc@5: 100.0000 (96.9718)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2560/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -1.1989  Acc@1: 87.5000 (82.1993)  Acc@5: 100.0000 (96.9763)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2570/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.9056  Acc@1: 81.2500 (82.1884)  Acc@5: 100.0000 (96.9759)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2580/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -1.1766  Acc@1: 81.2500 (82.1944)  Acc@5: 100.0000 (96.9779)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2590/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.7279  Acc@1: 81.2500 (82.1883)  Acc@5: 100.0000 (96.9751)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2600/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.7941  Acc@1: 75.0000 (82.1511)  Acc@5: 100.0000 (96.9627)  time: 0.3593  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2610/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -1.1005  Acc@1: 81.2500 (82.1692)  Acc@5: 100.0000 (96.9672)  time: 0.3594  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2620/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -1.2327  Acc@1: 87.5000 (82.1705)  Acc@5: 100.0000 (96.9740)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2630/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.8873  Acc@1: 87.5000 (82.1883)  Acc@5: 100.0000 (96.9783)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2640/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.8556  Acc@1: 87.5000 (82.1777)  Acc@5: 100.0000 (96.9827)  time: 0.5120  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2650/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.9932  Acc@1: 75.0000 (82.1553)  Acc@5: 100.0000 (96.9799)  time: 0.7032  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2660/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.0852  Acc@1: 81.2500 (82.1684)  Acc@5: 100.0000 (96.9889)  time: 0.7411  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2670/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -1.1192  Acc@1: 81.2500 (82.1579)  Acc@5: 100.0000 (96.9815)  time: 0.7389  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2680/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.9505  Acc@1: 87.5000 (82.1662)  Acc@5: 93.7500 (96.9764)  time: 0.7351  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2690/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.3530  Acc@1: 87.5000 (82.1628)  Acc@5: 100.0000 (96.9760)  time: 0.6287  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2700/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.9962  Acc@1: 87.5000 (82.1756)  Acc@5: 93.7500 (96.9687)  time: 0.4335  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -1.0364  Acc@1: 81.2500 (82.1653)  Acc@5: 93.7500 (96.9661)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2720/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -1.3772  Acc@1: 75.0000 (82.1619)  Acc@5: 100.0000 (96.9657)  time: 0.3516  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2730/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -1.1243  Acc@1: 81.2500 (82.1769)  Acc@5: 100.0000 (96.9746)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2740/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.6531  Acc@1: 81.2500 (82.1735)  Acc@5: 100.0000 (96.9742)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2750/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -1.2112  Acc@1: 87.5000 (82.1997)  Acc@5: 100.0000 (96.9784)  time: 0.3602  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2760/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -1.1329  Acc@1: 87.5000 (82.2098)  Acc@5: 100.0000 (96.9803)  time: 0.3598  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2770/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -1.2724  Acc@1: 81.2500 (82.2131)  Acc@5: 100.0000 (96.9821)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2780/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6923  Acc@1: 81.2500 (82.2096)  Acc@5: 100.0000 (96.9773)  time: 0.3634  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2790/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.0340  Acc@1: 81.2500 (82.2017)  Acc@5: 93.7500 (96.9724)  time: 0.5571  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2800/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -0.7122  Acc@1: 75.0000 (82.1805)  Acc@5: 100.0000 (96.9765)  time: 0.7351  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2810/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.9858  Acc@1: 81.2500 (82.1838)  Acc@5: 100.0000 (96.9784)  time: 0.7339  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2820/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -1.2148  Acc@1: 81.2500 (82.1761)  Acc@5: 100.0000 (96.9758)  time: 0.7396  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2830/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -1.1885  Acc@1: 81.2500 (82.1816)  Acc@5: 100.0000 (96.9732)  time: 0.7417  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2840/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -1.0193  Acc@1: 81.2500 (82.1872)  Acc@5: 100.0000 (96.9795)  time: 0.7399  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2850/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.7941  Acc@1: 81.2500 (82.1905)  Acc@5: 100.0000 (96.9879)  time: 0.7454  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2860/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -1.0254  Acc@1: 81.2500 (82.1894)  Acc@5: 100.0000 (96.9919)  time: 0.7467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2870/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.9891  Acc@1: 81.2500 (82.1883)  Acc@5: 100.0000 (96.9915)  time: 0.7380  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.5053  Acc@1: 81.2500 (82.1807)  Acc@5: 100.0000 (96.9867)  time: 0.5398  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -1.2728  Acc@1: 81.2500 (82.1774)  Acc@5: 100.0000 (96.9863)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2900/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.8552  Acc@1: 81.2500 (82.1872)  Acc@5: 100.0000 (96.9816)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2910/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -1.1030  Acc@1: 87.5000 (82.1968)  Acc@5: 93.7500 (96.9791)  time: 0.3558  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [2920/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.8872  Acc@1: 81.2500 (82.1936)  Acc@5: 93.7500 (96.9766)  time: 0.3624  data: 0.0032  max mem: 2500
Train: Epoch[5/5]  [2930/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -1.1526  Acc@1: 81.2500 (82.1861)  Acc@5: 93.7500 (96.9699)  time: 0.3600  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2940/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -1.3190  Acc@1: 81.2500 (82.1851)  Acc@5: 100.0000 (96.9738)  time: 0.3566  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2950/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -1.2051  Acc@1: 87.5000 (82.2009)  Acc@5: 100.0000 (96.9735)  time: 0.3572  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2960/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -1.0404  Acc@1: 81.2500 (82.2041)  Acc@5: 100.0000 (96.9774)  time: 0.3653  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2970/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -1.3431  Acc@1: 81.2500 (82.2009)  Acc@5: 100.0000 (96.9728)  time: 0.3639  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2980/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.5413  Acc@1: 81.2500 (82.2061)  Acc@5: 100.0000 (96.9662)  time: 0.3527  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2990/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.6987  Acc@1: 81.2500 (82.1924)  Acc@5: 100.0000 (96.9575)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3000/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -1.0592  Acc@1: 87.5000 (82.2080)  Acc@5: 100.0000 (96.9614)  time: 0.4641  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3010/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -1.3080  Acc@1: 87.5000 (82.2090)  Acc@5: 100.0000 (96.9632)  time: 0.6604  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.9103  Acc@1: 81.2500 (82.2162)  Acc@5: 100.0000 (96.9691)  time: 0.7412  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -1.3354  Acc@1: 87.5000 (82.2274)  Acc@5: 100.0000 (96.9688)  time: 0.7422  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -1.1024  Acc@1: 87.5000 (82.2386)  Acc@5: 100.0000 (96.9706)  time: 0.7408  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -1.3762  Acc@1: 81.2500 (82.2333)  Acc@5: 100.0000 (96.9682)  time: 0.7431  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.6516  Acc@1: 81.2500 (82.2178)  Acc@5: 100.0000 (96.9659)  time: 0.7458  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3070/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -1.0096  Acc@1: 81.2500 (82.2004)  Acc@5: 93.7500 (96.9534)  time: 0.7426  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3080/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.1731  Acc@1: 81.2500 (82.2055)  Acc@5: 100.0000 (96.9531)  time: 0.7451  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3090/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -1.0381  Acc@1: 81.2500 (82.2064)  Acc@5: 100.0000 (96.9528)  time: 0.7444  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3100/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.0817  Acc@1: 81.2500 (82.2114)  Acc@5: 100.0000 (96.9586)  time: 0.7405  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3110/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.6578  Acc@1: 87.5000 (82.2203)  Acc@5: 100.0000 (96.9604)  time: 0.7409  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3120/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.5666  Acc@1: 81.2500 (82.2212)  Acc@5: 100.0000 (96.9581)  time: 0.7390  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3130/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -1.0517  Acc@1: 81.2500 (82.2261)  Acc@5: 93.7500 (96.9519)  time: 0.7332  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3140/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.9313  Acc@1: 81.2500 (82.2210)  Acc@5: 93.7500 (96.9556)  time: 0.7329  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3150/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -1.0461  Acc@1: 81.2500 (82.2140)  Acc@5: 100.0000 (96.9514)  time: 0.7415  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3160/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.7406  Acc@1: 75.0000 (82.2070)  Acc@5: 93.7500 (96.9432)  time: 0.7495  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3170/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.6495  Acc@1: 81.2500 (82.2217)  Acc@5: 100.0000 (96.9469)  time: 0.7380  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3180/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.8500  Acc@1: 87.5000 (82.2304)  Acc@5: 100.0000 (96.9467)  time: 0.7306  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.2268  Acc@1: 81.2500 (82.2274)  Acc@5: 100.0000 (96.9484)  time: 0.7462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -0.9352  Acc@1: 81.2500 (82.2321)  Acc@5: 100.0000 (96.9521)  time: 0.7469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -1.3561  Acc@1: 81.2500 (82.2407)  Acc@5: 100.0000 (96.9577)  time: 0.7420  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.8324  Acc@1: 87.5000 (82.2454)  Acc@5: 100.0000 (96.9536)  time: 0.7404  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -1.3855  Acc@1: 87.5000 (82.2539)  Acc@5: 100.0000 (96.9572)  time: 0.7386  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3240/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -1.1015  Acc@1: 81.2500 (82.2566)  Acc@5: 100.0000 (96.9570)  time: 0.7394  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3250/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -1.3361  Acc@1: 87.5000 (82.2689)  Acc@5: 100.0000 (96.9586)  time: 0.7312  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3260/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -1.3135  Acc@1: 87.5000 (82.2658)  Acc@5: 100.0000 (96.9603)  time: 0.7263  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3270/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.7373  Acc@1: 81.2500 (82.2589)  Acc@5: 100.0000 (96.9562)  time: 0.7268  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3280/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -1.0982  Acc@1: 81.2500 (82.2577)  Acc@5: 100.0000 (96.9579)  time: 0.7288  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3290/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -1.2590  Acc@1: 87.5000 (82.2641)  Acc@5: 100.0000 (96.9633)  time: 0.7297  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3300/3750]  eta: 0:03:17  Lr: 0.001875  Loss: -0.9100  Acc@1: 87.5000 (82.2648)  Acc@5: 100.0000 (96.9687)  time: 0.7283  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3310/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -1.3604  Acc@1: 81.2500 (82.2637)  Acc@5: 100.0000 (96.9703)  time: 0.6946  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3320/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.9611  Acc@1: 81.2500 (82.2531)  Acc@5: 100.0000 (96.9606)  time: 0.6822  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3330/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.6105  Acc@1: 81.2500 (82.2444)  Acc@5: 93.7500 (96.9585)  time: 0.7126  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3340/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -1.4170  Acc@1: 81.2500 (82.2471)  Acc@5: 100.0000 (96.9601)  time: 0.7224  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -1.1783  Acc@1: 81.2500 (82.2497)  Acc@5: 100.0000 (96.9599)  time: 0.7203  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -1.2218  Acc@1: 81.2500 (82.2523)  Acc@5: 100.0000 (96.9578)  time: 0.7177  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.8196  Acc@1: 81.2500 (82.2530)  Acc@5: 93.7500 (96.9575)  time: 0.7243  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.8788  Acc@1: 81.2500 (82.2519)  Acc@5: 93.7500 (96.9517)  time: 0.7288  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.0513  Acc@1: 81.2500 (82.2545)  Acc@5: 100.0000 (96.9533)  time: 0.7278  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.9423  Acc@1: 87.5000 (82.2791)  Acc@5: 100.0000 (96.9605)  time: 0.7300  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3410/3750]  eta: 0:02:32  Lr: 0.001875  Loss: -0.9627  Acc@1: 87.5000 (82.2669)  Acc@5: 100.0000 (96.9602)  time: 0.7292  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3420/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -1.3566  Acc@1: 81.2500 (82.2786)  Acc@5: 100.0000 (96.9563)  time: 0.7300  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3430/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.4259  Acc@1: 81.2500 (82.2683)  Acc@5: 93.7500 (96.9561)  time: 0.7313  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3440/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.0873  Acc@1: 75.0000 (82.2581)  Acc@5: 100.0000 (96.9540)  time: 0.7329  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [3450/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.7390  Acc@1: 81.2500 (82.2533)  Acc@5: 93.7500 (96.9465)  time: 0.7324  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [3460/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -1.0454  Acc@1: 81.2500 (82.2522)  Acc@5: 93.7500 (96.9481)  time: 0.7203  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3470/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -1.0744  Acc@1: 81.2500 (82.2656)  Acc@5: 100.0000 (96.9479)  time: 0.7199  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3480/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.1529  Acc@1: 81.2500 (82.2519)  Acc@5: 93.7500 (96.9387)  time: 0.7290  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:57  Lr: 0.001875  Loss: -0.9395  Acc@1: 81.2500 (82.2526)  Acc@5: 100.0000 (96.9439)  time: 0.7281  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:53  Lr: 0.001875  Loss: -0.9511  Acc@1: 81.2500 (82.2694)  Acc@5: 100.0000 (96.9473)  time: 0.7282  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -1.3057  Acc@1: 81.2500 (82.2629)  Acc@5: 100.0000 (96.9471)  time: 0.7292  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.9476  Acc@1: 81.2500 (82.2724)  Acc@5: 100.0000 (96.9469)  time: 0.7301  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -1.0937  Acc@1: 87.5000 (82.2872)  Acc@5: 100.0000 (96.9467)  time: 0.7341  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:36  Lr: 0.001875  Loss: -1.1188  Acc@1: 81.2500 (82.2773)  Acc@5: 100.0000 (96.9500)  time: 0.7253  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7122  Acc@1: 81.2500 (82.2708)  Acc@5: 100.0000 (96.9498)  time: 0.7201  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.7903  Acc@1: 81.2500 (82.2855)  Acc@5: 100.0000 (96.9513)  time: 0.7280  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:22  Lr: 0.001875  Loss: -1.2099  Acc@1: 87.5000 (82.2879)  Acc@5: 100.0000 (96.9511)  time: 0.6301  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3580/3750]  eta: 0:01:18  Lr: 0.001875  Loss: -1.0332  Acc@1: 81.2500 (82.2885)  Acc@5: 93.7500 (96.9509)  time: 0.4409  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3590/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.3545  Acc@1: 81.2500 (82.2873)  Acc@5: 100.0000 (96.9559)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3600/3750]  eta: 0:01:08  Lr: 0.001875  Loss: -1.3644  Acc@1: 87.5000 (82.3105)  Acc@5: 100.0000 (96.9626)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3610/3750]  eta: 0:01:04  Lr: 0.001875  Loss: -1.3572  Acc@1: 87.5000 (82.3145)  Acc@5: 100.0000 (96.9624)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.9507  Acc@1: 87.5000 (82.3271)  Acc@5: 100.0000 (96.9673)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:54  Lr: 0.001875  Loss: -1.1239  Acc@1: 87.5000 (82.3413)  Acc@5: 100.0000 (96.9688)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:50  Lr: 0.001875  Loss: -1.0940  Acc@1: 81.2500 (82.3229)  Acc@5: 93.7500 (96.9600)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.3467  Acc@1: 75.0000 (82.3199)  Acc@5: 93.7500 (96.9632)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9427  Acc@1: 81.2500 (82.3221)  Acc@5: 100.0000 (96.9612)  time: 0.3523  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:36  Lr: 0.001875  Loss: -0.9243  Acc@1: 87.5000 (82.3209)  Acc@5: 100.0000 (96.9627)  time: 0.3572  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.2260  Acc@1: 87.5000 (82.3282)  Acc@5: 100.0000 (96.9624)  time: 0.3574  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6063  Acc@1: 81.2500 (82.3219)  Acc@5: 100.0000 (96.9605)  time: 0.3574  data: 0.0028  max mem: 2500
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:22  Lr: 0.001875  Loss: -0.5063  Acc@1: 81.2500 (82.3207)  Acc@5: 100.0000 (96.9586)  time: 0.3558  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:18  Lr: 0.001875  Loss: -1.0038  Acc@1: 81.2500 (82.3060)  Acc@5: 93.7500 (96.9533)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.3392  Acc@1: 81.2500 (82.3183)  Acc@5: 100.0000 (96.9565)  time: 0.3530  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:09  Lr: 0.001875  Loss: -1.3120  Acc@1: 87.5000 (82.3037)  Acc@5: 100.0000 (96.9546)  time: 0.3529  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: -0.4984  Acc@1: 81.2500 (82.2975)  Acc@5: 100.0000 (96.9544)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.2952  Acc@1: 87.5000 (82.3067)  Acc@5: 100.0000 (96.9533)  time: 0.3539  data: 0.0013  max mem: 2500
Train: Epoch[5/5] Total time: 0:28:23 (0.4543 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.2952  Acc@1: 87.5000 (82.3067)  Acc@5: 100.0000 (96.9533)
Test: [Task 1]  [   0/1627]  eta: 0:15:53  Loss: 1.4926 (1.4926)  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5862  data: 0.3692  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:49  Loss: 1.1840 (1.1568)  Acc@1: 68.7500 (65.9091)  Acc@5: 100.0000 (96.0227)  time: 0.2531  data: 0.0357  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:19  Loss: 1.0841 (1.1154)  Acc@1: 68.7500 (69.0476)  Acc@5: 93.7500 (94.9405)  time: 0.2186  data: 0.0014  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:07  Loss: 1.0841 (1.1104)  Acc@1: 68.7500 (70.1613)  Acc@5: 93.7500 (94.9597)  time: 0.2171  data: 0.0004  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:06:00  Loss: 1.1570 (1.1186)  Acc@1: 68.7500 (69.9695)  Acc@5: 93.7500 (94.9695)  time: 0.2176  data: 0.0004  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:55  Loss: 0.9474 (1.1012)  Acc@1: 68.7500 (70.8333)  Acc@5: 100.0000 (95.2206)  time: 0.2181  data: 0.0004  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:51  Loss: 1.0472 (1.1144)  Acc@1: 68.7500 (70.4918)  Acc@5: 93.7500 (94.8770)  time: 0.2177  data: 0.0006  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:47  Loss: 0.9871 (1.1109)  Acc@1: 68.7500 (70.4225)  Acc@5: 93.7500 (95.1585)  time: 0.2175  data: 0.0007  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:44  Loss: 0.9418 (1.0932)  Acc@1: 75.0000 (70.9105)  Acc@5: 100.0000 (95.3704)  time: 0.2178  data: 0.0004  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:40  Loss: 0.9833 (1.1116)  Acc@1: 75.0000 (70.4670)  Acc@5: 93.7500 (95.1923)  time: 0.2171  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:37  Loss: 1.3678 (1.1377)  Acc@1: 62.5000 (69.9257)  Acc@5: 93.7500 (94.8020)  time: 0.2162  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:35  Loss: 1.1267 (1.1361)  Acc@1: 62.5000 (69.3694)  Acc@5: 100.0000 (95.1577)  time: 0.2168  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:32  Loss: 1.0988 (1.1320)  Acc@1: 68.7500 (69.9380)  Acc@5: 100.0000 (95.1446)  time: 0.2169  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:29  Loss: 1.1725 (1.1386)  Acc@1: 75.0000 (69.5611)  Acc@5: 93.7500 (95.2290)  time: 0.2173  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:27  Loss: 1.0975 (1.1382)  Acc@1: 62.5000 (69.2819)  Acc@5: 93.7500 (95.2571)  time: 0.2174  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:24  Loss: 0.8456 (1.1235)  Acc@1: 75.0000 (69.7434)  Acc@5: 93.7500 (95.3228)  time: 0.2168  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:22  Loss: 0.8392 (1.1160)  Acc@1: 75.0000 (70.1475)  Acc@5: 100.0000 (95.4193)  time: 0.2172  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:20  Loss: 1.0357 (1.1122)  Acc@1: 75.0000 (70.2120)  Acc@5: 93.7500 (95.3947)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:18  Loss: 1.1038 (1.1172)  Acc@1: 68.7500 (69.9240)  Acc@5: 93.7500 (95.4075)  time: 0.2219  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:16  Loss: 1.1038 (1.1137)  Acc@1: 68.7500 (69.9935)  Acc@5: 93.7500 (95.3534)  time: 0.2231  data: 0.0020  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:13  Loss: 1.0925 (1.1112)  Acc@1: 68.7500 (70.1182)  Acc@5: 93.7500 (95.3980)  time: 0.2207  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:11  Loss: 1.0482 (1.1104)  Acc@1: 75.0000 (70.3495)  Acc@5: 93.7500 (95.4088)  time: 0.2199  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:09  Loss: 1.0275 (1.1131)  Acc@1: 75.0000 (70.3337)  Acc@5: 93.7500 (95.4186)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:07  Loss: 1.0445 (1.1079)  Acc@1: 75.0000 (70.5898)  Acc@5: 93.7500 (95.4275)  time: 0.2196  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:05  Loss: 1.0236 (1.1032)  Acc@1: 75.0000 (70.7469)  Acc@5: 93.7500 (95.4357)  time: 0.2220  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:03  Loss: 0.9649 (1.1058)  Acc@1: 75.0000 (70.8167)  Acc@5: 93.7500 (95.3187)  time: 0.2235  data: 0.0018  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:05:01  Loss: 1.0583 (1.1062)  Acc@1: 68.7500 (70.7854)  Acc@5: 93.7500 (95.3544)  time: 0.2235  data: 0.0023  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:59  Loss: 1.0023 (1.1002)  Acc@1: 68.7500 (70.8026)  Acc@5: 100.0000 (95.4336)  time: 0.2218  data: 0.0017  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:56  Loss: 0.9800 (1.1002)  Acc@1: 68.7500 (70.7518)  Acc@5: 100.0000 (95.3737)  time: 0.2190  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:54  Loss: 1.0945 (1.1000)  Acc@1: 68.7500 (70.7904)  Acc@5: 93.7500 (95.3393)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:52  Loss: 1.0709 (1.1004)  Acc@1: 68.7500 (70.8056)  Acc@5: 93.7500 (95.3488)  time: 0.2199  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:50  Loss: 0.9751 (1.1025)  Acc@1: 68.7500 (70.6592)  Acc@5: 93.7500 (95.3577)  time: 0.2265  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:48  Loss: 1.0855 (1.1020)  Acc@1: 68.7500 (70.5413)  Acc@5: 93.7500 (95.3271)  time: 0.2262  data: 0.0024  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:46  Loss: 0.9784 (1.0997)  Acc@1: 68.7500 (70.5816)  Acc@5: 93.7500 (95.3739)  time: 0.2206  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:43  Loss: 0.9367 (1.0995)  Acc@1: 68.7500 (70.6195)  Acc@5: 100.0000 (95.3996)  time: 0.2200  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:41  Loss: 1.0022 (1.1012)  Acc@1: 75.0000 (70.6731)  Acc@5: 93.7500 (95.3170)  time: 0.2203  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:39  Loss: 1.0022 (1.0994)  Acc@1: 75.0000 (70.6717)  Acc@5: 93.7500 (95.3774)  time: 0.2261  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:37  Loss: 0.9810 (1.0982)  Acc@1: 68.7500 (70.6199)  Acc@5: 100.0000 (95.3841)  time: 0.2282  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:35  Loss: 0.9948 (1.0971)  Acc@1: 68.7500 (70.7185)  Acc@5: 93.7500 (95.3576)  time: 0.2223  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:33  Loss: 1.0154 (1.0981)  Acc@1: 75.0000 (70.7321)  Acc@5: 93.7500 (95.3325)  time: 0.2213  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:31  Loss: 0.9575 (1.0988)  Acc@1: 75.0000 (70.6515)  Acc@5: 93.7500 (95.3398)  time: 0.2224  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:32  Loss: 0.9714 (1.0986)  Acc@1: 68.7500 (70.7269)  Acc@5: 93.7500 (95.3163)  time: 0.2873  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:37  Loss: 1.0031 (1.0977)  Acc@1: 75.0000 (70.7245)  Acc@5: 100.0000 (95.3830)  time: 0.4094  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:41  Loss: 1.0031 (1.0959)  Acc@1: 68.7500 (70.6932)  Acc@5: 100.0000 (95.4321)  time: 0.4605  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:45  Loss: 1.1377 (1.0959)  Acc@1: 68.7500 (70.6774)  Acc@5: 100.0000 (95.4649)  time: 0.4586  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:48  Loss: 1.1567 (1.0995)  Acc@1: 62.5000 (70.4407)  Acc@5: 93.7500 (95.4130)  time: 0.4642  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:51  Loss: 1.1700 (1.0995)  Acc@1: 62.5000 (70.4582)  Acc@5: 93.7500 (95.4582)  time: 0.4656  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:54  Loss: 1.0399 (1.0978)  Acc@1: 68.7500 (70.4618)  Acc@5: 100.0000 (95.4751)  time: 0.4652  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:57  Loss: 1.1152 (1.1017)  Acc@1: 68.7500 (70.3352)  Acc@5: 100.0000 (95.4392)  time: 0.4627  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:59  Loss: 1.1416 (1.1016)  Acc@1: 68.7500 (70.3157)  Acc@5: 93.7500 (95.4430)  time: 0.4652  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:05:01  Loss: 1.0834 (1.1027)  Acc@1: 68.7500 (70.3094)  Acc@5: 93.7500 (95.4341)  time: 0.4729  data: 0.0020  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:05:02  Loss: 1.1501 (1.1088)  Acc@1: 62.5000 (70.1199)  Acc@5: 93.7500 (95.4134)  time: 0.4665  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:05:04  Loss: 1.2736 (1.1156)  Acc@1: 62.5000 (70.0696)  Acc@5: 93.7500 (95.3455)  time: 0.4622  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:05:05  Loss: 1.0929 (1.1123)  Acc@1: 68.7500 (70.1742)  Acc@5: 93.7500 (95.3743)  time: 0.4684  data: 0.0019  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:05:06  Loss: 1.0169 (1.1129)  Acc@1: 68.7500 (70.1825)  Acc@5: 93.7500 (95.3443)  time: 0.4654  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:05:07  Loss: 1.2105 (1.1153)  Acc@1: 68.7500 (70.1565)  Acc@5: 93.7500 (95.3607)  time: 0.4616  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:05:07  Loss: 1.2302 (1.1174)  Acc@1: 68.7500 (70.0646)  Acc@5: 100.0000 (95.3766)  time: 0.4630  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:05:08  Loss: 1.1095 (1.1146)  Acc@1: 68.7500 (70.1073)  Acc@5: 93.7500 (95.3809)  time: 0.4613  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:05:08  Loss: 1.0505 (1.1149)  Acc@1: 75.0000 (70.1162)  Acc@5: 93.7500 (95.4066)  time: 0.4611  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:05:08  Loss: 1.1148 (1.1144)  Acc@1: 68.7500 (70.1354)  Acc@5: 100.0000 (95.4420)  time: 0.4635  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:05:08  Loss: 1.1250 (1.1163)  Acc@1: 75.0000 (70.1227)  Acc@5: 100.0000 (95.4243)  time: 0.4643  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:05:07  Loss: 1.0800 (1.1144)  Acc@1: 75.0000 (70.2025)  Acc@5: 100.0000 (95.4480)  time: 0.4646  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:05:07  Loss: 1.0366 (1.1162)  Acc@1: 75.0000 (70.1490)  Acc@5: 100.0000 (95.4207)  time: 0.4659  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:05:07  Loss: 1.0057 (1.1160)  Acc@1: 68.7500 (70.2258)  Acc@5: 93.7500 (95.4140)  time: 0.4660  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:05:06  Loss: 0.9973 (1.1155)  Acc@1: 75.0000 (70.2613)  Acc@5: 93.7500 (95.4173)  time: 0.4667  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:05:05  Loss: 0.9561 (1.1144)  Acc@1: 75.0000 (70.3245)  Acc@5: 100.0000 (95.4493)  time: 0.4591  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:05:04  Loss: 0.9561 (1.1129)  Acc@1: 75.0000 (70.3480)  Acc@5: 100.0000 (95.4331)  time: 0.4588  data: 0.0018  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:05:03  Loss: 1.0872 (1.1126)  Acc@1: 75.0000 (70.3241)  Acc@5: 93.7500 (95.4266)  time: 0.4669  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:05:02  Loss: 1.0872 (1.1120)  Acc@1: 75.0000 (70.3377)  Acc@5: 93.7500 (95.4295)  time: 0.4580  data: 0.0026  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:05:00  Loss: 1.0653 (1.1099)  Acc@1: 75.0000 (70.3962)  Acc@5: 100.0000 (95.4595)  time: 0.4548  data: 0.0032  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:04:59  Loss: 1.0835 (1.1092)  Acc@1: 75.0000 (70.4797)  Acc@5: 100.0000 (95.4618)  time: 0.4588  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:04:58  Loss: 0.9341 (1.1068)  Acc@1: 75.0000 (70.5608)  Acc@5: 100.0000 (95.4905)  time: 0.4576  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:04:56  Loss: 0.8817 (1.1058)  Acc@1: 75.0000 (70.5270)  Acc@5: 100.0000 (95.5010)  time: 0.4571  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:04:54  Loss: 1.0561 (1.1063)  Acc@1: 68.7500 (70.4942)  Acc@5: 93.7500 (95.5113)  time: 0.4579  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:04:53  Loss: 1.1098 (1.1072)  Acc@1: 68.7500 (70.4875)  Acc@5: 93.7500 (95.4875)  time: 0.4568  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:04:51  Loss: 1.1098 (1.1062)  Acc@1: 68.7500 (70.5892)  Acc@5: 93.7500 (95.4977)  time: 0.4593  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:04:49  Loss: 1.1350 (1.1092)  Acc@1: 68.7500 (70.5158)  Acc@5: 93.7500 (95.4501)  time: 0.4618  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:04:47  Loss: 0.9625 (1.1058)  Acc@1: 75.0000 (70.6550)  Acc@5: 93.7500 (95.4767)  time: 0.4583  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:04:45  Loss: 0.8664 (1.1042)  Acc@1: 75.0000 (70.7106)  Acc@5: 100.0000 (95.4786)  time: 0.4609  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:04:43  Loss: 0.9488 (1.1060)  Acc@1: 68.7500 (70.7253)  Acc@5: 100.0000 (95.4646)  time: 0.4610  data: 0.0032  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:04:41  Loss: 1.0288 (1.1046)  Acc@1: 68.7500 (70.7319)  Acc@5: 100.0000 (95.4978)  time: 0.4589  data: 0.0017  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:04:39  Loss: 0.9772 (1.1038)  Acc@1: 75.0000 (70.7922)  Acc@5: 100.0000 (95.5071)  time: 0.4622  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:04:36  Loss: 0.9132 (1.1029)  Acc@1: 75.0000 (70.8206)  Acc@5: 100.0000 (95.5085)  time: 0.4577  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:04:34  Loss: 0.9124 (1.1022)  Acc@1: 75.0000 (70.8183)  Acc@5: 100.0000 (95.5174)  time: 0.4605  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:04:32  Loss: 0.8933 (1.0996)  Acc@1: 75.0000 (70.8903)  Acc@5: 100.0000 (95.5559)  time: 0.4654  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:04:29  Loss: 1.1204 (1.1008)  Acc@1: 68.7500 (70.8211)  Acc@5: 100.0000 (95.5567)  time: 0.4576  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:04:27  Loss: 1.0693 (1.0999)  Acc@1: 62.5000 (70.8116)  Acc@5: 100.0000 (95.6010)  time: 0.4539  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:04:24  Loss: 0.9933 (1.0988)  Acc@1: 68.7500 (70.8166)  Acc@5: 100.0000 (95.6085)  time: 0.4588  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:04:21  Loss: 1.0919 (1.1010)  Acc@1: 68.7500 (70.7577)  Acc@5: 100.0000 (95.6158)  time: 0.4425  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:04:18  Loss: 1.1877 (1.1033)  Acc@1: 62.5000 (70.7071)  Acc@5: 93.7500 (95.5948)  time: 0.4109  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:04:16  Loss: 1.1686 (1.1035)  Acc@1: 68.7500 (70.6992)  Acc@5: 93.7500 (95.5952)  time: 0.4259  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:04:13  Loss: 1.1702 (1.1048)  Acc@1: 68.7500 (70.7121)  Acc@5: 93.7500 (95.5612)  time: 0.4527  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:04:10  Loss: 1.1243 (1.1048)  Acc@1: 68.7500 (70.6976)  Acc@5: 93.7500 (95.5822)  time: 0.4542  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:04:07  Loss: 1.0126 (1.1057)  Acc@1: 68.7500 (70.6968)  Acc@5: 93.7500 (95.5491)  time: 0.4525  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:04:04  Loss: 1.0239 (1.1041)  Acc@1: 68.7500 (70.7492)  Acc@5: 100.0000 (95.5765)  time: 0.4579  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:04:02  Loss: 1.1220 (1.1053)  Acc@1: 62.5000 (70.6756)  Acc@5: 100.0000 (95.5836)  time: 0.4662  data: 0.0028  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:03:59  Loss: 1.1241 (1.1046)  Acc@1: 62.5000 (70.6881)  Acc@5: 93.7500 (95.5645)  time: 0.4612  data: 0.0035  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:03:56  Loss: 0.9777 (1.1037)  Acc@1: 75.0000 (70.7132)  Acc@5: 93.7500 (95.5587)  time: 0.4565  data: 0.0024  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:03:53  Loss: 1.0506 (1.1036)  Acc@1: 75.0000 (70.7441)  Acc@5: 93.7500 (95.5657)  time: 0.4592  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:03:50  Loss: 1.1558 (1.1064)  Acc@1: 75.0000 (70.7177)  Acc@5: 93.7500 (95.5474)  time: 0.4590  data: 0.0017  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:03:47  Loss: 1.1558 (1.1067)  Acc@1: 68.7500 (70.7105)  Acc@5: 93.7500 (95.5357)  time: 0.4560  data: 0.0006  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:03:44  Loss: 1.0625 (1.1063)  Acc@1: 75.0000 (70.7344)  Acc@5: 93.7500 (95.5428)  time: 0.4539  data: 0.0005  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:03:41  Loss: 1.0625 (1.1057)  Acc@1: 75.0000 (70.7333)  Acc@5: 100.0000 (95.5558)  time: 0.4551  data: 0.0004  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:03:38  Loss: 0.9615 (1.1040)  Acc@1: 75.0000 (70.7929)  Acc@5: 100.0000 (95.5807)  time: 0.4546  data: 0.0004  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:03:34  Loss: 0.8121 (1.1022)  Acc@1: 75.0000 (70.8393)  Acc@5: 100.0000 (95.6112)  time: 0.4519  data: 0.0003  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:03:30  Loss: 0.9192 (1.1008)  Acc@1: 75.0000 (70.8908)  Acc@5: 100.0000 (95.6232)  time: 0.3671  data: 0.0003  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:03:26  Loss: 1.1137 (1.1014)  Acc@1: 68.7500 (70.8883)  Acc@5: 93.7500 (95.6056)  time: 0.2486  data: 0.0003  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:03:21  Loss: 1.1797 (1.1020)  Acc@1: 68.7500 (70.8742)  Acc@5: 93.7500 (95.5882)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:03:17  Loss: 1.1105 (1.1027)  Acc@1: 68.7500 (70.8950)  Acc@5: 93.7500 (95.5886)  time: 0.2158  data: 0.0003  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:03:13  Loss: 1.1105 (1.1028)  Acc@1: 75.0000 (70.9154)  Acc@5: 100.0000 (95.5946)  time: 0.2167  data: 0.0010  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:03:09  Loss: 0.9854 (1.1009)  Acc@1: 75.0000 (70.9639)  Acc@5: 100.0000 (95.6119)  time: 0.2177  data: 0.0011  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:03:04  Loss: 0.9529 (1.1010)  Acc@1: 75.0000 (70.9608)  Acc@5: 100.0000 (95.6177)  time: 0.2200  data: 0.0006  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:03:00  Loss: 1.1154 (1.1025)  Acc@1: 68.7500 (70.9077)  Acc@5: 100.0000 (95.6066)  time: 0.2229  data: 0.0018  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:02:56  Loss: 1.0399 (1.1030)  Acc@1: 68.7500 (70.8886)  Acc@5: 100.0000 (95.5957)  time: 0.2222  data: 0.0023  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:02:52  Loss: 1.0762 (1.1040)  Acc@1: 68.7500 (70.8534)  Acc@5: 93.7500 (95.5741)  time: 0.2191  data: 0.0011  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:02:48  Loss: 1.2386 (1.1045)  Acc@1: 68.7500 (70.8297)  Acc@5: 93.7500 (95.5745)  time: 0.2179  data: 0.0008  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:02:44  Loss: 1.1010 (1.1035)  Acc@1: 68.7500 (70.8872)  Acc@5: 100.0000 (95.5857)  time: 0.2203  data: 0.0012  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:02:40  Loss: 0.9944 (1.1026)  Acc@1: 75.0000 (70.9116)  Acc@5: 100.0000 (95.5914)  time: 0.2219  data: 0.0017  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:02:36  Loss: 1.0806 (1.1030)  Acc@1: 75.0000 (70.9304)  Acc@5: 93.7500 (95.5970)  time: 0.2240  data: 0.0019  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:02:32  Loss: 1.1416 (1.1038)  Acc@1: 68.7500 (70.8858)  Acc@5: 93.7500 (95.5919)  time: 0.2257  data: 0.0017  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:02:28  Loss: 1.1366 (1.1038)  Acc@1: 68.7500 (70.8888)  Acc@5: 100.0000 (95.5922)  time: 0.2251  data: 0.0012  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:02:24  Loss: 0.9715 (1.1045)  Acc@1: 75.0000 (70.8351)  Acc@5: 100.0000 (95.5976)  time: 0.2286  data: 0.0005  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:02:20  Loss: 0.8952 (1.1034)  Acc@1: 68.7500 (70.8538)  Acc@5: 100.0000 (95.6132)  time: 0.2248  data: 0.0004  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:02:16  Loss: 1.0529 (1.1038)  Acc@1: 68.7500 (70.8469)  Acc@5: 100.0000 (95.6184)  time: 0.2198  data: 0.0011  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:02:12  Loss: 1.1283 (1.1037)  Acc@1: 68.7500 (70.8300)  Acc@5: 100.0000 (95.6285)  time: 0.2222  data: 0.0012  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:02:09  Loss: 1.2296 (1.1041)  Acc@1: 68.7500 (70.8133)  Acc@5: 100.0000 (95.6235)  time: 0.2211  data: 0.0005  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:02:05  Loss: 1.1231 (1.1040)  Acc@1: 68.7500 (70.8119)  Acc@5: 100.0000 (95.6235)  time: 0.2711  data: 0.0008  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:02:02  Loss: 1.0223 (1.1048)  Acc@1: 68.7500 (70.7809)  Acc@5: 100.0000 (95.6235)  time: 0.3922  data: 0.0008  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:59  Loss: 0.9978 (1.1034)  Acc@1: 75.0000 (70.8138)  Acc@5: 93.7500 (95.6187)  time: 0.4630  data: 0.0004  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:56  Loss: 1.0319 (1.1035)  Acc@1: 75.0000 (70.7833)  Acc@5: 100.0000 (95.6284)  time: 0.4634  data: 0.0004  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:53  Loss: 1.0319 (1.1029)  Acc@1: 75.0000 (70.8061)  Acc@5: 100.0000 (95.6380)  time: 0.4613  data: 0.0003  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:49  Loss: 0.9070 (1.1018)  Acc@1: 75.0000 (70.8572)  Acc@5: 100.0000 (95.6379)  time: 0.4621  data: 0.0005  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:46  Loss: 0.8188 (1.1003)  Acc@1: 81.2500 (70.9217)  Acc@5: 100.0000 (95.6472)  time: 0.4649  data: 0.0005  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:43  Loss: 0.8858 (1.1000)  Acc@1: 75.0000 (70.9335)  Acc@5: 93.7500 (95.6330)  time: 0.4658  data: 0.0011  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:40  Loss: 1.0393 (1.1004)  Acc@1: 68.7500 (70.9265)  Acc@5: 93.7500 (95.6469)  time: 0.4635  data: 0.0018  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:37  Loss: 0.9371 (1.0996)  Acc@1: 75.0000 (70.9428)  Acc@5: 100.0000 (95.6514)  time: 0.4621  data: 0.0031  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:01:33  Loss: 0.9398 (1.0990)  Acc@1: 75.0000 (70.9359)  Acc@5: 100.0000 (95.6741)  time: 0.4622  data: 0.0035  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:01:30  Loss: 0.9801 (1.0983)  Acc@1: 68.7500 (70.9063)  Acc@5: 100.0000 (95.6875)  time: 0.4596  data: 0.0017  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:01:27  Loss: 1.0287 (1.0986)  Acc@1: 62.5000 (70.8771)  Acc@5: 100.0000 (95.6915)  time: 0.4586  data: 0.0021  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:01:23  Loss: 1.1381 (1.0982)  Acc@1: 68.7500 (70.8843)  Acc@5: 93.7500 (95.7000)  time: 0.4591  data: 0.0021  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:01:20  Loss: 1.0678 (1.0984)  Acc@1: 75.0000 (70.8913)  Acc@5: 93.7500 (95.6817)  time: 0.4618  data: 0.0015  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:01:17  Loss: 0.8699 (1.0977)  Acc@1: 81.2500 (70.9249)  Acc@5: 93.7500 (95.6945)  time: 0.4612  data: 0.0014  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:01:13  Loss: 0.9703 (1.0971)  Acc@1: 75.0000 (70.9316)  Acc@5: 100.0000 (95.7160)  time: 0.4613  data: 0.0004  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:01:10  Loss: 1.2143 (1.0989)  Acc@1: 68.7500 (70.9163)  Acc@5: 100.0000 (95.6805)  time: 0.4625  data: 0.0004  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:01:06  Loss: 1.0899 (1.0984)  Acc@1: 68.7500 (70.9230)  Acc@5: 93.7500 (95.6931)  time: 0.4613  data: 0.0003  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:01:03  Loss: 1.1343 (1.0998)  Acc@1: 68.7500 (70.8735)  Acc@5: 93.7500 (95.6754)  time: 0.4626  data: 0.0003  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:59  Loss: 1.2259 (1.1002)  Acc@1: 68.7500 (70.8462)  Acc@5: 93.7500 (95.6708)  time: 0.4618  data: 0.0003  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:56  Loss: 1.1516 (1.1006)  Acc@1: 68.7500 (70.8319)  Acc@5: 100.0000 (95.6662)  time: 0.4605  data: 0.0003  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:52  Loss: 1.1516 (1.1011)  Acc@1: 68.7500 (70.8179)  Acc@5: 100.0000 (95.6575)  time: 0.4612  data: 0.0003  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:49  Loss: 1.1123 (1.1015)  Acc@1: 68.7500 (70.8040)  Acc@5: 93.7500 (95.6531)  time: 0.4598  data: 0.0012  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:45  Loss: 1.0544 (1.1016)  Acc@1: 68.7500 (70.8236)  Acc@5: 93.7500 (95.6362)  time: 0.4560  data: 0.0014  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:42  Loss: 0.8796 (1.1014)  Acc@1: 68.7500 (70.8347)  Acc@5: 93.7500 (95.6320)  time: 0.4586  data: 0.0019  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:38  Loss: 0.9172 (1.1002)  Acc@1: 68.7500 (70.8621)  Acc@5: 100.0000 (95.6484)  time: 0.4605  data: 0.0019  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:35  Loss: 0.9395 (1.0998)  Acc@1: 68.7500 (70.8361)  Acc@5: 100.0000 (95.6524)  time: 0.4566  data: 0.0012  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:31  Loss: 0.8966 (1.0990)  Acc@1: 68.7500 (70.8509)  Acc@5: 100.0000 (95.6725)  time: 0.4570  data: 0.0011  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:28  Loss: 0.8967 (1.0987)  Acc@1: 75.0000 (70.8374)  Acc@5: 100.0000 (95.6721)  time: 0.4558  data: 0.0013  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:24  Loss: 0.8967 (1.0977)  Acc@1: 75.0000 (70.8800)  Acc@5: 100.0000 (95.6799)  time: 0.4559  data: 0.0017  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:20  Loss: 0.9548 (1.0974)  Acc@1: 75.0000 (70.9142)  Acc@5: 100.0000 (95.6795)  time: 0.4613  data: 0.0010  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:17  Loss: 0.9912 (1.0977)  Acc@1: 75.0000 (70.9084)  Acc@5: 100.0000 (95.6831)  time: 0.4641  data: 0.0004  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:13  Loss: 0.9817 (1.0974)  Acc@1: 68.7500 (70.9027)  Acc@5: 100.0000 (95.6945)  time: 0.4633  data: 0.0006  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:09  Loss: 1.0833 (1.0984)  Acc@1: 68.7500 (70.8542)  Acc@5: 100.0000 (95.6863)  time: 0.4578  data: 0.0006  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:06  Loss: 1.1750 (1.0978)  Acc@1: 68.7500 (70.8605)  Acc@5: 100.0000 (95.7053)  time: 0.4577  data: 0.0003  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:02  Loss: 0.8837 (1.0968)  Acc@1: 75.0000 (70.8937)  Acc@5: 100.0000 (95.7125)  time: 0.4579  data: 0.0003  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9092 (1.0963)  Acc@1: 75.0000 (70.9127)  Acc@5: 100.0000 (95.7130)  time: 0.4563  data: 0.0003  max mem: 2500
Test: [Task 1] Total time: 0:10:00 (0.3690 s / it)
* Acc@1 70.913 Acc@5 95.713 loss 1.096
Test: [Task 2]  [  0/625]  eta: 0:07:49  Loss: 0.1592 (0.1592)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7517  data: 0.2842  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:04:50  Loss: 0.1592 (0.2174)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (99.4318)  time: 0.4726  data: 0.0262  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:04:40  Loss: 0.1580 (0.2211)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (99.7024)  time: 0.4496  data: 0.0006  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:04:35  Loss: 0.1773 (0.2446)  Acc@1: 93.7500 (94.5565)  Acc@5: 100.0000 (99.3952)  time: 0.4568  data: 0.0008  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:04:29  Loss: 0.2570 (0.2439)  Acc@1: 93.7500 (94.3598)  Acc@5: 100.0000 (99.5427)  time: 0.4584  data: 0.0007  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:04:24  Loss: 0.2207 (0.2513)  Acc@1: 93.7500 (94.4853)  Acc@5: 100.0000 (99.6324)  time: 0.4556  data: 0.0007  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:04:19  Loss: 0.1982 (0.2526)  Acc@1: 93.7500 (94.1598)  Acc@5: 100.0000 (99.5902)  time: 0.4530  data: 0.0013  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:04:13  Loss: 0.2050 (0.2495)  Acc@1: 93.7500 (94.0141)  Acc@5: 100.0000 (99.6479)  time: 0.4500  data: 0.0012  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:04:08  Loss: 0.2302 (0.2570)  Acc@1: 93.7500 (93.9043)  Acc@5: 100.0000 (99.5370)  time: 0.4509  data: 0.0006  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:04:04  Loss: 0.2302 (0.2517)  Acc@1: 93.7500 (94.0934)  Acc@5: 100.0000 (99.5879)  time: 0.4560  data: 0.0009  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:04:00  Loss: 0.2014 (0.2497)  Acc@1: 100.0000 (94.1213)  Acc@5: 100.0000 (99.5668)  time: 0.4616  data: 0.0007  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:03:52  Loss: 0.1571 (0.2473)  Acc@1: 100.0000 (94.2568)  Acc@5: 100.0000 (99.6059)  time: 0.4313  data: 0.0004  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:03:48  Loss: 0.1785 (0.2468)  Acc@1: 93.7500 (94.3182)  Acc@5: 100.0000 (99.5868)  time: 0.4273  data: 0.0004  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:03:44  Loss: 0.1979 (0.2475)  Acc@1: 93.7500 (94.2748)  Acc@5: 100.0000 (99.6183)  time: 0.4567  data: 0.0003  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:03:39  Loss: 0.1922 (0.2499)  Acc@1: 93.7500 (94.0603)  Acc@5: 100.0000 (99.6011)  time: 0.4559  data: 0.0010  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:03:35  Loss: 0.1913 (0.2556)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.6275)  time: 0.4567  data: 0.0013  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:03:30  Loss: 0.2236 (0.2590)  Acc@1: 93.7500 (93.7112)  Acc@5: 100.0000 (99.5730)  time: 0.4581  data: 0.0017  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:03:25  Loss: 0.2283 (0.2597)  Acc@1: 93.7500 (93.6769)  Acc@5: 100.0000 (99.5614)  time: 0.4412  data: 0.0016  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:03:15  Loss: 0.2283 (0.2591)  Acc@1: 93.7500 (93.7155)  Acc@5: 100.0000 (99.5511)  time: 0.3214  data: 0.0006  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:03:07  Loss: 0.2258 (0.2612)  Acc@1: 93.7500 (93.6846)  Acc@5: 100.0000 (99.5419)  time: 0.2519  data: 0.0005  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:03:03  Loss: 0.1931 (0.2591)  Acc@1: 93.7500 (93.7189)  Acc@5: 100.0000 (99.5647)  time: 0.3694  data: 0.0007  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:02:59  Loss: 0.1816 (0.2591)  Acc@1: 93.7500 (93.6908)  Acc@5: 100.0000 (99.5853)  time: 0.4550  data: 0.0008  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:02:56  Loss: 0.1653 (0.2574)  Acc@1: 93.7500 (93.7783)  Acc@5: 100.0000 (99.6041)  time: 0.4609  data: 0.0007  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:02:52  Loss: 0.2193 (0.2562)  Acc@1: 100.0000 (93.8853)  Acc@5: 100.0000 (99.6212)  time: 0.4595  data: 0.0006  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:02:48  Loss: 0.2623 (0.2572)  Acc@1: 93.7500 (93.9315)  Acc@5: 100.0000 (99.6369)  time: 0.4551  data: 0.0008  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:02:43  Loss: 0.2800 (0.2602)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.6016)  time: 0.4529  data: 0.0006  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:02:39  Loss: 0.2936 (0.2626)  Acc@1: 93.7500 (93.7261)  Acc@5: 100.0000 (99.5929)  time: 0.4511  data: 0.0004  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:02:35  Loss: 0.2741 (0.2625)  Acc@1: 93.7500 (93.6808)  Acc@5: 100.0000 (99.6079)  time: 0.4526  data: 0.0004  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:02:31  Loss: 0.2741 (0.2643)  Acc@1: 93.7500 (93.5721)  Acc@5: 100.0000 (99.5774)  time: 0.4546  data: 0.0004  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:02:27  Loss: 0.2252 (0.2642)  Acc@1: 93.7500 (93.5137)  Acc@5: 100.0000 (99.5919)  time: 0.4563  data: 0.0009  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:02:22  Loss: 0.2252 (0.2639)  Acc@1: 93.7500 (93.5008)  Acc@5: 100.0000 (99.6055)  time: 0.4534  data: 0.0009  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:02:18  Loss: 0.2415 (0.2653)  Acc@1: 93.7500 (93.4686)  Acc@5: 100.0000 (99.5981)  time: 0.4546  data: 0.0004  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:02:14  Loss: 0.1043 (0.2592)  Acc@1: 93.7500 (93.6332)  Acc@5: 100.0000 (99.6106)  time: 0.4529  data: 0.0009  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:02:10  Loss: 0.0895 (0.2552)  Acc@1: 100.0000 (93.7689)  Acc@5: 100.0000 (99.6224)  time: 0.4500  data: 0.0012  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:02:05  Loss: 0.0741 (0.2493)  Acc@1: 100.0000 (93.9516)  Acc@5: 100.0000 (99.6334)  time: 0.4473  data: 0.0008  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:02:01  Loss: 0.0528 (0.2454)  Acc@1: 100.0000 (94.0349)  Acc@5: 100.0000 (99.6439)  time: 0.4468  data: 0.0008  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:01:56  Loss: 0.1511 (0.2463)  Acc@1: 93.7500 (94.0270)  Acc@5: 100.0000 (99.6364)  time: 0.4489  data: 0.0014  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:01:52  Loss: 0.1747 (0.2433)  Acc@1: 93.7500 (94.1206)  Acc@5: 100.0000 (99.6462)  time: 0.4460  data: 0.0012  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:01:48  Loss: 0.1990 (0.2461)  Acc@1: 93.7500 (94.0781)  Acc@5: 100.0000 (99.6063)  time: 0.4454  data: 0.0006  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:01:43  Loss: 0.1882 (0.2453)  Acc@1: 93.7500 (94.0377)  Acc@5: 100.0000 (99.6004)  time: 0.4501  data: 0.0005  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:01:39  Loss: 0.0697 (0.2415)  Acc@1: 100.0000 (94.1397)  Acc@5: 100.0000 (99.6103)  time: 0.4529  data: 0.0004  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:01:35  Loss: 0.0559 (0.2395)  Acc@1: 100.0000 (94.2214)  Acc@5: 100.0000 (99.6046)  time: 0.4547  data: 0.0007  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:01:30  Loss: 0.0750 (0.2384)  Acc@1: 100.0000 (94.2696)  Acc@5: 100.0000 (99.6140)  time: 0.4519  data: 0.0007  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:01:26  Loss: 0.1021 (0.2359)  Acc@1: 100.0000 (94.3590)  Acc@5: 100.0000 (99.6230)  time: 0.4478  data: 0.0004  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:01:21  Loss: 0.0652 (0.2318)  Acc@1: 100.0000 (94.4870)  Acc@5: 100.0000 (99.6315)  time: 0.4490  data: 0.0004  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:01:17  Loss: 0.0566 (0.2284)  Acc@1: 100.0000 (94.5538)  Acc@5: 100.0000 (99.6397)  time: 0.4523  data: 0.0007  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:01:13  Loss: 0.0582 (0.2253)  Acc@1: 100.0000 (94.6448)  Acc@5: 100.0000 (99.6475)  time: 0.4541  data: 0.0005  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:01:08  Loss: 0.0942 (0.2230)  Acc@1: 100.0000 (94.7452)  Acc@5: 100.0000 (99.6550)  time: 0.4481  data: 0.0005  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:01:04  Loss: 0.1052 (0.2215)  Acc@1: 100.0000 (94.8155)  Acc@5: 100.0000 (99.6622)  time: 0.4440  data: 0.0005  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:59  Loss: 0.1076 (0.2195)  Acc@1: 100.0000 (94.8956)  Acc@5: 100.0000 (99.6690)  time: 0.4462  data: 0.0020  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:55  Loss: 0.0899 (0.2174)  Acc@1: 100.0000 (94.9726)  Acc@5: 100.0000 (99.6756)  time: 0.4492  data: 0.0023  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:51  Loss: 0.1365 (0.2183)  Acc@1: 100.0000 (94.8875)  Acc@5: 100.0000 (99.6820)  time: 0.4472  data: 0.0020  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:46  Loss: 0.1499 (0.2176)  Acc@1: 93.7500 (94.9136)  Acc@5: 100.0000 (99.6881)  time: 0.4459  data: 0.0018  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:42  Loss: 0.1291 (0.2158)  Acc@1: 100.0000 (94.9506)  Acc@5: 100.0000 (99.6940)  time: 0.4519  data: 0.0005  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:37  Loss: 0.0971 (0.2142)  Acc@1: 100.0000 (95.0208)  Acc@5: 100.0000 (99.6996)  time: 0.4526  data: 0.0006  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:33  Loss: 0.0556 (0.2112)  Acc@1: 100.0000 (95.1112)  Acc@5: 100.0000 (99.7051)  time: 0.4498  data: 0.0005  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:28  Loss: 0.0379 (0.2081)  Acc@1: 100.0000 (95.1983)  Acc@5: 100.0000 (99.7103)  time: 0.4504  data: 0.0006  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:24  Loss: 0.0380 (0.2070)  Acc@1: 100.0000 (95.2277)  Acc@5: 100.0000 (99.7154)  time: 0.4501  data: 0.0006  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:20  Loss: 0.0610 (0.2047)  Acc@1: 100.0000 (95.2883)  Acc@5: 100.0000 (99.7203)  time: 0.4498  data: 0.0006  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:15  Loss: 0.0704 (0.2038)  Acc@1: 93.7500 (95.2623)  Acc@5: 100.0000 (99.7250)  time: 0.4486  data: 0.0006  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:11  Loss: 0.1341 (0.2036)  Acc@1: 93.7500 (95.2371)  Acc@5: 100.0000 (99.7296)  time: 0.4472  data: 0.0004  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:06  Loss: 0.2346 (0.2058)  Acc@1: 93.7500 (95.1923)  Acc@5: 100.0000 (99.6931)  time: 0.4460  data: 0.0004  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:02  Loss: 0.2467 (0.2060)  Acc@1: 93.7500 (95.1993)  Acc@5: 100.0000 (99.6981)  time: 0.4430  data: 0.0003  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2227 (0.2057)  Acc@1: 93.7500 (95.2100)  Acc@5: 100.0000 (99.7000)  time: 0.4475  data: 0.0003  max mem: 2500
Test: [Task 2] Total time: 0:04:38 (0.4451 s / it)
* Acc@1 95.210 Acc@5 99.700 loss 0.206
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task2]	Acc@1: 83.0614	Acc@5: 97.7065	Loss: 0.6510	Forgetting: 15.0738	Backward: -15.0738
Train: Epoch[1/5]  [   0/3125]  eta: 1:14:20  Lr: 0.001875  Loss: 2.2953  Acc@1: 12.5000 (12.5000)  Acc@5: 43.7500 (43.7500)  time: 1.4275  data: 0.7171  max mem: 2500
Train: Epoch[1/5]  [  10/3125]  eta: 0:40:44  Lr: 0.001875  Loss: 2.1321  Acc@1: 25.0000 (26.7045)  Acc@5: 62.5000 (63.0682)  time: 0.7849  data: 0.0659  max mem: 2502
Train: Epoch[1/5]  [  20/3125]  eta: 0:37:28  Lr: 0.001875  Loss: 1.9949  Acc@1: 37.5000 (39.2857)  Acc@5: 75.0000 (74.7024)  time: 0.6891  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [  30/3125]  eta: 0:31:15  Lr: 0.001875  Loss: 1.7190  Acc@1: 50.0000 (43.3468)  Acc@5: 87.5000 (78.8306)  time: 0.5076  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [  40/3125]  eta: 0:28:02  Lr: 0.001875  Loss: 1.3620  Acc@1: 56.2500 (48.3232)  Acc@5: 87.5000 (81.7073)  time: 0.3578  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [  50/3125]  eta: 0:25:59  Lr: 0.001875  Loss: 1.1560  Acc@1: 68.7500 (53.3088)  Acc@5: 93.7500 (84.5588)  time: 0.3543  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [  60/3125]  eta: 0:24:39  Lr: 0.001875  Loss: 1.4678  Acc@1: 68.7500 (54.7131)  Acc@5: 93.7500 (85.4508)  time: 0.3540  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [  70/3125]  eta: 0:23:39  Lr: 0.001875  Loss: 1.2443  Acc@1: 68.7500 (56.9542)  Acc@5: 93.7500 (86.7958)  time: 0.3556  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [  80/3125]  eta: 0:22:52  Lr: 0.001875  Loss: 0.7953  Acc@1: 68.7500 (58.2562)  Acc@5: 93.7500 (87.8086)  time: 0.3530  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  90/3125]  eta: 0:22:15  Lr: 0.001875  Loss: 0.7618  Acc@1: 68.7500 (59.0659)  Acc@5: 93.7500 (88.4615)  time: 0.3525  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 100/3125]  eta: 0:21:44  Lr: 0.001875  Loss: 0.6758  Acc@1: 68.7500 (61.0767)  Acc@5: 93.7500 (89.0470)  time: 0.3526  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 110/3125]  eta: 0:21:19  Lr: 0.001875  Loss: 0.9976  Acc@1: 75.0000 (62.1059)  Acc@5: 93.7500 (89.6959)  time: 0.3527  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 120/3125]  eta: 0:20:57  Lr: 0.001875  Loss: 0.6409  Acc@1: 68.7500 (62.8616)  Acc@5: 93.7500 (90.1343)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 130/3125]  eta: 0:20:37  Lr: 0.001875  Loss: 0.7232  Acc@1: 68.7500 (63.1679)  Acc@5: 93.7500 (90.3149)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 140/3125]  eta: 0:20:20  Lr: 0.001875  Loss: 0.5537  Acc@1: 68.7500 (63.7411)  Acc@5: 93.7500 (90.7358)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 150/3125]  eta: 0:20:05  Lr: 0.001875  Loss: 0.1171  Acc@1: 75.0000 (64.5695)  Acc@5: 100.0000 (91.1010)  time: 0.3527  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [ 160/3125]  eta: 0:19:51  Lr: 0.001875  Loss: 0.3624  Acc@1: 75.0000 (65.0621)  Acc@5: 93.7500 (91.3043)  time: 0.3532  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [ 170/3125]  eta: 0:19:39  Lr: 0.001875  Loss: 0.3906  Acc@1: 75.0000 (65.8626)  Acc@5: 93.7500 (91.7032)  time: 0.3522  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 180/3125]  eta: 0:19:27  Lr: 0.001875  Loss: 0.6835  Acc@1: 81.2500 (66.6091)  Acc@5: 100.0000 (92.0235)  time: 0.3527  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 190/3125]  eta: 0:19:16  Lr: 0.001875  Loss: 0.4169  Acc@1: 75.0000 (66.6558)  Acc@5: 100.0000 (92.1466)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 200/3125]  eta: 0:19:05  Lr: 0.001875  Loss: 0.5507  Acc@1: 75.0000 (67.2886)  Acc@5: 100.0000 (92.5062)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 210/3125]  eta: 0:18:55  Lr: 0.001875  Loss: 0.2178  Acc@1: 75.0000 (67.6540)  Acc@5: 100.0000 (92.7725)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 220/3125]  eta: 0:18:47  Lr: 0.001875  Loss: 0.4423  Acc@1: 75.0000 (68.0430)  Acc@5: 100.0000 (93.0147)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 230/3125]  eta: 0:18:39  Lr: 0.001875  Loss: 0.1044  Acc@1: 75.0000 (68.3983)  Acc@5: 100.0000 (93.1548)  time: 0.3549  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 240/3125]  eta: 0:18:31  Lr: 0.001875  Loss: 0.3287  Acc@1: 81.2500 (68.8278)  Acc@5: 100.0000 (93.3351)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 250/3125]  eta: 0:18:24  Lr: 0.001875  Loss: 0.4324  Acc@1: 81.2500 (69.0986)  Acc@5: 100.0000 (93.4512)  time: 0.3536  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 260/3125]  eta: 0:18:16  Lr: 0.001875  Loss: 0.1183  Acc@1: 81.2500 (69.4923)  Acc@5: 100.0000 (93.6063)  time: 0.3545  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 270/3125]  eta: 0:18:09  Lr: 0.001875  Loss: 0.1815  Acc@1: 81.2500 (69.6956)  Acc@5: 93.7500 (93.6808)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 280/3125]  eta: 0:18:03  Lr: 0.001875  Loss: 0.4490  Acc@1: 68.7500 (69.5952)  Acc@5: 93.7500 (93.7722)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 290/3125]  eta: 0:17:57  Lr: 0.001875  Loss: 0.0273  Acc@1: 68.7500 (69.7380)  Acc@5: 100.0000 (93.8789)  time: 0.3566  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 300/3125]  eta: 0:17:51  Lr: 0.001875  Loss: 0.1061  Acc@1: 75.0000 (69.8920)  Acc@5: 100.0000 (93.9576)  time: 0.3578  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 310/3125]  eta: 0:17:45  Lr: 0.001875  Loss: 0.4660  Acc@1: 75.0000 (70.0362)  Acc@5: 100.0000 (94.0314)  time: 0.3534  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 320/3125]  eta: 0:17:39  Lr: 0.001875  Loss: 0.1932  Acc@1: 75.0000 (70.2492)  Acc@5: 100.0000 (94.1199)  time: 0.3529  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 330/3125]  eta: 0:17:33  Lr: 0.001875  Loss: 0.7169  Acc@1: 81.2500 (70.6193)  Acc@5: 100.0000 (94.2221)  time: 0.3528  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 340/3125]  eta: 0:17:28  Lr: 0.001875  Loss: -0.3347  Acc@1: 75.0000 (70.6928)  Acc@5: 100.0000 (94.2632)  time: 0.3600  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 350/3125]  eta: 0:17:23  Lr: 0.001875  Loss: 0.0458  Acc@1: 75.0000 (70.9224)  Acc@5: 100.0000 (94.3554)  time: 0.3625  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 360/3125]  eta: 0:17:17  Lr: 0.001875  Loss: 0.3428  Acc@1: 81.2500 (71.1738)  Acc@5: 100.0000 (94.3906)  time: 0.3537  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 370/3125]  eta: 0:17:12  Lr: 0.001875  Loss: 0.4187  Acc@1: 81.2500 (71.4286)  Acc@5: 93.7500 (94.3733)  time: 0.3523  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 380/3125]  eta: 0:17:08  Lr: 0.001875  Loss: -0.2608  Acc@1: 81.2500 (71.7520)  Acc@5: 93.7500 (94.4390)  time: 0.3619  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 390/3125]  eta: 0:17:03  Lr: 0.001875  Loss: 0.3640  Acc@1: 81.2500 (71.9309)  Acc@5: 93.7500 (94.4214)  time: 0.3629  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 400/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.0855  Acc@1: 81.2500 (72.1789)  Acc@5: 93.7500 (94.4670)  time: 0.3528  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 410/3125]  eta: 0:16:54  Lr: 0.001875  Loss: 0.0295  Acc@1: 81.2500 (72.4605)  Acc@5: 100.0000 (94.5408)  time: 0.3619  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 420/3125]  eta: 0:16:48  Lr: 0.001875  Loss: 0.2614  Acc@1: 81.2500 (72.5505)  Acc@5: 100.0000 (94.5814)  time: 0.3609  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 430/3125]  eta: 0:16:43  Lr: 0.001875  Loss: -0.1320  Acc@1: 75.0000 (72.7523)  Acc@5: 100.0000 (94.6346)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 440/3125]  eta: 0:16:38  Lr: 0.001875  Loss: 0.2645  Acc@1: 75.0000 (72.7891)  Acc@5: 100.0000 (94.6712)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 450/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.1492  Acc@1: 75.0000 (72.9629)  Acc@5: 100.0000 (94.7339)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 460/3125]  eta: 0:16:28  Lr: 0.001875  Loss: -0.1220  Acc@1: 75.0000 (72.9935)  Acc@5: 100.0000 (94.8075)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 470/3125]  eta: 0:16:23  Lr: 0.001875  Loss: 0.0213  Acc@1: 75.0000 (73.0494)  Acc@5: 100.0000 (94.8912)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 480/3125]  eta: 0:16:19  Lr: 0.001875  Loss: 0.0674  Acc@1: 81.2500 (73.1939)  Acc@5: 100.0000 (94.9584)  time: 0.3530  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 490/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.3371  Acc@1: 81.2500 (73.3707)  Acc@5: 100.0000 (95.0229)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 500/3125]  eta: 0:16:09  Lr: 0.001875  Loss: -0.2182  Acc@1: 81.2500 (73.4905)  Acc@5: 100.0000 (95.1223)  time: 0.3527  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 510/3125]  eta: 0:16:05  Lr: 0.001875  Loss: -0.5378  Acc@1: 81.2500 (73.5934)  Acc@5: 100.0000 (95.1688)  time: 0.3545  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 520/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.3575  Acc@1: 81.2500 (73.7044)  Acc@5: 100.0000 (95.2135)  time: 0.3605  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 530/3125]  eta: 0:15:57  Lr: 0.001875  Loss: 0.0724  Acc@1: 81.2500 (73.7641)  Acc@5: 100.0000 (95.2566)  time: 0.3592  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 540/3125]  eta: 0:15:53  Lr: 0.001875  Loss: 0.0742  Acc@1: 81.2500 (73.8563)  Acc@5: 100.0000 (95.3096)  time: 0.3646  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 550/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.0985  Acc@1: 81.2500 (73.9338)  Acc@5: 93.7500 (95.3153)  time: 0.3648  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [ 560/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.4199  Acc@1: 81.2500 (74.0642)  Acc@5: 93.7500 (95.3543)  time: 0.3546  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 570/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.4185  Acc@1: 81.2500 (74.1353)  Acc@5: 100.0000 (95.3809)  time: 0.3581  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 580/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.3161  Acc@1: 81.2500 (74.2577)  Acc@5: 100.0000 (95.4281)  time: 0.3782  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 590/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.3171  Acc@1: 75.0000 (74.3232)  Acc@5: 100.0000 (95.4315)  time: 0.3730  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 600/3125]  eta: 0:15:29  Lr: 0.001875  Loss: -0.0589  Acc@1: 75.0000 (74.3864)  Acc@5: 93.7500 (95.4659)  time: 0.3523  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 610/3125]  eta: 0:15:25  Lr: 0.001875  Loss: -0.3895  Acc@1: 75.0000 (74.5192)  Acc@5: 100.0000 (95.5196)  time: 0.3540  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 620/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.3152  Acc@1: 75.0000 (74.4968)  Acc@5: 100.0000 (95.5515)  time: 0.3577  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [ 630/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.2842  Acc@1: 75.0000 (74.5246)  Acc@5: 100.0000 (95.6121)  time: 0.3562  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [ 640/3125]  eta: 0:15:12  Lr: 0.001875  Loss: 0.1220  Acc@1: 75.0000 (74.5710)  Acc@5: 100.0000 (95.6416)  time: 0.3512  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 650/3125]  eta: 0:15:08  Lr: 0.001875  Loss: -0.4438  Acc@1: 81.2500 (74.6448)  Acc@5: 100.0000 (95.6509)  time: 0.3507  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 660/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.0795  Acc@1: 75.0000 (74.6502)  Acc@5: 93.7500 (95.6505)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 670/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.3060  Acc@1: 81.2500 (74.7765)  Acc@5: 100.0000 (95.6967)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 680/3125]  eta: 0:14:55  Lr: 0.001875  Loss: -0.3495  Acc@1: 81.2500 (74.8990)  Acc@5: 100.0000 (95.7232)  time: 0.3521  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 690/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.2351  Acc@1: 81.2500 (74.9548)  Acc@5: 100.0000 (95.7399)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 700/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.1410  Acc@1: 81.2500 (75.0178)  Acc@5: 93.7500 (95.7471)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 710/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.2500  Acc@1: 81.2500 (75.1055)  Acc@5: 100.0000 (95.7718)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 720/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.3673  Acc@1: 81.2500 (75.2080)  Acc@5: 100.0000 (95.7958)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 730/3125]  eta: 0:14:35  Lr: 0.001875  Loss: -0.3281  Acc@1: 81.2500 (75.3334)  Acc@5: 100.0000 (95.8276)  time: 0.3528  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 740/3125]  eta: 0:14:31  Lr: 0.001875  Loss: -0.5632  Acc@1: 81.2500 (75.3458)  Acc@5: 100.0000 (95.8586)  time: 0.3616  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 750/3125]  eta: 0:14:27  Lr: 0.001875  Loss: -0.2270  Acc@1: 81.2500 (75.4328)  Acc@5: 100.0000 (95.8722)  time: 0.3603  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 760/3125]  eta: 0:14:23  Lr: 0.001875  Loss: -0.0749  Acc@1: 81.2500 (75.4928)  Acc@5: 100.0000 (95.8443)  time: 0.3525  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 770/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.1649  Acc@1: 81.2500 (75.5350)  Acc@5: 100.0000 (95.8820)  time: 0.3574  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 780/3125]  eta: 0:14:17  Lr: 0.001875  Loss: -0.4765  Acc@1: 81.2500 (75.6162)  Acc@5: 100.0000 (95.9027)  time: 0.3778  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 790/3125]  eta: 0:14:13  Lr: 0.001875  Loss: -0.0927  Acc@1: 81.2500 (75.6953)  Acc@5: 100.0000 (95.9466)  time: 0.3730  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 800/3125]  eta: 0:14:09  Lr: 0.001875  Loss: -0.5142  Acc@1: 81.2500 (75.7803)  Acc@5: 100.0000 (95.9582)  time: 0.3531  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 810/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.1539  Acc@1: 81.2500 (75.8169)  Acc@5: 93.7500 (95.9618)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 820/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.2936  Acc@1: 75.0000 (75.8374)  Acc@5: 100.0000 (95.9881)  time: 0.3538  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 830/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.5014  Acc@1: 81.2500 (75.8950)  Acc@5: 100.0000 (96.0138)  time: 0.3530  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 840/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.5904  Acc@1: 81.2500 (75.9661)  Acc@5: 100.0000 (96.0166)  time: 0.3523  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 850/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.5936  Acc@1: 81.2500 (75.9988)  Acc@5: 93.7500 (96.0047)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 860/3125]  eta: 0:13:45  Lr: 0.001875  Loss: -0.4145  Acc@1: 75.0000 (76.0090)  Acc@5: 93.7500 (96.0221)  time: 0.3606  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 870/3125]  eta: 0:13:41  Lr: 0.001875  Loss: -0.3415  Acc@1: 81.2500 (76.0476)  Acc@5: 100.0000 (96.0103)  time: 0.3650  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 880/3125]  eta: 0:13:38  Lr: 0.001875  Loss: -0.3711  Acc@1: 81.2500 (76.0641)  Acc@5: 100.0000 (96.0201)  time: 0.3593  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 890/3125]  eta: 0:13:34  Lr: 0.001875  Loss: 0.0192  Acc@1: 81.2500 (76.0732)  Acc@5: 93.7500 (96.0157)  time: 0.3535  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 900/3125]  eta: 0:13:31  Lr: 0.001875  Loss: -0.2444  Acc@1: 81.2500 (76.0821)  Acc@5: 93.7500 (96.0252)  time: 0.3792  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 910/3125]  eta: 0:13:27  Lr: 0.001875  Loss: -0.6155  Acc@1: 81.2500 (76.1046)  Acc@5: 100.0000 (96.0346)  time: 0.3786  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 920/3125]  eta: 0:13:23  Lr: 0.001875  Loss: -0.3957  Acc@1: 81.2500 (76.1740)  Acc@5: 100.0000 (96.0641)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 930/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.2056  Acc@1: 87.5000 (76.2755)  Acc@5: 100.0000 (96.0795)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 940/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.4869  Acc@1: 87.5000 (76.3350)  Acc@5: 100.0000 (96.1145)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 950/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4061  Acc@1: 81.2500 (76.3736)  Acc@5: 100.0000 (96.1291)  time: 0.3532  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 960/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.5441  Acc@1: 81.2500 (76.4113)  Acc@5: 100.0000 (96.1498)  time: 0.3528  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 970/3125]  eta: 0:13:03  Lr: 0.001875  Loss: -0.5942  Acc@1: 81.2500 (76.5448)  Acc@5: 100.0000 (96.1766)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 980/3125]  eta: 0:12:59  Lr: 0.001875  Loss: -0.4813  Acc@1: 87.5000 (76.5736)  Acc@5: 100.0000 (96.1901)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 990/3125]  eta: 0:12:56  Lr: 0.001875  Loss: -0.3830  Acc@1: 81.2500 (76.6019)  Acc@5: 100.0000 (96.1844)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1000/3125]  eta: 0:12:52  Lr: 0.001875  Loss: -0.4513  Acc@1: 81.2500 (76.6608)  Acc@5: 93.7500 (96.1726)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1010/3125]  eta: 0:12:48  Lr: 0.001875  Loss: -0.4721  Acc@1: 81.2500 (76.6815)  Acc@5: 100.0000 (96.1981)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1020/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.7129  Acc@1: 81.2500 (76.7507)  Acc@5: 100.0000 (96.2047)  time: 0.3551  data: 0.0025  max mem: 2502
Train: Epoch[1/5]  [1030/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.2306  Acc@1: 81.2500 (76.8247)  Acc@5: 100.0000 (96.2173)  time: 0.3551  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [1040/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.5338  Acc@1: 81.2500 (76.8492)  Acc@5: 100.0000 (96.2356)  time: 0.3532  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1050/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.5350  Acc@1: 81.2500 (76.8792)  Acc@5: 100.0000 (96.2536)  time: 0.3522  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1060/3125]  eta: 0:12:29  Lr: 0.001875  Loss: 0.0455  Acc@1: 81.2500 (76.9557)  Acc@5: 100.0000 (96.2712)  time: 0.3532  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [1070/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.3455  Acc@1: 81.2500 (76.9841)  Acc@5: 100.0000 (96.2885)  time: 0.3555  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [1080/3125]  eta: 0:12:21  Lr: 0.001875  Loss: -0.3203  Acc@1: 81.2500 (77.0236)  Acc@5: 100.0000 (96.3228)  time: 0.3563  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1090/3125]  eta: 0:12:17  Lr: 0.001875  Loss: -0.4406  Acc@1: 81.2500 (77.0795)  Acc@5: 100.0000 (96.3394)  time: 0.3547  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1100/3125]  eta: 0:12:14  Lr: 0.001875  Loss: -0.2401  Acc@1: 81.2500 (77.1060)  Acc@5: 100.0000 (96.3499)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1110/3125]  eta: 0:12:10  Lr: 0.001875  Loss: -0.0234  Acc@1: 81.2500 (77.1321)  Acc@5: 100.0000 (96.3546)  time: 0.3530  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1120/3125]  eta: 0:12:06  Lr: 0.001875  Loss: -0.2466  Acc@1: 81.2500 (77.1577)  Acc@5: 100.0000 (96.3704)  time: 0.3538  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1130/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.5008  Acc@1: 81.2500 (77.1828)  Acc@5: 100.0000 (96.3638)  time: 0.3542  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1140/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.3434  Acc@1: 81.2500 (77.1965)  Acc@5: 100.0000 (96.3738)  time: 0.3543  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1150/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.1315  Acc@1: 81.2500 (77.2480)  Acc@5: 100.0000 (96.3890)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1160/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.2332  Acc@1: 87.5000 (77.3094)  Acc@5: 100.0000 (96.3932)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1170/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.4524  Acc@1: 87.5000 (77.3538)  Acc@5: 100.0000 (96.4080)  time: 0.3520  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1180/3125]  eta: 0:11:43  Lr: 0.001875  Loss: -0.7376  Acc@1: 87.5000 (77.3815)  Acc@5: 100.0000 (96.4172)  time: 0.3529  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1190/3125]  eta: 0:11:39  Lr: 0.001875  Loss: -0.6916  Acc@1: 87.5000 (77.4769)  Acc@5: 100.0000 (96.4316)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1200/3125]  eta: 0:11:36  Lr: 0.001875  Loss: -0.7283  Acc@1: 81.2500 (77.5187)  Acc@5: 100.0000 (96.4353)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1210/3125]  eta: 0:11:32  Lr: 0.001875  Loss: -0.4296  Acc@1: 81.2500 (77.5754)  Acc@5: 100.0000 (96.4441)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1220/3125]  eta: 0:11:28  Lr: 0.001875  Loss: -0.8474  Acc@1: 81.2500 (77.6259)  Acc@5: 100.0000 (96.4527)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1230/3125]  eta: 0:11:24  Lr: 0.001875  Loss: -0.4822  Acc@1: 87.5000 (77.6757)  Acc@5: 100.0000 (96.4764)  time: 0.3497  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1240/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.0676  Acc@1: 81.2500 (77.6692)  Acc@5: 100.0000 (96.4797)  time: 0.3497  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [1250/3125]  eta: 0:11:17  Lr: 0.001875  Loss: -0.5120  Acc@1: 81.2500 (77.6878)  Acc@5: 100.0000 (96.4778)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1260/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.5505  Acc@1: 87.5000 (77.7706)  Acc@5: 93.7500 (96.4760)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1270/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.6742  Acc@1: 87.5000 (77.7931)  Acc@5: 100.0000 (96.4841)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1280/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.4973  Acc@1: 81.2500 (77.8201)  Acc@5: 100.0000 (96.4871)  time: 0.3546  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1290/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.3734  Acc@1: 81.2500 (77.8369)  Acc@5: 100.0000 (96.4950)  time: 0.3552  data: 0.0022  max mem: 2502
Train: Epoch[1/5]  [1300/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.3698  Acc@1: 81.2500 (77.8584)  Acc@5: 100.0000 (96.5075)  time: 0.3534  data: 0.0021  max mem: 2502
Train: Epoch[1/5]  [1310/3125]  eta: 0:10:54  Lr: 0.001875  Loss: -0.2466  Acc@1: 81.2500 (77.9176)  Acc@5: 100.0000 (96.5198)  time: 0.3522  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1320/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.5929  Acc@1: 81.2500 (77.9381)  Acc@5: 100.0000 (96.5273)  time: 0.3543  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1330/3125]  eta: 0:10:47  Lr: 0.001875  Loss: -0.8193  Acc@1: 87.5000 (78.0334)  Acc@5: 100.0000 (96.5486)  time: 0.3560  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1340/3125]  eta: 0:10:43  Lr: 0.001875  Loss: -0.7401  Acc@1: 87.5000 (78.0714)  Acc@5: 100.0000 (96.5604)  time: 0.3558  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1350/3125]  eta: 0:10:40  Lr: 0.001875  Loss: -0.3214  Acc@1: 81.2500 (78.0949)  Acc@5: 100.0000 (96.5627)  time: 0.3532  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1360/3125]  eta: 0:10:36  Lr: 0.001875  Loss: -0.5183  Acc@1: 81.2500 (78.0952)  Acc@5: 93.7500 (96.5650)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1370/3125]  eta: 0:10:32  Lr: 0.001875  Loss: -0.5488  Acc@1: 81.2500 (78.1683)  Acc@5: 100.0000 (96.5810)  time: 0.3530  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1380/3125]  eta: 0:10:28  Lr: 0.001875  Loss: -0.6294  Acc@1: 87.5000 (78.2042)  Acc@5: 100.0000 (96.6057)  time: 0.3529  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1390/3125]  eta: 0:10:25  Lr: 0.001875  Loss: -0.1622  Acc@1: 81.2500 (78.1902)  Acc@5: 100.0000 (96.6256)  time: 0.3544  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1400/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.2233  Acc@1: 81.2500 (78.2388)  Acc@5: 100.0000 (96.6363)  time: 0.3538  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1410/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.4079  Acc@1: 81.2500 (78.2557)  Acc@5: 100.0000 (96.6380)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1420/3125]  eta: 0:10:14  Lr: 0.001875  Loss: -0.7497  Acc@1: 81.2500 (78.2943)  Acc@5: 100.0000 (96.6397)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1430/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.0445  Acc@1: 81.2500 (78.2888)  Acc@5: 93.7500 (96.6282)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1440/3125]  eta: 0:10:06  Lr: 0.001875  Loss: 0.0339  Acc@1: 75.0000 (78.2876)  Acc@5: 93.7500 (96.6299)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1450/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.4355  Acc@1: 81.2500 (78.3339)  Acc@5: 100.0000 (96.6402)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1460/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.5850  Acc@1: 81.2500 (78.3496)  Acc@5: 100.0000 (96.6461)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1470/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.3896  Acc@1: 81.2500 (78.3906)  Acc@5: 100.0000 (96.6647)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1480/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.7307  Acc@1: 81.2500 (78.3761)  Acc@5: 100.0000 (96.6577)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1490/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.3032  Acc@1: 81.2500 (78.3954)  Acc@5: 93.7500 (96.6549)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1500/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.5670  Acc@1: 81.2500 (78.4061)  Acc@5: 100.0000 (96.6606)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1510/3125]  eta: 0:09:40  Lr: 0.001875  Loss: -0.4686  Acc@1: 81.2500 (78.4207)  Acc@5: 100.0000 (96.6620)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1520/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.3553  Acc@1: 81.2500 (78.4517)  Acc@5: 100.0000 (96.6593)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1530/3125]  eta: 0:09:33  Lr: 0.001875  Loss: -0.3393  Acc@1: 81.2500 (78.4618)  Acc@5: 100.0000 (96.6688)  time: 0.3540  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1540/3125]  eta: 0:09:29  Lr: 0.001875  Loss: -0.2633  Acc@1: 81.2500 (78.4961)  Acc@5: 100.0000 (96.6742)  time: 0.3536  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1550/3125]  eta: 0:09:26  Lr: 0.001875  Loss: -0.4348  Acc@1: 81.2500 (78.5260)  Acc@5: 100.0000 (96.6917)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1560/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.4832  Acc@1: 81.2500 (78.5434)  Acc@5: 100.0000 (96.6968)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1570/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.1924  Acc@1: 81.2500 (78.5487)  Acc@5: 100.0000 (96.7139)  time: 0.3558  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1580/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.6055  Acc@1: 81.2500 (78.5737)  Acc@5: 100.0000 (96.7149)  time: 0.3563  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1590/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.0803  Acc@1: 81.2500 (78.5866)  Acc@5: 100.0000 (96.7238)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1600/3125]  eta: 0:09:07  Lr: 0.001875  Loss: -0.5098  Acc@1: 81.2500 (78.6149)  Acc@5: 100.0000 (96.7325)  time: 0.3531  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [1610/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.5422  Acc@1: 81.2500 (78.6196)  Acc@5: 100.0000 (96.7334)  time: 0.3544  data: 0.0028  max mem: 2502
Train: Epoch[1/5]  [1620/3125]  eta: 0:09:00  Lr: 0.001875  Loss: -0.4386  Acc@1: 81.2500 (78.6513)  Acc@5: 100.0000 (96.7420)  time: 0.3536  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [1630/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.5015  Acc@1: 87.5000 (78.6864)  Acc@5: 100.0000 (96.7505)  time: 0.3526  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1640/3125]  eta: 0:08:53  Lr: 0.001875  Loss: -0.4280  Acc@1: 87.5000 (78.7134)  Acc@5: 100.0000 (96.7474)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1650/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.9377  Acc@1: 81.2500 (78.7326)  Acc@5: 100.0000 (96.7595)  time: 0.3538  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1660/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.2989  Acc@1: 81.2500 (78.7553)  Acc@5: 100.0000 (96.7602)  time: 0.3557  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1670/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.7625  Acc@1: 81.2500 (78.7964)  Acc@5: 100.0000 (96.7684)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1680/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.5137  Acc@1: 81.2500 (78.8221)  Acc@5: 100.0000 (96.7765)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1690/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.4086  Acc@1: 81.2500 (78.8439)  Acc@5: 100.0000 (96.7844)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1700/3125]  eta: 0:08:31  Lr: 0.001875  Loss: -0.5229  Acc@1: 81.2500 (78.8801)  Acc@5: 100.0000 (96.7923)  time: 0.3522  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1710/3125]  eta: 0:08:27  Lr: 0.001875  Loss: -0.2615  Acc@1: 87.5000 (78.9158)  Acc@5: 100.0000 (96.7892)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1720/3125]  eta: 0:08:24  Lr: 0.001875  Loss: -0.5325  Acc@1: 81.2500 (78.9403)  Acc@5: 100.0000 (96.7933)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1730/3125]  eta: 0:08:20  Lr: 0.001875  Loss: -0.4218  Acc@1: 81.2500 (78.9861)  Acc@5: 100.0000 (96.7974)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1740/3125]  eta: 0:08:16  Lr: 0.001875  Loss: -0.5124  Acc@1: 81.2500 (79.0027)  Acc@5: 100.0000 (96.7978)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1750/3125]  eta: 0:08:13  Lr: 0.001875  Loss: -0.5815  Acc@1: 81.2500 (79.0441)  Acc@5: 100.0000 (96.7983)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1760/3125]  eta: 0:08:09  Lr: 0.001875  Loss: -0.0196  Acc@1: 87.5000 (79.0779)  Acc@5: 100.0000 (96.7987)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1770/3125]  eta: 0:08:05  Lr: 0.001875  Loss: -0.6922  Acc@1: 75.0000 (79.0902)  Acc@5: 100.0000 (96.8027)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1780/3125]  eta: 0:08:02  Lr: 0.001875  Loss: -0.7119  Acc@1: 75.0000 (79.1093)  Acc@5: 100.0000 (96.8136)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1790/3125]  eta: 0:07:58  Lr: 0.001875  Loss: -0.4368  Acc@1: 81.2500 (79.1318)  Acc@5: 100.0000 (96.8244)  time: 0.3532  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1800/3125]  eta: 0:07:54  Lr: 0.001875  Loss: 0.0467  Acc@1: 81.2500 (79.1470)  Acc@5: 100.0000 (96.8247)  time: 0.3519  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1810/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.2844  Acc@1: 87.5000 (79.1897)  Acc@5: 100.0000 (96.8388)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1820/3125]  eta: 0:07:47  Lr: 0.001875  Loss: -0.3265  Acc@1: 81.2500 (79.1976)  Acc@5: 100.0000 (96.8390)  time: 0.3511  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1830/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.3913  Acc@1: 81.2500 (79.2190)  Acc@5: 100.0000 (96.8392)  time: 0.3543  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1840/3125]  eta: 0:07:40  Lr: 0.001875  Loss: -0.4974  Acc@1: 81.2500 (79.2334)  Acc@5: 100.0000 (96.8461)  time: 0.3550  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1850/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.4675  Acc@1: 81.2500 (79.2511)  Acc@5: 100.0000 (96.8531)  time: 0.3519  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1860/3125]  eta: 0:07:33  Lr: 0.001875  Loss: -0.4977  Acc@1: 81.2500 (79.2887)  Acc@5: 100.0000 (96.8666)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1870/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.3929  Acc@1: 81.2500 (79.3025)  Acc@5: 100.0000 (96.8666)  time: 0.3544  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1880/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.2799  Acc@1: 81.2500 (79.3162)  Acc@5: 100.0000 (96.8767)  time: 0.3545  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1890/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.2720  Acc@1: 81.2500 (79.3330)  Acc@5: 100.0000 (96.8767)  time: 0.3516  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.3950  Acc@1: 81.2500 (79.3595)  Acc@5: 93.7500 (96.8734)  time: 0.3505  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1910/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.2874  Acc@1: 87.5000 (79.3825)  Acc@5: 100.0000 (96.8864)  time: 0.3520  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1920/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.0971  Acc@1: 81.2500 (79.3922)  Acc@5: 100.0000 (96.8799)  time: 0.3595  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1930/3125]  eta: 0:07:07  Lr: 0.001875  Loss: -0.5941  Acc@1: 81.2500 (79.3986)  Acc@5: 93.7500 (96.8766)  time: 0.3585  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1940/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.2579  Acc@1: 81.2500 (79.4146)  Acc@5: 100.0000 (96.8766)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1950/3125]  eta: 0:07:00  Lr: 0.001875  Loss: -0.4698  Acc@1: 81.2500 (79.4240)  Acc@5: 100.0000 (96.8734)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1960/3125]  eta: 0:06:57  Lr: 0.001875  Loss: 0.1711  Acc@1: 81.2500 (79.4397)  Acc@5: 100.0000 (96.8830)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1970/3125]  eta: 0:06:53  Lr: 0.001875  Loss: -0.4606  Acc@1: 81.2500 (79.4425)  Acc@5: 100.0000 (96.8893)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1980/3125]  eta: 0:06:49  Lr: 0.001875  Loss: -0.5582  Acc@1: 81.2500 (79.4706)  Acc@5: 100.0000 (96.8924)  time: 0.3536  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [1990/3125]  eta: 0:06:46  Lr: 0.001875  Loss: -0.6403  Acc@1: 81.2500 (79.4607)  Acc@5: 100.0000 (96.8923)  time: 0.3523  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [2000/3125]  eta: 0:06:42  Lr: 0.001875  Loss: -0.4001  Acc@1: 81.2500 (79.4946)  Acc@5: 100.0000 (96.8984)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2010/3125]  eta: 0:06:38  Lr: 0.001875  Loss: -0.7641  Acc@1: 81.2500 (79.4847)  Acc@5: 100.0000 (96.8921)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2020/3125]  eta: 0:06:35  Lr: 0.001875  Loss: -0.3143  Acc@1: 75.0000 (79.4718)  Acc@5: 100.0000 (96.8951)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2030/3125]  eta: 0:06:31  Lr: 0.001875  Loss: -0.5500  Acc@1: 75.0000 (79.4775)  Acc@5: 100.0000 (96.9012)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2040/3125]  eta: 0:06:28  Lr: 0.001875  Loss: -0.5456  Acc@1: 81.2500 (79.5015)  Acc@5: 100.0000 (96.9102)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2050/3125]  eta: 0:06:24  Lr: 0.001875  Loss: 0.1521  Acc@1: 87.5000 (79.5344)  Acc@5: 100.0000 (96.9192)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:20  Lr: 0.001875  Loss: -0.4397  Acc@1: 81.2500 (79.5488)  Acc@5: 100.0000 (96.9250)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8233  Acc@1: 81.2500 (79.5751)  Acc@5: 100.0000 (96.9308)  time: 0.3534  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2080/3125]  eta: 0:06:13  Lr: 0.001875  Loss: -0.4369  Acc@1: 87.5000 (79.5981)  Acc@5: 100.0000 (96.9336)  time: 0.3528  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2090/3125]  eta: 0:06:10  Lr: 0.001875  Loss: -0.0806  Acc@1: 81.2500 (79.5971)  Acc@5: 100.0000 (96.9303)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2100/3125]  eta: 0:06:06  Lr: 0.001875  Loss: -0.7367  Acc@1: 81.2500 (79.6079)  Acc@5: 100.0000 (96.9360)  time: 0.3542  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2110/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.5606  Acc@1: 87.5000 (79.6157)  Acc@5: 100.0000 (96.9387)  time: 0.3530  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2120/3125]  eta: 0:05:59  Lr: 0.001875  Loss: -0.4869  Acc@1: 87.5000 (79.6381)  Acc@5: 100.0000 (96.9501)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2130/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.6104  Acc@1: 87.5000 (79.6692)  Acc@5: 100.0000 (96.9557)  time: 0.3544  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2140/3125]  eta: 0:05:52  Lr: 0.001875  Loss: -0.6888  Acc@1: 87.5000 (79.7233)  Acc@5: 100.0000 (96.9640)  time: 0.3542  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2150/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.7118  Acc@1: 87.5000 (79.7245)  Acc@5: 100.0000 (96.9694)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2160/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.2078  Acc@1: 81.2500 (79.7229)  Acc@5: 100.0000 (96.9690)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2170/3125]  eta: 0:05:41  Lr: 0.001875  Loss: -0.5947  Acc@1: 81.2500 (79.7386)  Acc@5: 100.0000 (96.9714)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2180/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.2443  Acc@1: 87.5000 (79.7627)  Acc@5: 100.0000 (96.9767)  time: 0.3556  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2190/3125]  eta: 0:05:34  Lr: 0.001875  Loss: -0.4527  Acc@1: 87.5000 (79.8066)  Acc@5: 100.0000 (96.9791)  time: 0.3534  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2200/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.5468  Acc@1: 87.5000 (79.8359)  Acc@5: 100.0000 (96.9843)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.7156  Acc@1: 87.5000 (79.8507)  Acc@5: 100.0000 (96.9838)  time: 0.3513  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.2467  Acc@1: 81.2500 (79.8599)  Acc@5: 100.0000 (96.9890)  time: 0.3527  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.1776  Acc@1: 81.2500 (79.8633)  Acc@5: 100.0000 (96.9885)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.4179  Acc@1: 81.2500 (79.8527)  Acc@5: 100.0000 (96.9963)  time: 0.3514  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2219  Acc@1: 81.2500 (79.8756)  Acc@5: 100.0000 (97.0069)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2260/3125]  eta: 0:05:08  Lr: 0.001875  Loss: -0.4310  Acc@1: 87.5000 (79.8927)  Acc@5: 100.0000 (97.0118)  time: 0.3516  data: 0.0024  max mem: 2502
Train: Epoch[1/5]  [2270/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.7468  Acc@1: 81.2500 (79.9070)  Acc@5: 100.0000 (97.0222)  time: 0.3535  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [2280/3125]  eta: 0:05:01  Lr: 0.001875  Loss: -0.6526  Acc@1: 81.2500 (79.9129)  Acc@5: 100.0000 (97.0189)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2290/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5021  Acc@1: 87.5000 (79.9460)  Acc@5: 100.0000 (97.0210)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2300/3125]  eta: 0:04:54  Lr: 0.001875  Loss: -0.7457  Acc@1: 87.5000 (79.9788)  Acc@5: 100.0000 (97.0257)  time: 0.3533  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2310/3125]  eta: 0:04:51  Lr: 0.001875  Loss: 0.0225  Acc@1: 81.2500 (79.9654)  Acc@5: 100.0000 (97.0197)  time: 0.3534  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2320/3125]  eta: 0:04:47  Lr: 0.001875  Loss: -0.7907  Acc@1: 81.2500 (79.9763)  Acc@5: 93.7500 (97.0164)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2330/3125]  eta: 0:04:43  Lr: 0.001875  Loss: -0.3583  Acc@1: 87.5000 (80.0005)  Acc@5: 93.7500 (97.0158)  time: 0.3534  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [2340/3125]  eta: 0:04:40  Lr: 0.001875  Loss: -0.7548  Acc@1: 87.5000 (80.0272)  Acc@5: 100.0000 (97.0205)  time: 0.3559  data: 0.0033  max mem: 2502
Train: Epoch[1/5]  [2350/3125]  eta: 0:04:36  Lr: 0.001875  Loss: -0.5571  Acc@1: 87.5000 (80.0510)  Acc@5: 100.0000 (97.0279)  time: 0.3553  data: 0.0024  max mem: 2502
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:33  Lr: 0.001875  Loss: 0.2039  Acc@1: 87.5000 (80.0694)  Acc@5: 100.0000 (97.0325)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:29  Lr: 0.001875  Loss: -0.5106  Acc@1: 87.5000 (80.0822)  Acc@5: 100.0000 (97.0345)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:25  Lr: 0.001875  Loss: -0.2368  Acc@1: 81.2500 (80.1055)  Acc@5: 100.0000 (97.0338)  time: 0.3566  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:22  Lr: 0.001875  Loss: -0.5711  Acc@1: 81.2500 (80.1234)  Acc@5: 93.7500 (97.0305)  time: 0.3608  data: 0.0026  max mem: 2502
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:18  Lr: 0.001875  Loss: -0.8491  Acc@1: 81.2500 (80.1385)  Acc@5: 100.0000 (97.0429)  time: 0.3556  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:15  Lr: 0.001875  Loss: -0.5057  Acc@1: 87.5000 (80.1664)  Acc@5: 100.0000 (97.0500)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:11  Lr: 0.001875  Loss: -0.4810  Acc@1: 87.5000 (80.1786)  Acc@5: 100.0000 (97.0467)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2430/3125]  eta: 0:04:08  Lr: 0.001875  Loss: -0.0882  Acc@1: 81.2500 (80.1753)  Acc@5: 100.0000 (97.0511)  time: 0.3546  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [2440/3125]  eta: 0:04:04  Lr: 0.001875  Loss: -0.4978  Acc@1: 81.2500 (80.1925)  Acc@5: 100.0000 (97.0581)  time: 0.3562  data: 0.0021  max mem: 2502
Train: Epoch[1/5]  [2450/3125]  eta: 0:04:00  Lr: 0.001875  Loss: -0.5050  Acc@1: 81.2500 (80.1969)  Acc@5: 100.0000 (97.0548)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2460/3125]  eta: 0:03:57  Lr: 0.001875  Loss: -0.2324  Acc@1: 81.2500 (80.2011)  Acc@5: 100.0000 (97.0566)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2470/3125]  eta: 0:03:53  Lr: 0.001875  Loss: -0.5397  Acc@1: 81.2500 (80.2104)  Acc@5: 100.0000 (97.0634)  time: 0.3541  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2480/3125]  eta: 0:03:50  Lr: 0.001875  Loss: -0.5865  Acc@1: 87.5000 (80.2348)  Acc@5: 100.0000 (97.0728)  time: 0.3566  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2490/3125]  eta: 0:03:46  Lr: 0.001875  Loss: -0.5705  Acc@1: 81.2500 (80.2288)  Acc@5: 100.0000 (97.0695)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2500/3125]  eta: 0:03:43  Lr: 0.001875  Loss: -0.0693  Acc@1: 87.5000 (80.2579)  Acc@5: 100.0000 (97.0737)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2510/3125]  eta: 0:03:39  Lr: 0.001875  Loss: -0.8122  Acc@1: 87.5000 (80.3091)  Acc@5: 100.0000 (97.0828)  time: 0.3514  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.8946  Acc@1: 87.5000 (80.3178)  Acc@5: 100.0000 (97.0820)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:32  Lr: 0.001875  Loss: -0.2846  Acc@1: 81.2500 (80.3289)  Acc@5: 100.0000 (97.0935)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.3547  Acc@1: 81.2500 (80.3375)  Acc@5: 100.0000 (97.1001)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:25  Lr: 0.001875  Loss: -0.7143  Acc@1: 87.5000 (80.3631)  Acc@5: 100.0000 (97.1041)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.6158  Acc@1: 87.5000 (80.3861)  Acc@5: 100.0000 (97.1105)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.6499  Acc@1: 87.5000 (80.4113)  Acc@5: 100.0000 (97.1193)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.8270  Acc@1: 87.5000 (80.4339)  Acc@5: 100.0000 (97.1256)  time: 0.3546  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.3691  Acc@1: 87.5000 (80.4467)  Acc@5: 100.0000 (97.1343)  time: 0.3549  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.5633  Acc@1: 87.5000 (80.4787)  Acc@5: 100.0000 (97.1381)  time: 0.3551  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2610/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.1558  Acc@1: 87.5000 (80.4960)  Acc@5: 100.0000 (97.1395)  time: 0.3529  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2620/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.6719  Acc@1: 87.5000 (80.5132)  Acc@5: 100.0000 (97.1409)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2630/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.4652  Acc@1: 87.5000 (80.5302)  Acc@5: 100.0000 (97.1446)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2640/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.6513  Acc@1: 87.5000 (80.5424)  Acc@5: 100.0000 (97.1365)  time: 0.3563  data: 0.0022  max mem: 2502
Train: Epoch[1/5]  [2650/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.6969  Acc@1: 87.5000 (80.5569)  Acc@5: 93.7500 (97.1332)  time: 0.3590  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [2660/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.9511  Acc@1: 87.5000 (80.5759)  Acc@5: 93.7500 (97.1275)  time: 0.3533  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.4867  Acc@1: 87.5000 (80.6018)  Acc@5: 100.0000 (97.1382)  time: 0.3506  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.2705  Acc@1: 87.5000 (80.6019)  Acc@5: 100.0000 (97.1466)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.4538  Acc@1: 81.2500 (80.6229)  Acc@5: 100.0000 (97.1456)  time: 0.3574  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.8172  Acc@1: 87.5000 (80.6484)  Acc@5: 100.0000 (97.1538)  time: 0.3557  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:27  Lr: 0.001875  Loss: -0.7392  Acc@1: 87.5000 (80.6529)  Acc@5: 100.0000 (97.1551)  time: 0.3579  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.7038  Acc@1: 87.5000 (80.6413)  Acc@5: 100.0000 (97.1587)  time: 0.3571  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:20  Lr: 0.001875  Loss: -0.4733  Acc@1: 81.2500 (80.6573)  Acc@5: 100.0000 (97.1576)  time: 0.3516  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.5976  Acc@1: 87.5000 (80.6822)  Acc@5: 100.0000 (97.1612)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:13  Lr: 0.001875  Loss: -0.6625  Acc@1: 81.2500 (80.6934)  Acc@5: 100.0000 (97.1624)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.7712  Acc@1: 81.2500 (80.7158)  Acc@5: 100.0000 (97.1636)  time: 0.3517  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:06  Lr: 0.001875  Loss: -0.3691  Acc@1: 81.2500 (80.7290)  Acc@5: 93.7500 (97.1603)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2780/3125]  eta: 0:02:02  Lr: 0.001875  Loss: -0.5125  Acc@1: 81.2500 (80.7421)  Acc@5: 100.0000 (97.1660)  time: 0.3604  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2790/3125]  eta: 0:01:59  Lr: 0.001875  Loss: -0.2744  Acc@1: 81.2500 (80.7663)  Acc@5: 100.0000 (97.1672)  time: 0.3600  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2800/3125]  eta: 0:01:55  Lr: 0.001875  Loss: -0.1697  Acc@1: 81.2500 (80.7569)  Acc@5: 100.0000 (97.1707)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2810/3125]  eta: 0:01:52  Lr: 0.001875  Loss: -0.7311  Acc@1: 81.2500 (80.7675)  Acc@5: 100.0000 (97.1740)  time: 0.3637  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:48  Lr: 0.001875  Loss: -0.7030  Acc@1: 87.5000 (80.7759)  Acc@5: 100.0000 (97.1752)  time: 0.3804  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:45  Lr: 0.001875  Loss: -0.4121  Acc@1: 87.5000 (80.7974)  Acc@5: 100.0000 (97.1764)  time: 0.3660  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:41  Lr: 0.001875  Loss: 0.5548  Acc@1: 87.5000 (80.8012)  Acc@5: 100.0000 (97.1775)  time: 0.3504  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:38  Lr: 0.001875  Loss: -0.1428  Acc@1: 81.2500 (80.8137)  Acc@5: 100.0000 (97.1830)  time: 0.3520  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5866  Acc@1: 87.5000 (80.8306)  Acc@5: 100.0000 (97.1841)  time: 0.3529  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:30  Lr: 0.001875  Loss: -0.8482  Acc@1: 87.5000 (80.8560)  Acc@5: 100.0000 (97.1874)  time: 0.3540  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:27  Lr: 0.001875  Loss: -0.5045  Acc@1: 87.5000 (80.8747)  Acc@5: 100.0000 (97.1972)  time: 0.3531  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5318  Acc@1: 87.5000 (80.8955)  Acc@5: 100.0000 (97.2025)  time: 0.3547  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7151  Acc@1: 87.5000 (80.9096)  Acc@5: 100.0000 (97.2079)  time: 0.3553  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:16  Lr: 0.001875  Loss: -0.0689  Acc@1: 87.5000 (80.9172)  Acc@5: 100.0000 (97.2089)  time: 0.3526  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4515  Acc@1: 87.5000 (80.9376)  Acc@5: 100.0000 (97.2056)  time: 0.3516  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:09  Lr: 0.001875  Loss: -0.7942  Acc@1: 87.5000 (80.9472)  Acc@5: 100.0000 (97.2087)  time: 0.3504  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:05  Lr: 0.001875  Loss: -0.2824  Acc@1: 81.2500 (80.9610)  Acc@5: 100.0000 (97.2097)  time: 0.3511  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:02  Lr: 0.001875  Loss: -0.5248  Acc@1: 87.5000 (80.9683)  Acc@5: 100.0000 (97.2149)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2960/3125]  eta: 0:00:58  Lr: 0.001875  Loss: -0.4044  Acc@1: 87.5000 (80.9777)  Acc@5: 100.0000 (97.2180)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2970/3125]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6615  Acc@1: 87.5000 (81.0165)  Acc@5: 100.0000 (97.2211)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:51  Lr: 0.001875  Loss: -0.5074  Acc@1: 93.7500 (81.0424)  Acc@5: 100.0000 (97.2262)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:48  Lr: 0.001875  Loss: -0.4309  Acc@1: 87.5000 (81.0598)  Acc@5: 100.0000 (97.2334)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.4676  Acc@1: 87.5000 (81.0792)  Acc@5: 100.0000 (97.2405)  time: 0.3515  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3286  Acc@1: 81.2500 (81.0798)  Acc@5: 100.0000 (97.2434)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.3346  Acc@1: 81.2500 (81.0845)  Acc@5: 100.0000 (97.2484)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.8068  Acc@1: 87.5000 (81.1077)  Acc@5: 100.0000 (97.2534)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:30  Lr: 0.001875  Loss: -0.5638  Acc@1: 87.5000 (81.1144)  Acc@5: 100.0000 (97.2542)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6212  Acc@1: 81.2500 (81.1353)  Acc@5: 100.0000 (97.2591)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0740  Acc@1: 87.5000 (81.1377)  Acc@5: 100.0000 (97.2640)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.6691  Acc@1: 87.5000 (81.1584)  Acc@5: 100.0000 (97.2688)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:16  Lr: 0.001875  Loss: -0.6301  Acc@1: 81.2500 (81.1628)  Acc@5: 100.0000 (97.2716)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.7664  Acc@1: 81.2500 (81.1671)  Acc@5: 100.0000 (97.2723)  time: 0.3535  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.2506  Acc@1: 81.2500 (81.1835)  Acc@5: 100.0000 (97.2771)  time: 0.3548  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4744  Acc@1: 81.2500 (81.1716)  Acc@5: 100.0000 (97.2798)  time: 0.3532  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.4905  Acc@1: 81.2500 (81.1739)  Acc@5: 100.0000 (97.2885)  time: 0.3534  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2055  Acc@1: 81.2500 (81.1660)  Acc@5: 100.0000 (97.2880)  time: 0.3540  data: 0.0017  max mem: 2502
Train: Epoch[1/5] Total time: 0:18:33 (0.3564 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.2055  Acc@1: 81.2500 (81.1660)  Acc@5: 100.0000 (97.2880)
Train: Epoch[2/5]  [   0/3125]  eta: 0:50:25  Lr: 0.001875  Loss: -0.7092  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.9683  data: 0.6142  max mem: 2502
Train: Epoch[2/5]  [  10/3125]  eta: 0:21:45  Lr: 0.001875  Loss: -0.2778  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (98.2955)  time: 0.4190  data: 0.0565  max mem: 2502
Train: Epoch[2/5]  [  20/3125]  eta: 0:20:09  Lr: 0.001875  Loss: -0.3582  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (98.5119)  time: 0.3606  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [  30/3125]  eta: 0:19:31  Lr: 0.001875  Loss: -0.6450  Acc@1: 81.2500 (82.4597)  Acc@5: 100.0000 (98.1855)  time: 0.3561  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [  40/3125]  eta: 0:19:06  Lr: 0.001875  Loss: -0.7857  Acc@1: 81.2500 (83.2317)  Acc@5: 100.0000 (98.1707)  time: 0.3526  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  50/3125]  eta: 0:18:49  Lr: 0.001875  Loss: -0.2852  Acc@1: 81.2500 (82.7206)  Acc@5: 100.0000 (98.4069)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  60/3125]  eta: 0:18:41  Lr: 0.001875  Loss: -0.7541  Acc@1: 81.2500 (83.5041)  Acc@5: 100.0000 (98.6680)  time: 0.3544  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [  70/3125]  eta: 0:18:33  Lr: 0.001875  Loss: -0.4647  Acc@1: 81.2500 (83.4507)  Acc@5: 100.0000 (98.5035)  time: 0.3573  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [  80/3125]  eta: 0:18:25  Lr: 0.001875  Loss: -0.3680  Acc@1: 81.2500 (82.5617)  Acc@5: 100.0000 (98.2253)  time: 0.3541  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [  90/3125]  eta: 0:18:17  Lr: 0.001875  Loss: -0.6729  Acc@1: 81.2500 (82.6923)  Acc@5: 93.7500 (98.0769)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 100/3125]  eta: 0:18:10  Lr: 0.001875  Loss: -0.2627  Acc@1: 87.5000 (82.4257)  Acc@5: 100.0000 (97.9579)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 110/3125]  eta: 0:18:04  Lr: 0.001875  Loss: -0.3913  Acc@1: 81.2500 (82.4887)  Acc@5: 100.0000 (97.9167)  time: 0.3515  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 120/3125]  eta: 0:17:58  Lr: 0.001875  Loss: -0.6251  Acc@1: 81.2500 (82.6446)  Acc@5: 100.0000 (97.8822)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 130/3125]  eta: 0:17:53  Lr: 0.001875  Loss: -0.6671  Acc@1: 81.2500 (82.7290)  Acc@5: 100.0000 (97.9008)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 140/3125]  eta: 0:17:47  Lr: 0.001875  Loss: -0.3777  Acc@1: 81.2500 (82.8457)  Acc@5: 100.0000 (98.0053)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 150/3125]  eta: 0:17:43  Lr: 0.001875  Loss: -0.3922  Acc@1: 87.5000 (82.9884)  Acc@5: 100.0000 (98.0546)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 160/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.1515  Acc@1: 87.5000 (83.1522)  Acc@5: 100.0000 (98.0978)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 170/3125]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6410  Acc@1: 87.5000 (83.3333)  Acc@5: 100.0000 (98.0629)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 180/3125]  eta: 0:17:28  Lr: 0.001875  Loss: -0.7022  Acc@1: 87.5000 (83.4254)  Acc@5: 100.0000 (98.1354)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 190/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.8344  Acc@1: 81.2500 (83.5079)  Acc@5: 100.0000 (98.1348)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 200/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.4356  Acc@1: 81.2500 (83.5199)  Acc@5: 100.0000 (98.1343)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 210/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.4640  Acc@1: 81.2500 (83.6789)  Acc@5: 100.0000 (98.1931)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 220/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.3317  Acc@1: 87.5000 (83.7387)  Acc@5: 100.0000 (98.2183)  time: 0.3514  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 230/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.8468  Acc@1: 87.5000 (83.7933)  Acc@5: 100.0000 (98.1872)  time: 0.3541  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 240/3125]  eta: 0:17:03  Lr: 0.001875  Loss: 0.0550  Acc@1: 81.2500 (83.7137)  Acc@5: 100.0000 (98.1587)  time: 0.3538  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 250/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.0891  Acc@1: 81.2500 (83.6404)  Acc@5: 100.0000 (98.1574)  time: 0.3510  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 260/3125]  eta: 0:16:56  Lr: 0.001875  Loss: -0.5209  Acc@1: 81.2500 (83.6446)  Acc@5: 100.0000 (98.1801)  time: 0.3518  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 270/3125]  eta: 0:16:53  Lr: 0.001875  Loss: -0.4335  Acc@1: 81.2500 (83.7177)  Acc@5: 100.0000 (98.2242)  time: 0.3562  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 280/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.6518  Acc@1: 81.2500 (83.7411)  Acc@5: 100.0000 (98.1762)  time: 0.3577  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [ 290/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.6964  Acc@1: 87.5000 (83.8488)  Acc@5: 100.0000 (98.1314)  time: 0.3532  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 300/3125]  eta: 0:16:42  Lr: 0.001875  Loss: 0.0426  Acc@1: 81.2500 (83.6794)  Acc@5: 100.0000 (98.0897)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 310/3125]  eta: 0:16:38  Lr: 0.001875  Loss: -0.5987  Acc@1: 81.2500 (83.7219)  Acc@5: 100.0000 (98.1310)  time: 0.3531  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 320/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.7062  Acc@1: 87.5000 (83.9369)  Acc@5: 100.0000 (98.1308)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 330/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.4503  Acc@1: 87.5000 (83.9690)  Acc@5: 100.0000 (98.1307)  time: 0.3562  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 340/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.8961  Acc@1: 87.5000 (84.0726)  Acc@5: 100.0000 (98.1122)  time: 0.3544  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 350/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.3100  Acc@1: 87.5000 (84.1168)  Acc@5: 100.0000 (98.0947)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 360/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.5663  Acc@1: 87.5000 (84.1932)  Acc@5: 100.0000 (98.0956)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 370/3125]  eta: 0:16:16  Lr: 0.001875  Loss: -0.2105  Acc@1: 87.5000 (84.3160)  Acc@5: 100.0000 (98.1469)  time: 0.3521  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 380/3125]  eta: 0:16:12  Lr: 0.001875  Loss: -0.1631  Acc@1: 87.5000 (84.3504)  Acc@5: 100.0000 (98.1463)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 390/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.3740  Acc@1: 87.5000 (84.4949)  Acc@5: 100.0000 (98.1618)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 400/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.3549  Acc@1: 87.5000 (84.5075)  Acc@5: 100.0000 (98.1920)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 410/3125]  eta: 0:16:00  Lr: 0.001875  Loss: -0.3769  Acc@1: 87.5000 (84.5651)  Acc@5: 100.0000 (98.2056)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 420/3125]  eta: 0:15:56  Lr: 0.001875  Loss: -0.3056  Acc@1: 87.5000 (84.5606)  Acc@5: 100.0000 (98.2037)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 430/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.1618  Acc@1: 81.2500 (84.4403)  Acc@5: 100.0000 (98.2019)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 440/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.4315  Acc@1: 81.2500 (84.4104)  Acc@5: 100.0000 (98.2001)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 450/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.4929  Acc@1: 81.2500 (84.4512)  Acc@5: 100.0000 (98.1984)  time: 0.3512  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 460/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.5836  Acc@1: 87.5000 (84.4631)  Acc@5: 100.0000 (98.1833)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 470/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.7427  Acc@1: 87.5000 (84.5011)  Acc@5: 100.0000 (98.2086)  time: 0.3530  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 480/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.7286  Acc@1: 87.5000 (84.4725)  Acc@5: 100.0000 (98.2328)  time: 0.3533  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 490/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.7513  Acc@1: 87.5000 (84.5468)  Acc@5: 100.0000 (98.2688)  time: 0.3531  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 500/3125]  eta: 0:15:27  Lr: 0.001875  Loss: -0.6046  Acc@1: 87.5000 (84.5309)  Acc@5: 100.0000 (98.2660)  time: 0.3512  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 510/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.5795  Acc@1: 87.5000 (84.5034)  Acc@5: 100.0000 (98.2877)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 520/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.6832  Acc@1: 87.5000 (84.6209)  Acc@5: 100.0000 (98.2845)  time: 0.3554  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 530/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.7613  Acc@1: 87.5000 (84.6634)  Acc@5: 100.0000 (98.3169)  time: 0.3571  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 540/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.7728  Acc@1: 87.5000 (84.7505)  Acc@5: 100.0000 (98.3364)  time: 0.3536  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 550/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.4957  Acc@1: 87.5000 (84.7436)  Acc@5: 100.0000 (98.2872)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 560/3125]  eta: 0:15:06  Lr: 0.001875  Loss: -0.1089  Acc@1: 87.5000 (84.7148)  Acc@5: 100.0000 (98.2843)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 570/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.2141  Acc@1: 87.5000 (84.7855)  Acc@5: 100.0000 (98.2925)  time: 0.3554  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 580/3125]  eta: 0:14:59  Lr: 0.001875  Loss: -0.7256  Acc@1: 87.5000 (84.7892)  Acc@5: 100.0000 (98.2681)  time: 0.3587  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [ 590/3125]  eta: 0:14:56  Lr: 0.001875  Loss: 0.0104  Acc@1: 87.5000 (84.7716)  Acc@5: 100.0000 (98.2551)  time: 0.3548  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [ 600/3125]  eta: 0:14:52  Lr: 0.001875  Loss: -0.6558  Acc@1: 87.5000 (84.7650)  Acc@5: 100.0000 (98.2633)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 610/3125]  eta: 0:14:48  Lr: 0.001875  Loss: -0.5180  Acc@1: 87.5000 (84.7381)  Acc@5: 100.0000 (98.2610)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 620/3125]  eta: 0:14:45  Lr: 0.001875  Loss: -0.3938  Acc@1: 81.2500 (84.7424)  Acc@5: 100.0000 (98.2689)  time: 0.3551  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 630/3125]  eta: 0:14:41  Lr: 0.001875  Loss: -0.8168  Acc@1: 87.5000 (84.8059)  Acc@5: 100.0000 (98.2765)  time: 0.3533  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 640/3125]  eta: 0:14:38  Lr: 0.001875  Loss: -0.5503  Acc@1: 87.5000 (84.7991)  Acc@5: 100.0000 (98.2742)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 650/3125]  eta: 0:14:34  Lr: 0.001875  Loss: -0.3997  Acc@1: 87.5000 (84.8694)  Acc@5: 100.0000 (98.3007)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 660/3125]  eta: 0:14:30  Lr: 0.001875  Loss: -0.5137  Acc@1: 87.5000 (84.9187)  Acc@5: 100.0000 (98.3169)  time: 0.3509  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 670/3125]  eta: 0:14:27  Lr: 0.001875  Loss: -0.8308  Acc@1: 87.5000 (84.9944)  Acc@5: 100.0000 (98.3141)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 680/3125]  eta: 0:14:23  Lr: 0.001875  Loss: -0.3106  Acc@1: 87.5000 (84.9945)  Acc@5: 100.0000 (98.3113)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 690/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.3016  Acc@1: 87.5000 (85.0308)  Acc@5: 100.0000 (98.2905)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 700/3125]  eta: 0:14:16  Lr: 0.001875  Loss: -0.3613  Acc@1: 87.5000 (85.0125)  Acc@5: 100.0000 (98.2792)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 710/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.1836  Acc@1: 87.5000 (84.9859)  Acc@5: 100.0000 (98.2419)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 720/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.1894  Acc@1: 81.2500 (84.9428)  Acc@5: 93.7500 (98.2143)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 730/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.3678  Acc@1: 81.2500 (84.8923)  Acc@5: 100.0000 (98.2131)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 740/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.8214  Acc@1: 81.2500 (84.8684)  Acc@5: 100.0000 (98.2034)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 750/3125]  eta: 0:13:58  Lr: 0.001875  Loss: -0.8230  Acc@1: 87.5000 (84.8785)  Acc@5: 100.0000 (98.1941)  time: 0.3542  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 760/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.5011  Acc@1: 87.5000 (84.9376)  Acc@5: 100.0000 (98.2014)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 770/3125]  eta: 0:13:51  Lr: 0.001875  Loss: -0.6413  Acc@1: 87.5000 (84.9546)  Acc@5: 100.0000 (98.2004)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 780/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.2298  Acc@1: 87.5000 (84.9792)  Acc@5: 100.0000 (98.1914)  time: 0.3576  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 790/3125]  eta: 0:13:44  Lr: 0.001875  Loss: -0.0776  Acc@1: 87.5000 (84.9320)  Acc@5: 100.0000 (98.1827)  time: 0.3566  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 800/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.4198  Acc@1: 87.5000 (84.9485)  Acc@5: 100.0000 (98.1976)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 810/3125]  eta: 0:13:37  Lr: 0.001875  Loss: -0.1320  Acc@1: 87.5000 (84.9260)  Acc@5: 100.0000 (98.1967)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 820/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.2808  Acc@1: 81.2500 (84.8889)  Acc@5: 100.0000 (98.1806)  time: 0.3535  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 830/3125]  eta: 0:13:30  Lr: 0.001875  Loss: -0.3380  Acc@1: 87.5000 (84.9203)  Acc@5: 100.0000 (98.1874)  time: 0.3535  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 840/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.5177  Acc@1: 87.5000 (84.8989)  Acc@5: 100.0000 (98.1793)  time: 0.3518  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 850/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.7120  Acc@1: 87.5000 (84.9075)  Acc@5: 100.0000 (98.1566)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 860/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.1043  Acc@1: 87.5000 (84.8940)  Acc@5: 100.0000 (98.1417)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 870/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.7740  Acc@1: 81.2500 (84.8809)  Acc@5: 100.0000 (98.1630)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 880/3125]  eta: 0:13:12  Lr: 0.001875  Loss: -0.6105  Acc@1: 81.2500 (84.8680)  Acc@5: 100.0000 (98.1697)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 890/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.2921  Acc@1: 87.5000 (84.9397)  Acc@5: 100.0000 (98.1692)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 900/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.1349  Acc@1: 87.5000 (84.9334)  Acc@5: 100.0000 (98.1548)  time: 0.3608  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 910/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.5548  Acc@1: 87.5000 (84.9616)  Acc@5: 100.0000 (98.1682)  time: 0.3605  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 920/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.8421  Acc@1: 87.5000 (85.0027)  Acc@5: 100.0000 (98.1813)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 930/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.7542  Acc@1: 87.5000 (85.0363)  Acc@5: 100.0000 (98.1807)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 940/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.5512  Acc@1: 87.5000 (85.0093)  Acc@5: 100.0000 (98.1668)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 950/3125]  eta: 0:12:48  Lr: 0.001875  Loss: -0.5985  Acc@1: 87.5000 (85.0092)  Acc@5: 100.0000 (98.1598)  time: 0.3685  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 960/3125]  eta: 0:12:45  Lr: 0.001875  Loss: -0.4218  Acc@1: 87.5000 (85.0221)  Acc@5: 100.0000 (98.1530)  time: 0.3817  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 970/3125]  eta: 0:12:41  Lr: 0.001875  Loss: -0.7021  Acc@1: 87.5000 (85.0476)  Acc@5: 100.0000 (98.1591)  time: 0.3621  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 980/3125]  eta: 0:12:38  Lr: 0.001875  Loss: -0.5234  Acc@1: 87.5000 (85.0663)  Acc@5: 100.0000 (98.1779)  time: 0.3510  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 990/3125]  eta: 0:12:34  Lr: 0.001875  Loss: -0.6934  Acc@1: 87.5000 (85.0908)  Acc@5: 100.0000 (98.1710)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1000/3125]  eta: 0:12:31  Lr: 0.001875  Loss: -0.6611  Acc@1: 87.5000 (85.1086)  Acc@5: 100.0000 (98.1831)  time: 0.3547  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1010/3125]  eta: 0:12:27  Lr: 0.001875  Loss: -0.2329  Acc@1: 87.5000 (85.0952)  Acc@5: 100.0000 (98.1825)  time: 0.3551  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1020/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.4667  Acc@1: 87.5000 (85.1249)  Acc@5: 100.0000 (98.1758)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1030/3125]  eta: 0:12:20  Lr: 0.001875  Loss: -0.4493  Acc@1: 87.5000 (85.0812)  Acc@5: 100.0000 (98.1814)  time: 0.3519  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1040/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.6456  Acc@1: 81.2500 (85.0925)  Acc@5: 100.0000 (98.1808)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1050/3125]  eta: 0:12:13  Lr: 0.001875  Loss: -0.5319  Acc@1: 87.5000 (85.1213)  Acc@5: 100.0000 (98.1803)  time: 0.3578  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1060/3125]  eta: 0:12:09  Lr: 0.001875  Loss: -0.2905  Acc@1: 87.5000 (85.1143)  Acc@5: 100.0000 (98.1857)  time: 0.3587  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [1070/3125]  eta: 0:12:06  Lr: 0.001875  Loss: -0.3154  Acc@1: 87.5000 (85.0957)  Acc@5: 100.0000 (98.1909)  time: 0.3549  data: 0.0023  max mem: 2502
Train: Epoch[2/5]  [1080/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.7812  Acc@1: 81.2500 (85.0775)  Acc@5: 100.0000 (98.1788)  time: 0.3569  data: 0.0025  max mem: 2502
Train: Epoch[2/5]  [1090/3125]  eta: 0:11:59  Lr: 0.001875  Loss: -0.5786  Acc@1: 87.5000 (85.1054)  Acc@5: 100.0000 (98.1840)  time: 0.3569  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1100/3125]  eta: 0:11:56  Lr: 0.001875  Loss: -0.0594  Acc@1: 87.5000 (85.1045)  Acc@5: 100.0000 (98.1835)  time: 0.3573  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1110/3125]  eta: 0:11:52  Lr: 0.001875  Loss: -0.6045  Acc@1: 81.2500 (85.0810)  Acc@5: 100.0000 (98.1942)  time: 0.3541  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1120/3125]  eta: 0:11:49  Lr: 0.001875  Loss: -0.2115  Acc@1: 81.2500 (85.0691)  Acc@5: 100.0000 (98.1880)  time: 0.3560  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1130/3125]  eta: 0:11:45  Lr: 0.001875  Loss: -0.3810  Acc@1: 81.2500 (85.0740)  Acc@5: 100.0000 (98.1819)  time: 0.3599  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1140/3125]  eta: 0:11:42  Lr: 0.001875  Loss: -0.5152  Acc@1: 81.2500 (85.0679)  Acc@5: 100.0000 (98.1814)  time: 0.3553  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1150/3125]  eta: 0:11:38  Lr: 0.001875  Loss: -0.7689  Acc@1: 81.2500 (85.0565)  Acc@5: 100.0000 (98.1646)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1160/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.3409  Acc@1: 81.2500 (85.0775)  Acc@5: 100.0000 (98.1643)  time: 0.3540  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1170/3125]  eta: 0:11:31  Lr: 0.001875  Loss: -0.1231  Acc@1: 81.2500 (85.0555)  Acc@5: 100.0000 (98.1640)  time: 0.3640  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1180/3125]  eta: 0:11:28  Lr: 0.001875  Loss: 0.1875  Acc@1: 81.2500 (85.0233)  Acc@5: 100.0000 (98.1636)  time: 0.3637  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1190/3125]  eta: 0:11:24  Lr: 0.001875  Loss: -0.4576  Acc@1: 87.5000 (85.0546)  Acc@5: 100.0000 (98.1686)  time: 0.3517  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1200/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.8439  Acc@1: 87.5000 (85.0853)  Acc@5: 100.0000 (98.1734)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1210/3125]  eta: 0:11:17  Lr: 0.001875  Loss: -0.0324  Acc@1: 87.5000 (85.0692)  Acc@5: 100.0000 (98.1678)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1220/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.6440  Acc@1: 87.5000 (85.0891)  Acc@5: 100.0000 (98.1624)  time: 0.3531  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1230/3125]  eta: 0:11:10  Lr: 0.001875  Loss: -0.4837  Acc@1: 87.5000 (85.0782)  Acc@5: 100.0000 (98.1621)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1240/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.7962  Acc@1: 87.5000 (85.0927)  Acc@5: 100.0000 (98.1668)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1250/3125]  eta: 0:11:03  Lr: 0.001875  Loss: -0.7621  Acc@1: 87.5000 (85.1269)  Acc@5: 100.0000 (98.1715)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1260/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.5234  Acc@1: 87.5000 (85.1556)  Acc@5: 100.0000 (98.1860)  time: 0.3564  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1270/3125]  eta: 0:10:56  Lr: 0.001875  Loss: -0.8781  Acc@1: 87.5000 (85.1544)  Acc@5: 100.0000 (98.1904)  time: 0.3561  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1280/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.5635  Acc@1: 87.5000 (85.1825)  Acc@5: 100.0000 (98.1899)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1290/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.5825  Acc@1: 87.5000 (85.1617)  Acc@5: 100.0000 (98.1845)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1300/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.8704  Acc@1: 87.5000 (85.1989)  Acc@5: 100.0000 (98.1937)  time: 0.3529  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1310/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.3343  Acc@1: 87.5000 (85.1783)  Acc@5: 100.0000 (98.1979)  time: 0.3542  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1320/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.7525  Acc@1: 81.2500 (85.1911)  Acc@5: 100.0000 (98.2069)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1330/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.1768  Acc@1: 87.5000 (85.1850)  Acc@5: 100.0000 (98.2062)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1340/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.7620  Acc@1: 87.5000 (85.1836)  Acc@5: 100.0000 (98.1963)  time: 0.3545  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1350/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.5380  Acc@1: 87.5000 (85.1869)  Acc@5: 100.0000 (98.2004)  time: 0.3640  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1360/3125]  eta: 0:10:24  Lr: 0.001875  Loss: 0.0238  Acc@1: 87.5000 (85.1809)  Acc@5: 100.0000 (98.2044)  time: 0.3669  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1370/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.0958  Acc@1: 81.2500 (85.1568)  Acc@5: 100.0000 (98.2130)  time: 0.3591  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1380/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.6447  Acc@1: 81.2500 (85.1828)  Acc@5: 100.0000 (98.2214)  time: 0.3652  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1390/3125]  eta: 0:10:14  Lr: 0.001875  Loss: -0.6067  Acc@1: 87.5000 (85.1950)  Acc@5: 100.0000 (98.2117)  time: 0.3624  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1400/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.1490  Acc@1: 81.2500 (85.1579)  Acc@5: 100.0000 (98.1933)  time: 0.3518  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1410/3125]  eta: 0:10:07  Lr: 0.001875  Loss: -0.6176  Acc@1: 81.2500 (85.1701)  Acc@5: 100.0000 (98.1839)  time: 0.3546  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1420/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.5693  Acc@1: 81.2500 (85.1249)  Acc@5: 100.0000 (98.1791)  time: 0.3516  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1430/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.1587  Acc@1: 81.2500 (85.1197)  Acc@5: 100.0000 (98.1918)  time: 0.3496  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1440/3125]  eta: 0:09:56  Lr: 0.001875  Loss: -0.4940  Acc@1: 81.2500 (85.0972)  Acc@5: 100.0000 (98.1914)  time: 0.3513  data: 0.0023  max mem: 2502
Train: Epoch[2/5]  [1450/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.7980  Acc@1: 87.5000 (85.0965)  Acc@5: 100.0000 (98.1823)  time: 0.3509  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [1460/3125]  eta: 0:09:49  Lr: 0.001875  Loss: -0.6005  Acc@1: 87.5000 (85.1258)  Acc@5: 100.0000 (98.1862)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1470/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.7210  Acc@1: 87.5000 (85.1547)  Acc@5: 100.0000 (98.1943)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1480/3125]  eta: 0:09:42  Lr: 0.001875  Loss: -0.4816  Acc@1: 87.5000 (85.1452)  Acc@5: 100.0000 (98.1980)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1490/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.5298  Acc@1: 81.2500 (85.1232)  Acc@5: 100.0000 (98.1933)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1500/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.1154  Acc@1: 87.5000 (85.1349)  Acc@5: 100.0000 (98.1929)  time: 0.3519  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1510/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.8210  Acc@1: 87.5000 (85.1630)  Acc@5: 100.0000 (98.2007)  time: 0.3518  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1520/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.5447  Acc@1: 81.2500 (85.1537)  Acc@5: 100.0000 (98.1961)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1530/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.4378  Acc@1: 81.2500 (85.1486)  Acc@5: 100.0000 (98.1915)  time: 0.3593  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [1540/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.3953  Acc@1: 81.2500 (85.1436)  Acc@5: 100.0000 (98.1992)  time: 0.3600  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [1550/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.3685  Acc@1: 81.2500 (85.0983)  Acc@5: 100.0000 (98.1907)  time: 0.3527  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1560/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.4938  Acc@1: 81.2500 (85.0857)  Acc@5: 100.0000 (98.1983)  time: 0.3534  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1570/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.7430  Acc@1: 81.2500 (85.0732)  Acc@5: 100.0000 (98.1978)  time: 0.3577  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1580/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.8528  Acc@1: 87.5000 (85.0965)  Acc@5: 100.0000 (98.1934)  time: 0.3574  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1590/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.5385  Acc@1: 87.5000 (85.0605)  Acc@5: 100.0000 (98.2047)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1600/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.6851  Acc@1: 81.2500 (85.0718)  Acc@5: 100.0000 (98.2042)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1610/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.7165  Acc@1: 87.5000 (85.0675)  Acc@5: 100.0000 (98.1960)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1620/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.5727  Acc@1: 81.2500 (85.0594)  Acc@5: 100.0000 (98.1801)  time: 0.3529  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1630/3125]  eta: 0:08:48  Lr: 0.001875  Loss: -0.6791  Acc@1: 87.5000 (85.0667)  Acc@5: 100.0000 (98.1913)  time: 0.3528  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1640/3125]  eta: 0:08:45  Lr: 0.001875  Loss: -0.5732  Acc@1: 87.5000 (85.0625)  Acc@5: 100.0000 (98.1833)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1650/3125]  eta: 0:08:41  Lr: 0.001875  Loss: -0.5714  Acc@1: 87.5000 (85.0810)  Acc@5: 100.0000 (98.1943)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1660/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.2102  Acc@1: 87.5000 (85.0993)  Acc@5: 100.0000 (98.1788)  time: 0.3536  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1670/3125]  eta: 0:08:34  Lr: 0.001875  Loss: -0.2411  Acc@1: 87.5000 (85.0838)  Acc@5: 93.7500 (98.1710)  time: 0.3533  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1680/3125]  eta: 0:08:31  Lr: 0.001875  Loss: -0.4363  Acc@1: 87.5000 (85.0907)  Acc@5: 100.0000 (98.1670)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1690/3125]  eta: 0:08:27  Lr: 0.001875  Loss: -0.3621  Acc@1: 87.5000 (85.1013)  Acc@5: 100.0000 (98.1631)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1700/3125]  eta: 0:08:24  Lr: 0.001875  Loss: -0.6629  Acc@1: 87.5000 (85.1044)  Acc@5: 100.0000 (98.1665)  time: 0.3500  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1710/3125]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6616  Acc@1: 87.5000 (85.0928)  Acc@5: 100.0000 (98.1736)  time: 0.3509  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [1720/3125]  eta: 0:08:16  Lr: 0.001875  Loss: -0.6339  Acc@1: 87.5000 (85.1068)  Acc@5: 100.0000 (98.1806)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1730/3125]  eta: 0:08:13  Lr: 0.001875  Loss: -0.8188  Acc@1: 87.5000 (85.1495)  Acc@5: 100.0000 (98.1766)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1740/3125]  eta: 0:08:09  Lr: 0.001875  Loss: -0.6213  Acc@1: 87.5000 (85.1594)  Acc@5: 100.0000 (98.1799)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1750/3125]  eta: 0:08:06  Lr: 0.001875  Loss: -0.3127  Acc@1: 81.2500 (85.1406)  Acc@5: 100.0000 (98.1832)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1760/3125]  eta: 0:08:02  Lr: 0.001875  Loss: -0.6034  Acc@1: 81.2500 (85.1363)  Acc@5: 100.0000 (98.1899)  time: 0.3530  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1770/3125]  eta: 0:07:59  Lr: 0.001875  Loss: -0.5040  Acc@1: 87.5000 (85.1708)  Acc@5: 100.0000 (98.1931)  time: 0.3548  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1780/3125]  eta: 0:07:55  Lr: 0.001875  Loss: -0.8526  Acc@1: 93.7500 (85.1979)  Acc@5: 100.0000 (98.1927)  time: 0.3554  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1790/3125]  eta: 0:07:52  Lr: 0.001875  Loss: -0.7516  Acc@1: 87.5000 (85.2073)  Acc@5: 100.0000 (98.1924)  time: 0.3555  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1800/3125]  eta: 0:07:48  Lr: 0.001875  Loss: -0.5078  Acc@1: 87.5000 (85.2131)  Acc@5: 100.0000 (98.1850)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1810/3125]  eta: 0:07:45  Lr: 0.001875  Loss: -0.7033  Acc@1: 87.5000 (85.2119)  Acc@5: 100.0000 (98.1882)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1820/3125]  eta: 0:07:41  Lr: 0.001875  Loss: -0.4833  Acc@1: 87.5000 (85.2142)  Acc@5: 100.0000 (98.1844)  time: 0.3562  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1830/3125]  eta: 0:07:38  Lr: 0.001875  Loss: -0.5307  Acc@1: 87.5000 (85.2369)  Acc@5: 100.0000 (98.1875)  time: 0.3558  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1840/3125]  eta: 0:07:34  Lr: 0.001875  Loss: -0.6215  Acc@1: 87.5000 (85.2526)  Acc@5: 100.0000 (98.1871)  time: 0.3514  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1850/3125]  eta: 0:07:30  Lr: 0.001875  Loss: -0.6916  Acc@1: 87.5000 (85.2580)  Acc@5: 100.0000 (98.1935)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1860/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.6211  Acc@1: 81.2500 (85.2331)  Acc@5: 100.0000 (98.1932)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1870/3125]  eta: 0:07:23  Lr: 0.001875  Loss: -0.8440  Acc@1: 81.2500 (85.2251)  Acc@5: 100.0000 (98.1928)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1880/3125]  eta: 0:07:20  Lr: 0.001875  Loss: -0.4601  Acc@1: 81.2500 (85.2040)  Acc@5: 100.0000 (98.1958)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1890/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.7267  Acc@1: 81.2500 (85.2162)  Acc@5: 100.0000 (98.1954)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:13  Lr: 0.001875  Loss: -0.2468  Acc@1: 81.2500 (85.2084)  Acc@5: 100.0000 (98.1950)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1910/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.4009  Acc@1: 87.5000 (85.2335)  Acc@5: 100.0000 (98.1979)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1920/3125]  eta: 0:07:06  Lr: 0.001875  Loss: -0.8016  Acc@1: 87.5000 (85.2290)  Acc@5: 100.0000 (98.1943)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1930/3125]  eta: 0:07:02  Lr: 0.001875  Loss: 0.0028  Acc@1: 87.5000 (85.2311)  Acc@5: 100.0000 (98.2004)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1940/3125]  eta: 0:06:58  Lr: 0.001875  Loss: -0.5288  Acc@1: 87.5000 (85.2428)  Acc@5: 100.0000 (98.2065)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1950/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.2952  Acc@1: 81.2500 (85.2415)  Acc@5: 100.0000 (98.1964)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1960/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.5868  Acc@1: 81.2500 (85.2403)  Acc@5: 100.0000 (98.1993)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1970/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.4171  Acc@1: 87.5000 (85.2486)  Acc@5: 100.0000 (98.2021)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1980/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.6116  Acc@1: 87.5000 (85.2253)  Acc@5: 100.0000 (98.2048)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1990/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.4265  Acc@1: 87.5000 (85.2210)  Acc@5: 100.0000 (98.2044)  time: 0.3534  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2000/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.6345  Acc@1: 87.5000 (85.2293)  Acc@5: 100.0000 (98.2071)  time: 0.3519  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2010/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6122  Acc@1: 87.5000 (85.2219)  Acc@5: 100.0000 (98.2005)  time: 0.3504  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2020/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.5176  Acc@1: 81.2500 (85.2115)  Acc@5: 100.0000 (98.2032)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2030/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.6261  Acc@1: 81.2500 (85.2013)  Acc@5: 100.0000 (98.2029)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2040/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.1145  Acc@1: 81.2500 (85.2095)  Acc@5: 100.0000 (98.2055)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2050/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.8618  Acc@1: 87.5000 (85.2145)  Acc@5: 100.0000 (98.2112)  time: 0.3545  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.7906  Acc@1: 87.5000 (85.2468)  Acc@5: 100.0000 (98.2139)  time: 0.3543  data: 0.0024  max mem: 2502
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.2269  Acc@1: 87.5000 (85.2396)  Acc@5: 100.0000 (98.2164)  time: 0.3524  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [2080/3125]  eta: 0:06:09  Lr: 0.001875  Loss: -0.6651  Acc@1: 87.5000 (85.2385)  Acc@5: 100.0000 (98.2160)  time: 0.3517  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2090/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5538  Acc@1: 81.2500 (85.2313)  Acc@5: 100.0000 (98.2126)  time: 0.3546  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2100/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.5157  Acc@1: 87.5000 (85.2451)  Acc@5: 100.0000 (98.2151)  time: 0.3569  data: 0.0031  max mem: 2502
Train: Epoch[2/5]  [2110/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.4656  Acc@1: 87.5000 (85.2647)  Acc@5: 100.0000 (98.2206)  time: 0.3541  data: 0.0030  max mem: 2502
Train: Epoch[2/5]  [2120/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.4782  Acc@1: 87.5000 (85.2723)  Acc@5: 100.0000 (98.2261)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2130/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.4725  Acc@1: 81.2500 (85.2710)  Acc@5: 100.0000 (98.2256)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2140/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.7772  Acc@1: 87.5000 (85.2697)  Acc@5: 100.0000 (98.2280)  time: 0.3540  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2150/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.7312  Acc@1: 87.5000 (85.2859)  Acc@5: 100.0000 (98.2305)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2160/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.3771  Acc@1: 87.5000 (85.2730)  Acc@5: 100.0000 (98.2358)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2170/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6458  Acc@1: 81.2500 (85.2574)  Acc@5: 100.0000 (98.2381)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2180/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.4944  Acc@1: 81.2500 (85.2476)  Acc@5: 100.0000 (98.2348)  time: 0.3538  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2190/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.9032  Acc@1: 81.2500 (85.2579)  Acc@5: 100.0000 (98.2428)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2200/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.5946  Acc@1: 81.2500 (85.2567)  Acc@5: 100.0000 (98.2423)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.8271  Acc@1: 81.2500 (85.2612)  Acc@5: 100.0000 (98.2417)  time: 0.3519  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.5332  Acc@1: 87.5000 (85.2656)  Acc@5: 100.0000 (98.2412)  time: 0.3511  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.3333  Acc@1: 87.5000 (85.2645)  Acc@5: 100.0000 (98.2407)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4761  Acc@1: 87.5000 (85.2716)  Acc@5: 100.0000 (98.2458)  time: 0.3521  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.6830  Acc@1: 87.5000 (85.2815)  Acc@5: 100.0000 (98.2424)  time: 0.3537  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2260/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.4426  Acc@1: 87.5000 (85.3052)  Acc@5: 100.0000 (98.2475)  time: 0.3549  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2270/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.5121  Acc@1: 87.5000 (85.3066)  Acc@5: 100.0000 (98.2469)  time: 0.3535  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2280/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5174  Acc@1: 87.5000 (85.3052)  Acc@5: 100.0000 (98.2464)  time: 0.3529  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2290/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6220  Acc@1: 87.5000 (85.3121)  Acc@5: 100.0000 (98.2486)  time: 0.3552  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2300/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.5202  Acc@1: 81.2500 (85.2999)  Acc@5: 100.0000 (98.2480)  time: 0.3562  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2310/3125]  eta: 0:04:47  Lr: 0.001875  Loss: -0.3309  Acc@1: 81.2500 (85.3040)  Acc@5: 100.0000 (98.2475)  time: 0.3574  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2320/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.6490  Acc@1: 87.5000 (85.2811)  Acc@5: 100.0000 (98.2497)  time: 0.3542  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2330/3125]  eta: 0:04:40  Lr: 0.001875  Loss: -0.8356  Acc@1: 81.2500 (85.2906)  Acc@5: 100.0000 (98.2572)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2340/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.7490  Acc@1: 87.5000 (85.3081)  Acc@5: 100.0000 (98.2646)  time: 0.3522  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2350/3125]  eta: 0:04:33  Lr: 0.001875  Loss: -0.6328  Acc@1: 87.5000 (85.3227)  Acc@5: 100.0000 (98.2694)  time: 0.3628  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.7771  Acc@1: 87.5000 (85.3134)  Acc@5: 100.0000 (98.2634)  time: 0.3672  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:26  Lr: 0.001875  Loss: -0.3602  Acc@1: 81.2500 (85.3147)  Acc@5: 100.0000 (98.2681)  time: 0.3589  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.6991  Acc@1: 87.5000 (85.3292)  Acc@5: 100.0000 (98.2728)  time: 0.3540  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:19  Lr: 0.001875  Loss: -0.6712  Acc@1: 87.5000 (85.3304)  Acc@5: 100.0000 (98.2722)  time: 0.3770  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.8061  Acc@1: 87.5000 (85.3290)  Acc@5: 100.0000 (98.2768)  time: 0.3760  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:12  Lr: 0.001875  Loss: -0.7150  Acc@1: 87.5000 (85.3173)  Acc@5: 100.0000 (98.2813)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.6222  Acc@1: 87.5000 (85.3392)  Acc@5: 100.0000 (98.2858)  time: 0.3521  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2430/3125]  eta: 0:04:05  Lr: 0.001875  Loss: -0.2306  Acc@1: 87.5000 (85.3378)  Acc@5: 100.0000 (98.2903)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2440/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4444  Acc@1: 81.2500 (85.3160)  Acc@5: 100.0000 (98.2896)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2450/3125]  eta: 0:03:58  Lr: 0.001875  Loss: -0.6624  Acc@1: 87.5000 (85.3300)  Acc@5: 100.0000 (98.2941)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2460/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6046  Acc@1: 87.5000 (85.3032)  Acc@5: 100.0000 (98.2858)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2470/3125]  eta: 0:03:51  Lr: 0.001875  Loss: -0.2273  Acc@1: 87.5000 (85.2969)  Acc@5: 100.0000 (98.2902)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2480/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.0700  Acc@1: 87.5000 (85.3058)  Acc@5: 100.0000 (98.2845)  time: 0.3503  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2490/3125]  eta: 0:03:44  Lr: 0.001875  Loss: -0.3766  Acc@1: 87.5000 (85.3171)  Acc@5: 100.0000 (98.2838)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2500/3125]  eta: 0:03:40  Lr: 0.001875  Loss: -0.3901  Acc@1: 87.5000 (85.3259)  Acc@5: 100.0000 (98.2832)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2510/3125]  eta: 0:03:37  Lr: 0.001875  Loss: -0.6122  Acc@1: 81.2500 (85.3121)  Acc@5: 100.0000 (98.2850)  time: 0.3527  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:33  Lr: 0.001875  Loss: -0.6824  Acc@1: 81.2500 (85.3109)  Acc@5: 100.0000 (98.2918)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:30  Lr: 0.001875  Loss: -0.2597  Acc@1: 87.5000 (85.3245)  Acc@5: 100.0000 (98.2912)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:26  Lr: 0.001875  Loss: -0.5766  Acc@1: 87.5000 (85.3207)  Acc@5: 100.0000 (98.2856)  time: 0.3540  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:23  Lr: 0.001875  Loss: -0.3811  Acc@1: 81.2500 (85.3268)  Acc@5: 100.0000 (98.2874)  time: 0.3546  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:19  Lr: 0.001875  Loss: -0.8002  Acc@1: 87.5000 (85.3475)  Acc@5: 100.0000 (98.2917)  time: 0.3577  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:16  Lr: 0.001875  Loss: -0.5039  Acc@1: 87.5000 (85.3510)  Acc@5: 100.0000 (98.2910)  time: 0.3582  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:12  Lr: 0.001875  Loss: -0.6027  Acc@1: 87.5000 (85.3666)  Acc@5: 100.0000 (98.2928)  time: 0.3542  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:09  Lr: 0.001875  Loss: -0.3500  Acc@1: 87.5000 (85.3628)  Acc@5: 100.0000 (98.2922)  time: 0.3600  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:05  Lr: 0.001875  Loss: -0.7586  Acc@1: 87.5000 (85.3878)  Acc@5: 100.0000 (98.2939)  time: 0.3579  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2610/3125]  eta: 0:03:02  Lr: 0.001875  Loss: -0.4900  Acc@1: 87.5000 (85.3983)  Acc@5: 100.0000 (98.2909)  time: 0.3542  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2620/3125]  eta: 0:02:58  Lr: 0.001875  Loss: -0.7074  Acc@1: 87.5000 (85.3896)  Acc@5: 100.0000 (98.2831)  time: 0.3939  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2630/3125]  eta: 0:02:55  Lr: 0.001875  Loss: -0.5486  Acc@1: 81.2500 (85.3905)  Acc@5: 100.0000 (98.2849)  time: 0.5017  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2640/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.9554  Acc@1: 87.5000 (85.3985)  Acc@5: 100.0000 (98.2795)  time: 0.4618  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2650/3125]  eta: 0:02:48  Lr: 0.001875  Loss: -0.3718  Acc@1: 81.2500 (85.3899)  Acc@5: 100.0000 (98.2695)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2660/3125]  eta: 0:02:44  Lr: 0.001875  Loss: -0.8057  Acc@1: 87.5000 (85.4026)  Acc@5: 100.0000 (98.2666)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:41  Lr: 0.001875  Loss: -0.3350  Acc@1: 87.5000 (85.3987)  Acc@5: 100.0000 (98.2684)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:37  Lr: 0.001875  Loss: -0.6928  Acc@1: 87.5000 (85.4159)  Acc@5: 100.0000 (98.2679)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:34  Lr: 0.001875  Loss: -0.2183  Acc@1: 87.5000 (85.4051)  Acc@5: 100.0000 (98.2674)  time: 0.3494  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4440  Acc@1: 81.2500 (85.4012)  Acc@5: 100.0000 (98.2715)  time: 0.3493  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:27  Lr: 0.001875  Loss: -0.3482  Acc@1: 81.2500 (85.3975)  Acc@5: 100.0000 (98.2663)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:23  Lr: 0.001875  Loss: -0.6875  Acc@1: 87.5000 (85.4052)  Acc@5: 100.0000 (98.2658)  time: 0.3518  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:20  Lr: 0.001875  Loss: -0.8244  Acc@1: 87.5000 (85.4129)  Acc@5: 100.0000 (98.2676)  time: 0.3530  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:16  Lr: 0.001875  Loss: -0.4513  Acc@1: 87.5000 (85.4045)  Acc@5: 100.0000 (98.2671)  time: 0.3553  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:12  Lr: 0.001875  Loss: -0.0840  Acc@1: 87.5000 (85.4099)  Acc@5: 100.0000 (98.2665)  time: 0.3539  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:09  Lr: 0.001875  Loss: -0.4491  Acc@1: 87.5000 (85.4061)  Acc@5: 100.0000 (98.2638)  time: 0.3514  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:05  Lr: 0.001875  Loss: -0.8484  Acc@1: 81.2500 (85.4204)  Acc@5: 100.0000 (98.2655)  time: 0.3559  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2780/3125]  eta: 0:02:02  Lr: 0.001875  Loss: -0.5504  Acc@1: 93.7500 (85.4481)  Acc@5: 100.0000 (98.2718)  time: 0.3564  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2790/3125]  eta: 0:01:58  Lr: 0.001875  Loss: -0.5617  Acc@1: 87.5000 (85.4353)  Acc@5: 100.0000 (98.2668)  time: 0.3539  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2800/3125]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4754  Acc@1: 87.5000 (85.4449)  Acc@5: 100.0000 (98.2662)  time: 0.3536  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2810/3125]  eta: 0:01:51  Lr: 0.001875  Loss: -0.7322  Acc@1: 87.5000 (85.4545)  Acc@5: 100.0000 (98.2680)  time: 0.3550  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:48  Lr: 0.001875  Loss: -0.8526  Acc@1: 87.5000 (85.4617)  Acc@5: 100.0000 (98.2697)  time: 0.3544  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8303  Acc@1: 87.5000 (85.4601)  Acc@5: 100.0000 (98.2692)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8908  Acc@1: 87.5000 (85.4695)  Acc@5: 100.0000 (98.2753)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:37  Lr: 0.001875  Loss: -0.1988  Acc@1: 87.5000 (85.4634)  Acc@5: 100.0000 (98.2747)  time: 0.3534  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:33  Lr: 0.001875  Loss: -0.2545  Acc@1: 87.5000 (85.4684)  Acc@5: 100.0000 (98.2764)  time: 0.3531  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:30  Lr: 0.001875  Loss: -0.4108  Acc@1: 87.5000 (85.4602)  Acc@5: 100.0000 (98.2737)  time: 0.3521  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:26  Lr: 0.001875  Loss: -0.2331  Acc@1: 87.5000 (85.4586)  Acc@5: 100.0000 (98.2775)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:23  Lr: 0.001875  Loss: -0.3103  Acc@1: 87.5000 (85.4570)  Acc@5: 100.0000 (98.2748)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:19  Lr: 0.001875  Loss: -0.2976  Acc@1: 87.5000 (85.4533)  Acc@5: 100.0000 (98.2743)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:16  Lr: 0.001875  Loss: -0.8978  Acc@1: 87.5000 (85.4689)  Acc@5: 100.0000 (98.2759)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:12  Lr: 0.001875  Loss: -0.6293  Acc@1: 87.5000 (85.4780)  Acc@5: 100.0000 (98.2776)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:09  Lr: 0.001875  Loss: -0.2636  Acc@1: 87.5000 (85.4764)  Acc@5: 100.0000 (98.2749)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:05  Lr: 0.001875  Loss: 0.0611  Acc@1: 87.5000 (85.4769)  Acc@5: 100.0000 (98.2701)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:02  Lr: 0.001875  Loss: -0.4665  Acc@1: 87.5000 (85.4816)  Acc@5: 100.0000 (98.2697)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2960/3125]  eta: 0:00:58  Lr: 0.001875  Loss: -0.4443  Acc@1: 87.5000 (85.4927)  Acc@5: 100.0000 (98.2671)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5240  Acc@1: 87.5000 (85.4973)  Acc@5: 100.0000 (98.2603)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:51  Lr: 0.001875  Loss: -0.1494  Acc@1: 87.5000 (85.5019)  Acc@5: 100.0000 (98.2598)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6343  Acc@1: 87.5000 (85.5023)  Acc@5: 100.0000 (98.2594)  time: 0.3525  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5462  Acc@1: 87.5000 (85.5132)  Acc@5: 100.0000 (98.2631)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4580  Acc@1: 87.5000 (85.4990)  Acc@5: 100.0000 (98.2585)  time: 0.3525  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.3857  Acc@1: 87.5000 (85.5118)  Acc@5: 100.0000 (98.2580)  time: 0.3562  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7883  Acc@1: 87.5000 (85.5060)  Acc@5: 100.0000 (98.2576)  time: 0.3577  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0227  Acc@1: 87.5000 (85.5044)  Acc@5: 100.0000 (98.2613)  time: 0.3544  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.7267  Acc@1: 81.2500 (85.5007)  Acc@5: 100.0000 (98.2588)  time: 0.3580  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:23  Lr: 0.001875  Loss: -0.7402  Acc@1: 81.2500 (85.5031)  Acc@5: 100.0000 (98.2624)  time: 0.3616  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.2794  Acc@1: 81.2500 (85.4913)  Acc@5: 100.0000 (98.2640)  time: 0.3565  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.5816  Acc@1: 87.5000 (85.4938)  Acc@5: 100.0000 (98.2595)  time: 0.3541  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.2626  Acc@1: 87.5000 (85.4881)  Acc@5: 100.0000 (98.2550)  time: 0.3676  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.4515  Acc@1: 87.5000 (85.4785)  Acc@5: 100.0000 (98.2566)  time: 0.3656  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5923  Acc@1: 87.5000 (85.4749)  Acc@5: 100.0000 (98.2602)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5521  Acc@1: 87.5000 (85.4794)  Acc@5: 100.0000 (98.2618)  time: 0.3517  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4442  Acc@1: 81.2500 (85.4640)  Acc@5: 100.0000 (98.2560)  time: 0.3530  data: 0.0013  max mem: 2502
Train: Epoch[2/5] Total time: 0:18:28 (0.3547 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4442  Acc@1: 81.2500 (85.4640)  Acc@5: 100.0000 (98.2560)
Train: Epoch[3/5]  [   0/3125]  eta: 0:47:24  Lr: 0.001875  Loss: -0.6817  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.9101  data: 0.5592  max mem: 2502
Train: Epoch[3/5]  [  10/3125]  eta: 0:20:46  Lr: 0.001875  Loss: -0.6196  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.2955)  time: 0.4003  data: 0.0512  max mem: 2502
Train: Epoch[3/5]  [  20/3125]  eta: 0:19:30  Lr: 0.001875  Loss: -0.7754  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.5119)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  30/3125]  eta: 0:19:03  Lr: 0.001875  Loss: -0.6395  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.7903)  time: 0.3528  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  40/3125]  eta: 0:18:45  Lr: 0.001875  Loss: -0.6101  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (98.7805)  time: 0.3519  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  50/3125]  eta: 0:18:31  Lr: 0.001875  Loss: -0.2442  Acc@1: 81.2500 (85.1716)  Acc@5: 100.0000 (98.6520)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  60/3125]  eta: 0:18:21  Lr: 0.001875  Loss: -0.6062  Acc@1: 87.5000 (85.6557)  Acc@5: 100.0000 (98.6680)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  70/3125]  eta: 0:18:15  Lr: 0.001875  Loss: -0.6638  Acc@1: 87.5000 (85.5634)  Acc@5: 100.0000 (98.6796)  time: 0.3518  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [  80/3125]  eta: 0:18:07  Lr: 0.001875  Loss: -0.1816  Acc@1: 87.5000 (85.8025)  Acc@5: 100.0000 (98.4568)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [  90/3125]  eta: 0:18:02  Lr: 0.001875  Loss: -0.4843  Acc@1: 87.5000 (85.3709)  Acc@5: 100.0000 (98.6264)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 100/3125]  eta: 0:17:57  Lr: 0.001875  Loss: -0.5901  Acc@1: 87.5000 (86.0149)  Acc@5: 100.0000 (98.7005)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 110/3125]  eta: 0:17:53  Lr: 0.001875  Loss: -0.4253  Acc@1: 87.5000 (85.9797)  Acc@5: 100.0000 (98.6486)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 120/3125]  eta: 0:17:49  Lr: 0.001875  Loss: -0.6067  Acc@1: 87.5000 (85.8988)  Acc@5: 100.0000 (98.5021)  time: 0.3536  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 130/3125]  eta: 0:17:45  Lr: 0.001875  Loss: -0.8334  Acc@1: 87.5000 (86.0687)  Acc@5: 100.0000 (98.5210)  time: 0.3551  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 140/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.8733  Acc@1: 87.5000 (86.0816)  Acc@5: 100.0000 (98.6259)  time: 0.3549  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 150/3125]  eta: 0:17:38  Lr: 0.001875  Loss: -0.4737  Acc@1: 87.5000 (86.0513)  Acc@5: 100.0000 (98.6341)  time: 0.3550  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 160/3125]  eta: 0:17:33  Lr: 0.001875  Loss: -0.6657  Acc@1: 87.5000 (86.1025)  Acc@5: 100.0000 (98.6413)  time: 0.3529  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 170/3125]  eta: 0:17:29  Lr: 0.001875  Loss: -0.8374  Acc@1: 87.5000 (86.1111)  Acc@5: 100.0000 (98.6111)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 180/3125]  eta: 0:17:25  Lr: 0.001875  Loss: -0.6040  Acc@1: 87.5000 (86.1878)  Acc@5: 100.0000 (98.5843)  time: 0.3534  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 190/3125]  eta: 0:17:21  Lr: 0.001875  Loss: -0.8094  Acc@1: 87.5000 (86.4202)  Acc@5: 100.0000 (98.5929)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 200/3125]  eta: 0:17:18  Lr: 0.001875  Loss: -0.5892  Acc@1: 93.7500 (86.5672)  Acc@5: 100.0000 (98.6318)  time: 0.3539  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 210/3125]  eta: 0:17:14  Lr: 0.001875  Loss: -0.6233  Acc@1: 87.5000 (86.6410)  Acc@5: 100.0000 (98.6374)  time: 0.3542  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 220/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.3827  Acc@1: 87.5000 (86.6233)  Acc@5: 100.0000 (98.6708)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 230/3125]  eta: 0:17:06  Lr: 0.001875  Loss: -0.3709  Acc@1: 87.5000 (86.5260)  Acc@5: 100.0000 (98.6742)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 240/3125]  eta: 0:17:02  Lr: 0.001875  Loss: -0.8161  Acc@1: 87.5000 (86.5405)  Acc@5: 100.0000 (98.6255)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 250/3125]  eta: 0:16:58  Lr: 0.001875  Loss: -0.3155  Acc@1: 87.5000 (86.5040)  Acc@5: 100.0000 (98.6554)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 260/3125]  eta: 0:16:55  Lr: 0.001875  Loss: -0.1677  Acc@1: 87.5000 (86.4703)  Acc@5: 100.0000 (98.6590)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 270/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.3785  Acc@1: 87.5000 (86.4391)  Acc@5: 100.0000 (98.6624)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 280/3125]  eta: 0:16:47  Lr: 0.001875  Loss: -0.3571  Acc@1: 87.5000 (86.4769)  Acc@5: 100.0000 (98.6432)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 290/3125]  eta: 0:16:43  Lr: 0.001875  Loss: -0.4858  Acc@1: 81.2500 (86.3402)  Acc@5: 100.0000 (98.6684)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 300/3125]  eta: 0:16:39  Lr: 0.001875  Loss: -0.5033  Acc@1: 81.2500 (86.2749)  Acc@5: 100.0000 (98.6088)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 310/3125]  eta: 0:16:35  Lr: 0.001875  Loss: -0.2191  Acc@1: 87.5000 (86.3143)  Acc@5: 100.0000 (98.6334)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 320/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.4964  Acc@1: 87.5000 (86.3512)  Acc@5: 100.0000 (98.6565)  time: 0.3505  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 330/3125]  eta: 0:16:28  Lr: 0.001875  Loss: -0.5523  Acc@1: 87.5000 (86.3671)  Acc@5: 100.0000 (98.6405)  time: 0.3512  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 340/3125]  eta: 0:16:24  Lr: 0.001875  Loss: -0.5845  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.6254)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 350/3125]  eta: 0:16:20  Lr: 0.001875  Loss: -0.2257  Acc@1: 81.2500 (86.1467)  Acc@5: 100.0000 (98.6111)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 360/3125]  eta: 0:16:17  Lr: 0.001875  Loss: -0.3317  Acc@1: 81.2500 (86.0976)  Acc@5: 100.0000 (98.6150)  time: 0.3522  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 370/3125]  eta: 0:16:13  Lr: 0.001875  Loss: -0.1330  Acc@1: 87.5000 (86.2365)  Acc@5: 100.0000 (98.6018)  time: 0.3527  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 380/3125]  eta: 0:16:10  Lr: 0.001875  Loss: -0.8144  Acc@1: 87.5000 (86.3353)  Acc@5: 100.0000 (98.6056)  time: 0.3542  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 390/3125]  eta: 0:16:06  Lr: 0.001875  Loss: -0.5060  Acc@1: 87.5000 (86.2852)  Acc@5: 100.0000 (98.6413)  time: 0.3553  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 400/3125]  eta: 0:16:03  Lr: 0.001875  Loss: -0.3380  Acc@1: 81.2500 (86.1128)  Acc@5: 100.0000 (98.5817)  time: 0.3546  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [ 410/3125]  eta: 0:15:59  Lr: 0.001875  Loss: -0.6088  Acc@1: 87.5000 (86.1162)  Acc@5: 100.0000 (98.5858)  time: 0.3508  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 420/3125]  eta: 0:15:55  Lr: 0.001875  Loss: -0.4179  Acc@1: 87.5000 (86.1639)  Acc@5: 100.0000 (98.6194)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 430/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.5413  Acc@1: 87.5000 (86.1079)  Acc@5: 100.0000 (98.5789)  time: 0.3515  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 440/3125]  eta: 0:15:48  Lr: 0.001875  Loss: -0.4576  Acc@1: 81.2500 (86.0828)  Acc@5: 100.0000 (98.5828)  time: 0.3539  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 450/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.4555  Acc@1: 87.5000 (86.0588)  Acc@5: 100.0000 (98.6003)  time: 0.3574  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 460/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.7902  Acc@1: 87.5000 (86.1578)  Acc@5: 100.0000 (98.6036)  time: 0.3550  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 470/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.5975  Acc@1: 93.7500 (86.2128)  Acc@5: 100.0000 (98.6067)  time: 0.3499  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 480/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.2350  Acc@1: 87.5000 (86.2526)  Acc@5: 100.0000 (98.5837)  time: 0.3523  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 490/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.6339  Acc@1: 87.5000 (86.3162)  Acc@5: 100.0000 (98.5998)  time: 0.3533  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 500/3125]  eta: 0:15:27  Lr: 0.001875  Loss: -0.6566  Acc@1: 87.5000 (86.3523)  Acc@5: 100.0000 (98.6028)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 510/3125]  eta: 0:15:23  Lr: 0.001875  Loss: -0.5918  Acc@1: 87.5000 (86.4114)  Acc@5: 100.0000 (98.5934)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 520/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.5889  Acc@1: 87.5000 (86.4083)  Acc@5: 100.0000 (98.6084)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 530/3125]  eta: 0:15:16  Lr: 0.001875  Loss: -0.1172  Acc@1: 87.5000 (86.3583)  Acc@5: 100.0000 (98.5993)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 540/3125]  eta: 0:15:12  Lr: 0.001875  Loss: -0.5816  Acc@1: 81.2500 (86.3101)  Acc@5: 100.0000 (98.5790)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 550/3125]  eta: 0:15:09  Lr: 0.001875  Loss: -0.5788  Acc@1: 87.5000 (86.2636)  Acc@5: 100.0000 (98.5821)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 560/3125]  eta: 0:15:05  Lr: 0.001875  Loss: -0.2510  Acc@1: 87.5000 (86.2188)  Acc@5: 100.0000 (98.5517)  time: 0.3510  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 570/3125]  eta: 0:15:01  Lr: 0.001875  Loss: -0.3399  Acc@1: 87.5000 (86.2960)  Acc@5: 100.0000 (98.5661)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 580/3125]  eta: 0:14:58  Lr: 0.001875  Loss: -0.7809  Acc@1: 87.5000 (86.3167)  Acc@5: 100.0000 (98.5908)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 590/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.7201  Acc@1: 87.5000 (86.3261)  Acc@5: 100.0000 (98.5723)  time: 0.3556  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 600/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.4790  Acc@1: 87.5000 (86.3353)  Acc@5: 100.0000 (98.5753)  time: 0.3558  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 610/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.8631  Acc@1: 93.7500 (86.3748)  Acc@5: 100.0000 (98.5884)  time: 0.3514  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 620/3125]  eta: 0:14:44  Lr: 0.001875  Loss: -0.8107  Acc@1: 87.5000 (86.3929)  Acc@5: 100.0000 (98.5709)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 630/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.2987  Acc@1: 81.2500 (86.3411)  Acc@5: 100.0000 (98.5440)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 640/3125]  eta: 0:14:37  Lr: 0.001875  Loss: 0.1619  Acc@1: 81.2500 (86.2227)  Acc@5: 100.0000 (98.5374)  time: 0.3600  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 650/3125]  eta: 0:14:34  Lr: 0.001875  Loss: -0.8251  Acc@1: 81.2500 (86.2135)  Acc@5: 100.0000 (98.5599)  time: 0.3587  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 660/3125]  eta: 0:14:30  Lr: 0.001875  Loss: -0.2314  Acc@1: 87.5000 (86.1857)  Acc@5: 100.0000 (98.5439)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 670/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.8173  Acc@1: 87.5000 (86.2146)  Acc@5: 100.0000 (98.5283)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 680/3125]  eta: 0:14:23  Lr: 0.001875  Loss: -0.1946  Acc@1: 81.2500 (86.2335)  Acc@5: 100.0000 (98.5132)  time: 0.3550  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 690/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.6635  Acc@1: 87.5000 (86.2518)  Acc@5: 100.0000 (98.5257)  time: 0.3566  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 700/3125]  eta: 0:14:16  Lr: 0.001875  Loss: -0.6943  Acc@1: 87.5000 (86.2429)  Acc@5: 100.0000 (98.5378)  time: 0.3542  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 710/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.3423  Acc@1: 87.5000 (86.2605)  Acc@5: 100.0000 (98.5496)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 720/3125]  eta: 0:14:09  Lr: 0.001875  Loss: -0.3348  Acc@1: 87.5000 (86.2864)  Acc@5: 100.0000 (98.5610)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 730/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.7286  Acc@1: 87.5000 (86.3372)  Acc@5: 100.0000 (98.5636)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 740/3125]  eta: 0:14:02  Lr: 0.001875  Loss: -0.4938  Acc@1: 87.5000 (86.3529)  Acc@5: 100.0000 (98.5661)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 750/3125]  eta: 0:13:58  Lr: 0.001875  Loss: -0.7179  Acc@1: 87.5000 (86.3931)  Acc@5: 100.0000 (98.5686)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 760/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6516  Acc@1: 87.5000 (86.3502)  Acc@5: 100.0000 (98.5463)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 770/3125]  eta: 0:13:51  Lr: 0.001875  Loss: -0.5872  Acc@1: 87.5000 (86.3489)  Acc@5: 100.0000 (98.5490)  time: 0.3527  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 780/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.3904  Acc@1: 87.5000 (86.3956)  Acc@5: 100.0000 (98.5595)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 790/3125]  eta: 0:13:44  Lr: 0.001875  Loss: -0.6607  Acc@1: 93.7500 (86.4570)  Acc@5: 100.0000 (98.5698)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 800/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.8275  Acc@1: 93.7500 (86.4778)  Acc@5: 100.0000 (98.5409)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 810/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.8532  Acc@1: 87.5000 (86.4982)  Acc@5: 100.0000 (98.5435)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 820/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.5943  Acc@1: 87.5000 (86.4951)  Acc@5: 100.0000 (98.5536)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 830/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.2343  Acc@1: 87.5000 (86.5223)  Acc@5: 100.0000 (98.5484)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 840/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.4853  Acc@1: 93.7500 (86.5636)  Acc@5: 100.0000 (98.5434)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 850/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.4901  Acc@1: 93.7500 (86.5893)  Acc@5: 100.0000 (98.5605)  time: 0.3551  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 860/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.4470  Acc@1: 87.5000 (86.5418)  Acc@5: 100.0000 (98.5700)  time: 0.3558  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 870/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6668  Acc@1: 87.5000 (86.5528)  Acc@5: 100.0000 (98.5720)  time: 0.3536  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 880/3125]  eta: 0:13:12  Lr: 0.001875  Loss: -0.7406  Acc@1: 87.5000 (86.5707)  Acc@5: 100.0000 (98.5741)  time: 0.3530  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 890/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.4133  Acc@1: 87.5000 (86.5530)  Acc@5: 100.0000 (98.5760)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 900/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.4572  Acc@1: 87.5000 (86.5774)  Acc@5: 100.0000 (98.5849)  time: 0.3578  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 910/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.5555  Acc@1: 87.5000 (86.6013)  Acc@5: 100.0000 (98.5799)  time: 0.3573  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 920/3125]  eta: 0:12:58  Lr: 0.001875  Loss: 0.0129  Acc@1: 87.5000 (86.5907)  Acc@5: 100.0000 (98.5681)  time: 0.3509  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 930/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.8425  Acc@1: 87.5000 (86.6004)  Acc@5: 100.0000 (98.5499)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 940/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.2608  Acc@1: 81.2500 (86.5701)  Acc@5: 100.0000 (98.5454)  time: 0.3558  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 950/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.6544  Acc@1: 81.2500 (86.5471)  Acc@5: 100.0000 (98.5344)  time: 0.3555  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 960/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.3057  Acc@1: 81.2500 (86.5310)  Acc@5: 100.0000 (98.5367)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 970/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.6793  Acc@1: 87.5000 (86.5796)  Acc@5: 100.0000 (98.5453)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 980/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.4330  Acc@1: 87.5000 (86.5698)  Acc@5: 100.0000 (98.5347)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 990/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.9345  Acc@1: 87.5000 (86.5477)  Acc@5: 100.0000 (98.5368)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1000/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.5268  Acc@1: 87.5000 (86.5697)  Acc@5: 100.0000 (98.5327)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1010/3125]  eta: 0:12:26  Lr: 0.001875  Loss: 0.0088  Acc@1: 87.5000 (86.5356)  Acc@5: 100.0000 (98.5287)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1020/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.1861  Acc@1: 81.2500 (86.4594)  Acc@5: 100.0000 (98.5186)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1030/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.2753  Acc@1: 87.5000 (86.4816)  Acc@5: 100.0000 (98.5148)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1040/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.4709  Acc@1: 87.5000 (86.5034)  Acc@5: 100.0000 (98.5231)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1050/3125]  eta: 0:12:11  Lr: 0.001875  Loss: -0.6699  Acc@1: 87.5000 (86.5069)  Acc@5: 100.0000 (98.5252)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1060/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.5866  Acc@1: 87.5000 (86.5104)  Acc@5: 100.0000 (98.5273)  time: 0.3524  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [1070/3125]  eta: 0:12:04  Lr: 0.001875  Loss: -0.4883  Acc@1: 87.5000 (86.5138)  Acc@5: 100.0000 (98.5236)  time: 0.3523  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [1080/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.3969  Acc@1: 87.5000 (86.5229)  Acc@5: 100.0000 (98.5083)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1090/3125]  eta: 0:11:57  Lr: 0.001875  Loss: -0.6340  Acc@1: 87.5000 (86.5376)  Acc@5: 100.0000 (98.5105)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1100/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.7664  Acc@1: 87.5000 (86.5520)  Acc@5: 100.0000 (98.5070)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1110/3125]  eta: 0:11:50  Lr: 0.001875  Loss: -0.7690  Acc@1: 87.5000 (86.5155)  Acc@5: 100.0000 (98.5092)  time: 0.3514  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1120/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.3486  Acc@1: 87.5000 (86.5020)  Acc@5: 100.0000 (98.5169)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1130/3125]  eta: 0:11:43  Lr: 0.001875  Loss: -0.4303  Acc@1: 87.5000 (86.5274)  Acc@5: 100.0000 (98.5245)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1140/3125]  eta: 0:11:39  Lr: 0.001875  Loss: -0.1131  Acc@1: 87.5000 (86.5195)  Acc@5: 100.0000 (98.5210)  time: 0.3531  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1150/3125]  eta: 0:11:36  Lr: 0.001875  Loss: -0.6620  Acc@1: 87.5000 (86.4954)  Acc@5: 100.0000 (98.5285)  time: 0.3561  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1160/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.4135  Acc@1: 81.2500 (86.4610)  Acc@5: 100.0000 (98.5304)  time: 0.3555  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1170/3125]  eta: 0:11:29  Lr: 0.001875  Loss: -0.5185  Acc@1: 87.5000 (86.4592)  Acc@5: 100.0000 (98.5376)  time: 0.3565  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1180/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.7205  Acc@1: 87.5000 (86.4733)  Acc@5: 100.0000 (98.5394)  time: 0.3627  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1190/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.6941  Acc@1: 87.5000 (86.4977)  Acc@5: 100.0000 (98.5411)  time: 0.3585  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1200/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.7177  Acc@1: 87.5000 (86.4748)  Acc@5: 100.0000 (98.5429)  time: 0.3580  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1210/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.7429  Acc@1: 81.2500 (86.4162)  Acc@5: 100.0000 (98.5394)  time: 0.3738  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1220/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.2574  Acc@1: 87.5000 (86.4148)  Acc@5: 100.0000 (98.5514)  time: 0.3668  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1230/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.7708  Acc@1: 87.5000 (86.4490)  Acc@5: 100.0000 (98.5632)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1240/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.7036  Acc@1: 87.5000 (86.4273)  Acc@5: 100.0000 (98.5647)  time: 0.3548  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1250/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.7210  Acc@1: 87.5000 (86.4458)  Acc@5: 100.0000 (98.5711)  time: 0.3542  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1260/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.4991  Acc@1: 87.5000 (86.4592)  Acc@5: 100.0000 (98.5775)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1270/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.4366  Acc@1: 87.5000 (86.4821)  Acc@5: 100.0000 (98.5690)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1280/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.2412  Acc@1: 87.5000 (86.4608)  Acc@5: 93.7500 (98.5509)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1290/3125]  eta: 0:10:47  Lr: 0.001875  Loss: -0.6712  Acc@1: 87.5000 (86.4737)  Acc@5: 100.0000 (98.5525)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1300/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.4092  Acc@1: 87.5000 (86.4575)  Acc@5: 100.0000 (98.5444)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1310/3125]  eta: 0:10:40  Lr: 0.001875  Loss: -0.5801  Acc@1: 81.2500 (86.4226)  Acc@5: 100.0000 (98.5507)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1320/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.1626  Acc@1: 81.2500 (86.3976)  Acc@5: 100.0000 (98.5475)  time: 0.3578  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1330/3125]  eta: 0:10:33  Lr: 0.001875  Loss: -0.7325  Acc@1: 81.2500 (86.3449)  Acc@5: 100.0000 (98.5537)  time: 0.3614  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1340/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.4098  Acc@1: 81.2500 (86.3395)  Acc@5: 100.0000 (98.5505)  time: 0.3542  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1350/3125]  eta: 0:10:26  Lr: 0.001875  Loss: -0.1763  Acc@1: 87.5000 (86.3157)  Acc@5: 100.0000 (98.5474)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1360/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.7423  Acc@1: 87.5000 (86.3244)  Acc@5: 100.0000 (98.5489)  time: 0.3687  data: 0.0023  max mem: 2502
Train: Epoch[3/5]  [1370/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.1978  Acc@1: 87.5000 (86.3102)  Acc@5: 100.0000 (98.5458)  time: 0.3695  data: 0.0025  max mem: 2502
Train: Epoch[3/5]  [1380/3125]  eta: 0:10:16  Lr: 0.001875  Loss: 0.0014  Acc@1: 87.5000 (86.3097)  Acc@5: 100.0000 (98.5472)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1390/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.0147  Acc@1: 93.7500 (86.3183)  Acc@5: 100.0000 (98.5532)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1400/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.2563  Acc@1: 81.2500 (86.2955)  Acc@5: 100.0000 (98.5457)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1410/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.6892  Acc@1: 81.2500 (86.2819)  Acc@5: 100.0000 (98.5516)  time: 0.3559  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1420/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.3714  Acc@1: 87.5000 (86.2861)  Acc@5: 100.0000 (98.5530)  time: 0.3539  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1430/3125]  eta: 0:09:58  Lr: 0.001875  Loss: -0.4821  Acc@1: 87.5000 (86.2378)  Acc@5: 100.0000 (98.5587)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1440/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.6642  Acc@1: 81.2500 (86.2162)  Acc@5: 100.0000 (98.5557)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1450/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.2468  Acc@1: 87.5000 (86.2336)  Acc@5: 100.0000 (98.5613)  time: 0.3522  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1460/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.3168  Acc@1: 87.5000 (86.2337)  Acc@5: 100.0000 (98.5626)  time: 0.3536  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1470/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.6008  Acc@1: 87.5000 (86.2466)  Acc@5: 100.0000 (98.5597)  time: 0.3525  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1480/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.4049  Acc@1: 87.5000 (86.2424)  Acc@5: 100.0000 (98.5652)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1490/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.6811  Acc@1: 81.2500 (86.2089)  Acc@5: 100.0000 (98.5706)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1500/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.3015  Acc@1: 81.2500 (86.1925)  Acc@5: 100.0000 (98.5676)  time: 0.3622  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1510/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.2541  Acc@1: 81.2500 (86.1764)  Acc@5: 100.0000 (98.5647)  time: 0.3629  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1520/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.8293  Acc@1: 87.5000 (86.1892)  Acc@5: 100.0000 (98.5618)  time: 0.3509  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1530/3125]  eta: 0:09:23  Lr: 0.001875  Loss: -0.4884  Acc@1: 87.5000 (86.2018)  Acc@5: 100.0000 (98.5630)  time: 0.3624  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1540/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.3987  Acc@1: 87.5000 (86.2184)  Acc@5: 100.0000 (98.5724)  time: 0.3626  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1550/3125]  eta: 0:09:16  Lr: 0.001875  Loss: -0.7697  Acc@1: 87.5000 (86.2307)  Acc@5: 100.0000 (98.5816)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1560/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.0891  Acc@1: 87.5000 (86.2028)  Acc@5: 100.0000 (98.5826)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1570/3125]  eta: 0:09:09  Lr: 0.001875  Loss: -0.7098  Acc@1: 81.2500 (86.1991)  Acc@5: 100.0000 (98.5797)  time: 0.3461  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1580/3125]  eta: 0:09:05  Lr: 0.001875  Loss: -0.8185  Acc@1: 81.2500 (86.1994)  Acc@5: 100.0000 (98.5769)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1590/3125]  eta: 0:09:02  Lr: 0.001875  Loss: -0.3734  Acc@1: 87.5000 (86.1958)  Acc@5: 100.0000 (98.5819)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1600/3125]  eta: 0:08:58  Lr: 0.001875  Loss: -0.4087  Acc@1: 87.5000 (86.2196)  Acc@5: 100.0000 (98.5829)  time: 0.3506  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1610/3125]  eta: 0:08:55  Lr: 0.001875  Loss: -0.6172  Acc@1: 93.7500 (86.2314)  Acc@5: 100.0000 (98.5801)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1620/3125]  eta: 0:08:51  Lr: 0.001875  Loss: -0.7880  Acc@1: 87.5000 (86.2508)  Acc@5: 100.0000 (98.5811)  time: 0.3526  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1630/3125]  eta: 0:08:48  Lr: 0.001875  Loss: -0.1178  Acc@1: 87.5000 (86.2469)  Acc@5: 100.0000 (98.5745)  time: 0.3530  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1640/3125]  eta: 0:08:44  Lr: 0.001875  Loss: -0.5964  Acc@1: 87.5000 (86.2393)  Acc@5: 100.0000 (98.5794)  time: 0.3542  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1650/3125]  eta: 0:08:41  Lr: 0.001875  Loss: -0.1541  Acc@1: 81.2500 (86.2167)  Acc@5: 100.0000 (98.5539)  time: 0.3549  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1660/3125]  eta: 0:08:37  Lr: 0.001875  Loss: -0.4460  Acc@1: 81.2500 (86.2094)  Acc@5: 100.0000 (98.5551)  time: 0.3566  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1670/3125]  eta: 0:08:34  Lr: 0.001875  Loss: 0.6014  Acc@1: 87.5000 (86.1946)  Acc@5: 100.0000 (98.5376)  time: 0.3642  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1680/3125]  eta: 0:08:30  Lr: 0.001875  Loss: -0.7145  Acc@1: 87.5000 (86.1987)  Acc@5: 100.0000 (98.5388)  time: 0.3601  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1690/3125]  eta: 0:08:27  Lr: 0.001875  Loss: -0.4509  Acc@1: 87.5000 (86.2101)  Acc@5: 100.0000 (98.5364)  time: 0.3526  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1700/3125]  eta: 0:08:23  Lr: 0.001875  Loss: -0.3417  Acc@1: 87.5000 (86.1956)  Acc@5: 100.0000 (98.5376)  time: 0.3531  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1710/3125]  eta: 0:08:20  Lr: 0.001875  Loss: -0.4879  Acc@1: 81.2500 (86.1923)  Acc@5: 100.0000 (98.5352)  time: 0.3540  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1720/3125]  eta: 0:08:16  Lr: 0.001875  Loss: -0.6002  Acc@1: 87.5000 (86.2253)  Acc@5: 100.0000 (98.5437)  time: 0.3654  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1730/3125]  eta: 0:08:13  Lr: 0.001875  Loss: -0.5312  Acc@1: 87.5000 (86.2399)  Acc@5: 100.0000 (98.5449)  time: 0.3638  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1740/3125]  eta: 0:08:09  Lr: 0.001875  Loss: 0.1134  Acc@1: 87.5000 (86.2184)  Acc@5: 100.0000 (98.5461)  time: 0.3536  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [1750/3125]  eta: 0:08:06  Lr: 0.001875  Loss: 0.0597  Acc@1: 87.5000 (86.2186)  Acc@5: 100.0000 (98.5437)  time: 0.3522  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [1760/3125]  eta: 0:08:02  Lr: 0.001875  Loss: -0.7061  Acc@1: 87.5000 (86.2152)  Acc@5: 100.0000 (98.5413)  time: 0.3494  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1770/3125]  eta: 0:07:58  Lr: 0.001875  Loss: -0.5522  Acc@1: 87.5000 (86.2119)  Acc@5: 100.0000 (98.5425)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1780/3125]  eta: 0:07:55  Lr: 0.001875  Loss: -0.2971  Acc@1: 87.5000 (86.2226)  Acc@5: 100.0000 (98.5401)  time: 0.3528  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [1790/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.5105  Acc@1: 87.5000 (86.2332)  Acc@5: 100.0000 (98.5448)  time: 0.3536  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [1800/3125]  eta: 0:07:48  Lr: 0.001875  Loss: -0.7916  Acc@1: 87.5000 (86.2611)  Acc@5: 100.0000 (98.5494)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1810/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.1153  Acc@1: 87.5000 (86.2748)  Acc@5: 100.0000 (98.5402)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1820/3125]  eta: 0:07:41  Lr: 0.001875  Loss: -0.4949  Acc@1: 87.5000 (86.2678)  Acc@5: 100.0000 (98.5345)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1830/3125]  eta: 0:07:37  Lr: 0.001875  Loss: -0.4242  Acc@1: 81.2500 (86.2643)  Acc@5: 100.0000 (98.5390)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1840/3125]  eta: 0:07:34  Lr: 0.001875  Loss: -0.8347  Acc@1: 87.5000 (86.2744)  Acc@5: 100.0000 (98.5368)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1850/3125]  eta: 0:07:30  Lr: 0.001875  Loss: -0.5744  Acc@1: 81.2500 (86.2642)  Acc@5: 100.0000 (98.5380)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1860/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.2745  Acc@1: 87.5000 (86.2708)  Acc@5: 100.0000 (98.5357)  time: 0.3545  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [1870/3125]  eta: 0:07:23  Lr: 0.001875  Loss: -0.7039  Acc@1: 87.5000 (86.2607)  Acc@5: 100.0000 (98.5369)  time: 0.3537  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [1880/3125]  eta: 0:07:19  Lr: 0.001875  Loss: -0.8570  Acc@1: 87.5000 (86.2772)  Acc@5: 100.0000 (98.5380)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1890/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.1374  Acc@1: 93.7500 (86.2639)  Acc@5: 100.0000 (98.5292)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:12  Lr: 0.001875  Loss: -0.6820  Acc@1: 87.5000 (86.2539)  Acc@5: 100.0000 (98.5271)  time: 0.3552  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1910/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.6398  Acc@1: 87.5000 (86.2474)  Acc@5: 100.0000 (98.5283)  time: 0.3565  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1920/3125]  eta: 0:07:05  Lr: 0.001875  Loss: -0.8557  Acc@1: 87.5000 (86.2637)  Acc@5: 100.0000 (98.5262)  time: 0.3545  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1930/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.4445  Acc@1: 87.5000 (86.2668)  Acc@5: 100.0000 (98.5208)  time: 0.3542  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1940/3125]  eta: 0:06:58  Lr: 0.001875  Loss: -0.6536  Acc@1: 81.2500 (86.2345)  Acc@5: 100.0000 (98.5252)  time: 0.3555  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1950/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.6191  Acc@1: 81.2500 (86.2442)  Acc@5: 100.0000 (98.5264)  time: 0.3572  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [1960/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.3692  Acc@1: 87.5000 (86.2251)  Acc@5: 100.0000 (98.5212)  time: 0.3574  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1970/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.6851  Acc@1: 87.5000 (86.2316)  Acc@5: 100.0000 (98.5223)  time: 0.3542  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1980/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.6136  Acc@1: 87.5000 (86.2254)  Acc@5: 100.0000 (98.5266)  time: 0.3518  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1990/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.6354  Acc@1: 81.2500 (86.2098)  Acc@5: 100.0000 (98.5277)  time: 0.3580  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2000/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.7044  Acc@1: 81.2500 (86.2006)  Acc@5: 100.0000 (98.5289)  time: 0.3730  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2010/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6754  Acc@1: 81.2500 (86.1854)  Acc@5: 100.0000 (98.5237)  time: 0.3679  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2020/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6930  Acc@1: 87.5000 (86.2073)  Acc@5: 100.0000 (98.5218)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2030/3125]  eta: 0:06:27  Lr: 0.001875  Loss: -0.5295  Acc@1: 93.7500 (86.2168)  Acc@5: 100.0000 (98.5260)  time: 0.3632  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2040/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.3179  Acc@1: 87.5000 (86.2108)  Acc@5: 100.0000 (98.5301)  time: 0.3627  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:20  Lr: 0.001875  Loss: -0.6549  Acc@1: 87.5000 (86.2201)  Acc@5: 100.0000 (98.5343)  time: 0.3534  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.6916  Acc@1: 87.5000 (86.2142)  Acc@5: 100.0000 (98.5323)  time: 0.3536  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:13  Lr: 0.001875  Loss: -0.2661  Acc@1: 87.5000 (86.2204)  Acc@5: 100.0000 (98.5333)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2080/3125]  eta: 0:06:09  Lr: 0.001875  Loss: -0.5160  Acc@1: 87.5000 (86.2116)  Acc@5: 100.0000 (98.5314)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2090/3125]  eta: 0:06:06  Lr: 0.001875  Loss: -0.6956  Acc@1: 87.5000 (86.2357)  Acc@5: 100.0000 (98.5384)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2100/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.6682  Acc@1: 87.5000 (86.2446)  Acc@5: 100.0000 (98.5394)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2110/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.3542  Acc@1: 87.5000 (86.2447)  Acc@5: 100.0000 (98.5433)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2120/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.3749  Acc@1: 87.5000 (86.2359)  Acc@5: 100.0000 (98.5443)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2130/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.5125  Acc@1: 87.5000 (86.2301)  Acc@5: 100.0000 (98.5482)  time: 0.3528  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2140/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.2878  Acc@1: 87.5000 (86.2418)  Acc@5: 100.0000 (98.5550)  time: 0.3534  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2150/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.6863  Acc@1: 87.5000 (86.2215)  Acc@5: 100.0000 (98.5530)  time: 0.3534  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [2160/3125]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6225  Acc@1: 87.5000 (86.2448)  Acc@5: 100.0000 (98.5568)  time: 0.3545  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [2170/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6251  Acc@1: 87.5000 (86.2621)  Acc@5: 100.0000 (98.5577)  time: 0.3563  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [2180/3125]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6306  Acc@1: 87.5000 (86.2878)  Acc@5: 100.0000 (98.5586)  time: 0.3579  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2190/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4825  Acc@1: 87.5000 (86.2877)  Acc@5: 100.0000 (98.5594)  time: 0.3578  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2200/3125]  eta: 0:05:27  Lr: 0.001875  Loss: -0.5799  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.5603)  time: 0.3593  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.1542  Acc@1: 87.5000 (86.2873)  Acc@5: 100.0000 (98.5583)  time: 0.3555  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:20  Lr: 0.001875  Loss: -0.7127  Acc@1: 81.2500 (86.2731)  Acc@5: 100.0000 (98.5536)  time: 0.3578  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.3702  Acc@1: 81.2500 (86.2674)  Acc@5: 100.0000 (98.5545)  time: 0.3686  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:13  Lr: 0.001875  Loss: -0.7006  Acc@1: 87.5000 (86.2812)  Acc@5: 100.0000 (98.5525)  time: 0.3637  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.7555  Acc@1: 87.5000 (86.2811)  Acc@5: 100.0000 (98.5534)  time: 0.3536  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [2260/3125]  eta: 0:05:06  Lr: 0.001875  Loss: -0.3390  Acc@1: 87.5000 (86.2893)  Acc@5: 100.0000 (98.5460)  time: 0.3652  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2270/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.1577  Acc@1: 87.5000 (86.2836)  Acc@5: 100.0000 (98.5469)  time: 0.3693  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2280/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.6650  Acc@1: 87.5000 (86.2999)  Acc@5: 100.0000 (98.5505)  time: 0.3557  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2290/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.7664  Acc@1: 93.7500 (86.3160)  Acc@5: 100.0000 (98.5514)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2300/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.5229  Acc@1: 87.5000 (86.3266)  Acc@5: 100.0000 (98.5441)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2310/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.5598  Acc@1: 87.5000 (86.3290)  Acc@5: 100.0000 (98.5450)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2320/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.7333  Acc@1: 87.5000 (86.3206)  Acc@5: 100.0000 (98.5486)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2330/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.4954  Acc@1: 87.5000 (86.3149)  Acc@5: 100.0000 (98.5494)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2340/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.5729  Acc@1: 87.5000 (86.3119)  Acc@5: 100.0000 (98.5503)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2350/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.4738  Acc@1: 87.5000 (86.3037)  Acc@5: 100.0000 (98.5538)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.4966  Acc@1: 87.5000 (86.3167)  Acc@5: 100.0000 (98.5573)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.3783  Acc@1: 87.5000 (86.3112)  Acc@5: 100.0000 (98.5581)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.7073  Acc@1: 87.5000 (86.3188)  Acc@5: 100.0000 (98.5642)  time: 0.3519  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.4479  Acc@1: 81.2500 (86.3080)  Acc@5: 100.0000 (98.5571)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.2383  Acc@1: 81.2500 (86.2766)  Acc@5: 100.0000 (98.5579)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:12  Lr: 0.001875  Loss: -0.2852  Acc@1: 81.2500 (86.2505)  Acc@5: 100.0000 (98.5535)  time: 0.3546  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.3666  Acc@1: 81.2500 (86.2583)  Acc@5: 100.0000 (98.5569)  time: 0.3559  data: 0.0027  max mem: 2502
Train: Epoch[3/5]  [2430/3125]  eta: 0:04:05  Lr: 0.001875  Loss: -0.4823  Acc@1: 87.5000 (86.2608)  Acc@5: 100.0000 (98.5526)  time: 0.3547  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2440/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.5962  Acc@1: 87.5000 (86.2684)  Acc@5: 100.0000 (98.5585)  time: 0.3557  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2450/3125]  eta: 0:03:58  Lr: 0.001875  Loss: -0.8963  Acc@1: 87.5000 (86.2582)  Acc@5: 100.0000 (98.5593)  time: 0.3554  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2460/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.3062  Acc@1: 87.5000 (86.2708)  Acc@5: 100.0000 (98.5626)  time: 0.3558  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2470/3125]  eta: 0:03:51  Lr: 0.001875  Loss: -0.6225  Acc@1: 87.5000 (86.2682)  Acc@5: 100.0000 (98.5608)  time: 0.3551  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2480/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.8237  Acc@1: 87.5000 (86.2757)  Acc@5: 100.0000 (98.5616)  time: 0.3522  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [2490/3125]  eta: 0:03:44  Lr: 0.001875  Loss: -0.6415  Acc@1: 87.5000 (86.2681)  Acc@5: 100.0000 (98.5623)  time: 0.3529  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [2500/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.7321  Acc@1: 87.5000 (86.2730)  Acc@5: 100.0000 (98.5631)  time: 0.3549  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [2510/3125]  eta: 0:03:37  Lr: 0.001875  Loss: -0.7728  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.5638)  time: 0.3571  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.6434  Acc@1: 93.7500 (86.3100)  Acc@5: 100.0000 (98.5670)  time: 0.3556  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:30  Lr: 0.001875  Loss: -0.5814  Acc@1: 93.7500 (86.3048)  Acc@5: 100.0000 (98.5678)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:26  Lr: 0.001875  Loss: -0.5651  Acc@1: 87.5000 (86.3021)  Acc@5: 100.0000 (98.5734)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:23  Lr: 0.001875  Loss: -0.5073  Acc@1: 87.5000 (86.2823)  Acc@5: 100.0000 (98.5692)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:19  Lr: 0.001875  Loss: -0.2990  Acc@1: 87.5000 (86.2822)  Acc@5: 100.0000 (98.5723)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:16  Lr: 0.001875  Loss: -0.6442  Acc@1: 81.2500 (86.2651)  Acc@5: 100.0000 (98.5633)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:12  Lr: 0.001875  Loss: -0.7511  Acc@1: 87.5000 (86.2747)  Acc@5: 100.0000 (98.5664)  time: 0.3510  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:09  Lr: 0.001875  Loss: -0.5457  Acc@1: 87.5000 (86.2746)  Acc@5: 100.0000 (98.5696)  time: 0.3541  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:05  Lr: 0.001875  Loss: -0.1742  Acc@1: 81.2500 (86.2529)  Acc@5: 100.0000 (98.5631)  time: 0.3543  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2610/3125]  eta: 0:03:02  Lr: 0.001875  Loss: -0.7919  Acc@1: 81.2500 (86.2529)  Acc@5: 100.0000 (98.5662)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2620/3125]  eta: 0:02:58  Lr: 0.001875  Loss: -0.7344  Acc@1: 87.5000 (86.2529)  Acc@5: 100.0000 (98.5621)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2630/3125]  eta: 0:02:55  Lr: 0.001875  Loss: -0.3649  Acc@1: 87.5000 (86.2742)  Acc@5: 100.0000 (98.5628)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2640/3125]  eta: 0:02:51  Lr: 0.001875  Loss: -0.5708  Acc@1: 87.5000 (86.2694)  Acc@5: 100.0000 (98.5612)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2650/3125]  eta: 0:02:48  Lr: 0.001875  Loss: -0.4595  Acc@1: 87.5000 (86.2599)  Acc@5: 100.0000 (98.5595)  time: 0.3526  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2660/3125]  eta: 0:02:44  Lr: 0.001875  Loss: -0.4417  Acc@1: 87.5000 (86.2787)  Acc@5: 100.0000 (98.5602)  time: 0.3527  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:40  Lr: 0.001875  Loss: -0.7417  Acc@1: 87.5000 (86.2832)  Acc@5: 100.0000 (98.5609)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:37  Lr: 0.001875  Loss: -0.1298  Acc@1: 87.5000 (86.2831)  Acc@5: 100.0000 (98.5546)  time: 0.3554  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:33  Lr: 0.001875  Loss: -0.5544  Acc@1: 87.5000 (86.2830)  Acc@5: 100.0000 (98.5530)  time: 0.3544  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:30  Lr: 0.001875  Loss: -0.6428  Acc@1: 87.5000 (86.2805)  Acc@5: 100.0000 (98.5561)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:26  Lr: 0.001875  Loss: -0.6636  Acc@1: 87.5000 (86.2989)  Acc@5: 100.0000 (98.5568)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:23  Lr: 0.001875  Loss: -0.7704  Acc@1: 87.5000 (86.2849)  Acc@5: 100.0000 (98.5598)  time: 0.3524  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6969  Acc@1: 87.5000 (86.2894)  Acc@5: 100.0000 (98.5628)  time: 0.3529  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7439  Acc@1: 87.5000 (86.3006)  Acc@5: 100.0000 (98.5612)  time: 0.3523  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:12  Lr: 0.001875  Loss: -0.9312  Acc@1: 93.7500 (86.3163)  Acc@5: 100.0000 (98.5619)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8778  Acc@1: 93.7500 (86.3274)  Acc@5: 100.0000 (98.5671)  time: 0.3545  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6498  Acc@1: 87.5000 (86.3384)  Acc@5: 100.0000 (98.5700)  time: 0.3574  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2780/3125]  eta: 0:02:02  Lr: 0.001875  Loss: -0.5649  Acc@1: 87.5000 (86.3426)  Acc@5: 100.0000 (98.5729)  time: 0.3544  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2790/3125]  eta: 0:01:58  Lr: 0.001875  Loss: -0.7165  Acc@1: 87.5000 (86.3579)  Acc@5: 100.0000 (98.5780)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2800/3125]  eta: 0:01:54  Lr: 0.001875  Loss: -0.6715  Acc@1: 87.5000 (86.3687)  Acc@5: 100.0000 (98.5786)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2810/3125]  eta: 0:01:51  Lr: 0.001875  Loss: -0.6083  Acc@1: 87.5000 (86.3438)  Acc@5: 100.0000 (98.5748)  time: 0.3513  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:47  Lr: 0.001875  Loss: -0.7638  Acc@1: 87.5000 (86.3501)  Acc@5: 100.0000 (98.5776)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6571  Acc@1: 87.5000 (86.3432)  Acc@5: 100.0000 (98.5760)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:40  Lr: 0.001875  Loss: -0.3074  Acc@1: 87.5000 (86.3494)  Acc@5: 100.0000 (98.5744)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6087  Acc@1: 87.5000 (86.3535)  Acc@5: 100.0000 (98.5751)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:33  Lr: 0.001875  Loss: -0.2043  Acc@1: 87.5000 (86.3509)  Acc@5: 100.0000 (98.5735)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:30  Lr: 0.001875  Loss: -0.7823  Acc@1: 87.5000 (86.3549)  Acc@5: 100.0000 (98.5741)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:26  Lr: 0.001875  Loss: -0.1167  Acc@1: 87.5000 (86.3394)  Acc@5: 100.0000 (98.5704)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:23  Lr: 0.001875  Loss: -0.8762  Acc@1: 87.5000 (86.3412)  Acc@5: 100.0000 (98.5710)  time: 0.3536  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:19  Lr: 0.001875  Loss: -0.5045  Acc@1: 87.5000 (86.3452)  Acc@5: 100.0000 (98.5716)  time: 0.3524  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:16  Lr: 0.001875  Loss: -0.6840  Acc@1: 87.5000 (86.3449)  Acc@5: 100.0000 (98.5701)  time: 0.3530  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:12  Lr: 0.001875  Loss: -0.2699  Acc@1: 87.5000 (86.3382)  Acc@5: 100.0000 (98.5707)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7331  Acc@1: 87.5000 (86.3464)  Acc@5: 100.0000 (98.5734)  time: 0.3529  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:05  Lr: 0.001875  Loss: -0.5552  Acc@1: 87.5000 (86.3461)  Acc@5: 100.0000 (98.5740)  time: 0.3543  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.5199  Acc@1: 81.2500 (86.3309)  Acc@5: 100.0000 (98.5746)  time: 0.3520  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2960/3125]  eta: 0:00:58  Lr: 0.001875  Loss: -0.5359  Acc@1: 87.5000 (86.3243)  Acc@5: 100.0000 (98.5689)  time: 0.3524  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7403  Acc@1: 87.5000 (86.3240)  Acc@5: 100.0000 (98.5674)  time: 0.3545  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:51  Lr: 0.001875  Loss: -0.4088  Acc@1: 87.5000 (86.3427)  Acc@5: 100.0000 (98.5701)  time: 0.3535  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.3042  Acc@1: 87.5000 (86.3382)  Acc@5: 100.0000 (98.5728)  time: 0.3533  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.4764  Acc@1: 81.2500 (86.3212)  Acc@5: 100.0000 (98.5734)  time: 0.3540  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3163  Acc@1: 87.5000 (86.3148)  Acc@5: 100.0000 (98.5761)  time: 0.3604  data: 0.0023  max mem: 2502
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7166  Acc@1: 87.5000 (86.3125)  Acc@5: 100.0000 (98.5787)  time: 0.3645  data: 0.0027  max mem: 2502
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.4147  Acc@1: 87.5000 (86.3143)  Acc@5: 100.0000 (98.5793)  time: 0.3593  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6223  Acc@1: 87.5000 (86.3182)  Acc@5: 100.0000 (98.5798)  time: 0.3567  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5189  Acc@1: 87.5000 (86.3139)  Acc@5: 100.0000 (98.5824)  time: 0.3632  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.4520  Acc@1: 87.5000 (86.3341)  Acc@5: 100.0000 (98.5809)  time: 0.3628  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.6977  Acc@1: 87.5000 (86.3359)  Acc@5: 100.0000 (98.5835)  time: 0.3530  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.6032  Acc@1: 87.5000 (86.3336)  Acc@5: 100.0000 (98.5841)  time: 0.3555  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.7370  Acc@1: 87.5000 (86.3394)  Acc@5: 100.0000 (98.5846)  time: 0.3628  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.7030  Acc@1: 87.5000 (86.3431)  Acc@5: 100.0000 (98.5871)  time: 0.3567  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.7440  Acc@1: 87.5000 (86.3488)  Acc@5: 100.0000 (98.5897)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5169  Acc@1: 87.5000 (86.3545)  Acc@5: 100.0000 (98.5882)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5548  Acc@1: 87.5000 (86.3580)  Acc@5: 100.0000 (98.5860)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[3/5] Total time: 0:18:26 (0.3540 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.5548  Acc@1: 87.5000 (86.3580)  Acc@5: 100.0000 (98.5860)
Train: Epoch[4/5]  [   0/3125]  eta: 0:40:47  Lr: 0.001875  Loss: -0.3745  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7830  data: 0.4341  max mem: 2502
Train: Epoch[4/5]  [  10/3125]  eta: 0:20:07  Lr: 0.001875  Loss: -0.9346  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  time: 0.3876  data: 0.0398  max mem: 2502
Train: Epoch[4/5]  [  20/3125]  eta: 0:19:17  Lr: 0.001875  Loss: -0.4620  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.5119)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  30/3125]  eta: 0:18:51  Lr: 0.001875  Loss: -0.3280  Acc@1: 81.2500 (86.2903)  Acc@5: 100.0000 (98.7903)  time: 0.3535  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  40/3125]  eta: 0:18:39  Lr: 0.001875  Loss: -0.4329  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (98.7805)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [  50/3125]  eta: 0:18:29  Lr: 0.001875  Loss: -0.6181  Acc@1: 87.5000 (87.1324)  Acc@5: 100.0000 (98.7745)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [  60/3125]  eta: 0:18:22  Lr: 0.001875  Loss: -0.6951  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (98.8730)  time: 0.3535  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [  70/3125]  eta: 0:18:17  Lr: 0.001875  Loss: -0.6172  Acc@1: 87.5000 (86.8838)  Acc@5: 100.0000 (98.6796)  time: 0.3556  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [  80/3125]  eta: 0:18:13  Lr: 0.001875  Loss: -0.8886  Acc@1: 93.7500 (87.0370)  Acc@5: 100.0000 (98.7654)  time: 0.3573  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [  90/3125]  eta: 0:18:08  Lr: 0.001875  Loss: -0.6326  Acc@1: 87.5000 (86.6758)  Acc@5: 100.0000 (98.6264)  time: 0.3565  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 100/3125]  eta: 0:18:03  Lr: 0.001875  Loss: -0.5210  Acc@1: 87.5000 (86.7574)  Acc@5: 100.0000 (98.7005)  time: 0.3542  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 110/3125]  eta: 0:18:00  Lr: 0.001875  Loss: -0.4819  Acc@1: 81.2500 (86.3739)  Acc@5: 100.0000 (98.7613)  time: 0.3578  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [ 120/3125]  eta: 0:17:56  Lr: 0.001875  Loss: -0.2228  Acc@1: 87.5000 (86.4153)  Acc@5: 100.0000 (98.8120)  time: 0.3584  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 130/3125]  eta: 0:17:50  Lr: 0.001875  Loss: -0.7734  Acc@1: 87.5000 (86.4981)  Acc@5: 100.0000 (98.8550)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 140/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.7476  Acc@1: 87.5000 (86.6578)  Acc@5: 100.0000 (98.7589)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 150/3125]  eta: 0:17:42  Lr: 0.001875  Loss: -0.2867  Acc@1: 87.5000 (86.6722)  Acc@5: 100.0000 (98.7583)  time: 0.3551  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 160/3125]  eta: 0:17:39  Lr: 0.001875  Loss: -0.7493  Acc@1: 81.2500 (86.4519)  Acc@5: 100.0000 (98.7578)  time: 0.3568  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 170/3125]  eta: 0:17:34  Lr: 0.001875  Loss: -0.8038  Acc@1: 81.2500 (86.6228)  Acc@5: 100.0000 (98.8304)  time: 0.3542  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 180/3125]  eta: 0:17:30  Lr: 0.001875  Loss: -0.5686  Acc@1: 87.5000 (86.7403)  Acc@5: 100.0000 (98.8950)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 190/3125]  eta: 0:17:25  Lr: 0.001875  Loss: -0.7479  Acc@1: 93.7500 (87.1728)  Acc@5: 100.0000 (98.9202)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 200/3125]  eta: 0:17:21  Lr: 0.001875  Loss: -0.4084  Acc@1: 93.7500 (87.1891)  Acc@5: 100.0000 (98.9739)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 210/3125]  eta: 0:17:17  Lr: 0.001875  Loss: -0.7535  Acc@1: 87.5000 (87.3519)  Acc@5: 100.0000 (98.9929)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 220/3125]  eta: 0:17:12  Lr: 0.001875  Loss: -0.7666  Acc@1: 87.5000 (87.2455)  Acc@5: 100.0000 (98.9819)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 230/3125]  eta: 0:17:08  Lr: 0.001875  Loss: -0.4274  Acc@1: 87.5000 (87.1483)  Acc@5: 100.0000 (98.9989)  time: 0.3509  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 240/3125]  eta: 0:17:04  Lr: 0.001875  Loss: 0.1056  Acc@1: 81.2500 (86.9295)  Acc@5: 100.0000 (98.9108)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 250/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.6484  Acc@1: 87.5000 (86.9771)  Acc@5: 100.0000 (98.8795)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 260/3125]  eta: 0:16:56  Lr: 0.001875  Loss: -0.7629  Acc@1: 87.5000 (86.7816)  Acc@5: 100.0000 (98.8506)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 270/3125]  eta: 0:16:52  Lr: 0.001875  Loss: -0.4332  Acc@1: 81.2500 (86.6928)  Acc@5: 100.0000 (98.7546)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 280/3125]  eta: 0:16:48  Lr: 0.001875  Loss: -0.4179  Acc@1: 87.5000 (86.6548)  Acc@5: 100.0000 (98.7767)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 290/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.6624  Acc@1: 87.5000 (86.5979)  Acc@5: 100.0000 (98.7758)  time: 0.3545  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 300/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.8240  Acc@1: 87.5000 (86.6279)  Acc@5: 100.0000 (98.7957)  time: 0.3556  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 310/3125]  eta: 0:16:38  Lr: 0.001875  Loss: -0.3597  Acc@1: 87.5000 (86.5756)  Acc@5: 100.0000 (98.7942)  time: 0.3556  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 320/3125]  eta: 0:16:35  Lr: 0.001875  Loss: -0.8636  Acc@1: 87.5000 (86.6238)  Acc@5: 100.0000 (98.8123)  time: 0.3555  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 330/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.1137  Acc@1: 87.5000 (86.6881)  Acc@5: 100.0000 (98.7915)  time: 0.3569  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 340/3125]  eta: 0:16:28  Lr: 0.001875  Loss: -0.8030  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (98.8270)  time: 0.3584  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 350/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.2341  Acc@1: 87.5000 (86.5563)  Acc@5: 100.0000 (98.8070)  time: 0.3565  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 360/3125]  eta: 0:16:21  Lr: 0.001875  Loss: -0.7227  Acc@1: 87.5000 (86.6517)  Acc@5: 100.0000 (98.8227)  time: 0.3553  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 370/3125]  eta: 0:16:17  Lr: 0.001875  Loss: -0.6332  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.8376)  time: 0.3542  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 380/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.4251  Acc@1: 87.5000 (86.6470)  Acc@5: 100.0000 (98.8189)  time: 0.3549  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 390/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.7254  Acc@1: 87.5000 (86.7168)  Acc@5: 100.0000 (98.8331)  time: 0.3572  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 400/3125]  eta: 0:16:07  Lr: 0.001875  Loss: -0.4578  Acc@1: 87.5000 (86.7207)  Acc@5: 100.0000 (98.8310)  time: 0.3598  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [ 410/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.8222  Acc@1: 81.2500 (86.6484)  Acc@5: 100.0000 (98.8139)  time: 0.3584  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 420/3125]  eta: 0:16:00  Lr: 0.001875  Loss: -0.4249  Acc@1: 81.2500 (86.6538)  Acc@5: 100.0000 (98.7827)  time: 0.3540  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 430/3125]  eta: 0:15:56  Lr: 0.001875  Loss: -0.5900  Acc@1: 87.5000 (86.5864)  Acc@5: 100.0000 (98.7819)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 440/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.4063  Acc@1: 81.2500 (86.4938)  Acc@5: 100.0000 (98.7670)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 450/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.8169  Acc@1: 81.2500 (86.4745)  Acc@5: 100.0000 (98.7666)  time: 0.3616  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 460/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.6107  Acc@1: 87.5000 (86.4561)  Acc@5: 100.0000 (98.7527)  time: 0.3593  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 470/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.0659  Acc@1: 81.2500 (86.4252)  Acc@5: 100.0000 (98.7261)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 480/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.3916  Acc@1: 87.5000 (86.4865)  Acc@5: 100.0000 (98.7526)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 490/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.6252  Acc@1: 87.5000 (86.5071)  Acc@5: 100.0000 (98.7780)  time: 0.3523  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 500/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.2012  Acc@1: 87.5000 (86.5394)  Acc@5: 100.0000 (98.7774)  time: 0.3627  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 510/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.6516  Acc@1: 87.5000 (86.4971)  Acc@5: 100.0000 (98.7769)  time: 0.3598  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 520/3125]  eta: 0:15:25  Lr: 0.001875  Loss: -0.6886  Acc@1: 87.5000 (86.5523)  Acc@5: 100.0000 (98.8004)  time: 0.3539  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 530/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.6914  Acc@1: 87.5000 (86.5113)  Acc@5: 100.0000 (98.8112)  time: 0.3583  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 540/3125]  eta: 0:15:18  Lr: 0.001875  Loss: -0.6449  Acc@1: 87.5000 (86.4718)  Acc@5: 100.0000 (98.7870)  time: 0.3541  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 550/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.6128  Acc@1: 87.5000 (86.5472)  Acc@5: 100.0000 (98.8090)  time: 0.3521  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 560/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.1565  Acc@1: 93.7500 (86.5419)  Acc@5: 100.0000 (98.7857)  time: 0.3523  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 570/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.6621  Acc@1: 93.7500 (86.6243)  Acc@5: 100.0000 (98.8069)  time: 0.3546  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 580/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.6072  Acc@1: 87.5000 (86.5749)  Acc@5: 100.0000 (98.8167)  time: 0.3563  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 590/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.6131  Acc@1: 87.5000 (86.5376)  Acc@5: 100.0000 (98.8156)  time: 0.3579  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 600/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.7651  Acc@1: 87.5000 (86.5225)  Acc@5: 100.0000 (98.7937)  time: 0.3602  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 610/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.3407  Acc@1: 87.5000 (86.4669)  Acc@5: 100.0000 (98.7623)  time: 0.3667  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 620/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.6796  Acc@1: 87.5000 (86.5539)  Acc@5: 100.0000 (98.7621)  time: 0.3664  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 630/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.2247  Acc@1: 87.5000 (86.5590)  Acc@5: 100.0000 (98.7421)  time: 0.3577  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 640/3125]  eta: 0:14:44  Lr: 0.001875  Loss: -0.4968  Acc@1: 87.5000 (86.5640)  Acc@5: 100.0000 (98.7227)  time: 0.3651  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 650/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.3559  Acc@1: 87.5000 (86.6263)  Acc@5: 100.0000 (98.7039)  time: 0.3624  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 660/3125]  eta: 0:14:37  Lr: 0.001875  Loss: -0.7015  Acc@1: 87.5000 (86.6301)  Acc@5: 100.0000 (98.6952)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 670/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.7542  Acc@1: 87.5000 (86.6617)  Acc@5: 100.0000 (98.7053)  time: 0.3533  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 680/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5260  Acc@1: 81.2500 (86.5914)  Acc@5: 100.0000 (98.6876)  time: 0.3531  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 690/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.5236  Acc@1: 81.2500 (86.5412)  Acc@5: 100.0000 (98.6885)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 700/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7572  Acc@1: 87.5000 (86.5728)  Acc@5: 100.0000 (98.6894)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 710/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.6235  Acc@1: 87.5000 (86.5682)  Acc@5: 100.0000 (98.6726)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 720/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5984  Acc@1: 87.5000 (86.5985)  Acc@5: 100.0000 (98.6564)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 730/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.5721  Acc@1: 87.5000 (86.6536)  Acc@5: 100.0000 (98.6577)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 740/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.7326  Acc@1: 87.5000 (86.6144)  Acc@5: 100.0000 (98.6420)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 750/3125]  eta: 0:14:03  Lr: 0.001875  Loss: -0.1228  Acc@1: 87.5000 (86.6761)  Acc@5: 100.0000 (98.6352)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 760/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.6868  Acc@1: 87.5000 (86.6130)  Acc@5: 100.0000 (98.6202)  time: 0.3602  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 770/3125]  eta: 0:13:56  Lr: 0.001875  Loss: 0.2806  Acc@1: 87.5000 (86.6245)  Acc@5: 100.0000 (98.6138)  time: 0.3577  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 780/3125]  eta: 0:13:52  Lr: 0.001875  Loss: -0.6449  Acc@1: 93.7500 (86.6917)  Acc@5: 100.0000 (98.6316)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 790/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.7083  Acc@1: 93.7500 (86.7494)  Acc@5: 100.0000 (98.6252)  time: 0.3552  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 800/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.3313  Acc@1: 87.5000 (86.7431)  Acc@5: 100.0000 (98.6345)  time: 0.3684  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 810/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.6774  Acc@1: 87.5000 (86.7910)  Acc@5: 100.0000 (98.6282)  time: 0.3629  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 820/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.6947  Acc@1: 87.5000 (86.7463)  Acc@5: 100.0000 (98.6373)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 830/3125]  eta: 0:13:35  Lr: 0.001875  Loss: -0.7999  Acc@1: 87.5000 (86.7855)  Acc@5: 100.0000 (98.6462)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 840/3125]  eta: 0:13:31  Lr: 0.001875  Loss: -0.3988  Acc@1: 81.2500 (86.7345)  Acc@5: 100.0000 (98.6474)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 850/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.5413  Acc@1: 81.2500 (86.7362)  Acc@5: 100.0000 (98.6486)  time: 0.3527  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 860/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.7133  Acc@1: 87.5000 (86.7451)  Acc@5: 100.0000 (98.6571)  time: 0.3540  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 870/3125]  eta: 0:13:21  Lr: 0.001875  Loss: -0.5775  Acc@1: 87.5000 (86.7609)  Acc@5: 100.0000 (98.6582)  time: 0.3530  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [ 880/3125]  eta: 0:13:17  Lr: 0.001875  Loss: -0.6001  Acc@1: 93.7500 (86.8190)  Acc@5: 100.0000 (98.6734)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 890/3125]  eta: 0:13:13  Lr: 0.001875  Loss: -0.7383  Acc@1: 93.7500 (86.8406)  Acc@5: 100.0000 (98.6742)  time: 0.3547  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 900/3125]  eta: 0:13:10  Lr: 0.001875  Loss: -0.6220  Acc@1: 87.5000 (86.8688)  Acc@5: 100.0000 (98.6681)  time: 0.3537  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 910/3125]  eta: 0:13:06  Lr: 0.001875  Loss: -0.4110  Acc@1: 87.5000 (86.8688)  Acc@5: 100.0000 (98.6690)  time: 0.3512  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 920/3125]  eta: 0:13:03  Lr: 0.001875  Loss: -0.6750  Acc@1: 87.5000 (86.8825)  Acc@5: 100.0000 (98.6699)  time: 0.3593  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 930/3125]  eta: 0:12:59  Lr: 0.001875  Loss: -0.2971  Acc@1: 87.5000 (86.9025)  Acc@5: 100.0000 (98.6372)  time: 0.3602  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 940/3125]  eta: 0:12:56  Lr: 0.001875  Loss: -0.2334  Acc@1: 87.5000 (86.8557)  Acc@5: 100.0000 (98.6384)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 950/3125]  eta: 0:12:52  Lr: 0.001875  Loss: -0.2002  Acc@1: 87.5000 (86.8559)  Acc@5: 100.0000 (98.6396)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 960/3125]  eta: 0:12:48  Lr: 0.001875  Loss: 0.1733  Acc@1: 87.5000 (86.8301)  Acc@5: 100.0000 (98.6277)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 970/3125]  eta: 0:12:45  Lr: 0.001875  Loss: -0.6766  Acc@1: 81.2500 (86.7920)  Acc@5: 100.0000 (98.6226)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 980/3125]  eta: 0:12:41  Lr: 0.001875  Loss: -0.7934  Acc@1: 87.5000 (86.8310)  Acc@5: 100.0000 (98.6366)  time: 0.3526  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 990/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.5250  Acc@1: 87.5000 (86.8441)  Acc@5: 100.0000 (98.6504)  time: 0.3514  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [1000/3125]  eta: 0:12:34  Lr: 0.001875  Loss: -0.8566  Acc@1: 87.5000 (86.8944)  Acc@5: 100.0000 (98.6451)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1010/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.2355  Acc@1: 87.5000 (86.9065)  Acc@5: 100.0000 (98.6523)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1020/3125]  eta: 0:12:27  Lr: 0.001875  Loss: -0.7281  Acc@1: 87.5000 (86.9123)  Acc@5: 100.0000 (98.6472)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1030/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.4148  Acc@1: 87.5000 (86.9180)  Acc@5: 100.0000 (98.6482)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1040/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.3328  Acc@1: 87.5000 (86.9116)  Acc@5: 100.0000 (98.6551)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1050/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.4276  Acc@1: 87.5000 (86.9053)  Acc@5: 100.0000 (98.6441)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1060/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.2476  Acc@1: 87.5000 (86.8992)  Acc@5: 100.0000 (98.6393)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1070/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.5469  Acc@1: 87.5000 (86.9164)  Acc@5: 100.0000 (98.6345)  time: 0.3521  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1080/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.4320  Acc@1: 87.5000 (86.9623)  Acc@5: 100.0000 (98.6355)  time: 0.3537  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1090/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.4199  Acc@1: 87.5000 (86.9615)  Acc@5: 100.0000 (98.6366)  time: 0.3534  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1100/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.3001  Acc@1: 87.5000 (86.9267)  Acc@5: 100.0000 (98.6376)  time: 0.3537  data: 0.0023  max mem: 2502
Train: Epoch[4/5]  [1110/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.3771  Acc@1: 81.2500 (86.8756)  Acc@5: 100.0000 (98.6217)  time: 0.3548  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [1120/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.6017  Acc@1: 81.2500 (86.8644)  Acc@5: 100.0000 (98.6340)  time: 0.3550  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1130/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.0574  Acc@1: 87.5000 (86.8424)  Acc@5: 100.0000 (98.6295)  time: 0.3548  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1140/3125]  eta: 0:11:43  Lr: 0.001875  Loss: -0.6632  Acc@1: 87.5000 (86.8646)  Acc@5: 100.0000 (98.6361)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1150/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.6288  Acc@1: 87.5000 (86.8593)  Acc@5: 100.0000 (98.6371)  time: 0.3553  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1160/3125]  eta: 0:11:36  Lr: 0.001875  Loss: -0.1252  Acc@1: 87.5000 (86.8809)  Acc@5: 100.0000 (98.6273)  time: 0.3548  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1170/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.8494  Acc@1: 87.5000 (86.9182)  Acc@5: 100.0000 (98.6336)  time: 0.3543  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1180/3125]  eta: 0:11:29  Lr: 0.001875  Loss: -0.2330  Acc@1: 87.5000 (86.9179)  Acc@5: 100.0000 (98.6452)  time: 0.3582  data: 0.0023  max mem: 2502
Train: Epoch[4/5]  [1190/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.3844  Acc@1: 87.5000 (86.8755)  Acc@5: 100.0000 (98.6304)  time: 0.3543  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [1200/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.5974  Acc@1: 81.2500 (86.8599)  Acc@5: 100.0000 (98.6366)  time: 0.3605  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1210/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.6770  Acc@1: 81.2500 (86.8858)  Acc@5: 100.0000 (98.6375)  time: 0.3611  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1220/3125]  eta: 0:11:15  Lr: 0.001875  Loss: -0.8162  Acc@1: 81.2500 (86.8499)  Acc@5: 100.0000 (98.6486)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1230/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.5747  Acc@1: 81.2500 (86.8349)  Acc@5: 100.0000 (98.6444)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1240/3125]  eta: 0:11:08  Lr: 0.001875  Loss: -0.4601  Acc@1: 87.5000 (86.8554)  Acc@5: 100.0000 (98.6503)  time: 0.3626  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1250/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.9535  Acc@1: 87.5000 (86.8855)  Acc@5: 100.0000 (98.6561)  time: 0.3605  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1260/3125]  eta: 0:11:01  Lr: 0.001875  Loss: -0.8480  Acc@1: 87.5000 (86.8854)  Acc@5: 100.0000 (98.6667)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1270/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.4464  Acc@1: 87.5000 (86.8755)  Acc@5: 100.0000 (98.6772)  time: 0.3514  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1280/3125]  eta: 0:10:54  Lr: 0.001875  Loss: -0.6742  Acc@1: 87.5000 (86.8804)  Acc@5: 100.0000 (98.6827)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1290/3125]  eta: 0:10:50  Lr: 0.001875  Loss: -0.7237  Acc@1: 87.5000 (86.8706)  Acc@5: 100.0000 (98.6784)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1300/3125]  eta: 0:10:47  Lr: 0.001875  Loss: -0.2800  Acc@1: 87.5000 (86.8803)  Acc@5: 100.0000 (98.6741)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1310/3125]  eta: 0:10:43  Lr: 0.001875  Loss: -0.5104  Acc@1: 87.5000 (86.8469)  Acc@5: 100.0000 (98.6794)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1320/3125]  eta: 0:10:40  Lr: 0.001875  Loss: -0.4613  Acc@1: 81.2500 (86.8187)  Acc@5: 100.0000 (98.6800)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1330/3125]  eta: 0:10:36  Lr: 0.001875  Loss: -0.5464  Acc@1: 87.5000 (86.8238)  Acc@5: 100.0000 (98.6805)  time: 0.3527  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1340/3125]  eta: 0:10:32  Lr: 0.001875  Loss: -0.5213  Acc@1: 87.5000 (86.8195)  Acc@5: 100.0000 (98.6670)  time: 0.3545  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1350/3125]  eta: 0:10:29  Lr: 0.001875  Loss: -0.6047  Acc@1: 87.5000 (86.8199)  Acc@5: 100.0000 (98.6677)  time: 0.3529  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1360/3125]  eta: 0:10:25  Lr: 0.001875  Loss: -0.2052  Acc@1: 81.2500 (86.8020)  Acc@5: 100.0000 (98.6683)  time: 0.3518  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1370/3125]  eta: 0:10:22  Lr: 0.001875  Loss: -0.5922  Acc@1: 87.5000 (86.8162)  Acc@5: 100.0000 (98.6780)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1380/3125]  eta: 0:10:18  Lr: 0.001875  Loss: -0.8067  Acc@1: 87.5000 (86.8302)  Acc@5: 100.0000 (98.6785)  time: 0.3578  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1390/3125]  eta: 0:10:15  Lr: 0.001875  Loss: -0.5340  Acc@1: 87.5000 (86.8125)  Acc@5: 100.0000 (98.6790)  time: 0.3602  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1400/3125]  eta: 0:10:11  Lr: 0.001875  Loss: -0.3708  Acc@1: 87.5000 (86.8308)  Acc@5: 100.0000 (98.6795)  time: 0.3537  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1410/3125]  eta: 0:10:08  Lr: 0.001875  Loss: -0.4617  Acc@1: 87.5000 (86.8356)  Acc@5: 100.0000 (98.6800)  time: 0.3511  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1420/3125]  eta: 0:10:04  Lr: 0.001875  Loss: -0.3665  Acc@1: 81.2500 (86.8183)  Acc@5: 100.0000 (98.6893)  time: 0.3594  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1430/3125]  eta: 0:10:01  Lr: 0.001875  Loss: -0.5390  Acc@1: 87.5000 (86.8318)  Acc@5: 100.0000 (98.6941)  time: 0.3620  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1440/3125]  eta: 0:09:57  Lr: 0.001875  Loss: -0.7209  Acc@1: 87.5000 (86.8147)  Acc@5: 100.0000 (98.6945)  time: 0.3572  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1450/3125]  eta: 0:09:54  Lr: 0.001875  Loss: -0.8839  Acc@1: 87.5000 (86.8108)  Acc@5: 100.0000 (98.6819)  time: 0.3607  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1460/3125]  eta: 0:09:50  Lr: 0.001875  Loss: -0.3438  Acc@1: 87.5000 (86.8070)  Acc@5: 100.0000 (98.6781)  time: 0.3662  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1470/3125]  eta: 0:09:47  Lr: 0.001875  Loss: -0.2421  Acc@1: 81.2500 (86.7777)  Acc@5: 100.0000 (98.6659)  time: 0.3593  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1480/3125]  eta: 0:09:43  Lr: 0.001875  Loss: -0.3420  Acc@1: 81.2500 (86.7699)  Acc@5: 100.0000 (98.6580)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1490/3125]  eta: 0:09:40  Lr: 0.001875  Loss: -0.2450  Acc@1: 87.5000 (86.7539)  Acc@5: 100.0000 (98.6502)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1500/3125]  eta: 0:09:36  Lr: 0.001875  Loss: -0.5192  Acc@1: 87.5000 (86.7713)  Acc@5: 100.0000 (98.6509)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1510/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.3005  Acc@1: 87.5000 (86.7596)  Acc@5: 100.0000 (98.6557)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1520/3125]  eta: 0:09:29  Lr: 0.001875  Loss: -0.6913  Acc@1: 87.5000 (86.7521)  Acc@5: 100.0000 (98.6522)  time: 0.3503  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1530/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.5222  Acc@1: 87.5000 (86.7693)  Acc@5: 100.0000 (98.6528)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1540/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.6111  Acc@1: 87.5000 (86.7862)  Acc@5: 100.0000 (98.6413)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1550/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.7211  Acc@1: 87.5000 (86.8109)  Acc@5: 100.0000 (98.6460)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1560/3125]  eta: 0:09:14  Lr: 0.001875  Loss: -0.6349  Acc@1: 87.5000 (86.8113)  Acc@5: 100.0000 (98.6467)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1570/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.3964  Acc@1: 87.5000 (86.7998)  Acc@5: 100.0000 (98.6434)  time: 0.3520  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1580/3125]  eta: 0:09:07  Lr: 0.001875  Loss: -0.3105  Acc@1: 87.5000 (86.8042)  Acc@5: 100.0000 (98.6322)  time: 0.3516  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1590/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.2636  Acc@1: 87.5000 (86.8125)  Acc@5: 100.0000 (98.6369)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1600/3125]  eta: 0:09:00  Lr: 0.001875  Loss: -0.5643  Acc@1: 87.5000 (86.8207)  Acc@5: 100.0000 (98.6376)  time: 0.3530  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1610/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.5611  Acc@1: 87.5000 (86.8250)  Acc@5: 100.0000 (98.6421)  time: 0.3558  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1620/3125]  eta: 0:08:53  Lr: 0.001875  Loss: -0.4751  Acc@1: 87.5000 (86.8137)  Acc@5: 100.0000 (98.6351)  time: 0.3537  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [1630/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.3712  Acc@1: 81.2500 (86.7719)  Acc@5: 100.0000 (98.6320)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1640/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.3428  Acc@1: 81.2500 (86.7611)  Acc@5: 100.0000 (98.6403)  time: 0.3577  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1650/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.9333  Acc@1: 81.2500 (86.7580)  Acc@5: 100.0000 (98.6448)  time: 0.3643  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1660/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.6560  Acc@1: 87.5000 (86.7700)  Acc@5: 100.0000 (98.6454)  time: 0.3609  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [1670/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.7282  Acc@1: 87.5000 (86.7445)  Acc@5: 100.0000 (98.6385)  time: 0.3559  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [1680/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.5370  Acc@1: 81.2500 (86.7341)  Acc@5: 100.0000 (98.6318)  time: 0.3667  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [1690/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.3020  Acc@1: 87.5000 (86.7460)  Acc@5: 100.0000 (98.6251)  time: 0.3653  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1700/3125]  eta: 0:08:25  Lr: 0.001875  Loss: 0.1756  Acc@1: 87.5000 (86.7394)  Acc@5: 100.0000 (98.6185)  time: 0.3517  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1710/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5042  Acc@1: 87.5000 (86.7329)  Acc@5: 100.0000 (98.6083)  time: 0.3545  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1720/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.5632  Acc@1: 87.5000 (86.7337)  Acc@5: 100.0000 (98.6091)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1730/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.3787  Acc@1: 87.5000 (86.7201)  Acc@5: 100.0000 (98.6099)  time: 0.3542  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1740/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.3753  Acc@1: 81.2500 (86.7102)  Acc@5: 100.0000 (98.5999)  time: 0.3540  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1750/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.7139  Acc@1: 87.5000 (86.7397)  Acc@5: 100.0000 (98.6008)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1760/3125]  eta: 0:08:04  Lr: 0.001875  Loss: 0.0958  Acc@1: 87.5000 (86.7298)  Acc@5: 100.0000 (98.5945)  time: 0.3513  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1770/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.8222  Acc@1: 87.5000 (86.7307)  Acc@5: 100.0000 (98.5919)  time: 0.3519  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1780/3125]  eta: 0:07:56  Lr: 0.001875  Loss: -0.5522  Acc@1: 87.5000 (86.7245)  Acc@5: 100.0000 (98.5893)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1790/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4891  Acc@1: 87.5000 (86.7078)  Acc@5: 100.0000 (98.5867)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1800/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.6854  Acc@1: 87.5000 (86.7296)  Acc@5: 100.0000 (98.5911)  time: 0.3603  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1810/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.3688  Acc@1: 87.5000 (86.7235)  Acc@5: 100.0000 (98.5885)  time: 0.3593  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1820/3125]  eta: 0:07:42  Lr: 0.001875  Loss: -0.4079  Acc@1: 87.5000 (86.7415)  Acc@5: 100.0000 (98.5928)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1830/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.4380  Acc@1: 87.5000 (86.7490)  Acc@5: 100.0000 (98.5937)  time: 0.3544  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1840/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.3833  Acc@1: 87.5000 (86.7226)  Acc@5: 100.0000 (98.5945)  time: 0.3624  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1850/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.4586  Acc@1: 81.2500 (86.7031)  Acc@5: 100.0000 (98.5818)  time: 0.3582  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1860/3125]  eta: 0:07:28  Lr: 0.001875  Loss: -0.7601  Acc@1: 87.5000 (86.7041)  Acc@5: 100.0000 (98.5895)  time: 0.3533  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1870/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.5800  Acc@1: 87.5000 (86.7016)  Acc@5: 100.0000 (98.5870)  time: 0.3542  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1880/3125]  eta: 0:07:21  Lr: 0.001875  Loss: -0.5815  Acc@1: 87.5000 (86.6992)  Acc@5: 100.0000 (98.5845)  time: 0.3549  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1890/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.6124  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (98.5887)  time: 0.3543  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:14  Lr: 0.001875  Loss: -0.8652  Acc@1: 87.5000 (86.7142)  Acc@5: 100.0000 (98.5928)  time: 0.3530  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1910/3125]  eta: 0:07:10  Lr: 0.001875  Loss: -0.8600  Acc@1: 87.5000 (86.7282)  Acc@5: 100.0000 (98.5904)  time: 0.3526  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [1920/3125]  eta: 0:07:07  Lr: 0.001875  Loss: -0.3527  Acc@1: 87.5000 (86.7159)  Acc@5: 100.0000 (98.5912)  time: 0.3526  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1930/3125]  eta: 0:07:03  Lr: 0.001875  Loss: -0.8096  Acc@1: 87.5000 (86.7070)  Acc@5: 100.0000 (98.5921)  time: 0.3546  data: 0.0024  max mem: 2502
Train: Epoch[4/5]  [1940/3125]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5846  Acc@1: 87.5000 (86.7079)  Acc@5: 100.0000 (98.5864)  time: 0.3559  data: 0.0024  max mem: 2502
Train: Epoch[4/5]  [1950/3125]  eta: 0:06:56  Lr: 0.001875  Loss: -0.5529  Acc@1: 87.5000 (86.6959)  Acc@5: 100.0000 (98.5873)  time: 0.3539  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1960/3125]  eta: 0:06:53  Lr: 0.001875  Loss: -0.6278  Acc@1: 87.5000 (86.7064)  Acc@5: 100.0000 (98.5945)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1970/3125]  eta: 0:06:49  Lr: 0.001875  Loss: -0.3285  Acc@1: 87.5000 (86.6660)  Acc@5: 100.0000 (98.5953)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1980/3125]  eta: 0:06:46  Lr: 0.001875  Loss: -0.4857  Acc@1: 81.2500 (86.6829)  Acc@5: 100.0000 (98.5992)  time: 0.3544  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [1990/3125]  eta: 0:06:42  Lr: 0.001875  Loss: -0.4338  Acc@1: 87.5000 (86.6775)  Acc@5: 100.0000 (98.5968)  time: 0.3550  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [2000/3125]  eta: 0:06:38  Lr: 0.001875  Loss: -0.7097  Acc@1: 87.5000 (86.6910)  Acc@5: 100.0000 (98.5945)  time: 0.3523  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2010/3125]  eta: 0:06:35  Lr: 0.001875  Loss: -0.7891  Acc@1: 87.5000 (86.7137)  Acc@5: 100.0000 (98.5983)  time: 0.3584  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2020/3125]  eta: 0:06:31  Lr: 0.001875  Loss: -0.5778  Acc@1: 87.5000 (86.6990)  Acc@5: 100.0000 (98.5991)  time: 0.3605  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2030/3125]  eta: 0:06:28  Lr: 0.001875  Loss: -0.3826  Acc@1: 87.5000 (86.7122)  Acc@5: 100.0000 (98.5968)  time: 0.3556  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2040/3125]  eta: 0:06:24  Lr: 0.001875  Loss: -0.5919  Acc@1: 87.5000 (86.7191)  Acc@5: 100.0000 (98.5914)  time: 0.3533  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:21  Lr: 0.001875  Loss: -0.5439  Acc@1: 87.5000 (86.7138)  Acc@5: 100.0000 (98.5952)  time: 0.3547  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:17  Lr: 0.001875  Loss: -0.7155  Acc@1: 87.5000 (86.7419)  Acc@5: 100.0000 (98.5929)  time: 0.3643  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:14  Lr: 0.001875  Loss: -0.7968  Acc@1: 87.5000 (86.7335)  Acc@5: 100.0000 (98.5907)  time: 0.3606  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:10  Lr: 0.001875  Loss: -0.4684  Acc@1: 87.5000 (86.7311)  Acc@5: 100.0000 (98.5884)  time: 0.3520  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2090/3125]  eta: 0:06:07  Lr: 0.001875  Loss: -0.0438  Acc@1: 87.5000 (86.7348)  Acc@5: 100.0000 (98.5832)  time: 0.3512  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2100/3125]  eta: 0:06:03  Lr: 0.001875  Loss: -0.5366  Acc@1: 87.5000 (86.7355)  Acc@5: 100.0000 (98.5840)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2110/3125]  eta: 0:05:59  Lr: 0.001875  Loss: -0.3429  Acc@1: 87.5000 (86.7273)  Acc@5: 100.0000 (98.5848)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2120/3125]  eta: 0:05:56  Lr: 0.001875  Loss: -0.5716  Acc@1: 87.5000 (86.7162)  Acc@5: 100.0000 (98.5856)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2130/3125]  eta: 0:05:52  Lr: 0.001875  Loss: -0.5505  Acc@1: 81.2500 (86.6905)  Acc@5: 100.0000 (98.5834)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2140/3125]  eta: 0:05:49  Lr: 0.001875  Loss: -0.5594  Acc@1: 87.5000 (86.6943)  Acc@5: 100.0000 (98.5813)  time: 0.3526  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2150/3125]  eta: 0:05:45  Lr: 0.001875  Loss: -0.1488  Acc@1: 87.5000 (86.6893)  Acc@5: 100.0000 (98.5850)  time: 0.3553  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [2160/3125]  eta: 0:05:42  Lr: 0.001875  Loss: -0.5848  Acc@1: 87.5000 (86.7018)  Acc@5: 100.0000 (98.5828)  time: 0.3538  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2170/3125]  eta: 0:05:38  Lr: 0.001875  Loss: -0.5831  Acc@1: 87.5000 (86.7112)  Acc@5: 100.0000 (98.5836)  time: 0.3537  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2180/3125]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4424  Acc@1: 87.5000 (86.7205)  Acc@5: 100.0000 (98.5844)  time: 0.3533  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2190/3125]  eta: 0:05:31  Lr: 0.001875  Loss: -0.7198  Acc@1: 87.5000 (86.7270)  Acc@5: 100.0000 (98.5880)  time: 0.3552  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2200/3125]  eta: 0:05:28  Lr: 0.001875  Loss: -0.4242  Acc@1: 87.5000 (86.7447)  Acc@5: 100.0000 (98.5887)  time: 0.3651  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:24  Lr: 0.001875  Loss: -0.8367  Acc@1: 87.5000 (86.7481)  Acc@5: 100.0000 (98.5923)  time: 0.3636  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:21  Lr: 0.001875  Loss: -0.4619  Acc@1: 87.5000 (86.7402)  Acc@5: 100.0000 (98.5930)  time: 0.3548  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:17  Lr: 0.001875  Loss: -0.7489  Acc@1: 87.5000 (86.7464)  Acc@5: 100.0000 (98.5965)  time: 0.3709  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:14  Lr: 0.001875  Loss: -0.6175  Acc@1: 87.5000 (86.7442)  Acc@5: 100.0000 (98.5972)  time: 0.3685  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:10  Lr: 0.001875  Loss: -0.8102  Acc@1: 87.5000 (86.7476)  Acc@5: 100.0000 (98.5951)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2260/3125]  eta: 0:05:06  Lr: 0.001875  Loss: -0.2359  Acc@1: 87.5000 (86.7288)  Acc@5: 100.0000 (98.5847)  time: 0.3527  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2270/3125]  eta: 0:05:03  Lr: 0.001875  Loss: -0.7155  Acc@1: 87.5000 (86.7487)  Acc@5: 100.0000 (98.5909)  time: 0.3535  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2280/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.3404  Acc@1: 93.7500 (86.7657)  Acc@5: 100.0000 (98.5916)  time: 0.3531  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2290/3125]  eta: 0:04:56  Lr: 0.001875  Loss: -0.7246  Acc@1: 87.5000 (86.7743)  Acc@5: 100.0000 (98.5950)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2300/3125]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6366  Acc@1: 87.5000 (86.7829)  Acc@5: 100.0000 (98.5930)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2310/3125]  eta: 0:04:49  Lr: 0.001875  Loss: -0.6906  Acc@1: 87.5000 (86.7779)  Acc@5: 100.0000 (98.5910)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2320/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.0316  Acc@1: 87.5000 (86.7702)  Acc@5: 100.0000 (98.5863)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2330/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.7717  Acc@1: 81.2500 (86.7734)  Acc@5: 100.0000 (98.5843)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2340/3125]  eta: 0:04:38  Lr: 0.001875  Loss: 0.0558  Acc@1: 81.2500 (86.7551)  Acc@5: 100.0000 (98.5717)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2350/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.4345  Acc@1: 81.2500 (86.7556)  Acc@5: 100.0000 (98.5751)  time: 0.3517  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.5445  Acc@1: 87.5000 (86.7667)  Acc@5: 100.0000 (98.5758)  time: 0.3503  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.4927  Acc@1: 87.5000 (86.7593)  Acc@5: 100.0000 (98.5765)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.6868  Acc@1: 87.5000 (86.7545)  Acc@5: 100.0000 (98.5825)  time: 0.3518  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.4077  Acc@1: 87.5000 (86.7655)  Acc@5: 100.0000 (98.5832)  time: 0.3529  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.7210  Acc@1: 87.5000 (86.7659)  Acc@5: 100.0000 (98.5787)  time: 0.3529  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3756  Acc@1: 87.5000 (86.7716)  Acc@5: 100.0000 (98.5794)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.3238  Acc@1: 87.5000 (86.7694)  Acc@5: 100.0000 (98.5827)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2430/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.2688  Acc@1: 87.5000 (86.7827)  Acc@5: 100.0000 (98.5885)  time: 0.3532  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2440/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.6161  Acc@1: 93.7500 (86.7959)  Acc@5: 100.0000 (98.5918)  time: 0.3560  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [2450/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.6558  Acc@1: 87.5000 (86.8090)  Acc@5: 100.0000 (98.5950)  time: 0.3548  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2460/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.2388  Acc@1: 87.5000 (86.7914)  Acc@5: 100.0000 (98.5956)  time: 0.3532  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2470/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.7546  Acc@1: 87.5000 (86.8070)  Acc@5: 100.0000 (98.5962)  time: 0.3531  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2480/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7084  Acc@1: 87.5000 (86.8022)  Acc@5: 100.0000 (98.5893)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2490/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7278  Acc@1: 87.5000 (86.8175)  Acc@5: 100.0000 (98.5924)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2500/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.3209  Acc@1: 87.5000 (86.8128)  Acc@5: 100.0000 (98.5931)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2510/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.7448  Acc@1: 87.5000 (86.8255)  Acc@5: 100.0000 (98.5962)  time: 0.3533  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.4486  Acc@1: 87.5000 (86.8281)  Acc@5: 100.0000 (98.5968)  time: 0.3534  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:30  Lr: 0.001875  Loss: -0.7739  Acc@1: 87.5000 (86.8431)  Acc@5: 100.0000 (98.5999)  time: 0.3523  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.8858  Acc@1: 87.5000 (86.8384)  Acc@5: 100.0000 (98.5955)  time: 0.3546  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:23  Lr: 0.001875  Loss: -0.1538  Acc@1: 87.5000 (86.8385)  Acc@5: 100.0000 (98.5961)  time: 0.3539  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.7421  Acc@1: 87.5000 (86.8386)  Acc@5: 100.0000 (98.5992)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:16  Lr: 0.001875  Loss: -0.6906  Acc@1: 87.5000 (86.8461)  Acc@5: 100.0000 (98.5973)  time: 0.3528  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.4104  Acc@1: 87.5000 (86.8462)  Acc@5: 100.0000 (98.5931)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:09  Lr: 0.001875  Loss: -0.5908  Acc@1: 87.5000 (86.8439)  Acc@5: 100.0000 (98.5937)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.3769  Acc@1: 87.5000 (86.8416)  Acc@5: 100.0000 (98.5967)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2610/3125]  eta: 0:03:02  Lr: 0.001875  Loss: -0.5704  Acc@1: 87.5000 (86.8441)  Acc@5: 100.0000 (98.5925)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2620/3125]  eta: 0:02:58  Lr: 0.001875  Loss: -0.3649  Acc@1: 87.5000 (86.8490)  Acc@5: 100.0000 (98.5955)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2630/3125]  eta: 0:02:55  Lr: 0.001875  Loss: -0.5094  Acc@1: 87.5000 (86.8444)  Acc@5: 100.0000 (98.5937)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2640/3125]  eta: 0:02:51  Lr: 0.001875  Loss: -0.8082  Acc@1: 87.5000 (86.8587)  Acc@5: 100.0000 (98.5895)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2650/3125]  eta: 0:02:48  Lr: 0.001875  Loss: -0.7634  Acc@1: 87.5000 (86.8540)  Acc@5: 100.0000 (98.5878)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2660/3125]  eta: 0:02:44  Lr: 0.001875  Loss: -0.7060  Acc@1: 87.5000 (86.8635)  Acc@5: 100.0000 (98.5908)  time: 0.3523  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:41  Lr: 0.001875  Loss: -0.6813  Acc@1: 87.5000 (86.8448)  Acc@5: 100.0000 (98.5867)  time: 0.3590  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:37  Lr: 0.001875  Loss: 0.1536  Acc@1: 87.5000 (86.8403)  Acc@5: 100.0000 (98.5849)  time: 0.3560  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:34  Lr: 0.001875  Loss: -0.2832  Acc@1: 87.5000 (86.8474)  Acc@5: 100.0000 (98.5879)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:30  Lr: 0.001875  Loss: -0.7585  Acc@1: 87.5000 (86.8336)  Acc@5: 100.0000 (98.5908)  time: 0.3695  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:27  Lr: 0.001875  Loss: -0.6536  Acc@1: 87.5000 (86.8383)  Acc@5: 100.0000 (98.5914)  time: 0.3692  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:23  Lr: 0.001875  Loss: -0.2661  Acc@1: 87.5000 (86.8385)  Acc@5: 100.0000 (98.5897)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:20  Lr: 0.001875  Loss: -0.6445  Acc@1: 93.7500 (86.8546)  Acc@5: 100.0000 (98.5948)  time: 0.3547  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:16  Lr: 0.001875  Loss: -0.5408  Acc@1: 93.7500 (86.8707)  Acc@5: 100.0000 (98.5954)  time: 0.3549  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:12  Lr: 0.001875  Loss: -0.5866  Acc@1: 87.5000 (86.8798)  Acc@5: 100.0000 (98.5960)  time: 0.3538  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:09  Lr: 0.001875  Loss: -0.2959  Acc@1: 87.5000 (86.8684)  Acc@5: 100.0000 (98.5943)  time: 0.3530  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:05  Lr: 0.001875  Loss: -0.5596  Acc@1: 81.2500 (86.8662)  Acc@5: 100.0000 (98.5948)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2780/3125]  eta: 0:02:02  Lr: 0.001875  Loss: -0.5272  Acc@1: 87.5000 (86.8640)  Acc@5: 100.0000 (98.5886)  time: 0.3513  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2790/3125]  eta: 0:01:58  Lr: 0.001875  Loss: -0.4953  Acc@1: 87.5000 (86.8506)  Acc@5: 100.0000 (98.5847)  time: 0.3527  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2800/3125]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4059  Acc@1: 87.5000 (86.8462)  Acc@5: 100.0000 (98.5853)  time: 0.3525  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [2810/3125]  eta: 0:01:51  Lr: 0.001875  Loss: -0.6951  Acc@1: 87.5000 (86.8530)  Acc@5: 100.0000 (98.5837)  time: 0.3528  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:48  Lr: 0.001875  Loss: -0.3504  Acc@1: 87.5000 (86.8553)  Acc@5: 100.0000 (98.5865)  time: 0.3546  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6060  Acc@1: 87.5000 (86.8509)  Acc@5: 100.0000 (98.5871)  time: 0.3528  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:41  Lr: 0.001875  Loss: -0.4707  Acc@1: 87.5000 (86.8598)  Acc@5: 100.0000 (98.5898)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:37  Lr: 0.001875  Loss: -0.5744  Acc@1: 87.5000 (86.8621)  Acc@5: 100.0000 (98.5904)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:33  Lr: 0.001875  Loss: -0.7712  Acc@1: 87.5000 (86.8643)  Acc@5: 100.0000 (98.5953)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:30  Lr: 0.001875  Loss: -0.8039  Acc@1: 87.5000 (86.8730)  Acc@5: 100.0000 (98.5937)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:26  Lr: 0.001875  Loss: -0.1635  Acc@1: 87.5000 (86.8730)  Acc@5: 100.0000 (98.5899)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5583  Acc@1: 87.5000 (86.8903)  Acc@5: 100.0000 (98.5926)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:19  Lr: 0.001875  Loss: 0.2263  Acc@1: 93.7500 (86.9011)  Acc@5: 100.0000 (98.5910)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:16  Lr: 0.001875  Loss: -0.8191  Acc@1: 87.5000 (86.9010)  Acc@5: 100.0000 (98.5915)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:12  Lr: 0.001875  Loss: -0.8284  Acc@1: 87.5000 (86.9030)  Acc@5: 100.0000 (98.5900)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:09  Lr: 0.001875  Loss: -0.4754  Acc@1: 87.5000 (86.9008)  Acc@5: 100.0000 (98.5905)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:05  Lr: 0.001875  Loss: -0.5353  Acc@1: 87.5000 (86.8901)  Acc@5: 100.0000 (98.5932)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0947  Acc@1: 81.2500 (86.8794)  Acc@5: 100.0000 (98.5873)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2960/3125]  eta: 0:00:58  Lr: 0.001875  Loss: -0.6737  Acc@1: 87.5000 (86.8879)  Acc@5: 100.0000 (98.5900)  time: 0.3527  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5106  Acc@1: 87.5000 (86.8984)  Acc@5: 100.0000 (98.5926)  time: 0.3515  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:51  Lr: 0.001875  Loss: -0.0410  Acc@1: 87.5000 (86.8752)  Acc@5: 100.0000 (98.5932)  time: 0.3519  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6263  Acc@1: 87.5000 (86.8752)  Acc@5: 100.0000 (98.5937)  time: 0.3528  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6074  Acc@1: 87.5000 (86.8856)  Acc@5: 100.0000 (98.5921)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3450  Acc@1: 87.5000 (86.8897)  Acc@5: 100.0000 (98.5927)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8585  Acc@1: 87.5000 (86.8938)  Acc@5: 100.0000 (98.5973)  time: 0.3551  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6631  Acc@1: 87.5000 (86.8917)  Acc@5: 100.0000 (98.5958)  time: 0.3556  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:30  Lr: 0.001875  Loss: -0.5745  Acc@1: 87.5000 (86.8875)  Acc@5: 100.0000 (98.5942)  time: 0.3524  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.4971  Acc@1: 87.5000 (86.8895)  Acc@5: 100.0000 (98.5927)  time: 0.3543  data: 0.0028  max mem: 2502
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:23  Lr: 0.001875  Loss: -0.3025  Acc@1: 87.5000 (86.8875)  Acc@5: 100.0000 (98.5952)  time: 0.3544  data: 0.0028  max mem: 2502
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.4315  Acc@1: 87.5000 (86.8915)  Acc@5: 100.0000 (98.5957)  time: 0.3522  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.7481  Acc@1: 87.5000 (86.8894)  Acc@5: 100.0000 (98.5962)  time: 0.3529  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.5340  Acc@1: 87.5000 (86.9015)  Acc@5: 100.0000 (98.5947)  time: 0.3525  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5254  Acc@1: 87.5000 (86.8933)  Acc@5: 100.0000 (98.5972)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4821  Acc@1: 87.5000 (86.9013)  Acc@5: 100.0000 (98.5997)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5853  Acc@1: 93.7500 (86.9092)  Acc@5: 100.0000 (98.5962)  time: 0.3531  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7307  Acc@1: 87.5000 (86.9120)  Acc@5: 100.0000 (98.5980)  time: 0.3527  data: 0.0007  max mem: 2502
Train: Epoch[4/5] Total time: 0:18:27 (0.3544 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.7307  Acc@1: 87.5000 (86.9120)  Acc@5: 100.0000 (98.5980)
Train: Epoch[5/5]  [   0/3125]  eta: 0:50:19  Lr: 0.001875  Loss: -0.3409  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.9662  data: 0.6085  max mem: 2502
Train: Epoch[5/5]  [  10/3125]  eta: 0:21:11  Lr: 0.001875  Loss: -0.0695  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (97.1591)  time: 0.4083  data: 0.0558  max mem: 2502
Train: Epoch[5/5]  [  20/3125]  eta: 0:19:43  Lr: 0.001875  Loss: -0.3703  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (97.6190)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [  30/3125]  eta: 0:19:09  Lr: 0.001875  Loss: -0.7764  Acc@1: 93.7500 (88.5081)  Acc@5: 100.0000 (98.1855)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [  40/3125]  eta: 0:18:51  Lr: 0.001875  Loss: -0.6566  Acc@1: 93.7500 (88.5671)  Acc@5: 100.0000 (98.3232)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  50/3125]  eta: 0:18:38  Lr: 0.001875  Loss: -0.4424  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (98.4069)  time: 0.3517  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [  60/3125]  eta: 0:18:28  Lr: 0.001875  Loss: -0.9207  Acc@1: 87.5000 (88.4221)  Acc@5: 100.0000 (98.4631)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [  70/3125]  eta: 0:18:20  Lr: 0.001875  Loss: -0.3613  Acc@1: 87.5000 (88.6444)  Acc@5: 100.0000 (98.6796)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  80/3125]  eta: 0:18:15  Lr: 0.001875  Loss: -0.7650  Acc@1: 87.5000 (88.1173)  Acc@5: 100.0000 (98.6111)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  90/3125]  eta: 0:18:11  Lr: 0.001875  Loss: -0.6346  Acc@1: 87.5000 (88.2555)  Acc@5: 100.0000 (98.7637)  time: 0.3584  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 100/3125]  eta: 0:18:06  Lr: 0.001875  Loss: -0.7933  Acc@1: 87.5000 (88.5520)  Acc@5: 100.0000 (98.8243)  time: 0.3566  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 110/3125]  eta: 0:18:00  Lr: 0.001875  Loss: -0.7898  Acc@1: 93.7500 (88.7950)  Acc@5: 100.0000 (98.8739)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 120/3125]  eta: 0:17:55  Lr: 0.001875  Loss: -0.4997  Acc@1: 87.5000 (88.6880)  Acc@5: 100.0000 (98.8636)  time: 0.3524  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 130/3125]  eta: 0:17:52  Lr: 0.001875  Loss: -0.7983  Acc@1: 93.7500 (88.8359)  Acc@5: 100.0000 (98.9504)  time: 0.3553  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 140/3125]  eta: 0:17:49  Lr: 0.001875  Loss: 0.1222  Acc@1: 93.7500 (88.7411)  Acc@5: 100.0000 (98.9805)  time: 0.3613  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 150/3125]  eta: 0:17:45  Lr: 0.001875  Loss: -0.3705  Acc@1: 87.5000 (88.5348)  Acc@5: 100.0000 (98.8825)  time: 0.3592  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 160/3125]  eta: 0:17:40  Lr: 0.001875  Loss: -0.8309  Acc@1: 87.5000 (88.3540)  Acc@5: 100.0000 (98.8742)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 170/3125]  eta: 0:17:36  Lr: 0.001875  Loss: -0.5423  Acc@1: 87.5000 (88.4503)  Acc@5: 100.0000 (98.9035)  time: 0.3531  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 180/3125]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6364  Acc@1: 87.5000 (88.1215)  Acc@5: 100.0000 (98.8260)  time: 0.3553  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 190/3125]  eta: 0:17:28  Lr: 0.001875  Loss: -0.6416  Acc@1: 87.5000 (88.2526)  Acc@5: 100.0000 (98.8220)  time: 0.3541  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 200/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.6387  Acc@1: 87.5000 (88.3396)  Acc@5: 100.0000 (98.8184)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 210/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6462  Acc@1: 87.5000 (88.2405)  Acc@5: 100.0000 (98.8152)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 220/3125]  eta: 0:17:16  Lr: 0.001875  Loss: -0.7873  Acc@1: 87.5000 (88.2070)  Acc@5: 100.0000 (98.8405)  time: 0.3544  data: 0.0032  max mem: 2502
Train: Epoch[5/5]  [ 230/3125]  eta: 0:17:12  Lr: 0.001875  Loss: -0.5314  Acc@1: 87.5000 (87.9870)  Acc@5: 100.0000 (98.8366)  time: 0.3585  data: 0.0032  max mem: 2502
Train: Epoch[5/5]  [ 240/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.5615  Acc@1: 87.5000 (88.0187)  Acc@5: 100.0000 (98.8849)  time: 0.3623  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 250/3125]  eta: 0:17:06  Lr: 0.001875  Loss: -0.6323  Acc@1: 87.5000 (88.0229)  Acc@5: 100.0000 (98.9044)  time: 0.3587  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 260/3125]  eta: 0:17:02  Lr: 0.001875  Loss: -0.6021  Acc@1: 87.5000 (88.1226)  Acc@5: 100.0000 (98.9224)  time: 0.3526  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 270/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.0437  Acc@1: 87.5000 (88.1919)  Acc@5: 100.0000 (98.9161)  time: 0.3651  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 280/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5265  Acc@1: 87.5000 (88.0783)  Acc@5: 100.0000 (98.8879)  time: 0.3677  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 290/3125]  eta: 0:16:52  Lr: 0.001875  Loss: -0.3330  Acc@1: 87.5000 (88.1658)  Acc@5: 100.0000 (98.8832)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 300/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.7018  Acc@1: 87.5000 (88.0399)  Acc@5: 100.0000 (98.8372)  time: 0.3532  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 310/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.4237  Acc@1: 87.5000 (88.0024)  Acc@5: 100.0000 (98.8344)  time: 0.3543  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 320/3125]  eta: 0:16:40  Lr: 0.001875  Loss: -0.8166  Acc@1: 87.5000 (87.8699)  Acc@5: 100.0000 (98.8318)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 330/3125]  eta: 0:16:36  Lr: 0.001875  Loss: 0.0327  Acc@1: 81.2500 (87.7266)  Acc@5: 100.0000 (98.7538)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 340/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.8815  Acc@1: 87.5000 (87.7749)  Acc@5: 100.0000 (98.7720)  time: 0.3552  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 350/3125]  eta: 0:16:29  Lr: 0.001875  Loss: -0.6986  Acc@1: 87.5000 (87.7315)  Acc@5: 100.0000 (98.7536)  time: 0.3534  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 360/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.4124  Acc@1: 81.2500 (87.6212)  Acc@5: 100.0000 (98.7361)  time: 0.3521  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 370/3125]  eta: 0:16:21  Lr: 0.001875  Loss: -0.6425  Acc@1: 87.5000 (87.6179)  Acc@5: 100.0000 (98.7365)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 380/3125]  eta: 0:16:18  Lr: 0.001875  Loss: -0.2310  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7205)  time: 0.3544  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 390/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.7959  Acc@1: 87.5000 (87.5480)  Acc@5: 100.0000 (98.7212)  time: 0.3569  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 400/3125]  eta: 0:16:10  Lr: 0.001875  Loss: -0.3874  Acc@1: 87.5000 (87.5935)  Acc@5: 100.0000 (98.7375)  time: 0.3541  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 410/3125]  eta: 0:16:06  Lr: 0.001875  Loss: -0.8189  Acc@1: 87.5000 (87.6521)  Acc@5: 100.0000 (98.7530)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 420/3125]  eta: 0:16:02  Lr: 0.001875  Loss: -0.4792  Acc@1: 87.5000 (87.6039)  Acc@5: 100.0000 (98.7233)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 430/3125]  eta: 0:15:59  Lr: 0.001875  Loss: -0.6195  Acc@1: 87.5000 (87.6450)  Acc@5: 100.0000 (98.6949)  time: 0.3571  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 440/3125]  eta: 0:15:55  Lr: 0.001875  Loss: -0.6020  Acc@1: 87.5000 (87.6559)  Acc@5: 100.0000 (98.7103)  time: 0.3573  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 450/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.5405  Acc@1: 87.5000 (87.6663)  Acc@5: 100.0000 (98.7112)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 460/3125]  eta: 0:15:48  Lr: 0.001875  Loss: -0.8271  Acc@1: 87.5000 (87.7305)  Acc@5: 100.0000 (98.7392)  time: 0.3520  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 470/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.5452  Acc@1: 93.7500 (87.7256)  Acc@5: 100.0000 (98.7527)  time: 0.3585  data: 0.0021  max mem: 2502
Train: Epoch[5/5]  [ 480/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.8092  Acc@1: 81.2500 (87.6429)  Acc@5: 100.0000 (98.7136)  time: 0.3604  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 490/3125]  eta: 0:15:37  Lr: 0.001875  Loss: -0.3538  Acc@1: 81.2500 (87.6527)  Acc@5: 100.0000 (98.6889)  time: 0.3537  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 500/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.5941  Acc@1: 87.5000 (87.6497)  Acc@5: 100.0000 (98.6402)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 510/3125]  eta: 0:15:30  Lr: 0.001875  Loss: -0.5012  Acc@1: 81.2500 (87.5367)  Acc@5: 100.0000 (98.6546)  time: 0.3527  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 520/3125]  eta: 0:15:26  Lr: 0.001875  Loss: -0.7890  Acc@1: 81.2500 (87.5000)  Acc@5: 100.0000 (98.6204)  time: 0.3534  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 530/3125]  eta: 0:15:22  Lr: 0.001875  Loss: -0.5009  Acc@1: 81.2500 (87.4647)  Acc@5: 100.0000 (98.6464)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 540/3125]  eta: 0:15:18  Lr: 0.001875  Loss: -0.7373  Acc@1: 87.5000 (87.5347)  Acc@5: 100.0000 (98.6483)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 550/3125]  eta: 0:15:15  Lr: 0.001875  Loss: -0.3989  Acc@1: 87.5000 (87.4773)  Acc@5: 100.0000 (98.6275)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 560/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.5027  Acc@1: 87.5000 (87.4554)  Acc@5: 100.0000 (98.6408)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 570/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.4901  Acc@1: 87.5000 (87.4891)  Acc@5: 100.0000 (98.6537)  time: 0.3509  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 580/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.5351  Acc@1: 87.5000 (87.5430)  Acc@5: 100.0000 (98.6338)  time: 0.3518  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 590/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.2608  Acc@1: 87.5000 (87.4788)  Acc@5: 100.0000 (98.6146)  time: 0.3536  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 600/3125]  eta: 0:14:56  Lr: 0.001875  Loss: -0.7086  Acc@1: 87.5000 (87.5520)  Acc@5: 100.0000 (98.6273)  time: 0.3548  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 610/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.8391  Acc@1: 87.5000 (87.5307)  Acc@5: 100.0000 (98.6395)  time: 0.3531  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 620/3125]  eta: 0:14:49  Lr: 0.001875  Loss: -0.4819  Acc@1: 87.5000 (87.4698)  Acc@5: 100.0000 (98.6413)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 630/3125]  eta: 0:14:45  Lr: 0.001875  Loss: -0.4169  Acc@1: 87.5000 (87.4307)  Acc@5: 100.0000 (98.6331)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 640/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.5971  Acc@1: 87.5000 (87.4512)  Acc@5: 100.0000 (98.6544)  time: 0.3538  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 650/3125]  eta: 0:14:38  Lr: 0.001875  Loss: -0.4426  Acc@1: 87.5000 (87.4136)  Acc@5: 100.0000 (98.6463)  time: 0.3545  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 660/3125]  eta: 0:14:35  Lr: 0.001875  Loss: -0.5721  Acc@1: 87.5000 (87.3865)  Acc@5: 100.0000 (98.6479)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 670/3125]  eta: 0:14:31  Lr: 0.001875  Loss: -0.4771  Acc@1: 87.5000 (87.3510)  Acc@5: 100.0000 (98.6494)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 680/3125]  eta: 0:14:27  Lr: 0.001875  Loss: -0.4683  Acc@1: 87.5000 (87.3256)  Acc@5: 100.0000 (98.6509)  time: 0.3542  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 690/3125]  eta: 0:14:24  Lr: 0.001875  Loss: -0.7513  Acc@1: 87.5000 (87.3553)  Acc@5: 100.0000 (98.6614)  time: 0.3534  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 700/3125]  eta: 0:14:20  Lr: 0.001875  Loss: -0.6626  Acc@1: 93.7500 (87.3663)  Acc@5: 100.0000 (98.6537)  time: 0.3528  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [ 710/3125]  eta: 0:14:17  Lr: 0.001875  Loss: -0.8287  Acc@1: 87.5000 (87.3418)  Acc@5: 100.0000 (98.6463)  time: 0.3527  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 720/3125]  eta: 0:14:13  Lr: 0.001875  Loss: -0.3153  Acc@1: 87.5000 (87.3440)  Acc@5: 100.0000 (98.6564)  time: 0.3512  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 730/3125]  eta: 0:14:09  Lr: 0.001875  Loss: -0.5293  Acc@1: 87.5000 (87.3461)  Acc@5: 100.0000 (98.6491)  time: 0.3533  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 740/3125]  eta: 0:14:06  Lr: 0.001875  Loss: -0.4363  Acc@1: 87.5000 (87.3397)  Acc@5: 100.0000 (98.6252)  time: 0.3529  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 750/3125]  eta: 0:14:02  Lr: 0.001875  Loss: -0.6250  Acc@1: 87.5000 (87.3086)  Acc@5: 100.0000 (98.6268)  time: 0.3516  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 760/3125]  eta: 0:13:58  Lr: 0.001875  Loss: -0.6458  Acc@1: 87.5000 (87.2947)  Acc@5: 100.0000 (98.6202)  time: 0.3512  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 770/3125]  eta: 0:13:55  Lr: 0.001875  Loss: -0.7366  Acc@1: 81.2500 (87.2325)  Acc@5: 100.0000 (98.6057)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 780/3125]  eta: 0:13:51  Lr: 0.001875  Loss: -0.5102  Acc@1: 87.5000 (87.2999)  Acc@5: 100.0000 (98.6236)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 790/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.2416  Acc@1: 93.7500 (87.3420)  Acc@5: 100.0000 (98.6252)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 800/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4543  Acc@1: 87.5000 (87.3361)  Acc@5: 100.0000 (98.6345)  time: 0.3471  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 810/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.4432  Acc@1: 87.5000 (87.3382)  Acc@5: 100.0000 (98.6514)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 820/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.6067  Acc@1: 87.5000 (87.3325)  Acc@5: 100.0000 (98.6297)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 830/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.7789  Acc@1: 87.5000 (87.3270)  Acc@5: 93.7500 (98.6086)  time: 0.3468  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 840/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5052  Acc@1: 87.5000 (87.3588)  Acc@5: 100.0000 (98.5954)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 850/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4659  Acc@1: 93.7500 (87.4045)  Acc@5: 100.0000 (98.6046)  time: 0.3510  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 860/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.5279  Acc@1: 87.5000 (87.4274)  Acc@5: 100.0000 (98.6063)  time: 0.3539  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 870/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.5544  Acc@1: 87.5000 (87.4354)  Acc@5: 100.0000 (98.6079)  time: 0.3527  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 880/3125]  eta: 0:13:14  Lr: 0.001875  Loss: -0.8140  Acc@1: 81.2500 (87.3510)  Acc@5: 100.0000 (98.5670)  time: 0.3531  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 890/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4481  Acc@1: 81.2500 (87.3387)  Acc@5: 100.0000 (98.5690)  time: 0.3543  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 900/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.5701  Acc@1: 87.5000 (87.3127)  Acc@5: 100.0000 (98.5572)  time: 0.3536  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 910/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.7153  Acc@1: 87.5000 (87.3079)  Acc@5: 100.0000 (98.5456)  time: 0.3530  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 920/3125]  eta: 0:13:00  Lr: 0.001875  Loss: -0.7530  Acc@1: 87.5000 (87.2964)  Acc@5: 100.0000 (98.5478)  time: 0.3521  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 930/3125]  eta: 0:12:57  Lr: 0.001875  Loss: -0.7841  Acc@1: 87.5000 (87.2986)  Acc@5: 100.0000 (98.5567)  time: 0.3522  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 940/3125]  eta: 0:12:53  Lr: 0.001875  Loss: -0.6470  Acc@1: 87.5000 (87.3007)  Acc@5: 100.0000 (98.5521)  time: 0.3530  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 950/3125]  eta: 0:12:49  Lr: 0.001875  Loss: -0.7910  Acc@1: 87.5000 (87.2831)  Acc@5: 100.0000 (98.5607)  time: 0.3521  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 960/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.4880  Acc@1: 87.5000 (87.3244)  Acc@5: 100.0000 (98.5757)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 970/3125]  eta: 0:12:42  Lr: 0.001875  Loss: -0.6652  Acc@1: 87.5000 (87.3455)  Acc@5: 100.0000 (98.5839)  time: 0.3524  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 980/3125]  eta: 0:12:39  Lr: 0.001875  Loss: -0.4509  Acc@1: 87.5000 (87.3471)  Acc@5: 100.0000 (98.5856)  time: 0.3542  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 990/3125]  eta: 0:12:35  Lr: 0.001875  Loss: -0.3658  Acc@1: 87.5000 (87.3486)  Acc@5: 100.0000 (98.5873)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1000/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.7006  Acc@1: 87.5000 (87.3751)  Acc@5: 100.0000 (98.5952)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1010/3125]  eta: 0:12:28  Lr: 0.001875  Loss: -0.8039  Acc@1: 87.5000 (87.3578)  Acc@5: 100.0000 (98.5905)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1020/3125]  eta: 0:12:24  Lr: 0.001875  Loss: -0.4931  Acc@1: 87.5000 (87.3408)  Acc@5: 100.0000 (98.5859)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1030/3125]  eta: 0:12:21  Lr: 0.001875  Loss: -0.6260  Acc@1: 87.5000 (87.3545)  Acc@5: 100.0000 (98.5936)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1040/3125]  eta: 0:12:17  Lr: 0.001875  Loss: -0.5302  Acc@1: 87.5000 (87.3319)  Acc@5: 100.0000 (98.5831)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1050/3125]  eta: 0:12:14  Lr: 0.001875  Loss: -0.4697  Acc@1: 87.5000 (87.3692)  Acc@5: 100.0000 (98.5906)  time: 0.3496  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1060/3125]  eta: 0:12:10  Lr: 0.001875  Loss: -0.5083  Acc@1: 87.5000 (87.3410)  Acc@5: 100.0000 (98.5980)  time: 0.3513  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1070/3125]  eta: 0:12:06  Lr: 0.001875  Loss: -0.5700  Acc@1: 87.5000 (87.3191)  Acc@5: 100.0000 (98.6111)  time: 0.3509  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1080/3125]  eta: 0:12:03  Lr: 0.001875  Loss: -0.5806  Acc@1: 87.5000 (87.3381)  Acc@5: 100.0000 (98.6240)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1090/3125]  eta: 0:11:59  Lr: 0.001875  Loss: -0.4373  Acc@1: 87.5000 (87.3281)  Acc@5: 100.0000 (98.6308)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1100/3125]  eta: 0:11:56  Lr: 0.001875  Loss: -0.7520  Acc@1: 87.5000 (87.3638)  Acc@5: 100.0000 (98.6376)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1110/3125]  eta: 0:11:52  Lr: 0.001875  Loss: -0.4735  Acc@1: 93.7500 (87.3594)  Acc@5: 100.0000 (98.6161)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1120/3125]  eta: 0:11:49  Lr: 0.001875  Loss: -0.5835  Acc@1: 87.5000 (87.3662)  Acc@5: 100.0000 (98.6229)  time: 0.3529  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1130/3125]  eta: 0:11:45  Lr: 0.001875  Loss: -0.8404  Acc@1: 87.5000 (87.3453)  Acc@5: 100.0000 (98.6185)  time: 0.3533  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1140/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.3238  Acc@1: 81.2500 (87.2864)  Acc@5: 100.0000 (98.6032)  time: 0.3534  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1150/3125]  eta: 0:11:38  Lr: 0.001875  Loss: -0.5367  Acc@1: 81.2500 (87.2719)  Acc@5: 100.0000 (98.6045)  time: 0.3524  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1160/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.8087  Acc@1: 87.5000 (87.2631)  Acc@5: 100.0000 (98.6057)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1170/3125]  eta: 0:11:31  Lr: 0.001875  Loss: -0.5270  Acc@1: 87.5000 (87.3079)  Acc@5: 100.0000 (98.6123)  time: 0.3550  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1180/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.5380  Acc@1: 87.5000 (87.2883)  Acc@5: 100.0000 (98.6029)  time: 0.3590  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [1190/3125]  eta: 0:11:24  Lr: 0.001875  Loss: -0.4357  Acc@1: 87.5000 (87.2953)  Acc@5: 100.0000 (98.6041)  time: 0.3556  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1200/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.5428  Acc@1: 87.5000 (87.2866)  Acc@5: 100.0000 (98.5949)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1210/3125]  eta: 0:11:17  Lr: 0.001875  Loss: -0.5079  Acc@1: 87.5000 (87.3090)  Acc@5: 100.0000 (98.6014)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1220/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.5225  Acc@1: 87.5000 (87.3055)  Acc@5: 100.0000 (98.6026)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1230/3125]  eta: 0:11:10  Lr: 0.001875  Loss: -0.8752  Acc@1: 87.5000 (87.3121)  Acc@5: 100.0000 (98.5885)  time: 0.3555  data: 0.0021  max mem: 2502
Train: Epoch[5/5]  [1240/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.4153  Acc@1: 87.5000 (87.2734)  Acc@5: 100.0000 (98.5848)  time: 0.3566  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1250/3125]  eta: 0:11:03  Lr: 0.001875  Loss: -0.5001  Acc@1: 81.2500 (87.1753)  Acc@5: 100.0000 (98.5811)  time: 0.3534  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1260/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.6189  Acc@1: 81.2500 (87.1977)  Acc@5: 100.0000 (98.5924)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1270/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.4825  Acc@1: 87.5000 (87.1853)  Acc@5: 100.0000 (98.5887)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1280/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.3224  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (98.5900)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1290/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.5404  Acc@1: 87.5000 (87.1902)  Acc@5: 100.0000 (98.5960)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1300/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.5238  Acc@1: 87.5000 (87.2022)  Acc@5: 100.0000 (98.5924)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1310/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.4393  Acc@1: 87.5000 (87.1901)  Acc@5: 100.0000 (98.5889)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1320/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.4843  Acc@1: 87.5000 (87.1830)  Acc@5: 100.0000 (98.5806)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1330/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.3569  Acc@1: 87.5000 (87.1807)  Acc@5: 100.0000 (98.5866)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1340/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.7924  Acc@1: 93.7500 (87.1784)  Acc@5: 100.0000 (98.5831)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1350/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.4406  Acc@1: 87.5000 (87.1438)  Acc@5: 100.0000 (98.5705)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1360/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.5158  Acc@1: 81.2500 (87.1326)  Acc@5: 100.0000 (98.5626)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1370/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.4955  Acc@1: 87.5000 (87.1262)  Acc@5: 100.0000 (98.5731)  time: 0.3498  data: 0.0023  max mem: 2502
Train: Epoch[5/5]  [1380/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.6492  Acc@1: 87.5000 (87.1244)  Acc@5: 100.0000 (98.5744)  time: 0.3515  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1390/3125]  eta: 0:10:12  Lr: 0.001875  Loss: -0.7376  Acc@1: 87.5000 (87.1361)  Acc@5: 100.0000 (98.5802)  time: 0.3523  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1400/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.4825  Acc@1: 87.5000 (87.1431)  Acc@5: 100.0000 (98.5858)  time: 0.3526  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1410/3125]  eta: 0:10:05  Lr: 0.001875  Loss: -0.6732  Acc@1: 87.5000 (87.1501)  Acc@5: 100.0000 (98.5914)  time: 0.3509  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1420/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.7881  Acc@1: 87.5000 (87.1437)  Acc@5: 100.0000 (98.5925)  time: 0.3519  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1430/3125]  eta: 0:09:58  Lr: 0.001875  Loss: -0.2987  Acc@1: 87.5000 (87.1550)  Acc@5: 100.0000 (98.5762)  time: 0.3557  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1440/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.8038  Acc@1: 87.5000 (87.1617)  Acc@5: 100.0000 (98.5730)  time: 0.3553  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [1450/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.6856  Acc@1: 87.5000 (87.1640)  Acc@5: 100.0000 (98.5743)  time: 0.3534  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1460/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.8791  Acc@1: 87.5000 (87.1492)  Acc@5: 100.0000 (98.5797)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1470/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.6481  Acc@1: 87.5000 (87.1431)  Acc@5: 100.0000 (98.5766)  time: 0.3522  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1480/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.6327  Acc@1: 87.5000 (87.1286)  Acc@5: 100.0000 (98.5736)  time: 0.3536  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1490/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.5905  Acc@1: 87.5000 (87.1269)  Acc@5: 100.0000 (98.5790)  time: 0.3574  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [1500/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.6713  Acc@1: 87.5000 (87.1419)  Acc@5: 100.0000 (98.5801)  time: 0.3574  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1510/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.5707  Acc@1: 87.5000 (87.1236)  Acc@5: 100.0000 (98.5771)  time: 0.3554  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1520/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.4219  Acc@1: 87.5000 (87.1261)  Acc@5: 100.0000 (98.5700)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1530/3125]  eta: 0:09:23  Lr: 0.001875  Loss: -0.6682  Acc@1: 87.5000 (87.1081)  Acc@5: 100.0000 (98.5753)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1540/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.6822  Acc@1: 87.5000 (87.1147)  Acc@5: 100.0000 (98.5805)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1550/3125]  eta: 0:09:16  Lr: 0.001875  Loss: -0.4692  Acc@1: 87.5000 (87.1212)  Acc@5: 100.0000 (98.5775)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1560/3125]  eta: 0:09:12  Lr: 0.001875  Loss: -0.6089  Acc@1: 81.2500 (87.0956)  Acc@5: 100.0000 (98.5786)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1570/3125]  eta: 0:09:09  Lr: 0.001875  Loss: -0.4600  Acc@1: 81.2500 (87.0743)  Acc@5: 100.0000 (98.5757)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1580/3125]  eta: 0:09:05  Lr: 0.001875  Loss: -0.3772  Acc@1: 87.5000 (87.0889)  Acc@5: 100.0000 (98.5729)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1590/3125]  eta: 0:09:02  Lr: 0.001875  Loss: -0.2782  Acc@1: 87.5000 (87.0993)  Acc@5: 100.0000 (98.5779)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1600/3125]  eta: 0:08:58  Lr: 0.001875  Loss: -0.8052  Acc@1: 87.5000 (87.0940)  Acc@5: 100.0000 (98.5790)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1610/3125]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7851  Acc@1: 87.5000 (87.1159)  Acc@5: 100.0000 (98.5878)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1620/3125]  eta: 0:08:51  Lr: 0.001875  Loss: -0.5929  Acc@1: 87.5000 (87.1106)  Acc@5: 100.0000 (98.5888)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1630/3125]  eta: 0:08:48  Lr: 0.001875  Loss: -0.7198  Acc@1: 93.7500 (87.1513)  Acc@5: 100.0000 (98.5975)  time: 0.3546  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1640/3125]  eta: 0:08:44  Lr: 0.001875  Loss: -0.3677  Acc@1: 93.7500 (87.1801)  Acc@5: 100.0000 (98.5946)  time: 0.3548  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1650/3125]  eta: 0:08:40  Lr: 0.001875  Loss: -0.9168  Acc@1: 87.5000 (87.1820)  Acc@5: 100.0000 (98.5955)  time: 0.3530  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1660/3125]  eta: 0:08:37  Lr: 0.001875  Loss: -0.6017  Acc@1: 87.5000 (87.1839)  Acc@5: 100.0000 (98.5927)  time: 0.3543  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [1670/3125]  eta: 0:08:33  Lr: 0.001875  Loss: -0.7302  Acc@1: 87.5000 (87.1821)  Acc@5: 100.0000 (98.5862)  time: 0.3540  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1680/3125]  eta: 0:08:30  Lr: 0.001875  Loss: -0.1923  Acc@1: 87.5000 (87.1617)  Acc@5: 100.0000 (98.5797)  time: 0.3530  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1690/3125]  eta: 0:08:26  Lr: 0.001875  Loss: -0.3767  Acc@1: 87.5000 (87.1637)  Acc@5: 100.0000 (98.5733)  time: 0.3537  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1700/3125]  eta: 0:08:23  Lr: 0.001875  Loss: -0.4240  Acc@1: 87.5000 (87.1583)  Acc@5: 100.0000 (98.5780)  time: 0.3556  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1710/3125]  eta: 0:08:19  Lr: 0.001875  Loss: -0.5350  Acc@1: 87.5000 (87.1786)  Acc@5: 100.0000 (98.5790)  time: 0.3605  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1720/3125]  eta: 0:08:16  Lr: 0.001875  Loss: 0.1405  Acc@1: 87.5000 (87.1877)  Acc@5: 100.0000 (98.5837)  time: 0.3626  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1730/3125]  eta: 0:08:12  Lr: 0.001875  Loss: -0.6907  Acc@1: 87.5000 (87.1606)  Acc@5: 100.0000 (98.5810)  time: 0.3586  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1740/3125]  eta: 0:08:09  Lr: 0.001875  Loss: -0.5760  Acc@1: 87.5000 (87.1733)  Acc@5: 100.0000 (98.5856)  time: 0.3581  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1750/3125]  eta: 0:08:06  Lr: 0.001875  Loss: -0.7249  Acc@1: 87.5000 (87.1645)  Acc@5: 100.0000 (98.5794)  time: 0.3646  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1760/3125]  eta: 0:08:02  Lr: 0.001875  Loss: -0.5802  Acc@1: 87.5000 (87.1699)  Acc@5: 100.0000 (98.5839)  time: 0.3637  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1770/3125]  eta: 0:07:59  Lr: 0.001875  Loss: -0.9311  Acc@1: 87.5000 (87.1542)  Acc@5: 100.0000 (98.5813)  time: 0.3557  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1780/3125]  eta: 0:07:55  Lr: 0.001875  Loss: -0.7420  Acc@1: 87.5000 (87.1701)  Acc@5: 100.0000 (98.5858)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1790/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.2318  Acc@1: 87.5000 (87.1615)  Acc@5: 100.0000 (98.5867)  time: 0.3528  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1800/3125]  eta: 0:07:48  Lr: 0.001875  Loss: -0.4891  Acc@1: 87.5000 (87.1426)  Acc@5: 100.0000 (98.5876)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1810/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.7923  Acc@1: 87.5000 (87.1514)  Acc@5: 100.0000 (98.5885)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1820/3125]  eta: 0:07:41  Lr: 0.001875  Loss: -0.4932  Acc@1: 87.5000 (87.1465)  Acc@5: 100.0000 (98.5894)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1830/3125]  eta: 0:07:37  Lr: 0.001875  Loss: -0.3326  Acc@1: 87.5000 (87.1518)  Acc@5: 100.0000 (98.5937)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1840/3125]  eta: 0:07:34  Lr: 0.001875  Loss: -0.6240  Acc@1: 93.7500 (87.1775)  Acc@5: 100.0000 (98.5945)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1850/3125]  eta: 0:07:30  Lr: 0.001875  Loss: -0.5615  Acc@1: 87.5000 (87.1792)  Acc@5: 100.0000 (98.5954)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1860/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.6593  Acc@1: 87.5000 (87.1675)  Acc@5: 100.0000 (98.5995)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1870/3125]  eta: 0:07:23  Lr: 0.001875  Loss: -0.2863  Acc@1: 87.5000 (87.1626)  Acc@5: 100.0000 (98.6003)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1880/3125]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6551  Acc@1: 87.5000 (87.1644)  Acc@5: 100.0000 (98.5945)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1890/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.6554  Acc@1: 81.2500 (87.1530)  Acc@5: 100.0000 (98.5887)  time: 0.3601  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:12  Lr: 0.001875  Loss: -0.8378  Acc@1: 87.5000 (87.1745)  Acc@5: 100.0000 (98.5896)  time: 0.3643  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1910/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.6883  Acc@1: 87.5000 (87.1533)  Acc@5: 100.0000 (98.5839)  time: 0.3570  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1920/3125]  eta: 0:07:05  Lr: 0.001875  Loss: -0.5324  Acc@1: 87.5000 (87.1519)  Acc@5: 100.0000 (98.5782)  time: 0.3536  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1930/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.3864  Acc@1: 87.5000 (87.1375)  Acc@5: 100.0000 (98.5759)  time: 0.3757  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1940/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.5975  Acc@1: 87.5000 (87.1587)  Acc@5: 100.0000 (98.5800)  time: 0.5790  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1950/3125]  eta: 0:07:00  Lr: 0.001875  Loss: -0.3468  Acc@1: 87.5000 (87.1476)  Acc@5: 100.0000 (98.5744)  time: 0.7574  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1960/3125]  eta: 0:06:59  Lr: 0.001875  Loss: -0.8255  Acc@1: 87.5000 (87.1430)  Acc@5: 100.0000 (98.5690)  time: 0.7548  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1970/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.3662  Acc@1: 81.2500 (87.1385)  Acc@5: 100.0000 (98.5635)  time: 0.7511  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1980/3125]  eta: 0:06:56  Lr: 0.001875  Loss: -0.6944  Acc@1: 87.5000 (87.1246)  Acc@5: 100.0000 (98.5708)  time: 0.7498  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1990/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.8588  Acc@1: 87.5000 (87.1296)  Acc@5: 100.0000 (98.5717)  time: 0.7512  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2000/3125]  eta: 0:06:53  Lr: 0.001875  Loss: -0.4337  Acc@1: 87.5000 (87.1346)  Acc@5: 100.0000 (98.5726)  time: 0.7502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2010/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.4323  Acc@1: 87.5000 (87.1488)  Acc@5: 100.0000 (98.5735)  time: 0.7411  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2020/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.8052  Acc@1: 87.5000 (87.1320)  Acc@5: 100.0000 (98.5805)  time: 0.5416  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2030/3125]  eta: 0:06:44  Lr: 0.001875  Loss: 0.3826  Acc@1: 87.5000 (87.1338)  Acc@5: 100.0000 (98.5721)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2040/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.8565  Acc@1: 87.5000 (87.1172)  Acc@5: 100.0000 (98.5730)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2050/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.0774  Acc@1: 87.5000 (87.1221)  Acc@5: 100.0000 (98.5739)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:32  Lr: 0.001875  Loss: -0.3928  Acc@1: 87.5000 (87.1240)  Acc@5: 100.0000 (98.5747)  time: 0.3512  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.5673  Acc@1: 87.5000 (87.1288)  Acc@5: 100.0000 (98.5786)  time: 0.3524  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2080/3125]  eta: 0:06:25  Lr: 0.001875  Loss: -0.4545  Acc@1: 87.5000 (87.1306)  Acc@5: 100.0000 (98.5794)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2090/3125]  eta: 0:06:21  Lr: 0.001875  Loss: -0.7997  Acc@1: 93.7500 (87.1443)  Acc@5: 100.0000 (98.5832)  time: 0.3529  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2100/3125]  eta: 0:06:17  Lr: 0.001875  Loss: -0.7686  Acc@1: 93.7500 (87.1430)  Acc@5: 100.0000 (98.5870)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2110/3125]  eta: 0:06:14  Lr: 0.001875  Loss: -0.3587  Acc@1: 87.5000 (87.1418)  Acc@5: 100.0000 (98.5907)  time: 0.3544  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2120/3125]  eta: 0:06:10  Lr: 0.001875  Loss: -0.6232  Acc@1: 87.5000 (87.1376)  Acc@5: 100.0000 (98.5944)  time: 0.3575  data: 0.0021  max mem: 2502
Train: Epoch[5/5]  [2130/3125]  eta: 0:06:06  Lr: 0.001875  Loss: -0.3988  Acc@1: 87.5000 (87.1246)  Acc@5: 100.0000 (98.5893)  time: 0.3569  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [2140/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.3447  Acc@1: 87.5000 (87.1439)  Acc@5: 100.0000 (98.5929)  time: 0.3531  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2150/3125]  eta: 0:05:59  Lr: 0.001875  Loss: -0.6358  Acc@1: 87.5000 (87.1513)  Acc@5: 100.0000 (98.5908)  time: 0.3517  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2160/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.4585  Acc@1: 87.5000 (87.1298)  Acc@5: 100.0000 (98.5886)  time: 0.3546  data: 0.0023  max mem: 2502
Train: Epoch[5/5]  [2170/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.7608  Acc@1: 81.2500 (87.1114)  Acc@5: 100.0000 (98.5865)  time: 0.3577  data: 0.0031  max mem: 2502
Train: Epoch[5/5]  [2180/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.3740  Acc@1: 81.2500 (87.1131)  Acc@5: 100.0000 (98.5872)  time: 0.3544  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [2190/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.4997  Acc@1: 87.5000 (87.1235)  Acc@5: 100.0000 (98.5908)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2200/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.8915  Acc@1: 87.5000 (87.1223)  Acc@5: 100.0000 (98.5887)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:36  Lr: 0.001875  Loss: -0.6713  Acc@1: 87.5000 (87.1269)  Acc@5: 100.0000 (98.5894)  time: 0.3534  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:32  Lr: 0.001875  Loss: -0.6694  Acc@1: 87.5000 (87.1314)  Acc@5: 100.0000 (98.5873)  time: 0.3528  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:29  Lr: 0.001875  Loss: -0.9212  Acc@1: 87.5000 (87.1358)  Acc@5: 100.0000 (98.5853)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:25  Lr: 0.001875  Loss: -0.8829  Acc@1: 87.5000 (87.1346)  Acc@5: 100.0000 (98.5860)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:21  Lr: 0.001875  Loss: -0.8990  Acc@1: 87.5000 (87.1585)  Acc@5: 100.0000 (98.5840)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2260/3125]  eta: 0:05:17  Lr: 0.001875  Loss: -0.7298  Acc@1: 93.7500 (87.1793)  Acc@5: 100.0000 (98.5902)  time: 0.3515  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2270/3125]  eta: 0:05:14  Lr: 0.001875  Loss: -0.3749  Acc@1: 87.5000 (87.1725)  Acc@5: 100.0000 (98.5909)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2280/3125]  eta: 0:05:10  Lr: 0.001875  Loss: 0.1622  Acc@1: 87.5000 (87.1602)  Acc@5: 100.0000 (98.5916)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2290/3125]  eta: 0:05:06  Lr: 0.001875  Loss: -0.4778  Acc@1: 87.5000 (87.1754)  Acc@5: 100.0000 (98.5950)  time: 0.3527  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2300/3125]  eta: 0:05:03  Lr: 0.001875  Loss: -0.6046  Acc@1: 93.7500 (87.1931)  Acc@5: 100.0000 (98.5930)  time: 0.3642  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2310/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.6577  Acc@1: 93.7500 (87.2106)  Acc@5: 100.0000 (98.5991)  time: 0.3624  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2320/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.7093  Acc@1: 87.5000 (87.2065)  Acc@5: 100.0000 (98.5997)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2330/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.7643  Acc@1: 87.5000 (87.1863)  Acc@5: 100.0000 (98.5897)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2340/3125]  eta: 0:04:49  Lr: 0.001875  Loss: -0.6743  Acc@1: 87.5000 (87.1983)  Acc@5: 100.0000 (98.5877)  time: 0.4784  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2350/3125]  eta: 0:04:46  Lr: 0.001875  Loss: -0.7285  Acc@1: 87.5000 (87.1943)  Acc@5: 100.0000 (98.5910)  time: 0.6780  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.5488  Acc@1: 87.5000 (87.2009)  Acc@5: 100.0000 (98.5943)  time: 0.7479  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.2094  Acc@1: 87.5000 (87.1995)  Acc@5: 100.0000 (98.5924)  time: 0.7443  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:39  Lr: 0.001875  Loss: -0.8058  Acc@1: 87.5000 (87.2034)  Acc@5: 100.0000 (98.5957)  time: 0.7483  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:36  Lr: 0.001875  Loss: -0.5008  Acc@1: 87.5000 (87.2046)  Acc@5: 100.0000 (98.5963)  time: 0.7524  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:33  Lr: 0.001875  Loss: -0.5752  Acc@1: 87.5000 (87.2006)  Acc@5: 100.0000 (98.5969)  time: 0.7497  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.5265  Acc@1: 87.5000 (87.1993)  Acc@5: 100.0000 (98.5898)  time: 0.7463  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:28  Lr: 0.001875  Loss: -0.6121  Acc@1: 81.2500 (87.2005)  Acc@5: 100.0000 (98.5905)  time: 0.7440  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2430/3125]  eta: 0:04:25  Lr: 0.001875  Loss: -0.7224  Acc@1: 81.2500 (87.1838)  Acc@5: 100.0000 (98.5911)  time: 0.7459  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2440/3125]  eta: 0:04:22  Lr: 0.001875  Loss: -0.6045  Acc@1: 87.5000 (87.1902)  Acc@5: 100.0000 (98.5943)  time: 0.7449  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [2450/3125]  eta: 0:04:19  Lr: 0.001875  Loss: -0.7262  Acc@1: 87.5000 (87.1940)  Acc@5: 100.0000 (98.5975)  time: 0.7402  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2460/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.6971  Acc@1: 87.5000 (87.1902)  Acc@5: 100.0000 (98.6032)  time: 0.7410  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2470/3125]  eta: 0:04:14  Lr: 0.001875  Loss: -0.3371  Acc@1: 87.5000 (87.1864)  Acc@5: 100.0000 (98.6089)  time: 0.7399  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2480/3125]  eta: 0:04:11  Lr: 0.001875  Loss: -0.3940  Acc@1: 81.2500 (87.1675)  Acc@5: 100.0000 (98.6069)  time: 0.7374  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2490/3125]  eta: 0:04:08  Lr: 0.001875  Loss: -0.4866  Acc@1: 81.2500 (87.1663)  Acc@5: 100.0000 (98.6050)  time: 0.7380  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2500/3125]  eta: 0:04:05  Lr: 0.001875  Loss: -0.9299  Acc@1: 87.5000 (87.1826)  Acc@5: 100.0000 (98.6081)  time: 0.7414  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2510/3125]  eta: 0:04:01  Lr: 0.001875  Loss: -0.5332  Acc@1: 87.5000 (87.1739)  Acc@5: 100.0000 (98.6086)  time: 0.7068  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:57  Lr: 0.001875  Loss: -0.8435  Acc@1: 87.5000 (87.1827)  Acc@5: 100.0000 (98.6042)  time: 0.5102  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:53  Lr: 0.001875  Loss: -0.5342  Acc@1: 93.7500 (87.1987)  Acc@5: 100.0000 (98.6097)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.6398  Acc@1: 93.7500 (87.2073)  Acc@5: 100.0000 (98.6128)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.8154  Acc@1: 87.5000 (87.2231)  Acc@5: 100.0000 (98.6108)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.7170  Acc@1: 87.5000 (87.2193)  Acc@5: 100.0000 (98.6065)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:37  Lr: 0.001875  Loss: -0.4676  Acc@1: 87.5000 (87.2277)  Acc@5: 100.0000 (98.6046)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:33  Lr: 0.001875  Loss: -0.6356  Acc@1: 87.5000 (87.2457)  Acc@5: 100.0000 (98.6052)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:29  Lr: 0.001875  Loss: -0.8747  Acc@1: 87.5000 (87.2443)  Acc@5: 100.0000 (98.6058)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:25  Lr: 0.001875  Loss: -0.5450  Acc@1: 81.2500 (87.2405)  Acc@5: 100.0000 (98.6111)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2610/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.3274  Acc@1: 87.5000 (87.2343)  Acc@5: 100.0000 (98.6140)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2620/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.6013  Acc@1: 87.5000 (87.2425)  Acc@5: 100.0000 (98.6193)  time: 0.3522  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2630/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.2976  Acc@1: 87.5000 (87.2387)  Acc@5: 100.0000 (98.6174)  time: 0.3527  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2640/3125]  eta: 0:03:09  Lr: 0.001875  Loss: -0.5722  Acc@1: 87.5000 (87.2326)  Acc@5: 100.0000 (98.6203)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2650/3125]  eta: 0:03:05  Lr: 0.001875  Loss: -0.5258  Acc@1: 87.5000 (87.2265)  Acc@5: 100.0000 (98.6184)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2660/3125]  eta: 0:03:01  Lr: 0.001875  Loss: -0.5833  Acc@1: 87.5000 (87.2346)  Acc@5: 100.0000 (98.6213)  time: 0.3550  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:57  Lr: 0.001875  Loss: -0.7594  Acc@1: 87.5000 (87.2309)  Acc@5: 100.0000 (98.6194)  time: 0.3581  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.5625  Acc@1: 81.2500 (87.2226)  Acc@5: 100.0000 (98.6199)  time: 0.3547  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.5474  Acc@1: 81.2500 (87.2166)  Acc@5: 100.0000 (98.6227)  time: 0.3510  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.6366  Acc@1: 87.5000 (87.2200)  Acc@5: 100.0000 (98.6186)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:41  Lr: 0.001875  Loss: -0.4375  Acc@1: 87.5000 (87.2187)  Acc@5: 100.0000 (98.6167)  time: 0.3570  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.5545  Acc@1: 93.7500 (87.2290)  Acc@5: 100.0000 (98.6172)  time: 0.3584  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:34  Lr: 0.001875  Loss: -0.8074  Acc@1: 93.7500 (87.2345)  Acc@5: 100.0000 (98.6154)  time: 0.3543  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4567  Acc@1: 87.5000 (87.2401)  Acc@5: 100.0000 (98.6182)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:26  Lr: 0.001875  Loss: -0.3369  Acc@1: 87.5000 (87.2319)  Acc@5: 100.0000 (98.6164)  time: 0.3504  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:22  Lr: 0.001875  Loss: -0.5218  Acc@1: 87.5000 (87.2352)  Acc@5: 100.0000 (98.6169)  time: 0.3523  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.6578  Acc@1: 87.5000 (87.2474)  Acc@5: 100.0000 (98.6196)  time: 0.3519  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2780/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5003  Acc@1: 87.5000 (87.2550)  Acc@5: 100.0000 (98.6156)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2790/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.5714  Acc@1: 87.5000 (87.2671)  Acc@5: 100.0000 (98.6116)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2800/3125]  eta: 0:02:06  Lr: 0.001875  Loss: -0.9186  Acc@1: 87.5000 (87.2836)  Acc@5: 100.0000 (98.6143)  time: 0.3514  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2810/3125]  eta: 0:02:02  Lr: 0.001875  Loss: -0.6438  Acc@1: 93.7500 (87.2888)  Acc@5: 100.0000 (98.6148)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6644  Acc@1: 93.7500 (87.3028)  Acc@5: 100.0000 (98.6153)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:54  Lr: 0.001875  Loss: -0.5945  Acc@1: 93.7500 (87.3057)  Acc@5: 100.0000 (98.6091)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7153  Acc@1: 87.5000 (87.3086)  Acc@5: 100.0000 (98.6096)  time: 0.3509  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.8010  Acc@1: 87.5000 (87.3049)  Acc@5: 100.0000 (98.6123)  time: 0.3556  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:42  Lr: 0.001875  Loss: -0.4970  Acc@1: 87.5000 (87.3034)  Acc@5: 100.0000 (98.6106)  time: 0.3628  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6880  Acc@1: 87.5000 (87.3150)  Acc@5: 100.0000 (98.6068)  time: 0.3593  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:35  Lr: 0.001875  Loss: -0.6332  Acc@1: 87.5000 (87.3048)  Acc@5: 100.0000 (98.6029)  time: 0.3568  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:31  Lr: 0.001875  Loss: -0.2957  Acc@1: 87.5000 (87.2968)  Acc@5: 100.0000 (98.5991)  time: 0.5287  data: 0.0032  max mem: 2502
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:27  Lr: 0.001875  Loss: -0.5245  Acc@1: 87.5000 (87.2996)  Acc@5: 100.0000 (98.6039)  time: 0.7291  data: 0.0031  max mem: 2502
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7018  Acc@1: 87.5000 (87.3003)  Acc@5: 100.0000 (98.6023)  time: 0.7563  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8966  Acc@1: 87.5000 (87.2925)  Acc@5: 100.0000 (98.5985)  time: 0.7517  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:16  Lr: 0.001875  Loss: -0.8085  Acc@1: 81.2500 (87.2825)  Acc@5: 100.0000 (98.5990)  time: 0.6528  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:12  Lr: 0.001875  Loss: -0.2425  Acc@1: 81.2500 (87.2747)  Acc@5: 100.0000 (98.6038)  time: 0.4550  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.2497  Acc@1: 87.5000 (87.2776)  Acc@5: 100.0000 (98.5958)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2960/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6143  Acc@1: 87.5000 (87.2784)  Acc@5: 100.0000 (98.5921)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2970/3125]  eta: 0:01:00  Lr: 0.001875  Loss: -0.3693  Acc@1: 87.5000 (87.2791)  Acc@5: 100.0000 (98.5926)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:56  Lr: 0.001875  Loss: -0.6968  Acc@1: 87.5000 (87.2757)  Acc@5: 100.0000 (98.5974)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:53  Lr: 0.001875  Loss: -0.4333  Acc@1: 87.5000 (87.2681)  Acc@5: 100.0000 (98.5958)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:49  Lr: 0.001875  Loss: -0.5776  Acc@1: 87.5000 (87.2605)  Acc@5: 100.0000 (98.5921)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4021  Acc@1: 87.5000 (87.2675)  Acc@5: 100.0000 (98.5947)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7416  Acc@1: 93.7500 (87.2807)  Acc@5: 100.0000 (98.5932)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6669  Acc@1: 87.5000 (87.2711)  Acc@5: 100.0000 (98.5958)  time: 0.3516  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6122  Acc@1: 87.5000 (87.2678)  Acc@5: 100.0000 (98.5942)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.6069  Acc@1: 87.5000 (87.2685)  Acc@5: 100.0000 (98.5947)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:25  Lr: 0.001875  Loss: -0.7937  Acc@1: 87.5000 (87.2713)  Acc@5: 100.0000 (98.5932)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:21  Lr: 0.001875  Loss: -0.5475  Acc@1: 87.5000 (87.2721)  Acc@5: 100.0000 (98.5978)  time: 0.3521  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8473  Acc@1: 87.5000 (87.2687)  Acc@5: 100.0000 (98.5962)  time: 0.3534  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:13  Lr: 0.001875  Loss: -0.6968  Acc@1: 87.5000 (87.2654)  Acc@5: 100.0000 (98.5988)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:09  Lr: 0.001875  Loss: -0.4466  Acc@1: 87.5000 (87.2541)  Acc@5: 100.0000 (98.5992)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.6144  Acc@1: 87.5000 (87.2569)  Acc@5: 100.0000 (98.5977)  time: 0.3530  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.7363  Acc@1: 87.5000 (87.2597)  Acc@5: 100.0000 (98.5982)  time: 0.3550  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5391  Acc@1: 87.5000 (87.2620)  Acc@5: 100.0000 (98.6000)  time: 0.3562  data: 0.0018  max mem: 2502
Train: Epoch[5/5] Total time: 0:20:22 (0.3912 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.5391  Acc@1: 87.5000 (87.2620)  Acc@5: 100.0000 (98.6000)
Test: [Task 1]  [   0/1627]  eta: 0:21:14  Loss: 1.5068 (1.5068)  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7832  data: 0.5651  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:07:17  Loss: 1.1913 (1.1742)  Acc@1: 68.7500 (65.9091)  Acc@5: 93.7500 (94.8864)  time: 0.2705  data: 0.0521  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:47  Loss: 1.1170 (1.1376)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.0476)  time: 0.2273  data: 0.0007  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:29  Loss: 1.1321 (1.1351)  Acc@1: 68.7500 (69.7581)  Acc@5: 93.7500 (94.1532)  time: 0.2292  data: 0.0020  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:06:17  Loss: 1.1719 (1.1429)  Acc@1: 68.7500 (69.5122)  Acc@5: 93.7500 (94.2073)  time: 0.2209  data: 0.0026  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:06:11  Loss: 0.9632 (1.1239)  Acc@1: 68.7500 (70.2206)  Acc@5: 93.7500 (94.3627)  time: 0.2226  data: 0.0044  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:06:05  Loss: 1.0730 (1.1371)  Acc@1: 68.7500 (69.9795)  Acc@5: 93.7500 (93.9549)  time: 0.2240  data: 0.0046  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:59  Loss: 1.0205 (1.1344)  Acc@1: 68.7500 (69.8063)  Acc@5: 93.7500 (94.3662)  time: 0.2193  data: 0.0014  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:56  Loss: 0.9653 (1.1172)  Acc@1: 75.0000 (70.2160)  Acc@5: 93.7500 (94.4444)  time: 0.2225  data: 0.0008  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:06:21  Loss: 1.0102 (1.1349)  Acc@1: 75.0000 (69.8489)  Acc@5: 93.7500 (94.1621)  time: 0.3102  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:06:53  Loss: 1.3821 (1.1620)  Acc@1: 62.5000 (69.1832)  Acc@5: 93.7500 (93.6262)  time: 0.4346  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:07:18  Loss: 1.1459 (1.1604)  Acc@1: 62.5000 (68.5811)  Acc@5: 100.0000 (94.0878)  time: 0.4743  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:07:38  Loss: 1.1259 (1.1569)  Acc@1: 68.7500 (69.1116)  Acc@5: 100.0000 (94.0599)  time: 0.4715  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:07:54  Loss: 1.1976 (1.1637)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.0363)  time: 0.4697  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:08:07  Loss: 1.1141 (1.1627)  Acc@1: 62.5000 (68.5284)  Acc@5: 93.7500 (94.0160)  time: 0.4694  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:08:17  Loss: 0.8633 (1.1475)  Acc@1: 75.0000 (69.0397)  Acc@5: 93.7500 (94.0811)  time: 0.4707  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:08:26  Loss: 0.8456 (1.1398)  Acc@1: 75.0000 (69.4099)  Acc@5: 93.7500 (94.1770)  time: 0.4701  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:08:33  Loss: 1.0470 (1.1360)  Acc@1: 68.7500 (69.4079)  Acc@5: 93.7500 (94.1155)  time: 0.4690  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:08:39  Loss: 1.1265 (1.1411)  Acc@1: 68.7500 (69.1298)  Acc@5: 93.7500 (94.0953)  time: 0.4678  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:08:28  Loss: 1.1265 (1.1374)  Acc@1: 68.7500 (69.2081)  Acc@5: 93.7500 (94.0772)  time: 0.3655  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:08:15  Loss: 1.1270 (1.1352)  Acc@1: 68.7500 (69.3097)  Acc@5: 93.7500 (94.1542)  time: 0.2405  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:08:03  Loss: 1.0690 (1.1343)  Acc@1: 68.7500 (69.5498)  Acc@5: 93.7500 (94.1943)  time: 0.2196  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:07:52  Loss: 1.0621 (1.1372)  Acc@1: 75.0000 (69.5419)  Acc@5: 93.7500 (94.2308)  time: 0.2207  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:07:41  Loss: 1.0621 (1.1318)  Acc@1: 75.0000 (69.8323)  Acc@5: 93.7500 (94.2370)  time: 0.2184  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:07:31  Loss: 1.0451 (1.1271)  Acc@1: 75.0000 (69.9689)  Acc@5: 93.7500 (94.2168)  time: 0.2176  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:07:22  Loss: 0.9773 (1.1295)  Acc@1: 75.0000 (70.0697)  Acc@5: 93.7500 (94.1235)  time: 0.2183  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:07:14  Loss: 1.0768 (1.1301)  Acc@1: 68.7500 (70.0192)  Acc@5: 93.7500 (94.1331)  time: 0.2193  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:07:06  Loss: 1.0450 (1.1240)  Acc@1: 68.7500 (70.0185)  Acc@5: 93.7500 (94.2343)  time: 0.2191  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:06:58  Loss: 0.9936 (1.1241)  Acc@1: 68.7500 (69.9733)  Acc@5: 93.7500 (94.1059)  time: 0.2193  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:06:51  Loss: 1.1065 (1.1236)  Acc@1: 68.7500 (70.0387)  Acc@5: 93.7500 (94.1151)  time: 0.2219  data: 0.0029  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:06:44  Loss: 1.0984 (1.1239)  Acc@1: 68.7500 (70.0789)  Acc@5: 93.7500 (94.1030)  time: 0.2230  data: 0.0036  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:06:38  Loss: 0.9962 (1.1258)  Acc@1: 68.7500 (69.9558)  Acc@5: 93.7500 (94.1519)  time: 0.2234  data: 0.0035  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:06:31  Loss: 1.1012 (1.1258)  Acc@1: 68.7500 (69.7819)  Acc@5: 93.7500 (94.1589)  time: 0.2216  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:06:25  Loss: 1.0316 (1.1234)  Acc@1: 68.7500 (69.8452)  Acc@5: 93.7500 (94.1843)  time: 0.2195  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:06:19  Loss: 0.9634 (1.1236)  Acc@1: 68.7500 (69.8497)  Acc@5: 93.7500 (94.1899)  time: 0.2203  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:06:14  Loss: 1.0240 (1.1252)  Acc@1: 75.0000 (69.9252)  Acc@5: 93.7500 (94.0883)  time: 0.2256  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:06:09  Loss: 1.0240 (1.1232)  Acc@1: 75.0000 (69.9273)  Acc@5: 93.7500 (94.0963)  time: 0.2314  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:06:03  Loss: 1.0119 (1.1221)  Acc@1: 68.7500 (69.8619)  Acc@5: 93.7500 (94.1038)  time: 0.2268  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:05:58  Loss: 1.0123 (1.1210)  Acc@1: 68.7500 (69.9475)  Acc@5: 93.7500 (94.0289)  time: 0.2199  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:05:53  Loss: 1.0289 (1.1220)  Acc@1: 75.0000 (69.9648)  Acc@5: 93.7500 (93.9898)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:05:48  Loss: 0.9964 (1.1226)  Acc@1: 68.7500 (69.8878)  Acc@5: 93.7500 (93.9994)  time: 0.2208  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:05:45  Loss: 0.9875 (1.1222)  Acc@1: 68.7500 (69.9818)  Acc@5: 93.7500 (93.9781)  time: 0.2517  data: 0.0028  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:05:48  Loss: 1.0276 (1.1213)  Acc@1: 75.0000 (69.9822)  Acc@5: 100.0000 (94.0618)  time: 0.3762  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:05:50  Loss: 1.0276 (1.1196)  Acc@1: 68.7500 (69.9681)  Acc@5: 100.0000 (94.1415)  time: 0.4714  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:05:52  Loss: 1.1564 (1.1200)  Acc@1: 68.7500 (69.9263)  Acc@5: 100.0000 (94.1752)  time: 0.4717  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:05:54  Loss: 1.1972 (1.1235)  Acc@1: 62.5000 (69.6785)  Acc@5: 93.7500 (94.0549)  time: 0.4720  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:05:55  Loss: 1.1896 (1.1235)  Acc@1: 56.2500 (69.7126)  Acc@5: 93.7500 (94.0889)  time: 0.4683  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:05:56  Loss: 1.0444 (1.1216)  Acc@1: 68.7500 (69.7320)  Acc@5: 93.7500 (94.0817)  time: 0.4678  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:05:57  Loss: 1.1357 (1.1255)  Acc@1: 68.7500 (69.6206)  Acc@5: 93.7500 (94.0489)  time: 0.4708  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:05:57  Loss: 1.1596 (1.1255)  Acc@1: 68.7500 (69.6029)  Acc@5: 93.7500 (94.0682)  time: 0.4669  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:05:57  Loss: 1.1029 (1.1267)  Acc@1: 68.7500 (69.5858)  Acc@5: 93.7500 (94.0494)  time: 0.4657  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:05:57  Loss: 1.2063 (1.1330)  Acc@1: 62.5000 (69.3860)  Acc@5: 93.7500 (94.0435)  time: 0.4681  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:05:57  Loss: 1.2894 (1.1398)  Acc@1: 62.5000 (69.3378)  Acc@5: 93.7500 (93.9779)  time: 0.4668  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:05:57  Loss: 1.1166 (1.1364)  Acc@1: 68.7500 (69.4444)  Acc@5: 93.7500 (94.0089)  time: 0.4669  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:05:57  Loss: 1.0285 (1.1370)  Acc@1: 68.7500 (69.4663)  Acc@5: 93.7500 (93.9695)  time: 0.4701  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:05:56  Loss: 1.2567 (1.1396)  Acc@1: 68.7500 (69.4306)  Acc@5: 93.7500 (93.9655)  time: 0.4693  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:05:55  Loss: 1.2767 (1.1418)  Acc@1: 68.7500 (69.3405)  Acc@5: 93.7500 (93.9617)  time: 0.4670  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:05:55  Loss: 1.1177 (1.1389)  Acc@1: 68.7500 (69.3958)  Acc@5: 93.7500 (93.9799)  time: 0.4670  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:05:54  Loss: 1.0797 (1.1393)  Acc@1: 75.0000 (69.3954)  Acc@5: 93.7500 (94.0189)  time: 0.4671  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:05:52  Loss: 1.1361 (1.1388)  Acc@1: 68.7500 (69.3951)  Acc@5: 100.0000 (94.0673)  time: 0.4667  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:05:51  Loss: 1.1590 (1.1406)  Acc@1: 68.7500 (69.3844)  Acc@5: 93.7500 (94.0308)  time: 0.4687  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:05:50  Loss: 1.1074 (1.1388)  Acc@1: 75.0000 (69.4558)  Acc@5: 93.7500 (94.0466)  time: 0.4662  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:05:48  Loss: 1.0436 (1.1405)  Acc@1: 68.7500 (69.4042)  Acc@5: 93.7500 (94.0117)  time: 0.4636  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:05:47  Loss: 1.0216 (1.1402)  Acc@1: 68.7500 (69.4929)  Acc@5: 93.7500 (94.0174)  time: 0.4694  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:05:45  Loss: 1.0142 (1.1397)  Acc@1: 75.0000 (69.5398)  Acc@5: 93.7500 (94.0035)  time: 0.4691  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:05:43  Loss: 1.0142 (1.1388)  Acc@1: 75.0000 (69.5853)  Acc@5: 93.7500 (94.0284)  time: 0.4644  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:05:42  Loss: 1.0352 (1.1373)  Acc@1: 75.0000 (69.6199)  Acc@5: 93.7500 (94.0148)  time: 0.4663  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:05:40  Loss: 1.1428 (1.1370)  Acc@1: 75.0000 (69.6069)  Acc@5: 93.7500 (94.0201)  time: 0.4709  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:05:38  Loss: 1.1428 (1.1364)  Acc@1: 75.0000 (69.6311)  Acc@5: 93.7500 (94.0070)  time: 0.4688  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:05:36  Loss: 1.1019 (1.1344)  Acc@1: 75.0000 (69.6816)  Acc@5: 93.7500 (94.0575)  time: 0.4668  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:05:33  Loss: 1.1049 (1.1338)  Acc@1: 75.0000 (69.7575)  Acc@5: 100.0000 (94.0799)  time: 0.4653  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:05:31  Loss: 0.9886 (1.1314)  Acc@1: 75.0000 (69.8400)  Acc@5: 93.7500 (94.1192)  time: 0.4634  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:05:29  Loss: 0.9016 (1.1304)  Acc@1: 75.0000 (69.8162)  Acc@5: 93.7500 (94.1227)  time: 0.4623  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:05:26  Loss: 1.0949 (1.1309)  Acc@1: 68.7500 (69.7931)  Acc@5: 93.7500 (94.1176)  time: 0.4611  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:05:24  Loss: 1.1339 (1.1317)  Acc@1: 68.7500 (69.7790)  Acc@5: 93.7500 (94.1127)  time: 0.4658  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:05:22  Loss: 1.1339 (1.1307)  Acc@1: 68.7500 (69.8818)  Acc@5: 93.7500 (94.1328)  time: 0.4695  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:05:19  Loss: 1.1462 (1.1336)  Acc@1: 68.7500 (69.8177)  Acc@5: 93.7500 (94.0867)  time: 0.4637  data: 0.0020  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:05:16  Loss: 0.9747 (1.1302)  Acc@1: 75.0000 (69.9497)  Acc@5: 93.7500 (94.1148)  time: 0.4645  data: 0.0020  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:05:14  Loss: 0.9074 (1.1286)  Acc@1: 75.0000 (70.0144)  Acc@5: 93.7500 (94.1181)  time: 0.4704  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:05:11  Loss: 0.9778 (1.1305)  Acc@1: 68.7500 (70.0221)  Acc@5: 93.7500 (94.0661)  time: 0.4666  data: 0.0021  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:05:08  Loss: 1.0422 (1.1291)  Acc@1: 68.7500 (70.0375)  Acc@5: 93.7500 (94.1011)  time: 0.4640  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:05:05  Loss: 0.9961 (1.1284)  Acc@1: 75.0000 (70.0832)  Acc@5: 100.0000 (94.1122)  time: 0.4640  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:05:03  Loss: 0.9728 (1.1275)  Acc@1: 75.0000 (70.1127)  Acc@5: 100.0000 (94.1306)  time: 0.4627  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:05:00  Loss: 0.9633 (1.1267)  Acc@1: 68.7500 (70.0963)  Acc@5: 100.0000 (94.1411)  time: 0.4619  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:04:57  Loss: 0.9102 (1.1241)  Acc@1: 75.0000 (70.1620)  Acc@5: 93.7500 (94.1810)  time: 0.4614  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:04:54  Loss: 1.1385 (1.1253)  Acc@1: 68.7500 (70.1014)  Acc@5: 100.0000 (94.1686)  time: 0.4613  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:04:51  Loss: 1.0886 (1.1243)  Acc@1: 62.5000 (70.1002)  Acc@5: 100.0000 (94.1855)  time: 0.4595  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:04:47  Loss: 1.0207 (1.1232)  Acc@1: 68.7500 (70.1134)  Acc@5: 93.7500 (94.1877)  time: 0.4590  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:04:44  Loss: 1.1198 (1.1254)  Acc@1: 68.7500 (70.0411)  Acc@5: 93.7500 (94.2040)  time: 0.4524  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:04:41  Loss: 1.2034 (1.1278)  Acc@1: 62.5000 (69.9916)  Acc@5: 93.7500 (94.1849)  time: 0.4216  data: 0.0034  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:04:37  Loss: 1.1875 (1.1278)  Acc@1: 62.5000 (69.9847)  Acc@5: 93.7500 (94.1940)  time: 0.4305  data: 0.0020  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:04:34  Loss: 1.1941 (1.1291)  Acc@1: 68.7500 (69.9986)  Acc@5: 93.7500 (94.1342)  time: 0.4581  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:04:31  Loss: 1.1441 (1.1291)  Acc@1: 68.7500 (69.9851)  Acc@5: 93.7500 (94.1640)  time: 0.4592  data: 0.0018  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:04:28  Loss: 1.0312 (1.1300)  Acc@1: 68.7500 (69.9919)  Acc@5: 93.7500 (94.1327)  time: 0.4649  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:04:24  Loss: 1.0324 (1.1283)  Acc@1: 68.7500 (70.0452)  Acc@5: 93.7500 (94.1618)  time: 0.4599  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:04:21  Loss: 1.1367 (1.1295)  Acc@1: 62.5000 (69.9724)  Acc@5: 100.0000 (94.1640)  time: 0.4227  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:04:16  Loss: 1.1315 (1.1290)  Acc@1: 62.5000 (69.9792)  Acc@5: 93.7500 (94.1597)  time: 0.3061  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:04:11  Loss: 0.9897 (1.1280)  Acc@1: 68.7500 (69.9987)  Acc@5: 93.7500 (94.1555)  time: 0.2206  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:04:06  Loss: 1.0624 (1.1281)  Acc@1: 68.7500 (69.9796)  Acc@5: 93.7500 (94.1705)  time: 0.2200  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:04:02  Loss: 1.1791 (1.1309)  Acc@1: 68.7500 (69.9483)  Acc@5: 93.7500 (94.1473)  time: 0.2810  data: 0.0006  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:03:58  Loss: 1.1862 (1.1313)  Acc@1: 68.7500 (69.9426)  Acc@5: 93.7500 (94.1246)  time: 0.4007  data: 0.0012  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:03:55  Loss: 1.1106 (1.1308)  Acc@1: 68.7500 (69.9617)  Acc@5: 93.7500 (94.1209)  time: 0.4556  data: 0.0020  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:03:52  Loss: 1.0657 (1.1303)  Acc@1: 75.0000 (69.9620)  Acc@5: 93.7500 (94.1418)  time: 0.4542  data: 0.0012  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:03:48  Loss: 0.9677 (1.1285)  Acc@1: 75.0000 (70.0170)  Acc@5: 93.7500 (94.1622)  time: 0.4581  data: 0.0004  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:03:45  Loss: 0.8227 (1.1267)  Acc@1: 75.0000 (70.0708)  Acc@5: 100.0000 (94.1883)  time: 0.4580  data: 0.0004  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:03:41  Loss: 0.9362 (1.1253)  Acc@1: 75.0000 (70.1296)  Acc@5: 100.0000 (94.2020)  time: 0.4579  data: 0.0011  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:03:38  Loss: 1.1417 (1.1258)  Acc@1: 68.7500 (70.1343)  Acc@5: 93.7500 (94.1741)  time: 0.4584  data: 0.0011  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:03:34  Loss: 1.1947 (1.1263)  Acc@1: 68.7500 (70.1214)  Acc@5: 93.7500 (94.1643)  time: 0.4588  data: 0.0005  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:03:31  Loss: 1.1267 (1.1271)  Acc@1: 68.7500 (70.1376)  Acc@5: 93.7500 (94.1721)  time: 0.4603  data: 0.0008  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:03:27  Loss: 1.1267 (1.1271)  Acc@1: 68.7500 (70.1593)  Acc@5: 93.7500 (94.1739)  time: 0.4570  data: 0.0008  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:03:24  Loss: 0.9913 (1.1252)  Acc@1: 75.0000 (70.2089)  Acc@5: 100.0000 (94.1985)  time: 0.4560  data: 0.0015  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:03:20  Loss: 0.9750 (1.1254)  Acc@1: 75.0000 (70.1958)  Acc@5: 100.0000 (94.2113)  time: 0.4574  data: 0.0018  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:03:17  Loss: 1.1563 (1.1270)  Acc@1: 62.5000 (70.1383)  Acc@5: 93.7500 (94.2072)  time: 0.4572  data: 0.0008  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:03:13  Loss: 1.0821 (1.1275)  Acc@1: 62.5000 (70.1205)  Acc@5: 93.7500 (94.2031)  time: 0.4645  data: 0.0017  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:03:10  Loss: 1.0996 (1.1285)  Acc@1: 68.7500 (70.0865)  Acc@5: 93.7500 (94.1718)  time: 0.4638  data: 0.0016  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:03:06  Loss: 1.2571 (1.1290)  Acc@1: 68.7500 (70.0695)  Acc@5: 93.7500 (94.1790)  time: 0.4552  data: 0.0005  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:03:02  Loss: 1.1228 (1.1279)  Acc@1: 68.7500 (70.1281)  Acc@5: 93.7500 (94.1807)  time: 0.4580  data: 0.0006  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:02:59  Loss: 1.0131 (1.1269)  Acc@1: 75.0000 (70.1537)  Acc@5: 93.7500 (94.1983)  time: 0.4611  data: 0.0008  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:02:55  Loss: 1.1119 (1.1275)  Acc@1: 75.0000 (70.1683)  Acc@5: 93.7500 (94.2157)  time: 0.4552  data: 0.0010  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:02:51  Loss: 1.1694 (1.1282)  Acc@1: 68.7500 (70.1249)  Acc@5: 93.7500 (94.2118)  time: 0.4549  data: 0.0008  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:02:48  Loss: 1.1694 (1.1282)  Acc@1: 68.7500 (70.1291)  Acc@5: 93.7500 (94.2236)  time: 0.4546  data: 0.0012  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:02:44  Loss: 0.9977 (1.1289)  Acc@1: 68.7500 (70.0712)  Acc@5: 93.7500 (94.2042)  time: 0.4496  data: 0.0017  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:02:40  Loss: 0.9447 (1.1278)  Acc@1: 68.7500 (70.0962)  Acc@5: 93.7500 (94.2158)  time: 0.4525  data: 0.0010  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:02:36  Loss: 1.0713 (1.1282)  Acc@1: 68.7500 (70.0853)  Acc@5: 93.7500 (94.2120)  time: 0.3813  data: 0.0005  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:02:31  Loss: 1.1590 (1.1282)  Acc@1: 68.7500 (70.0645)  Acc@5: 93.7500 (94.2234)  time: 0.2626  data: 0.0005  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:02:27  Loss: 1.2539 (1.1286)  Acc@1: 68.7500 (70.0540)  Acc@5: 93.7500 (94.2096)  time: 0.2192  data: 0.0008  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:02:23  Loss: 1.1473 (1.1285)  Acc@1: 68.7500 (70.0535)  Acc@5: 93.7500 (94.2159)  time: 0.2203  data: 0.0010  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:02:18  Loss: 1.0460 (1.1293)  Acc@1: 62.5000 (70.0285)  Acc@5: 93.7500 (94.1975)  time: 0.2197  data: 0.0007  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:02:14  Loss: 1.0229 (1.1278)  Acc@1: 68.7500 (70.0527)  Acc@5: 93.7500 (94.1989)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:02:10  Loss: 1.0445 (1.1280)  Acc@1: 68.7500 (70.0232)  Acc@5: 93.7500 (94.2051)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:02:05  Loss: 1.0445 (1.1274)  Acc@1: 75.0000 (70.0471)  Acc@5: 93.7500 (94.2160)  time: 0.2165  data: 0.0003  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:02:01  Loss: 0.9362 (1.1262)  Acc@1: 75.0000 (70.0992)  Acc@5: 93.7500 (94.2267)  time: 0.2177  data: 0.0007  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:57  Loss: 0.8374 (1.1247)  Acc@1: 75.0000 (70.1694)  Acc@5: 100.0000 (94.2468)  time: 0.2196  data: 0.0010  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:53  Loss: 0.9033 (1.1244)  Acc@1: 75.0000 (70.1822)  Acc@5: 93.7500 (94.2290)  time: 0.2192  data: 0.0007  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:48  Loss: 1.0528 (1.1248)  Acc@1: 68.7500 (70.1808)  Acc@5: 93.7500 (94.2254)  time: 0.2237  data: 0.0004  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:44  Loss: 0.9663 (1.1240)  Acc@1: 75.0000 (70.2026)  Acc@5: 93.7500 (94.2358)  time: 0.2278  data: 0.0004  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:01:40  Loss: 0.9718 (1.1234)  Acc@1: 75.0000 (70.1920)  Acc@5: 93.7500 (94.2506)  time: 0.2218  data: 0.0004  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:01:36  Loss: 0.9829 (1.1227)  Acc@1: 68.7500 (70.1632)  Acc@5: 100.0000 (94.2651)  time: 0.2185  data: 0.0009  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:01:32  Loss: 1.0353 (1.1230)  Acc@1: 62.5000 (70.1394)  Acc@5: 93.7500 (94.2569)  time: 0.2213  data: 0.0020  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:01:28  Loss: 1.1597 (1.1226)  Acc@1: 68.7500 (70.1474)  Acc@5: 93.7500 (94.2757)  time: 0.2213  data: 0.0016  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:01:24  Loss: 1.0840 (1.1227)  Acc@1: 68.7500 (70.1597)  Acc@5: 93.7500 (94.2496)  time: 0.2384  data: 0.0013  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:01:21  Loss: 0.9193 (1.1220)  Acc@1: 81.2500 (70.1984)  Acc@5: 93.7500 (94.2594)  time: 0.3641  data: 0.0012  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:01:17  Loss: 0.9963 (1.1214)  Acc@1: 75.0000 (70.2102)  Acc@5: 100.0000 (94.2866)  time: 0.4700  data: 0.0005  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:01:13  Loss: 1.2356 (1.1232)  Acc@1: 68.7500 (70.1957)  Acc@5: 93.7500 (94.2610)  time: 0.4695  data: 0.0006  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:01:10  Loss: 1.1300 (1.1227)  Acc@1: 68.7500 (70.1943)  Acc@5: 93.7500 (94.2618)  time: 0.4710  data: 0.0007  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:01:06  Loss: 1.1592 (1.1241)  Acc@1: 68.7500 (70.1413)  Acc@5: 93.7500 (94.2540)  time: 0.4693  data: 0.0006  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:01:02  Loss: 1.2401 (1.1245)  Acc@1: 68.7500 (70.1189)  Acc@5: 93.7500 (94.2548)  time: 0.4682  data: 0.0005  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:59  Loss: 1.1867 (1.1249)  Acc@1: 68.7500 (70.1054)  Acc@5: 93.7500 (94.2386)  time: 0.4677  data: 0.0017  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:55  Loss: 1.1905 (1.1254)  Acc@1: 68.7500 (70.0962)  Acc@5: 93.7500 (94.2311)  time: 0.4653  data: 0.0017  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:51  Loss: 1.1359 (1.1257)  Acc@1: 68.7500 (70.0830)  Acc@5: 93.7500 (94.2237)  time: 0.4666  data: 0.0005  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:48  Loss: 1.0754 (1.1258)  Acc@1: 68.7500 (70.1033)  Acc@5: 93.7500 (94.2080)  time: 0.4702  data: 0.0004  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:44  Loss: 0.9079 (1.1257)  Acc@1: 68.7500 (70.1150)  Acc@5: 93.7500 (94.2009)  time: 0.4699  data: 0.0004  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:40  Loss: 0.9429 (1.1244)  Acc@1: 68.7500 (70.1471)  Acc@5: 93.7500 (94.2184)  time: 0.4688  data: 0.0012  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:36  Loss: 0.9516 (1.1240)  Acc@1: 68.7500 (70.1217)  Acc@5: 100.0000 (94.2317)  time: 0.4699  data: 0.0013  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:33  Loss: 0.9291 (1.1232)  Acc@1: 68.7500 (70.1411)  Acc@5: 100.0000 (94.2529)  time: 0.4689  data: 0.0009  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:29  Loss: 0.9430 (1.1229)  Acc@1: 75.0000 (70.1322)  Acc@5: 100.0000 (94.2577)  time: 0.4663  data: 0.0008  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:25  Loss: 0.9430 (1.1218)  Acc@1: 75.0000 (70.1634)  Acc@5: 100.0000 (94.2705)  time: 0.4659  data: 0.0011  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:21  Loss: 0.9870 (1.1215)  Acc@1: 75.0000 (70.1902)  Acc@5: 100.0000 (94.2791)  time: 0.4662  data: 0.0013  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:18  Loss: 1.0168 (1.1218)  Acc@1: 75.0000 (70.1850)  Acc@5: 93.7500 (94.2758)  time: 0.4662  data: 0.0015  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:14  Loss: 1.0157 (1.1216)  Acc@1: 68.7500 (70.1838)  Acc@5: 93.7500 (94.2921)  time: 0.4684  data: 0.0015  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:10  Loss: 1.1226 (1.1226)  Acc@1: 68.7500 (70.1280)  Acc@5: 100.0000 (94.2809)  time: 0.4613  data: 0.0008  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:06  Loss: 1.1881 (1.1219)  Acc@1: 68.7500 (70.1350)  Acc@5: 93.7500 (94.2854)  time: 0.4580  data: 0.0005  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:02  Loss: 0.9272 (1.1209)  Acc@1: 75.0000 (70.1650)  Acc@5: 93.7500 (94.2975)  time: 0.4670  data: 0.0012  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9348 (1.1205)  Acc@1: 75.0000 (70.1867)  Acc@5: 93.7500 (94.2955)  time: 0.4679  data: 0.0011  max mem: 2502
Test: [Task 1] Total time: 0:10:28 (0.3865 s / it)
* Acc@1 70.187 Acc@5 94.295 loss 1.120
Test: [Task 2]  [  0/625]  eta: 0:11:43  Loss: 0.1623 (0.1623)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 1.1256  data: 0.6603  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:05:19  Loss: 0.1883 (0.2370)  Acc@1: 93.7500 (95.4545)  Acc@5: 100.0000 (99.4318)  time: 0.5193  data: 0.0609  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:04:57  Loss: 0.1883 (0.2422)  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (99.7024)  time: 0.4594  data: 0.0007  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:04:47  Loss: 0.1956 (0.2640)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (99.3952)  time: 0.4645  data: 0.0008  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:04:41  Loss: 0.2716 (0.2639)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.3902)  time: 0.4695  data: 0.0017  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:04:34  Loss: 0.2716 (0.2741)  Acc@1: 93.7500 (93.6275)  Acc@5: 100.0000 (99.3873)  time: 0.4694  data: 0.0014  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:04:28  Loss: 0.2332 (0.2746)  Acc@1: 93.7500 (93.3402)  Acc@5: 100.0000 (99.2828)  time: 0.4649  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:04:19  Loss: 0.2219 (0.2706)  Acc@1: 93.7500 (93.3099)  Acc@5: 100.0000 (99.3838)  time: 0.4387  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:03:58  Loss: 0.2580 (0.2779)  Acc@1: 93.7500 (93.2870)  Acc@5: 100.0000 (99.2284)  time: 0.3199  data: 0.0008  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:03:41  Loss: 0.2512 (0.2721)  Acc@1: 93.7500 (93.4753)  Acc@5: 100.0000 (99.3132)  time: 0.2214  data: 0.0011  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:03:26  Loss: 0.2131 (0.2708)  Acc@1: 93.7500 (93.5025)  Acc@5: 100.0000 (99.3193)  time: 0.2191  data: 0.0006  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:03:14  Loss: 0.1734 (0.2682)  Acc@1: 93.7500 (93.6374)  Acc@5: 100.0000 (99.3243)  time: 0.2185  data: 0.0004  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:03:04  Loss: 0.2142 (0.2678)  Acc@1: 93.7500 (93.6983)  Acc@5: 100.0000 (99.3285)  time: 0.2184  data: 0.0004  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:02:55  Loss: 0.2407 (0.2692)  Acc@1: 93.7500 (93.6546)  Acc@5: 100.0000 (99.3798)  time: 0.2185  data: 0.0004  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:02:46  Loss: 0.2080 (0.2713)  Acc@1: 93.7500 (93.4840)  Acc@5: 100.0000 (99.3794)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:02:39  Loss: 0.2110 (0.2769)  Acc@1: 93.7500 (93.2119)  Acc@5: 100.0000 (99.3791)  time: 0.2197  data: 0.0008  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:02:32  Loss: 0.2318 (0.2798)  Acc@1: 93.7500 (93.2065)  Acc@5: 100.0000 (99.3012)  time: 0.2189  data: 0.0008  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:02:26  Loss: 0.2491 (0.2809)  Acc@1: 93.7500 (93.1652)  Acc@5: 100.0000 (99.3056)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:02:21  Loss: 0.2673 (0.2812)  Acc@1: 93.7500 (93.1630)  Acc@5: 100.0000 (99.3094)  time: 0.2277  data: 0.0004  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:02:15  Loss: 0.2673 (0.2830)  Acc@1: 93.7500 (93.1283)  Acc@5: 100.0000 (99.2801)  time: 0.2275  data: 0.0005  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:02:10  Loss: 0.2381 (0.2808)  Acc@1: 93.7500 (93.1903)  Acc@5: 100.0000 (99.3159)  time: 0.2201  data: 0.0006  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:02:05  Loss: 0.2218 (0.2815)  Acc@1: 93.7500 (93.1872)  Acc@5: 100.0000 (99.3187)  time: 0.2201  data: 0.0006  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:02:01  Loss: 0.2218 (0.2794)  Acc@1: 93.7500 (93.2975)  Acc@5: 100.0000 (99.3213)  time: 0.2210  data: 0.0013  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:57  Loss: 0.2245 (0.2783)  Acc@1: 93.7500 (93.3983)  Acc@5: 100.0000 (99.3506)  time: 0.2253  data: 0.0012  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:55  Loss: 0.2970 (0.2802)  Acc@1: 93.7500 (93.3869)  Acc@5: 100.0000 (99.3517)  time: 0.3051  data: 0.0005  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:55  Loss: 0.3109 (0.2832)  Acc@1: 93.7500 (93.2022)  Acc@5: 100.0000 (99.3028)  time: 0.4249  data: 0.0005  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:54  Loss: 0.3109 (0.2854)  Acc@1: 93.7500 (93.1992)  Acc@5: 100.0000 (99.3056)  time: 0.4736  data: 0.0020  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:53  Loss: 0.2878 (0.2853)  Acc@1: 93.7500 (93.1734)  Acc@5: 100.0000 (99.3081)  time: 0.4745  data: 0.0027  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:52  Loss: 0.2878 (0.2871)  Acc@1: 93.7500 (93.0605)  Acc@5: 100.0000 (99.2883)  time: 0.4700  data: 0.0011  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:50  Loss: 0.2412 (0.2867)  Acc@1: 93.7500 (93.0198)  Acc@5: 100.0000 (99.3127)  time: 0.4670  data: 0.0005  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:48  Loss: 0.2412 (0.2862)  Acc@1: 93.7500 (93.0025)  Acc@5: 100.0000 (99.3355)  time: 0.4630  data: 0.0016  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:46  Loss: 0.2552 (0.2873)  Acc@1: 93.7500 (92.9461)  Acc@5: 100.0000 (99.3167)  time: 0.4660  data: 0.0027  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:44  Loss: 0.1301 (0.2808)  Acc@1: 93.7500 (93.1269)  Acc@5: 100.0000 (99.3380)  time: 0.4695  data: 0.0024  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:42  Loss: 0.0956 (0.2765)  Acc@1: 100.0000 (93.2779)  Acc@5: 100.0000 (99.3580)  time: 0.4689  data: 0.0012  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:39  Loss: 0.0778 (0.2701)  Acc@1: 100.0000 (93.4751)  Acc@5: 100.0000 (99.3768)  time: 0.4674  data: 0.0005  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:01:37  Loss: 0.0564 (0.2661)  Acc@1: 100.0000 (93.5363)  Acc@5: 100.0000 (99.3946)  time: 0.4676  data: 0.0005  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:01:34  Loss: 0.1568 (0.2674)  Acc@1: 93.7500 (93.5076)  Acc@5: 100.0000 (99.3940)  time: 0.4708  data: 0.0018  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:01:31  Loss: 0.1840 (0.2642)  Acc@1: 93.7500 (93.5984)  Acc@5: 100.0000 (99.4104)  time: 0.4705  data: 0.0023  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:01:28  Loss: 0.2068 (0.2667)  Acc@1: 93.7500 (93.5696)  Acc@5: 100.0000 (99.3766)  time: 0.4672  data: 0.0009  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:01:25  Loss: 0.2193 (0.2658)  Acc@1: 93.7500 (93.5422)  Acc@5: 100.0000 (99.3606)  time: 0.4650  data: 0.0004  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:01:22  Loss: 0.0740 (0.2616)  Acc@1: 100.0000 (93.6565)  Acc@5: 100.0000 (99.3766)  time: 0.4666  data: 0.0008  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:01:19  Loss: 0.0702 (0.2597)  Acc@1: 100.0000 (93.7348)  Acc@5: 100.0000 (99.3461)  time: 0.4662  data: 0.0009  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:01:16  Loss: 0.0997 (0.2588)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.3616)  time: 0.4687  data: 0.0005  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:01:13  Loss: 0.1075 (0.2567)  Acc@1: 93.7500 (93.8225)  Acc@5: 100.0000 (99.3765)  time: 0.4714  data: 0.0021  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:01:09  Loss: 0.0684 (0.2522)  Acc@1: 100.0000 (93.9626)  Acc@5: 100.0000 (99.3906)  time: 0.4658  data: 0.0029  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:01:06  Loss: 0.0684 (0.2493)  Acc@1: 100.0000 (93.9856)  Acc@5: 100.0000 (99.4041)  time: 0.4613  data: 0.0017  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:01:02  Loss: 0.0886 (0.2462)  Acc@1: 100.0000 (94.0754)  Acc@5: 100.0000 (99.4170)  time: 0.4657  data: 0.0019  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:59  Loss: 0.1102 (0.2442)  Acc@1: 100.0000 (94.1481)  Acc@5: 100.0000 (99.4294)  time: 0.4711  data: 0.0014  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:55  Loss: 0.1423 (0.2428)  Acc@1: 100.0000 (94.2178)  Acc@5: 100.0000 (99.4413)  time: 0.4648  data: 0.0005  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:52  Loss: 0.1401 (0.2405)  Acc@1: 100.0000 (94.3101)  Acc@5: 100.0000 (99.4526)  time: 0.4616  data: 0.0006  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:48  Loss: 0.1135 (0.2388)  Acc@1: 100.0000 (94.3613)  Acc@5: 100.0000 (99.4636)  time: 0.4707  data: 0.0042  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:44  Loss: 0.1593 (0.2398)  Acc@1: 93.7500 (94.2759)  Acc@5: 100.0000 (99.4618)  time: 0.4705  data: 0.0040  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:40  Loss: 0.1603 (0.2395)  Acc@1: 93.7500 (94.3018)  Acc@5: 100.0000 (99.4722)  time: 0.4630  data: 0.0004  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:37  Loss: 0.1414 (0.2374)  Acc@1: 100.0000 (94.3503)  Acc@5: 100.0000 (99.4821)  time: 0.4649  data: 0.0008  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:33  Loss: 0.1008 (0.2356)  Acc@1: 100.0000 (94.4316)  Acc@5: 100.0000 (99.4917)  time: 0.4686  data: 0.0009  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:29  Loss: 0.0637 (0.2324)  Acc@1: 100.0000 (94.5213)  Acc@5: 100.0000 (99.5009)  time: 0.4652  data: 0.0005  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:25  Loss: 0.0450 (0.2294)  Acc@1: 100.0000 (94.5856)  Acc@5: 100.0000 (99.5098)  time: 0.4632  data: 0.0009  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:21  Loss: 0.0580 (0.2285)  Acc@1: 100.0000 (94.5928)  Acc@5: 100.0000 (99.5184)  time: 0.4654  data: 0.0025  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:17  Loss: 0.0865 (0.2264)  Acc@1: 100.0000 (94.6321)  Acc@5: 100.0000 (99.5267)  time: 0.4630  data: 0.0020  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:13  Loss: 0.1364 (0.2253)  Acc@1: 93.7500 (94.6172)  Acc@5: 100.0000 (99.5347)  time: 0.4627  data: 0.0012  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:10  Loss: 0.1411 (0.2254)  Acc@1: 93.7500 (94.6027)  Acc@5: 100.0000 (99.5424)  time: 0.4625  data: 0.0013  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:06  Loss: 0.2614 (0.2288)  Acc@1: 93.7500 (94.4660)  Acc@5: 100.0000 (99.5090)  time: 0.4626  data: 0.0007  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:02  Loss: 0.2873 (0.2292)  Acc@1: 93.7500 (94.4746)  Acc@5: 100.0000 (99.5169)  time: 0.4634  data: 0.0006  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2356 (0.2287)  Acc@1: 93.7500 (94.4900)  Acc@5: 100.0000 (99.5200)  time: 0.4595  data: 0.0004  max mem: 2502
Test: [Task 2] Total time: 0:04:11 (0.4031 s / it)
* Acc@1 94.490 Acc@5 99.520 loss 0.229
Test: [Task 3]  [  0/625]  eta: 0:11:35  Loss: 0.2474 (0.2474)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 1.1130  data: 0.6373  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:05:18  Loss: 0.2474 (0.2587)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (99.4318)  time: 0.5178  data: 0.0599  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:04:56  Loss: 0.2015 (0.2596)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (99.7024)  time: 0.4593  data: 0.0018  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:04:46  Loss: 0.2031 (0.2531)  Acc@1: 93.7500 (95.7661)  Acc@5: 100.0000 (99.5968)  time: 0.4605  data: 0.0009  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:04:38  Loss: 0.1427 (0.2248)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.6951)  time: 0.4624  data: 0.0010  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:04:32  Loss: 0.1242 (0.2199)  Acc@1: 100.0000 (96.6912)  Acc@5: 100.0000 (99.5098)  time: 0.4612  data: 0.0014  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:04:26  Loss: 0.1878 (0.2127)  Acc@1: 100.0000 (96.9262)  Acc@5: 100.0000 (99.5902)  time: 0.4604  data: 0.0017  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:04:20  Loss: 0.1366 (0.2015)  Acc@1: 100.0000 (97.0951)  Acc@5: 100.0000 (99.5599)  time: 0.4623  data: 0.0014  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:04:11  Loss: 0.1269 (0.2049)  Acc@1: 100.0000 (96.9907)  Acc@5: 100.0000 (99.6142)  time: 0.4302  data: 0.0015  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:04:05  Loss: 0.1558 (0.2057)  Acc@1: 100.0000 (96.9093)  Acc@5: 100.0000 (99.5879)  time: 0.4188  data: 0.0014  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:04:01  Loss: 0.1565 (0.2014)  Acc@1: 100.0000 (97.0916)  Acc@5: 100.0000 (99.6287)  time: 0.4517  data: 0.0004  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:03:56  Loss: 0.1560 (0.1959)  Acc@1: 100.0000 (97.2973)  Acc@5: 100.0000 (99.6622)  time: 0.4644  data: 0.0005  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:03:52  Loss: 0.1803 (0.1976)  Acc@1: 100.0000 (97.2107)  Acc@5: 100.0000 (99.6901)  time: 0.4635  data: 0.0005  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:03:47  Loss: 0.1712 (0.1969)  Acc@1: 100.0000 (97.2805)  Acc@5: 100.0000 (99.7137)  time: 0.4585  data: 0.0004  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:03:42  Loss: 0.1712 (0.2019)  Acc@1: 100.0000 (97.0745)  Acc@5: 100.0000 (99.6011)  time: 0.4546  data: 0.0007  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:03:33  Loss: 0.1955 (0.2054)  Acc@1: 93.7500 (96.9785)  Acc@5: 100.0000 (99.5861)  time: 0.3892  data: 0.0007  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:03:22  Loss: 0.1708 (0.2075)  Acc@1: 93.7500 (96.8944)  Acc@5: 100.0000 (99.5342)  time: 0.2712  data: 0.0004  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:03:13  Loss: 0.1447 (0.2067)  Acc@1: 100.0000 (96.9298)  Acc@5: 100.0000 (99.5614)  time: 0.2316  data: 0.0004  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:03:09  Loss: 0.2405 (0.2106)  Acc@1: 93.7500 (96.8577)  Acc@5: 100.0000 (99.5166)  time: 0.3511  data: 0.0004  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:03:06  Loss: 0.1758 (0.2087)  Acc@1: 93.7500 (96.8586)  Acc@5: 100.0000 (99.5092)  time: 0.4573  data: 0.0005  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:03:02  Loss: 0.1952 (0.2125)  Acc@1: 93.7500 (96.7973)  Acc@5: 100.0000 (99.5025)  time: 0.4579  data: 0.0011  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:02:58  Loss: 0.1952 (0.2145)  Acc@1: 100.0000 (96.7713)  Acc@5: 100.0000 (99.4668)  time: 0.4577  data: 0.0011  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:02:54  Loss: 0.1654 (0.2160)  Acc@1: 100.0000 (96.7195)  Acc@5: 100.0000 (99.4627)  time: 0.4555  data: 0.0012  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:02:51  Loss: 0.1861 (0.2158)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (99.4589)  time: 0.4542  data: 0.0028  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:02:47  Loss: 0.1552 (0.2179)  Acc@1: 93.7500 (96.6546)  Acc@5: 100.0000 (99.4295)  time: 0.4567  data: 0.0027  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:02:43  Loss: 0.1611 (0.2160)  Acc@1: 93.7500 (96.6633)  Acc@5: 100.0000 (99.4522)  time: 0.4598  data: 0.0012  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:02:39  Loss: 0.1552 (0.2138)  Acc@1: 100.0000 (96.7433)  Acc@5: 100.0000 (99.4492)  time: 0.4601  data: 0.0008  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:02:35  Loss: 0.1320 (0.2133)  Acc@1: 100.0000 (96.7020)  Acc@5: 100.0000 (99.4465)  time: 0.4608  data: 0.0023  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:02:31  Loss: 0.1767 (0.2124)  Acc@1: 100.0000 (96.7082)  Acc@5: 100.0000 (99.4440)  time: 0.4591  data: 0.0020  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:02:26  Loss: 0.1788 (0.2134)  Acc@1: 100.0000 (96.6924)  Acc@5: 100.0000 (99.4631)  time: 0.4571  data: 0.0004  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:02:22  Loss: 0.1739 (0.2179)  Acc@1: 100.0000 (96.5532)  Acc@5: 100.0000 (99.3978)  time: 0.4532  data: 0.0012  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:02:18  Loss: 0.1512 (0.2199)  Acc@1: 100.0000 (96.5032)  Acc@5: 100.0000 (99.3569)  time: 0.4565  data: 0.0013  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:02:14  Loss: 0.1792 (0.2194)  Acc@1: 93.7500 (96.5148)  Acc@5: 100.0000 (99.3380)  time: 0.4599  data: 0.0005  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:02:09  Loss: 0.1879 (0.2200)  Acc@1: 93.7500 (96.4690)  Acc@5: 100.0000 (99.3391)  time: 0.4257  data: 0.0006  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:02:03  Loss: 0.1614 (0.2182)  Acc@1: 100.0000 (96.5176)  Acc@5: 100.0000 (99.3402)  time: 0.3094  data: 0.0025  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:01:57  Loss: 0.1445 (0.2189)  Acc@1: 100.0000 (96.4922)  Acc@5: 100.0000 (99.3234)  time: 0.2203  data: 0.0023  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:01:51  Loss: 0.2117 (0.2196)  Acc@1: 93.7500 (96.4335)  Acc@5: 100.0000 (99.3248)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:01:45  Loss: 0.2117 (0.2202)  Acc@1: 93.7500 (96.3949)  Acc@5: 100.0000 (99.3093)  time: 0.2175  data: 0.0004  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:01:40  Loss: 0.1931 (0.2189)  Acc@1: 93.7500 (96.4239)  Acc@5: 100.0000 (99.3274)  time: 0.2176  data: 0.0005  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:01:35  Loss: 0.1661 (0.2198)  Acc@1: 100.0000 (96.3715)  Acc@5: 100.0000 (99.3446)  time: 0.2181  data: 0.0005  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:01:30  Loss: 0.1706 (0.2190)  Acc@1: 100.0000 (96.3685)  Acc@5: 100.0000 (99.3454)  time: 0.2198  data: 0.0005  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:01:25  Loss: 0.1816 (0.2198)  Acc@1: 100.0000 (96.3656)  Acc@5: 100.0000 (99.3461)  time: 0.2200  data: 0.0009  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:01:20  Loss: 0.1768 (0.2196)  Acc@1: 93.7500 (96.3628)  Acc@5: 100.0000 (99.3468)  time: 0.2183  data: 0.0008  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:01:15  Loss: 0.1555 (0.2192)  Acc@1: 100.0000 (96.3602)  Acc@5: 100.0000 (99.3474)  time: 0.2181  data: 0.0004  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:01:11  Loss: 0.1758 (0.2205)  Acc@1: 100.0000 (96.3152)  Acc@5: 100.0000 (99.3481)  time: 0.2185  data: 0.0006  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:01:06  Loss: 0.1976 (0.2204)  Acc@1: 100.0000 (96.3276)  Acc@5: 100.0000 (99.3487)  time: 0.2230  data: 0.0007  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:01:02  Loss: 0.1339 (0.2196)  Acc@1: 100.0000 (96.3395)  Acc@5: 100.0000 (99.3492)  time: 0.2298  data: 0.0005  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:57  Loss: 0.1498 (0.2194)  Acc@1: 93.7500 (96.2978)  Acc@5: 100.0000 (99.3498)  time: 0.2265  data: 0.0006  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:53  Loss: 0.1767 (0.2200)  Acc@1: 93.7500 (96.3228)  Acc@5: 100.0000 (99.3503)  time: 0.2193  data: 0.0006  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:49  Loss: 0.2086 (0.2201)  Acc@1: 100.0000 (96.3340)  Acc@5: 100.0000 (99.3381)  time: 0.2182  data: 0.0004  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:45  Loss: 0.1912 (0.2195)  Acc@1: 93.7500 (96.3199)  Acc@5: 100.0000 (99.3513)  time: 0.2184  data: 0.0004  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:41  Loss: 0.1209 (0.2190)  Acc@1: 100.0000 (96.3430)  Acc@5: 100.0000 (99.3640)  time: 0.2222  data: 0.0005  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:38  Loss: 0.1995 (0.2189)  Acc@1: 100.0000 (96.3532)  Acc@5: 100.0000 (99.3762)  time: 0.3183  data: 0.0004  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:34  Loss: 0.1995 (0.2196)  Acc@1: 100.0000 (96.3395)  Acc@5: 100.0000 (99.3879)  time: 0.4401  data: 0.0005  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:31  Loss: 0.2250 (0.2205)  Acc@1: 100.0000 (96.3262)  Acc@5: 100.0000 (99.3762)  time: 0.4722  data: 0.0012  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:27  Loss: 0.1933 (0.2212)  Acc@1: 100.0000 (96.3362)  Acc@5: 100.0000 (99.3534)  time: 0.4746  data: 0.0018  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:24  Loss: 0.1999 (0.2213)  Acc@1: 100.0000 (96.3347)  Acc@5: 100.0000 (99.3650)  time: 0.4706  data: 0.0010  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:20  Loss: 0.1999 (0.2206)  Acc@1: 93.7500 (96.3551)  Acc@5: 100.0000 (99.3651)  time: 0.4750  data: 0.0037  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:16  Loss: 0.1514 (0.2218)  Acc@1: 93.7500 (96.2887)  Acc@5: 100.0000 (99.3653)  time: 0.4772  data: 0.0045  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:13  Loss: 0.1631 (0.2212)  Acc@1: 100.0000 (96.3409)  Acc@5: 100.0000 (99.3761)  time: 0.4716  data: 0.0014  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:09  Loss: 0.1660 (0.2208)  Acc@1: 100.0000 (96.3498)  Acc@5: 100.0000 (99.3656)  time: 0.4738  data: 0.0013  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:05  Loss: 0.1836 (0.2202)  Acc@1: 100.0000 (96.3687)  Acc@5: 100.0000 (99.3658)  time: 0.4726  data: 0.0015  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2015 (0.2210)  Acc@1: 100.0000 (96.3567)  Acc@5: 100.0000 (99.3659)  time: 0.4690  data: 0.0008  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1710 (0.2205)  Acc@1: 100.0000 (96.3800)  Acc@5: 100.0000 (99.3700)  time: 0.4685  data: 0.0007  max mem: 2502
Test: [Task 3] Total time: 0:03:58 (0.3813 s / it)
* Acc@1 96.380 Acc@5 99.370 loss 0.220
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task3]	Acc@1: 87.0189	Acc@5: 97.7285	Loss: 0.5232	Forgetting: 8.2599	Backward: -8.2599
Train: Epoch[1/5]  [   0/1142]  eta: 0:25:56  Lr: 0.001875  Loss: 2.2761  Acc@1: 6.2500 (6.2500)  Acc@5: 43.7500 (43.7500)  time: 1.3632  data: 0.6099  max mem: 2502
Train: Epoch[1/5]  [  10/1142]  eta: 0:15:12  Lr: 0.001875  Loss: 2.0175  Acc@1: 25.0000 (25.5682)  Acc@5: 68.7500 (63.6364)  time: 0.8057  data: 0.0559  max mem: 2502
Train: Epoch[1/5]  [  20/1142]  eta: 0:14:33  Lr: 0.001875  Loss: 1.7583  Acc@1: 31.2500 (30.0595)  Acc@5: 75.0000 (69.3452)  time: 0.7492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  30/1142]  eta: 0:14:14  Lr: 0.001875  Loss: 1.6212  Acc@1: 31.2500 (30.6452)  Acc@5: 81.2500 (73.3871)  time: 0.7479  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  40/1142]  eta: 0:14:00  Lr: 0.001875  Loss: 1.7445  Acc@1: 31.2500 (32.6220)  Acc@5: 87.5000 (76.2195)  time: 0.7464  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  50/1142]  eta: 0:13:50  Lr: 0.001875  Loss: 1.5161  Acc@1: 43.7500 (36.7647)  Acc@5: 87.5000 (79.2892)  time: 0.7474  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [  60/1142]  eta: 0:13:39  Lr: 0.001875  Loss: 1.6603  Acc@1: 43.7500 (38.2172)  Acc@5: 87.5000 (80.3279)  time: 0.7477  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [  70/1142]  eta: 0:13:31  Lr: 0.001875  Loss: 1.5060  Acc@1: 50.0000 (39.4366)  Acc@5: 87.5000 (81.0739)  time: 0.7481  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  80/1142]  eta: 0:13:21  Lr: 0.001875  Loss: 1.0408  Acc@1: 43.7500 (40.4321)  Acc@5: 87.5000 (81.7901)  time: 0.7468  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  90/1142]  eta: 0:13:12  Lr: 0.001875  Loss: 0.9691  Acc@1: 43.7500 (40.7967)  Acc@5: 87.5000 (82.0742)  time: 0.7412  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 100/1142]  eta: 0:13:03  Lr: 0.001875  Loss: 0.9352  Acc@1: 50.0000 (42.6361)  Acc@5: 87.5000 (82.6114)  time: 0.7399  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 110/1142]  eta: 0:12:55  Lr: 0.001875  Loss: 0.8918  Acc@1: 56.2500 (43.0743)  Acc@5: 87.5000 (82.7140)  time: 0.7421  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 120/1142]  eta: 0:12:47  Lr: 0.001875  Loss: 1.3007  Acc@1: 56.2500 (43.9050)  Acc@5: 87.5000 (83.3161)  time: 0.7456  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 130/1142]  eta: 0:12:39  Lr: 0.001875  Loss: 0.6526  Acc@1: 50.0000 (44.0840)  Acc@5: 87.5000 (83.5878)  time: 0.7449  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 140/1142]  eta: 0:12:31  Lr: 0.001875  Loss: 0.7874  Acc@1: 50.0000 (44.0603)  Acc@5: 87.5000 (83.8652)  time: 0.7414  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 150/1142]  eta: 0:12:22  Lr: 0.001875  Loss: 0.8602  Acc@1: 56.2500 (44.7020)  Acc@5: 87.5000 (84.1474)  time: 0.7398  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 160/1142]  eta: 0:12:14  Lr: 0.001875  Loss: 1.0988  Acc@1: 56.2500 (44.8758)  Acc@5: 87.5000 (84.4720)  time: 0.7394  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 170/1142]  eta: 0:12:07  Lr: 0.001875  Loss: 0.6971  Acc@1: 50.0000 (45.2485)  Acc@5: 87.5000 (84.8684)  time: 0.7429  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 180/1142]  eta: 0:11:59  Lr: 0.001875  Loss: 1.0887  Acc@1: 50.0000 (45.6492)  Acc@5: 87.5000 (85.1174)  time: 0.7411  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 190/1142]  eta: 0:11:50  Lr: 0.001875  Loss: 1.0193  Acc@1: 43.7500 (45.5825)  Acc@5: 87.5000 (85.2749)  time: 0.7328  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 200/1142]  eta: 0:11:43  Lr: 0.001875  Loss: 0.6528  Acc@1: 50.0000 (46.3308)  Acc@5: 87.5000 (85.4478)  time: 0.7370  data: 0.0030  max mem: 2502
Train: Epoch[1/5]  [ 210/1142]  eta: 0:11:34  Lr: 0.001875  Loss: 0.6852  Acc@1: 56.2500 (46.8009)  Acc@5: 87.5000 (85.8116)  time: 0.7353  data: 0.0030  max mem: 2502
Train: Epoch[1/5]  [ 220/1142]  eta: 0:11:23  Lr: 0.001875  Loss: 0.4814  Acc@1: 56.2500 (47.2002)  Acc@5: 93.7500 (86.1708)  time: 0.6884  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 230/1142]  eta: 0:11:14  Lr: 0.001875  Loss: 0.6432  Acc@1: 56.2500 (47.4297)  Acc@5: 93.7500 (86.5260)  time: 0.6820  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [ 240/1142]  eta: 0:11:07  Lr: 0.001875  Loss: 0.7823  Acc@1: 50.0000 (47.8734)  Acc@5: 93.7500 (86.6442)  time: 0.7196  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [ 250/1142]  eta: 0:10:59  Lr: 0.001875  Loss: 0.8027  Acc@1: 56.2500 (48.2072)  Acc@5: 87.5000 (86.7281)  time: 0.7258  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 260/1142]  eta: 0:10:43  Lr: 0.001875  Loss: 0.5654  Acc@1: 56.2500 (48.5632)  Acc@5: 87.5000 (86.9253)  time: 0.6046  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 270/1142]  eta: 0:10:30  Lr: 0.001875  Loss: 0.1257  Acc@1: 50.0000 (48.7777)  Acc@5: 93.7500 (87.0849)  time: 0.5292  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 280/1142]  eta: 0:10:23  Lr: 0.001875  Loss: 0.5388  Acc@1: 50.0000 (48.9546)  Acc@5: 87.5000 (87.1664)  time: 0.6551  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 290/1142]  eta: 0:10:17  Lr: 0.001875  Loss: 0.3023  Acc@1: 56.2500 (49.1838)  Acc@5: 87.5000 (87.1778)  time: 0.7351  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 300/1142]  eta: 0:10:09  Lr: 0.001875  Loss: 0.4316  Acc@1: 56.2500 (49.4186)  Acc@5: 93.7500 (87.3339)  time: 0.7283  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 310/1142]  eta: 0:10:02  Lr: 0.001875  Loss: 0.2759  Acc@1: 56.2500 (49.6785)  Acc@5: 93.7500 (87.5000)  time: 0.7262  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 320/1142]  eta: 0:09:55  Lr: 0.001875  Loss: 0.1175  Acc@1: 56.2500 (49.8248)  Acc@5: 93.7500 (87.6168)  time: 0.7353  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 330/1142]  eta: 0:09:48  Lr: 0.001875  Loss: 0.2252  Acc@1: 56.2500 (49.9811)  Acc@5: 93.7500 (87.7266)  time: 0.7395  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 340/1142]  eta: 0:09:41  Lr: 0.001875  Loss: 0.2868  Acc@1: 56.2500 (50.2383)  Acc@5: 87.5000 (87.7566)  time: 0.7382  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 350/1142]  eta: 0:09:34  Lr: 0.001875  Loss: 0.0111  Acc@1: 62.5000 (50.5342)  Acc@5: 93.7500 (87.7849)  time: 0.7369  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 360/1142]  eta: 0:09:27  Lr: 0.001875  Loss: 0.1985  Acc@1: 62.5000 (50.8830)  Acc@5: 93.7500 (87.9328)  time: 0.7373  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 370/1142]  eta: 0:09:20  Lr: 0.001875  Loss: 0.1072  Acc@1: 62.5000 (51.1287)  Acc@5: 93.7500 (88.0391)  time: 0.7367  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [ 380/1142]  eta: 0:09:13  Lr: 0.001875  Loss: 0.7250  Acc@1: 56.2500 (51.1319)  Acc@5: 93.7500 (88.0906)  time: 0.7351  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [ 390/1142]  eta: 0:09:06  Lr: 0.001875  Loss: -0.0084  Acc@1: 50.0000 (51.1988)  Acc@5: 93.7500 (88.3152)  time: 0.7369  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 400/1142]  eta: 0:08:59  Lr: 0.001875  Loss: 0.3900  Acc@1: 56.2500 (51.4027)  Acc@5: 100.0000 (88.4352)  time: 0.7368  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 410/1142]  eta: 0:08:52  Lr: 0.001875  Loss: 0.3699  Acc@1: 62.5000 (51.7488)  Acc@5: 93.7500 (88.4884)  time: 0.7354  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 420/1142]  eta: 0:08:45  Lr: 0.001875  Loss: 0.1658  Acc@1: 56.2500 (51.7072)  Acc@5: 87.5000 (88.4947)  time: 0.7369  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 430/1142]  eta: 0:08:38  Lr: 0.001875  Loss: -0.1380  Acc@1: 56.2500 (51.8561)  Acc@5: 93.7500 (88.6311)  time: 0.7372  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 440/1142]  eta: 0:08:31  Lr: 0.001875  Loss: -0.2086  Acc@1: 56.2500 (51.8707)  Acc@5: 93.7500 (88.7046)  time: 0.7359  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 450/1142]  eta: 0:08:23  Lr: 0.001875  Loss: 0.0163  Acc@1: 56.2500 (52.0371)  Acc@5: 87.5000 (88.7472)  time: 0.7307  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [ 460/1142]  eta: 0:08:16  Lr: 0.001875  Loss: 0.1766  Acc@1: 56.2500 (52.0336)  Acc@5: 87.5000 (88.7744)  time: 0.7253  data: 0.0031  max mem: 2502
Train: Epoch[1/5]  [ 470/1142]  eta: 0:08:09  Lr: 0.001875  Loss: -0.3659  Acc@1: 56.2500 (52.2426)  Acc@5: 93.7500 (88.8800)  time: 0.7277  data: 0.0021  max mem: 2502
Train: Epoch[1/5]  [ 480/1142]  eta: 0:08:01  Lr: 0.001875  Loss: 0.6371  Acc@1: 56.2500 (52.1700)  Acc@5: 93.7500 (88.9553)  time: 0.7300  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 490/1142]  eta: 0:07:54  Lr: 0.001875  Loss: 0.2748  Acc@1: 56.2500 (52.2912)  Acc@5: 93.7500 (89.0530)  time: 0.7301  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 500/1142]  eta: 0:07:47  Lr: 0.001875  Loss: 0.0890  Acc@1: 62.5000 (52.5699)  Acc@5: 93.7500 (89.1093)  time: 0.7298  data: 0.0021  max mem: 2502
Train: Epoch[1/5]  [ 510/1142]  eta: 0:07:40  Lr: 0.001875  Loss: -0.3548  Acc@1: 62.5000 (52.7153)  Acc@5: 93.7500 (89.1634)  time: 0.7296  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 520/1142]  eta: 0:07:32  Lr: 0.001875  Loss: -0.0980  Acc@1: 56.2500 (52.7351)  Acc@5: 93.7500 (89.2035)  time: 0.7298  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 530/1142]  eta: 0:07:25  Lr: 0.001875  Loss: 0.2854  Acc@1: 56.2500 (52.9073)  Acc@5: 93.7500 (89.2891)  time: 0.7294  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 540/1142]  eta: 0:07:18  Lr: 0.001875  Loss: -0.0077  Acc@1: 56.2500 (52.9806)  Acc@5: 93.7500 (89.2907)  time: 0.7306  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 550/1142]  eta: 0:07:11  Lr: 0.001875  Loss: -0.2439  Acc@1: 50.0000 (52.9378)  Acc@5: 87.5000 (89.2922)  time: 0.7317  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 560/1142]  eta: 0:07:03  Lr: 0.001875  Loss: -0.3376  Acc@1: 50.0000 (52.9969)  Acc@5: 87.5000 (89.2825)  time: 0.7314  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 570/1142]  eta: 0:06:56  Lr: 0.001875  Loss: 0.0304  Acc@1: 62.5000 (53.1305)  Acc@5: 93.7500 (89.3060)  time: 0.7314  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 580/1142]  eta: 0:06:48  Lr: 0.001875  Loss: 0.0483  Acc@1: 62.5000 (53.2917)  Acc@5: 93.7500 (89.3287)  time: 0.6957  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 590/1142]  eta: 0:06:41  Lr: 0.001875  Loss: 0.2704  Acc@1: 62.5000 (53.3629)  Acc@5: 93.7500 (89.4036)  time: 0.6923  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 600/1142]  eta: 0:06:34  Lr: 0.001875  Loss: -0.3790  Acc@1: 62.5000 (53.5046)  Acc@5: 93.7500 (89.4447)  time: 0.7258  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 610/1142]  eta: 0:06:26  Lr: 0.001875  Loss: -0.2038  Acc@1: 68.7500 (53.6927)  Acc@5: 93.7500 (89.4845)  time: 0.7210  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 620/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.3174  Acc@1: 62.5000 (53.7842)  Acc@5: 93.7500 (89.5028)  time: 0.7157  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 630/1142]  eta: 0:06:11  Lr: 0.001875  Loss: -0.4119  Acc@1: 56.2500 (53.8332)  Acc@5: 93.7500 (89.5701)  time: 0.6792  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 640/1142]  eta: 0:06:04  Lr: 0.001875  Loss: -0.1177  Acc@1: 62.5000 (53.9587)  Acc@5: 93.7500 (89.5768)  time: 0.6827  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 650/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.0787  Acc@1: 62.5000 (54.1091)  Acc@5: 87.5000 (89.6217)  time: 0.7228  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 660/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.7104  Acc@1: 56.2500 (54.1604)  Acc@5: 93.7500 (89.6464)  time: 0.7227  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 670/1142]  eta: 0:05:40  Lr: 0.001875  Loss: -0.1362  Acc@1: 56.2500 (54.2753)  Acc@5: 93.7500 (89.6982)  time: 0.6114  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 680/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.3929  Acc@1: 62.5000 (54.3686)  Acc@5: 93.7500 (89.7026)  time: 0.4578  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 690/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.2223  Acc@1: 56.2500 (54.4229)  Acc@5: 93.7500 (89.7341)  time: 0.5732  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 700/1142]  eta: 0:05:17  Lr: 0.001875  Loss: -0.3726  Acc@1: 62.5000 (54.5292)  Acc@5: 93.7500 (89.7557)  time: 0.7308  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 710/1142]  eta: 0:05:10  Lr: 0.001875  Loss: -0.2948  Acc@1: 62.5000 (54.6326)  Acc@5: 93.7500 (89.8031)  time: 0.7298  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 720/1142]  eta: 0:05:03  Lr: 0.001875  Loss: -0.2531  Acc@1: 56.2500 (54.6983)  Acc@5: 93.7500 (89.8318)  time: 0.7241  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 730/1142]  eta: 0:04:55  Lr: 0.001875  Loss: 0.1054  Acc@1: 56.2500 (54.7452)  Acc@5: 93.7500 (89.8427)  time: 0.7267  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 740/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.0069  Acc@1: 62.5000 (54.8330)  Acc@5: 87.5000 (89.8532)  time: 0.7319  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 750/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.1605  Acc@1: 62.5000 (54.9101)  Acc@5: 93.7500 (89.8802)  time: 0.7270  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 760/1142]  eta: 0:04:34  Lr: 0.001875  Loss: -0.0946  Acc@1: 56.2500 (55.0427)  Acc@5: 93.7500 (89.9146)  time: 0.7274  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 770/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.3371  Acc@1: 56.2500 (55.0827)  Acc@5: 93.7500 (89.9400)  time: 0.7301  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 780/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.4281  Acc@1: 56.2500 (55.1857)  Acc@5: 93.7500 (89.9728)  time: 0.7326  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 790/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.4089  Acc@1: 62.5000 (55.3492)  Acc@5: 93.7500 (90.0363)  time: 0.7334  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 800/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.6570  Acc@1: 68.7500 (55.4541)  Acc@5: 93.7500 (90.0905)  time: 0.7254  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 810/1142]  eta: 0:03:57  Lr: 0.001875  Loss: -0.3728  Acc@1: 62.5000 (55.5487)  Acc@5: 93.7500 (90.1433)  time: 0.5357  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 820/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.2150  Acc@1: 62.5000 (55.7019)  Acc@5: 93.7500 (90.1873)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 830/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.1615  Acc@1: 62.5000 (55.7611)  Acc@5: 93.7500 (90.1775)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 840/1142]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6311  Acc@1: 56.2500 (55.8487)  Acc@5: 93.7500 (90.2274)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 850/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.6579  Acc@1: 62.5000 (55.9562)  Acc@5: 93.7500 (90.2615)  time: 0.3531  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 860/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.0940  Acc@1: 62.5000 (56.0105)  Acc@5: 93.7500 (90.2439)  time: 0.3539  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 870/1142]  eta: 0:03:07  Lr: 0.001875  Loss: -0.2383  Acc@1: 62.5000 (56.0778)  Acc@5: 93.7500 (90.2985)  time: 0.3539  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 880/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.3633  Acc@1: 62.5000 (56.1010)  Acc@5: 93.7500 (90.3164)  time: 0.3536  data: 0.0022  max mem: 2502
Train: Epoch[1/5]  [ 890/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.1414  Acc@1: 56.2500 (56.1378)  Acc@5: 93.7500 (90.3760)  time: 0.3525  data: 0.0021  max mem: 2502
Train: Epoch[1/5]  [ 900/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.1434  Acc@1: 56.2500 (56.2014)  Acc@5: 93.7500 (90.4342)  time: 0.3525  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 910/1142]  eta: 0:02:36  Lr: 0.001875  Loss: -0.0239  Acc@1: 62.5000 (56.2226)  Acc@5: 93.7500 (90.4432)  time: 0.3560  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 920/1142]  eta: 0:02:29  Lr: 0.001875  Loss: -0.3675  Acc@1: 62.5000 (56.2229)  Acc@5: 93.7500 (90.4927)  time: 0.3552  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 930/1142]  eta: 0:02:21  Lr: 0.001875  Loss: -0.2408  Acc@1: 62.5000 (56.2567)  Acc@5: 93.7500 (90.5008)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 940/1142]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5149  Acc@1: 56.2500 (56.2367)  Acc@5: 93.7500 (90.5287)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 950/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.2205  Acc@1: 50.0000 (56.2763)  Acc@5: 93.7500 (90.5560)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.0108  Acc@1: 62.5000 (56.3736)  Acc@5: 93.7500 (90.6087)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 970/1142]  eta: 0:01:52  Lr: 0.001875  Loss: 0.0173  Acc@1: 62.5000 (56.5268)  Acc@5: 93.7500 (90.6347)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 980/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.2706  Acc@1: 68.7500 (56.6068)  Acc@5: 93.7500 (90.6473)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 990/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.5117  Acc@1: 56.2500 (56.6158)  Acc@5: 87.5000 (90.6534)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1000/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.0669  Acc@1: 56.2500 (56.6496)  Acc@5: 93.7500 (90.6656)  time: 0.3539  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1010/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6603  Acc@1: 56.2500 (56.6580)  Acc@5: 93.7500 (90.6590)  time: 0.3549  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1020/1142]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5820  Acc@1: 56.2500 (56.6724)  Acc@5: 93.7500 (90.7015)  time: 0.3532  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1030/1142]  eta: 0:01:11  Lr: 0.001875  Loss: -0.4668  Acc@1: 62.5000 (56.7410)  Acc@5: 93.7500 (90.7008)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1040/1142]  eta: 0:01:04  Lr: 0.001875  Loss: 0.1112  Acc@1: 62.5000 (56.8204)  Acc@5: 93.7500 (90.7121)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0789  Acc@1: 62.5000 (56.8804)  Acc@5: 93.7500 (90.7588)  time: 0.3538  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:51  Lr: 0.001875  Loss: -0.5813  Acc@1: 56.2500 (56.8862)  Acc@5: 93.7500 (90.7340)  time: 0.3532  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:45  Lr: 0.001875  Loss: -0.7706  Acc@1: 56.2500 (56.9094)  Acc@5: 93.7500 (90.7563)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1352  Acc@1: 62.5000 (56.9727)  Acc@5: 93.7500 (90.7551)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.2219  Acc@1: 62.5000 (56.9833)  Acc@5: 93.7500 (90.7539)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:26  Lr: 0.001875  Loss: -0.3935  Acc@1: 56.2500 (57.0391)  Acc@5: 93.7500 (90.7641)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:19  Lr: 0.001875  Loss: -0.7173  Acc@1: 62.5000 (57.1332)  Acc@5: 93.7500 (90.7910)  time: 0.3515  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:13  Lr: 0.001875  Loss: -0.5596  Acc@1: 62.5000 (57.2090)  Acc@5: 93.7500 (90.7950)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4220  Acc@1: 68.7500 (57.2944)  Acc@5: 93.7500 (90.8101)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:01  Lr: 0.001875  Loss: -0.6100  Acc@1: 62.5000 (57.3236)  Acc@5: 93.7500 (90.8578)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1676  Acc@1: 62.5000 (57.3227)  Acc@5: 93.7500 (90.8514)  time: 0.3449  data: 0.0005  max mem: 2502
Train: Epoch[1/5] Total time: 0:11:36 (0.6099 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1676  Acc@1: 62.5000 (57.3227)  Acc@5: 93.7500 (90.8514)
Train: Epoch[2/5]  [   0/1142]  eta: 0:19:49  Lr: 0.001875  Loss: -1.0081  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 1.0420  data: 0.6859  max mem: 2502
Train: Epoch[2/5]  [  10/1142]  eta: 0:07:48  Lr: 0.001875  Loss: -0.6618  Acc@1: 68.7500 (71.0227)  Acc@5: 100.0000 (93.7500)  time: 0.4142  data: 0.0628  max mem: 2502
Train: Epoch[2/5]  [  20/1142]  eta: 0:07:10  Lr: 0.001875  Loss: 0.0507  Acc@1: 68.7500 (69.0476)  Acc@5: 93.7500 (90.4762)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  30/1142]  eta: 0:06:55  Lr: 0.001875  Loss: -0.2352  Acc@1: 62.5000 (67.5403)  Acc@5: 87.5000 (89.7177)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [  40/1142]  eta: 0:06:46  Lr: 0.001875  Loss: 0.2149  Acc@1: 68.7500 (66.4634)  Acc@5: 93.7500 (91.0061)  time: 0.3527  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [  50/1142]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5615  Acc@1: 68.7500 (67.2794)  Acc@5: 93.7500 (91.5441)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  60/1142]  eta: 0:06:33  Lr: 0.001875  Loss: -0.5724  Acc@1: 68.7500 (67.2131)  Acc@5: 93.7500 (91.3934)  time: 0.3540  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  70/1142]  eta: 0:06:28  Lr: 0.001875  Loss: -0.5983  Acc@1: 68.7500 (67.5176)  Acc@5: 93.7500 (91.9894)  time: 0.3541  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  80/1142]  eta: 0:06:23  Lr: 0.001875  Loss: -0.3811  Acc@1: 68.7500 (66.3580)  Acc@5: 93.7500 (92.2068)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:18  Lr: 0.001875  Loss: 0.0710  Acc@1: 62.5000 (66.0714)  Acc@5: 93.7500 (92.1703)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:14  Lr: 0.001875  Loss: -0.4983  Acc@1: 68.7500 (66.2129)  Acc@5: 93.7500 (92.3267)  time: 0.3527  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 110/1142]  eta: 0:06:09  Lr: 0.001875  Loss: -0.4388  Acc@1: 62.5000 (65.1464)  Acc@5: 93.7500 (91.8356)  time: 0.3511  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 120/1142]  eta: 0:06:05  Lr: 0.001875  Loss: 0.2123  Acc@1: 56.2500 (65.0310)  Acc@5: 87.5000 (91.5289)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 130/1142]  eta: 0:06:01  Lr: 0.001875  Loss: -0.5509  Acc@1: 62.5000 (65.3149)  Acc@5: 93.7500 (91.6508)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 140/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.3259  Acc@1: 62.5000 (64.9823)  Acc@5: 93.7500 (91.5780)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 150/1142]  eta: 0:05:53  Lr: 0.001875  Loss: 0.7214  Acc@1: 62.5000 (64.8179)  Acc@5: 93.7500 (91.6391)  time: 0.3519  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 160/1142]  eta: 0:05:50  Lr: 0.001875  Loss: -0.8528  Acc@1: 68.7500 (65.4503)  Acc@5: 93.7500 (91.8866)  time: 0.3543  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 170/1142]  eta: 0:05:46  Lr: 0.001875  Loss: 0.0566  Acc@1: 68.7500 (65.3143)  Acc@5: 93.7500 (91.9591)  time: 0.3540  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 180/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.3306  Acc@1: 62.5000 (65.3660)  Acc@5: 93.7500 (91.8854)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 190/1142]  eta: 0:05:39  Lr: 0.001875  Loss: -0.5734  Acc@1: 62.5000 (65.4450)  Acc@5: 93.7500 (92.0157)  time: 0.3532  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 200/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.7547  Acc@1: 62.5000 (65.5473)  Acc@5: 93.7500 (92.1020)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 210/1142]  eta: 0:05:31  Lr: 0.001875  Loss: 0.1833  Acc@1: 68.7500 (65.3140)  Acc@5: 93.7500 (92.0912)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 220/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.0220  Acc@1: 62.5000 (64.9887)  Acc@5: 93.7500 (92.1380)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4119  Acc@1: 62.5000 (64.8268)  Acc@5: 93.7500 (92.2078)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:20  Lr: 0.001875  Loss: -0.3661  Acc@1: 62.5000 (64.8340)  Acc@5: 93.7500 (92.2459)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.5014  Acc@1: 62.5000 (64.6663)  Acc@5: 93.7500 (92.3058)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.1848  Acc@1: 62.5000 (64.6552)  Acc@5: 93.7500 (92.3611)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.2004  Acc@1: 62.5000 (64.6218)  Acc@5: 93.7500 (92.4124)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 280/1142]  eta: 0:05:05  Lr: 0.001875  Loss: 0.1300  Acc@1: 62.5000 (64.5685)  Acc@5: 93.7500 (92.4822)  time: 0.3539  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 290/1142]  eta: 0:05:01  Lr: 0.001875  Loss: -0.7796  Acc@1: 62.5000 (64.6048)  Acc@5: 93.7500 (92.6332)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 300/1142]  eta: 0:04:58  Lr: 0.001875  Loss: -0.7000  Acc@1: 68.7500 (64.6179)  Acc@5: 93.7500 (92.5872)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 310/1142]  eta: 0:04:54  Lr: 0.001875  Loss: -0.3370  Acc@1: 68.7500 (64.4293)  Acc@5: 93.7500 (92.4839)  time: 0.3524  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 320/1142]  eta: 0:04:51  Lr: 0.001875  Loss: -0.3911  Acc@1: 62.5000 (64.3886)  Acc@5: 93.7500 (92.4455)  time: 0.3524  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 330/1142]  eta: 0:04:47  Lr: 0.001875  Loss: -0.3169  Acc@1: 62.5000 (64.3693)  Acc@5: 93.7500 (92.4660)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 340/1142]  eta: 0:04:43  Lr: 0.001875  Loss: -0.2058  Acc@1: 62.5000 (64.2229)  Acc@5: 93.7500 (92.4304)  time: 0.3516  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 350/1142]  eta: 0:04:40  Lr: 0.001875  Loss: -0.0406  Acc@1: 62.5000 (64.1382)  Acc@5: 87.5000 (92.3611)  time: 0.3533  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 360/1142]  eta: 0:04:36  Lr: 0.001875  Loss: -0.2072  Acc@1: 56.2500 (64.0235)  Acc@5: 87.5000 (92.3650)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 370/1142]  eta: 0:04:33  Lr: 0.001875  Loss: -0.1598  Acc@1: 62.5000 (64.1678)  Acc@5: 93.7500 (92.4191)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6552  Acc@1: 62.5000 (63.9764)  Acc@5: 93.7500 (92.4541)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:26  Lr: 0.001875  Loss: -0.1657  Acc@1: 62.5000 (64.0985)  Acc@5: 93.7500 (92.4872)  time: 0.3518  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:22  Lr: 0.001875  Loss: -0.6240  Acc@1: 62.5000 (64.0898)  Acc@5: 93.7500 (92.4875)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:18  Lr: 0.001875  Loss: -0.0130  Acc@1: 56.2500 (64.0055)  Acc@5: 93.7500 (92.5030)  time: 0.3545  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:15  Lr: 0.001875  Loss: -0.4822  Acc@1: 56.2500 (63.9103)  Acc@5: 93.7500 (92.5624)  time: 0.3569  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -0.2543  Acc@1: 62.5000 (63.9211)  Acc@5: 93.7500 (92.5464)  time: 0.3532  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:08  Lr: 0.001875  Loss: -0.5501  Acc@1: 68.7500 (63.9881)  Acc@5: 93.7500 (92.5170)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 450/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.5800  Acc@1: 62.5000 (63.9412)  Acc@5: 93.7500 (92.5028)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 460/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.1321  Acc@1: 62.5000 (63.9371)  Acc@5: 93.7500 (92.4756)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 470/1142]  eta: 0:03:57  Lr: 0.001875  Loss: -0.7942  Acc@1: 62.5000 (63.8933)  Acc@5: 93.7500 (92.5159)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 480/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.4093  Acc@1: 62.5000 (63.9163)  Acc@5: 93.7500 (92.5936)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 490/1142]  eta: 0:03:50  Lr: 0.001875  Loss: -0.6112  Acc@1: 68.7500 (64.0657)  Acc@5: 93.7500 (92.6426)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 500/1142]  eta: 0:03:46  Lr: 0.001875  Loss: -0.8014  Acc@1: 68.7500 (64.0843)  Acc@5: 93.7500 (92.6771)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 510/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.3490  Acc@1: 62.5000 (64.0411)  Acc@5: 93.7500 (92.6003)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 520/1142]  eta: 0:03:39  Lr: 0.001875  Loss: -0.5604  Acc@1: 62.5000 (64.0115)  Acc@5: 93.7500 (92.5864)  time: 0.3524  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 530/1142]  eta: 0:03:36  Lr: 0.001875  Loss: 0.1050  Acc@1: 62.5000 (64.0301)  Acc@5: 93.7500 (92.6436)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:32  Lr: 0.001875  Loss: -0.0351  Acc@1: 62.5000 (64.1058)  Acc@5: 93.7500 (92.6409)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:29  Lr: 0.001875  Loss: -0.7513  Acc@1: 68.7500 (64.1107)  Acc@5: 93.7500 (92.6838)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:25  Lr: 0.001875  Loss: -0.3657  Acc@1: 62.5000 (64.1488)  Acc@5: 93.7500 (92.6582)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:22  Lr: 0.001875  Loss: -0.1161  Acc@1: 68.7500 (64.2513)  Acc@5: 93.7500 (92.6664)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:18  Lr: 0.001875  Loss: -0.3243  Acc@1: 62.5000 (64.1459)  Acc@5: 93.7500 (92.6312)  time: 0.3523  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.5140  Acc@1: 62.5000 (64.1180)  Acc@5: 93.7500 (92.6079)  time: 0.3530  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:11  Lr: 0.001875  Loss: -0.1455  Acc@1: 62.5000 (64.0911)  Acc@5: 93.7500 (92.5957)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.1977  Acc@1: 62.5000 (64.0241)  Acc@5: 93.7500 (92.5839)  time: 0.3558  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 620/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.4168  Acc@1: 56.2500 (63.8788)  Acc@5: 93.7500 (92.6127)  time: 0.3564  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 630/1142]  eta: 0:03:00  Lr: 0.001875  Loss: -0.6714  Acc@1: 62.5000 (63.9065)  Acc@5: 93.7500 (92.6406)  time: 0.3542  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 640/1142]  eta: 0:02:57  Lr: 0.001875  Loss: -0.5909  Acc@1: 62.5000 (63.9138)  Acc@5: 93.7500 (92.6580)  time: 0.3590  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 650/1142]  eta: 0:02:53  Lr: 0.001875  Loss: -0.4202  Acc@1: 62.5000 (63.8057)  Acc@5: 93.7500 (92.6843)  time: 0.3566  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 660/1142]  eta: 0:02:50  Lr: 0.001875  Loss: -0.1447  Acc@1: 62.5000 (63.7954)  Acc@5: 93.7500 (92.6532)  time: 0.3517  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 670/1142]  eta: 0:02:46  Lr: 0.001875  Loss: -0.4427  Acc@1: 62.5000 (63.7575)  Acc@5: 93.7500 (92.6695)  time: 0.3528  data: 0.0023  max mem: 2502
Train: Epoch[2/5]  [ 680/1142]  eta: 0:02:43  Lr: 0.001875  Loss: -0.1154  Acc@1: 62.5000 (63.7206)  Acc@5: 93.7500 (92.6946)  time: 0.3585  data: 0.0028  max mem: 2502
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:39  Lr: 0.001875  Loss: -0.5593  Acc@1: 62.5000 (63.7572)  Acc@5: 93.7500 (92.7370)  time: 0.3589  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:36  Lr: 0.001875  Loss: -0.7087  Acc@1: 68.7500 (63.8463)  Acc@5: 93.7500 (92.7603)  time: 0.3546  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:32  Lr: 0.001875  Loss: -0.2154  Acc@1: 68.7500 (63.8801)  Acc@5: 93.7500 (92.7655)  time: 0.3540  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:29  Lr: 0.001875  Loss: -0.4502  Acc@1: 62.5000 (63.8956)  Acc@5: 93.7500 (92.7878)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:25  Lr: 0.001875  Loss: -0.5505  Acc@1: 62.5000 (63.8680)  Acc@5: 93.7500 (92.7753)  time: 0.3522  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:22  Lr: 0.001875  Loss: -0.1333  Acc@1: 62.5000 (63.8748)  Acc@5: 93.7500 (92.7969)  time: 0.3528  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:18  Lr: 0.001875  Loss: -0.3680  Acc@1: 62.5000 (63.8232)  Acc@5: 93.7500 (92.7846)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:15  Lr: 0.001875  Loss: -0.5671  Acc@1: 68.7500 (63.8962)  Acc@5: 93.7500 (92.7562)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3386  Acc@1: 68.7500 (63.9348)  Acc@5: 93.7500 (92.7448)  time: 0.3530  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:07  Lr: 0.001875  Loss: -0.3264  Acc@1: 68.7500 (63.9405)  Acc@5: 93.7500 (92.7337)  time: 0.3540  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:04  Lr: 0.001875  Loss: 0.0995  Acc@1: 62.5000 (63.8274)  Acc@5: 93.7500 (92.6912)  time: 0.3524  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 800/1142]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4633  Acc@1: 62.5000 (63.7953)  Acc@5: 87.5000 (92.6498)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 810/1142]  eta: 0:01:57  Lr: 0.001875  Loss: -0.3127  Acc@1: 62.5000 (63.7716)  Acc@5: 93.7500 (92.6557)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 820/1142]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0336  Acc@1: 62.5000 (63.8018)  Acc@5: 93.7500 (92.6386)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 830/1142]  eta: 0:01:50  Lr: 0.001875  Loss: -0.2192  Acc@1: 62.5000 (63.8538)  Acc@5: 93.7500 (92.6218)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:46  Lr: 0.001875  Loss: -0.2327  Acc@1: 62.5000 (63.8228)  Acc@5: 93.7500 (92.6353)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:43  Lr: 0.001875  Loss: -0.6136  Acc@1: 62.5000 (63.8587)  Acc@5: 93.7500 (92.6410)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:39  Lr: 0.001875  Loss: -0.5838  Acc@1: 62.5000 (63.8211)  Acc@5: 93.7500 (92.6103)  time: 0.3527  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:36  Lr: 0.001875  Loss: -0.4813  Acc@1: 62.5000 (63.7916)  Acc@5: 93.7500 (92.6449)  time: 0.3550  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:32  Lr: 0.001875  Loss: -0.3603  Acc@1: 62.5000 (63.7770)  Acc@5: 93.7500 (92.6220)  time: 0.3545  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:29  Lr: 0.001875  Loss: 0.0602  Acc@1: 68.7500 (63.7416)  Acc@5: 93.7500 (92.6136)  time: 0.3550  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:25  Lr: 0.001875  Loss: 0.1361  Acc@1: 62.5000 (63.7347)  Acc@5: 93.7500 (92.5708)  time: 0.3536  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4678  Acc@1: 62.5000 (63.7692)  Acc@5: 93.7500 (92.5700)  time: 0.3530  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5487  Acc@1: 68.7500 (63.8165)  Acc@5: 93.7500 (92.6099)  time: 0.3551  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6128  Acc@1: 68.7500 (63.8628)  Acc@5: 93.7500 (92.6020)  time: 0.3555  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5881  Acc@1: 62.5000 (63.8151)  Acc@5: 93.7500 (92.5943)  time: 0.3545  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.4060  Acc@1: 62.5000 (63.8275)  Acc@5: 93.7500 (92.6130)  time: 0.3536  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5075  Acc@1: 62.5000 (63.8137)  Acc@5: 93.7500 (92.5989)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.4547  Acc@1: 62.5000 (63.8002)  Acc@5: 93.7500 (92.6043)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 980/1142]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4592  Acc@1: 62.5000 (63.8570)  Acc@5: 93.7500 (92.6287)  time: 0.3543  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: 0.2721  Acc@1: 62.5000 (63.7803)  Acc@5: 93.7500 (92.6400)  time: 0.3547  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:50  Lr: 0.001875  Loss: -0.4037  Acc@1: 62.5000 (63.8049)  Acc@5: 93.7500 (92.6449)  time: 0.3515  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.4880  Acc@1: 62.5000 (63.7920)  Acc@5: 93.7500 (92.6558)  time: 0.3599  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:43  Lr: 0.001875  Loss: -0.6422  Acc@1: 62.5000 (63.8222)  Acc@5: 93.7500 (92.6787)  time: 0.3605  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.2524  Acc@1: 62.5000 (63.8155)  Acc@5: 93.7500 (92.6831)  time: 0.3537  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1245  Acc@1: 68.7500 (63.8268)  Acc@5: 93.7500 (92.6933)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.2749  Acc@1: 68.7500 (63.8618)  Acc@5: 93.7500 (92.7093)  time: 0.4194  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:29  Lr: 0.001875  Loss: 0.0562  Acc@1: 62.5000 (63.8431)  Acc@5: 93.7500 (92.7368)  time: 0.6212  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:26  Lr: 0.001875  Loss: -0.2013  Acc@1: 56.2500 (63.7722)  Acc@5: 93.7500 (92.7346)  time: 0.7530  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:22  Lr: 0.001875  Loss: -0.9562  Acc@1: 62.5000 (63.8009)  Acc@5: 93.7500 (92.7382)  time: 0.7506  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:19  Lr: 0.001875  Loss: -0.3221  Acc@1: 68.7500 (63.8462)  Acc@5: 93.7500 (92.7188)  time: 0.7549  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:15  Lr: 0.001875  Loss: -0.4705  Acc@1: 68.7500 (63.8624)  Acc@5: 93.7500 (92.7396)  time: 0.7537  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:12  Lr: 0.001875  Loss: -0.0682  Acc@1: 62.5000 (63.8333)  Acc@5: 93.7500 (92.7205)  time: 0.7476  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5720  Acc@1: 62.5000 (63.8325)  Acc@5: 93.7500 (92.7186)  time: 0.5561  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7953  Acc@1: 62.5000 (63.8815)  Acc@5: 93.7500 (92.7332)  time: 0.3574  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9536  Acc@1: 62.5000 (63.8913)  Acc@5: 93.7500 (92.7202)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8666  Acc@1: 62.5000 (63.8982)  Acc@5: 93.7500 (92.7238)  time: 0.3439  data: 0.0005  max mem: 2502
Train: Epoch[2/5] Total time: 0:07:09 (0.3760 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.8666  Acc@1: 62.5000 (63.8982)  Acc@5: 93.7500 (92.7238)
Train: Epoch[3/5]  [   0/1142]  eta: 0:18:54  Lr: 0.001875  Loss: -0.3537  Acc@1: 56.2500 (56.2500)  Acc@5: 81.2500 (81.2500)  time: 0.9937  data: 0.6452  max mem: 2502
Train: Epoch[3/5]  [  10/1142]  eta: 0:07:41  Lr: 0.001875  Loss: -0.5223  Acc@1: 68.7500 (67.0455)  Acc@5: 100.0000 (94.8864)  time: 0.4081  data: 0.0590  max mem: 2502
Train: Epoch[3/5]  [  20/1142]  eta: 0:07:08  Lr: 0.001875  Loss: -0.9470  Acc@1: 68.7500 (66.3690)  Acc@5: 100.0000 (94.9405)  time: 0.3517  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [  30/1142]  eta: 0:06:55  Lr: 0.001875  Loss: -0.5172  Acc@1: 56.2500 (63.9113)  Acc@5: 93.7500 (93.7500)  time: 0.3543  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [  40/1142]  eta: 0:06:45  Lr: 0.001875  Loss: -0.3117  Acc@1: 62.5000 (64.3293)  Acc@5: 93.7500 (94.0549)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [  50/1142]  eta: 0:06:41  Lr: 0.001875  Loss: -0.6516  Acc@1: 68.7500 (65.5637)  Acc@5: 93.7500 (94.4853)  time: 0.3594  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  60/1142]  eta: 0:06:35  Lr: 0.001875  Loss: -0.2108  Acc@1: 62.5000 (64.2418)  Acc@5: 93.7500 (94.0574)  time: 0.3596  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  70/1142]  eta: 0:06:29  Lr: 0.001875  Loss: -0.1721  Acc@1: 62.5000 (64.1725)  Acc@5: 93.7500 (93.5739)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  80/1142]  eta: 0:06:23  Lr: 0.001875  Loss: -0.0989  Acc@1: 62.5000 (64.4290)  Acc@5: 87.5000 (93.4414)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:18  Lr: 0.001875  Loss: -0.5893  Acc@1: 68.7500 (64.6291)  Acc@5: 93.7500 (93.4066)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:13  Lr: 0.001875  Loss: 0.3338  Acc@1: 68.7500 (64.6040)  Acc@5: 93.7500 (93.3787)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 110/1142]  eta: 0:06:09  Lr: 0.001875  Loss: 0.2009  Acc@1: 68.7500 (64.8649)  Acc@5: 93.7500 (93.2995)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 120/1142]  eta: 0:06:05  Lr: 0.001875  Loss: -0.6227  Acc@1: 68.7500 (65.2376)  Acc@5: 93.7500 (93.5950)  time: 0.3519  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 130/1142]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6840  Acc@1: 68.7500 (65.5057)  Acc@5: 100.0000 (93.5592)  time: 0.3524  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 140/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.3207  Acc@1: 68.7500 (65.7801)  Acc@5: 100.0000 (93.7057)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 150/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.7072  Acc@1: 62.5000 (65.3560)  Acc@5: 93.7500 (93.7500)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 160/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.7799  Acc@1: 56.2500 (65.3339)  Acc@5: 93.7500 (93.8665)  time: 0.3535  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 170/1142]  eta: 0:05:46  Lr: 0.001875  Loss: -0.4796  Acc@1: 68.7500 (65.5702)  Acc@5: 93.7500 (93.9693)  time: 0.3556  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 180/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.3448  Acc@1: 68.7500 (65.5041)  Acc@5: 93.7500 (93.9227)  time: 0.3539  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 190/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.1642  Acc@1: 62.5000 (65.3141)  Acc@5: 93.7500 (93.7827)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 200/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4147  Acc@1: 62.5000 (65.1119)  Acc@5: 93.7500 (93.8744)  time: 0.3517  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 210/1142]  eta: 0:05:31  Lr: 0.001875  Loss: 0.0436  Acc@1: 62.5000 (65.0474)  Acc@5: 93.7500 (93.7500)  time: 0.3544  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 220/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.6375  Acc@1: 62.5000 (64.8473)  Acc@5: 93.7500 (93.6652)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.2425  Acc@1: 62.5000 (64.8810)  Acc@5: 93.7500 (93.7229)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:20  Lr: 0.001875  Loss: 0.7859  Acc@1: 62.5000 (64.8859)  Acc@5: 93.7500 (93.7241)  time: 0.3535  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.5593  Acc@1: 62.5000 (64.8904)  Acc@5: 93.7500 (93.6255)  time: 0.3542  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:13  Lr: 0.001875  Loss: -0.5192  Acc@1: 68.7500 (64.8946)  Acc@5: 93.7500 (93.5584)  time: 0.3530  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.3429  Acc@1: 62.5000 (64.6910)  Acc@5: 93.7500 (93.4732)  time: 0.3569  data: 0.0027  max mem: 2502
Train: Epoch[3/5]  [ 280/1142]  eta: 0:05:06  Lr: 0.001875  Loss: -0.1895  Acc@1: 62.5000 (64.8577)  Acc@5: 93.7500 (93.3941)  time: 0.3557  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [ 290/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.3455  Acc@1: 68.7500 (64.7981)  Acc@5: 93.7500 (93.3204)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 300/1142]  eta: 0:04:58  Lr: 0.001875  Loss: -0.6496  Acc@1: 62.5000 (64.6802)  Acc@5: 93.7500 (93.3347)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 310/1142]  eta: 0:04:55  Lr: 0.001875  Loss: 0.4997  Acc@1: 62.5000 (64.7709)  Acc@5: 93.7500 (93.3280)  time: 0.3615  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 320/1142]  eta: 0:04:52  Lr: 0.001875  Loss: -0.8717  Acc@1: 68.7500 (64.9143)  Acc@5: 93.7500 (93.4385)  time: 0.3613  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 330/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4047  Acc@1: 68.7500 (64.9736)  Acc@5: 93.7500 (93.4290)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 340/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.2451  Acc@1: 68.7500 (65.0477)  Acc@5: 93.7500 (93.4201)  time: 0.3738  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 350/1142]  eta: 0:04:51  Lr: 0.001875  Loss: 0.1163  Acc@1: 62.5000 (65.0463)  Acc@5: 93.7500 (93.4117)  time: 0.5747  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 360/1142]  eta: 0:04:55  Lr: 0.001875  Loss: -0.2219  Acc@1: 62.5000 (65.0277)  Acc@5: 93.7500 (93.3172)  time: 0.7530  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 370/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.8032  Acc@1: 68.7500 (65.2460)  Acc@5: 93.7500 (93.3962)  time: 0.7524  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 380/1142]  eta: 0:05:03  Lr: 0.001875  Loss: -0.1572  Acc@1: 68.7500 (65.3215)  Acc@5: 100.0000 (93.4875)  time: 0.7516  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 390/1142]  eta: 0:05:06  Lr: 0.001875  Loss: -0.5243  Acc@1: 68.7500 (65.4252)  Acc@5: 93.7500 (93.5422)  time: 0.7517  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 400/1142]  eta: 0:05:08  Lr: 0.001875  Loss: 0.2232  Acc@1: 68.7500 (65.3367)  Acc@5: 93.7500 (93.5318)  time: 0.7501  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 410/1142]  eta: 0:05:10  Lr: 0.001875  Loss: -0.0730  Acc@1: 56.2500 (65.1460)  Acc@5: 93.7500 (93.4459)  time: 0.7522  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 420/1142]  eta: 0:05:07  Lr: 0.001875  Loss: -0.3153  Acc@1: 62.5000 (65.2761)  Acc@5: 93.7500 (93.4086)  time: 0.6380  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 430/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.2075  Acc@1: 62.5000 (65.3277)  Acc@5: 93.7500 (93.3730)  time: 0.4366  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:56  Lr: 0.001875  Loss: -0.2315  Acc@1: 68.7500 (65.3486)  Acc@5: 93.7500 (93.4099)  time: 0.3540  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 450/1142]  eta: 0:04:51  Lr: 0.001875  Loss: -0.6537  Acc@1: 68.7500 (65.5211)  Acc@5: 93.7500 (93.4174)  time: 0.3548  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 460/1142]  eta: 0:04:46  Lr: 0.001875  Loss: -0.4764  Acc@1: 68.7500 (65.5233)  Acc@5: 93.7500 (93.4924)  time: 0.3545  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 470/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.8351  Acc@1: 68.7500 (65.6714)  Acc@5: 93.7500 (93.5111)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 480/1142]  eta: 0:04:36  Lr: 0.001875  Loss: -0.4600  Acc@1: 68.7500 (65.6575)  Acc@5: 93.7500 (93.5551)  time: 0.3536  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 490/1142]  eta: 0:04:31  Lr: 0.001875  Loss: 0.0642  Acc@1: 62.5000 (65.5041)  Acc@5: 93.7500 (93.5845)  time: 0.3556  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 500/1142]  eta: 0:04:26  Lr: 0.001875  Loss: 0.3076  Acc@1: 62.5000 (65.4441)  Acc@5: 93.7500 (93.5254)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 510/1142]  eta: 0:04:21  Lr: 0.001875  Loss: -0.7836  Acc@1: 62.5000 (65.4354)  Acc@5: 87.5000 (93.4809)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 520/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.1525  Acc@1: 62.5000 (65.4151)  Acc@5: 87.5000 (93.4501)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 530/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -0.0511  Acc@1: 62.5000 (65.4543)  Acc@5: 93.7500 (93.5028)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 540/1142]  eta: 0:04:06  Lr: 0.001875  Loss: 0.0227  Acc@1: 68.7500 (65.5152)  Acc@5: 93.7500 (93.5074)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 550/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.7849  Acc@1: 68.7500 (65.5513)  Acc@5: 93.7500 (93.5458)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:57  Lr: 0.001875  Loss: -0.1629  Acc@1: 68.7500 (65.5080)  Acc@5: 93.7500 (93.5160)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:52  Lr: 0.001875  Loss: -0.3419  Acc@1: 62.5000 (65.4553)  Acc@5: 93.7500 (93.4982)  time: 0.3523  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.3969  Acc@1: 62.5000 (65.3077)  Acc@5: 93.7500 (93.4380)  time: 0.3516  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.6398  Acc@1: 62.5000 (65.2496)  Acc@5: 87.5000 (93.4327)  time: 0.3514  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -0.4545  Acc@1: 62.5000 (65.2038)  Acc@5: 93.7500 (93.3964)  time: 0.3538  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.9296  Acc@1: 68.7500 (65.3437)  Acc@5: 93.7500 (93.4124)  time: 0.3584  data: 0.0030  max mem: 2502
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:30  Lr: 0.001875  Loss: -0.1526  Acc@1: 68.7500 (65.2878)  Acc@5: 93.7500 (93.4279)  time: 0.3556  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 630/1142]  eta: 0:03:25  Lr: 0.001875  Loss: 0.0370  Acc@1: 68.7500 (65.3427)  Acc@5: 93.7500 (93.4529)  time: 0.3517  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 640/1142]  eta: 0:03:21  Lr: 0.001875  Loss: 0.1308  Acc@1: 68.7500 (65.3374)  Acc@5: 93.7500 (93.4185)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 650/1142]  eta: 0:03:16  Lr: 0.001875  Loss: -0.6100  Acc@1: 62.5000 (65.2362)  Acc@5: 93.7500 (93.3948)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 660/1142]  eta: 0:03:12  Lr: 0.001875  Loss: -0.4985  Acc@1: 62.5000 (65.2421)  Acc@5: 93.7500 (93.4096)  time: 0.3536  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 670/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.0637  Acc@1: 68.7500 (65.2664)  Acc@5: 93.7500 (93.4147)  time: 0.3531  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 680/1142]  eta: 0:03:03  Lr: 0.001875  Loss: -0.8324  Acc@1: 68.7500 (65.2625)  Acc@5: 93.7500 (93.3921)  time: 0.3545  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.5505  Acc@1: 68.7500 (65.3582)  Acc@5: 93.7500 (93.3973)  time: 0.3547  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.5432  Acc@1: 68.7500 (65.3531)  Acc@5: 93.7500 (93.4112)  time: 0.3527  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.6214  Acc@1: 68.7500 (65.3833)  Acc@5: 93.7500 (93.3984)  time: 0.3531  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:46  Lr: 0.001875  Loss: 0.0089  Acc@1: 68.7500 (65.4213)  Acc@5: 93.7500 (93.4033)  time: 0.3531  data: 0.0025  max mem: 2502
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:42  Lr: 0.001875  Loss: -0.5209  Acc@1: 62.5000 (65.3557)  Acc@5: 93.7500 (93.3482)  time: 0.3520  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4427  Acc@1: 62.5000 (65.3509)  Acc@5: 93.7500 (93.3114)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.0848  Acc@1: 62.5000 (65.2963)  Acc@5: 93.7500 (93.3256)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:30  Lr: 0.001875  Loss: 0.2855  Acc@1: 62.5000 (65.2513)  Acc@5: 93.7500 (93.3311)  time: 0.3515  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:26  Lr: 0.001875  Loss: -0.9330  Acc@1: 62.5000 (65.2724)  Acc@5: 93.7500 (93.3123)  time: 0.3517  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:21  Lr: 0.001875  Loss: -0.4070  Acc@1: 68.7500 (65.2449)  Acc@5: 93.7500 (93.3019)  time: 0.3515  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.2036  Acc@1: 68.7500 (65.2339)  Acc@5: 93.7500 (93.2680)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 800/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.9781  Acc@1: 68.7500 (65.3480)  Acc@5: 93.7500 (93.2662)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 810/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.5759  Acc@1: 68.7500 (65.3129)  Acc@5: 100.0000 (93.3338)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 820/1142]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6664  Acc@1: 68.7500 (65.3548)  Acc@5: 93.7500 (93.2932)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 830/1142]  eta: 0:02:01  Lr: 0.001875  Loss: -0.2396  Acc@1: 68.7500 (65.3956)  Acc@5: 93.7500 (93.2912)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:57  Lr: 0.001875  Loss: -0.8012  Acc@1: 68.7500 (65.3835)  Acc@5: 93.7500 (93.2818)  time: 0.3521  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4179  Acc@1: 62.5000 (65.3569)  Acc@5: 93.7500 (93.2800)  time: 0.3538  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6078  Acc@1: 68.7500 (65.4181)  Acc@5: 93.7500 (93.2201)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.4503  Acc@1: 75.0000 (65.5066)  Acc@5: 93.7500 (93.2549)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:41  Lr: 0.001875  Loss: 0.0492  Acc@1: 68.7500 (65.5221)  Acc@5: 93.7500 (93.2818)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:37  Lr: 0.001875  Loss: -0.5568  Acc@1: 62.5000 (65.4882)  Acc@5: 93.7500 (93.2941)  time: 0.3523  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:33  Lr: 0.001875  Loss: -0.5221  Acc@1: 62.5000 (65.4828)  Acc@5: 93.7500 (93.2991)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:29  Lr: 0.001875  Loss: -0.4418  Acc@1: 68.7500 (65.5118)  Acc@5: 93.7500 (93.3315)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1036  Acc@1: 62.5000 (65.4520)  Acc@5: 93.7500 (93.3293)  time: 0.3530  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2637  Acc@1: 62.5000 (65.5209)  Acc@5: 93.7500 (93.3338)  time: 0.3551  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7185  Acc@1: 68.7500 (65.5685)  Acc@5: 93.7500 (93.3581)  time: 0.3544  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:13  Lr: 0.001875  Loss: 0.0177  Acc@1: 68.7500 (65.5560)  Acc@5: 93.7500 (93.3557)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.4819  Acc@1: 68.7500 (65.5177)  Acc@5: 93.7500 (93.3338)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 970/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.2320  Acc@1: 62.5000 (65.5124)  Acc@5: 93.7500 (93.3252)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 980/1142]  eta: 0:01:02  Lr: 0.001875  Loss: -0.2330  Acc@1: 68.7500 (65.5645)  Acc@5: 100.0000 (93.3677)  time: 0.3536  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:58  Lr: 0.001875  Loss: -0.7525  Acc@1: 68.7500 (65.5903)  Acc@5: 93.7500 (93.3653)  time: 0.3568  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6992  Acc@1: 68.7500 (65.5969)  Acc@5: 93.7500 (93.3754)  time: 0.3542  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:50  Lr: 0.001875  Loss: 0.1509  Acc@1: 62.5000 (65.6281)  Acc@5: 93.7500 (93.3667)  time: 0.3535  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.2910  Acc@1: 62.5000 (65.6281)  Acc@5: 93.7500 (93.3582)  time: 0.3540  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.3158  Acc@1: 62.5000 (65.5917)  Acc@5: 93.7500 (93.3802)  time: 0.3519  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:38  Lr: 0.001875  Loss: -0.8067  Acc@1: 62.5000 (65.6400)  Acc@5: 100.0000 (93.4138)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.1070  Acc@1: 68.7500 (65.6458)  Acc@5: 100.0000 (93.4170)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:31  Lr: 0.001875  Loss: -0.9615  Acc@1: 68.7500 (65.6751)  Acc@5: 93.7500 (93.4260)  time: 0.3514  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:27  Lr: 0.001875  Loss: -0.0085  Acc@1: 68.7500 (65.7155)  Acc@5: 93.7500 (93.4349)  time: 0.3519  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:23  Lr: 0.001875  Loss: -0.1280  Acc@1: 68.7500 (65.7840)  Acc@5: 93.7500 (93.4436)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:19  Lr: 0.001875  Loss: -0.7574  Acc@1: 68.7500 (65.8284)  Acc@5: 93.7500 (93.4521)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:15  Lr: 0.001875  Loss: -0.3792  Acc@1: 68.7500 (65.8436)  Acc@5: 93.7500 (93.4435)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:12  Lr: 0.001875  Loss: 0.0858  Acc@1: 68.7500 (65.9091)  Acc@5: 93.7500 (93.4350)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5921  Acc@1: 68.7500 (65.9121)  Acc@5: 93.7500 (93.4489)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.2258  Acc@1: 62.5000 (65.8820)  Acc@5: 93.7500 (93.4571)  time: 0.3514  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4879  Acc@1: 62.5000 (65.8907)  Acc@5: 93.7500 (93.4871)  time: 0.3509  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -1.3823  Acc@1: 62.5000 (65.9075)  Acc@5: 100.0000 (93.4903)  time: 0.3435  data: 0.0006  max mem: 2502
Train: Epoch[3/5] Total time: 0:07:13 (0.3797 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.3823  Acc@1: 62.5000 (65.9075)  Acc@5: 100.0000 (93.4903)
Train: Epoch[4/5]  [   0/1142]  eta: 0:19:18  Lr: 0.001875  Loss: -0.7125  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 1.0147  data: 0.6695  max mem: 2502
Train: Epoch[4/5]  [  10/1142]  eta: 0:07:52  Lr: 0.001875  Loss: -0.2054  Acc@1: 62.5000 (65.9091)  Acc@5: 93.7500 (91.4773)  time: 0.4173  data: 0.0650  max mem: 2502
Train: Epoch[4/5]  [  20/1142]  eta: 0:07:12  Lr: 0.001875  Loss: -0.3506  Acc@1: 68.7500 (69.3452)  Acc@5: 93.7500 (94.3452)  time: 0.3540  data: 0.0026  max mem: 2502
Train: Epoch[4/5]  [  30/1142]  eta: 0:06:56  Lr: 0.001875  Loss: -0.7849  Acc@1: 68.7500 (67.1371)  Acc@5: 100.0000 (92.7419)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  40/1142]  eta: 0:06:46  Lr: 0.001875  Loss: -0.0032  Acc@1: 68.7500 (67.3780)  Acc@5: 93.7500 (92.6829)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  50/1142]  eta: 0:06:38  Lr: 0.001875  Loss: -0.7082  Acc@1: 68.7500 (67.4020)  Acc@5: 93.7500 (92.6471)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [  60/1142]  eta: 0:06:32  Lr: 0.001875  Loss: -0.6018  Acc@1: 62.5000 (65.6762)  Acc@5: 93.7500 (92.8279)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [  70/1142]  eta: 0:06:29  Lr: 0.001875  Loss: -0.4339  Acc@1: 62.5000 (66.1092)  Acc@5: 93.7500 (93.3979)  time: 0.3587  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [  80/1142]  eta: 0:06:24  Lr: 0.001875  Loss: -0.1061  Acc@1: 62.5000 (65.8951)  Acc@5: 100.0000 (93.8272)  time: 0.3573  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.4981  Acc@1: 62.5000 (66.2775)  Acc@5: 100.0000 (94.2308)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:14  Lr: 0.001875  Loss: -0.1790  Acc@1: 68.7500 (66.1510)  Acc@5: 93.7500 (93.9975)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 110/1142]  eta: 0:06:10  Lr: 0.001875  Loss: -0.6337  Acc@1: 68.7500 (66.3851)  Acc@5: 93.7500 (94.0315)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 120/1142]  eta: 0:06:06  Lr: 0.001875  Loss: -0.8715  Acc@1: 68.7500 (66.9421)  Acc@5: 93.7500 (94.3182)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 130/1142]  eta: 0:06:01  Lr: 0.001875  Loss: -0.3231  Acc@1: 68.7500 (66.4122)  Acc@5: 93.7500 (94.1317)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 140/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.9670  Acc@1: 62.5000 (66.6667)  Acc@5: 93.7500 (94.1933)  time: 0.3516  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 150/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.0868  Acc@1: 68.7500 (66.7219)  Acc@5: 93.7500 (94.1225)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 160/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -1.1885  Acc@1: 68.7500 (66.8866)  Acc@5: 93.7500 (94.0217)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 170/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.6329  Acc@1: 68.7500 (67.2880)  Acc@5: 93.7500 (94.2617)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 180/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.4112  Acc@1: 68.7500 (67.5414)  Acc@5: 93.7500 (94.1989)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 190/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.2380  Acc@1: 62.5000 (66.9830)  Acc@5: 93.7500 (94.3063)  time: 0.3521  data: 0.0024  max mem: 2502
Train: Epoch[4/5]  [ 200/1142]  eta: 0:05:34  Lr: 0.001875  Loss: -0.0256  Acc@1: 62.5000 (67.0398)  Acc@5: 100.0000 (94.3719)  time: 0.3507  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 210/1142]  eta: 0:05:30  Lr: 0.001875  Loss: -0.5424  Acc@1: 62.5000 (66.7950)  Acc@5: 93.7500 (94.4017)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 220/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.9705  Acc@1: 62.5000 (66.7986)  Acc@5: 93.7500 (94.3722)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 230/1142]  eta: 0:05:23  Lr: 0.001875  Loss: 0.1352  Acc@1: 68.7500 (66.6937)  Acc@5: 93.7500 (94.2370)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:19  Lr: 0.001875  Loss: -1.0514  Acc@1: 68.7500 (66.8309)  Acc@5: 93.7500 (94.2687)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:15  Lr: 0.001875  Loss: -0.3781  Acc@1: 68.7500 (66.9323)  Acc@5: 93.7500 (94.2978)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.6901  Acc@1: 68.7500 (66.8582)  Acc@5: 93.7500 (94.3247)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:08  Lr: 0.001875  Loss: -0.6159  Acc@1: 68.7500 (66.9742)  Acc@5: 93.7500 (94.2804)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 280/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.7898  Acc@1: 68.7500 (67.0151)  Acc@5: 93.7500 (94.2616)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 290/1142]  eta: 0:05:01  Lr: 0.001875  Loss: -0.3499  Acc@1: 68.7500 (67.1177)  Acc@5: 93.7500 (94.3084)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 300/1142]  eta: 0:04:57  Lr: 0.001875  Loss: -0.0429  Acc@1: 62.5000 (66.8397)  Acc@5: 93.7500 (94.2691)  time: 0.3505  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 310/1142]  eta: 0:04:53  Lr: 0.001875  Loss: -0.1875  Acc@1: 56.2500 (66.5595)  Acc@5: 93.7500 (94.1519)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 320/1142]  eta: 0:04:50  Lr: 0.001875  Loss: -0.3529  Acc@1: 62.5000 (66.5109)  Acc@5: 93.7500 (94.1394)  time: 0.3510  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 330/1142]  eta: 0:04:46  Lr: 0.001875  Loss: -0.3857  Acc@1: 68.7500 (66.5219)  Acc@5: 93.7500 (94.0899)  time: 0.3533  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 340/1142]  eta: 0:04:43  Lr: 0.001875  Loss: -1.0326  Acc@1: 68.7500 (66.6972)  Acc@5: 93.7500 (94.0982)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 350/1142]  eta: 0:04:39  Lr: 0.001875  Loss: -0.1860  Acc@1: 68.7500 (66.8447)  Acc@5: 93.7500 (94.1417)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 360/1142]  eta: 0:04:36  Lr: 0.001875  Loss: 0.2637  Acc@1: 68.7500 (66.8629)  Acc@5: 93.7500 (94.1309)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 370/1142]  eta: 0:04:32  Lr: 0.001875  Loss: -0.4978  Acc@1: 68.7500 (66.8464)  Acc@5: 93.7500 (94.0869)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6056  Acc@1: 68.7500 (66.8143)  Acc@5: 93.7500 (94.1109)  time: 0.3517  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:25  Lr: 0.001875  Loss: 0.0602  Acc@1: 68.7500 (66.8638)  Acc@5: 93.7500 (94.0697)  time: 0.3530  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:21  Lr: 0.001875  Loss: -0.1639  Acc@1: 62.5000 (66.6771)  Acc@5: 93.7500 (93.9994)  time: 0.3523  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:18  Lr: 0.001875  Loss: -0.4299  Acc@1: 68.7500 (66.7883)  Acc@5: 93.7500 (93.9781)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:14  Lr: 0.001875  Loss: -0.9741  Acc@1: 68.7500 (66.6716)  Acc@5: 93.7500 (93.9727)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -0.2587  Acc@1: 62.5000 (66.6618)  Acc@5: 93.7500 (93.9240)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:07  Lr: 0.001875  Loss: -0.0876  Acc@1: 68.7500 (66.8793)  Acc@5: 93.7500 (93.9626)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 450/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.5822  Acc@1: 68.7500 (66.7822)  Acc@5: 100.0000 (94.0133)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 460/1142]  eta: 0:04:00  Lr: 0.001875  Loss: -0.3909  Acc@1: 68.7500 (66.7977)  Acc@5: 93.7500 (93.9805)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 470/1142]  eta: 0:03:56  Lr: 0.001875  Loss: -0.1588  Acc@1: 68.7500 (66.7596)  Acc@5: 93.7500 (93.9225)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 480/1142]  eta: 0:03:53  Lr: 0.001875  Loss: -0.2346  Acc@1: 68.7500 (66.7230)  Acc@5: 93.7500 (93.9449)  time: 0.3492  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 490/1142]  eta: 0:03:49  Lr: 0.001875  Loss: -0.4817  Acc@1: 62.5000 (66.5860)  Acc@5: 93.7500 (93.8900)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 500/1142]  eta: 0:03:46  Lr: 0.001875  Loss: -0.8230  Acc@1: 62.5000 (66.6043)  Acc@5: 93.7500 (93.9122)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 510/1142]  eta: 0:03:42  Lr: 0.001875  Loss: -0.8053  Acc@1: 68.7500 (66.6830)  Acc@5: 100.0000 (93.9335)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 520/1142]  eta: 0:03:39  Lr: 0.001875  Loss: 0.6320  Acc@1: 68.7500 (66.6507)  Acc@5: 93.7500 (93.9060)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 530/1142]  eta: 0:03:35  Lr: 0.001875  Loss: -0.6629  Acc@1: 68.7500 (66.6314)  Acc@5: 93.7500 (93.9501)  time: 0.3543  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:32  Lr: 0.001875  Loss: -0.3293  Acc@1: 68.7500 (66.7398)  Acc@5: 100.0000 (93.9695)  time: 0.3520  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:28  Lr: 0.001875  Loss: -0.2347  Acc@1: 68.7500 (66.7536)  Acc@5: 93.7500 (93.9882)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:25  Lr: 0.001875  Loss: -0.4292  Acc@1: 68.7500 (66.7558)  Acc@5: 93.7500 (93.9283)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:21  Lr: 0.001875  Loss: -0.5790  Acc@1: 62.5000 (66.8017)  Acc@5: 93.7500 (93.9142)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:18  Lr: 0.001875  Loss: 0.2171  Acc@1: 62.5000 (66.8029)  Acc@5: 93.7500 (93.9006)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:14  Lr: 0.001875  Loss: -0.4391  Acc@1: 62.5000 (66.7830)  Acc@5: 93.7500 (93.8981)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.0304  Acc@1: 62.5000 (66.7013)  Acc@5: 93.7500 (93.8956)  time: 0.3528  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:07  Lr: 0.001875  Loss: -0.0449  Acc@1: 62.5000 (66.5917)  Acc@5: 93.7500 (93.8523)  time: 0.3538  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:03  Lr: 0.001875  Loss: -0.0165  Acc@1: 56.2500 (66.5459)  Acc@5: 93.7500 (93.9010)  time: 0.3529  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 630/1142]  eta: 0:03:00  Lr: 0.001875  Loss: -0.0319  Acc@1: 68.7500 (66.5808)  Acc@5: 93.7500 (93.8689)  time: 0.3547  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 640/1142]  eta: 0:02:56  Lr: 0.001875  Loss: -0.4501  Acc@1: 68.7500 (66.5464)  Acc@5: 93.7500 (93.8475)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 650/1142]  eta: 0:02:53  Lr: 0.001875  Loss: -0.3197  Acc@1: 68.7500 (66.5803)  Acc@5: 93.7500 (93.8268)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 660/1142]  eta: 0:02:49  Lr: 0.001875  Loss: 0.0474  Acc@1: 62.5000 (66.3672)  Acc@5: 87.5000 (93.7500)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 670/1142]  eta: 0:02:46  Lr: 0.001875  Loss: -0.4994  Acc@1: 62.5000 (66.4028)  Acc@5: 93.7500 (93.8152)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 680/1142]  eta: 0:02:42  Lr: 0.001875  Loss: -0.4703  Acc@1: 68.7500 (66.5015)  Acc@5: 100.0000 (93.8510)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:39  Lr: 0.001875  Loss: -0.3844  Acc@1: 75.0000 (66.5702)  Acc@5: 93.7500 (93.8585)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:35  Lr: 0.001875  Loss: -0.7855  Acc@1: 75.0000 (66.7350)  Acc@5: 93.7500 (93.8837)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:32  Lr: 0.001875  Loss: -0.6522  Acc@1: 68.7500 (66.7370)  Acc@5: 100.0000 (93.8906)  time: 0.3506  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:28  Lr: 0.001875  Loss: -0.2514  Acc@1: 68.7500 (66.6956)  Acc@5: 93.7500 (93.8887)  time: 0.3522  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:25  Lr: 0.001875  Loss: -0.4450  Acc@1: 68.7500 (66.6809)  Acc@5: 93.7500 (93.8697)  time: 0.3510  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:21  Lr: 0.001875  Loss: -0.9097  Acc@1: 68.7500 (66.7088)  Acc@5: 93.7500 (93.8765)  time: 0.3482  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: 0.1425  Acc@1: 68.7500 (66.6944)  Acc@5: 93.7500 (93.8832)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:14  Lr: 0.001875  Loss: -0.2474  Acc@1: 68.7500 (66.6804)  Acc@5: 93.7500 (93.8321)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4303  Acc@1: 62.5000 (66.6180)  Acc@5: 93.7500 (93.8392)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:07  Lr: 0.001875  Loss: -0.5696  Acc@1: 68.7500 (66.6533)  Acc@5: 93.7500 (93.8300)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.0330  Acc@1: 62.5000 (66.5929)  Acc@5: 93.7500 (93.7816)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 800/1142]  eta: 0:02:00  Lr: 0.001875  Loss: -0.2027  Acc@1: 62.5000 (66.5652)  Acc@5: 93.7500 (93.7734)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.5970  Acc@1: 62.5000 (66.4920)  Acc@5: 93.7500 (93.7423)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 820/1142]  eta: 0:01:53  Lr: 0.001875  Loss: -0.1893  Acc@1: 62.5000 (66.4586)  Acc@5: 87.5000 (93.6891)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.4603  Acc@1: 68.7500 (66.4937)  Acc@5: 93.7500 (93.6974)  time: 0.3509  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:46  Lr: 0.001875  Loss: -0.4948  Acc@1: 68.7500 (66.4611)  Acc@5: 93.7500 (93.6608)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.3645  Acc@1: 62.5000 (66.4733)  Acc@5: 93.7500 (93.6472)  time: 0.3539  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:39  Lr: 0.001875  Loss: -0.4575  Acc@1: 62.5000 (66.4344)  Acc@5: 93.7500 (93.6629)  time: 0.3543  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5711  Acc@1: 68.7500 (66.4753)  Acc@5: 93.7500 (93.6854)  time: 0.3511  data: 0.0023  max mem: 2502
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:32  Lr: 0.001875  Loss: -0.0202  Acc@1: 68.7500 (66.4231)  Acc@5: 93.7500 (93.6791)  time: 0.3518  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.7122  Acc@1: 68.7500 (66.4703)  Acc@5: 93.7500 (93.7009)  time: 0.3548  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1613  Acc@1: 68.7500 (66.4609)  Acc@5: 93.7500 (93.6945)  time: 0.3545  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.1946  Acc@1: 62.5000 (66.4723)  Acc@5: 93.7500 (93.6883)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:18  Lr: 0.001875  Loss: -0.8555  Acc@1: 68.7500 (66.4495)  Acc@5: 93.7500 (93.6414)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5042  Acc@1: 68.7500 (66.4675)  Acc@5: 93.7500 (93.6426)  time: 0.3504  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:11  Lr: 0.001875  Loss: -0.2059  Acc@1: 68.7500 (66.4851)  Acc@5: 93.7500 (93.6437)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.4099  Acc@1: 68.7500 (66.5089)  Acc@5: 93.7500 (93.6514)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6854  Acc@1: 62.5000 (66.4802)  Acc@5: 93.7500 (93.6524)  time: 0.3503  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6201  Acc@1: 68.7500 (66.5615)  Acc@5: 93.7500 (93.6921)  time: 0.3521  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.4013  Acc@1: 68.7500 (66.6030)  Acc@5: 100.0000 (93.7054)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.3915  Acc@1: 68.7500 (66.6498)  Acc@5: 93.7500 (93.7059)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6470  Acc@1: 75.0000 (66.7333)  Acc@5: 93.7500 (93.7000)  time: 0.3523  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.6501  Acc@1: 75.0000 (66.7594)  Acc@5: 93.7500 (93.7191)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.1978  Acc@1: 68.7500 (66.7238)  Acc@5: 93.7500 (93.7010)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.6336  Acc@1: 68.7500 (66.7131)  Acc@5: 93.7500 (93.7015)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.5190  Acc@1: 68.7500 (66.7627)  Acc@5: 93.7500 (93.6960)  time: 0.3521  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.1846  Acc@1: 75.0000 (66.7757)  Acc@5: 93.7500 (93.7143)  time: 0.3521  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1704  Acc@1: 62.5000 (66.7472)  Acc@5: 93.7500 (93.6852)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.1404  Acc@1: 62.5000 (66.7192)  Acc@5: 87.5000 (93.6741)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7985  Acc@1: 68.7500 (66.7669)  Acc@5: 93.7500 (93.6922)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.9484  Acc@1: 62.5000 (66.7621)  Acc@5: 93.7500 (93.6870)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5041  Acc@1: 62.5000 (66.7518)  Acc@5: 93.7500 (93.6876)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.4112  Acc@1: 62.5000 (66.7360)  Acc@5: 93.7500 (93.6656)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0264  Acc@1: 62.5000 (66.7317)  Acc@5: 93.7500 (93.6664)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8633  Acc@1: 68.7500 (66.7606)  Acc@5: 93.7500 (93.6561)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6358  Acc@1: 68.7500 (66.7945)  Acc@5: 93.7500 (93.6788)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6625  Acc@1: 68.7500 (66.7999)  Acc@5: 93.7500 (93.6764)  time: 0.3446  data: 0.0006  max mem: 2502
Train: Epoch[4/5] Total time: 0:06:41 (0.3519 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6625  Acc@1: 68.7500 (66.7999)  Acc@5: 93.7500 (93.6764)
Train: Epoch[5/5]  [   0/1142]  eta: 0:18:46  Lr: 0.001875  Loss: -0.4250  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.9862  data: 0.6350  max mem: 2502
Train: Epoch[5/5]  [  10/1142]  eta: 0:07:43  Lr: 0.001875  Loss: -0.3939  Acc@1: 68.7500 (64.7727)  Acc@5: 93.7500 (92.0455)  time: 0.4095  data: 0.0583  max mem: 2502
Train: Epoch[5/5]  [  20/1142]  eta: 0:07:07  Lr: 0.001875  Loss: -0.1964  Acc@1: 68.7500 (66.9643)  Acc@5: 93.7500 (92.8571)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  30/1142]  eta: 0:06:54  Lr: 0.001875  Loss: 0.3643  Acc@1: 68.7500 (67.3387)  Acc@5: 93.7500 (92.5403)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [  40/1142]  eta: 0:06:44  Lr: 0.001875  Loss: -0.2321  Acc@1: 68.7500 (66.6159)  Acc@5: 93.7500 (92.9878)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [  50/1142]  eta: 0:06:38  Lr: 0.001875  Loss: -0.5818  Acc@1: 68.7500 (67.4020)  Acc@5: 93.7500 (93.2598)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  60/1142]  eta: 0:06:31  Lr: 0.001875  Loss: -0.7524  Acc@1: 68.7500 (67.3156)  Acc@5: 93.7500 (93.3402)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [  70/1142]  eta: 0:06:26  Lr: 0.001875  Loss: -1.0805  Acc@1: 68.7500 (68.3099)  Acc@5: 93.7500 (93.5739)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [  80/1142]  eta: 0:06:21  Lr: 0.001875  Loss: -0.3634  Acc@1: 68.7500 (67.9012)  Acc@5: 93.7500 (93.7500)  time: 0.3492  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:16  Lr: 0.001875  Loss: -0.8340  Acc@1: 68.7500 (68.2005)  Acc@5: 93.7500 (93.8187)  time: 0.3502  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:12  Lr: 0.001875  Loss: -0.4205  Acc@1: 68.7500 (68.0693)  Acc@5: 93.7500 (93.7500)  time: 0.3519  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 110/1142]  eta: 0:06:08  Lr: 0.001875  Loss: -0.4563  Acc@1: 68.7500 (67.3986)  Acc@5: 93.7500 (93.6374)  time: 0.3522  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 120/1142]  eta: 0:06:04  Lr: 0.001875  Loss: -0.0733  Acc@1: 62.5000 (66.8388)  Acc@5: 93.7500 (93.5434)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 130/1142]  eta: 0:06:00  Lr: 0.001875  Loss: -0.0011  Acc@1: 62.5000 (66.7462)  Acc@5: 93.7500 (93.5115)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 140/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.3106  Acc@1: 62.5000 (67.1099)  Acc@5: 93.7500 (93.5284)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 150/1142]  eta: 0:05:52  Lr: 0.001875  Loss: -0.4547  Acc@1: 68.7500 (66.9288)  Acc@5: 93.7500 (93.5017)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 160/1142]  eta: 0:05:48  Lr: 0.001875  Loss: -0.1942  Acc@1: 62.5000 (66.6149)  Acc@5: 87.5000 (93.3618)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 170/1142]  eta: 0:05:44  Lr: 0.001875  Loss: -0.6979  Acc@1: 62.5000 (66.6301)  Acc@5: 93.7500 (93.4211)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 180/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6936  Acc@1: 68.7500 (66.4019)  Acc@5: 93.7500 (93.3011)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 190/1142]  eta: 0:05:37  Lr: 0.001875  Loss: -0.9421  Acc@1: 68.7500 (66.4267)  Acc@5: 93.7500 (93.3901)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 200/1142]  eta: 0:05:33  Lr: 0.001875  Loss: 0.0076  Acc@1: 68.7500 (66.2624)  Acc@5: 93.7500 (93.2836)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 210/1142]  eta: 0:05:29  Lr: 0.001875  Loss: -0.7891  Acc@1: 68.7500 (66.7062)  Acc@5: 93.7500 (93.3353)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 220/1142]  eta: 0:05:25  Lr: 0.001875  Loss: -0.3260  Acc@1: 68.7500 (66.7421)  Acc@5: 93.7500 (93.4672)  time: 0.3493  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:22  Lr: 0.001875  Loss: -0.4164  Acc@1: 68.7500 (67.0455)  Acc@5: 100.0000 (93.5606)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:18  Lr: 0.001875  Loss: -0.4589  Acc@1: 68.7500 (67.0124)  Acc@5: 93.7500 (93.5685)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:15  Lr: 0.001875  Loss: -0.1717  Acc@1: 62.5000 (66.8078)  Acc@5: 93.7500 (93.5259)  time: 0.3514  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:11  Lr: 0.001875  Loss: -0.1309  Acc@1: 68.7500 (66.8822)  Acc@5: 93.7500 (93.5584)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:07  Lr: 0.001875  Loss: -0.7329  Acc@1: 75.0000 (67.1356)  Acc@5: 93.7500 (93.6577)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 280/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.4293  Acc@1: 75.0000 (67.4155)  Acc@5: 100.0000 (93.7722)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 290/1142]  eta: 0:05:00  Lr: 0.001875  Loss: -0.5662  Acc@1: 75.0000 (67.4399)  Acc@5: 93.7500 (93.6641)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 300/1142]  eta: 0:04:56  Lr: 0.001875  Loss: -0.5439  Acc@1: 68.7500 (67.5664)  Acc@5: 93.7500 (93.6462)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 310/1142]  eta: 0:04:53  Lr: 0.001875  Loss: -0.5966  Acc@1: 68.7500 (67.5844)  Acc@5: 93.7500 (93.6093)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 320/1142]  eta: 0:04:49  Lr: 0.001875  Loss: -0.3841  Acc@1: 68.7500 (67.4650)  Acc@5: 93.7500 (93.5748)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 330/1142]  eta: 0:04:46  Lr: 0.001875  Loss: -0.6022  Acc@1: 62.5000 (67.4660)  Acc@5: 93.7500 (93.6745)  time: 0.3518  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 340/1142]  eta: 0:04:42  Lr: 0.001875  Loss: -0.5251  Acc@1: 68.7500 (67.4487)  Acc@5: 93.7500 (93.6950)  time: 0.3532  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 350/1142]  eta: 0:04:39  Lr: 0.001875  Loss: -0.1481  Acc@1: 68.7500 (67.3967)  Acc@5: 93.7500 (93.6254)  time: 0.3529  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 360/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.4444  Acc@1: 68.7500 (67.4688)  Acc@5: 93.7500 (93.6807)  time: 0.3528  data: 0.0021  max mem: 2502
Train: Epoch[5/5]  [ 370/1142]  eta: 0:04:32  Lr: 0.001875  Loss: -0.5889  Acc@1: 68.7500 (67.5539)  Acc@5: 93.7500 (93.7163)  time: 0.3516  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:28  Lr: 0.001875  Loss: -0.5916  Acc@1: 68.7500 (67.5361)  Acc@5: 93.7500 (93.6844)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:25  Lr: 0.001875  Loss: -0.8247  Acc@1: 68.7500 (67.6471)  Acc@5: 93.7500 (93.7500)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:21  Lr: 0.001875  Loss: -0.2300  Acc@1: 68.7500 (67.6901)  Acc@5: 93.7500 (93.7188)  time: 0.3533  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:17  Lr: 0.001875  Loss: -0.4547  Acc@1: 62.5000 (67.5791)  Acc@5: 93.7500 (93.7044)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:14  Lr: 0.001875  Loss: -0.4155  Acc@1: 62.5000 (67.5475)  Acc@5: 100.0000 (93.7945)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:10  Lr: 0.001875  Loss: -0.7328  Acc@1: 68.7500 (67.6479)  Acc@5: 100.0000 (93.7935)  time: 0.3516  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:07  Lr: 0.001875  Loss: -0.3608  Acc@1: 68.7500 (67.6729)  Acc@5: 93.7500 (93.7500)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 450/1142]  eta: 0:04:03  Lr: 0.001875  Loss: -0.4018  Acc@1: 62.5000 (67.5028)  Acc@5: 93.7500 (93.7361)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 460/1142]  eta: 0:04:00  Lr: 0.001875  Loss: -0.7322  Acc@1: 62.5000 (67.3536)  Acc@5: 93.7500 (93.7636)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 470/1142]  eta: 0:03:56  Lr: 0.001875  Loss: -0.4105  Acc@1: 62.5000 (67.3301)  Acc@5: 93.7500 (93.7500)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 480/1142]  eta: 0:03:53  Lr: 0.001875  Loss: -0.1074  Acc@1: 62.5000 (67.3467)  Acc@5: 93.7500 (93.7240)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 490/1142]  eta: 0:03:49  Lr: 0.001875  Loss: -0.6736  Acc@1: 68.7500 (67.3880)  Acc@5: 93.7500 (93.7373)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 500/1142]  eta: 0:03:45  Lr: 0.001875  Loss: -0.2790  Acc@1: 62.5000 (67.3029)  Acc@5: 93.7500 (93.7375)  time: 0.3516  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 510/1142]  eta: 0:03:42  Lr: 0.001875  Loss: -0.5521  Acc@1: 62.5000 (67.3190)  Acc@5: 93.7500 (93.7011)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -1.0672  Acc@1: 68.7500 (67.3824)  Acc@5: 93.7500 (93.7020)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 530/1142]  eta: 0:03:35  Lr: 0.001875  Loss: -0.1771  Acc@1: 75.0000 (67.4435)  Acc@5: 93.7500 (93.7147)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6780  Acc@1: 68.7500 (67.4445)  Acc@5: 93.7500 (93.7269)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:28  Lr: 0.001875  Loss: -0.7751  Acc@1: 62.5000 (67.4229)  Acc@5: 93.7500 (93.7160)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.4643  Acc@1: 68.7500 (67.4799)  Acc@5: 93.7500 (93.7834)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:21  Lr: 0.001875  Loss: -0.6616  Acc@1: 68.7500 (67.4365)  Acc@5: 93.7500 (93.7609)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:17  Lr: 0.001875  Loss: -0.4025  Acc@1: 62.5000 (67.4269)  Acc@5: 93.7500 (93.7500)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:14  Lr: 0.001875  Loss: -0.1886  Acc@1: 62.5000 (67.3752)  Acc@5: 93.7500 (93.7288)  time: 0.3531  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.0114  Acc@1: 62.5000 (67.2837)  Acc@5: 93.7500 (93.6876)  time: 0.3540  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0295  Acc@1: 62.5000 (67.1543)  Acc@5: 93.7500 (93.6784)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:03  Lr: 0.001875  Loss: -0.3787  Acc@1: 68.7500 (67.2001)  Acc@5: 93.7500 (93.6393)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 630/1142]  eta: 0:03:00  Lr: 0.001875  Loss: 0.2050  Acc@1: 75.0000 (67.3138)  Acc@5: 93.7500 (93.6708)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 640/1142]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7612  Acc@1: 75.0000 (67.3362)  Acc@5: 93.7500 (93.7110)  time: 0.3561  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 650/1142]  eta: 0:02:53  Lr: 0.001875  Loss: -1.0979  Acc@1: 68.7500 (67.3867)  Acc@5: 93.7500 (93.7308)  time: 0.3539  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 660/1142]  eta: 0:02:49  Lr: 0.001875  Loss: -0.3331  Acc@1: 68.7500 (67.3884)  Acc@5: 93.7500 (93.7405)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 670/1142]  eta: 0:02:46  Lr: 0.001875  Loss: -0.3047  Acc@1: 68.7500 (67.3994)  Acc@5: 93.7500 (93.7779)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 680/1142]  eta: 0:02:42  Lr: 0.001875  Loss: -0.7609  Acc@1: 68.7500 (67.4009)  Acc@5: 93.7500 (93.7408)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:39  Lr: 0.001875  Loss: -0.8317  Acc@1: 68.7500 (67.3842)  Acc@5: 93.7500 (93.7681)  time: 0.3528  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6594  Acc@1: 68.7500 (67.4840)  Acc@5: 100.0000 (93.8213)  time: 0.3514  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:32  Lr: 0.001875  Loss: -0.5136  Acc@1: 75.0000 (67.5281)  Acc@5: 93.7500 (93.8203)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:28  Lr: 0.001875  Loss: -0.5403  Acc@1: 68.7500 (67.5104)  Acc@5: 93.7500 (93.8193)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.2277  Acc@1: 62.5000 (67.4248)  Acc@5: 93.7500 (93.8269)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:21  Lr: 0.001875  Loss: -0.5098  Acc@1: 62.5000 (67.3583)  Acc@5: 93.7500 (93.8512)  time: 0.3545  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.0368  Acc@1: 68.7500 (67.4101)  Acc@5: 93.7500 (93.8582)  time: 0.3524  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5419  Acc@1: 75.0000 (67.4277)  Acc@5: 93.7500 (93.8732)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.6910  Acc@1: 68.7500 (67.4935)  Acc@5: 93.7500 (93.9040)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6189  Acc@1: 68.7500 (67.5096)  Acc@5: 93.7500 (93.9181)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.2805  Acc@1: 68.7500 (67.5016)  Acc@5: 93.7500 (93.9001)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 800/1142]  eta: 0:02:00  Lr: 0.001875  Loss: -0.3071  Acc@1: 62.5000 (67.4547)  Acc@5: 93.7500 (93.8983)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.2327  Acc@1: 68.7500 (67.4861)  Acc@5: 93.7500 (93.9118)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 820/1142]  eta: 0:01:53  Lr: 0.001875  Loss: -0.3107  Acc@1: 68.7500 (67.4939)  Acc@5: 93.7500 (93.8794)  time: 0.3496  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.1433  Acc@1: 68.7500 (67.5015)  Acc@5: 93.7500 (93.8553)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:46  Lr: 0.001875  Loss: -0.6177  Acc@1: 68.7500 (67.4866)  Acc@5: 93.7500 (93.8466)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.3609  Acc@1: 68.7500 (67.5749)  Acc@5: 93.7500 (93.8528)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:39  Lr: 0.001875  Loss: -0.6380  Acc@1: 68.7500 (67.5813)  Acc@5: 93.7500 (93.8589)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5294  Acc@1: 68.7500 (67.5875)  Acc@5: 93.7500 (93.8792)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7517  Acc@1: 68.7500 (67.6007)  Acc@5: 93.7500 (93.8777)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.1978  Acc@1: 62.5000 (67.5084)  Acc@5: 93.7500 (93.8833)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:25  Lr: 0.001875  Loss: 0.1240  Acc@1: 62.5000 (67.5291)  Acc@5: 93.7500 (93.8749)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.1907  Acc@1: 68.7500 (67.4945)  Acc@5: 93.7500 (93.8666)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4569  Acc@1: 68.7500 (67.5149)  Acc@5: 93.7500 (93.8586)  time: 0.3529  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7666  Acc@1: 68.7500 (67.5148)  Acc@5: 93.7500 (93.8574)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:11  Lr: 0.001875  Loss: -0.4004  Acc@1: 68.7500 (67.5545)  Acc@5: 93.7500 (93.8496)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7200  Acc@1: 68.7500 (67.5868)  Acc@5: 93.7500 (93.8683)  time: 0.3512  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: 0.0706  Acc@1: 68.7500 (67.5663)  Acc@5: 93.7500 (93.8736)  time: 0.3503  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.2747  Acc@1: 62.5000 (67.5528)  Acc@5: 93.7500 (93.8787)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.2215  Acc@1: 68.7500 (67.5522)  Acc@5: 93.7500 (93.8902)  time: 0.3545  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.2009  Acc@1: 62.5000 (67.4634)  Acc@5: 93.7500 (93.8509)  time: 0.3517  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1759  Acc@1: 62.5000 (67.4388)  Acc@5: 93.7500 (93.8499)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.0465  Acc@1: 68.7500 (67.4271)  Acc@5: 93.7500 (93.8056)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.5702  Acc@1: 68.7500 (67.4645)  Acc@5: 93.7500 (93.8235)  time: 0.3523  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.2122  Acc@1: 68.7500 (67.4891)  Acc@5: 93.7500 (93.8046)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.0822  Acc@1: 68.7500 (67.4772)  Acc@5: 87.5000 (93.7860)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.6628  Acc@1: 68.7500 (67.4715)  Acc@5: 87.5000 (93.7500)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.5273  Acc@1: 68.7500 (67.4776)  Acc@5: 93.7500 (93.7559)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.1868  Acc@1: 68.7500 (67.5012)  Acc@5: 93.7500 (93.7617)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0372  Acc@1: 68.7500 (67.4549)  Acc@5: 93.7500 (93.7789)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.5372  Acc@1: 68.7500 (67.4897)  Acc@5: 93.7500 (93.7443)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7357  Acc@1: 75.0000 (67.5465)  Acc@5: 93.7500 (93.7841)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.5918  Acc@1: 75.0000 (67.5911)  Acc@5: 100.0000 (93.8063)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4865  Acc@1: 75.0000 (67.6517)  Acc@5: 93.7500 (93.8169)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.3928  Acc@1: 68.7500 (67.6503)  Acc@5: 93.7500 (93.8163)  time: 0.3511  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0085  Acc@1: 68.7500 (67.6490)  Acc@5: 93.7500 (93.8157)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9294  Acc@1: 68.7500 (67.6595)  Acc@5: 93.7500 (93.8188)  time: 0.3435  data: 0.0006  max mem: 2502
Train: Epoch[5/5] Total time: 0:06:41 (0.3517 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.9294  Acc@1: 68.7500 (67.6595)  Acc@5: 93.7500 (93.8188)
Test: [Task 1]  [   0/1627]  eta: 0:21:02  Loss: 1.5711 (1.5711)  Acc@1: 50.0000 (50.0000)  Acc@5: 87.5000 (87.5000)  time: 0.7762  data: 0.5548  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:07:20  Loss: 1.2642 (1.2174)  Acc@1: 62.5000 (64.7727)  Acc@5: 93.7500 (93.1818)  time: 0.2722  data: 0.0514  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:34  Loss: 1.1731 (1.1779)  Acc@1: 68.7500 (67.8571)  Acc@5: 93.7500 (91.3690)  time: 0.2191  data: 0.0007  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:18  Loss: 1.1731 (1.1782)  Acc@1: 68.7500 (68.1452)  Acc@5: 93.7500 (91.7339)  time: 0.2175  data: 0.0011  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:06:08  Loss: 1.2123 (1.1842)  Acc@1: 62.5000 (68.1402)  Acc@5: 93.7500 (92.0732)  time: 0.2177  data: 0.0012  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:06:01  Loss: 0.9966 (1.1648)  Acc@1: 68.7500 (69.1176)  Acc@5: 93.7500 (92.2794)  time: 0.2173  data: 0.0007  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:55  Loss: 1.1129 (1.1784)  Acc@1: 68.7500 (68.9549)  Acc@5: 93.7500 (92.0082)  time: 0.2170  data: 0.0006  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:51  Loss: 1.0512 (1.1756)  Acc@1: 68.7500 (68.6620)  Acc@5: 93.7500 (92.3415)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:48  Loss: 0.9974 (1.1578)  Acc@1: 75.0000 (68.9815)  Acc@5: 93.7500 (92.3611)  time: 0.2185  data: 0.0007  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:44  Loss: 1.0625 (1.1761)  Acc@1: 68.7500 (68.4753)  Acc@5: 93.7500 (92.1016)  time: 0.2190  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:41  Loss: 1.4105 (1.2030)  Acc@1: 62.5000 (67.9455)  Acc@5: 87.5000 (91.5223)  time: 0.2174  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:38  Loss: 1.1968 (1.2016)  Acc@1: 62.5000 (67.3986)  Acc@5: 93.7500 (92.1171)  time: 0.2186  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:35  Loss: 1.1579 (1.1980)  Acc@1: 68.7500 (67.9752)  Acc@5: 93.7500 (92.2004)  time: 0.2192  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:32  Loss: 1.2337 (1.2048)  Acc@1: 68.7500 (67.6050)  Acc@5: 93.7500 (92.0324)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:29  Loss: 1.1477 (1.2037)  Acc@1: 62.5000 (67.3759)  Acc@5: 93.7500 (91.9770)  time: 0.2163  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:27  Loss: 0.9037 (1.1881)  Acc@1: 68.7500 (67.9222)  Acc@5: 93.7500 (92.1772)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:24  Loss: 0.8718 (1.1799)  Acc@1: 75.0000 (68.3230)  Acc@5: 93.7500 (92.3137)  time: 0.2180  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:22  Loss: 1.1224 (1.1759)  Acc@1: 68.7500 (68.3480)  Acc@5: 93.7500 (92.2515)  time: 0.2193  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:20  Loss: 1.1691 (1.1819)  Acc@1: 62.5000 (68.0594)  Acc@5: 93.7500 (92.1961)  time: 0.2199  data: 0.0028  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:17  Loss: 1.1760 (1.1782)  Acc@1: 68.7500 (68.1937)  Acc@5: 93.7500 (92.1793)  time: 0.2188  data: 0.0022  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:14  Loss: 1.1613 (1.1765)  Acc@1: 68.7500 (68.3147)  Acc@5: 93.7500 (92.2575)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:12  Loss: 1.1078 (1.1760)  Acc@1: 68.7500 (68.4834)  Acc@5: 93.7500 (92.3282)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:10  Loss: 1.0942 (1.1788)  Acc@1: 75.0000 (68.4955)  Acc@5: 93.7500 (92.2794)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:07  Loss: 1.0942 (1.1730)  Acc@1: 75.0000 (68.8041)  Acc@5: 93.7500 (92.3701)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:05  Loss: 1.0661 (1.1679)  Acc@1: 75.0000 (68.9315)  Acc@5: 93.7500 (92.4274)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:05:02  Loss: 0.9975 (1.1701)  Acc@1: 68.7500 (69.0488)  Acc@5: 93.7500 (92.3805)  time: 0.2177  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:05:00  Loss: 1.1246 (1.1705)  Acc@1: 68.7500 (69.0374)  Acc@5: 93.7500 (92.3851)  time: 0.2176  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:58  Loss: 1.0606 (1.1643)  Acc@1: 68.7500 (69.0498)  Acc@5: 93.7500 (92.5277)  time: 0.2172  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:55  Loss: 1.0197 (1.1640)  Acc@1: 68.7500 (69.0169)  Acc@5: 93.7500 (92.4155)  time: 0.2166  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:53  Loss: 1.1379 (1.1634)  Acc@1: 68.7500 (69.1151)  Acc@5: 93.7500 (92.3969)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:51  Loss: 1.1354 (1.1633)  Acc@1: 68.7500 (69.1653)  Acc@5: 93.7500 (92.4211)  time: 0.2181  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:49  Loss: 1.0536 (1.1657)  Acc@1: 68.7500 (68.9912)  Acc@5: 93.7500 (92.4236)  time: 0.2182  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:46  Loss: 1.1453 (1.1656)  Acc@1: 62.5000 (68.8474)  Acc@5: 93.7500 (92.4650)  time: 0.2177  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:44  Loss: 1.0536 (1.1631)  Acc@1: 68.7500 (68.9388)  Acc@5: 93.7500 (92.4849)  time: 0.2175  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:42  Loss: 0.9955 (1.1631)  Acc@1: 68.7500 (68.9150)  Acc@5: 93.7500 (92.5403)  time: 0.2166  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:39  Loss: 1.0557 (1.1647)  Acc@1: 75.0000 (68.9815)  Acc@5: 93.7500 (92.4501)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:37  Loss: 1.0557 (1.1629)  Acc@1: 75.0000 (68.9578)  Acc@5: 93.7500 (92.3996)  time: 0.2166  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:35  Loss: 1.0425 (1.1620)  Acc@1: 62.5000 (68.8679)  Acc@5: 93.7500 (92.4360)  time: 0.2171  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:33  Loss: 1.0563 (1.1610)  Acc@1: 68.7500 (68.9469)  Acc@5: 93.7500 (92.3720)  time: 0.2177  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:30  Loss: 1.0563 (1.1621)  Acc@1: 75.0000 (68.9738)  Acc@5: 93.7500 (92.3593)  time: 0.2185  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:28  Loss: 1.0409 (1.1628)  Acc@1: 68.7500 (68.8903)  Acc@5: 93.7500 (92.3628)  time: 0.2178  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:26  Loss: 1.0232 (1.1622)  Acc@1: 68.7500 (68.9933)  Acc@5: 93.7500 (92.3206)  time: 0.2172  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:24  Loss: 1.1036 (1.1612)  Acc@1: 75.0000 (69.0024)  Acc@5: 93.7500 (92.3694)  time: 0.2175  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:22  Loss: 1.0622 (1.1595)  Acc@1: 68.7500 (68.9820)  Acc@5: 93.7500 (92.4449)  time: 0.2176  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:19  Loss: 1.1993 (1.1598)  Acc@1: 62.5000 (68.9342)  Acc@5: 93.7500 (92.4603)  time: 0.2183  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:17  Loss: 1.2417 (1.1634)  Acc@1: 62.5000 (68.6946)  Acc@5: 93.7500 (92.3365)  time: 0.2174  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:15  Loss: 1.2503 (1.1634)  Acc@1: 56.2500 (68.7229)  Acc@5: 93.7500 (92.3536)  time: 0.2195  data: 0.0021  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:13  Loss: 1.1108 (1.1616)  Acc@1: 68.7500 (68.7633)  Acc@5: 93.7500 (92.3567)  time: 0.2214  data: 0.0023  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:11  Loss: 1.1720 (1.1658)  Acc@1: 62.5000 (68.6071)  Acc@5: 93.7500 (92.3077)  time: 0.2187  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:08  Loss: 1.2189 (1.1658)  Acc@1: 62.5000 (68.5973)  Acc@5: 93.7500 (92.3371)  time: 0.2180  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:06  Loss: 1.1341 (1.1669)  Acc@1: 68.7500 (68.6003)  Acc@5: 93.7500 (92.3154)  time: 0.2183  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:04  Loss: 1.2603 (1.1733)  Acc@1: 62.5000 (68.3953)  Acc@5: 87.5000 (92.3068)  time: 0.2179  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:04:02  Loss: 1.3037 (1.1801)  Acc@1: 62.5000 (68.3541)  Acc@5: 87.5000 (92.2505)  time: 0.2199  data: 0.0020  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:04:00  Loss: 1.1631 (1.1767)  Acc@1: 68.7500 (68.4793)  Acc@5: 93.7500 (92.2905)  time: 0.2208  data: 0.0027  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:58  Loss: 1.0871 (1.1773)  Acc@1: 68.7500 (68.5074)  Acc@5: 93.7500 (92.2597)  time: 0.2204  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:55  Loss: 1.3180 (1.1800)  Acc@1: 68.7500 (68.4324)  Acc@5: 93.7500 (92.2414)  time: 0.2202  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:53  Loss: 1.3246 (1.1823)  Acc@1: 62.5000 (68.3601)  Acc@5: 93.7500 (92.2237)  time: 0.2180  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:51  Loss: 1.1698 (1.1794)  Acc@1: 68.7500 (68.4216)  Acc@5: 93.7500 (92.2395)  time: 0.2168  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:49  Loss: 1.1196 (1.1798)  Acc@1: 68.7500 (68.3950)  Acc@5: 93.7500 (92.2547)  time: 0.2172  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:46  Loss: 1.1826 (1.1794)  Acc@1: 68.7500 (68.4116)  Acc@5: 93.7500 (92.3118)  time: 0.2184  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:44  Loss: 1.1988 (1.1814)  Acc@1: 68.7500 (68.3652)  Acc@5: 93.7500 (92.2733)  time: 0.2201  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:42  Loss: 1.1686 (1.1796)  Acc@1: 68.7500 (68.4227)  Acc@5: 93.7500 (92.3077)  time: 0.2211  data: 0.0021  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:40  Loss: 1.0852 (1.1813)  Acc@1: 68.7500 (68.3776)  Acc@5: 93.7500 (92.2806)  time: 0.2192  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:38  Loss: 1.0542 (1.1810)  Acc@1: 68.7500 (68.4628)  Acc@5: 93.7500 (92.2841)  time: 0.2177  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 1.0303 (1.1803)  Acc@1: 75.0000 (68.5062)  Acc@5: 93.7500 (92.2777)  time: 0.2184  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:33  Loss: 1.0403 (1.1794)  Acc@1: 75.0000 (68.5580)  Acc@5: 93.7500 (92.3003)  time: 0.2186  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:31  Loss: 1.0765 (1.1777)  Acc@1: 75.0000 (68.6082)  Acc@5: 93.7500 (92.3033)  time: 0.2172  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:29  Loss: 1.1696 (1.1775)  Acc@1: 68.7500 (68.6010)  Acc@5: 93.7500 (92.2876)  time: 0.2164  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:27  Loss: 1.1696 (1.1768)  Acc@1: 68.7500 (68.6307)  Acc@5: 93.7500 (92.2632)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 1.1489 (1.1748)  Acc@1: 75.0000 (68.6957)  Acc@5: 93.7500 (92.3209)  time: 0.2184  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:22  Loss: 1.1489 (1.1741)  Acc@1: 75.0000 (68.7767)  Acc@5: 93.7500 (92.3680)  time: 0.2186  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:20  Loss: 1.0270 (1.1717)  Acc@1: 75.0000 (68.8555)  Acc@5: 93.7500 (92.4051)  time: 0.2169  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:18  Loss: 0.9476 (1.1706)  Acc@1: 75.0000 (68.8367)  Acc@5: 93.7500 (92.4150)  time: 0.2165  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:16  Loss: 1.1354 (1.1712)  Acc@1: 68.7500 (68.8269)  Acc@5: 93.7500 (92.4162)  time: 0.2167  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:13  Loss: 1.1712 (1.1720)  Acc@1: 68.7500 (68.8090)  Acc@5: 93.7500 (92.4173)  time: 0.2168  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:11  Loss: 1.1655 (1.1709)  Acc@1: 68.7500 (68.8998)  Acc@5: 93.7500 (92.4351)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:09  Loss: 1.1723 (1.1740)  Acc@1: 68.7500 (68.8075)  Acc@5: 93.7500 (92.3702)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:07  Loss: 1.0126 (1.1706)  Acc@1: 75.0000 (68.9527)  Acc@5: 93.7500 (92.4125)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:05  Loss: 0.9385 (1.1689)  Acc@1: 75.0000 (69.0301)  Acc@5: 93.7500 (92.4296)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:02  Loss: 1.0091 (1.1709)  Acc@1: 68.7500 (69.0345)  Acc@5: 93.7500 (92.3673)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:03:00  Loss: 1.1158 (1.1694)  Acc@1: 68.7500 (69.0465)  Acc@5: 93.7500 (92.3923)  time: 0.2156  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:58  Loss: 1.0263 (1.1687)  Acc@1: 75.0000 (69.0968)  Acc@5: 93.7500 (92.4168)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:56  Loss: 1.0113 (1.1677)  Acc@1: 75.0000 (69.1382)  Acc@5: 100.0000 (92.4482)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:54  Loss: 1.0113 (1.1669)  Acc@1: 68.7500 (69.1261)  Acc@5: 100.0000 (92.4639)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:51  Loss: 0.9314 (1.1644)  Acc@1: 75.0000 (69.1810)  Acc@5: 93.7500 (92.5089)  time: 0.2188  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:49  Loss: 1.1896 (1.1658)  Acc@1: 62.5000 (69.1099)  Acc@5: 93.7500 (92.4941)  time: 0.2193  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:47  Loss: 1.1136 (1.1648)  Acc@1: 62.5000 (69.1202)  Acc@5: 93.7500 (92.5305)  time: 0.2181  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:45  Loss: 1.0619 (1.1635)  Acc@1: 68.7500 (69.1447)  Acc@5: 93.7500 (92.5373)  time: 0.2184  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:43  Loss: 1.1584 (1.1657)  Acc@1: 68.7500 (69.0692)  Acc@5: 93.7500 (92.5440)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 1.2624 (1.1681)  Acc@1: 62.5000 (69.0236)  Acc@5: 93.7500 (92.5295)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:38  Loss: 1.2159 (1.1682)  Acc@1: 62.5000 (69.0136)  Acc@5: 93.7500 (92.5291)  time: 0.2177  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:36  Loss: 1.2181 (1.1694)  Acc@1: 68.7500 (69.0244)  Acc@5: 93.7500 (92.4671)  time: 0.2188  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:34  Loss: 1.1649 (1.1693)  Acc@1: 68.7500 (69.0214)  Acc@5: 93.7500 (92.4674)  time: 0.2184  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:32  Loss: 1.0773 (1.1702)  Acc@1: 68.7500 (69.0320)  Acc@5: 93.7500 (92.4409)  time: 0.2195  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 1.0913 (1.1686)  Acc@1: 68.7500 (69.0755)  Acc@5: 93.7500 (92.4748)  time: 0.2208  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:27  Loss: 1.1888 (1.1698)  Acc@1: 62.5000 (69.0063)  Acc@5: 93.7500 (92.4816)  time: 0.2193  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:25  Loss: 1.1582 (1.1692)  Acc@1: 62.5000 (69.0101)  Acc@5: 93.7500 (92.4753)  time: 0.2191  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:23  Loss: 1.0426 (1.1682)  Acc@1: 68.7500 (69.0332)  Acc@5: 93.7500 (92.4627)  time: 0.2195  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:21  Loss: 1.0919 (1.1682)  Acc@1: 68.7500 (69.0112)  Acc@5: 93.7500 (92.4822)  time: 0.2178  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 1.2076 (1.1711)  Acc@1: 68.7500 (68.9707)  Acc@5: 93.7500 (92.4571)  time: 0.2167  data: 0.0005  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:16  Loss: 1.2292 (1.1714)  Acc@1: 68.7500 (68.9685)  Acc@5: 87.5000 (92.4013)  time: 0.2171  data: 0.0005  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:14  Loss: 1.1594 (1.1711)  Acc@1: 68.7500 (68.9849)  Acc@5: 87.5000 (92.4023)  time: 0.2210  data: 0.0017  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:12  Loss: 1.1090 (1.1706)  Acc@1: 75.0000 (68.9949)  Acc@5: 93.7500 (92.4155)  time: 0.2213  data: 0.0018  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:10  Loss: 0.9793 (1.1688)  Acc@1: 75.0000 (69.0470)  Acc@5: 93.7500 (92.4527)  time: 0.2173  data: 0.0006  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 0.8690 (1.1669)  Acc@1: 75.0000 (69.1042)  Acc@5: 100.0000 (92.4832)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 1.0074 (1.1654)  Acc@1: 75.0000 (69.1663)  Acc@5: 93.7500 (92.4952)  time: 0.2174  data: 0.0005  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:03  Loss: 1.1784 (1.1660)  Acc@1: 68.7500 (69.1565)  Acc@5: 93.7500 (92.4776)  time: 0.2185  data: 0.0008  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:01  Loss: 1.2287 (1.1665)  Acc@1: 68.7500 (69.1527)  Acc@5: 93.7500 (92.4603)  time: 0.2209  data: 0.0020  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:59  Loss: 1.1574 (1.1673)  Acc@1: 68.7500 (69.1721)  Acc@5: 93.7500 (92.4549)  time: 0.2264  data: 0.0023  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 1.1574 (1.1674)  Acc@1: 68.7500 (69.1911)  Acc@5: 93.7500 (92.4610)  time: 0.2231  data: 0.0010  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 1.0208 (1.1654)  Acc@1: 75.0000 (69.2439)  Acc@5: 100.0000 (92.4955)  time: 0.2166  data: 0.0004  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 0.9917 (1.1655)  Acc@1: 75.0000 (69.2394)  Acc@5: 100.0000 (92.4899)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:50  Loss: 1.1980 (1.1670)  Acc@1: 62.5000 (69.1905)  Acc@5: 93.7500 (92.4900)  time: 0.2172  data: 0.0004  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:48  Loss: 1.1127 (1.1676)  Acc@1: 62.5000 (69.1700)  Acc@5: 93.7500 (92.4735)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 1.1387 (1.1686)  Acc@1: 68.7500 (69.1389)  Acc@5: 93.7500 (92.4408)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 1.2761 (1.1691)  Acc@1: 68.7500 (69.1247)  Acc@5: 93.7500 (92.4414)  time: 0.2162  data: 0.0007  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 1.1428 (1.1680)  Acc@1: 68.7500 (69.1860)  Acc@5: 93.7500 (92.4419)  time: 0.2167  data: 0.0011  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:39  Loss: 1.0644 (1.1669)  Acc@1: 75.0000 (69.2143)  Acc@5: 93.7500 (92.4637)  time: 0.2169  data: 0.0008  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:37  Loss: 1.1536 (1.1674)  Acc@1: 75.0000 (69.2210)  Acc@5: 93.7500 (92.4693)  time: 0.2174  data: 0.0008  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 1.2017 (1.1682)  Acc@1: 68.7500 (69.1803)  Acc@5: 93.7500 (92.4486)  time: 0.2172  data: 0.0008  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 1.1963 (1.1682)  Acc@1: 68.7500 (69.1819)  Acc@5: 93.7500 (92.4438)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 1.0360 (1.1689)  Acc@1: 68.7500 (69.1319)  Acc@5: 93.7500 (92.4030)  time: 0.2181  data: 0.0008  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 0.9850 (1.1677)  Acc@1: 68.7500 (69.1544)  Acc@5: 93.7500 (92.4140)  time: 0.2182  data: 0.0013  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 1.1040 (1.1682)  Acc@1: 68.7500 (69.1409)  Acc@5: 93.7500 (92.4096)  time: 0.2171  data: 0.0009  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 1.1858 (1.1681)  Acc@1: 68.7500 (69.1277)  Acc@5: 93.7500 (92.3952)  time: 0.2168  data: 0.0005  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 1.2968 (1.1686)  Acc@1: 68.7500 (69.1247)  Acc@5: 93.7500 (92.3961)  time: 0.2174  data: 0.0005  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 1.1725 (1.1685)  Acc@1: 68.7500 (69.1168)  Acc@5: 93.7500 (92.4068)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.0729 (1.1693)  Acc@1: 62.5000 (69.0893)  Acc@5: 93.7500 (92.3830)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 1.0548 (1.1677)  Acc@1: 68.7500 (69.1159)  Acc@5: 87.5000 (92.3936)  time: 0.2193  data: 0.0006  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 1.0801 (1.1679)  Acc@1: 68.7500 (69.0840)  Acc@5: 93.7500 (92.3993)  time: 0.2208  data: 0.0012  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 1.0801 (1.1674)  Acc@1: 68.7500 (69.1007)  Acc@5: 93.7500 (92.4145)  time: 0.2189  data: 0.0010  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 0.9900 (1.1662)  Acc@1: 75.0000 (69.1600)  Acc@5: 93.7500 (92.4294)  time: 0.2191  data: 0.0022  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 0.8726 (1.1646)  Acc@1: 75.0000 (69.2373)  Acc@5: 93.7500 (92.4442)  time: 0.2184  data: 0.0022  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.9473 (1.1643)  Acc@1: 68.7500 (69.2384)  Acc@5: 93.7500 (92.4352)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.0931 (1.1647)  Acc@1: 68.7500 (69.2394)  Acc@5: 93.7500 (92.4357)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 1.0277 (1.1639)  Acc@1: 75.0000 (69.2681)  Acc@5: 93.7500 (92.4500)  time: 0.2176  data: 0.0009  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 1.0304 (1.1633)  Acc@1: 75.0000 (69.2643)  Acc@5: 93.7500 (92.4642)  time: 0.2192  data: 0.0015  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 1.0304 (1.1626)  Acc@1: 68.7500 (69.2378)  Acc@5: 93.7500 (92.4827)  time: 0.2194  data: 0.0011  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.0842 (1.1629)  Acc@1: 62.5000 (69.2026)  Acc@5: 93.7500 (92.4783)  time: 0.2184  data: 0.0007  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.2557 (1.1625)  Acc@1: 68.7500 (69.2173)  Acc@5: 93.7500 (92.4919)  time: 0.2225  data: 0.0023  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.1439 (1.1627)  Acc@1: 68.7500 (69.2318)  Acc@5: 93.7500 (92.4741)  time: 0.2231  data: 0.0021  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.9644 (1.1621)  Acc@1: 81.2500 (69.2727)  Acc@5: 93.7500 (92.4876)  time: 0.2177  data: 0.0004  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.0749 (1.1615)  Acc@1: 75.0000 (69.2778)  Acc@5: 93.7500 (92.5053)  time: 0.2162  data: 0.0003  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.2724 (1.1633)  Acc@1: 68.7500 (69.2654)  Acc@5: 93.7500 (92.4703)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1685 (1.1628)  Acc@1: 68.7500 (69.2618)  Acc@5: 93.7500 (92.4705)  time: 0.2173  data: 0.0005  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.2134 (1.1642)  Acc@1: 68.7500 (69.2109)  Acc@5: 93.7500 (92.4406)  time: 0.2181  data: 0.0005  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.2808 (1.1647)  Acc@1: 68.7500 (69.1863)  Acc@5: 93.7500 (92.4410)  time: 0.2203  data: 0.0005  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.2155 (1.1651)  Acc@1: 68.7500 (69.1791)  Acc@5: 93.7500 (92.4329)  time: 0.2199  data: 0.0005  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 1.2155 (1.1655)  Acc@1: 68.7500 (69.1762)  Acc@5: 93.7500 (92.4249)  time: 0.2178  data: 0.0006  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.1753 (1.1659)  Acc@1: 68.7500 (69.1608)  Acc@5: 87.5000 (92.4212)  time: 0.2179  data: 0.0009  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.1114 (1.1660)  Acc@1: 68.7500 (69.1706)  Acc@5: 87.5000 (92.4051)  time: 0.2182  data: 0.0015  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.9416 (1.1658)  Acc@1: 68.7500 (69.1760)  Acc@5: 93.7500 (92.4016)  time: 0.2204  data: 0.0021  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.9762 (1.1646)  Acc@1: 68.7500 (69.2061)  Acc@5: 93.7500 (92.4227)  time: 0.2211  data: 0.0021  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.9762 (1.1641)  Acc@1: 68.7500 (69.1827)  Acc@5: 100.0000 (92.4396)  time: 0.2197  data: 0.0014  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 0.9711 (1.1633)  Acc@1: 68.7500 (69.1961)  Acc@5: 100.0000 (92.4603)  time: 0.2188  data: 0.0008  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.9927 (1.1630)  Acc@1: 68.7500 (69.1852)  Acc@5: 100.0000 (92.4686)  time: 0.2184  data: 0.0005  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.9927 (1.1620)  Acc@1: 68.7500 (69.2225)  Acc@5: 93.7500 (92.4888)  time: 0.2192  data: 0.0005  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.0563 (1.1617)  Acc@1: 75.0000 (69.2393)  Acc@5: 93.7500 (92.5048)  time: 0.2182  data: 0.0004  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.0748 (1.1621)  Acc@1: 68.7500 (69.2283)  Acc@5: 93.7500 (92.5047)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.0768 (1.1618)  Acc@1: 68.7500 (69.2293)  Acc@5: 93.7500 (92.5283)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.1478 (1.1628)  Acc@1: 62.5000 (69.1560)  Acc@5: 93.7500 (92.5047)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.2138 (1.1622)  Acc@1: 62.5000 (69.1651)  Acc@5: 93.7500 (92.5163)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.9625 (1.1612)  Acc@1: 68.7500 (69.1973)  Acc@5: 93.7500 (92.5316)  time: 0.2175  data: 0.0004  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9643 (1.1607)  Acc@1: 68.7500 (69.2187)  Acc@5: 93.7500 (92.5284)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 1] Total time: 0:05:55 (0.2187 s / it)
* Acc@1 69.219 Acc@5 92.528 loss 1.161
Test: [Task 2]  [  0/625]  eta: 0:07:08  Loss: 0.1659 (0.1659)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6864  data: 0.4621  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:39  Loss: 0.1949 (0.2428)  Acc@1: 93.7500 (95.4545)  Acc@5: 100.0000 (99.4318)  time: 0.2594  data: 0.0425  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:25  Loss: 0.1949 (0.2484)  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (99.7024)  time: 0.2177  data: 0.0005  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:19  Loss: 0.1999 (0.2712)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (99.1935)  time: 0.2197  data: 0.0006  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:14  Loss: 0.2778 (0.2708)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.2378)  time: 0.2186  data: 0.0005  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:10  Loss: 0.2778 (0.2819)  Acc@1: 93.7500 (93.6275)  Acc@5: 100.0000 (99.1422)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:07  Loss: 0.2456 (0.2821)  Acc@1: 93.7500 (93.3402)  Acc@5: 100.0000 (99.0779)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:04  Loss: 0.2273 (0.2780)  Acc@1: 93.7500 (93.3099)  Acc@5: 100.0000 (99.2077)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:01  Loss: 0.2644 (0.2853)  Acc@1: 93.7500 (93.2870)  Acc@5: 100.0000 (99.0741)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 0.2595 (0.2797)  Acc@1: 93.7500 (93.4753)  Acc@5: 100.0000 (99.1758)  time: 0.2170  data: 0.0010  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:56  Loss: 0.2281 (0.2784)  Acc@1: 93.7500 (93.5025)  Acc@5: 100.0000 (99.1955)  time: 0.2185  data: 0.0017  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 0.1767 (0.2758)  Acc@1: 93.7500 (93.6374)  Acc@5: 100.0000 (99.2117)  time: 0.2179  data: 0.0012  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:51  Loss: 0.2194 (0.2756)  Acc@1: 93.7500 (93.6983)  Acc@5: 100.0000 (99.2252)  time: 0.2194  data: 0.0008  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 0.2516 (0.2772)  Acc@1: 93.7500 (93.6546)  Acc@5: 100.0000 (99.2844)  time: 0.2195  data: 0.0008  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 0.2250 (0.2795)  Acc@1: 93.7500 (93.4397)  Acc@5: 100.0000 (99.2908)  time: 0.2204  data: 0.0014  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 0.2358 (0.2853)  Acc@1: 93.7500 (93.1705)  Acc@5: 100.0000 (99.2550)  time: 0.2216  data: 0.0013  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 0.2459 (0.2884)  Acc@1: 93.7500 (93.1677)  Acc@5: 100.0000 (99.1460)  time: 0.2181  data: 0.0004  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 0.2737 (0.2896)  Acc@1: 93.7500 (93.1287)  Acc@5: 100.0000 (99.1594)  time: 0.2214  data: 0.0018  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 0.2737 (0.2898)  Acc@1: 93.7500 (93.1285)  Acc@5: 100.0000 (99.1713)  time: 0.2230  data: 0.0019  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:36  Loss: 0.2696 (0.2917)  Acc@1: 93.7500 (93.0955)  Acc@5: 100.0000 (99.1492)  time: 0.2190  data: 0.0005  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 0.2465 (0.2896)  Acc@1: 93.7500 (93.1592)  Acc@5: 100.0000 (99.1604)  time: 0.2177  data: 0.0005  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 0.2465 (0.2910)  Acc@1: 93.7500 (93.1280)  Acc@5: 100.0000 (99.1706)  time: 0.2185  data: 0.0005  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 0.2273 (0.2889)  Acc@1: 93.7500 (93.2410)  Acc@5: 100.0000 (99.1516)  time: 0.2196  data: 0.0005  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:27  Loss: 0.2273 (0.2878)  Acc@1: 93.7500 (93.3442)  Acc@5: 100.0000 (99.1613)  time: 0.2185  data: 0.0007  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 0.3069 (0.2897)  Acc@1: 93.7500 (93.3351)  Acc@5: 100.0000 (99.1701)  time: 0.2176  data: 0.0006  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 0.3162 (0.2925)  Acc@1: 93.7500 (93.1524)  Acc@5: 100.0000 (99.1285)  time: 0.2191  data: 0.0015  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 0.3162 (0.2947)  Acc@1: 93.7500 (93.1513)  Acc@5: 100.0000 (99.1379)  time: 0.2194  data: 0.0015  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 0.2998 (0.2946)  Acc@1: 93.7500 (93.1273)  Acc@5: 100.0000 (99.1467)  time: 0.2182  data: 0.0004  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:16  Loss: 0.2998 (0.2965)  Acc@1: 93.7500 (93.0160)  Acc@5: 100.0000 (99.1103)  time: 0.2182  data: 0.0005  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 0.2521 (0.2962)  Acc@1: 93.7500 (92.9768)  Acc@5: 100.0000 (99.1194)  time: 0.2182  data: 0.0005  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 0.2521 (0.2956)  Acc@1: 93.7500 (92.9610)  Acc@5: 100.0000 (99.1487)  time: 0.2206  data: 0.0026  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 0.2594 (0.2966)  Acc@1: 93.7500 (92.9059)  Acc@5: 100.0000 (99.1359)  time: 0.2223  data: 0.0045  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 0.1349 (0.2900)  Acc@1: 93.7500 (93.0880)  Acc@5: 100.0000 (99.1628)  time: 0.2212  data: 0.0028  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.1083 (0.2856)  Acc@1: 100.0000 (93.2402)  Acc@5: 100.0000 (99.1881)  time: 0.2190  data: 0.0009  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.0820 (0.2790)  Acc@1: 100.0000 (93.4384)  Acc@5: 100.0000 (99.2119)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.0619 (0.2750)  Acc@1: 100.0000 (93.5007)  Acc@5: 100.0000 (99.2343)  time: 0.2202  data: 0.0009  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 0.1735 (0.2763)  Acc@1: 93.7500 (93.4730)  Acc@5: 100.0000 (99.2382)  time: 0.2189  data: 0.0009  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 0.1904 (0.2730)  Acc@1: 93.7500 (93.5647)  Acc@5: 100.0000 (99.2588)  time: 0.2184  data: 0.0005  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2286 (0.2756)  Acc@1: 93.7500 (93.5367)  Acc@5: 100.0000 (99.1798)  time: 0.2184  data: 0.0005  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.2286 (0.2746)  Acc@1: 93.7500 (93.5102)  Acc@5: 100.0000 (99.1528)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.0766 (0.2703)  Acc@1: 100.0000 (93.6253)  Acc@5: 100.0000 (99.1739)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 0.0730 (0.2683)  Acc@1: 100.0000 (93.7044)  Acc@5: 100.0000 (99.1484)  time: 0.2180  data: 0.0004  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 0.1026 (0.2673)  Acc@1: 93.7500 (93.7203)  Acc@5: 100.0000 (99.1686)  time: 0.2180  data: 0.0004  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.1116 (0.2651)  Acc@1: 93.7500 (93.7935)  Acc@5: 100.0000 (99.1879)  time: 0.2180  data: 0.0004  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.0716 (0.2606)  Acc@1: 100.0000 (93.9342)  Acc@5: 100.0000 (99.2063)  time: 0.2183  data: 0.0004  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.0716 (0.2575)  Acc@1: 100.0000 (93.9579)  Acc@5: 100.0000 (99.2239)  time: 0.2188  data: 0.0012  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 0.0906 (0.2543)  Acc@1: 100.0000 (94.0483)  Acc@5: 100.0000 (99.2408)  time: 0.2180  data: 0.0012  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 0.1159 (0.2521)  Acc@1: 100.0000 (94.1215)  Acc@5: 100.0000 (99.2569)  time: 0.2171  data: 0.0004  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1478 (0.2507)  Acc@1: 100.0000 (94.1918)  Acc@5: 100.0000 (99.2723)  time: 0.2175  data: 0.0004  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1424 (0.2483)  Acc@1: 100.0000 (94.2846)  Acc@5: 100.0000 (99.2872)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1174 (0.2465)  Acc@1: 100.0000 (94.3363)  Acc@5: 100.0000 (99.3014)  time: 0.2180  data: 0.0004  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.1680 (0.2476)  Acc@1: 93.7500 (94.2515)  Acc@5: 100.0000 (99.2906)  time: 0.2183  data: 0.0005  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 0.1743 (0.2472)  Acc@1: 93.7500 (94.2778)  Acc@5: 100.0000 (99.3042)  time: 0.2181  data: 0.0006  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1465 (0.2451)  Acc@1: 100.0000 (94.3267)  Acc@5: 100.0000 (99.3173)  time: 0.2192  data: 0.0005  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1034 (0.2432)  Acc@1: 100.0000 (94.4085)  Acc@5: 100.0000 (99.3299)  time: 0.2205  data: 0.0011  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0660 (0.2399)  Acc@1: 100.0000 (94.4986)  Acc@5: 100.0000 (99.3421)  time: 0.2196  data: 0.0010  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0466 (0.2368)  Acc@1: 100.0000 (94.5633)  Acc@5: 100.0000 (99.3538)  time: 0.2190  data: 0.0007  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 0.0668 (0.2358)  Acc@1: 100.0000 (94.5709)  Acc@5: 100.0000 (99.3651)  time: 0.2213  data: 0.0024  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.0895 (0.2337)  Acc@1: 100.0000 (94.6106)  Acc@5: 100.0000 (99.3761)  time: 0.2220  data: 0.0021  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1396 (0.2326)  Acc@1: 93.7500 (94.5960)  Acc@5: 100.0000 (99.3866)  time: 0.2203  data: 0.0009  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1470 (0.2327)  Acc@1: 93.7500 (94.5819)  Acc@5: 100.0000 (99.3968)  time: 0.2195  data: 0.0008  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2841 (0.2361)  Acc@1: 93.7500 (94.4456)  Acc@5: 100.0000 (99.3658)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.2915 (0.2364)  Acc@1: 93.7500 (94.4545)  Acc@5: 100.0000 (99.3760)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2460 (0.2360)  Acc@1: 93.7500 (94.4700)  Acc@5: 100.0000 (99.3800)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 2] Total time: 0:02:17 (0.2200 s / it)
* Acc@1 94.470 Acc@5 99.380 loss 0.236
Test: [Task 3]  [  0/625]  eta: 0:07:16  Loss: 0.2518 (0.2518)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6991  data: 0.4769  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:43  Loss: 0.2518 (0.2649)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (99.4318)  time: 0.2666  data: 0.0450  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:27  Loss: 0.2076 (0.2657)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (99.4048)  time: 0.2207  data: 0.0011  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:20  Loss: 0.2104 (0.2588)  Acc@1: 93.7500 (95.7661)  Acc@5: 100.0000 (99.3952)  time: 0.2185  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:15  Loss: 0.1465 (0.2298)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.5427)  time: 0.2190  data: 0.0006  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:11  Loss: 0.1268 (0.2249)  Acc@1: 100.0000 (96.6912)  Acc@5: 100.0000 (99.3873)  time: 0.2190  data: 0.0006  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:08  Loss: 0.1976 (0.2178)  Acc@1: 100.0000 (96.9262)  Acc@5: 100.0000 (99.4877)  time: 0.2197  data: 0.0017  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:05  Loss: 0.1392 (0.2063)  Acc@1: 100.0000 (97.0951)  Acc@5: 100.0000 (99.4718)  time: 0.2203  data: 0.0032  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:02  Loss: 0.1308 (0.2097)  Acc@1: 100.0000 (96.9907)  Acc@5: 100.0000 (99.4599)  time: 0.2189  data: 0.0020  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:02:00  Loss: 0.1608 (0.2104)  Acc@1: 100.0000 (96.9093)  Acc@5: 100.0000 (99.4505)  time: 0.2179  data: 0.0004  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:57  Loss: 0.1646 (0.2062)  Acc@1: 100.0000 (97.0916)  Acc@5: 100.0000 (99.5050)  time: 0.2179  data: 0.0004  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:55  Loss: 0.1646 (0.2007)  Acc@1: 100.0000 (97.2973)  Acc@5: 100.0000 (99.5495)  time: 0.2175  data: 0.0005  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:52  Loss: 0.1846 (0.2025)  Acc@1: 100.0000 (97.2107)  Acc@5: 100.0000 (99.5868)  time: 0.2194  data: 0.0009  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:50  Loss: 0.1769 (0.2018)  Acc@1: 100.0000 (97.2805)  Acc@5: 100.0000 (99.6183)  time: 0.2211  data: 0.0009  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:48  Loss: 0.1769 (0.2069)  Acc@1: 100.0000 (97.0745)  Acc@5: 100.0000 (99.5124)  time: 0.2199  data: 0.0007  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:45  Loss: 0.2034 (0.2103)  Acc@1: 93.7500 (96.9785)  Acc@5: 100.0000 (99.5033)  time: 0.2198  data: 0.0014  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:43  Loss: 0.1733 (0.2124)  Acc@1: 93.7500 (96.8944)  Acc@5: 100.0000 (99.4565)  time: 0.2200  data: 0.0015  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:41  Loss: 0.1502 (0.2116)  Acc@1: 100.0000 (96.9298)  Acc@5: 100.0000 (99.4883)  time: 0.2181  data: 0.0007  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:38  Loss: 0.2452 (0.2155)  Acc@1: 93.7500 (96.8577)  Acc@5: 100.0000 (99.4475)  time: 0.2172  data: 0.0004  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:36  Loss: 0.1797 (0.2137)  Acc@1: 93.7500 (96.8586)  Acc@5: 100.0000 (99.4437)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:34  Loss: 0.2009 (0.2175)  Acc@1: 93.7500 (96.7973)  Acc@5: 100.0000 (99.4403)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:31  Loss: 0.1992 (0.2195)  Acc@1: 100.0000 (96.7417)  Acc@5: 100.0000 (99.4076)  time: 0.2170  data: 0.0004  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:29  Loss: 0.1684 (0.2210)  Acc@1: 100.0000 (96.6912)  Acc@5: 100.0000 (99.4061)  time: 0.2169  data: 0.0005  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:27  Loss: 0.1902 (0.2208)  Acc@1: 100.0000 (96.6991)  Acc@5: 100.0000 (99.4048)  time: 0.2173  data: 0.0010  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:24  Loss: 0.1619 (0.2229)  Acc@1: 93.7500 (96.6286)  Acc@5: 100.0000 (99.3776)  time: 0.2184  data: 0.0022  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:22  Loss: 0.1625 (0.2209)  Acc@1: 93.7500 (96.6384)  Acc@5: 100.0000 (99.4024)  time: 0.2179  data: 0.0016  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:20  Loss: 0.1591 (0.2188)  Acc@1: 100.0000 (96.7193)  Acc@5: 100.0000 (99.4013)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.1335 (0.2182)  Acc@1: 100.0000 (96.6790)  Acc@5: 100.0000 (99.4004)  time: 0.2170  data: 0.0011  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:15  Loss: 0.1822 (0.2173)  Acc@1: 100.0000 (96.6859)  Acc@5: 100.0000 (99.3995)  time: 0.2179  data: 0.0014  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:13  Loss: 0.1834 (0.2183)  Acc@1: 100.0000 (96.6710)  Acc@5: 100.0000 (99.3986)  time: 0.2188  data: 0.0008  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.1811 (0.2229)  Acc@1: 100.0000 (96.5324)  Acc@5: 100.0000 (99.3355)  time: 0.2194  data: 0.0005  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:09  Loss: 0.1546 (0.2249)  Acc@1: 100.0000 (96.4831)  Acc@5: 100.0000 (99.2765)  time: 0.2184  data: 0.0007  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.1834 (0.2244)  Acc@1: 93.7500 (96.4953)  Acc@5: 100.0000 (99.2601)  time: 0.2174  data: 0.0007  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:04  Loss: 0.1933 (0.2250)  Acc@1: 93.7500 (96.4502)  Acc@5: 100.0000 (99.2636)  time: 0.2177  data: 0.0005  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:02  Loss: 0.1660 (0.2232)  Acc@1: 100.0000 (96.4993)  Acc@5: 100.0000 (99.2669)  time: 0.2182  data: 0.0004  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.1543 (0.2238)  Acc@1: 100.0000 (96.4744)  Acc@5: 100.0000 (99.2521)  time: 0.2175  data: 0.0004  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.2153 (0.2245)  Acc@1: 93.7500 (96.4162)  Acc@5: 100.0000 (99.2555)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.2153 (0.2251)  Acc@1: 93.7500 (96.3780)  Acc@5: 100.0000 (99.2419)  time: 0.2166  data: 0.0004  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.1998 (0.2238)  Acc@1: 93.7500 (96.4075)  Acc@5: 100.0000 (99.2618)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.1692 (0.2247)  Acc@1: 100.0000 (96.3555)  Acc@5: 100.0000 (99.2807)  time: 0.2159  data: 0.0005  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.1756 (0.2239)  Acc@1: 100.0000 (96.3529)  Acc@5: 100.0000 (99.2830)  time: 0.2163  data: 0.0007  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.1879 (0.2247)  Acc@1: 100.0000 (96.3352)  Acc@5: 100.0000 (99.2853)  time: 0.2177  data: 0.0006  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.1825 (0.2245)  Acc@1: 93.7500 (96.3331)  Acc@5: 100.0000 (99.2874)  time: 0.2185  data: 0.0012  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1631 (0.2242)  Acc@1: 100.0000 (96.3312)  Acc@5: 100.0000 (99.2749)  time: 0.2190  data: 0.0025  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.1847 (0.2255)  Acc@1: 100.0000 (96.2868)  Acc@5: 100.0000 (99.2630)  time: 0.2192  data: 0.0019  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.2017 (0.2253)  Acc@1: 100.0000 (96.2999)  Acc@5: 100.0000 (99.2655)  time: 0.2170  data: 0.0007  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.1374 (0.2245)  Acc@1: 100.0000 (96.3124)  Acc@5: 100.0000 (99.2679)  time: 0.2162  data: 0.0005  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1537 (0.2243)  Acc@1: 93.7500 (96.2712)  Acc@5: 100.0000 (99.2702)  time: 0.2187  data: 0.0005  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1800 (0.2249)  Acc@1: 93.7500 (96.2968)  Acc@5: 100.0000 (99.2723)  time: 0.2191  data: 0.0005  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2105 (0.2251)  Acc@1: 100.0000 (96.3086)  Acc@5: 100.0000 (99.2617)  time: 0.2192  data: 0.0026  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.1958 (0.2244)  Acc@1: 93.7500 (96.2949)  Acc@5: 100.0000 (99.2764)  time: 0.2190  data: 0.0026  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.1255 (0.2239)  Acc@1: 100.0000 (96.3185)  Acc@5: 100.0000 (99.2906)  time: 0.2216  data: 0.0023  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.2054 (0.2239)  Acc@1: 100.0000 (96.3292)  Acc@5: 100.0000 (99.3042)  time: 0.2224  data: 0.0024  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.2054 (0.2246)  Acc@1: 100.0000 (96.3159)  Acc@5: 100.0000 (99.3173)  time: 0.2171  data: 0.0005  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2304 (0.2255)  Acc@1: 100.0000 (96.3031)  Acc@5: 100.0000 (99.3068)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.1965 (0.2262)  Acc@1: 100.0000 (96.3135)  Acc@5: 100.0000 (99.2854)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2033 (0.2262)  Acc@1: 100.0000 (96.3124)  Acc@5: 100.0000 (99.2981)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.2033 (0.2256)  Acc@1: 93.7500 (96.3332)  Acc@5: 100.0000 (99.2995)  time: 0.2183  data: 0.0012  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.1547 (0.2268)  Acc@1: 93.7500 (96.2672)  Acc@5: 100.0000 (99.3008)  time: 0.2228  data: 0.0012  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1667 (0.2261)  Acc@1: 100.0000 (96.3198)  Acc@5: 100.0000 (99.3126)  time: 0.2215  data: 0.0004  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1696 (0.2257)  Acc@1: 100.0000 (96.3290)  Acc@5: 100.0000 (99.3032)  time: 0.2189  data: 0.0010  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1875 (0.2252)  Acc@1: 100.0000 (96.3482)  Acc@5: 100.0000 (99.3044)  time: 0.2182  data: 0.0010  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2049 (0.2260)  Acc@1: 100.0000 (96.3366)  Acc@5: 100.0000 (99.3056)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1735 (0.2255)  Acc@1: 100.0000 (96.3600)  Acc@5: 100.0000 (99.3100)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 3] Total time: 0:02:17 (0.2195 s / it)
* Acc@1 96.360 Acc@5 99.310 loss 0.225
Test: [Task 4]  [ 0/29]  eta: 0:00:20  Loss: 2.4410 (2.4410)  Acc@1: 18.7500 (18.7500)  Acc@5: 81.2500 (81.2500)  time: 0.6995  data: 0.4811  max mem: 2502
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 1.9244 (2.0286)  Acc@1: 56.2500 (46.0227)  Acc@5: 81.2500 (81.2500)  time: 0.2599  data: 0.0441  max mem: 2502
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.8287 (1.8710)  Acc@1: 56.2500 (53.8690)  Acc@5: 81.2500 (80.9524)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.5077 (1.7048)  Acc@1: 63.6364 (59.2593)  Acc@5: 81.2500 (82.5708)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 4] Total time: 0:00:06 (0.2413 s / it)
* Acc@1 59.259 Acc@5 82.571 loss 1.705
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 176, 5: 176, 6: 176, 7: 176, 8: 0, 9: 0, 10: 0, 11: 0, 12: 283, 13: 283, 14: 283, 15: 283, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task4]	Acc@1: 79.8270	Acc@5: 93.4473	Loss: 0.8317	Forgetting: 5.8426	Backward: -5.8426
Train: Epoch[1/5]  [   0/3750]  eta: 1:02:14  Lr: 0.001875  Loss: 2.2920  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  time: 0.9960  data: 0.5771  max mem: 2502
Train: Epoch[1/5]  [  10/3750]  eta: 0:25:19  Lr: 0.001875  Loss: 2.0411  Acc@1: 25.0000 (21.0227)  Acc@5: 68.7500 (63.6364)  time: 0.4062  data: 0.0529  max mem: 2503
Train: Epoch[1/5]  [  20/3750]  eta: 0:23:31  Lr: 0.001875  Loss: 1.9583  Acc@1: 25.0000 (25.5952)  Acc@5: 81.2500 (73.8095)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:55  Lr: 0.001875  Loss: 1.8489  Acc@1: 37.5000 (30.6452)  Acc@5: 87.5000 (79.8387)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:33  Lr: 0.001875  Loss: 1.5149  Acc@1: 43.7500 (35.5183)  Acc@5: 93.7500 (83.0793)  time: 0.3504  data: 0.0026  max mem: 2503
Train: Epoch[1/5]  [  50/3750]  eta: 0:22:18  Lr: 0.001875  Loss: 1.0959  Acc@1: 56.2500 (40.8088)  Acc@5: 93.7500 (85.0490)  time: 0.3497  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [  60/3750]  eta: 0:22:06  Lr: 0.001875  Loss: 1.0645  Acc@1: 68.7500 (45.4918)  Acc@5: 93.7500 (86.7828)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:58  Lr: 0.001875  Loss: 1.2529  Acc@1: 68.7500 (48.1514)  Acc@5: 93.7500 (87.9401)  time: 0.3498  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:52  Lr: 0.001875  Loss: 0.8272  Acc@1: 62.5000 (50.1543)  Acc@5: 93.7500 (88.8117)  time: 0.3520  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:45  Lr: 0.001875  Loss: 0.9773  Acc@1: 62.5000 (51.5110)  Acc@5: 93.7500 (89.4918)  time: 0.3500  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:39  Lr: 0.001875  Loss: 1.0299  Acc@1: 62.5000 (52.9084)  Acc@5: 93.7500 (89.9752)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:34  Lr: 0.001875  Loss: 0.5561  Acc@1: 62.5000 (54.1104)  Acc@5: 93.7500 (90.6532)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:29  Lr: 0.001875  Loss: 0.6154  Acc@1: 62.5000 (55.0103)  Acc@5: 100.0000 (91.1674)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:24  Lr: 0.001875  Loss: 0.7333  Acc@1: 62.5000 (56.1546)  Acc@5: 93.7500 (91.6031)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:19  Lr: 0.001875  Loss: 0.5232  Acc@1: 68.7500 (57.1809)  Acc@5: 100.0000 (91.9770)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:15  Lr: 0.001875  Loss: 0.2320  Acc@1: 68.7500 (57.8228)  Acc@5: 93.7500 (92.2599)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:10  Lr: 0.001875  Loss: 0.5359  Acc@1: 62.5000 (58.0357)  Acc@5: 100.0000 (92.6242)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 170/3750]  eta: 0:21:06  Lr: 0.001875  Loss: 0.6362  Acc@1: 68.7500 (58.6623)  Acc@5: 100.0000 (92.8728)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 180/3750]  eta: 0:21:03  Lr: 0.001875  Loss: 0.3771  Acc@1: 68.7500 (59.4959)  Acc@5: 100.0000 (92.9903)  time: 0.3538  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 190/3750]  eta: 0:21:00  Lr: 0.001875  Loss: 0.3975  Acc@1: 68.7500 (60.1440)  Acc@5: 93.7500 (93.0955)  time: 0.3556  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:55  Lr: 0.001875  Loss: 0.4814  Acc@1: 68.7500 (60.6654)  Acc@5: 100.0000 (93.4080)  time: 0.3519  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:51  Lr: 0.001875  Loss: 0.3159  Acc@1: 62.5000 (60.7524)  Acc@5: 100.0000 (93.5723)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:47  Lr: 0.001875  Loss: 0.3772  Acc@1: 62.5000 (60.9729)  Acc@5: 100.0000 (93.8348)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:43  Lr: 0.001875  Loss: 0.5020  Acc@1: 62.5000 (61.0660)  Acc@5: 100.0000 (93.9394)  time: 0.3512  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:40  Lr: 0.001875  Loss: 0.3152  Acc@1: 62.5000 (61.3589)  Acc@5: 100.0000 (94.0353)  time: 0.3547  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:37  Lr: 0.001875  Loss: 0.0659  Acc@1: 68.7500 (61.8277)  Acc@5: 93.7500 (94.0986)  time: 0.3546  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:33  Lr: 0.001875  Loss: 0.1462  Acc@1: 75.0000 (62.3803)  Acc@5: 93.7500 (94.2050)  time: 0.3521  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:29  Lr: 0.001875  Loss: 0.2739  Acc@1: 68.7500 (62.5923)  Acc@5: 93.7500 (94.2574)  time: 0.3512  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:25  Lr: 0.001875  Loss: 0.4747  Acc@1: 68.7500 (62.9004)  Acc@5: 93.7500 (94.3728)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.0261  Acc@1: 68.7500 (63.1229)  Acc@5: 100.0000 (94.5232)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:17  Lr: 0.001875  Loss: 0.3695  Acc@1: 75.0000 (63.4967)  Acc@5: 100.0000 (94.6221)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:14  Lr: 0.001875  Loss: 0.7957  Acc@1: 75.0000 (63.5852)  Acc@5: 100.0000 (94.6945)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.0650  Acc@1: 75.0000 (63.9408)  Acc@5: 100.0000 (94.7625)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 330/3750]  eta: 0:20:06  Lr: 0.001875  Loss: 0.3365  Acc@1: 68.7500 (64.0106)  Acc@5: 100.0000 (94.8263)  time: 0.3525  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [ 340/3750]  eta: 0:20:03  Lr: 0.001875  Loss: 0.0210  Acc@1: 68.7500 (64.0029)  Acc@5: 100.0000 (94.9413)  time: 0.3533  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.1402  Acc@1: 68.7500 (64.1560)  Acc@5: 100.0000 (95.0499)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:55  Lr: 0.001875  Loss: 0.2506  Acc@1: 68.7500 (64.1967)  Acc@5: 100.0000 (95.0658)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.3326  Acc@1: 68.7500 (64.4036)  Acc@5: 93.7500 (95.0977)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.0783  Acc@1: 68.7500 (64.4685)  Acc@5: 100.0000 (95.1936)  time: 0.3500  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:44  Lr: 0.001875  Loss: 0.0865  Acc@1: 68.7500 (64.6579)  Acc@5: 100.0000 (95.2526)  time: 0.3512  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:40  Lr: 0.001875  Loss: 0.3728  Acc@1: 68.7500 (64.7911)  Acc@5: 100.0000 (95.2930)  time: 0.3535  data: 0.0026  max mem: 2503
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.1516  Acc@1: 68.7500 (65.0091)  Acc@5: 100.0000 (95.3923)  time: 0.3538  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:33  Lr: 0.001875  Loss: 0.0427  Acc@1: 68.7500 (64.9347)  Acc@5: 100.0000 (95.4424)  time: 0.3528  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.0448  Acc@1: 62.5000 (64.8927)  Acc@5: 100.0000 (95.5046)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.0001  Acc@1: 68.7500 (65.0935)  Acc@5: 100.0000 (95.5357)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.3775  Acc@1: 75.0000 (65.3271)  Acc@5: 100.0000 (95.6070)  time: 0.3523  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.2368  Acc@1: 75.0000 (65.4284)  Acc@5: 100.0000 (95.6752)  time: 0.3544  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.0268  Acc@1: 75.0000 (65.6184)  Acc@5: 100.0000 (95.7272)  time: 0.3551  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.1822  Acc@1: 68.7500 (65.6575)  Acc@5: 100.0000 (95.7640)  time: 0.3540  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [ 490/3750]  eta: 0:19:09  Lr: 0.001875  Loss: 0.0664  Acc@1: 68.7500 (65.7714)  Acc@5: 100.0000 (95.8248)  time: 0.3517  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [ 500/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.4041  Acc@1: 75.0000 (65.9431)  Acc@5: 100.0000 (95.8583)  time: 0.3524  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [ 510/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.6253  Acc@1: 75.0000 (66.0837)  Acc@5: 100.0000 (95.9026)  time: 0.3551  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.5299  Acc@1: 68.7500 (66.1228)  Acc@5: 100.0000 (95.9213)  time: 0.3549  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.3220  Acc@1: 68.7500 (66.2076)  Acc@5: 100.0000 (95.9628)  time: 0.3531  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.1567  Acc@1: 68.7500 (66.2893)  Acc@5: 100.0000 (95.9912)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.2953  Acc@1: 68.7500 (66.3793)  Acc@5: 100.0000 (96.0299)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.1098  Acc@1: 68.7500 (66.3436)  Acc@5: 100.0000 (96.0673)  time: 0.3533  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.3275  Acc@1: 68.7500 (66.4405)  Acc@5: 100.0000 (96.1033)  time: 0.3524  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.1713  Acc@1: 75.0000 (66.5663)  Acc@5: 100.0000 (96.1274)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.4330  Acc@1: 75.0000 (66.7301)  Acc@5: 100.0000 (96.1717)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.1011  Acc@1: 75.0000 (66.8781)  Acc@5: 100.0000 (96.2042)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:26  Lr: 0.001875  Loss: 0.0711  Acc@1: 75.0000 (66.9394)  Acc@5: 100.0000 (96.2255)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.3988  Acc@1: 68.7500 (66.9787)  Acc@5: 100.0000 (96.2460)  time: 0.3522  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.2940  Acc@1: 68.7500 (67.0166)  Acc@5: 100.0000 (96.2857)  time: 0.3539  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.3404  Acc@1: 68.7500 (67.0729)  Acc@5: 100.0000 (96.2656)  time: 0.3529  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:12  Lr: 0.001875  Loss: 0.0123  Acc@1: 68.7500 (67.0795)  Acc@5: 93.7500 (96.2654)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:09  Lr: 0.001875  Loss: 0.0254  Acc@1: 62.5000 (67.0669)  Acc@5: 93.7500 (96.2462)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 670/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.1032  Acc@1: 68.7500 (67.1107)  Acc@5: 100.0000 (96.2742)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 680/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.5316  Acc@1: 68.7500 (67.2449)  Acc@5: 100.0000 (96.2922)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.5299  Acc@1: 75.0000 (67.3209)  Acc@5: 100.0000 (96.3187)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.2904  Acc@1: 75.0000 (67.4483)  Acc@5: 100.0000 (96.2910)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.1205  Acc@1: 75.0000 (67.5545)  Acc@5: 93.7500 (96.3080)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.5113  Acc@1: 75.0000 (67.6144)  Acc@5: 100.0000 (96.3506)  time: 0.3508  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.0933  Acc@1: 68.7500 (67.6043)  Acc@5: 100.0000 (96.4005)  time: 0.3513  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.5659  Acc@1: 75.0000 (67.6535)  Acc@5: 100.0000 (96.4069)  time: 0.3517  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:36  Lr: 0.001875  Loss: 0.1430  Acc@1: 75.0000 (67.6598)  Acc@5: 93.7500 (96.3798)  time: 0.3507  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.2126  Acc@1: 75.0000 (67.8384)  Acc@5: 93.7500 (96.3945)  time: 0.3523  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.6670  Acc@1: 75.0000 (67.9313)  Acc@5: 100.0000 (96.4251)  time: 0.3538  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.5368  Acc@1: 75.0000 (67.9818)  Acc@5: 100.0000 (96.4309)  time: 0.3577  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:23  Lr: 0.001875  Loss: 0.0426  Acc@1: 68.7500 (67.9678)  Acc@5: 100.0000 (96.4602)  time: 0.3565  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6043  Acc@1: 68.7500 (68.0478)  Acc@5: 100.0000 (96.4654)  time: 0.3504  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.0461  Acc@1: 68.7500 (68.0487)  Acc@5: 100.0000 (96.4704)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.6584  Acc@1: 68.7500 (68.1181)  Acc@5: 100.0000 (96.4906)  time: 0.3509  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.2267  Acc@1: 75.0000 (68.1258)  Acc@5: 100.0000 (96.4952)  time: 0.3513  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 840/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.3561  Acc@1: 68.7500 (68.1406)  Acc@5: 100.0000 (96.4774)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 850/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.6370  Acc@1: 75.0000 (68.2212)  Acc@5: 100.0000 (96.4747)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.3277  Acc@1: 75.0000 (68.2346)  Acc@5: 100.0000 (96.4721)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.5235  Acc@1: 68.7500 (68.2979)  Acc@5: 100.0000 (96.4911)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.2213  Acc@1: 68.7500 (68.2605)  Acc@5: 100.0000 (96.5309)  time: 0.3531  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.3025  Acc@1: 75.0000 (68.3502)  Acc@5: 100.0000 (96.5558)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.5608  Acc@1: 68.7500 (68.3685)  Acc@5: 100.0000 (96.5524)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.7064  Acc@1: 68.7500 (68.3864)  Acc@5: 93.7500 (96.5423)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.2621  Acc@1: 75.0000 (68.4378)  Acc@5: 100.0000 (96.5527)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.3407  Acc@1: 75.0000 (68.5352)  Acc@5: 100.0000 (96.5830)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.8493  Acc@1: 75.0000 (68.6371)  Acc@5: 100.0000 (96.6126)  time: 0.3496  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.1261  Acc@1: 75.0000 (68.6711)  Acc@5: 100.0000 (96.6417)  time: 0.3509  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.0861  Acc@1: 75.0000 (68.7630)  Acc@5: 100.0000 (96.6701)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.7200  Acc@1: 75.0000 (68.8530)  Acc@5: 100.0000 (96.6916)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.4780  Acc@1: 75.0000 (68.8902)  Acc@5: 100.0000 (96.6998)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.6196  Acc@1: 75.0000 (68.9897)  Acc@5: 100.0000 (96.7268)  time: 0.3507  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1000/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.6354  Acc@1: 75.0000 (69.0559)  Acc@5: 100.0000 (96.7470)  time: 0.3517  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1010/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4755  Acc@1: 75.0000 (69.1024)  Acc@5: 100.0000 (96.7730)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1020/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.8220  Acc@1: 75.0000 (69.1418)  Acc@5: 100.0000 (96.7862)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.7162  Acc@1: 75.0000 (69.1562)  Acc@5: 100.0000 (96.7992)  time: 0.3519  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.4285  Acc@1: 68.7500 (69.1583)  Acc@5: 100.0000 (96.8000)  time: 0.3550  data: 0.0027  max mem: 2503
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.3427  Acc@1: 75.0000 (69.2257)  Acc@5: 100.0000 (96.8007)  time: 0.3553  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.7460  Acc@1: 75.0000 (69.2507)  Acc@5: 100.0000 (96.8249)  time: 0.3533  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.4716  Acc@1: 75.0000 (69.3452)  Acc@5: 100.0000 (96.8371)  time: 0.3522  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.5156  Acc@1: 75.0000 (69.4091)  Acc@5: 100.0000 (96.8548)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.1047  Acc@1: 75.0000 (69.4661)  Acc@5: 100.0000 (96.8836)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.5788  Acc@1: 68.7500 (69.4709)  Acc@5: 100.0000 (96.8892)  time: 0.3505  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.7991  Acc@1: 68.7500 (69.5207)  Acc@5: 100.0000 (96.9003)  time: 0.3519  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.4051  Acc@1: 75.0000 (69.5807)  Acc@5: 100.0000 (96.9112)  time: 0.3522  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.3697  Acc@1: 68.7500 (69.5844)  Acc@5: 100.0000 (96.9164)  time: 0.3502  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5822  Acc@1: 75.0000 (69.6374)  Acc@5: 100.0000 (96.9270)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.7583  Acc@1: 75.0000 (69.7111)  Acc@5: 100.0000 (96.9374)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.7827  Acc@1: 75.0000 (69.7944)  Acc@5: 100.0000 (96.9531)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.3083  Acc@1: 75.0000 (69.8655)  Acc@5: 100.0000 (96.9791)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1180/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.6830  Acc@1: 75.0000 (69.8666)  Acc@5: 100.0000 (96.9782)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1190/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.7967  Acc@1: 75.0000 (69.9360)  Acc@5: 100.0000 (96.9773)  time: 0.3503  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.6966  Acc@1: 75.0000 (69.9729)  Acc@5: 100.0000 (97.0025)  time: 0.3535  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.4556  Acc@1: 68.7500 (69.9938)  Acc@5: 100.0000 (96.9911)  time: 0.3521  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.5033  Acc@1: 68.7500 (69.9836)  Acc@5: 100.0000 (97.0004)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.1166  Acc@1: 68.7500 (69.9939)  Acc@5: 100.0000 (96.9892)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.9082  Acc@1: 75.0000 (70.0292)  Acc@5: 100.0000 (97.0135)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.2155  Acc@1: 68.7500 (70.0689)  Acc@5: 100.0000 (97.0274)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.3601  Acc@1: 75.0000 (70.1180)  Acc@5: 100.0000 (97.0361)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.4701  Acc@1: 75.0000 (70.1760)  Acc@5: 100.0000 (97.0594)  time: 0.3501  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.6004  Acc@1: 75.0000 (70.2186)  Acc@5: 100.0000 (97.0726)  time: 0.3542  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.7634  Acc@1: 81.2500 (70.2847)  Acc@5: 100.0000 (97.0953)  time: 0.3562  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.8285  Acc@1: 81.2500 (70.3353)  Acc@5: 100.0000 (97.1176)  time: 0.3524  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.7373  Acc@1: 81.2500 (70.3709)  Acc@5: 100.0000 (97.1348)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.3425  Acc@1: 75.0000 (70.3917)  Acc@5: 100.0000 (97.1423)  time: 0.3518  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.4256  Acc@1: 68.7500 (70.3794)  Acc@5: 100.0000 (97.1215)  time: 0.3547  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.5558  Acc@1: 68.7500 (70.4185)  Acc@5: 93.7500 (97.1243)  time: 0.3541  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1350/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.4200  Acc@1: 75.0000 (70.4339)  Acc@5: 93.7500 (97.1179)  time: 0.3521  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [1360/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.6154  Acc@1: 75.0000 (70.4629)  Acc@5: 100.0000 (97.1391)  time: 0.3508  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.1060  Acc@1: 75.0000 (70.4686)  Acc@5: 100.0000 (97.1462)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.1242  Acc@1: 68.7500 (70.4969)  Acc@5: 100.0000 (97.1624)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.3035  Acc@1: 75.0000 (70.5068)  Acc@5: 100.0000 (97.1648)  time: 0.3535  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.2361  Acc@1: 68.7500 (70.4720)  Acc@5: 100.0000 (97.1717)  time: 0.3552  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:43  Lr: 0.001875  Loss: 0.0688  Acc@1: 75.0000 (70.5174)  Acc@5: 100.0000 (97.1784)  time: 0.3549  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.8848  Acc@1: 75.0000 (70.5357)  Acc@5: 100.0000 (97.1895)  time: 0.3524  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.6557  Acc@1: 68.7500 (70.5407)  Acc@5: 100.0000 (97.2004)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:32  Lr: 0.001875  Loss: 0.4481  Acc@1: 62.5000 (70.5023)  Acc@5: 100.0000 (97.2111)  time: 0.3528  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.4745  Acc@1: 68.7500 (70.5419)  Acc@5: 100.0000 (97.2174)  time: 0.3519  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4927  Acc@1: 75.0000 (70.5510)  Acc@5: 100.0000 (97.2108)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.7714  Acc@1: 75.0000 (70.5685)  Acc@5: 100.0000 (97.2213)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.1295  Acc@1: 75.0000 (70.6111)  Acc@5: 100.0000 (97.2105)  time: 0.3523  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.2128  Acc@1: 75.0000 (70.6321)  Acc@5: 100.0000 (97.2292)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.6430  Acc@1: 75.0000 (70.6571)  Acc@5: 100.0000 (97.2435)  time: 0.3514  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.2421  Acc@1: 75.0000 (70.6734)  Acc@5: 100.0000 (97.2452)  time: 0.3522  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1520/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.6628  Acc@1: 68.7500 (70.6977)  Acc@5: 100.0000 (97.2510)  time: 0.3540  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1530/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.3800  Acc@1: 75.0000 (70.7503)  Acc@5: 100.0000 (97.2608)  time: 0.3559  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.4130  Acc@1: 81.2500 (70.8022)  Acc@5: 100.0000 (97.2542)  time: 0.3538  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.6173  Acc@1: 81.2500 (70.8736)  Acc@5: 100.0000 (97.2639)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.5504  Acc@1: 81.2500 (70.9001)  Acc@5: 100.0000 (97.2734)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.3991  Acc@1: 81.2500 (70.9421)  Acc@5: 100.0000 (97.2868)  time: 0.3544  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.5295  Acc@1: 81.2500 (70.9717)  Acc@5: 100.0000 (97.2921)  time: 0.3555  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.8474  Acc@1: 75.0000 (71.0009)  Acc@5: 100.0000 (97.3052)  time: 0.3538  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.6822  Acc@1: 81.2500 (71.0532)  Acc@5: 100.0000 (97.3103)  time: 0.3520  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.3719  Acc@1: 81.2500 (71.0894)  Acc@5: 100.0000 (97.3153)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -0.1847  Acc@1: 75.0000 (71.1019)  Acc@5: 100.0000 (97.3126)  time: 0.3556  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.6859  Acc@1: 75.0000 (71.1143)  Acc@5: 100.0000 (97.3099)  time: 0.3546  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -0.1735  Acc@1: 75.0000 (71.1380)  Acc@5: 100.0000 (97.3225)  time: 0.3534  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.7587  Acc@1: 81.2500 (71.1841)  Acc@5: 100.0000 (97.3349)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:15  Lr: 0.001875  Loss: -0.4629  Acc@1: 75.0000 (71.1996)  Acc@5: 100.0000 (97.3397)  time: 0.3534  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.7094  Acc@1: 75.0000 (71.2223)  Acc@5: 100.0000 (97.3481)  time: 0.3557  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -0.5942  Acc@1: 75.0000 (71.2411)  Acc@5: 100.0000 (97.3639)  time: 0.3560  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.6363  Acc@1: 75.0000 (71.2633)  Acc@5: 100.0000 (97.3647)  time: 0.3541  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1700/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.7988  Acc@1: 81.2500 (71.3404)  Acc@5: 100.0000 (97.3765)  time: 0.3498  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.6760  Acc@1: 81.2500 (71.3691)  Acc@5: 100.0000 (97.3882)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.0778  Acc@1: 75.0000 (71.3938)  Acc@5: 100.0000 (97.3998)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.4017  Acc@1: 75.0000 (71.4110)  Acc@5: 100.0000 (97.4003)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.4679  Acc@1: 75.0000 (71.4424)  Acc@5: 100.0000 (97.4081)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.3091  Acc@1: 75.0000 (71.4592)  Acc@5: 100.0000 (97.4122)  time: 0.3497  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.2262  Acc@1: 75.0000 (71.5112)  Acc@5: 100.0000 (97.4198)  time: 0.3506  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.6361  Acc@1: 81.2500 (71.5274)  Acc@5: 100.0000 (97.4238)  time: 0.3494  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.5788  Acc@1: 75.0000 (71.5258)  Acc@5: 100.0000 (97.4277)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.3018  Acc@1: 68.7500 (71.5208)  Acc@5: 100.0000 (97.4386)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.3225  Acc@1: 68.7500 (71.5124)  Acc@5: 100.0000 (97.4459)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.1864  Acc@1: 68.7500 (71.5213)  Acc@5: 100.0000 (97.4531)  time: 0.3509  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.4920  Acc@1: 75.0000 (71.5404)  Acc@5: 100.0000 (97.4671)  time: 0.3505  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.3432  Acc@1: 75.0000 (71.5627)  Acc@5: 100.0000 (97.4706)  time: 0.3511  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.7867  Acc@1: 75.0000 (71.6051)  Acc@5: 100.0000 (97.4776)  time: 0.3548  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.7442  Acc@1: 75.0000 (71.6201)  Acc@5: 100.0000 (97.4710)  time: 0.3562  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -0.6561  Acc@1: 75.0000 (71.6752)  Acc@5: 100.0000 (97.4812)  time: 0.3537  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1870/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.7837  Acc@1: 81.2500 (71.7030)  Acc@5: 100.0000 (97.4880)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -0.3339  Acc@1: 75.0000 (71.6972)  Acc@5: 100.0000 (97.4914)  time: 0.3510  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.4618  Acc@1: 68.7500 (71.7048)  Acc@5: 100.0000 (97.4980)  time: 0.3515  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.7286  Acc@1: 75.0000 (71.7320)  Acc@5: 100.0000 (97.5079)  time: 0.3534  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.8170  Acc@1: 75.0000 (71.7262)  Acc@5: 100.0000 (97.5013)  time: 0.3526  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.3643  Acc@1: 75.0000 (71.7660)  Acc@5: 100.0000 (97.5078)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.7028  Acc@1: 75.0000 (71.7989)  Acc@5: 100.0000 (97.5142)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.4986  Acc@1: 75.0000 (71.8122)  Acc@5: 100.0000 (97.5142)  time: 0.3533  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.5915  Acc@1: 75.0000 (71.8189)  Acc@5: 100.0000 (97.5173)  time: 0.3561  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -0.8463  Acc@1: 75.0000 (71.8383)  Acc@5: 100.0000 (97.5204)  time: 0.3531  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.5232  Acc@1: 75.0000 (71.8671)  Acc@5: 100.0000 (97.5171)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.6159  Acc@1: 75.0000 (71.8703)  Acc@5: 100.0000 (97.5170)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.1965  Acc@1: 68.7500 (71.8797)  Acc@5: 100.0000 (97.5201)  time: 0.3551  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.6706  Acc@1: 75.0000 (71.8891)  Acc@5: 100.0000 (97.5262)  time: 0.3559  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.5400  Acc@1: 75.0000 (71.9418)  Acc@5: 100.0000 (97.5323)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.5173  Acc@1: 75.0000 (71.9724)  Acc@5: 100.0000 (97.5383)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2030/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.2900  Acc@1: 75.0000 (71.9719)  Acc@5: 100.0000 (97.5474)  time: 0.3509  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2040/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.4446  Acc@1: 68.7500 (71.9806)  Acc@5: 100.0000 (97.5472)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.2657  Acc@1: 75.0000 (72.0015)  Acc@5: 100.0000 (97.5530)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.2551  Acc@1: 75.0000 (71.9948)  Acc@5: 100.0000 (97.5437)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.3940  Acc@1: 75.0000 (72.0214)  Acc@5: 100.0000 (97.5495)  time: 0.3497  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.4270  Acc@1: 75.0000 (72.0297)  Acc@5: 100.0000 (97.5583)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.0672  Acc@1: 75.0000 (72.0618)  Acc@5: 100.0000 (97.5550)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.8187  Acc@1: 75.0000 (72.0936)  Acc@5: 100.0000 (97.5547)  time: 0.3506  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.1923  Acc@1: 81.2500 (72.1252)  Acc@5: 100.0000 (97.5604)  time: 0.3499  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.4904  Acc@1: 75.0000 (72.1417)  Acc@5: 100.0000 (97.5660)  time: 0.3531  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.5868  Acc@1: 75.0000 (72.1610)  Acc@5: 100.0000 (97.5716)  time: 0.3532  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.0482  Acc@1: 75.0000 (72.1567)  Acc@5: 100.0000 (97.5771)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.6744  Acc@1: 75.0000 (72.1961)  Acc@5: 100.0000 (97.5854)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.5771  Acc@1: 75.0000 (72.2119)  Acc@5: 100.0000 (97.5850)  time: 0.3520  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.7449  Acc@1: 75.0000 (72.2277)  Acc@5: 100.0000 (97.5846)  time: 0.3558  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.4667  Acc@1: 68.7500 (72.2060)  Acc@5: 100.0000 (97.5957)  time: 0.3547  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4646  Acc@1: 75.0000 (72.2615)  Acc@5: 100.0000 (97.6067)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2200/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.9134  Acc@1: 87.5000 (72.2882)  Acc@5: 100.0000 (97.6119)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2210/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.4128  Acc@1: 81.2500 (72.3174)  Acc@5: 100.0000 (97.6114)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.6223  Acc@1: 75.0000 (72.3407)  Acc@5: 100.0000 (97.6221)  time: 0.3539  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.5219  Acc@1: 81.2500 (72.3919)  Acc@5: 100.0000 (97.6244)  time: 0.3536  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.5547  Acc@1: 81.2500 (72.4230)  Acc@5: 100.0000 (97.6238)  time: 0.3543  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.4300  Acc@1: 81.2500 (72.4261)  Acc@5: 100.0000 (97.6288)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.3504  Acc@1: 75.0000 (72.4375)  Acc@5: 100.0000 (97.6310)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.4758  Acc@1: 75.0000 (72.4571)  Acc@5: 100.0000 (97.6360)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.4297  Acc@1: 75.0000 (72.4710)  Acc@5: 100.0000 (97.6354)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.5715  Acc@1: 75.0000 (72.4820)  Acc@5: 100.0000 (97.6430)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.6343  Acc@1: 75.0000 (72.5147)  Acc@5: 100.0000 (97.6478)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.4900  Acc@1: 75.0000 (72.5119)  Acc@5: 100.0000 (97.6552)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.4787  Acc@1: 75.0000 (72.5549)  Acc@5: 100.0000 (97.6626)  time: 0.3521  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.9424  Acc@1: 81.2500 (72.5896)  Acc@5: 100.0000 (97.6646)  time: 0.3518  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.5365  Acc@1: 75.0000 (72.5972)  Acc@5: 100.0000 (97.6666)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.3671  Acc@1: 75.0000 (72.6047)  Acc@5: 100.0000 (97.6685)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.2717  Acc@1: 75.0000 (72.6334)  Acc@5: 100.0000 (97.6731)  time: 0.3546  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.3405  Acc@1: 75.0000 (72.6513)  Acc@5: 100.0000 (97.6724)  time: 0.3556  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2380/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.5882  Acc@1: 75.0000 (72.6743)  Acc@5: 100.0000 (97.6717)  time: 0.3547  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.8069  Acc@1: 75.0000 (72.6840)  Acc@5: 100.0000 (97.6683)  time: 0.3537  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.4445  Acc@1: 75.0000 (72.6807)  Acc@5: 100.0000 (97.6702)  time: 0.3569  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.6124  Acc@1: 75.0000 (72.7110)  Acc@5: 100.0000 (97.6721)  time: 0.3558  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.6117  Acc@1: 81.2500 (72.7230)  Acc@5: 100.0000 (97.6817)  time: 0.3548  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.4593  Acc@1: 81.2500 (72.7504)  Acc@5: 100.0000 (97.6887)  time: 0.3554  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.5319  Acc@1: 75.0000 (72.7622)  Acc@5: 100.0000 (97.6956)  time: 0.3541  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.9103  Acc@1: 81.2500 (72.7968)  Acc@5: 100.0000 (97.6948)  time: 0.3576  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.8138  Acc@1: 81.2500 (72.8058)  Acc@5: 100.0000 (97.6915)  time: 0.3571  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.8239  Acc@1: 81.2500 (72.8324)  Acc@5: 100.0000 (97.6958)  time: 0.3539  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.7250  Acc@1: 75.0000 (72.8486)  Acc@5: 100.0000 (97.7051)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:23  Lr: 0.001875  Loss: 0.0383  Acc@1: 68.7500 (72.8372)  Acc@5: 100.0000 (97.7118)  time: 0.3518  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.2986  Acc@1: 68.7500 (72.8184)  Acc@5: 100.0000 (97.7109)  time: 0.3556  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.5567  Acc@1: 68.7500 (72.8246)  Acc@5: 100.0000 (97.7175)  time: 0.3605  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.7084  Acc@1: 81.2500 (72.8605)  Acc@5: 100.0000 (97.7167)  time: 0.3557  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.7848  Acc@1: 81.2500 (72.8837)  Acc@5: 100.0000 (97.7158)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.1747  Acc@1: 81.2500 (72.9068)  Acc@5: 100.0000 (97.7224)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2550/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.2587  Acc@1: 75.0000 (72.9126)  Acc@5: 100.0000 (97.7239)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.7010  Acc@1: 75.0000 (72.9354)  Acc@5: 100.0000 (97.7304)  time: 0.3505  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.4650  Acc@1: 75.0000 (72.9629)  Acc@5: 100.0000 (97.7343)  time: 0.3512  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.4810  Acc@1: 75.0000 (72.9538)  Acc@5: 100.0000 (97.7383)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.7799  Acc@1: 68.7500 (72.9689)  Acc@5: 100.0000 (97.7374)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.5388  Acc@1: 75.0000 (72.9743)  Acc@5: 100.0000 (97.7437)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.2707  Acc@1: 75.0000 (72.9701)  Acc@5: 100.0000 (97.7499)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.2396  Acc@1: 75.0000 (72.9779)  Acc@5: 100.0000 (97.7537)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.4830  Acc@1: 68.7500 (72.9761)  Acc@5: 100.0000 (97.7528)  time: 0.3523  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.5001  Acc@1: 75.0000 (72.9885)  Acc@5: 100.0000 (97.7518)  time: 0.3515  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.8380  Acc@1: 81.2500 (73.0290)  Acc@5: 100.0000 (97.7579)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.6688  Acc@1: 75.0000 (73.0059)  Acc@5: 100.0000 (97.7640)  time: 0.3512  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.6910  Acc@1: 68.7500 (73.0181)  Acc@5: 100.0000 (97.7677)  time: 0.3513  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.4162  Acc@1: 75.0000 (73.0185)  Acc@5: 100.0000 (97.7714)  time: 0.3529  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.4007  Acc@1: 75.0000 (73.0258)  Acc@5: 100.0000 (97.7773)  time: 0.3524  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.3160  Acc@1: 81.2500 (73.0470)  Acc@5: 100.0000 (97.7809)  time: 0.3523  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.1351  Acc@1: 81.2500 (73.0542)  Acc@5: 100.0000 (97.7822)  time: 0.3535  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.6756  Acc@1: 68.7500 (73.0223)  Acc@5: 100.0000 (97.7857)  time: 0.3535  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.6378  Acc@1: 68.7500 (73.0319)  Acc@5: 100.0000 (97.7847)  time: 0.3535  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.1274  Acc@1: 81.2500 (73.0504)  Acc@5: 100.0000 (97.7837)  time: 0.3521  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.7746  Acc@1: 81.2500 (73.0802)  Acc@5: 100.0000 (97.7826)  time: 0.3504  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.4926  Acc@1: 81.2500 (73.1008)  Acc@5: 100.0000 (97.7861)  time: 0.3504  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.6211  Acc@1: 75.0000 (73.1076)  Acc@5: 100.0000 (97.7851)  time: 0.3540  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6332  Acc@1: 75.0000 (73.1054)  Acc@5: 100.0000 (97.7863)  time: 0.3546  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.0317  Acc@1: 75.0000 (73.1145)  Acc@5: 100.0000 (97.7875)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.8203  Acc@1: 75.0000 (73.1480)  Acc@5: 100.0000 (97.7932)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.5858  Acc@1: 81.2500 (73.1701)  Acc@5: 100.0000 (97.7966)  time: 0.3479  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.3313  Acc@1: 75.0000 (73.1811)  Acc@5: 100.0000 (97.8044)  time: 0.3500  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.7604  Acc@1: 81.2500 (73.1919)  Acc@5: 100.0000 (97.8122)  time: 0.3502  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.9277  Acc@1: 81.2500 (73.2291)  Acc@5: 100.0000 (97.8177)  time: 0.3502  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -1.0035  Acc@1: 81.2500 (73.2462)  Acc@5: 100.0000 (97.8231)  time: 0.3511  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.8400  Acc@1: 81.2500 (73.2611)  Acc@5: 100.0000 (97.8198)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.5149  Acc@1: 75.0000 (73.2802)  Acc@5: 100.0000 (97.8187)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.6398  Acc@1: 75.0000 (73.2818)  Acc@5: 100.0000 (97.8176)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.8879  Acc@1: 75.0000 (73.3008)  Acc@5: 100.0000 (97.8187)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.4103  Acc@1: 75.0000 (73.3002)  Acc@5: 100.0000 (97.8240)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -1.0551  Acc@1: 75.0000 (73.3146)  Acc@5: 100.0000 (97.8229)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.3745  Acc@1: 75.0000 (73.3332)  Acc@5: 100.0000 (97.8261)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.7820  Acc@1: 75.0000 (73.3282)  Acc@5: 100.0000 (97.8228)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.5641  Acc@1: 75.0000 (73.3488)  Acc@5: 100.0000 (97.8239)  time: 0.3513  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5903  Acc@1: 75.0000 (73.3438)  Acc@5: 100.0000 (97.8270)  time: 0.3545  data: 0.0027  max mem: 2503
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.8093  Acc@1: 68.7500 (73.3325)  Acc@5: 100.0000 (97.8301)  time: 0.3532  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.0846  Acc@1: 68.7500 (73.3402)  Acc@5: 100.0000 (97.8353)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.6957  Acc@1: 75.0000 (73.3458)  Acc@5: 100.0000 (97.8405)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.4889  Acc@1: 75.0000 (73.3471)  Acc@5: 100.0000 (97.8331)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.6193  Acc@1: 75.0000 (73.3693)  Acc@5: 100.0000 (97.8382)  time: 0.3563  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.6363  Acc@1: 81.2500 (73.3872)  Acc@5: 100.0000 (97.8412)  time: 0.3558  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.6428  Acc@1: 75.0000 (73.3925)  Acc@5: 100.0000 (97.8422)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3495  Acc@1: 75.0000 (73.4019)  Acc@5: 100.0000 (97.8390)  time: 0.3495  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.4261  Acc@1: 75.0000 (73.4113)  Acc@5: 100.0000 (97.8440)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:06  Lr: 0.001875  Loss: 0.3944  Acc@1: 75.0000 (73.4288)  Acc@5: 100.0000 (97.8368)  time: 0.3529  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -0.6856  Acc@1: 75.0000 (73.4523)  Acc@5: 100.0000 (97.8438)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.6903  Acc@1: 75.0000 (73.4655)  Acc@5: 100.0000 (97.8387)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6435  Acc@1: 75.0000 (73.4705)  Acc@5: 100.0000 (97.8396)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.4241  Acc@1: 75.0000 (73.4835)  Acc@5: 100.0000 (97.8445)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.4633  Acc@1: 75.0000 (73.4884)  Acc@5: 100.0000 (97.8475)  time: 0.3533  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.6121  Acc@1: 75.0000 (73.4912)  Acc@5: 100.0000 (97.8423)  time: 0.3538  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6758  Acc@1: 81.2500 (73.5001)  Acc@5: 100.0000 (97.8412)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.5018  Acc@1: 81.2500 (73.5009)  Acc@5: 100.0000 (97.8401)  time: 0.3514  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -0.8228  Acc@1: 75.0000 (73.5017)  Acc@5: 100.0000 (97.8430)  time: 0.3526  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.4194  Acc@1: 75.0000 (73.5044)  Acc@5: 100.0000 (97.8459)  time: 0.3520  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.7346  Acc@1: 75.0000 (73.5013)  Acc@5: 100.0000 (97.8488)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -0.8250  Acc@1: 75.0000 (73.5277)  Acc@5: 100.0000 (97.8536)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -0.2958  Acc@1: 81.2500 (73.5441)  Acc@5: 100.0000 (97.8584)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:17  Lr: 0.001875  Loss: -0.3038  Acc@1: 81.2500 (73.5682)  Acc@5: 100.0000 (97.8612)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.4085  Acc@1: 81.2500 (73.5805)  Acc@5: 100.0000 (97.8600)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6893  Acc@1: 81.2500 (73.5966)  Acc@5: 100.0000 (97.8570)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.0872  Acc@1: 75.0000 (73.6010)  Acc@5: 100.0000 (97.8559)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:03  Lr: 0.001875  Loss: -0.9069  Acc@1: 75.0000 (73.6227)  Acc@5: 100.0000 (97.8586)  time: 0.3525  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.4858  Acc@1: 75.0000 (73.6231)  Acc@5: 100.0000 (97.8633)  time: 0.3539  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.6553  Acc@1: 81.2500 (73.6523)  Acc@5: 100.0000 (97.8680)  time: 0.3522  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.3618  Acc@1: 81.2500 (73.6680)  Acc@5: 100.0000 (97.8688)  time: 0.3509  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.4274  Acc@1: 75.0000 (73.6740)  Acc@5: 100.0000 (97.8676)  time: 0.3523  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7049  Acc@1: 75.0000 (73.6799)  Acc@5: 100.0000 (97.8665)  time: 0.3542  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.3546  Acc@1: 75.0000 (73.6839)  Acc@5: 100.0000 (97.8730)  time: 0.3557  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.7645  Acc@1: 75.0000 (73.6822)  Acc@5: 100.0000 (97.8794)  time: 0.3529  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.4238  Acc@1: 75.0000 (73.6900)  Acc@5: 100.0000 (97.8802)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.0963  Acc@1: 75.0000 (73.6902)  Acc@5: 100.0000 (97.8790)  time: 0.3558  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.5940  Acc@1: 75.0000 (73.6866)  Acc@5: 100.0000 (97.8760)  time: 0.3593  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.4838  Acc@1: 75.0000 (73.6943)  Acc@5: 100.0000 (97.8786)  time: 0.3560  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.6231  Acc@1: 75.0000 (73.7075)  Acc@5: 100.0000 (97.8794)  time: 0.3552  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.7625  Acc@1: 81.2500 (73.7095)  Acc@5: 100.0000 (97.8838)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.7246  Acc@1: 81.2500 (73.7392)  Acc@5: 100.0000 (97.8864)  time: 0.3539  data: 0.0035  max mem: 2503
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4827  Acc@1: 81.2500 (73.7522)  Acc@5: 100.0000 (97.8908)  time: 0.3549  data: 0.0036  max mem: 2503
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.5572  Acc@1: 75.0000 (73.7670)  Acc@5: 100.0000 (97.8952)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.5903  Acc@1: 75.0000 (73.7724)  Acc@5: 100.0000 (97.8995)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.5775  Acc@1: 75.0000 (73.7779)  Acc@5: 100.0000 (97.8965)  time: 0.3523  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.6018  Acc@1: 75.0000 (73.7851)  Acc@5: 100.0000 (97.8954)  time: 0.3527  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.6151  Acc@1: 81.2500 (73.7941)  Acc@5: 100.0000 (97.9015)  time: 0.3514  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.5306  Acc@1: 75.0000 (73.8085)  Acc@5: 100.0000 (97.9058)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7658  Acc@1: 81.2500 (73.8192)  Acc@5: 100.0000 (97.9064)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -0.4984  Acc@1: 75.0000 (73.8244)  Acc@5: 100.0000 (97.9052)  time: 0.3514  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.2635  Acc@1: 75.0000 (73.8170)  Acc@5: 100.0000 (97.9077)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -0.7138  Acc@1: 75.0000 (73.8347)  Acc@5: 100.0000 (97.9101)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.5202  Acc@1: 81.2500 (73.8542)  Acc@5: 100.0000 (97.9143)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.4579  Acc@1: 75.0000 (73.8539)  Acc@5: 100.0000 (97.9167)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.3820  Acc@1: 75.0000 (73.8607)  Acc@5: 100.0000 (97.9155)  time: 0.3524  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6615  Acc@1: 81.2500 (73.8746)  Acc@5: 100.0000 (97.9196)  time: 0.3540  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7855  Acc@1: 75.0000 (73.8884)  Acc@5: 100.0000 (97.9237)  time: 0.3512  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9382  Acc@1: 75.0000 (73.9057)  Acc@5: 100.0000 (97.9278)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7703  Acc@1: 75.0000 (73.9228)  Acc@5: 100.0000 (97.9284)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6543  Acc@1: 81.2500 (73.9434)  Acc@5: 100.0000 (97.9290)  time: 0.3552  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4610  Acc@1: 81.2500 (73.9516)  Acc@5: 100.0000 (97.9278)  time: 0.3557  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.2317  Acc@1: 81.2500 (73.9546)  Acc@5: 100.0000 (97.9335)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.7514  Acc@1: 81.2500 (73.9714)  Acc@5: 100.0000 (97.9376)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.9484  Acc@1: 81.2500 (73.9829)  Acc@5: 100.0000 (97.9398)  time: 0.3511  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.8190  Acc@1: 81.2500 (74.0030)  Acc@5: 100.0000 (97.9421)  time: 0.3558  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4805  Acc@1: 81.2500 (74.0127)  Acc@5: 100.0000 (97.9460)  time: 0.3549  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6260  Acc@1: 81.2500 (74.0344)  Acc@5: 100.0000 (97.9448)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1795  Acc@1: 81.2500 (74.0370)  Acc@5: 100.0000 (97.9487)  time: 0.3512  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.3366  Acc@1: 81.2500 (74.0619)  Acc@5: 100.0000 (97.9509)  time: 0.3513  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.4309  Acc@1: 81.2500 (74.0696)  Acc@5: 100.0000 (97.9531)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.3261  Acc@1: 81.2500 (74.0891)  Acc@5: 100.0000 (97.9536)  time: 0.3511  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6695  Acc@1: 75.0000 (74.0916)  Acc@5: 100.0000 (97.9540)  time: 0.3511  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1478  Acc@1: 75.0000 (74.0975)  Acc@5: 100.0000 (97.9562)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7406  Acc@1: 75.0000 (74.1050)  Acc@5: 100.0000 (97.9583)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1925  Acc@1: 75.0000 (74.1023)  Acc@5: 100.0000 (97.9621)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6618  Acc@1: 75.0000 (74.1081)  Acc@5: 100.0000 (97.9659)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4063  Acc@1: 81.2500 (74.1239)  Acc@5: 100.0000 (97.9680)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6116  Acc@1: 81.2500 (74.1329)  Acc@5: 100.0000 (97.9718)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6287  Acc@1: 75.0000 (74.1317)  Acc@5: 100.0000 (97.9733)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[1/5] Total time: 0:22:00 (0.3522 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}}
Averaged stats: Lr: 0.001875  Loss: 0.6287  Acc@1: 75.0000 (74.1317)  Acc@5: 100.0000 (97.9733)
Train: Epoch[2/5]  [   0/3750]  eta: 0:50:44  Lr: 0.001875  Loss: -0.5994  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.8117  data: 0.4591  max mem: 2503
Train: Epoch[2/5]  [  10/3750]  eta: 0:24:28  Lr: 0.001875  Loss: -0.5780  Acc@1: 75.0000 (77.2727)  Acc@5: 100.0000 (98.8636)  time: 0.3925  data: 0.0424  max mem: 2503
Train: Epoch[2/5]  [  20/3750]  eta: 0:23:12  Lr: 0.001875  Loss: -0.6489  Acc@1: 75.0000 (76.4881)  Acc@5: 100.0000 (99.1071)  time: 0.3514  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:42  Lr: 0.001875  Loss: -0.7448  Acc@1: 75.0000 (78.0242)  Acc@5: 100.0000 (98.9919)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:25  Lr: 0.001875  Loss: -0.6763  Acc@1: 81.2500 (77.2866)  Acc@5: 100.0000 (98.7805)  time: 0.3515  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:15  Lr: 0.001875  Loss: -0.5523  Acc@1: 68.7500 (76.7157)  Acc@5: 100.0000 (98.6520)  time: 0.3528  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [  60/3750]  eta: 0:22:07  Lr: 0.001875  Loss: -0.3841  Acc@1: 75.0000 (76.6393)  Acc@5: 100.0000 (98.7705)  time: 0.3536  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -0.8658  Acc@1: 75.0000 (76.4965)  Acc@5: 100.0000 (98.7676)  time: 0.3525  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.8746  Acc@1: 81.2500 (77.5463)  Acc@5: 100.0000 (98.8426)  time: 0.3523  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:48  Lr: 0.001875  Loss: -0.9494  Acc@1: 81.2500 (77.2665)  Acc@5: 100.0000 (98.9011)  time: 0.3539  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.8958  Acc@1: 75.0000 (77.3515)  Acc@5: 100.0000 (98.9480)  time: 0.3564  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.3798  Acc@1: 75.0000 (77.6464)  Acc@5: 100.0000 (98.8739)  time: 0.3550  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.5702  Acc@1: 75.0000 (77.6860)  Acc@5: 100.0000 (98.9153)  time: 0.3518  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.5615  Acc@1: 81.2500 (77.9103)  Acc@5: 100.0000 (98.7595)  time: 0.3523  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:25  Lr: 0.001875  Loss: -0.4044  Acc@1: 81.2500 (78.1915)  Acc@5: 100.0000 (98.8032)  time: 0.3518  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.6706  Acc@1: 81.2500 (78.1457)  Acc@5: 100.0000 (98.7997)  time: 0.3512  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.6874  Acc@1: 75.0000 (78.1056)  Acc@5: 100.0000 (98.7966)  time: 0.3518  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 170/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.3239  Acc@1: 75.0000 (78.1433)  Acc@5: 100.0000 (98.7573)  time: 0.3510  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 180/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.4528  Acc@1: 75.0000 (78.0732)  Acc@5: 100.0000 (98.6878)  time: 0.3510  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 190/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.6334  Acc@1: 75.0000 (77.9450)  Acc@5: 100.0000 (98.6584)  time: 0.3518  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.7853  Acc@1: 81.2500 (78.1405)  Acc@5: 100.0000 (98.6629)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.5286  Acc@1: 81.2500 (78.0509)  Acc@5: 100.0000 (98.6078)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.7852  Acc@1: 75.0000 (77.9695)  Acc@5: 100.0000 (98.5860)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.5869  Acc@1: 75.0000 (77.7327)  Acc@5: 100.0000 (98.4848)  time: 0.3521  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.8323  Acc@1: 75.0000 (77.8008)  Acc@5: 100.0000 (98.4699)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.7900  Acc@1: 81.2500 (77.8635)  Acc@5: 100.0000 (98.4313)  time: 0.3529  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.5784  Acc@1: 75.0000 (77.7299)  Acc@5: 100.0000 (98.4435)  time: 0.3516  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.8153  Acc@1: 81.2500 (78.0673)  Acc@5: 100.0000 (98.5009)  time: 0.3505  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.1355  Acc@1: 81.2500 (78.0027)  Acc@5: 100.0000 (98.4653)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.4100  Acc@1: 81.2500 (78.1572)  Acc@5: 100.0000 (98.4536)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.4761  Acc@1: 75.0000 (77.8654)  Acc@5: 100.0000 (98.4012)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -0.5600  Acc@1: 68.7500 (77.7331)  Acc@5: 100.0000 (98.3320)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 320/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.9134  Acc@1: 81.2500 (77.7843)  Acc@5: 100.0000 (98.3645)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 330/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.8087  Acc@1: 81.2500 (77.7002)  Acc@5: 100.0000 (98.4139)  time: 0.3519  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 340/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.9430  Acc@1: 75.0000 (77.7493)  Acc@5: 100.0000 (98.4421)  time: 0.3513  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.4079  Acc@1: 75.0000 (77.6531)  Acc@5: 100.0000 (98.4330)  time: 0.3510  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -0.5554  Acc@1: 75.0000 (77.5796)  Acc@5: 100.0000 (98.4591)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:52  Lr: 0.001875  Loss: -0.6969  Acc@1: 75.0000 (77.5606)  Acc@5: 100.0000 (98.4670)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -0.5024  Acc@1: 81.2500 (77.6903)  Acc@5: 100.0000 (98.4580)  time: 0.3512  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -1.0221  Acc@1: 81.2500 (77.7813)  Acc@5: 100.0000 (98.4655)  time: 0.3568  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.7691  Acc@1: 81.2500 (77.9146)  Acc@5: 100.0000 (98.4414)  time: 0.3556  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.5039  Acc@1: 81.2500 (77.8893)  Acc@5: 100.0000 (98.4489)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.4578  Acc@1: 75.0000 (77.8058)  Acc@5: 100.0000 (98.4561)  time: 0.3513  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.4734  Acc@1: 81.2500 (77.8857)  Acc@5: 100.0000 (98.4484)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.4737  Acc@1: 81.2500 (77.9053)  Acc@5: 100.0000 (98.4694)  time: 0.3509  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.5816  Acc@1: 75.0000 (77.8271)  Acc@5: 100.0000 (98.4756)  time: 0.3503  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.6233  Acc@1: 75.0000 (77.7928)  Acc@5: 100.0000 (98.4680)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.7633  Acc@1: 81.2500 (77.8795)  Acc@5: 100.0000 (98.4873)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.1900  Acc@1: 75.0000 (77.8196)  Acc@5: 100.0000 (98.5187)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 490/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.5813  Acc@1: 75.0000 (77.7877)  Acc@5: 100.0000 (98.5234)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 500/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.4650  Acc@1: 81.2500 (77.9192)  Acc@5: 100.0000 (98.5155)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 510/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.2459  Acc@1: 81.2500 (77.9477)  Acc@5: 100.0000 (98.4956)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.8748  Acc@1: 81.2500 (78.0230)  Acc@5: 100.0000 (98.5125)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.9155  Acc@1: 81.2500 (77.9543)  Acc@5: 100.0000 (98.5287)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.2962  Acc@1: 75.0000 (77.8535)  Acc@5: 100.0000 (98.5328)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.6641  Acc@1: 75.0000 (77.9152)  Acc@5: 100.0000 (98.5254)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.7736  Acc@1: 81.2500 (77.9189)  Acc@5: 100.0000 (98.5517)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.8420  Acc@1: 75.0000 (77.9225)  Acc@5: 100.0000 (98.5552)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.4788  Acc@1: 81.2500 (78.0228)  Acc@5: 100.0000 (98.5585)  time: 0.3512  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.2549  Acc@1: 81.2500 (78.0140)  Acc@5: 100.0000 (98.5618)  time: 0.3514  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.4411  Acc@1: 81.2500 (78.0054)  Acc@5: 100.0000 (98.5649)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.5673  Acc@1: 75.0000 (77.9767)  Acc@5: 100.0000 (98.5884)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.4808  Acc@1: 75.0000 (77.9489)  Acc@5: 100.0000 (98.5809)  time: 0.3520  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.2312  Acc@1: 75.0000 (77.9418)  Acc@5: 100.0000 (98.5836)  time: 0.3535  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.4968  Acc@1: 75.0000 (77.8666)  Acc@5: 100.0000 (98.5667)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.6119  Acc@1: 68.7500 (77.8802)  Acc@5: 100.0000 (98.5695)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 660/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.4993  Acc@1: 75.0000 (77.8272)  Acc@5: 100.0000 (98.5817)  time: 0.3518  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 670/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.8525  Acc@1: 75.0000 (77.7664)  Acc@5: 100.0000 (98.5656)  time: 0.3548  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 680/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.6303  Acc@1: 75.0000 (77.7900)  Acc@5: 100.0000 (98.5683)  time: 0.3545  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.5428  Acc@1: 75.0000 (77.7858)  Acc@5: 100.0000 (98.5619)  time: 0.3525  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.5025  Acc@1: 75.0000 (77.7907)  Acc@5: 100.0000 (98.5556)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.3653  Acc@1: 75.0000 (77.7866)  Acc@5: 100.0000 (98.5408)  time: 0.3557  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:47  Lr: 0.001875  Loss: 0.0610  Acc@1: 75.0000 (77.7046)  Acc@5: 93.7500 (98.5003)  time: 0.3542  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.7665  Acc@1: 68.7500 (77.6932)  Acc@5: 100.0000 (98.5123)  time: 0.3516  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.4103  Acc@1: 75.0000 (77.6653)  Acc@5: 100.0000 (98.4987)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.1173  Acc@1: 81.2500 (77.7047)  Acc@5: 100.0000 (98.4770)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.2956  Acc@1: 75.0000 (77.6117)  Acc@5: 100.0000 (98.4724)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.7933  Acc@1: 75.0000 (77.5940)  Acc@5: 100.0000 (98.4922)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.5729  Acc@1: 75.0000 (77.5688)  Acc@5: 100.0000 (98.4875)  time: 0.3575  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.7762  Acc@1: 75.0000 (77.5838)  Acc@5: 100.0000 (98.4908)  time: 0.3592  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.8529  Acc@1: 75.0000 (77.5983)  Acc@5: 100.0000 (98.4863)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.5142  Acc@1: 75.0000 (77.6125)  Acc@5: 100.0000 (98.4972)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.4490  Acc@1: 75.0000 (77.6568)  Acc@5: 100.0000 (98.5079)  time: 0.3527  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 830/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.6674  Acc@1: 81.2500 (77.7226)  Acc@5: 100.0000 (98.5108)  time: 0.3528  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 840/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.6317  Acc@1: 81.2500 (77.7571)  Acc@5: 100.0000 (98.5211)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 850/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.3890  Acc@1: 81.2500 (77.7394)  Acc@5: 100.0000 (98.5238)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.3124  Acc@1: 75.0000 (77.7439)  Acc@5: 100.0000 (98.5264)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.5319  Acc@1: 75.0000 (77.7196)  Acc@5: 100.0000 (98.5362)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -1.0081  Acc@1: 75.0000 (77.7526)  Acc@5: 100.0000 (98.5528)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.6558  Acc@1: 81.2500 (77.7708)  Acc@5: 100.0000 (98.5550)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.6981  Acc@1: 75.0000 (77.7469)  Acc@5: 100.0000 (98.5641)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.5959  Acc@1: 75.0000 (77.7305)  Acc@5: 100.0000 (98.5593)  time: 0.3520  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.7996  Acc@1: 75.0000 (77.7348)  Acc@5: 100.0000 (98.5681)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.5281  Acc@1: 75.0000 (77.7256)  Acc@5: 100.0000 (98.5567)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.2733  Acc@1: 75.0000 (77.6700)  Acc@5: 93.7500 (98.5255)  time: 0.3510  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.8828  Acc@1: 75.0000 (77.6945)  Acc@5: 100.0000 (98.5279)  time: 0.3528  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.1789  Acc@1: 75.0000 (77.6600)  Acc@5: 100.0000 (98.5172)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.7056  Acc@1: 68.7500 (77.6326)  Acc@5: 100.0000 (98.5196)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.5245  Acc@1: 75.0000 (77.6058)  Acc@5: 100.0000 (98.5347)  time: 0.3518  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3972  Acc@1: 81.2500 (77.6678)  Acc@5: 100.0000 (98.5431)  time: 0.3534  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1000/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.5534  Acc@1: 81.2500 (77.6661)  Acc@5: 100.0000 (98.5390)  time: 0.3578  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1010/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4344  Acc@1: 75.0000 (77.6150)  Acc@5: 100.0000 (98.5410)  time: 0.3569  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1020/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7435  Acc@1: 75.0000 (77.6322)  Acc@5: 100.0000 (98.5370)  time: 0.3519  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.7142  Acc@1: 75.0000 (77.6431)  Acc@5: 100.0000 (98.5451)  time: 0.3507  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.7152  Acc@1: 75.0000 (77.6297)  Acc@5: 100.0000 (98.5531)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.6063  Acc@1: 75.0000 (77.6344)  Acc@5: 100.0000 (98.5371)  time: 0.3523  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.7980  Acc@1: 68.7500 (77.5683)  Acc@5: 100.0000 (98.5391)  time: 0.3533  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.9860  Acc@1: 68.7500 (77.5852)  Acc@5: 100.0000 (98.5411)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.7836  Acc@1: 81.2500 (77.6654)  Acc@5: 100.0000 (98.5546)  time: 0.3523  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.3893  Acc@1: 81.2500 (77.6467)  Acc@5: 100.0000 (98.5506)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.4744  Acc@1: 75.0000 (77.6624)  Acc@5: 100.0000 (98.5468)  time: 0.3518  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.6165  Acc@1: 75.0000 (77.5821)  Acc@5: 100.0000 (98.5486)  time: 0.3519  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.8313  Acc@1: 81.2500 (77.6204)  Acc@5: 100.0000 (98.5560)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.6083  Acc@1: 75.0000 (77.6028)  Acc@5: 100.0000 (98.5632)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.4416  Acc@1: 75.0000 (77.6402)  Acc@5: 100.0000 (98.5703)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.2216  Acc@1: 81.2500 (77.6499)  Acc@5: 100.0000 (98.5828)  time: 0.3497  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.4191  Acc@1: 81.2500 (77.6701)  Acc@5: 100.0000 (98.5950)  time: 0.3491  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1170/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.1785  Acc@1: 81.2500 (77.6740)  Acc@5: 100.0000 (98.6016)  time: 0.3514  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [1180/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.9576  Acc@1: 81.2500 (77.7202)  Acc@5: 100.0000 (98.5976)  time: 0.3519  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1190/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.4076  Acc@1: 81.2500 (77.7498)  Acc@5: 100.0000 (98.6094)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.8298  Acc@1: 75.0000 (77.7685)  Acc@5: 100.0000 (98.6105)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.6323  Acc@1: 81.2500 (77.7870)  Acc@5: 100.0000 (98.6014)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.1754  Acc@1: 81.2500 (77.7692)  Acc@5: 100.0000 (98.5923)  time: 0.3506  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.5089  Acc@1: 75.0000 (77.7468)  Acc@5: 100.0000 (98.5987)  time: 0.3524  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.6227  Acc@1: 81.2500 (77.7901)  Acc@5: 100.0000 (98.6050)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.6249  Acc@1: 81.2500 (77.8078)  Acc@5: 100.0000 (98.6011)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.7589  Acc@1: 81.2500 (77.8202)  Acc@5: 100.0000 (98.6023)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.3136  Acc@1: 81.2500 (77.8226)  Acc@5: 100.0000 (98.6035)  time: 0.3526  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.8242  Acc@1: 81.2500 (77.8591)  Acc@5: 100.0000 (98.5997)  time: 0.3544  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.3723  Acc@1: 81.2500 (77.8708)  Acc@5: 100.0000 (98.5960)  time: 0.3534  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7370  Acc@1: 81.2500 (77.8968)  Acc@5: 100.0000 (98.6020)  time: 0.3504  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.7542  Acc@1: 75.0000 (77.9129)  Acc@5: 100.0000 (98.6032)  time: 0.3497  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.5323  Acc@1: 81.2500 (77.9523)  Acc@5: 100.0000 (98.6090)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.1407  Acc@1: 81.2500 (77.9536)  Acc@5: 100.0000 (98.6054)  time: 0.3538  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1340/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.1574  Acc@1: 75.0000 (77.9456)  Acc@5: 100.0000 (98.6158)  time: 0.3529  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1350/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.4984  Acc@1: 75.0000 (77.9469)  Acc@5: 100.0000 (98.6168)  time: 0.3526  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1360/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.6966  Acc@1: 81.2500 (77.9620)  Acc@5: 100.0000 (98.6177)  time: 0.3522  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.7384  Acc@1: 81.2500 (77.9677)  Acc@5: 100.0000 (98.6187)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.4995  Acc@1: 75.0000 (77.9598)  Acc@5: 100.0000 (98.6197)  time: 0.3534  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.4451  Acc@1: 75.0000 (77.9790)  Acc@5: 100.0000 (98.6206)  time: 0.3524  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.5725  Acc@1: 87.5000 (77.9934)  Acc@5: 100.0000 (98.6215)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6303  Acc@1: 81.2500 (77.9988)  Acc@5: 100.0000 (98.6003)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.8925  Acc@1: 81.2500 (78.0348)  Acc@5: 100.0000 (98.6057)  time: 0.3501  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:36  Lr: 0.001875  Loss: 0.0886  Acc@1: 81.2500 (78.0573)  Acc@5: 100.0000 (98.6111)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.4301  Acc@1: 75.0000 (78.0448)  Acc@5: 100.0000 (98.6034)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5630  Acc@1: 68.7500 (77.9893)  Acc@5: 100.0000 (98.6044)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.7895  Acc@1: 68.7500 (77.9817)  Acc@5: 100.0000 (98.5926)  time: 0.3506  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.5564  Acc@1: 75.0000 (77.9487)  Acc@5: 100.0000 (98.5851)  time: 0.3508  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.7642  Acc@1: 75.0000 (77.9499)  Acc@5: 100.0000 (98.5820)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.4035  Acc@1: 75.0000 (77.9175)  Acc@5: 100.0000 (98.5874)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.5857  Acc@1: 75.0000 (77.9189)  Acc@5: 100.0000 (98.5884)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1510/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.8346  Acc@1: 75.0000 (77.8996)  Acc@5: 100.0000 (98.5812)  time: 0.3543  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1520/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.7942  Acc@1: 68.7500 (77.8887)  Acc@5: 100.0000 (98.5823)  time: 0.3558  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1530/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.2700  Acc@1: 68.7500 (77.8372)  Acc@5: 100.0000 (98.5753)  time: 0.3527  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.6881  Acc@1: 75.0000 (77.8553)  Acc@5: 100.0000 (98.5845)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.4531  Acc@1: 81.2500 (77.8409)  Acc@5: 100.0000 (98.5896)  time: 0.3533  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.9447  Acc@1: 81.2500 (77.8587)  Acc@5: 100.0000 (98.5906)  time: 0.3535  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.5141  Acc@1: 81.2500 (77.8724)  Acc@5: 100.0000 (98.5917)  time: 0.3540  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.8266  Acc@1: 81.2500 (77.8858)  Acc@5: 100.0000 (98.5966)  time: 0.3530  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.4994  Acc@1: 81.2500 (77.9227)  Acc@5: 100.0000 (98.6015)  time: 0.3515  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.6438  Acc@1: 81.2500 (77.9161)  Acc@5: 100.0000 (98.6024)  time: 0.3523  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.6355  Acc@1: 75.0000 (77.8942)  Acc@5: 100.0000 (98.6034)  time: 0.3541  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -0.4147  Acc@1: 81.2500 (77.9149)  Acc@5: 100.0000 (98.6004)  time: 0.3557  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.4534  Acc@1: 81.2500 (77.9200)  Acc@5: 100.0000 (98.6090)  time: 0.3531  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -0.5744  Acc@1: 81.2500 (77.9289)  Acc@5: 100.0000 (98.6022)  time: 0.3533  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.4048  Acc@1: 75.0000 (77.9187)  Acc@5: 100.0000 (98.6031)  time: 0.3528  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:15  Lr: 0.001875  Loss: -0.4196  Acc@1: 75.0000 (77.9049)  Acc@5: 100.0000 (98.6002)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.9117  Acc@1: 81.2500 (77.9286)  Acc@5: 100.0000 (98.5937)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -0.5527  Acc@1: 75.0000 (77.9001)  Acc@5: 100.0000 (98.5983)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1690/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.6027  Acc@1: 75.0000 (77.9088)  Acc@5: 100.0000 (98.5918)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1700/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.7218  Acc@1: 81.2500 (77.9101)  Acc@5: 100.0000 (98.5964)  time: 0.3504  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.3651  Acc@1: 81.2500 (77.8967)  Acc@5: 100.0000 (98.5973)  time: 0.3519  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.4932  Acc@1: 75.0000 (77.8799)  Acc@5: 100.0000 (98.6018)  time: 0.3523  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.2384  Acc@1: 68.7500 (77.8488)  Acc@5: 100.0000 (98.6063)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.4415  Acc@1: 75.0000 (77.8468)  Acc@5: 100.0000 (98.6071)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:43  Lr: 0.001875  Loss: 0.0258  Acc@1: 75.0000 (77.8234)  Acc@5: 100.0000 (98.6079)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.1323  Acc@1: 75.0000 (77.8180)  Acc@5: 100.0000 (98.6087)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.5880  Acc@1: 75.0000 (77.8303)  Acc@5: 100.0000 (98.6131)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.6256  Acc@1: 81.2500 (77.8355)  Acc@5: 100.0000 (98.6138)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.6861  Acc@1: 75.0000 (77.8231)  Acc@5: 100.0000 (98.6146)  time: 0.3512  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.6314  Acc@1: 81.2500 (77.8179)  Acc@5: 100.0000 (98.6154)  time: 0.3517  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.3553  Acc@1: 81.2500 (77.8230)  Acc@5: 100.0000 (98.6230)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.6005  Acc@1: 75.0000 (77.7904)  Acc@5: 100.0000 (98.6237)  time: 0.3510  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.1386  Acc@1: 68.7500 (77.7546)  Acc@5: 100.0000 (98.6210)  time: 0.3516  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.4795  Acc@1: 75.0000 (77.7465)  Acc@5: 100.0000 (98.6217)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.3519  Acc@1: 75.0000 (77.7857)  Acc@5: 100.0000 (98.6257)  time: 0.3534  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1860/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -0.8218  Acc@1: 81.2500 (77.8143)  Acc@5: 100.0000 (98.6264)  time: 0.3516  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1870/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.2539  Acc@1: 81.2500 (77.8394)  Acc@5: 100.0000 (98.6237)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.4731  Acc@1: 81.2500 (77.8343)  Acc@5: 100.0000 (98.6277)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.8404  Acc@1: 75.0000 (77.8622)  Acc@5: 100.0000 (98.6185)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.7299  Acc@1: 81.2500 (77.8735)  Acc@5: 100.0000 (98.6159)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.2153  Acc@1: 75.0000 (77.8552)  Acc@5: 100.0000 (98.6166)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.7667  Acc@1: 81.2500 (77.8956)  Acc@5: 100.0000 (98.6205)  time: 0.3536  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.5253  Acc@1: 81.2500 (77.8612)  Acc@5: 100.0000 (98.6277)  time: 0.3549  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.8211  Acc@1: 75.0000 (77.8916)  Acc@5: 100.0000 (98.6347)  time: 0.3515  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -1.0294  Acc@1: 81.2500 (77.9152)  Acc@5: 100.0000 (98.6321)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.6911  Acc@1: 81.2500 (77.9258)  Acc@5: 100.0000 (98.6327)  time: 0.3526  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.8962  Acc@1: 81.2500 (77.9300)  Acc@5: 100.0000 (98.6333)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.3931  Acc@1: 75.0000 (77.9373)  Acc@5: 100.0000 (98.6402)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.4575  Acc@1: 75.0000 (77.9162)  Acc@5: 100.0000 (98.6282)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.6818  Acc@1: 75.0000 (77.9204)  Acc@5: 100.0000 (98.6257)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.2829  Acc@1: 81.2500 (77.9028)  Acc@5: 100.0000 (98.6170)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.7331  Acc@1: 81.2500 (77.9224)  Acc@5: 100.0000 (98.6207)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.8431  Acc@1: 81.2500 (77.9204)  Acc@5: 100.0000 (98.6121)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2040/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.4858  Acc@1: 81.2500 (77.9305)  Acc@5: 100.0000 (98.6159)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.2504  Acc@1: 81.2500 (77.9010)  Acc@5: 100.0000 (98.6074)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.5591  Acc@1: 75.0000 (77.8748)  Acc@5: 100.0000 (98.6081)  time: 0.3550  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.5262  Acc@1: 68.7500 (77.8549)  Acc@5: 100.0000 (98.6027)  time: 0.3545  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.5503  Acc@1: 68.7500 (77.8412)  Acc@5: 100.0000 (98.6034)  time: 0.3528  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.3446  Acc@1: 75.0000 (77.8306)  Acc@5: 100.0000 (98.6011)  time: 0.3523  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.7429  Acc@1: 81.2500 (77.8647)  Acc@5: 100.0000 (98.6019)  time: 0.3539  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.4757  Acc@1: 81.2500 (77.8778)  Acc@5: 100.0000 (98.6055)  time: 0.3581  data: 0.0032  max mem: 2503
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.4915  Acc@1: 81.2500 (77.8731)  Acc@5: 100.0000 (98.6033)  time: 0.3585  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.5960  Acc@1: 81.2500 (77.8948)  Acc@5: 100.0000 (98.6098)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.1702  Acc@1: 81.2500 (77.8929)  Acc@5: 100.0000 (98.6075)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.7887  Acc@1: 81.2500 (77.8911)  Acc@5: 100.0000 (98.6082)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.3624  Acc@1: 75.0000 (77.8835)  Acc@5: 100.0000 (98.6089)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.5402  Acc@1: 75.0000 (77.8904)  Acc@5: 100.0000 (98.6009)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.4045  Acc@1: 75.0000 (77.8771)  Acc@5: 100.0000 (98.6044)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4887  Acc@1: 75.0000 (77.8840)  Acc@5: 100.0000 (98.6079)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.7995  Acc@1: 81.2500 (77.8822)  Acc@5: 100.0000 (98.6114)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2210/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.7550  Acc@1: 81.2500 (77.8918)  Acc@5: 100.0000 (98.6177)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.6039  Acc@1: 81.2500 (77.9125)  Acc@5: 100.0000 (98.6155)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.6416  Acc@1: 81.2500 (77.9107)  Acc@5: 100.0000 (98.6133)  time: 0.3527  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.4120  Acc@1: 75.0000 (77.9005)  Acc@5: 100.0000 (98.6111)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.6044  Acc@1: 75.0000 (77.9154)  Acc@5: 100.0000 (98.6062)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.9297  Acc@1: 75.0000 (77.9052)  Acc@5: 100.0000 (98.6040)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.6429  Acc@1: 75.0000 (77.8980)  Acc@5: 100.0000 (98.5992)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.6703  Acc@1: 75.0000 (77.8907)  Acc@5: 100.0000 (98.6026)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.5156  Acc@1: 81.2500 (77.9054)  Acc@5: 100.0000 (98.6087)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.3128  Acc@1: 75.0000 (77.8900)  Acc@5: 100.0000 (98.6066)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.5742  Acc@1: 75.0000 (77.8938)  Acc@5: 100.0000 (98.6099)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.4851  Acc@1: 81.2500 (77.9190)  Acc@5: 100.0000 (98.6132)  time: 0.3512  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.5251  Acc@1: 81.2500 (77.9199)  Acc@5: 100.0000 (98.6138)  time: 0.3527  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.7131  Acc@1: 81.2500 (77.9181)  Acc@5: 100.0000 (98.6117)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.7245  Acc@1: 81.2500 (77.9137)  Acc@5: 100.0000 (98.6070)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:08  Lr: 0.001875  Loss: 0.0041  Acc@1: 75.0000 (77.9066)  Acc@5: 100.0000 (98.6129)  time: 0.3521  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.6998  Acc@1: 81.2500 (77.9023)  Acc@5: 100.0000 (98.6187)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2380/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.6909  Acc@1: 81.2500 (77.9242)  Acc@5: 100.0000 (98.6193)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.6086  Acc@1: 81.2500 (77.9381)  Acc@5: 100.0000 (98.6224)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.4682  Acc@1: 81.2500 (77.9207)  Acc@5: 100.0000 (98.6256)  time: 0.3539  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.3073  Acc@1: 75.0000 (77.9397)  Acc@5: 100.0000 (98.6313)  time: 0.3526  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.6898  Acc@1: 81.2500 (77.9378)  Acc@5: 100.0000 (98.6343)  time: 0.3515  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.4400  Acc@1: 75.0000 (77.9283)  Acc@5: 100.0000 (98.6168)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.7075  Acc@1: 75.0000 (77.9342)  Acc@5: 100.0000 (98.6122)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.2131  Acc@1: 81.2500 (77.9503)  Acc@5: 100.0000 (98.6103)  time: 0.3559  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.4780  Acc@1: 81.2500 (77.9637)  Acc@5: 100.0000 (98.6134)  time: 0.3525  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.5001  Acc@1: 81.2500 (77.9694)  Acc@5: 100.0000 (98.6139)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.7165  Acc@1: 81.2500 (77.9726)  Acc@5: 100.0000 (98.6120)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.3905  Acc@1: 75.0000 (77.9632)  Acc@5: 100.0000 (98.6100)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6789  Acc@1: 81.2500 (77.9838)  Acc@5: 100.0000 (98.6131)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.4477  Acc@1: 81.2500 (77.9769)  Acc@5: 100.0000 (98.6161)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.5277  Acc@1: 75.0000 (77.9453)  Acc@5: 100.0000 (98.6042)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.2044  Acc@1: 68.7500 (77.9163)  Acc@5: 100.0000 (98.6048)  time: 0.3491  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.8810  Acc@1: 81.2500 (77.9418)  Acc@5: 100.0000 (98.6054)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2550/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.6996  Acc@1: 81.2500 (77.9645)  Acc@5: 100.0000 (98.6108)  time: 0.3494  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.8794  Acc@1: 81.2500 (77.9529)  Acc@5: 100.0000 (98.6065)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.9577  Acc@1: 81.2500 (77.9706)  Acc@5: 100.0000 (98.6119)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.5520  Acc@1: 81.2500 (77.9519)  Acc@5: 100.0000 (98.6173)  time: 0.3506  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.4600  Acc@1: 75.0000 (77.9525)  Acc@5: 100.0000 (98.6202)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.3119  Acc@1: 75.0000 (77.9460)  Acc@5: 100.0000 (98.6255)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.5633  Acc@1: 75.0000 (77.9395)  Acc@5: 100.0000 (98.6236)  time: 0.3502  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.3877  Acc@1: 75.0000 (77.9545)  Acc@5: 100.0000 (98.6289)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -1.0447  Acc@1: 81.2500 (77.9837)  Acc@5: 100.0000 (98.6269)  time: 0.3527  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6220  Acc@1: 81.2500 (77.9889)  Acc@5: 100.0000 (98.6274)  time: 0.3552  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.8200  Acc@1: 75.0000 (77.9824)  Acc@5: 100.0000 (98.6279)  time: 0.3544  data: 0.0024  max mem: 2503
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.4100  Acc@1: 81.2500 (77.9806)  Acc@5: 100.0000 (98.6283)  time: 0.3512  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.8249  Acc@1: 81.2500 (77.9694)  Acc@5: 100.0000 (98.6265)  time: 0.3514  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.4048  Acc@1: 75.0000 (77.9700)  Acc@5: 100.0000 (98.6292)  time: 0.3540  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.8394  Acc@1: 75.0000 (77.9682)  Acc@5: 100.0000 (98.6274)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.1162  Acc@1: 75.0000 (77.9619)  Acc@5: 100.0000 (98.6232)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.7274  Acc@1: 75.0000 (77.9717)  Acc@5: 100.0000 (98.6260)  time: 0.3497  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2720/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.8363  Acc@1: 81.2500 (77.9814)  Acc@5: 100.0000 (98.6287)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.5019  Acc@1: 81.2500 (77.9843)  Acc@5: 100.0000 (98.6292)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.9264  Acc@1: 81.2500 (77.9802)  Acc@5: 100.0000 (98.6250)  time: 0.3542  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.4721  Acc@1: 75.0000 (77.9853)  Acc@5: 100.0000 (98.6278)  time: 0.3559  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.4702  Acc@1: 75.0000 (78.0016)  Acc@5: 100.0000 (98.6282)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.4470  Acc@1: 75.0000 (78.0111)  Acc@5: 100.0000 (98.6287)  time: 0.3516  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.4228  Acc@1: 81.2500 (78.0182)  Acc@5: 100.0000 (98.6291)  time: 0.3530  data: 0.0024  max mem: 2503
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -1.0530  Acc@1: 75.0000 (78.0276)  Acc@5: 100.0000 (98.6228)  time: 0.3516  data: 0.0034  max mem: 2503
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.2143  Acc@1: 81.2500 (78.0436)  Acc@5: 100.0000 (98.6233)  time: 0.3493  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.7621  Acc@1: 81.2500 (78.0616)  Acc@5: 100.0000 (98.6193)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.4276  Acc@1: 81.2500 (78.0685)  Acc@5: 100.0000 (98.6175)  time: 0.3524  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4934  Acc@1: 81.2500 (78.0819)  Acc@5: 100.0000 (98.6224)  time: 0.3518  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.7267  Acc@1: 81.2500 (78.0909)  Acc@5: 100.0000 (98.6228)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.2239  Acc@1: 75.0000 (78.0691)  Acc@5: 100.0000 (98.6255)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.9541  Acc@1: 75.0000 (78.0868)  Acc@5: 100.0000 (98.6303)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.7593  Acc@1: 81.2500 (78.1043)  Acc@5: 100.0000 (98.6285)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.7236  Acc@1: 81.2500 (78.0935)  Acc@5: 100.0000 (98.6268)  time: 0.3503  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.0934  Acc@1: 75.0000 (78.0828)  Acc@5: 100.0000 (98.6272)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.9033  Acc@1: 68.7500 (78.0679)  Acc@5: 100.0000 (98.6212)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.5766  Acc@1: 75.0000 (78.0745)  Acc@5: 100.0000 (98.6173)  time: 0.3543  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.3132  Acc@1: 75.0000 (78.0619)  Acc@5: 100.0000 (98.6178)  time: 0.3535  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.7748  Acc@1: 75.0000 (78.0429)  Acc@5: 100.0000 (98.6118)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.8523  Acc@1: 75.0000 (78.0687)  Acc@5: 100.0000 (98.6165)  time: 0.3514  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.3327  Acc@1: 81.2500 (78.0689)  Acc@5: 100.0000 (98.6106)  time: 0.3524  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.0518  Acc@1: 75.0000 (78.0437)  Acc@5: 100.0000 (98.6090)  time: 0.3545  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.6743  Acc@1: 75.0000 (78.0587)  Acc@5: 100.0000 (98.6095)  time: 0.3540  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.4193  Acc@1: 81.2500 (78.0569)  Acc@5: 100.0000 (98.6037)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5109  Acc@1: 81.2500 (78.0613)  Acc@5: 100.0000 (98.6021)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.5049  Acc@1: 81.2500 (78.0573)  Acc@5: 100.0000 (98.6067)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7793  Acc@1: 81.2500 (78.0783)  Acc@5: 100.0000 (98.6093)  time: 0.3524  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.5866  Acc@1: 81.2500 (78.0785)  Acc@5: 100.0000 (98.6097)  time: 0.3542  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3834  Acc@1: 81.2500 (78.0704)  Acc@5: 100.0000 (98.6081)  time: 0.3526  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.6456  Acc@1: 75.0000 (78.0561)  Acc@5: 100.0000 (98.6065)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.8215  Acc@1: 75.0000 (78.0523)  Acc@5: 100.0000 (98.6070)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -0.7897  Acc@1: 75.0000 (78.0382)  Acc@5: 100.0000 (98.6075)  time: 0.3516  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.8161  Acc@1: 68.7500 (78.0202)  Acc@5: 100.0000 (98.6059)  time: 0.3507  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -0.3961  Acc@1: 68.7500 (78.0104)  Acc@5: 100.0000 (98.6104)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.5581  Acc@1: 75.0000 (78.0067)  Acc@5: 100.0000 (98.6109)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7774  Acc@1: 75.0000 (78.0152)  Acc@5: 100.0000 (98.6033)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.4560  Acc@1: 81.2500 (78.0155)  Acc@5: 100.0000 (98.6058)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6008  Acc@1: 81.2500 (78.0279)  Acc@5: 100.0000 (98.6102)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6102  Acc@1: 81.2500 (78.0202)  Acc@5: 100.0000 (98.6087)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -0.6720  Acc@1: 75.0000 (78.0205)  Acc@5: 100.0000 (98.6091)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.8709  Acc@1: 75.0000 (78.0228)  Acc@5: 100.0000 (98.6076)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.5955  Acc@1: 75.0000 (78.0172)  Acc@5: 100.0000 (98.6080)  time: 0.3507  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.6389  Acc@1: 81.2500 (78.0176)  Acc@5: 100.0000 (98.6124)  time: 0.3512  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -0.9473  Acc@1: 81.2500 (78.0238)  Acc@5: 100.0000 (98.6129)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.0896  Acc@1: 81.2500 (78.0261)  Acc@5: 100.0000 (98.6094)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.3230  Acc@1: 75.0000 (78.0166)  Acc@5: 100.0000 (98.6118)  time: 0.3521  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.6254  Acc@1: 75.0000 (78.0228)  Acc@5: 100.0000 (98.6161)  time: 0.3520  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.6272  Acc@1: 81.2500 (78.0406)  Acc@5: 100.0000 (98.6165)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.7364  Acc@1: 81.2500 (78.0409)  Acc@5: 100.0000 (98.6169)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.8779  Acc@1: 75.0000 (78.0392)  Acc@5: 100.0000 (98.6193)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.7638  Acc@1: 75.0000 (78.0337)  Acc@5: 100.0000 (98.6216)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.3761  Acc@1: 75.0000 (78.0397)  Acc@5: 100.0000 (98.6258)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.7946  Acc@1: 81.2500 (78.0476)  Acc@5: 100.0000 (98.6262)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.6941  Acc@1: 81.2500 (78.0326)  Acc@5: 100.0000 (98.6266)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.9961  Acc@1: 75.0000 (78.0329)  Acc@5: 100.0000 (98.6269)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.9433  Acc@1: 75.0000 (78.0332)  Acc@5: 100.0000 (98.6216)  time: 0.3509  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.9534  Acc@1: 81.2500 (78.0372)  Acc@5: 100.0000 (98.6201)  time: 0.3524  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5033  Acc@1: 81.2500 (78.0356)  Acc@5: 100.0000 (98.6243)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.9058  Acc@1: 81.2500 (78.0490)  Acc@5: 100.0000 (98.6209)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.2761  Acc@1: 81.2500 (78.0455)  Acc@5: 100.0000 (98.6250)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.6246  Acc@1: 75.0000 (78.0383)  Acc@5: 100.0000 (98.6235)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.8157  Acc@1: 75.0000 (78.0348)  Acc@5: 100.0000 (98.6202)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -1.0269  Acc@1: 81.2500 (78.0518)  Acc@5: 100.0000 (98.6206)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.8550  Acc@1: 87.5000 (78.0649)  Acc@5: 100.0000 (98.6173)  time: 0.3505  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.7738  Acc@1: 81.2500 (78.0614)  Acc@5: 100.0000 (98.6195)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.8756  Acc@1: 75.0000 (78.0542)  Acc@5: 100.0000 (98.6217)  time: 0.3498  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6657  Acc@1: 75.0000 (78.0545)  Acc@5: 100.0000 (98.6239)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.6835  Acc@1: 81.2500 (78.0675)  Acc@5: 100.0000 (98.6261)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.2715  Acc@1: 81.2500 (78.0913)  Acc@5: 100.0000 (98.6283)  time: 0.3500  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9613  Acc@1: 81.2500 (78.1041)  Acc@5: 100.0000 (98.6269)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.5842  Acc@1: 75.0000 (78.0897)  Acc@5: 100.0000 (98.6272)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5974  Acc@1: 75.0000 (78.0952)  Acc@5: 100.0000 (98.6294)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.8285  Acc@1: 75.0000 (78.0881)  Acc@5: 100.0000 (98.6279)  time: 0.3531  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.4060  Acc@1: 75.0000 (78.0972)  Acc@5: 100.0000 (98.6265)  time: 0.3522  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.3883  Acc@1: 81.2500 (78.0901)  Acc@5: 100.0000 (98.6286)  time: 0.3530  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.7710  Acc@1: 81.2500 (78.0955)  Acc@5: 100.0000 (98.6325)  time: 0.3524  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5121  Acc@1: 75.0000 (78.0956)  Acc@5: 100.0000 (98.6346)  time: 0.3505  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.1836  Acc@1: 75.0000 (78.0975)  Acc@5: 100.0000 (98.6332)  time: 0.3528  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6592  Acc@1: 81.2500 (78.1153)  Acc@5: 100.0000 (98.6335)  time: 0.3553  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4349  Acc@1: 87.5000 (78.1276)  Acc@5: 100.0000 (98.6321)  time: 0.3540  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.8599  Acc@1: 81.2500 (78.1259)  Acc@5: 100.0000 (98.6324)  time: 0.3523  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.8737  Acc@1: 81.2500 (78.1329)  Acc@5: 100.0000 (98.6275)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.5407  Acc@1: 81.2500 (78.1451)  Acc@5: 100.0000 (98.6278)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.3517  Acc@1: 81.2500 (78.1433)  Acc@5: 100.0000 (98.6264)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.7218  Acc@1: 81.2500 (78.1607)  Acc@5: 100.0000 (98.6285)  time: 0.3541  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8578  Acc@1: 81.2500 (78.1571)  Acc@5: 100.0000 (98.6289)  time: 0.3576  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.5219  Acc@1: 75.0000 (78.1588)  Acc@5: 100.0000 (98.6309)  time: 0.3544  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.7444  Acc@1: 81.2500 (78.1742)  Acc@5: 100.0000 (98.6347)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.4855  Acc@1: 75.0000 (78.1637)  Acc@5: 100.0000 (98.6367)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.6285  Acc@1: 75.0000 (78.1585)  Acc@5: 100.0000 (98.6302)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6991  Acc@1: 75.0000 (78.1447)  Acc@5: 100.0000 (98.6288)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5776  Acc@1: 75.0000 (78.1327)  Acc@5: 100.0000 (98.6325)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.7847  Acc@1: 75.0000 (78.1327)  Acc@5: 100.0000 (98.6346)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9140  Acc@1: 81.2500 (78.1394)  Acc@5: 100.0000 (98.6332)  time: 0.3546  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0235  Acc@1: 81.2500 (78.1394)  Acc@5: 100.0000 (98.6369)  time: 0.3534  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5326  Acc@1: 75.0000 (78.1444)  Acc@5: 100.0000 (98.6355)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4649  Acc@1: 81.2500 (78.1545)  Acc@5: 100.0000 (98.6341)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6553  Acc@1: 81.2500 (78.1494)  Acc@5: 100.0000 (98.6344)  time: 0.3547  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8390  Acc@1: 81.2500 (78.1526)  Acc@5: 100.0000 (98.6314)  time: 0.3548  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6723  Acc@1: 81.2500 (78.1542)  Acc@5: 100.0000 (98.6334)  time: 0.3512  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9447  Acc@1: 81.2500 (78.1633)  Acc@5: 100.0000 (98.6300)  time: 0.3515  data: 0.0010  max mem: 2503
Train: Epoch[2/5] Total time: 0:21:59 (0.3518 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}}
Averaged stats: Lr: 0.001875  Loss: -0.9447  Acc@1: 81.2500 (78.1633)  Acc@5: 100.0000 (98.6300)
Train: Epoch[3/5]  [   0/3750]  eta: 0:58:52  Lr: 0.001875  Loss: -1.0066  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.9421  data: 0.5936  max mem: 2503
Train: Epoch[3/5]  [  10/3750]  eta: 0:25:18  Lr: 0.001875  Loss: -0.1192  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (98.2955)  time: 0.4059  data: 0.0544  max mem: 2503
Train: Epoch[3/5]  [  20/3750]  eta: 0:23:37  Lr: 0.001875  Loss: -0.5032  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (98.5119)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:57  Lr: 0.001875  Loss: -0.5570  Acc@1: 75.0000 (78.4274)  Acc@5: 100.0000 (98.1855)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:37  Lr: 0.001875  Loss: -0.3546  Acc@1: 75.0000 (77.5915)  Acc@5: 100.0000 (98.3232)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [  50/3750]  eta: 0:22:23  Lr: 0.001875  Loss: -0.6999  Acc@1: 81.2500 (77.5735)  Acc@5: 100.0000 (98.2843)  time: 0.3521  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [  60/3750]  eta: 0:22:12  Lr: 0.001875  Loss: -0.8146  Acc@1: 81.2500 (77.4590)  Acc@5: 100.0000 (98.4631)  time: 0.3512  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [  70/3750]  eta: 0:22:05  Lr: 0.001875  Loss: -0.8174  Acc@1: 75.0000 (77.6408)  Acc@5: 100.0000 (98.5915)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -0.4769  Acc@1: 75.0000 (77.7006)  Acc@5: 100.0000 (98.6883)  time: 0.3541  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.8502  Acc@1: 81.2500 (78.1593)  Acc@5: 100.0000 (98.6951)  time: 0.3524  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.7752  Acc@1: 81.2500 (78.5891)  Acc@5: 100.0000 (98.7624)  time: 0.3499  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.3246  Acc@1: 81.2500 (78.3784)  Acc@5: 100.0000 (98.7050)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.7985  Acc@1: 81.2500 (78.9773)  Acc@5: 100.0000 (98.8120)  time: 0.3519  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.4905  Acc@1: 81.2500 (78.8645)  Acc@5: 100.0000 (98.8550)  time: 0.3541  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.9231  Acc@1: 75.0000 (79.0337)  Acc@5: 100.0000 (98.9362)  time: 0.3545  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.6519  Acc@1: 75.0000 (79.0977)  Acc@5: 100.0000 (98.9652)  time: 0.3509  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.8757  Acc@1: 75.0000 (79.2702)  Acc@5: 100.0000 (98.9519)  time: 0.3496  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 170/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.5947  Acc@1: 75.0000 (78.9474)  Acc@5: 100.0000 (98.8670)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 180/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -0.7385  Acc@1: 75.0000 (78.8674)  Acc@5: 100.0000 (98.8260)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 190/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.3814  Acc@1: 81.2500 (78.9267)  Acc@5: 100.0000 (98.7893)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.7952  Acc@1: 81.2500 (78.7624)  Acc@5: 100.0000 (98.8184)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.6002  Acc@1: 75.0000 (78.4953)  Acc@5: 100.0000 (98.7559)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.7840  Acc@1: 75.0000 (78.4219)  Acc@5: 100.0000 (98.6991)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.4308  Acc@1: 75.0000 (78.4903)  Acc@5: 100.0000 (98.7013)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.9656  Acc@1: 75.0000 (78.6826)  Acc@5: 100.0000 (98.7033)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.1533  Acc@1: 81.2500 (78.6355)  Acc@5: 100.0000 (98.6554)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.6290  Acc@1: 81.2500 (78.6638)  Acc@5: 100.0000 (98.6590)  time: 0.3505  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.6073  Acc@1: 81.2500 (78.6439)  Acc@5: 100.0000 (98.6624)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.8581  Acc@1: 81.2500 (78.7144)  Acc@5: 100.0000 (98.6432)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.6351  Acc@1: 75.0000 (78.6727)  Acc@5: 100.0000 (98.6469)  time: 0.3514  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.7579  Acc@1: 75.0000 (78.7375)  Acc@5: 100.0000 (98.6919)  time: 0.3545  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.9118  Acc@1: 81.2500 (78.7580)  Acc@5: 100.0000 (98.7138)  time: 0.3580  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 320/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.4615  Acc@1: 75.0000 (78.5826)  Acc@5: 100.0000 (98.6955)  time: 0.3547  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [ 330/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.7798  Acc@1: 75.0000 (78.5310)  Acc@5: 100.0000 (98.7349)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 340/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.5366  Acc@1: 75.0000 (78.5007)  Acc@5: 100.0000 (98.7720)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 350/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.6142  Acc@1: 75.0000 (78.5613)  Acc@5: 100.0000 (98.7892)  time: 0.3519  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.7350  Acc@1: 81.2500 (78.6530)  Acc@5: 100.0000 (98.8227)  time: 0.3543  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.1207  Acc@1: 81.2500 (78.7399)  Acc@5: 100.0000 (98.7871)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.6147  Acc@1: 75.0000 (78.5761)  Acc@5: 100.0000 (98.7533)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.6579  Acc@1: 75.0000 (78.6445)  Acc@5: 100.0000 (98.7532)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.6205  Acc@1: 81.2500 (78.7718)  Acc@5: 100.0000 (98.7687)  time: 0.3547  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.9882  Acc@1: 81.2500 (78.9082)  Acc@5: 100.0000 (98.7835)  time: 0.3539  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.6266  Acc@1: 81.2500 (78.9638)  Acc@5: 100.0000 (98.7827)  time: 0.3506  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.7247  Acc@1: 81.2500 (79.0168)  Acc@5: 100.0000 (98.7964)  time: 0.3532  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.7233  Acc@1: 81.2500 (79.0249)  Acc@5: 100.0000 (98.8095)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.8242  Acc@1: 75.0000 (78.9911)  Acc@5: 100.0000 (98.8221)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.6406  Acc@1: 81.2500 (78.9995)  Acc@5: 100.0000 (98.8341)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.7539  Acc@1: 81.2500 (79.0207)  Acc@5: 100.0000 (98.8455)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.5153  Acc@1: 81.2500 (78.9761)  Acc@5: 100.0000 (98.8436)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 490/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.4124  Acc@1: 75.0000 (78.8951)  Acc@5: 100.0000 (98.8289)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 500/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.5659  Acc@1: 75.0000 (78.8673)  Acc@5: 100.0000 (98.8273)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 510/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.5294  Acc@1: 75.0000 (78.8772)  Acc@5: 100.0000 (98.8136)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.3660  Acc@1: 81.2500 (78.9587)  Acc@5: 100.0000 (98.8124)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.5194  Acc@1: 81.2500 (78.9901)  Acc@5: 100.0000 (98.8230)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.7775  Acc@1: 75.0000 (78.9048)  Acc@5: 100.0000 (98.7985)  time: 0.3533  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.9524  Acc@1: 81.2500 (78.9247)  Acc@5: 100.0000 (98.7976)  time: 0.3557  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.6096  Acc@1: 81.2500 (78.8547)  Acc@5: 100.0000 (98.7745)  time: 0.3549  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.6578  Acc@1: 81.2500 (78.9733)  Acc@5: 100.0000 (98.7522)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -0.6399  Acc@1: 87.5000 (79.0448)  Acc@5: 100.0000 (98.7737)  time: 0.3537  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.7811  Acc@1: 75.0000 (78.9869)  Acc@5: 100.0000 (98.7733)  time: 0.3551  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.7084  Acc@1: 75.0000 (78.9621)  Acc@5: 100.0000 (98.7521)  time: 0.3534  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.0101  Acc@1: 81.2500 (79.0303)  Acc@5: 100.0000 (98.7520)  time: 0.3524  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.2613  Acc@1: 81.2500 (78.9251)  Acc@5: 100.0000 (98.7319)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.5409  Acc@1: 81.2500 (78.9521)  Acc@5: 100.0000 (98.7223)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.5564  Acc@1: 81.2500 (78.9587)  Acc@5: 100.0000 (98.7227)  time: 0.3531  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.8382  Acc@1: 75.0000 (78.8786)  Acc@5: 100.0000 (98.7327)  time: 0.3524  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 660/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.6633  Acc@1: 81.2500 (78.9523)  Acc@5: 100.0000 (98.7519)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 670/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.7297  Acc@1: 81.2500 (78.9214)  Acc@5: 100.0000 (98.7519)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 680/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.3588  Acc@1: 81.2500 (78.9739)  Acc@5: 100.0000 (98.7610)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.1560  Acc@1: 87.5000 (79.0159)  Acc@5: 100.0000 (98.7428)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.7575  Acc@1: 81.2500 (79.0210)  Acc@5: 100.0000 (98.7250)  time: 0.3552  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.7433  Acc@1: 81.2500 (79.0788)  Acc@5: 100.0000 (98.7254)  time: 0.3541  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -1.0851  Acc@1: 81.2500 (79.1436)  Acc@5: 100.0000 (98.7257)  time: 0.3501  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.1863  Acc@1: 81.2500 (79.1382)  Acc@5: 100.0000 (98.7090)  time: 0.3503  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -0.7260  Acc@1: 81.2500 (79.2257)  Acc@5: 100.0000 (98.7011)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.5620  Acc@1: 81.2500 (79.1528)  Acc@5: 100.0000 (98.6851)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.8374  Acc@1: 75.0000 (79.1311)  Acc@5: 100.0000 (98.7024)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.0296  Acc@1: 81.2500 (79.1829)  Acc@5: 100.0000 (98.6787)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.6781  Acc@1: 81.2500 (79.2093)  Acc@5: 100.0000 (98.6956)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.7497  Acc@1: 81.2500 (79.1956)  Acc@5: 100.0000 (98.7121)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.2084  Acc@1: 81.2500 (79.1745)  Acc@5: 100.0000 (98.6813)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.9409  Acc@1: 81.2500 (79.2232)  Acc@5: 100.0000 (98.6899)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.8592  Acc@1: 75.0000 (79.1641)  Acc@5: 100.0000 (98.6906)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 830/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.5916  Acc@1: 75.0000 (79.1667)  Acc@5: 100.0000 (98.6989)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 840/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.4394  Acc@1: 81.2500 (79.1394)  Acc@5: 100.0000 (98.7069)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 850/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.7150  Acc@1: 81.2500 (79.1422)  Acc@5: 100.0000 (98.7221)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.3915  Acc@1: 81.2500 (79.1521)  Acc@5: 100.0000 (98.7224)  time: 0.3502  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.5790  Acc@1: 81.2500 (79.1475)  Acc@5: 100.0000 (98.7299)  time: 0.3532  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.3628  Acc@1: 81.2500 (79.1714)  Acc@5: 100.0000 (98.7372)  time: 0.3574  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.7541  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (98.7444)  time: 0.3546  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.4624  Acc@1: 81.2500 (79.0996)  Acc@5: 100.0000 (98.7375)  time: 0.3506  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.6442  Acc@1: 75.0000 (79.0409)  Acc@5: 100.0000 (98.7445)  time: 0.3509  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.4536  Acc@1: 75.0000 (79.0309)  Acc@5: 100.0000 (98.7378)  time: 0.3519  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.7601  Acc@1: 75.0000 (79.0011)  Acc@5: 100.0000 (98.7312)  time: 0.3523  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.4264  Acc@1: 81.2500 (79.0183)  Acc@5: 100.0000 (98.7380)  time: 0.3529  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.9134  Acc@1: 81.2500 (79.0484)  Acc@5: 100.0000 (98.7382)  time: 0.3543  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.7961  Acc@1: 87.5000 (79.0843)  Acc@5: 100.0000 (98.7448)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.6577  Acc@1: 81.2500 (79.1066)  Acc@5: 100.0000 (98.7513)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.7698  Acc@1: 81.2500 (79.1030)  Acc@5: 100.0000 (98.7576)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.5559  Acc@1: 81.2500 (79.1120)  Acc@5: 100.0000 (98.7576)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1000/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.7967  Acc@1: 81.2500 (79.0897)  Acc@5: 100.0000 (98.7575)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1010/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.1955  Acc@1: 81.2500 (79.1172)  Acc@5: 100.0000 (98.7512)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1020/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.5149  Acc@1: 81.2500 (79.1381)  Acc@5: 100.0000 (98.7573)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.6485  Acc@1: 81.2500 (79.1586)  Acc@5: 100.0000 (98.7573)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.8324  Acc@1: 81.2500 (79.2147)  Acc@5: 100.0000 (98.7512)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.7218  Acc@1: 81.2500 (79.2043)  Acc@5: 100.0000 (98.7571)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.5328  Acc@1: 81.2500 (79.2177)  Acc@5: 100.0000 (98.7630)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.7256  Acc@1: 81.2500 (79.2659)  Acc@5: 100.0000 (98.7687)  time: 0.3504  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.4491  Acc@1: 81.2500 (79.2611)  Acc@5: 100.0000 (98.7627)  time: 0.3512  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.5495  Acc@1: 75.0000 (79.2106)  Acc@5: 100.0000 (98.7454)  time: 0.3537  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.2873  Acc@1: 75.0000 (79.2348)  Acc@5: 100.0000 (98.7568)  time: 0.3535  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.5702  Acc@1: 75.0000 (79.2135)  Acc@5: 100.0000 (98.7624)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.4969  Acc@1: 81.2500 (79.2317)  Acc@5: 100.0000 (98.7567)  time: 0.3571  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.7052  Acc@1: 81.2500 (79.2551)  Acc@5: 100.0000 (98.7566)  time: 0.3582  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.6232  Acc@1: 81.2500 (79.3054)  Acc@5: 100.0000 (98.7621)  time: 0.3561  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.4317  Acc@1: 81.2500 (79.3223)  Acc@5: 100.0000 (98.7457)  time: 0.3556  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.7423  Acc@1: 75.0000 (79.2797)  Acc@5: 100.0000 (98.7403)  time: 0.3543  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1170/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.7433  Acc@1: 75.0000 (79.2432)  Acc@5: 100.0000 (98.7297)  time: 0.3518  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1180/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.3745  Acc@1: 75.0000 (79.2655)  Acc@5: 100.0000 (98.7299)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1190/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.7394  Acc@1: 81.2500 (79.2349)  Acc@5: 100.0000 (98.7301)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.6503  Acc@1: 81.2500 (79.2361)  Acc@5: 100.0000 (98.7250)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.6791  Acc@1: 81.2500 (79.2269)  Acc@5: 100.0000 (98.7304)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.6317  Acc@1: 81.2500 (79.2537)  Acc@5: 100.0000 (98.7408)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.6505  Acc@1: 81.2500 (79.2648)  Acc@5: 100.0000 (98.7459)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.6701  Acc@1: 81.2500 (79.2254)  Acc@5: 100.0000 (98.7409)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.4120  Acc@1: 75.0000 (79.2266)  Acc@5: 100.0000 (98.7310)  time: 0.3515  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.4128  Acc@1: 75.0000 (79.1931)  Acc@5: 100.0000 (98.7411)  time: 0.3496  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.4581  Acc@1: 81.2500 (79.2044)  Acc@5: 100.0000 (98.7411)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5035  Acc@1: 81.2500 (79.1764)  Acc@5: 100.0000 (98.7266)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.2575  Acc@1: 75.0000 (79.1731)  Acc@5: 100.0000 (98.7364)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.1942  Acc@1: 75.0000 (79.1410)  Acc@5: 100.0000 (98.7317)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.8683  Acc@1: 75.0000 (79.1476)  Acc@5: 100.0000 (98.7367)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.2423  Acc@1: 81.2500 (79.1588)  Acc@5: 100.0000 (98.7368)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.8409  Acc@1: 81.2500 (79.2027)  Acc@5: 100.0000 (98.7369)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1340/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.9003  Acc@1: 87.5000 (79.2179)  Acc@5: 100.0000 (98.7323)  time: 0.3496  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1350/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.7580  Acc@1: 81.2500 (79.1775)  Acc@5: 100.0000 (98.7417)  time: 0.3501  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1360/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.7789  Acc@1: 75.0000 (79.1697)  Acc@5: 100.0000 (98.7417)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.8483  Acc@1: 81.2500 (79.1940)  Acc@5: 100.0000 (98.7464)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6702  Acc@1: 81.2500 (79.1999)  Acc@5: 100.0000 (98.7373)  time: 0.3512  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.2240  Acc@1: 75.0000 (79.1562)  Acc@5: 100.0000 (98.7329)  time: 0.3516  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.7006  Acc@1: 75.0000 (79.1533)  Acc@5: 100.0000 (98.7241)  time: 0.3505  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4860  Acc@1: 75.0000 (79.1593)  Acc@5: 100.0000 (98.7332)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.8249  Acc@1: 75.0000 (79.1388)  Acc@5: 100.0000 (98.7289)  time: 0.3521  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.6678  Acc@1: 75.0000 (79.1317)  Acc@5: 100.0000 (98.7290)  time: 0.3547  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.7520  Acc@1: 81.2500 (79.1724)  Acc@5: 100.0000 (98.7379)  time: 0.3548  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5684  Acc@1: 81.2500 (79.1738)  Acc@5: 100.0000 (98.7379)  time: 0.3520  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4454  Acc@1: 75.0000 (79.1667)  Acc@5: 100.0000 (98.7423)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.2856  Acc@1: 81.2500 (79.1893)  Acc@5: 100.0000 (98.7339)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.1736  Acc@1: 87.5000 (79.1695)  Acc@5: 100.0000 (98.7340)  time: 0.3531  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.3866  Acc@1: 75.0000 (79.1415)  Acc@5: 100.0000 (98.7383)  time: 0.3564  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.7671  Acc@1: 81.2500 (79.1639)  Acc@5: 100.0000 (98.7425)  time: 0.3544  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [1510/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.5910  Acc@1: 81.2500 (79.1694)  Acc@5: 100.0000 (98.7426)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1520/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.5309  Acc@1: 75.0000 (79.1379)  Acc@5: 100.0000 (98.7303)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1530/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.9053  Acc@1: 75.0000 (79.1272)  Acc@5: 100.0000 (98.7386)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.7038  Acc@1: 81.2500 (79.1248)  Acc@5: 100.0000 (98.7346)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.3743  Acc@1: 81.2500 (79.1264)  Acc@5: 100.0000 (98.7347)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.7542  Acc@1: 75.0000 (79.0959)  Acc@5: 100.0000 (98.7348)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.1860  Acc@1: 75.0000 (79.0619)  Acc@5: 100.0000 (98.7309)  time: 0.3496  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.9110  Acc@1: 81.2500 (79.0560)  Acc@5: 100.0000 (98.7350)  time: 0.3504  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.5988  Acc@1: 81.2500 (79.0776)  Acc@5: 100.0000 (98.7351)  time: 0.3489  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.7836  Acc@1: 81.2500 (79.0717)  Acc@5: 100.0000 (98.7313)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.9609  Acc@1: 81.2500 (79.0813)  Acc@5: 100.0000 (98.7391)  time: 0.3505  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -0.8278  Acc@1: 81.2500 (79.0986)  Acc@5: 100.0000 (98.7431)  time: 0.3515  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.5456  Acc@1: 81.2500 (79.1117)  Acc@5: 100.0000 (98.7393)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -0.7000  Acc@1: 81.2500 (79.1172)  Acc@5: 100.0000 (98.7393)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.7124  Acc@1: 81.2500 (79.1225)  Acc@5: 100.0000 (98.7432)  time: 0.3501  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:15  Lr: 0.001875  Loss: -0.6019  Acc@1: 75.0000 (79.1165)  Acc@5: 100.0000 (98.7395)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.8202  Acc@1: 81.2500 (79.1480)  Acc@5: 100.0000 (98.7320)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -0.6786  Acc@1: 81.2500 (79.1456)  Acc@5: 100.0000 (98.7284)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1690/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.5723  Acc@1: 81.2500 (79.1396)  Acc@5: 100.0000 (98.7249)  time: 0.3516  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1700/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.7815  Acc@1: 81.2500 (79.1409)  Acc@5: 100.0000 (98.7324)  time: 0.3537  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -1.0302  Acc@1: 81.2500 (79.1387)  Acc@5: 100.0000 (98.7325)  time: 0.3564  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.4255  Acc@1: 81.2500 (79.1546)  Acc@5: 100.0000 (98.7362)  time: 0.3544  data: 0.0026  max mem: 2503
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.7841  Acc@1: 81.2500 (79.1558)  Acc@5: 100.0000 (98.7435)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.7419  Acc@1: 81.2500 (79.1679)  Acc@5: 100.0000 (98.7471)  time: 0.3514  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.5038  Acc@1: 81.2500 (79.1583)  Acc@5: 100.0000 (98.7400)  time: 0.3508  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.3629  Acc@1: 81.2500 (79.1631)  Acc@5: 100.0000 (98.7401)  time: 0.3551  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.9119  Acc@1: 81.2500 (79.1820)  Acc@5: 100.0000 (98.7401)  time: 0.3571  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.9630  Acc@1: 81.2500 (79.2076)  Acc@5: 100.0000 (98.7437)  time: 0.3515  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.6403  Acc@1: 87.5000 (79.2225)  Acc@5: 100.0000 (98.7437)  time: 0.3523  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.7922  Acc@1: 87.5000 (79.2407)  Acc@5: 100.0000 (98.7472)  time: 0.3579  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.7776  Acc@1: 81.2500 (79.2518)  Acc@5: 100.0000 (98.7472)  time: 0.3561  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.8022  Acc@1: 81.2500 (79.2353)  Acc@5: 100.0000 (98.7507)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.9774  Acc@1: 75.0000 (79.2429)  Acc@5: 100.0000 (98.7473)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.4093  Acc@1: 81.2500 (79.2300)  Acc@5: 100.0000 (98.7473)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.5795  Acc@1: 75.0000 (79.2241)  Acc@5: 100.0000 (98.7405)  time: 0.3541  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1860/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -0.9672  Acc@1: 75.0000 (79.2014)  Acc@5: 100.0000 (98.7339)  time: 0.3536  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1870/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.3143  Acc@1: 81.2500 (79.2023)  Acc@5: 100.0000 (98.7340)  time: 0.3516  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:58  Lr: 0.001875  Loss: 0.0893  Acc@1: 81.2500 (79.1800)  Acc@5: 100.0000 (98.7241)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.6126  Acc@1: 75.0000 (79.1678)  Acc@5: 100.0000 (98.7242)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.8342  Acc@1: 81.2500 (79.1623)  Acc@5: 100.0000 (98.7244)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.3430  Acc@1: 75.0000 (79.1470)  Acc@5: 100.0000 (98.7245)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.2075  Acc@1: 75.0000 (79.1612)  Acc@5: 100.0000 (98.7246)  time: 0.3511  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.7400  Acc@1: 75.0000 (79.1397)  Acc@5: 100.0000 (98.7118)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.3055  Acc@1: 81.2500 (79.1570)  Acc@5: 100.0000 (98.7152)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.5690  Acc@1: 81.2500 (79.1485)  Acc@5: 100.0000 (98.7154)  time: 0.3522  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.6562  Acc@1: 81.2500 (79.1592)  Acc@5: 100.0000 (98.7188)  time: 0.3526  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.9606  Acc@1: 81.2500 (79.1730)  Acc@5: 100.0000 (98.7189)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.5023  Acc@1: 81.2500 (79.1772)  Acc@5: 100.0000 (98.7159)  time: 0.3512  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.6268  Acc@1: 75.0000 (79.1562)  Acc@5: 100.0000 (98.7130)  time: 0.3535  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.5252  Acc@1: 75.0000 (79.1323)  Acc@5: 100.0000 (98.7100)  time: 0.3535  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.6936  Acc@1: 81.2500 (79.1522)  Acc@5: 100.0000 (98.7133)  time: 0.3508  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.3685  Acc@1: 81.2500 (79.1471)  Acc@5: 100.0000 (98.7073)  time: 0.3501  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2030/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.7886  Acc@1: 75.0000 (79.1359)  Acc@5: 100.0000 (98.7137)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2040/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.8301  Acc@1: 75.0000 (79.1279)  Acc@5: 100.0000 (98.7169)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.5714  Acc@1: 81.2500 (79.1413)  Acc@5: 100.0000 (98.7140)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.7125  Acc@1: 81.2500 (79.1394)  Acc@5: 100.0000 (98.7142)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.5054  Acc@1: 81.2500 (79.1465)  Acc@5: 100.0000 (98.7144)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.9237  Acc@1: 81.2500 (79.1717)  Acc@5: 100.0000 (98.7116)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.5929  Acc@1: 81.2500 (79.1697)  Acc@5: 100.0000 (98.7058)  time: 0.3523  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.8073  Acc@1: 75.0000 (79.1706)  Acc@5: 100.0000 (98.7000)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.6192  Acc@1: 75.0000 (79.1657)  Acc@5: 100.0000 (98.7003)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.5037  Acc@1: 81.2500 (79.1785)  Acc@5: 100.0000 (98.7005)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.5567  Acc@1: 81.2500 (79.1999)  Acc@5: 100.0000 (98.7007)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.6205  Acc@1: 81.2500 (79.2066)  Acc@5: 100.0000 (98.7010)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.7766  Acc@1: 81.2500 (79.1928)  Acc@5: 100.0000 (98.6954)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.8744  Acc@1: 81.2500 (79.1994)  Acc@5: 100.0000 (98.6956)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.4753  Acc@1: 81.2500 (79.1887)  Acc@5: 100.0000 (98.6872)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.5006  Acc@1: 75.0000 (79.1867)  Acc@5: 100.0000 (98.6875)  time: 0.3520  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.9603  Acc@1: 81.2500 (79.1933)  Acc@5: 100.0000 (98.6907)  time: 0.3509  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2200/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.9589  Acc@1: 81.2500 (79.2083)  Acc@5: 100.0000 (98.6853)  time: 0.3504  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2210/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.7014  Acc@1: 81.2500 (79.2091)  Acc@5: 100.0000 (98.6799)  time: 0.3515  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.7182  Acc@1: 81.2500 (79.2211)  Acc@5: 100.0000 (98.6802)  time: 0.3525  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.6938  Acc@1: 81.2500 (79.2134)  Acc@5: 100.0000 (98.6833)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.4875  Acc@1: 75.0000 (79.1946)  Acc@5: 100.0000 (98.6864)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.2590  Acc@1: 75.0000 (79.1787)  Acc@5: 100.0000 (98.6867)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.2041  Acc@1: 75.0000 (79.1547)  Acc@5: 100.0000 (98.6842)  time: 0.3504  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.8157  Acc@1: 81.2500 (79.1502)  Acc@5: 100.0000 (98.6845)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.3162  Acc@1: 81.2500 (79.1402)  Acc@5: 100.0000 (98.6848)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.5868  Acc@1: 81.2500 (79.1439)  Acc@5: 100.0000 (98.6851)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.8191  Acc@1: 81.2500 (79.1422)  Acc@5: 100.0000 (98.6799)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.7997  Acc@1: 81.2500 (79.1405)  Acc@5: 100.0000 (98.6802)  time: 0.3541  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.6675  Acc@1: 81.2500 (79.1550)  Acc@5: 100.0000 (98.6778)  time: 0.3552  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.4788  Acc@1: 81.2500 (79.1613)  Acc@5: 100.0000 (98.6835)  time: 0.3534  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.8310  Acc@1: 81.2500 (79.1702)  Acc@5: 100.0000 (98.6865)  time: 0.3517  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.0179  Acc@1: 81.2500 (79.1551)  Acc@5: 100.0000 (98.6814)  time: 0.3532  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.3623  Acc@1: 81.2500 (79.1693)  Acc@5: 100.0000 (98.6817)  time: 0.3523  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2370/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.5200  Acc@1: 81.2500 (79.1596)  Acc@5: 100.0000 (98.6820)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2380/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.4358  Acc@1: 75.0000 (79.1474)  Acc@5: 100.0000 (98.6797)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.7936  Acc@1: 75.0000 (79.1588)  Acc@5: 100.0000 (98.6799)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.7628  Acc@1: 81.2500 (79.1441)  Acc@5: 100.0000 (98.6802)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.3118  Acc@1: 75.0000 (79.1217)  Acc@5: 100.0000 (98.6727)  time: 0.3500  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.8611  Acc@1: 81.2500 (79.1331)  Acc@5: 100.0000 (98.6782)  time: 0.3501  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.8195  Acc@1: 81.2500 (79.1264)  Acc@5: 100.0000 (98.6785)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.6894  Acc@1: 75.0000 (79.1197)  Acc@5: 100.0000 (98.6814)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.7292  Acc@1: 81.2500 (79.1080)  Acc@5: 100.0000 (98.6689)  time: 0.3524  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.5175  Acc@1: 81.2500 (79.1320)  Acc@5: 100.0000 (98.6743)  time: 0.3554  data: 0.0037  max mem: 2503
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.9964  Acc@1: 81.2500 (79.1203)  Acc@5: 100.0000 (98.6746)  time: 0.3537  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.5472  Acc@1: 81.2500 (79.1339)  Acc@5: 100.0000 (98.6749)  time: 0.3526  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.3368  Acc@1: 75.0000 (79.1299)  Acc@5: 100.0000 (98.6777)  time: 0.3527  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6930  Acc@1: 75.0000 (79.1159)  Acc@5: 100.0000 (98.6805)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.7426  Acc@1: 81.2500 (79.1468)  Acc@5: 100.0000 (98.6808)  time: 0.3533  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.4654  Acc@1: 87.5000 (79.1477)  Acc@5: 100.0000 (98.6836)  time: 0.3543  data: 0.0034  max mem: 2503
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.4640  Acc@1: 75.0000 (79.1411)  Acc@5: 100.0000 (98.6789)  time: 0.3521  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.9568  Acc@1: 75.0000 (79.1347)  Acc@5: 100.0000 (98.6742)  time: 0.3518  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2550/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.9391  Acc@1: 81.2500 (79.1381)  Acc@5: 100.0000 (98.6770)  time: 0.3520  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.3457  Acc@1: 81.2500 (79.1439)  Acc@5: 100.0000 (98.6748)  time: 0.3518  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.6105  Acc@1: 81.2500 (79.1594)  Acc@5: 100.0000 (98.6776)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.8432  Acc@1: 81.2500 (79.1602)  Acc@5: 100.0000 (98.6778)  time: 0.3530  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.6927  Acc@1: 81.2500 (79.1659)  Acc@5: 100.0000 (98.6781)  time: 0.3517  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:44  Lr: 0.001875  Loss: 0.0063  Acc@1: 81.2500 (79.1522)  Acc@5: 100.0000 (98.6832)  time: 0.3540  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.3940  Acc@1: 81.2500 (79.1723)  Acc@5: 100.0000 (98.6835)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.4125  Acc@1: 81.2500 (79.1659)  Acc@5: 100.0000 (98.6789)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.8216  Acc@1: 81.2500 (79.1738)  Acc@5: 100.0000 (98.6792)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.3081  Acc@1: 75.0000 (79.1627)  Acc@5: 100.0000 (98.6771)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.9028  Acc@1: 75.0000 (79.1494)  Acc@5: 100.0000 (98.6774)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.5649  Acc@1: 75.0000 (79.1502)  Acc@5: 100.0000 (98.6800)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.8963  Acc@1: 75.0000 (79.1370)  Acc@5: 100.0000 (98.6779)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.9164  Acc@1: 81.2500 (79.1449)  Acc@5: 100.0000 (98.6759)  time: 0.3537  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.5020  Acc@1: 81.2500 (79.1388)  Acc@5: 100.0000 (98.6738)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.3894  Acc@1: 75.0000 (79.1304)  Acc@5: 100.0000 (98.6741)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.8075  Acc@1: 81.2500 (79.1382)  Acc@5: 100.0000 (98.6744)  time: 0.3503  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2720/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.4324  Acc@1: 75.0000 (79.1230)  Acc@5: 100.0000 (98.6747)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.6141  Acc@1: 75.0000 (79.1308)  Acc@5: 100.0000 (98.6795)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.5539  Acc@1: 81.2500 (79.1408)  Acc@5: 100.0000 (98.6821)  time: 0.3532  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.2066  Acc@1: 81.2500 (79.1394)  Acc@5: 100.0000 (98.6755)  time: 0.3586  data: 0.0050  max mem: 2503
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.8425  Acc@1: 81.2500 (79.1448)  Acc@5: 100.0000 (98.6803)  time: 0.3567  data: 0.0043  max mem: 2503
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.5011  Acc@1: 81.2500 (79.1546)  Acc@5: 100.0000 (98.6850)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -1.0314  Acc@1: 81.2500 (79.1599)  Acc@5: 100.0000 (98.6808)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.7880  Acc@1: 81.2500 (79.1719)  Acc@5: 100.0000 (98.6810)  time: 0.3550  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.7749  Acc@1: 81.2500 (79.1704)  Acc@5: 100.0000 (98.6813)  time: 0.3546  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.5258  Acc@1: 75.0000 (79.1555)  Acc@5: 100.0000 (98.6815)  time: 0.3524  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.4142  Acc@1: 81.2500 (79.1608)  Acc@5: 100.0000 (98.6818)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4341  Acc@1: 81.2500 (79.1770)  Acc@5: 100.0000 (98.6776)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.9654  Acc@1: 81.2500 (79.1821)  Acc@5: 100.0000 (98.6778)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.7798  Acc@1: 81.2500 (79.1652)  Acc@5: 100.0000 (98.6803)  time: 0.3524  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.5388  Acc@1: 75.0000 (79.1769)  Acc@5: 100.0000 (98.6849)  time: 0.3525  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.3903  Acc@1: 81.2500 (79.1776)  Acc@5: 100.0000 (98.6830)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.4784  Acc@1: 81.2500 (79.1804)  Acc@5: 100.0000 (98.6854)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.9149  Acc@1: 81.2500 (79.1811)  Acc@5: 100.0000 (98.6813)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.6553  Acc@1: 81.2500 (79.1817)  Acc@5: 100.0000 (98.6772)  time: 0.3530  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.4600  Acc@1: 81.2500 (79.1846)  Acc@5: 100.0000 (98.6753)  time: 0.3509  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.9112  Acc@1: 81.2500 (79.1938)  Acc@5: 100.0000 (98.6755)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.7908  Acc@1: 87.5000 (79.2029)  Acc@5: 100.0000 (98.6737)  time: 0.3518  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.1102  Acc@1: 81.2500 (79.1908)  Acc@5: 100.0000 (98.6760)  time: 0.3512  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5259  Acc@1: 81.2500 (79.1914)  Acc@5: 100.0000 (98.6784)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.4758  Acc@1: 75.0000 (79.1730)  Acc@5: 100.0000 (98.6808)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.1334  Acc@1: 75.0000 (79.1611)  Acc@5: 100.0000 (98.6768)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.9140  Acc@1: 81.2500 (79.1953)  Acc@5: 100.0000 (98.6812)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.3928  Acc@1: 87.5000 (79.2001)  Acc@5: 100.0000 (98.6794)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.9358  Acc@1: 81.2500 (79.2069)  Acc@5: 100.0000 (98.6734)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7397  Acc@1: 81.2500 (79.1992)  Acc@5: 100.0000 (98.6778)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.1466  Acc@1: 75.0000 (79.1811)  Acc@5: 100.0000 (98.6780)  time: 0.3533  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.8204  Acc@1: 81.2500 (79.1797)  Acc@5: 100.0000 (98.6741)  time: 0.3544  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.6794  Acc@1: 81.2500 (79.1721)  Acc@5: 100.0000 (98.6744)  time: 0.3517  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.4570  Acc@1: 75.0000 (79.1687)  Acc@5: 100.0000 (98.6705)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -0.9315  Acc@1: 81.2500 (79.1837)  Acc@5: 100.0000 (98.6728)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.3429  Acc@1: 81.2500 (79.1843)  Acc@5: 100.0000 (98.6710)  time: 0.3568  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -0.7846  Acc@1: 81.2500 (79.1910)  Acc@5: 100.0000 (98.6693)  time: 0.3574  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.3816  Acc@1: 81.2500 (79.2017)  Acc@5: 100.0000 (98.6715)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7676  Acc@1: 81.2500 (79.2023)  Acc@5: 100.0000 (98.6718)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.4856  Acc@1: 75.0000 (79.1908)  Acc@5: 100.0000 (98.6761)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6597  Acc@1: 75.0000 (79.2034)  Acc@5: 100.0000 (98.6803)  time: 0.3505  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.5750  Acc@1: 81.2500 (79.1979)  Acc@5: 100.0000 (98.6785)  time: 0.3511  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -0.5284  Acc@1: 75.0000 (79.1846)  Acc@5: 100.0000 (98.6688)  time: 0.3514  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.9194  Acc@1: 75.0000 (79.1891)  Acc@5: 100.0000 (98.6730)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.8995  Acc@1: 81.2500 (79.1897)  Acc@5: 100.0000 (98.6733)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -0.4494  Acc@1: 81.2500 (79.1943)  Acc@5: 100.0000 (98.6775)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -0.9182  Acc@1: 81.2500 (79.1929)  Acc@5: 100.0000 (98.6738)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.3763  Acc@1: 75.0000 (79.1817)  Acc@5: 100.0000 (98.6701)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.3901  Acc@1: 75.0000 (79.1686)  Acc@5: 100.0000 (98.6684)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.9553  Acc@1: 75.0000 (79.1712)  Acc@5: 100.0000 (98.6686)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.7820  Acc@1: 81.2500 (79.1835)  Acc@5: 100.0000 (98.6670)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.3901  Acc@1: 81.2500 (79.1725)  Acc@5: 100.0000 (98.6633)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.7940  Acc@1: 75.0000 (79.1596)  Acc@5: 100.0000 (98.6617)  time: 0.3513  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.7123  Acc@1: 81.2500 (79.1737)  Acc@5: 100.0000 (98.6639)  time: 0.3511  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.6666  Acc@1: 81.2500 (79.1782)  Acc@5: 100.0000 (98.6680)  time: 0.3540  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.5267  Acc@1: 81.2500 (79.1788)  Acc@5: 100.0000 (98.6682)  time: 0.3541  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7548  Acc@1: 81.2500 (79.1775)  Acc@5: 100.0000 (98.6704)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: 0.1758  Acc@1: 75.0000 (79.1572)  Acc@5: 100.0000 (98.6649)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.6260  Acc@1: 75.0000 (79.1446)  Acc@5: 100.0000 (98.6633)  time: 0.3530  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.5782  Acc@1: 81.2500 (79.1623)  Acc@5: 100.0000 (98.6617)  time: 0.3540  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5093  Acc@1: 81.2500 (79.1629)  Acc@5: 100.0000 (98.6582)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.7393  Acc@1: 81.2500 (79.1654)  Acc@5: 100.0000 (98.6584)  time: 0.3518  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.4683  Acc@1: 81.2500 (79.1698)  Acc@5: 100.0000 (98.6625)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.4672  Acc@1: 81.2500 (79.1760)  Acc@5: 100.0000 (98.6646)  time: 0.3517  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.6562  Acc@1: 81.2500 (79.1691)  Acc@5: 100.0000 (98.6667)  time: 0.3543  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.3591  Acc@1: 75.0000 (79.1568)  Acc@5: 100.0000 (98.6614)  time: 0.3518  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.5485  Acc@1: 81.2500 (79.1630)  Acc@5: 100.0000 (98.6635)  time: 0.3529  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6576  Acc@1: 81.2500 (79.1636)  Acc@5: 100.0000 (98.6656)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.6295  Acc@1: 81.2500 (79.1716)  Acc@5: 100.0000 (98.6677)  time: 0.3534  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.8935  Acc@1: 81.2500 (79.1850)  Acc@5: 100.0000 (98.6697)  time: 0.3550  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.5261  Acc@1: 81.2500 (79.1801)  Acc@5: 100.0000 (98.6736)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.7426  Acc@1: 81.2500 (79.1843)  Acc@5: 100.0000 (98.6702)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.8548  Acc@1: 75.0000 (79.1685)  Acc@5: 100.0000 (98.6704)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7948  Acc@1: 81.2500 (79.1799)  Acc@5: 100.0000 (98.6725)  time: 0.3530  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5598  Acc@1: 81.2500 (79.1661)  Acc@5: 100.0000 (98.6673)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.5452  Acc@1: 81.2500 (79.1811)  Acc@5: 100.0000 (98.6693)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5074  Acc@1: 81.2500 (79.1834)  Acc@5: 100.0000 (98.6678)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.3648  Acc@1: 81.2500 (79.1786)  Acc@5: 100.0000 (98.6662)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9738  Acc@1: 81.2500 (79.1827)  Acc@5: 100.0000 (98.6665)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.8469  Acc@1: 75.0000 (79.1797)  Acc@5: 100.0000 (98.6703)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8523  Acc@1: 75.0000 (79.1856)  Acc@5: 100.0000 (98.6669)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7480  Acc@1: 75.0000 (79.1667)  Acc@5: 100.0000 (98.6654)  time: 0.3509  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.6894  Acc@1: 75.0000 (79.1673)  Acc@5: 100.0000 (98.6621)  time: 0.3504  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9178  Acc@1: 81.2500 (79.1766)  Acc@5: 100.0000 (98.6641)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.9925  Acc@1: 81.2500 (79.1807)  Acc@5: 100.0000 (98.6626)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.6184  Acc@1: 81.2500 (79.1953)  Acc@5: 100.0000 (98.6646)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0324  Acc@1: 81.2500 (79.2062)  Acc@5: 100.0000 (98.6666)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.8658  Acc@1: 81.2500 (79.2032)  Acc@5: 100.0000 (98.6668)  time: 0.3534  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4643  Acc@1: 81.2500 (79.2124)  Acc@5: 100.0000 (98.6670)  time: 0.3526  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.2363  Acc@1: 81.2500 (79.2146)  Acc@5: 100.0000 (98.6673)  time: 0.3529  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8187  Acc@1: 81.2500 (79.2184)  Acc@5: 100.0000 (98.6675)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6113  Acc@1: 87.5000 (79.2309)  Acc@5: 100.0000 (98.6694)  time: 0.3522  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.6132  Acc@1: 87.5000 (79.2416)  Acc@5: 100.0000 (98.6714)  time: 0.3520  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.7272  Acc@1: 81.2500 (79.2420)  Acc@5: 100.0000 (98.6716)  time: 0.3515  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.4525  Acc@1: 81.2500 (79.2492)  Acc@5: 100.0000 (98.6701)  time: 0.3531  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.2569  Acc@1: 81.2500 (79.2461)  Acc@5: 100.0000 (98.6703)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7913  Acc@1: 81.2500 (79.2533)  Acc@5: 100.0000 (98.6739)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7663  Acc@1: 81.2500 (79.2485)  Acc@5: 100.0000 (98.6708)  time: 0.3528  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6091  Acc@1: 75.0000 (79.2421)  Acc@5: 100.0000 (98.6710)  time: 0.3519  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5192  Acc@1: 75.0000 (79.2475)  Acc@5: 100.0000 (98.6745)  time: 0.3517  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9214  Acc@1: 81.2500 (79.2479)  Acc@5: 100.0000 (98.6731)  time: 0.3528  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8221  Acc@1: 81.2500 (79.2499)  Acc@5: 100.0000 (98.6766)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.2051  Acc@1: 75.0000 (79.2318)  Acc@5: 100.0000 (98.6735)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5506  Acc@1: 75.0000 (79.2400)  Acc@5: 100.0000 (98.6750)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[3/5] Total time: 0:21:59 (0.3520 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}}
Averaged stats: Lr: 0.001875  Loss: -0.5506  Acc@1: 75.0000 (79.2400)  Acc@5: 100.0000 (98.6750)
Train: Epoch[4/5]  [   0/3750]  eta: 0:47:00  Lr: 0.001875  Loss: -0.4615  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7521  data: 0.3996  max mem: 2503
Train: Epoch[4/5]  [  10/3750]  eta: 0:24:02  Lr: 0.001875  Loss: -0.5532  Acc@1: 81.2500 (75.5682)  Acc@5: 100.0000 (98.2955)  time: 0.3857  data: 0.0368  max mem: 2503
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:54  Lr: 0.001875  Loss: -0.9030  Acc@1: 81.2500 (79.7619)  Acc@5: 100.0000 (98.8095)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:29  Lr: 0.001875  Loss: -0.2434  Acc@1: 81.2500 (79.0323)  Acc@5: 100.0000 (97.9839)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:14  Lr: 0.001875  Loss: -0.9380  Acc@1: 75.0000 (80.0305)  Acc@5: 100.0000 (98.1707)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  50/3750]  eta: 0:22:03  Lr: 0.001875  Loss: -0.4631  Acc@1: 75.0000 (79.6569)  Acc@5: 100.0000 (98.4069)  time: 0.3497  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -0.6097  Acc@1: 75.0000 (78.8934)  Acc@5: 100.0000 (98.5656)  time: 0.3491  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -0.6145  Acc@1: 75.0000 (78.5211)  Acc@5: 100.0000 (98.3275)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:43  Lr: 0.001875  Loss: -0.4922  Acc@1: 81.2500 (78.3179)  Acc@5: 100.0000 (98.3796)  time: 0.3516  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:40  Lr: 0.001875  Loss: -0.9208  Acc@1: 81.2500 (78.1593)  Acc@5: 100.0000 (98.4890)  time: 0.3547  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:35  Lr: 0.001875  Loss: -0.8021  Acc@1: 81.2500 (78.5891)  Acc@5: 100.0000 (98.6386)  time: 0.3550  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:31  Lr: 0.001875  Loss: -0.5902  Acc@1: 81.2500 (78.8851)  Acc@5: 100.0000 (98.5360)  time: 0.3528  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.1685  Acc@1: 81.2500 (78.1508)  Acc@5: 100.0000 (98.6054)  time: 0.3518  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -0.7314  Acc@1: 81.2500 (78.5305)  Acc@5: 100.0000 (98.6164)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 140/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.6516  Acc@1: 87.5000 (78.6348)  Acc@5: 100.0000 (98.6259)  time: 0.3535  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 150/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.5629  Acc@1: 75.0000 (78.3940)  Acc@5: 100.0000 (98.5927)  time: 0.3543  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [ 160/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.5513  Acc@1: 75.0000 (78.3385)  Acc@5: 100.0000 (98.4860)  time: 0.3531  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 170/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.5675  Acc@1: 81.2500 (78.6550)  Acc@5: 100.0000 (98.5380)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 180/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.7509  Acc@1: 81.2500 (78.5912)  Acc@5: 100.0000 (98.5152)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.6527  Acc@1: 75.0000 (78.5995)  Acc@5: 100.0000 (98.4620)  time: 0.3501  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.2990  Acc@1: 75.0000 (78.5759)  Acc@5: 100.0000 (98.5386)  time: 0.3526  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -1.0019  Acc@1: 81.2500 (78.6730)  Acc@5: 100.0000 (98.5782)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:48  Lr: 0.001875  Loss: 0.2685  Acc@1: 81.2500 (78.6765)  Acc@5: 100.0000 (98.5860)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.7983  Acc@1: 81.2500 (78.6526)  Acc@5: 100.0000 (98.6472)  time: 0.3526  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.7267  Acc@1: 75.0000 (78.6566)  Acc@5: 100.0000 (98.6774)  time: 0.3511  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.8151  Acc@1: 75.0000 (78.6853)  Acc@5: 100.0000 (98.6554)  time: 0.3519  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:32  Lr: 0.001875  Loss: 0.0042  Acc@1: 81.2500 (78.6877)  Acc@5: 100.0000 (98.5872)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.4661  Acc@1: 81.2500 (78.9207)  Acc@5: 100.0000 (98.6162)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.7490  Acc@1: 81.2500 (78.8701)  Acc@5: 100.0000 (98.6210)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.6141  Acc@1: 75.0000 (78.7156)  Acc@5: 100.0000 (98.6469)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:16  Lr: 0.001875  Loss: 0.1523  Acc@1: 75.0000 (78.6337)  Acc@5: 100.0000 (98.5880)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.7129  Acc@1: 81.2500 (78.7580)  Acc@5: 100.0000 (98.5932)  time: 0.3493  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 320/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.6544  Acc@1: 81.2500 (78.9330)  Acc@5: 100.0000 (98.6176)  time: 0.3513  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 330/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.5109  Acc@1: 81.2500 (78.8897)  Acc@5: 100.0000 (98.6594)  time: 0.3511  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 340/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.5287  Acc@1: 81.2500 (79.0139)  Acc@5: 100.0000 (98.6987)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.6627  Acc@1: 81.2500 (79.0598)  Acc@5: 100.0000 (98.7179)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.7574  Acc@1: 81.2500 (79.1551)  Acc@5: 100.0000 (98.7015)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.6366  Acc@1: 87.5000 (79.3632)  Acc@5: 100.0000 (98.7197)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.5800  Acc@1: 81.2500 (79.3143)  Acc@5: 100.0000 (98.6877)  time: 0.3517  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.8556  Acc@1: 75.0000 (79.2359)  Acc@5: 100.0000 (98.7212)  time: 0.3527  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.5582  Acc@1: 75.0000 (79.1303)  Acc@5: 100.0000 (98.7219)  time: 0.3528  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:36  Lr: 0.001875  Loss: 0.1587  Acc@1: 81.2500 (79.2427)  Acc@5: 100.0000 (98.7226)  time: 0.3519  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.9026  Acc@1: 81.2500 (79.3052)  Acc@5: 100.0000 (98.7530)  time: 0.3512  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.4257  Acc@1: 81.2500 (79.4374)  Acc@5: 100.0000 (98.7239)  time: 0.3542  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.7151  Acc@1: 81.2500 (79.4359)  Acc@5: 100.0000 (98.7387)  time: 0.3558  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.7920  Acc@1: 81.2500 (79.4207)  Acc@5: 100.0000 (98.7666)  time: 0.3539  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.6719  Acc@1: 81.2500 (79.5011)  Acc@5: 100.0000 (98.7934)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.7040  Acc@1: 81.2500 (79.4984)  Acc@5: 100.0000 (98.7792)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.1989  Acc@1: 87.5000 (79.6778)  Acc@5: 100.0000 (98.8046)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 490/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.8889  Acc@1: 87.5000 (79.7480)  Acc@5: 100.0000 (98.8162)  time: 0.3527  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 500/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.4478  Acc@1: 75.0000 (79.6282)  Acc@5: 100.0000 (98.8273)  time: 0.3527  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 510/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.4167  Acc@1: 75.0000 (79.5132)  Acc@5: 100.0000 (98.8136)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.6902  Acc@1: 75.0000 (79.4746)  Acc@5: 100.0000 (98.8244)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.8340  Acc@1: 81.2500 (79.5080)  Acc@5: 100.0000 (98.8230)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.3553  Acc@1: 75.0000 (79.4824)  Acc@5: 100.0000 (98.8101)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.1199  Acc@1: 75.0000 (79.4578)  Acc@5: 100.0000 (98.8203)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.2166  Acc@1: 75.0000 (79.4229)  Acc@5: 100.0000 (98.7968)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.8073  Acc@1: 81.2500 (79.4658)  Acc@5: 100.0000 (98.8069)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.4650  Acc@1: 81.2500 (79.4320)  Acc@5: 100.0000 (98.8167)  time: 0.3506  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.6507  Acc@1: 81.2500 (79.4945)  Acc@5: 100.0000 (98.8050)  time: 0.3526  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.7210  Acc@1: 87.5000 (79.5653)  Acc@5: 100.0000 (98.8041)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.5591  Acc@1: 81.2500 (79.5724)  Acc@5: 100.0000 (98.8032)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.9254  Acc@1: 81.2500 (79.6397)  Acc@5: 100.0000 (98.8023)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.7045  Acc@1: 81.2500 (79.6256)  Acc@5: 100.0000 (98.8114)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.5414  Acc@1: 81.2500 (79.6217)  Acc@5: 100.0000 (98.8105)  time: 0.3527  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.8122  Acc@1: 81.2500 (79.5987)  Acc@5: 100.0000 (98.7999)  time: 0.3513  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [ 660/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.9803  Acc@1: 81.2500 (79.6804)  Acc@5: 100.0000 (98.8086)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 670/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.7620  Acc@1: 81.2500 (79.7131)  Acc@5: 100.0000 (98.8171)  time: 0.3532  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 680/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.7968  Acc@1: 81.2500 (79.7816)  Acc@5: 100.0000 (98.8344)  time: 0.3534  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.7006  Acc@1: 87.5000 (79.8842)  Acc@5: 100.0000 (98.8513)  time: 0.3529  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.6289  Acc@1: 81.2500 (79.9126)  Acc@5: 100.0000 (98.8677)  time: 0.3530  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.7819  Acc@1: 81.2500 (79.9139)  Acc@5: 100.0000 (98.8485)  time: 0.3528  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.6826  Acc@1: 81.2500 (79.8977)  Acc@5: 100.0000 (98.8644)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.6337  Acc@1: 81.2500 (79.8906)  Acc@5: 100.0000 (98.8629)  time: 0.3537  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.9735  Acc@1: 75.0000 (79.8836)  Acc@5: 100.0000 (98.8276)  time: 0.3521  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.5732  Acc@1: 81.2500 (79.8602)  Acc@5: 100.0000 (98.8349)  time: 0.3532  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6754  Acc@1: 81.2500 (79.8702)  Acc@5: 100.0000 (98.8502)  time: 0.3530  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.6659  Acc@1: 81.2500 (79.9611)  Acc@5: 100.0000 (98.8651)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.5848  Acc@1: 81.2500 (79.9696)  Acc@5: 100.0000 (98.8716)  time: 0.3566  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.3796  Acc@1: 81.2500 (79.9305)  Acc@5: 100.0000 (98.8701)  time: 0.3563  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.5944  Acc@1: 87.5000 (80.0328)  Acc@5: 100.0000 (98.8764)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.3516  Acc@1: 81.2500 (79.9861)  Acc@5: 100.0000 (98.8594)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.3777  Acc@1: 75.0000 (79.9635)  Acc@5: 100.0000 (98.8276)  time: 0.3508  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 830/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.5458  Acc@1: 75.0000 (79.9263)  Acc@5: 100.0000 (98.8117)  time: 0.3520  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [ 840/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.4487  Acc@1: 81.2500 (79.9643)  Acc@5: 100.0000 (98.8109)  time: 0.3510  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 850/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.3019  Acc@1: 81.2500 (79.9721)  Acc@5: 100.0000 (98.8249)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.7290  Acc@1: 81.2500 (79.9869)  Acc@5: 100.0000 (98.8313)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.8998  Acc@1: 81.2500 (80.0301)  Acc@5: 100.0000 (98.8375)  time: 0.3520  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6234  Acc@1: 87.5000 (80.0795)  Acc@5: 100.0000 (98.8365)  time: 0.3517  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.7563  Acc@1: 81.2500 (80.0084)  Acc@5: 100.0000 (98.8426)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.4223  Acc@1: 75.0000 (79.9875)  Acc@5: 100.0000 (98.8485)  time: 0.3511  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.5124  Acc@1: 75.0000 (79.9533)  Acc@5: 100.0000 (98.8611)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.7842  Acc@1: 75.0000 (79.8996)  Acc@5: 100.0000 (98.8531)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.6708  Acc@1: 81.2500 (79.9074)  Acc@5: 100.0000 (98.8655)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.5164  Acc@1: 75.0000 (79.8154)  Acc@5: 100.0000 (98.8642)  time: 0.3533  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.8076  Acc@1: 75.0000 (79.8304)  Acc@5: 100.0000 (98.8565)  time: 0.3540  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.5938  Acc@1: 75.0000 (79.7802)  Acc@5: 100.0000 (98.8424)  time: 0.3526  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.2944  Acc@1: 81.2500 (79.8082)  Acc@5: 100.0000 (98.8414)  time: 0.3566  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.9601  Acc@1: 81.2500 (79.7847)  Acc@5: 100.0000 (98.8468)  time: 0.3569  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.5496  Acc@1: 81.2500 (79.7868)  Acc@5: 100.0000 (98.8396)  time: 0.3535  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1000/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.8282  Acc@1: 81.2500 (79.7640)  Acc@5: 100.0000 (98.8449)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1010/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.7160  Acc@1: 81.2500 (79.7910)  Acc@5: 100.0000 (98.8440)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1020/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.5112  Acc@1: 81.2500 (79.8359)  Acc@5: 100.0000 (98.8369)  time: 0.3512  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.5078  Acc@1: 81.2500 (79.8800)  Acc@5: 100.0000 (98.8421)  time: 0.3515  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.8378  Acc@1: 87.5000 (79.9412)  Acc@5: 100.0000 (98.8473)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.3744  Acc@1: 81.2500 (79.9298)  Acc@5: 100.0000 (98.8404)  time: 0.3512  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.8082  Acc@1: 81.2500 (79.9305)  Acc@5: 100.0000 (98.8454)  time: 0.3510  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.7346  Acc@1: 81.2500 (79.9078)  Acc@5: 100.0000 (98.8504)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.7131  Acc@1: 81.2500 (79.9491)  Acc@5: 100.0000 (98.8437)  time: 0.3519  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.6657  Acc@1: 81.2500 (79.9840)  Acc@5: 100.0000 (98.8428)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.7095  Acc@1: 81.2500 (79.9614)  Acc@5: 100.0000 (98.8420)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.3964  Acc@1: 81.2500 (79.9617)  Acc@5: 100.0000 (98.8355)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.1137  Acc@1: 81.2500 (79.9509)  Acc@5: 100.0000 (98.8292)  time: 0.3523  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.6213  Acc@1: 81.2500 (79.9127)  Acc@5: 100.0000 (98.8229)  time: 0.3511  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.6336  Acc@1: 81.2500 (79.8970)  Acc@5: 100.0000 (98.8278)  time: 0.3511  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.9601  Acc@1: 81.2500 (79.8490)  Acc@5: 100.0000 (98.8162)  time: 0.3540  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.9828  Acc@1: 75.0000 (79.8396)  Acc@5: 100.0000 (98.8103)  time: 0.3529  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1170/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.8537  Acc@1: 81.2500 (79.8570)  Acc@5: 100.0000 (98.8044)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1180/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.4279  Acc@1: 81.2500 (79.8317)  Acc@5: 100.0000 (98.8093)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1190/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.8228  Acc@1: 75.0000 (79.8174)  Acc@5: 100.0000 (98.8140)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.3752  Acc@1: 75.0000 (79.7981)  Acc@5: 100.0000 (98.8187)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.6621  Acc@1: 75.0000 (79.7791)  Acc@5: 100.0000 (98.8233)  time: 0.3538  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.7111  Acc@1: 81.2500 (79.7656)  Acc@5: 100.0000 (98.8278)  time: 0.3537  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.5583  Acc@1: 75.0000 (79.7624)  Acc@5: 100.0000 (98.8272)  time: 0.3529  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.4690  Acc@1: 75.0000 (79.7542)  Acc@5: 100.0000 (98.8114)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.4238  Acc@1: 75.0000 (79.7762)  Acc@5: 100.0000 (98.8110)  time: 0.3529  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.8752  Acc@1: 81.2500 (79.7978)  Acc@5: 100.0000 (98.8154)  time: 0.3532  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.3380  Acc@1: 81.2500 (79.8043)  Acc@5: 100.0000 (98.8198)  time: 0.3510  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.9013  Acc@1: 75.0000 (79.7863)  Acc@5: 100.0000 (98.8144)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.6988  Acc@1: 75.0000 (79.7976)  Acc@5: 100.0000 (98.8139)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.3585  Acc@1: 81.2500 (79.8136)  Acc@5: 100.0000 (98.8038)  time: 0.3515  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.3222  Acc@1: 81.2500 (79.8246)  Acc@5: 100.0000 (98.8082)  time: 0.3533  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -1.0234  Acc@1: 87.5000 (79.8637)  Acc@5: 100.0000 (98.8125)  time: 0.3542  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.5998  Acc@1: 87.5000 (79.8882)  Acc@5: 100.0000 (98.8120)  time: 0.3520  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1340/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.8621  Acc@1: 87.5000 (79.9264)  Acc@5: 100.0000 (98.8115)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1350/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.6634  Acc@1: 81.2500 (79.8575)  Acc@5: 100.0000 (98.8203)  time: 0.3502  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1360/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.9987  Acc@1: 75.0000 (79.8632)  Acc@5: 100.0000 (98.8152)  time: 0.3512  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.6803  Acc@1: 81.2500 (79.8778)  Acc@5: 100.0000 (98.8193)  time: 0.3514  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.4144  Acc@1: 75.0000 (79.8380)  Acc@5: 100.0000 (98.8097)  time: 0.3515  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.5605  Acc@1: 75.0000 (79.8436)  Acc@5: 100.0000 (98.8048)  time: 0.3517  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.5684  Acc@1: 81.2500 (79.8269)  Acc@5: 100.0000 (98.8044)  time: 0.3512  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6863  Acc@1: 81.2500 (79.8326)  Acc@5: 100.0000 (98.8085)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.4920  Acc@1: 81.2500 (79.8425)  Acc@5: 100.0000 (98.8081)  time: 0.3505  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.6734  Acc@1: 81.2500 (79.8524)  Acc@5: 100.0000 (98.8164)  time: 0.3514  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.5072  Acc@1: 81.2500 (79.8361)  Acc@5: 100.0000 (98.8159)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.9300  Acc@1: 81.2500 (79.8200)  Acc@5: 100.0000 (98.8112)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.5299  Acc@1: 81.2500 (79.8169)  Acc@5: 100.0000 (98.8107)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.6600  Acc@1: 81.2500 (79.8097)  Acc@5: 100.0000 (98.8146)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.6471  Acc@1: 81.2500 (79.8109)  Acc@5: 100.0000 (98.8184)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6772  Acc@1: 81.2500 (79.8122)  Acc@5: 100.0000 (98.8221)  time: 0.3514  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.7167  Acc@1: 81.2500 (79.7968)  Acc@5: 100.0000 (98.8216)  time: 0.3522  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.6335  Acc@1: 81.2500 (79.8106)  Acc@5: 100.0000 (98.8294)  time: 0.3533  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [1520/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.5663  Acc@1: 81.2500 (79.8406)  Acc@5: 100.0000 (98.8289)  time: 0.3525  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1530/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.7306  Acc@1: 81.2500 (79.8579)  Acc@5: 100.0000 (98.8325)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.5001  Acc@1: 75.0000 (79.8305)  Acc@5: 100.0000 (98.8360)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.7001  Acc@1: 75.0000 (79.8235)  Acc@5: 100.0000 (98.8354)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.8819  Acc@1: 75.0000 (79.8046)  Acc@5: 100.0000 (98.8389)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.6172  Acc@1: 81.2500 (79.7780)  Acc@5: 100.0000 (98.8343)  time: 0.3504  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.3756  Acc@1: 81.2500 (79.7873)  Acc@5: 100.0000 (98.8299)  time: 0.3514  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.9674  Acc@1: 81.2500 (79.7926)  Acc@5: 100.0000 (98.8215)  time: 0.3523  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.3981  Acc@1: 81.2500 (79.7783)  Acc@5: 100.0000 (98.8171)  time: 0.3533  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.5112  Acc@1: 81.2500 (79.7641)  Acc@5: 100.0000 (98.8167)  time: 0.3509  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -0.5433  Acc@1: 81.2500 (79.7617)  Acc@5: 100.0000 (98.8125)  time: 0.3509  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.5772  Acc@1: 75.0000 (79.7479)  Acc@5: 100.0000 (98.8121)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -0.8890  Acc@1: 75.0000 (79.7456)  Acc@5: 100.0000 (98.8117)  time: 0.3503  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.8013  Acc@1: 81.2500 (79.7585)  Acc@5: 100.0000 (98.8038)  time: 0.3499  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:15  Lr: 0.001875  Loss: -0.6146  Acc@1: 75.0000 (79.7298)  Acc@5: 100.0000 (98.7959)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.8638  Acc@1: 81.2500 (79.7464)  Acc@5: 100.0000 (98.8031)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1680/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -0.8912  Acc@1: 81.2500 (79.7702)  Acc@5: 100.0000 (98.8028)  time: 0.3531  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1690/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.7487  Acc@1: 81.2500 (79.7753)  Acc@5: 100.0000 (98.7914)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1700/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.9139  Acc@1: 87.5000 (79.7876)  Acc@5: 100.0000 (98.7912)  time: 0.3498  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.4672  Acc@1: 87.5000 (79.8035)  Acc@5: 100.0000 (98.7982)  time: 0.3498  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.2726  Acc@1: 81.2500 (79.7937)  Acc@5: 100.0000 (98.8052)  time: 0.3524  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.6801  Acc@1: 81.2500 (79.7877)  Acc@5: 100.0000 (98.8013)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.8401  Acc@1: 81.2500 (79.8176)  Acc@5: 100.0000 (98.8082)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.4226  Acc@1: 87.5000 (79.8330)  Acc@5: 100.0000 (98.8150)  time: 0.3534  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.4974  Acc@1: 81.2500 (79.8375)  Acc@5: 100.0000 (98.8146)  time: 0.3553  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.5115  Acc@1: 81.2500 (79.8348)  Acc@5: 100.0000 (98.8142)  time: 0.3518  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.8291  Acc@1: 81.2500 (79.8568)  Acc@5: 100.0000 (98.8139)  time: 0.3503  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.7371  Acc@1: 81.2500 (79.8681)  Acc@5: 100.0000 (98.8170)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.5613  Acc@1: 81.2500 (79.8584)  Acc@5: 100.0000 (98.8201)  time: 0.3535  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.5976  Acc@1: 81.2500 (79.8523)  Acc@5: 100.0000 (98.8197)  time: 0.3544  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.8349  Acc@1: 81.2500 (79.8668)  Acc@5: 100.0000 (98.8262)  time: 0.3520  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.9079  Acc@1: 81.2500 (79.8846)  Acc@5: 100.0000 (98.8326)  time: 0.3500  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.8302  Acc@1: 81.2500 (79.8649)  Acc@5: 100.0000 (98.8389)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.3963  Acc@1: 75.0000 (79.8420)  Acc@5: 100.0000 (98.8418)  time: 0.3526  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1860/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -0.5008  Acc@1: 75.0000 (79.8328)  Acc@5: 100.0000 (98.8413)  time: 0.3516  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1870/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.7857  Acc@1: 75.0000 (79.8236)  Acc@5: 100.0000 (98.8375)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.7668  Acc@1: 75.0000 (79.7980)  Acc@5: 100.0000 (98.8404)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.2892  Acc@1: 75.0000 (79.7594)  Acc@5: 100.0000 (98.8465)  time: 0.3539  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.6690  Acc@1: 75.0000 (79.7639)  Acc@5: 100.0000 (98.8460)  time: 0.3531  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.7914  Acc@1: 81.2500 (79.7586)  Acc@5: 100.0000 (98.8520)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.1885  Acc@1: 81.2500 (79.7371)  Acc@5: 100.0000 (98.8483)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.6585  Acc@1: 81.2500 (79.7223)  Acc@5: 100.0000 (98.8445)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.6279  Acc@1: 81.2500 (79.7173)  Acc@5: 100.0000 (98.8440)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.1468  Acc@1: 81.2500 (79.7283)  Acc@5: 100.0000 (98.8467)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.8454  Acc@1: 81.2500 (79.7520)  Acc@5: 100.0000 (98.8463)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.1434  Acc@1: 81.2500 (79.7216)  Acc@5: 100.0000 (98.8426)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.8493  Acc@1: 81.2500 (79.7356)  Acc@5: 100.0000 (98.8453)  time: 0.3530  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.3561  Acc@1: 81.2500 (79.7244)  Acc@5: 100.0000 (98.8511)  time: 0.3524  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.8358  Acc@1: 75.0000 (79.7383)  Acc@5: 100.0000 (98.8506)  time: 0.3523  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.4730  Acc@1: 75.0000 (79.7116)  Acc@5: 100.0000 (98.8470)  time: 0.3508  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.6329  Acc@1: 75.0000 (79.6945)  Acc@5: 100.0000 (98.8465)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2030/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.6797  Acc@1: 81.2500 (79.6929)  Acc@5: 100.0000 (98.8491)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2040/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.7722  Acc@1: 81.2500 (79.7036)  Acc@5: 100.0000 (98.8486)  time: 0.3521  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.8745  Acc@1: 81.2500 (79.6776)  Acc@5: 100.0000 (98.8512)  time: 0.3526  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.2857  Acc@1: 81.2500 (79.6883)  Acc@5: 100.0000 (98.8476)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.7044  Acc@1: 81.2500 (79.6717)  Acc@5: 100.0000 (98.8472)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.4147  Acc@1: 81.2500 (79.6582)  Acc@5: 100.0000 (98.8437)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.8006  Acc@1: 75.0000 (79.6419)  Acc@5: 100.0000 (98.8433)  time: 0.3515  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.5984  Acc@1: 75.0000 (79.6406)  Acc@5: 100.0000 (98.8398)  time: 0.3518  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -1.1227  Acc@1: 81.2500 (79.6423)  Acc@5: 100.0000 (98.8365)  time: 0.3508  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.3495  Acc@1: 81.2500 (79.6529)  Acc@5: 100.0000 (98.8390)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.2271  Acc@1: 81.2500 (79.6486)  Acc@5: 100.0000 (98.8386)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.4137  Acc@1: 75.0000 (79.6474)  Acc@5: 100.0000 (98.8382)  time: 0.3529  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.7075  Acc@1: 75.0000 (79.6519)  Acc@5: 100.0000 (98.8436)  time: 0.3504  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.4009  Acc@1: 75.0000 (79.6188)  Acc@5: 100.0000 (98.8489)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.8100  Acc@1: 75.0000 (79.6177)  Acc@5: 100.0000 (98.8456)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.8126  Acc@1: 81.2500 (79.6194)  Acc@5: 100.0000 (98.8451)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.6678  Acc@1: 81.2500 (79.6183)  Acc@5: 100.0000 (98.8419)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2200/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.3803  Acc@1: 81.2500 (79.6144)  Acc@5: 100.0000 (98.8414)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2210/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.9065  Acc@1: 81.2500 (79.6416)  Acc@5: 100.0000 (98.8467)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.0929  Acc@1: 81.2500 (79.6376)  Acc@5: 100.0000 (98.8462)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.6247  Acc@1: 81.2500 (79.6588)  Acc@5: 100.0000 (98.8514)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.4544  Acc@1: 81.2500 (79.6492)  Acc@5: 100.0000 (98.8537)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.3663  Acc@1: 81.2500 (79.6535)  Acc@5: 100.0000 (98.8561)  time: 0.3488  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.6243  Acc@1: 81.2500 (79.6550)  Acc@5: 100.0000 (98.8584)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.7196  Acc@1: 81.2500 (79.6648)  Acc@5: 100.0000 (98.8524)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.5226  Acc@1: 81.2500 (79.6772)  Acc@5: 100.0000 (98.8547)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.8371  Acc@1: 81.2500 (79.6595)  Acc@5: 100.0000 (98.8488)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.7149  Acc@1: 81.2500 (79.6719)  Acc@5: 100.0000 (98.8483)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.2700  Acc@1: 81.2500 (79.6679)  Acc@5: 100.0000 (98.8479)  time: 0.3539  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -0.3523  Acc@1: 75.0000 (79.6693)  Acc@5: 100.0000 (98.8475)  time: 0.3545  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.6744  Acc@1: 81.2500 (79.6707)  Acc@5: 100.0000 (98.8524)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.9519  Acc@1: 75.0000 (79.6401)  Acc@5: 100.0000 (98.8413)  time: 0.3520  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.6705  Acc@1: 81.2500 (79.6603)  Acc@5: 100.0000 (98.8462)  time: 0.3543  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.4815  Acc@1: 81.2500 (79.6590)  Acc@5: 100.0000 (98.8485)  time: 0.3527  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.4817  Acc@1: 75.0000 (79.6578)  Acc@5: 100.0000 (98.8507)  time: 0.3541  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2380/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.5326  Acc@1: 87.5000 (79.6934)  Acc@5: 100.0000 (98.8398)  time: 0.3544  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.6437  Acc@1: 87.5000 (79.6816)  Acc@5: 100.0000 (98.8420)  time: 0.3514  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.3252  Acc@1: 75.0000 (79.6699)  Acc@5: 100.0000 (98.8442)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.7639  Acc@1: 81.2500 (79.6791)  Acc@5: 100.0000 (98.8412)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.9616  Acc@1: 81.2500 (79.6830)  Acc@5: 100.0000 (98.8409)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.5934  Acc@1: 81.2500 (79.6740)  Acc@5: 100.0000 (98.8405)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.6703  Acc@1: 81.2500 (79.6933)  Acc@5: 100.0000 (98.8452)  time: 0.3519  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:37  Lr: 0.001875  Loss: 0.3544  Acc@1: 81.2500 (79.6741)  Acc@5: 100.0000 (98.8449)  time: 0.3513  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.2043  Acc@1: 81.2500 (79.6831)  Acc@5: 100.0000 (98.8470)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.9752  Acc@1: 87.5000 (79.7096)  Acc@5: 100.0000 (98.8517)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.2926  Acc@1: 81.2500 (79.6856)  Acc@5: 100.0000 (98.8563)  time: 0.3503  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.7650  Acc@1: 75.0000 (79.6844)  Acc@5: 100.0000 (98.8484)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6225  Acc@1: 81.2500 (79.6881)  Acc@5: 100.0000 (98.8505)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.6841  Acc@1: 87.5000 (79.7093)  Acc@5: 100.0000 (98.8550)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.1293  Acc@1: 81.2500 (79.6980)  Acc@5: 100.0000 (98.8546)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.1011  Acc@1: 75.0000 (79.6745)  Acc@5: 100.0000 (98.8542)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.7530  Acc@1: 75.0000 (79.6881)  Acc@5: 100.0000 (98.8587)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2550/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.4821  Acc@1: 81.2500 (79.6820)  Acc@5: 100.0000 (98.8583)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.6165  Acc@1: 81.2500 (79.6735)  Acc@5: 100.0000 (98.8603)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.5252  Acc@1: 75.0000 (79.6699)  Acc@5: 100.0000 (98.8647)  time: 0.3526  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.3856  Acc@1: 75.0000 (79.6712)  Acc@5: 100.0000 (98.8643)  time: 0.3526  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.5149  Acc@1: 81.2500 (79.6845)  Acc@5: 100.0000 (98.8687)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.9243  Acc@1: 81.2500 (79.6881)  Acc@5: 100.0000 (98.8682)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.8185  Acc@1: 81.2500 (79.6749)  Acc@5: 100.0000 (98.8702)  time: 0.3544  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -0.7941  Acc@1: 81.2500 (79.6833)  Acc@5: 100.0000 (98.8673)  time: 0.3543  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.5952  Acc@1: 81.2500 (79.6893)  Acc@5: 100.0000 (98.8716)  time: 0.3540  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.7293  Acc@1: 81.2500 (79.6834)  Acc@5: 100.0000 (98.8712)  time: 0.3539  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.5169  Acc@1: 75.0000 (79.6846)  Acc@5: 100.0000 (98.8754)  time: 0.3514  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.8260  Acc@1: 81.2500 (79.6881)  Acc@5: 100.0000 (98.8797)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.4280  Acc@1: 81.2500 (79.6822)  Acc@5: 100.0000 (98.8768)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.9323  Acc@1: 81.2500 (79.7044)  Acc@5: 100.0000 (98.8740)  time: 0.3545  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.3051  Acc@1: 81.2500 (79.6939)  Acc@5: 100.0000 (98.8736)  time: 0.3526  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.7030  Acc@1: 75.0000 (79.6788)  Acc@5: 100.0000 (98.8685)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.3210  Acc@1: 75.0000 (79.6731)  Acc@5: 100.0000 (98.8726)  time: 0.3537  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2720/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.8703  Acc@1: 81.2500 (79.6881)  Acc@5: 100.0000 (98.8768)  time: 0.3537  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.9092  Acc@1: 81.2500 (79.6869)  Acc@5: 100.0000 (98.8718)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -1.0391  Acc@1: 81.2500 (79.7109)  Acc@5: 100.0000 (98.8759)  time: 0.3518  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.4272  Acc@1: 81.2500 (79.7119)  Acc@5: 100.0000 (98.8754)  time: 0.3535  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.8703  Acc@1: 81.2500 (79.6926)  Acc@5: 100.0000 (98.8750)  time: 0.3528  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.8255  Acc@1: 81.2500 (79.7027)  Acc@5: 100.0000 (98.8722)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.7072  Acc@1: 81.2500 (79.6993)  Acc@5: 100.0000 (98.8718)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.5514  Acc@1: 81.2500 (79.6937)  Acc@5: 100.0000 (98.8691)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.7005  Acc@1: 75.0000 (79.6836)  Acc@5: 100.0000 (98.8665)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.5013  Acc@1: 75.0000 (79.6758)  Acc@5: 100.0000 (98.8594)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.5130  Acc@1: 75.0000 (79.6725)  Acc@5: 100.0000 (98.8612)  time: 0.3537  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.6956  Acc@1: 75.0000 (79.6671)  Acc@5: 100.0000 (98.8608)  time: 0.3529  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.5739  Acc@1: 75.0000 (79.6595)  Acc@5: 100.0000 (98.8604)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.6642  Acc@1: 81.2500 (79.6738)  Acc@5: 100.0000 (98.8644)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.4483  Acc@1: 81.2500 (79.6793)  Acc@5: 100.0000 (98.8575)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.6129  Acc@1: 81.2500 (79.6913)  Acc@5: 100.0000 (98.8571)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.6723  Acc@1: 81.2500 (79.6989)  Acc@5: 100.0000 (98.8567)  time: 0.3528  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2890/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.5011  Acc@1: 81.2500 (79.6956)  Acc@5: 100.0000 (98.8585)  time: 0.3548  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5966  Acc@1: 81.2500 (79.7031)  Acc@5: 100.0000 (98.8603)  time: 0.3534  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6917  Acc@1: 81.2500 (79.7192)  Acc@5: 100.0000 (98.8621)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.1130  Acc@1: 75.0000 (79.7116)  Acc@5: 100.0000 (98.8553)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.3359  Acc@1: 75.0000 (79.7190)  Acc@5: 100.0000 (98.8528)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.6225  Acc@1: 81.2500 (79.7242)  Acc@5: 100.0000 (98.8524)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.3667  Acc@1: 75.0000 (79.7060)  Acc@5: 100.0000 (98.8563)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.6857  Acc@1: 75.0000 (79.7197)  Acc@5: 100.0000 (98.8581)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.5204  Acc@1: 81.2500 (79.7206)  Acc@5: 100.0000 (98.8535)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.8958  Acc@1: 81.2500 (79.7153)  Acc@5: 100.0000 (98.8552)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.1314  Acc@1: 75.0000 (79.7100)  Acc@5: 100.0000 (98.8549)  time: 0.3502  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.6624  Acc@1: 75.0000 (79.6880)  Acc@5: 100.0000 (98.8504)  time: 0.3500  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.5945  Acc@1: 75.0000 (79.6953)  Acc@5: 100.0000 (98.8500)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.8610  Acc@1: 81.2500 (79.6756)  Acc@5: 100.0000 (98.8518)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.7426  Acc@1: 75.0000 (79.6602)  Acc@5: 100.0000 (98.8494)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.8453  Acc@1: 75.0000 (79.6490)  Acc@5: 100.0000 (98.8491)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5357  Acc@1: 75.0000 (79.6419)  Acc@5: 100.0000 (98.8487)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -0.9567  Acc@1: 75.0000 (79.6370)  Acc@5: 100.0000 (98.8525)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.6652  Acc@1: 75.0000 (79.6239)  Acc@5: 100.0000 (98.8542)  time: 0.3505  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -0.2366  Acc@1: 75.0000 (79.6190)  Acc@5: 100.0000 (98.8518)  time: 0.3509  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6761  Acc@1: 81.2500 (79.6324)  Acc@5: 100.0000 (98.8555)  time: 0.3504  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.8570  Acc@1: 87.5000 (79.6578)  Acc@5: 100.0000 (98.8592)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7068  Acc@1: 87.5000 (79.6709)  Acc@5: 100.0000 (98.8609)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -0.4274  Acc@1: 81.2500 (79.6640)  Acc@5: 100.0000 (98.8585)  time: 0.3530  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.9142  Acc@1: 81.2500 (79.6750)  Acc@5: 100.0000 (98.8562)  time: 0.3536  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -0.7929  Acc@1: 81.2500 (79.6741)  Acc@5: 100.0000 (98.8578)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.6267  Acc@1: 81.2500 (79.6573)  Acc@5: 100.0000 (98.8595)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.3253  Acc@1: 81.2500 (79.6564)  Acc@5: 100.0000 (98.8611)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.1714  Acc@1: 81.2500 (79.6574)  Acc@5: 100.0000 (98.8588)  time: 0.3526  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -0.6978  Acc@1: 75.0000 (79.6467)  Acc@5: 100.0000 (98.8604)  time: 0.3546  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.4530  Acc@1: 75.0000 (79.6557)  Acc@5: 100.0000 (98.8601)  time: 0.3549  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.8232  Acc@1: 81.2500 (79.6646)  Acc@5: 100.0000 (98.8597)  time: 0.3529  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.7073  Acc@1: 81.2500 (79.6753)  Acc@5: 100.0000 (98.8574)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.5561  Acc@1: 81.2500 (79.6802)  Acc@5: 100.0000 (98.8590)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.4380  Acc@1: 81.2500 (79.6715)  Acc@5: 100.0000 (98.8587)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.6474  Acc@1: 75.0000 (79.6764)  Acc@5: 100.0000 (98.8564)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.5377  Acc@1: 81.2500 (79.6966)  Acc@5: 100.0000 (98.8561)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.9397  Acc@1: 81.2500 (79.6803)  Acc@5: 100.0000 (98.8596)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.3473  Acc@1: 81.2500 (79.6908)  Acc@5: 100.0000 (98.8593)  time: 0.3529  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.4890  Acc@1: 81.2500 (79.6861)  Acc@5: 100.0000 (98.8609)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.5448  Acc@1: 75.0000 (79.6756)  Acc@5: 100.0000 (98.8586)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.7086  Acc@1: 75.0000 (79.6653)  Acc@5: 100.0000 (98.8564)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.9469  Acc@1: 81.2500 (79.6795)  Acc@5: 100.0000 (98.8542)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.7698  Acc@1: 81.2500 (79.6804)  Acc@5: 100.0000 (98.8520)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.7175  Acc@1: 81.2500 (79.6870)  Acc@5: 100.0000 (98.8517)  time: 0.3499  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.7738  Acc@1: 81.2500 (79.6880)  Acc@5: 100.0000 (98.8533)  time: 0.3508  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.2710  Acc@1: 75.0000 (79.6684)  Acc@5: 100.0000 (98.8530)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.7264  Acc@1: 81.2500 (79.6787)  Acc@5: 100.0000 (98.8564)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.8540  Acc@1: 81.2500 (79.6870)  Acc@5: 100.0000 (98.8561)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.6899  Acc@1: 81.2500 (79.6954)  Acc@5: 100.0000 (98.8576)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6777  Acc@1: 81.2500 (79.6907)  Acc@5: 100.0000 (98.8573)  time: 0.3548  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.2619  Acc@1: 81.2500 (79.6916)  Acc@5: 100.0000 (98.8606)  time: 0.3546  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.7022  Acc@1: 81.2500 (79.6870)  Acc@5: 100.0000 (98.8603)  time: 0.3547  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.2603  Acc@1: 75.0000 (79.6660)  Acc@5: 100.0000 (98.8545)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.8105  Acc@1: 75.0000 (79.6706)  Acc@5: 100.0000 (98.8524)  time: 0.3509  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.9173  Acc@1: 81.2500 (79.6952)  Acc@5: 100.0000 (98.8484)  time: 0.3512  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.5975  Acc@1: 81.2500 (79.6852)  Acc@5: 100.0000 (98.8500)  time: 0.3547  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5633  Acc@1: 81.2500 (79.6970)  Acc@5: 100.0000 (98.8515)  time: 0.3598  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6601  Acc@1: 81.2500 (79.6889)  Acc@5: 100.0000 (98.8512)  time: 0.3556  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6071  Acc@1: 81.2500 (79.6969)  Acc@5: 100.0000 (98.8545)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.4920  Acc@1: 81.2500 (79.6817)  Acc@5: 100.0000 (98.8542)  time: 0.3519  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8688  Acc@1: 75.0000 (79.6719)  Acc@5: 100.0000 (98.8539)  time: 0.3504  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4097  Acc@1: 75.0000 (79.6746)  Acc@5: 100.0000 (98.8572)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7944  Acc@1: 81.2500 (79.6862)  Acc@5: 100.0000 (98.8604)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8753  Acc@1: 81.2500 (79.6888)  Acc@5: 100.0000 (98.8583)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4513  Acc@1: 75.0000 (79.6703)  Acc@5: 100.0000 (98.8580)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.4940  Acc@1: 75.0000 (79.6783)  Acc@5: 100.0000 (98.8577)  time: 0.3520  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6880  Acc@1: 81.2500 (79.6757)  Acc@5: 100.0000 (98.8574)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.1139  Acc@1: 81.2500 (79.6731)  Acc@5: 100.0000 (98.8554)  time: 0.3525  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.8384  Acc@1: 81.2500 (79.6687)  Acc@5: 100.0000 (98.8498)  time: 0.3525  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.7262  Acc@1: 81.2500 (79.6749)  Acc@5: 100.0000 (98.8513)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8970  Acc@1: 81.2500 (79.6810)  Acc@5: 100.0000 (98.8510)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.9186  Acc@1: 75.0000 (79.6750)  Acc@5: 100.0000 (98.8507)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8561  Acc@1: 81.2500 (79.6931)  Acc@5: 100.0000 (98.8539)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.3980  Acc@1: 81.2500 (79.6991)  Acc@5: 100.0000 (98.8536)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.7287  Acc@1: 81.2500 (79.7102)  Acc@5: 100.0000 (98.8516)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.5523  Acc@1: 81.2500 (79.7042)  Acc@5: 100.0000 (98.8531)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0451  Acc@1: 81.2500 (79.7084)  Acc@5: 100.0000 (98.8528)  time: 0.3538  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.5114  Acc@1: 75.0000 (79.7058)  Acc@5: 100.0000 (98.8525)  time: 0.3600  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1419  Acc@1: 75.0000 (79.7015)  Acc@5: 100.0000 (98.8556)  time: 0.3583  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.8580  Acc@1: 75.0000 (79.6854)  Acc@5: 100.0000 (98.8519)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8255  Acc@1: 75.0000 (79.6829)  Acc@5: 100.0000 (98.8483)  time: 0.3530  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6486  Acc@1: 75.0000 (79.6787)  Acc@5: 100.0000 (98.8497)  time: 0.3534  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7036  Acc@1: 81.2500 (79.6879)  Acc@5: 100.0000 (98.8494)  time: 0.3550  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6256  Acc@1: 81.2500 (79.6921)  Acc@5: 100.0000 (98.8525)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5952  Acc@1: 81.2500 (79.6829)  Acc@5: 100.0000 (98.8506)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9775  Acc@1: 81.2500 (79.6883)  Acc@5: 100.0000 (98.8517)  time: 0.3528  data: 0.0011  max mem: 2503
Train: Epoch[4/5] Total time: 0:22:00 (0.3521 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}}
Averaged stats: Lr: 0.001875  Loss: -0.9775  Acc@1: 81.2500 (79.6883)  Acc@5: 100.0000 (98.8517)
Train: Epoch[5/5]  [   0/3750]  eta: 0:57:41  Lr: 0.001875  Loss: -0.8161  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.9230  data: 0.5705  max mem: 2503
Train: Epoch[5/5]  [  10/3750]  eta: 0:25:07  Lr: 0.001875  Loss: -0.7413  Acc@1: 81.2500 (84.6591)  Acc@5: 100.0000 (99.4318)  time: 0.4031  data: 0.0523  max mem: 2503
Train: Epoch[5/5]  [  20/3750]  eta: 0:23:28  Lr: 0.001875  Loss: -0.0768  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (99.1071)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:55  Lr: 0.001875  Loss: -0.5198  Acc@1: 75.0000 (80.8468)  Acc@5: 100.0000 (99.3952)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:32  Lr: 0.001875  Loss: -0.6226  Acc@1: 75.0000 (80.6402)  Acc@5: 100.0000 (99.3902)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  50/3750]  eta: 0:22:17  Lr: 0.001875  Loss: -0.9499  Acc@1: 81.2500 (81.0049)  Acc@5: 100.0000 (99.3873)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  60/3750]  eta: 0:22:07  Lr: 0.001875  Loss: -0.2380  Acc@1: 81.2500 (80.5328)  Acc@5: 100.0000 (99.2828)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -0.6099  Acc@1: 75.0000 (80.2817)  Acc@5: 100.0000 (98.9437)  time: 0.3510  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:52  Lr: 0.001875  Loss: -0.6618  Acc@1: 81.2500 (80.4012)  Acc@5: 100.0000 (98.9969)  time: 0.3509  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.7008  Acc@1: 81.2500 (80.4258)  Acc@5: 100.0000 (99.0385)  time: 0.3504  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:40  Lr: 0.001875  Loss: -0.6220  Acc@1: 81.2500 (80.6312)  Acc@5: 100.0000 (99.0099)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.9464  Acc@1: 81.2500 (80.5743)  Acc@5: 100.0000 (98.9302)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.4877  Acc@1: 81.2500 (80.5269)  Acc@5: 100.0000 (98.8636)  time: 0.3512  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.3270  Acc@1: 81.2500 (80.4389)  Acc@5: 100.0000 (98.9504)  time: 0.3537  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -0.2277  Acc@1: 81.2500 (80.5408)  Acc@5: 100.0000 (98.9362)  time: 0.3553  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [ 150/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.6218  Acc@1: 75.0000 (80.5050)  Acc@5: 100.0000 (98.9652)  time: 0.3549  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 160/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.5791  Acc@1: 75.0000 (80.2795)  Acc@5: 100.0000 (98.9519)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 170/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.4483  Acc@1: 81.2500 (80.4459)  Acc@5: 100.0000 (98.9401)  time: 0.3543  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [ 180/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.6229  Acc@1: 81.2500 (80.3522)  Acc@5: 100.0000 (98.9641)  time: 0.3565  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [ 190/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.6061  Acc@1: 75.0000 (80.4319)  Acc@5: 100.0000 (98.9202)  time: 0.3549  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 200/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.7106  Acc@1: 81.2500 (80.4726)  Acc@5: 100.0000 (98.9428)  time: 0.3536  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.7972  Acc@1: 75.0000 (80.0652)  Acc@5: 100.0000 (98.9929)  time: 0.3522  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.8744  Acc@1: 75.0000 (79.9774)  Acc@5: 100.0000 (98.9253)  time: 0.3514  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.6194  Acc@1: 81.2500 (79.8701)  Acc@5: 100.0000 (98.9177)  time: 0.3525  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.6859  Acc@1: 81.2500 (79.9533)  Acc@5: 100.0000 (98.9367)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.7366  Acc@1: 87.5000 (80.2042)  Acc@5: 100.0000 (98.9791)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.5044  Acc@1: 87.5000 (80.2203)  Acc@5: 100.0000 (98.9224)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.5732  Acc@1: 75.0000 (80.1430)  Acc@5: 100.0000 (98.9161)  time: 0.3518  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.5830  Acc@1: 75.0000 (79.8488)  Acc@5: 100.0000 (98.9101)  time: 0.3546  data: 0.0027  max mem: 2503
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.9263  Acc@1: 75.0000 (79.9613)  Acc@5: 100.0000 (98.9261)  time: 0.3546  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.8998  Acc@1: 81.2500 (79.9834)  Acc@5: 100.0000 (98.9410)  time: 0.3546  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.3346  Acc@1: 81.2500 (80.0643)  Acc@5: 100.0000 (98.9550)  time: 0.3558  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 320/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.6623  Acc@1: 81.2500 (79.9650)  Acc@5: 100.0000 (98.9681)  time: 0.3549  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 330/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.5878  Acc@1: 75.0000 (79.8150)  Acc@5: 100.0000 (98.9048)  time: 0.3554  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 340/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.6527  Acc@1: 75.0000 (79.7654)  Acc@5: 100.0000 (98.9186)  time: 0.3548  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 350/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.9467  Acc@1: 75.0000 (79.8077)  Acc@5: 100.0000 (98.8960)  time: 0.3535  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 360/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.9527  Acc@1: 81.2500 (79.8823)  Acc@5: 100.0000 (98.9266)  time: 0.3539  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.7176  Acc@1: 81.2500 (79.9360)  Acc@5: 100.0000 (98.9387)  time: 0.3534  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.3441  Acc@1: 81.2500 (79.9869)  Acc@5: 100.0000 (98.9009)  time: 0.3533  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.6612  Acc@1: 81.2500 (80.0512)  Acc@5: 100.0000 (98.8971)  time: 0.3520  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.3983  Acc@1: 81.2500 (79.9719)  Acc@5: 100.0000 (98.8466)  time: 0.3535  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.4421  Acc@1: 81.2500 (79.9574)  Acc@5: 100.0000 (98.8443)  time: 0.3551  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.5684  Acc@1: 81.2500 (79.9139)  Acc@5: 100.0000 (98.8569)  time: 0.3546  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.6505  Acc@1: 75.0000 (79.8289)  Acc@5: 100.0000 (98.8834)  time: 0.3574  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.6556  Acc@1: 75.0000 (79.7902)  Acc@5: 100.0000 (98.8237)  time: 0.3557  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.0442  Acc@1: 81.2500 (79.8088)  Acc@5: 100.0000 (98.8221)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.1692  Acc@1: 81.2500 (79.8129)  Acc@5: 100.0000 (98.8069)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.7047  Acc@1: 81.2500 (79.8965)  Acc@5: 100.0000 (98.8057)  time: 0.3570  data: 0.0025  max mem: 2503
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.7902  Acc@1: 81.2500 (79.8857)  Acc@5: 100.0000 (98.8046)  time: 0.3570  data: 0.0027  max mem: 2503
Train: Epoch[5/5]  [ 490/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.8534  Acc@1: 81.2500 (79.9389)  Acc@5: 100.0000 (98.8162)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 500/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.6403  Acc@1: 81.2500 (79.9401)  Acc@5: 100.0000 (98.7774)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 510/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -1.0154  Acc@1: 81.2500 (79.9535)  Acc@5: 100.0000 (98.7524)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 520/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.4250  Acc@1: 81.2500 (79.9544)  Acc@5: 100.0000 (98.7644)  time: 0.3535  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 530/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.5353  Acc@1: 81.2500 (79.9435)  Acc@5: 100.0000 (98.7759)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.5951  Acc@1: 81.2500 (79.9445)  Acc@5: 100.0000 (98.7985)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.7727  Acc@1: 81.2500 (79.9682)  Acc@5: 100.0000 (98.8203)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.5951  Acc@1: 81.2500 (80.0134)  Acc@5: 100.0000 (98.8191)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -1.0460  Acc@1: 87.5000 (80.0569)  Acc@5: 100.0000 (98.8179)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.7351  Acc@1: 81.2500 (80.0559)  Acc@5: 100.0000 (98.8275)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -0.3673  Acc@1: 81.2500 (80.0867)  Acc@5: 100.0000 (98.8367)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.7670  Acc@1: 81.2500 (80.1893)  Acc@5: 100.0000 (98.8561)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.6844  Acc@1: 87.5000 (80.2885)  Acc@5: 100.0000 (98.8543)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.8572  Acc@1: 81.2500 (80.2838)  Acc@5: 100.0000 (98.8527)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.5105  Acc@1: 81.2500 (80.2991)  Acc@5: 100.0000 (98.8510)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.7740  Acc@1: 81.2500 (80.2555)  Acc@5: 100.0000 (98.8495)  time: 0.3567  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.8860  Acc@1: 81.2500 (80.3187)  Acc@5: 100.0000 (98.8575)  time: 0.3565  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 660/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.9076  Acc@1: 81.2500 (80.3517)  Acc@5: 100.0000 (98.8559)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 670/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.5703  Acc@1: 81.2500 (80.2720)  Acc@5: 100.0000 (98.8543)  time: 0.3556  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 680/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.1596  Acc@1: 75.0000 (80.2496)  Acc@5: 100.0000 (98.8528)  time: 0.3590  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 690/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.9274  Acc@1: 81.2500 (80.2189)  Acc@5: 100.0000 (98.8242)  time: 0.3546  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.6147  Acc@1: 81.2500 (80.2068)  Acc@5: 100.0000 (98.8231)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.9732  Acc@1: 81.2500 (80.1951)  Acc@5: 100.0000 (98.8133)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.3067  Acc@1: 81.2500 (80.0884)  Acc@5: 100.0000 (98.7951)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.8147  Acc@1: 81.2500 (80.1043)  Acc@5: 100.0000 (98.7859)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.4241  Acc@1: 81.2500 (80.0860)  Acc@5: 100.0000 (98.8023)  time: 0.3542  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -0.8247  Acc@1: 81.2500 (80.1348)  Acc@5: 100.0000 (98.7933)  time: 0.3573  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.6578  Acc@1: 81.2500 (80.1413)  Acc@5: 100.0000 (98.8009)  time: 0.3567  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -0.7142  Acc@1: 81.2500 (80.1232)  Acc@5: 100.0000 (98.8084)  time: 0.3540  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.2013  Acc@1: 81.2500 (80.1376)  Acc@5: 100.0000 (98.8076)  time: 0.3551  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.7773  Acc@1: 81.2500 (80.1991)  Acc@5: 100.0000 (98.8069)  time: 0.3533  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.4552  Acc@1: 81.2500 (80.1888)  Acc@5: 100.0000 (98.8140)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.3472  Acc@1: 81.2500 (80.2404)  Acc@5: 100.0000 (98.8286)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 820/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.7186  Acc@1: 81.2500 (80.2147)  Acc@5: 100.0000 (98.8200)  time: 0.3539  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 830/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.5081  Acc@1: 81.2500 (80.1971)  Acc@5: 100.0000 (98.8192)  time: 0.3534  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 840/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.5484  Acc@1: 81.2500 (80.1798)  Acc@5: 100.0000 (98.7961)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 850/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.4337  Acc@1: 81.2500 (80.1851)  Acc@5: 100.0000 (98.7955)  time: 0.3513  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 860/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.3520  Acc@1: 81.2500 (80.1902)  Acc@5: 100.0000 (98.7877)  time: 0.3517  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.7616  Acc@1: 81.2500 (80.2526)  Acc@5: 100.0000 (98.7945)  time: 0.3511  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.5443  Acc@1: 81.2500 (80.2781)  Acc@5: 100.0000 (98.8082)  time: 0.3530  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.7810  Acc@1: 81.2500 (80.2609)  Acc@5: 100.0000 (98.8145)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.7589  Acc@1: 81.2500 (80.2511)  Acc@5: 100.0000 (98.8138)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.8862  Acc@1: 81.2500 (80.3170)  Acc@5: 100.0000 (98.8200)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.5773  Acc@1: 87.5000 (80.3339)  Acc@5: 100.0000 (98.8260)  time: 0.3546  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.6568  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (98.8386)  time: 0.3552  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.4180  Acc@1: 81.2500 (80.3600)  Acc@5: 100.0000 (98.8443)  time: 0.3537  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.5721  Acc@1: 81.2500 (80.3233)  Acc@5: 100.0000 (98.8433)  time: 0.3529  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.6248  Acc@1: 81.2500 (80.3850)  Acc@5: 100.0000 (98.8424)  time: 0.3522  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.6663  Acc@1: 81.2500 (80.3939)  Acc@5: 100.0000 (98.8414)  time: 0.3531  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.9878  Acc@1: 81.2500 (80.4027)  Acc@5: 100.0000 (98.8405)  time: 0.3537  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.9690  Acc@1: 81.2500 (80.3734)  Acc@5: 100.0000 (98.8459)  time: 0.3531  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1000/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.6036  Acc@1: 81.2500 (80.4071)  Acc@5: 100.0000 (98.8574)  time: 0.3542  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1010/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.4677  Acc@1: 81.2500 (80.4340)  Acc@5: 100.0000 (98.8625)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1020/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.8978  Acc@1: 87.5000 (80.4909)  Acc@5: 100.0000 (98.8675)  time: 0.3522  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1030/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.4875  Acc@1: 81.2500 (80.4559)  Acc@5: 100.0000 (98.8725)  time: 0.3526  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.7927  Acc@1: 81.2500 (80.4455)  Acc@5: 100.0000 (98.8593)  time: 0.3520  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.7640  Acc@1: 81.2500 (80.4472)  Acc@5: 100.0000 (98.8701)  time: 0.3513  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.5237  Acc@1: 81.2500 (80.4312)  Acc@5: 100.0000 (98.8749)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.8628  Acc@1: 87.5000 (80.4914)  Acc@5: 100.0000 (98.8796)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.4680  Acc@1: 81.2500 (80.4810)  Acc@5: 100.0000 (98.8841)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.7751  Acc@1: 81.2500 (80.5167)  Acc@5: 100.0000 (98.8829)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.5248  Acc@1: 81.2500 (80.5007)  Acc@5: 100.0000 (98.8760)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.2825  Acc@1: 81.2500 (80.5412)  Acc@5: 100.0000 (98.8861)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.5884  Acc@1: 87.5000 (80.5475)  Acc@5: 100.0000 (98.8849)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.9421  Acc@1: 87.5000 (80.5703)  Acc@5: 100.0000 (98.8837)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.5663  Acc@1: 75.0000 (80.4941)  Acc@5: 100.0000 (98.8880)  time: 0.3536  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.8832  Acc@1: 75.0000 (80.4952)  Acc@5: 100.0000 (98.8923)  time: 0.3557  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.4564  Acc@1: 81.2500 (80.4802)  Acc@5: 100.0000 (98.8910)  time: 0.3541  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1170/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.6799  Acc@1: 75.0000 (80.4547)  Acc@5: 100.0000 (98.8898)  time: 0.3511  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [1180/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.9762  Acc@1: 75.0000 (80.4562)  Acc@5: 100.0000 (98.8834)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1190/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.4359  Acc@1: 81.2500 (80.4314)  Acc@5: 100.0000 (98.8875)  time: 0.3540  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1200/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.5838  Acc@1: 75.0000 (80.4278)  Acc@5: 100.0000 (98.8811)  time: 0.3539  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.6034  Acc@1: 81.2500 (80.4036)  Acc@5: 100.0000 (98.8904)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.3215  Acc@1: 81.2500 (80.4003)  Acc@5: 100.0000 (98.8995)  time: 0.3566  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.9782  Acc@1: 81.2500 (80.4224)  Acc@5: 100.0000 (98.8983)  time: 0.3586  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.9762  Acc@1: 81.2500 (80.3989)  Acc@5: 100.0000 (98.9071)  time: 0.3559  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.5168  Acc@1: 75.0000 (80.4007)  Acc@5: 100.0000 (98.9159)  time: 0.3525  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.8317  Acc@1: 75.0000 (80.3925)  Acc@5: 100.0000 (98.9245)  time: 0.3519  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.3428  Acc@1: 75.0000 (80.3845)  Acc@5: 100.0000 (98.9231)  time: 0.3535  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.2409  Acc@1: 81.2500 (80.3767)  Acc@5: 100.0000 (98.9266)  time: 0.3542  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.6200  Acc@1: 81.2500 (80.3834)  Acc@5: 100.0000 (98.9204)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.9007  Acc@1: 75.0000 (80.3468)  Acc@5: 100.0000 (98.9287)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.8000  Acc@1: 81.2500 (80.3537)  Acc@5: 100.0000 (98.9178)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:18  Lr: 0.001875  Loss: 0.0386  Acc@1: 81.2500 (80.3416)  Acc@5: 100.0000 (98.9165)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.5367  Acc@1: 81.2500 (80.3578)  Acc@5: 100.0000 (98.9200)  time: 0.3521  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1340/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.7266  Acc@1: 81.2500 (80.3505)  Acc@5: 100.0000 (98.9234)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1350/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.9199  Acc@1: 87.5000 (80.4034)  Acc@5: 100.0000 (98.9267)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1360/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.7314  Acc@1: 87.5000 (80.4418)  Acc@5: 100.0000 (98.9346)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1370/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.7654  Acc@1: 87.5000 (80.4568)  Acc@5: 100.0000 (98.9378)  time: 0.3508  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.7316  Acc@1: 81.2500 (80.4806)  Acc@5: 100.0000 (98.9455)  time: 0.3507  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.5376  Acc@1: 81.2500 (80.4412)  Acc@5: 100.0000 (98.9351)  time: 0.3531  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7654  Acc@1: 75.0000 (80.4202)  Acc@5: 100.0000 (98.9427)  time: 0.3548  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.3964  Acc@1: 81.2500 (80.4305)  Acc@5: 100.0000 (98.9414)  time: 0.3536  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -1.0131  Acc@1: 81.2500 (80.4231)  Acc@5: 100.0000 (98.9400)  time: 0.3521  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.7847  Acc@1: 81.2500 (80.4202)  Acc@5: 100.0000 (98.9474)  time: 0.3515  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.5267  Acc@1: 81.2500 (80.3825)  Acc@5: 100.0000 (98.9460)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.0124  Acc@1: 81.2500 (80.3842)  Acc@5: 100.0000 (98.9490)  time: 0.3528  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.3556  Acc@1: 81.2500 (80.3645)  Acc@5: 100.0000 (98.9519)  time: 0.3544  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.8501  Acc@1: 81.2500 (80.3917)  Acc@5: 100.0000 (98.9463)  time: 0.3549  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.5342  Acc@1: 81.2500 (80.3722)  Acc@5: 100.0000 (98.9492)  time: 0.3540  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.8806  Acc@1: 81.2500 (80.3823)  Acc@5: 100.0000 (98.9562)  time: 0.3523  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -0.7876  Acc@1: 75.0000 (80.3714)  Acc@5: 100.0000 (98.9590)  time: 0.3529  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.6189  Acc@1: 75.0000 (80.3731)  Acc@5: 100.0000 (98.9576)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1520/3750]  eta: 0:13:07  Lr: 0.001875  Loss: 0.0303  Acc@1: 81.2500 (80.3419)  Acc@5: 100.0000 (98.9563)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1530/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.4439  Acc@1: 81.2500 (80.3315)  Acc@5: 100.0000 (98.9549)  time: 0.3531  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1540/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.1653  Acc@1: 75.0000 (80.3212)  Acc@5: 100.0000 (98.9455)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.3078  Acc@1: 75.0000 (80.2990)  Acc@5: 100.0000 (98.9523)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.3814  Acc@1: 81.2500 (80.3171)  Acc@5: 100.0000 (98.9510)  time: 0.3537  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.6630  Acc@1: 81.2500 (80.2992)  Acc@5: 100.0000 (98.9378)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.7782  Acc@1: 81.2500 (80.3052)  Acc@5: 100.0000 (98.9445)  time: 0.3531  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.7754  Acc@1: 81.2500 (80.3033)  Acc@5: 100.0000 (98.9472)  time: 0.3531  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.6708  Acc@1: 75.0000 (80.2740)  Acc@5: 100.0000 (98.9343)  time: 0.3525  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.5980  Acc@1: 75.0000 (80.2956)  Acc@5: 100.0000 (98.9409)  time: 0.3522  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.6949  Acc@1: 81.2500 (80.3131)  Acc@5: 100.0000 (98.9397)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.5011  Acc@1: 81.2500 (80.3073)  Acc@5: 100.0000 (98.9385)  time: 0.3533  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.4585  Acc@1: 81.2500 (80.3169)  Acc@5: 100.0000 (98.9298)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.2797  Acc@1: 81.2500 (80.3150)  Acc@5: 100.0000 (98.9363)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.5945  Acc@1: 81.2500 (80.3131)  Acc@5: 100.0000 (98.9389)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.8294  Acc@1: 75.0000 (80.3037)  Acc@5: 100.0000 (98.9452)  time: 0.3532  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.9418  Acc@1: 81.2500 (80.3354)  Acc@5: 100.0000 (98.9441)  time: 0.3539  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1690/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.8258  Acc@1: 81.2500 (80.3223)  Acc@5: 100.0000 (98.9429)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1700/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.4721  Acc@1: 81.2500 (80.3241)  Acc@5: 100.0000 (98.9418)  time: 0.3535  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1710/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.8130  Acc@1: 81.2500 (80.3404)  Acc@5: 100.0000 (98.9370)  time: 0.3539  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -1.1065  Acc@1: 81.2500 (80.3421)  Acc@5: 100.0000 (98.9359)  time: 0.3551  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.7896  Acc@1: 81.2500 (80.3654)  Acc@5: 100.0000 (98.9385)  time: 0.3548  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8364  Acc@1: 81.2500 (80.3418)  Acc@5: 100.0000 (98.9410)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.8333  Acc@1: 81.2500 (80.3469)  Acc@5: 100.0000 (98.9328)  time: 0.3538  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.8576  Acc@1: 81.2500 (80.3379)  Acc@5: 100.0000 (98.9353)  time: 0.3529  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.1376  Acc@1: 75.0000 (80.3219)  Acc@5: 100.0000 (98.9342)  time: 0.3521  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.5259  Acc@1: 75.0000 (80.3130)  Acc@5: 100.0000 (98.9332)  time: 0.3528  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.4855  Acc@1: 75.0000 (80.3252)  Acc@5: 100.0000 (98.9391)  time: 0.3516  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.5945  Acc@1: 75.0000 (80.2957)  Acc@5: 100.0000 (98.9416)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.7635  Acc@1: 75.0000 (80.2733)  Acc@5: 100.0000 (98.9371)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.9153  Acc@1: 81.2500 (80.2684)  Acc@5: 100.0000 (98.9395)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.7793  Acc@1: 81.2500 (80.2806)  Acc@5: 100.0000 (98.9452)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.7646  Acc@1: 81.2500 (80.2587)  Acc@5: 100.0000 (98.9340)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.7342  Acc@1: 81.2500 (80.2708)  Acc@5: 100.0000 (98.9330)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1860/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.5934  Acc@1: 81.2500 (80.2693)  Acc@5: 100.0000 (98.9354)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1870/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.7691  Acc@1: 81.2500 (80.2879)  Acc@5: 100.0000 (98.9277)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1880/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.7226  Acc@1: 81.2500 (80.2831)  Acc@5: 100.0000 (98.9301)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.6718  Acc@1: 81.2500 (80.2915)  Acc@5: 100.0000 (98.9258)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.3826  Acc@1: 81.2500 (80.2604)  Acc@5: 100.0000 (98.9216)  time: 0.3502  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.6500  Acc@1: 75.0000 (80.2394)  Acc@5: 100.0000 (98.9207)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.7496  Acc@1: 81.2500 (80.2479)  Acc@5: 100.0000 (98.9166)  time: 0.3563  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.4425  Acc@1: 81.2500 (80.2596)  Acc@5: 100.0000 (98.9157)  time: 0.3532  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.9026  Acc@1: 81.2500 (80.2518)  Acc@5: 100.0000 (98.9149)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.7349  Acc@1: 81.2500 (80.2441)  Acc@5: 100.0000 (98.9140)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.8184  Acc@1: 81.2500 (80.2429)  Acc@5: 100.0000 (98.9164)  time: 0.3546  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.4357  Acc@1: 81.2500 (80.2385)  Acc@5: 100.0000 (98.9187)  time: 0.3568  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.8346  Acc@1: 81.2500 (80.2309)  Acc@5: 100.0000 (98.9178)  time: 0.3541  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.6818  Acc@1: 81.2500 (80.2392)  Acc@5: 100.0000 (98.9139)  time: 0.3527  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.5579  Acc@1: 87.5000 (80.2505)  Acc@5: 100.0000 (98.9130)  time: 0.3515  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.7452  Acc@1: 81.2500 (80.2555)  Acc@5: 100.0000 (98.9060)  time: 0.3518  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.7963  Acc@1: 81.2500 (80.2882)  Acc@5: 100.0000 (98.9114)  time: 0.3516  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2030/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.9744  Acc@1: 87.5000 (80.3145)  Acc@5: 100.0000 (98.9106)  time: 0.3527  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2040/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.7010  Acc@1: 81.2500 (80.2915)  Acc@5: 100.0000 (98.9068)  time: 0.3535  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2050/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.7295  Acc@1: 75.0000 (80.2931)  Acc@5: 100.0000 (98.9030)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.9015  Acc@1: 81.2500 (80.3160)  Acc@5: 100.0000 (98.9083)  time: 0.3516  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.5458  Acc@1: 87.5000 (80.3326)  Acc@5: 100.0000 (98.8985)  time: 0.3521  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.8481  Acc@1: 81.2500 (80.3370)  Acc@5: 100.0000 (98.8948)  time: 0.3520  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -1.0153  Acc@1: 81.2500 (80.3324)  Acc@5: 100.0000 (98.8911)  time: 0.3522  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.5824  Acc@1: 75.0000 (80.3159)  Acc@5: 100.0000 (98.8874)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.8627  Acc@1: 75.0000 (80.3115)  Acc@5: 100.0000 (98.8897)  time: 0.3544  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.8793  Acc@1: 75.0000 (80.2982)  Acc@5: 100.0000 (98.8920)  time: 0.3529  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -1.0119  Acc@1: 81.2500 (80.3027)  Acc@5: 100.0000 (98.8943)  time: 0.3505  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.9464  Acc@1: 81.2500 (80.2983)  Acc@5: 100.0000 (98.8936)  time: 0.3529  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.6671  Acc@1: 81.2500 (80.2999)  Acc@5: 100.0000 (98.8959)  time: 0.3533  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.7563  Acc@1: 81.2500 (80.3071)  Acc@5: 100.0000 (98.9010)  time: 0.3549  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.3241  Acc@1: 75.0000 (80.2885)  Acc@5: 100.0000 (98.9003)  time: 0.3549  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.6306  Acc@1: 75.0000 (80.2785)  Acc@5: 100.0000 (98.8910)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.8089  Acc@1: 81.2500 (80.2773)  Acc@5: 100.0000 (98.8932)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2200/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -1.0163  Acc@1: 81.2500 (80.2817)  Acc@5: 100.0000 (98.8925)  time: 0.3521  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2210/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.6819  Acc@1: 81.2500 (80.2719)  Acc@5: 100.0000 (98.8976)  time: 0.3514  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2220/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.7855  Acc@1: 81.2500 (80.2932)  Acc@5: 100.0000 (98.8941)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.8349  Acc@1: 81.2500 (80.3059)  Acc@5: 100.0000 (98.8962)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.5642  Acc@1: 81.2500 (80.3046)  Acc@5: 100.0000 (98.8984)  time: 0.3603  data: 0.0033  max mem: 2503
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.3743  Acc@1: 75.0000 (80.2976)  Acc@5: 100.0000 (98.8922)  time: 0.3593  data: 0.0033  max mem: 2503
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.7346  Acc@1: 75.0000 (80.2963)  Acc@5: 100.0000 (98.8971)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.2322  Acc@1: 75.0000 (80.2868)  Acc@5: 100.0000 (98.8937)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -1.0413  Acc@1: 81.2500 (80.3157)  Acc@5: 100.0000 (98.8958)  time: 0.3553  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.8527  Acc@1: 87.5000 (80.3197)  Acc@5: 100.0000 (98.8951)  time: 0.3568  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.7314  Acc@1: 81.2500 (80.3265)  Acc@5: 100.0000 (98.8972)  time: 0.3528  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.4806  Acc@1: 81.2500 (80.3170)  Acc@5: 100.0000 (98.8966)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.6672  Acc@1: 81.2500 (80.3344)  Acc@5: 100.0000 (98.8960)  time: 0.3517  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5344  Acc@1: 81.2500 (80.3384)  Acc@5: 100.0000 (98.8926)  time: 0.3532  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.0234  Acc@1: 81.2500 (80.3316)  Acc@5: 100.0000 (98.8920)  time: 0.3523  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.9186  Acc@1: 81.2500 (80.3328)  Acc@5: 100.0000 (98.8967)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.9124  Acc@1: 87.5000 (80.3791)  Acc@5: 100.0000 (98.8961)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.6049  Acc@1: 87.5000 (80.3775)  Acc@5: 100.0000 (98.8981)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2380/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.4897  Acc@1: 81.2500 (80.3785)  Acc@5: 100.0000 (98.9028)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2390/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -1.0075  Acc@1: 81.2500 (80.4057)  Acc@5: 100.0000 (98.9047)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7281  Acc@1: 81.2500 (80.4066)  Acc@5: 100.0000 (98.9041)  time: 0.3510  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4271  Acc@1: 81.2500 (80.4049)  Acc@5: 100.0000 (98.9061)  time: 0.3512  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.6462  Acc@1: 81.2500 (80.3955)  Acc@5: 100.0000 (98.9054)  time: 0.3524  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.6725  Acc@1: 81.2500 (80.4016)  Acc@5: 100.0000 (98.9099)  time: 0.3536  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.5896  Acc@1: 81.2500 (80.4025)  Acc@5: 100.0000 (98.9093)  time: 0.3547  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.2561  Acc@1: 81.2500 (80.3983)  Acc@5: 100.0000 (98.9137)  time: 0.3550  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.6949  Acc@1: 81.2500 (80.3865)  Acc@5: 100.0000 (98.9130)  time: 0.3515  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.8741  Acc@1: 81.2500 (80.4001)  Acc@5: 100.0000 (98.9099)  time: 0.3509  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.5221  Acc@1: 81.2500 (80.3910)  Acc@5: 100.0000 (98.9067)  time: 0.3536  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.8181  Acc@1: 81.2500 (80.3869)  Acc@5: 100.0000 (98.9061)  time: 0.3545  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6177  Acc@1: 81.2500 (80.4028)  Acc@5: 100.0000 (98.9079)  time: 0.3570  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.8300  Acc@1: 75.0000 (80.3813)  Acc@5: 100.0000 (98.9098)  time: 0.3565  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.7215  Acc@1: 81.2500 (80.3872)  Acc@5: 100.0000 (98.9141)  time: 0.3535  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.5888  Acc@1: 81.2500 (80.3808)  Acc@5: 100.0000 (98.9159)  time: 0.3535  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.7837  Acc@1: 81.2500 (80.3719)  Acc@5: 100.0000 (98.9128)  time: 0.3517  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2550/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.1703  Acc@1: 81.2500 (80.3680)  Acc@5: 100.0000 (98.9122)  time: 0.3514  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2560/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.6063  Acc@1: 81.2500 (80.3739)  Acc@5: 100.0000 (98.9140)  time: 0.3537  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.4942  Acc@1: 75.0000 (80.3505)  Acc@5: 100.0000 (98.9182)  time: 0.3547  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.7277  Acc@1: 75.0000 (80.3347)  Acc@5: 100.0000 (98.9200)  time: 0.3530  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.2464  Acc@1: 75.0000 (80.3334)  Acc@5: 100.0000 (98.9217)  time: 0.3520  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.7709  Acc@1: 75.0000 (80.3297)  Acc@5: 100.0000 (98.9235)  time: 0.3523  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.0246  Acc@1: 75.0000 (80.3021)  Acc@5: 100.0000 (98.9204)  time: 0.3523  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.7963  Acc@1: 81.2500 (80.3129)  Acc@5: 100.0000 (98.9222)  time: 0.3516  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.9470  Acc@1: 81.2500 (80.3164)  Acc@5: 100.0000 (98.9215)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.7111  Acc@1: 75.0000 (80.2892)  Acc@5: 100.0000 (98.9209)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.7310  Acc@1: 75.0000 (80.2881)  Acc@5: 100.0000 (98.9179)  time: 0.3521  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.8184  Acc@1: 81.2500 (80.2847)  Acc@5: 100.0000 (98.9125)  time: 0.3510  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -0.6147  Acc@1: 81.2500 (80.2859)  Acc@5: 100.0000 (98.9166)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8705  Acc@1: 81.2500 (80.2779)  Acc@5: 100.0000 (98.9206)  time: 0.3521  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.8318  Acc@1: 81.2500 (80.2768)  Acc@5: 100.0000 (98.9223)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.9987  Acc@1: 81.2500 (80.2920)  Acc@5: 100.0000 (98.9217)  time: 0.3536  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.7696  Acc@1: 81.2500 (80.2979)  Acc@5: 100.0000 (98.9211)  time: 0.3544  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [2720/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.3914  Acc@1: 81.2500 (80.3037)  Acc@5: 100.0000 (98.9227)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2730/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.7480  Acc@1: 81.2500 (80.2957)  Acc@5: 100.0000 (98.9244)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.7470  Acc@1: 81.2500 (80.3060)  Acc@5: 100.0000 (98.9215)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.5752  Acc@1: 75.0000 (80.2981)  Acc@5: 100.0000 (98.9231)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.6949  Acc@1: 81.2500 (80.2947)  Acc@5: 100.0000 (98.9270)  time: 0.3527  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.7875  Acc@1: 81.2500 (80.2914)  Acc@5: 100.0000 (98.9286)  time: 0.3533  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.9801  Acc@1: 81.2500 (80.2949)  Acc@5: 100.0000 (98.9302)  time: 0.3553  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.6493  Acc@1: 81.2500 (80.2960)  Acc@5: 100.0000 (98.9341)  time: 0.3539  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4806  Acc@1: 81.2500 (80.2950)  Acc@5: 100.0000 (98.9334)  time: 0.3511  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.6821  Acc@1: 81.2500 (80.2850)  Acc@5: 100.0000 (98.9283)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.8999  Acc@1: 81.2500 (80.2929)  Acc@5: 100.0000 (98.9277)  time: 0.3523  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.7138  Acc@1: 81.2500 (80.2963)  Acc@5: 100.0000 (98.9293)  time: 0.3552  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.7256  Acc@1: 81.2500 (80.2930)  Acc@5: 100.0000 (98.9308)  time: 0.3554  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.9200  Acc@1: 75.0000 (80.2986)  Acc@5: 100.0000 (98.9302)  time: 0.3523  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.5497  Acc@1: 75.0000 (80.2910)  Acc@5: 100.0000 (98.9274)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.4943  Acc@1: 81.2500 (80.2965)  Acc@5: 100.0000 (98.9268)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.9914  Acc@1: 81.2500 (80.2955)  Acc@5: 100.0000 (98.9240)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.9550  Acc@1: 81.2500 (80.3117)  Acc@5: 100.0000 (98.9255)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2900/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.4736  Acc@1: 81.2500 (80.3193)  Acc@5: 100.0000 (98.9249)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.6583  Acc@1: 81.2500 (80.3246)  Acc@5: 100.0000 (98.9265)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -1.0123  Acc@1: 81.2500 (80.3214)  Acc@5: 100.0000 (98.9280)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.4179  Acc@1: 75.0000 (80.3182)  Acc@5: 100.0000 (98.9274)  time: 0.3506  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.5671  Acc@1: 81.2500 (80.3192)  Acc@5: 100.0000 (98.9289)  time: 0.3501  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.6155  Acc@1: 81.2500 (80.3287)  Acc@5: 100.0000 (98.9283)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.6681  Acc@1: 81.2500 (80.3424)  Acc@5: 100.0000 (98.9298)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.7702  Acc@1: 81.2500 (80.3412)  Acc@5: 100.0000 (98.9292)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.8888  Acc@1: 81.2500 (80.3506)  Acc@5: 100.0000 (98.9286)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.5192  Acc@1: 87.5000 (80.3661)  Acc@5: 100.0000 (98.9322)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.7002  Acc@1: 87.5000 (80.3732)  Acc@5: 100.0000 (98.9358)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.6705  Acc@1: 81.2500 (80.3844)  Acc@5: 100.0000 (98.9352)  time: 0.3568  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5453  Acc@1: 81.2500 (80.3790)  Acc@5: 100.0000 (98.9325)  time: 0.3560  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.8099  Acc@1: 81.2500 (80.3757)  Acc@5: 100.0000 (98.9339)  time: 0.3513  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.6313  Acc@1: 81.2500 (80.3806)  Acc@5: 100.0000 (98.9333)  time: 0.3537  data: 0.0026  max mem: 2503
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.1719  Acc@1: 81.2500 (80.3794)  Acc@5: 100.0000 (98.9368)  time: 0.3546  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.9121  Acc@1: 81.2500 (80.3802)  Acc@5: 100.0000 (98.9403)  time: 0.3541  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3070/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.6259  Acc@1: 81.2500 (80.3789)  Acc@5: 100.0000 (98.9397)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.5882  Acc@1: 81.2500 (80.3818)  Acc@5: 100.0000 (98.9411)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.1955  Acc@1: 81.2500 (80.3745)  Acc@5: 100.0000 (98.9425)  time: 0.3514  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.4643  Acc@1: 81.2500 (80.3793)  Acc@5: 100.0000 (98.9378)  time: 0.3546  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.6726  Acc@1: 81.2500 (80.3801)  Acc@5: 100.0000 (98.9352)  time: 0.3566  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.4048  Acc@1: 81.2500 (80.3809)  Acc@5: 100.0000 (98.9386)  time: 0.3538  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6057  Acc@1: 81.2500 (80.3717)  Acc@5: 100.0000 (98.9301)  time: 0.3521  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:35  Lr: 0.001875  Loss: 0.0471  Acc@1: 81.2500 (80.3745)  Acc@5: 100.0000 (98.9315)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6694  Acc@1: 81.2500 (80.3693)  Acc@5: 100.0000 (98.9329)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.7615  Acc@1: 81.2500 (80.3761)  Acc@5: 100.0000 (98.9303)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -0.3978  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (98.9317)  time: 0.3514  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.4909  Acc@1: 75.0000 (80.3560)  Acc@5: 100.0000 (98.9292)  time: 0.3517  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:17  Lr: 0.001875  Loss: -0.9415  Acc@1: 81.2500 (80.3627)  Acc@5: 100.0000 (98.9306)  time: 0.3525  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.3889  Acc@1: 81.2500 (80.3636)  Acc@5: 100.0000 (98.9320)  time: 0.3531  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:10  Lr: 0.001875  Loss: -0.7654  Acc@1: 81.2500 (80.3683)  Acc@5: 100.0000 (98.9334)  time: 0.3521  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.5433  Acc@1: 81.2500 (80.3632)  Acc@5: 100.0000 (98.9328)  time: 0.3527  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:03  Lr: 0.001875  Loss: -0.8217  Acc@1: 81.2500 (80.3776)  Acc@5: 100.0000 (98.9342)  time: 0.3530  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3240/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.7818  Acc@1: 87.5000 (80.3899)  Acc@5: 100.0000 (98.9355)  time: 0.3533  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.4966  Acc@1: 81.2500 (80.3810)  Acc@5: 100.0000 (98.9369)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.5224  Acc@1: 81.2500 (80.3780)  Acc@5: 100.0000 (98.9382)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:49  Lr: 0.001875  Loss: -1.0216  Acc@1: 81.2500 (80.3959)  Acc@5: 100.0000 (98.9357)  time: 0.3596  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.6618  Acc@1: 87.5000 (80.4099)  Acc@5: 100.0000 (98.9371)  time: 0.3609  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.7960  Acc@1: 81.2500 (80.4163)  Acc@5: 100.0000 (98.9384)  time: 0.3543  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.5468  Acc@1: 75.0000 (80.4112)  Acc@5: 100.0000 (98.9397)  time: 0.3517  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6780  Acc@1: 75.0000 (80.4006)  Acc@5: 100.0000 (98.9316)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5633  Acc@1: 81.2500 (80.4031)  Acc@5: 100.0000 (98.9310)  time: 0.3544  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:28  Lr: 0.001875  Loss: -0.7921  Acc@1: 81.2500 (80.3982)  Acc@5: 100.0000 (98.9305)  time: 0.3544  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.8733  Acc@1: 81.2500 (80.4063)  Acc@5: 100.0000 (98.9337)  time: 0.3518  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:21  Lr: 0.001875  Loss: -0.6768  Acc@1: 81.2500 (80.4014)  Acc@5: 100.0000 (98.9350)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.4214  Acc@1: 81.2500 (80.4039)  Acc@5: 100.0000 (98.9363)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5591  Acc@1: 75.0000 (80.3934)  Acc@5: 100.0000 (98.9358)  time: 0.3546  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.0092  Acc@1: 75.0000 (80.3812)  Acc@5: 100.0000 (98.9297)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6089  Acc@1: 81.2500 (80.3782)  Acc@5: 100.0000 (98.9310)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.8851  Acc@1: 81.2500 (80.3863)  Acc@5: 100.0000 (98.9323)  time: 0.3530  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3410/3750]  eta: 0:02:00  Lr: 0.001875  Loss: -0.6182  Acc@1: 81.2500 (80.3815)  Acc@5: 100.0000 (98.9336)  time: 0.3539  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.5873  Acc@1: 81.2500 (80.3822)  Acc@5: 100.0000 (98.9349)  time: 0.3526  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.9168  Acc@1: 81.2500 (80.3884)  Acc@5: 100.0000 (98.9362)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6176  Acc@1: 81.2500 (80.3927)  Acc@5: 100.0000 (98.9393)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.8011  Acc@1: 81.2500 (80.3988)  Acc@5: 100.0000 (98.9405)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5575  Acc@1: 81.2500 (80.3940)  Acc@5: 100.0000 (98.9418)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.7914  Acc@1: 75.0000 (80.3893)  Acc@5: 100.0000 (98.9376)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5146  Acc@1: 81.2500 (80.3954)  Acc@5: 100.0000 (98.9389)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7526  Acc@1: 81.2500 (80.3924)  Acc@5: 100.0000 (98.9401)  time: 0.3556  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:28  Lr: 0.001875  Loss: -0.7529  Acc@1: 81.2500 (80.3967)  Acc@5: 100.0000 (98.9396)  time: 0.3563  data: 0.0026  max mem: 2503
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5959  Acc@1: 75.0000 (80.3831)  Acc@5: 100.0000 (98.9373)  time: 0.3519  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7542  Acc@1: 75.0000 (80.3802)  Acc@5: 100.0000 (98.9403)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.4935  Acc@1: 81.2500 (80.3756)  Acc@5: 100.0000 (98.9397)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9134  Acc@1: 81.2500 (80.3728)  Acc@5: 100.0000 (98.9304)  time: 0.3590  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9440  Acc@1: 81.2500 (80.3682)  Acc@5: 100.0000 (98.9281)  time: 0.3594  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:07  Lr: 0.001875  Loss: -0.2043  Acc@1: 81.2500 (80.3672)  Acc@5: 100.0000 (98.9241)  time: 0.3537  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.7682  Acc@1: 81.2500 (80.3661)  Acc@5: 100.0000 (98.9236)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3580/3750]  eta: 0:01:00  Lr: 0.001875  Loss: 0.0186  Acc@1: 75.0000 (80.3477)  Acc@5: 100.0000 (98.9214)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.6269  Acc@1: 75.0000 (80.3537)  Acc@5: 100.0000 (98.9244)  time: 0.3573  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8754  Acc@1: 87.5000 (80.3648)  Acc@5: 100.0000 (98.9239)  time: 0.3593  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.4982  Acc@1: 81.2500 (80.3604)  Acc@5: 100.0000 (98.9234)  time: 0.3543  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4916  Acc@1: 75.0000 (80.3421)  Acc@5: 100.0000 (98.9247)  time: 0.3511  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.4859  Acc@1: 81.2500 (80.3446)  Acc@5: 100.0000 (98.9242)  time: 0.3523  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5401  Acc@1: 81.2500 (80.3454)  Acc@5: 100.0000 (98.9271)  time: 0.3542  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.7170  Acc@1: 81.2500 (80.3496)  Acc@5: 100.0000 (98.9284)  time: 0.3532  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.8223  Acc@1: 81.2500 (80.3486)  Acc@5: 100.0000 (98.9262)  time: 0.3518  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6157  Acc@1: 81.2500 (80.3579)  Acc@5: 100.0000 (98.9274)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6965  Acc@1: 75.0000 (80.3518)  Acc@5: 100.0000 (98.9252)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0682  Acc@1: 81.2500 (80.3525)  Acc@5: 100.0000 (98.9247)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3336  Acc@1: 81.2500 (80.3516)  Acc@5: 100.0000 (98.9260)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4674  Acc@1: 75.0000 (80.3389)  Acc@5: 100.0000 (98.9238)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6516  Acc@1: 81.2500 (80.3514)  Acc@5: 100.0000 (98.9250)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5974  Acc@1: 81.2500 (80.3387)  Acc@5: 100.0000 (98.9212)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6768  Acc@1: 81.2500 (80.3478)  Acc@5: 100.0000 (98.9224)  time: 0.3515  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7024  Acc@1: 81.2500 (80.3567)  Acc@5: 100.0000 (98.9217)  time: 0.3517  data: 0.0011  max mem: 2503
Train: Epoch[5/5] Total time: 0:22:04 (0.3532 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}}
Averaged stats: Lr: 0.001875  Loss: -0.7024  Acc@1: 81.2500 (80.3567)  Acc@5: 100.0000 (98.9217)
Test: [Task 1]  [   0/1627]  eta: 0:23:47  Loss: 1.6773 (1.6773)  Acc@1: 43.7500 (43.7500)  Acc@5: 81.2500 (81.2500)  time: 0.8776  data: 0.6612  max mem: 2503
Test: [Task 1]  [  10/1627]  eta: 0:07:37  Loss: 1.3523 (1.3236)  Acc@1: 62.5000 (60.2273)  Acc@5: 87.5000 (91.4773)  time: 0.2829  data: 0.0623  max mem: 2503
Test: [Task 1]  [  20/1627]  eta: 0:06:46  Loss: 1.2558 (1.2850)  Acc@1: 62.5000 (64.5833)  Acc@5: 87.5000 (89.8810)  time: 0.2217  data: 0.0021  max mem: 2503
Test: [Task 1]  [  30/1627]  eta: 0:06:26  Loss: 1.2558 (1.2787)  Acc@1: 62.5000 (64.7177)  Acc@5: 93.7500 (90.5242)  time: 0.2200  data: 0.0012  max mem: 2503
Test: [Task 1]  [  40/1627]  eta: 0:06:14  Loss: 1.2913 (1.2868)  Acc@1: 62.5000 (64.7866)  Acc@5: 93.7500 (90.7012)  time: 0.2184  data: 0.0005  max mem: 2503
Test: [Task 1]  [  50/1627]  eta: 0:06:06  Loss: 1.0701 (1.2616)  Acc@1: 68.7500 (65.6863)  Acc@5: 93.7500 (91.1765)  time: 0.2176  data: 0.0004  max mem: 2503
Test: [Task 1]  [  60/1627]  eta: 0:06:00  Loss: 1.1734 (1.2756)  Acc@1: 68.7500 (65.2664)  Acc@5: 93.7500 (90.9836)  time: 0.2183  data: 0.0005  max mem: 2503
Test: [Task 1]  [  70/1627]  eta: 0:05:55  Loss: 1.2661 (1.2695)  Acc@1: 56.2500 (65.0528)  Acc@5: 93.7500 (91.2852)  time: 0.2179  data: 0.0005  max mem: 2503
Test: [Task 1]  [  80/1627]  eta: 0:05:52  Loss: 1.0739 (1.2538)  Acc@1: 68.7500 (65.0463)  Acc@5: 93.7500 (91.4352)  time: 0.2192  data: 0.0005  max mem: 2503
Test: [Task 1]  [  90/1627]  eta: 0:05:49  Loss: 1.3064 (1.2719)  Acc@1: 68.7500 (64.6978)  Acc@5: 93.7500 (91.0714)  time: 0.2225  data: 0.0033  max mem: 2503
Test: [Task 1]  [ 100/1627]  eta: 0:05:45  Loss: 1.4897 (1.2998)  Acc@1: 62.5000 (64.1089)  Acc@5: 87.5000 (90.5322)  time: 0.2219  data: 0.0033  max mem: 2503
Test: [Task 1]  [ 110/1627]  eta: 0:05:42  Loss: 1.2993 (1.2991)  Acc@1: 62.5000 (63.6261)  Acc@5: 93.7500 (91.1036)  time: 0.2193  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 120/1627]  eta: 0:05:39  Loss: 1.2688 (1.2952)  Acc@1: 62.5000 (63.9979)  Acc@5: 93.7500 (91.0124)  time: 0.2186  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 130/1627]  eta: 0:05:36  Loss: 1.3398 (1.3049)  Acc@1: 62.5000 (63.4542)  Acc@5: 93.7500 (90.8874)  time: 0.2185  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 140/1627]  eta: 0:05:33  Loss: 1.3398 (1.3024)  Acc@1: 56.2500 (63.3865)  Acc@5: 93.7500 (90.7801)  time: 0.2176  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 150/1627]  eta: 0:05:30  Loss: 0.9852 (1.2850)  Acc@1: 68.7500 (64.0728)  Acc@5: 93.7500 (91.0596)  time: 0.2171  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 160/1627]  eta: 0:05:27  Loss: 0.9651 (1.2747)  Acc@1: 68.7500 (64.5575)  Acc@5: 93.7500 (91.0714)  time: 0.2172  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 170/1627]  eta: 0:05:25  Loss: 1.1949 (1.2692)  Acc@1: 68.7500 (64.6930)  Acc@5: 87.5000 (90.9722)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 180/1627]  eta: 0:05:22  Loss: 1.2301 (1.2734)  Acc@1: 62.5000 (64.5718)  Acc@5: 87.5000 (90.9185)  time: 0.2231  data: 0.0017  max mem: 2503
Test: [Task 1]  [ 190/1627]  eta: 0:05:20  Loss: 1.2760 (1.2690)  Acc@1: 62.5000 (64.6597)  Acc@5: 93.7500 (90.8704)  time: 0.2209  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 200/1627]  eta: 0:05:17  Loss: 1.2189 (1.2672)  Acc@1: 62.5000 (64.6766)  Acc@5: 93.7500 (90.9515)  time: 0.2179  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 210/1627]  eta: 0:05:15  Loss: 1.2073 (1.2671)  Acc@1: 68.7500 (64.8104)  Acc@5: 93.7500 (90.9953)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 220/1627]  eta: 0:05:12  Loss: 1.2073 (1.2706)  Acc@1: 68.7500 (64.7907)  Acc@5: 93.7500 (90.8937)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 230/1627]  eta: 0:05:10  Loss: 1.2077 (1.2646)  Acc@1: 68.7500 (65.0974)  Acc@5: 93.7500 (90.9632)  time: 0.2187  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 240/1627]  eta: 0:05:07  Loss: 1.1123 (1.2587)  Acc@1: 68.7500 (65.1971)  Acc@5: 93.7500 (91.0529)  time: 0.2174  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 250/1627]  eta: 0:05:05  Loss: 1.0745 (1.2603)  Acc@1: 68.7500 (65.2639)  Acc@5: 93.7500 (91.0359)  time: 0.2190  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 260/1627]  eta: 0:05:03  Loss: 1.1975 (1.2611)  Acc@1: 62.5000 (65.2299)  Acc@5: 93.7500 (91.0920)  time: 0.2195  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 270/1627]  eta: 0:05:00  Loss: 1.1636 (1.2538)  Acc@1: 62.5000 (65.2906)  Acc@5: 93.7500 (91.2362)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 280/1627]  eta: 0:04:58  Loss: 1.1085 (1.2537)  Acc@1: 62.5000 (65.2802)  Acc@5: 93.7500 (91.1477)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 290/1627]  eta: 0:04:55  Loss: 1.2108 (1.2530)  Acc@1: 62.5000 (65.3780)  Acc@5: 87.5000 (91.1082)  time: 0.2178  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 300/1627]  eta: 0:04:53  Loss: 1.1839 (1.2521)  Acc@1: 68.7500 (65.4900)  Acc@5: 93.7500 (91.1337)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 310/1627]  eta: 0:04:51  Loss: 1.1748 (1.2542)  Acc@1: 62.5000 (65.3738)  Acc@5: 93.7500 (91.1375)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 320/1627]  eta: 0:04:48  Loss: 1.2232 (1.2544)  Acc@1: 62.5000 (65.2648)  Acc@5: 93.7500 (91.2188)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 330/1627]  eta: 0:04:46  Loss: 1.2169 (1.2526)  Acc@1: 62.5000 (65.2946)  Acc@5: 93.7500 (91.2198)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 340/1627]  eta: 0:04:44  Loss: 1.0444 (1.2524)  Acc@1: 68.7500 (65.3043)  Acc@5: 93.7500 (91.2757)  time: 0.2187  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 350/1627]  eta: 0:04:42  Loss: 1.1215 (1.2546)  Acc@1: 68.7500 (65.4024)  Acc@5: 93.7500 (91.1859)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 360/1627]  eta: 0:04:39  Loss: 1.1215 (1.2521)  Acc@1: 68.7500 (65.4605)  Acc@5: 87.5000 (91.1530)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 370/1627]  eta: 0:04:37  Loss: 1.0993 (1.2518)  Acc@1: 56.2500 (65.3133)  Acc@5: 93.7500 (91.2062)  time: 0.2198  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 380/1627]  eta: 0:04:35  Loss: 1.1211 (1.2506)  Acc@1: 68.7500 (65.4528)  Acc@5: 93.7500 (91.1745)  time: 0.2219  data: 0.0022  max mem: 2503
Test: [Task 1]  [ 390/1627]  eta: 0:04:33  Loss: 1.1272 (1.2517)  Acc@1: 68.7500 (65.4891)  Acc@5: 87.5000 (91.1125)  time: 0.2218  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 400/1627]  eta: 0:04:30  Loss: 1.1272 (1.2524)  Acc@1: 68.7500 (65.4302)  Acc@5: 87.5000 (91.1160)  time: 0.2203  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 410/1627]  eta: 0:04:28  Loss: 1.0822 (1.2516)  Acc@1: 68.7500 (65.5262)  Acc@5: 87.5000 (91.0888)  time: 0.2208  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 420/1627]  eta: 0:04:26  Loss: 1.2039 (1.2506)  Acc@1: 68.7500 (65.5137)  Acc@5: 93.7500 (91.1075)  time: 0.2207  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 430/1627]  eta: 0:04:24  Loss: 1.1026 (1.2487)  Acc@1: 68.7500 (65.5162)  Acc@5: 93.7500 (91.1978)  time: 0.2198  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 440/1627]  eta: 0:04:22  Loss: 1.2958 (1.2492)  Acc@1: 62.5000 (65.5045)  Acc@5: 93.7500 (91.1848)  time: 0.2199  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 450/1627]  eta: 0:04:19  Loss: 1.3228 (1.2535)  Acc@1: 56.2500 (65.2716)  Acc@5: 87.5000 (91.0754)  time: 0.2204  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 460/1627]  eta: 0:04:17  Loss: 1.3102 (1.2535)  Acc@1: 56.2500 (65.2793)  Acc@5: 87.5000 (91.1063)  time: 0.2208  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 470/1627]  eta: 0:04:15  Loss: 1.1782 (1.2520)  Acc@1: 62.5000 (65.2468)  Acc@5: 93.7500 (91.1226)  time: 0.2224  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 480/1627]  eta: 0:04:13  Loss: 1.2904 (1.2564)  Acc@1: 62.5000 (65.1117)  Acc@5: 87.5000 (91.0213)  time: 0.2224  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 490/1627]  eta: 0:04:11  Loss: 1.2904 (1.2568)  Acc@1: 56.2500 (65.0967)  Acc@5: 87.5000 (91.0514)  time: 0.2204  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 500/1627]  eta: 0:04:08  Loss: 1.2155 (1.2581)  Acc@1: 68.7500 (65.0948)  Acc@5: 93.7500 (91.0180)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 510/1627]  eta: 0:04:06  Loss: 1.3407 (1.2646)  Acc@1: 56.2500 (64.9217)  Acc@5: 87.5000 (90.9980)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 520/1627]  eta: 0:04:04  Loss: 1.4259 (1.2721)  Acc@1: 56.2500 (64.8153)  Acc@5: 87.5000 (90.9309)  time: 0.2217  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 530/1627]  eta: 0:04:02  Loss: 1.2451 (1.2681)  Acc@1: 62.5000 (64.9600)  Acc@5: 87.5000 (90.9487)  time: 0.2235  data: 0.0014  max mem: 2503
Test: [Task 1]  [ 540/1627]  eta: 0:04:00  Loss: 1.2022 (1.2688)  Acc@1: 68.7500 (64.9838)  Acc@5: 87.5000 (90.9311)  time: 0.2234  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 550/1627]  eta: 0:03:57  Loss: 1.3778 (1.2719)  Acc@1: 62.5000 (64.8593)  Acc@5: 87.5000 (90.8916)  time: 0.2215  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 560/1627]  eta: 0:03:55  Loss: 1.4095 (1.2746)  Acc@1: 56.2500 (64.7504)  Acc@5: 87.5000 (90.8534)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 570/1627]  eta: 0:03:53  Loss: 1.2137 (1.2716)  Acc@1: 68.7500 (64.8533)  Acc@5: 87.5000 (90.8603)  time: 0.2207  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 580/1627]  eta: 0:03:51  Loss: 1.1683 (1.2722)  Acc@1: 68.7500 (64.8128)  Acc@5: 93.7500 (90.8563)  time: 0.2206  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 590/1627]  eta: 0:03:49  Loss: 1.2776 (1.2717)  Acc@1: 62.5000 (64.8371)  Acc@5: 93.7500 (90.9158)  time: 0.2216  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 600/1627]  eta: 0:03:47  Loss: 1.2914 (1.2738)  Acc@1: 62.5000 (64.7775)  Acc@5: 93.7500 (90.8798)  time: 0.2275  data: 0.0018  max mem: 2503
Test: [Task 1]  [ 610/1627]  eta: 0:03:44  Loss: 1.2733 (1.2714)  Acc@1: 62.5000 (64.8527)  Acc@5: 93.7500 (90.8858)  time: 0.2268  data: 0.0029  max mem: 2503
Test: [Task 1]  [ 620/1627]  eta: 0:03:42  Loss: 1.2260 (1.2729)  Acc@1: 68.7500 (64.8148)  Acc@5: 93.7500 (90.8313)  time: 0.2214  data: 0.0020  max mem: 2503
Test: [Task 1]  [ 630/1627]  eta: 0:03:40  Loss: 1.1399 (1.2722)  Acc@1: 68.7500 (64.9465)  Acc@5: 87.5000 (90.8281)  time: 0.2200  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 640/1627]  eta: 0:03:38  Loss: 1.0851 (1.2716)  Acc@1: 75.0000 (64.9961)  Acc@5: 93.7500 (90.8151)  time: 0.2199  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 650/1627]  eta: 0:03:35  Loss: 1.1359 (1.2708)  Acc@1: 68.7500 (65.0442)  Acc@5: 93.7500 (90.8218)  time: 0.2205  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 660/1627]  eta: 0:03:33  Loss: 1.1569 (1.2690)  Acc@1: 68.7500 (65.1002)  Acc@5: 93.7500 (90.8188)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 670/1627]  eta: 0:03:31  Loss: 1.2207 (1.2689)  Acc@1: 62.5000 (65.0894)  Acc@5: 87.5000 (90.7880)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 680/1627]  eta: 0:03:29  Loss: 1.2207 (1.2682)  Acc@1: 68.7500 (65.1523)  Acc@5: 87.5000 (90.7764)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 690/1627]  eta: 0:03:27  Loss: 1.2255 (1.2666)  Acc@1: 68.7500 (65.1592)  Acc@5: 93.7500 (90.8195)  time: 0.2213  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 700/1627]  eta: 0:03:24  Loss: 1.2485 (1.2658)  Acc@1: 68.7500 (65.2461)  Acc@5: 93.7500 (90.8613)  time: 0.2208  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 710/1627]  eta: 0:03:22  Loss: 1.1108 (1.2633)  Acc@1: 68.7500 (65.3481)  Acc@5: 93.7500 (90.9107)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 720/1627]  eta: 0:03:20  Loss: 1.0450 (1.2623)  Acc@1: 68.7500 (65.3519)  Acc@5: 93.7500 (90.9154)  time: 0.2205  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 730/1627]  eta: 0:03:18  Loss: 1.2062 (1.2630)  Acc@1: 68.7500 (65.3471)  Acc@5: 93.7500 (90.9029)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 740/1627]  eta: 0:03:15  Loss: 1.2743 (1.2634)  Acc@1: 68.7500 (65.3593)  Acc@5: 93.7500 (90.9076)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 750/1627]  eta: 0:03:13  Loss: 1.2078 (1.2624)  Acc@1: 68.7500 (65.4294)  Acc@5: 93.7500 (90.9204)  time: 0.2205  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 760/1627]  eta: 0:03:11  Loss: 1.2078 (1.2655)  Acc@1: 62.5000 (65.3334)  Acc@5: 93.7500 (90.8673)  time: 0.2204  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 770/1627]  eta: 0:03:09  Loss: 1.0630 (1.2617)  Acc@1: 75.0000 (65.4831)  Acc@5: 93.7500 (90.9290)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 780/1627]  eta: 0:03:07  Loss: 1.0331 (1.2598)  Acc@1: 75.0000 (65.5810)  Acc@5: 93.7500 (90.9571)  time: 0.2201  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 790/1627]  eta: 0:03:04  Loss: 1.0931 (1.2618)  Acc@1: 68.7500 (65.5973)  Acc@5: 93.7500 (90.8897)  time: 0.2202  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 800/1627]  eta: 0:03:02  Loss: 1.1741 (1.2599)  Acc@1: 68.7500 (65.6445)  Acc@5: 87.5000 (90.9098)  time: 0.2201  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 810/1627]  eta: 0:03:00  Loss: 1.1342 (1.2593)  Acc@1: 68.7500 (65.6674)  Acc@5: 93.7500 (90.9525)  time: 0.2220  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 820/1627]  eta: 0:02:58  Loss: 1.1015 (1.2582)  Acc@1: 68.7500 (65.6897)  Acc@5: 93.7500 (90.9638)  time: 0.2240  data: 0.0020  max mem: 2503
Test: [Task 1]  [ 830/1627]  eta: 0:02:56  Loss: 1.1005 (1.2572)  Acc@1: 68.7500 (65.7040)  Acc@5: 93.7500 (90.9898)  time: 0.2230  data: 0.0018  max mem: 2503
Test: [Task 1]  [ 840/1627]  eta: 0:02:53  Loss: 1.0032 (1.2543)  Acc@1: 75.0000 (65.7848)  Acc@5: 93.7500 (91.0300)  time: 0.2218  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 850/1627]  eta: 0:02:51  Loss: 1.2569 (1.2556)  Acc@1: 62.5000 (65.7168)  Acc@5: 93.7500 (91.0179)  time: 0.2213  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 860/1627]  eta: 0:02:49  Loss: 1.1784 (1.2547)  Acc@1: 62.5000 (65.7012)  Acc@5: 93.7500 (91.0424)  time: 0.2210  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 870/1627]  eta: 0:02:47  Loss: 1.1024 (1.2532)  Acc@1: 62.5000 (65.7434)  Acc@5: 93.7500 (91.0448)  time: 0.2217  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 880/1627]  eta: 0:02:45  Loss: 1.3311 (1.2556)  Acc@1: 62.5000 (65.6782)  Acc@5: 93.7500 (91.0542)  time: 0.2210  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 890/1627]  eta: 0:02:42  Loss: 1.3311 (1.2578)  Acc@1: 62.5000 (65.6566)  Acc@5: 93.7500 (91.0213)  time: 0.2222  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 900/1627]  eta: 0:02:40  Loss: 1.3172 (1.2576)  Acc@1: 62.5000 (65.6770)  Acc@5: 93.7500 (91.0031)  time: 0.2221  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 910/1627]  eta: 0:02:38  Loss: 1.3201 (1.2589)  Acc@1: 62.5000 (65.6696)  Acc@5: 87.5000 (90.9440)  time: 0.2207  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 920/1627]  eta: 0:02:36  Loss: 1.2725 (1.2590)  Acc@1: 62.5000 (65.6691)  Acc@5: 87.5000 (90.9406)  time: 0.2218  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 930/1627]  eta: 0:02:34  Loss: 1.1999 (1.2598)  Acc@1: 68.7500 (65.6888)  Acc@5: 87.5000 (90.9237)  time: 0.2203  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 940/1627]  eta: 0:02:31  Loss: 1.2264 (1.2585)  Acc@1: 68.7500 (65.7080)  Acc@5: 93.7500 (90.9604)  time: 0.2210  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 950/1627]  eta: 0:02:29  Loss: 1.2644 (1.2600)  Acc@1: 62.5000 (65.6151)  Acc@5: 93.7500 (90.9766)  time: 0.2214  data: 0.0014  max mem: 2503
Test: [Task 1]  [ 960/1627]  eta: 0:02:27  Loss: 1.2928 (1.2595)  Acc@1: 62.5000 (65.5827)  Acc@5: 93.7500 (90.9664)  time: 0.2191  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 970/1627]  eta: 0:02:25  Loss: 1.1206 (1.2588)  Acc@1: 62.5000 (65.6089)  Acc@5: 87.5000 (90.9436)  time: 0.2218  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 980/1627]  eta: 0:02:23  Loss: 1.1972 (1.2587)  Acc@1: 62.5000 (65.6027)  Acc@5: 87.5000 (90.9531)  time: 0.2231  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 990/1627]  eta: 0:02:20  Loss: 1.3415 (1.2618)  Acc@1: 62.5000 (65.5525)  Acc@5: 87.5000 (90.9120)  time: 0.2206  data: 0.0008  max mem: 2503
Test: [Task 1]  [1000/1627]  eta: 0:02:18  Loss: 1.4147 (1.2620)  Acc@1: 62.5000 (65.5719)  Acc@5: 87.5000 (90.8716)  time: 0.2200  data: 0.0008  max mem: 2503
Test: [Task 1]  [1010/1627]  eta: 0:02:16  Loss: 1.2254 (1.2616)  Acc@1: 68.7500 (65.5910)  Acc@5: 87.5000 (90.8754)  time: 0.2221  data: 0.0017  max mem: 2503
Test: [Task 1]  [1020/1627]  eta: 0:02:14  Loss: 1.1961 (1.2610)  Acc@1: 68.7500 (65.6158)  Acc@5: 93.7500 (90.8974)  time: 0.2230  data: 0.0028  max mem: 2503
Test: [Task 1]  [1030/1627]  eta: 0:02:11  Loss: 1.0119 (1.2591)  Acc@1: 75.0000 (65.6583)  Acc@5: 93.7500 (90.9311)  time: 0.2201  data: 0.0017  max mem: 2503
Test: [Task 1]  [1040/1627]  eta: 0:02:09  Loss: 0.9761 (1.2570)  Acc@1: 68.7500 (65.7241)  Acc@5: 93.7500 (90.9702)  time: 0.2186  data: 0.0005  max mem: 2503
Test: [Task 1]  [1050/1627]  eta: 0:02:07  Loss: 1.0974 (1.2554)  Acc@1: 75.0000 (65.8064)  Acc@5: 93.7500 (90.9848)  time: 0.2188  data: 0.0009  max mem: 2503
Test: [Task 1]  [1060/1627]  eta: 0:02:05  Loss: 1.2390 (1.2559)  Acc@1: 68.7500 (65.7988)  Acc@5: 93.7500 (90.9755)  time: 0.2192  data: 0.0010  max mem: 2503
Test: [Task 1]  [1070/1627]  eta: 0:02:03  Loss: 1.2669 (1.2564)  Acc@1: 68.7500 (65.8088)  Acc@5: 93.7500 (90.9664)  time: 0.2198  data: 0.0009  max mem: 2503
Test: [Task 1]  [1080/1627]  eta: 0:02:00  Loss: 1.2443 (1.2571)  Acc@1: 68.7500 (65.8302)  Acc@5: 93.7500 (90.9632)  time: 0.2205  data: 0.0016  max mem: 2503
Test: [Task 1]  [1090/1627]  eta: 0:01:58  Loss: 1.3070 (1.2572)  Acc@1: 68.7500 (65.8284)  Acc@5: 93.7500 (90.9830)  time: 0.2198  data: 0.0014  max mem: 2503
Test: [Task 1]  [1100/1627]  eta: 0:01:56  Loss: 1.0874 (1.2552)  Acc@1: 68.7500 (65.8833)  Acc@5: 93.7500 (91.0139)  time: 0.2183  data: 0.0005  max mem: 2503
Test: [Task 1]  [1110/1627]  eta: 0:01:54  Loss: 1.1241 (1.2556)  Acc@1: 68.7500 (65.8641)  Acc@5: 93.7500 (91.0160)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 1.2516 (1.2573)  Acc@1: 62.5000 (65.8062)  Acc@5: 93.7500 (91.0069)  time: 0.2185  data: 0.0006  max mem: 2503
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 1.2567 (1.2583)  Acc@1: 62.5000 (65.7604)  Acc@5: 87.5000 (90.9925)  time: 0.2178  data: 0.0006  max mem: 2503
Test: [Task 1]  [1140/1627]  eta: 0:01:47  Loss: 1.2567 (1.2592)  Acc@1: 62.5000 (65.7428)  Acc@5: 87.5000 (90.9674)  time: 0.2181  data: 0.0006  max mem: 2503
Test: [Task 1]  [1150/1627]  eta: 0:01:45  Loss: 1.4088 (1.2597)  Acc@1: 62.5000 (65.7417)  Acc@5: 87.5000 (90.9535)  time: 0.2188  data: 0.0008  max mem: 2503
Test: [Task 1]  [1160/1627]  eta: 0:01:43  Loss: 1.2013 (1.2586)  Acc@1: 68.7500 (65.7784)  Acc@5: 93.7500 (90.9615)  time: 0.2180  data: 0.0006  max mem: 2503
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 1.1739 (1.2576)  Acc@1: 68.7500 (65.8038)  Acc@5: 93.7500 (90.9853)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 1.2462 (1.2581)  Acc@1: 68.7500 (65.8287)  Acc@5: 93.7500 (90.9928)  time: 0.2186  data: 0.0005  max mem: 2503
Test: [Task 1]  [1190/1627]  eta: 0:01:36  Loss: 1.3698 (1.2588)  Acc@1: 62.5000 (65.8165)  Acc@5: 87.5000 (90.9582)  time: 0.2193  data: 0.0005  max mem: 2503
Test: [Task 1]  [1200/1627]  eta: 0:01:34  Loss: 1.3191 (1.2589)  Acc@1: 62.5000 (65.8201)  Acc@5: 87.5000 (90.9502)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [1210/1627]  eta: 0:01:32  Loss: 1.1166 (1.2599)  Acc@1: 68.7500 (65.7566)  Acc@5: 87.5000 (90.9114)  time: 0.2194  data: 0.0007  max mem: 2503
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 1.1166 (1.2589)  Acc@1: 62.5000 (65.7402)  Acc@5: 93.7500 (90.9347)  time: 0.2197  data: 0.0007  max mem: 2503
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 1.1937 (1.2593)  Acc@1: 62.5000 (65.7240)  Acc@5: 93.7500 (90.9271)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 1]  [1240/1627]  eta: 0:01:25  Loss: 1.2977 (1.2590)  Acc@1: 62.5000 (65.7131)  Acc@5: 93.7500 (90.9196)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [1250/1627]  eta: 0:01:23  Loss: 1.3593 (1.2596)  Acc@1: 62.5000 (65.7224)  Acc@5: 87.5000 (90.9223)  time: 0.2193  data: 0.0005  max mem: 2503
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 1.2805 (1.2596)  Acc@1: 62.5000 (65.6870)  Acc@5: 93.7500 (90.9348)  time: 0.2201  data: 0.0006  max mem: 2503
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 1.2166 (1.2605)  Acc@1: 56.2500 (65.6668)  Acc@5: 93.7500 (90.9127)  time: 0.2197  data: 0.0005  max mem: 2503
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 1.2051 (1.2589)  Acc@1: 68.7500 (65.6909)  Acc@5: 87.5000 (90.9348)  time: 0.2212  data: 0.0011  max mem: 2503
Test: [Task 1]  [1290/1627]  eta: 0:01:14  Loss: 1.1716 (1.2593)  Acc@1: 62.5000 (65.6613)  Acc@5: 87.5000 (90.9421)  time: 0.2231  data: 0.0015  max mem: 2503
Test: [Task 1]  [1300/1627]  eta: 0:01:12  Loss: 1.1716 (1.2588)  Acc@1: 62.5000 (65.6706)  Acc@5: 93.7500 (90.9637)  time: 0.2243  data: 0.0017  max mem: 2503
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 1.0496 (1.2577)  Acc@1: 68.7500 (65.7275)  Acc@5: 93.7500 (90.9802)  time: 0.2242  data: 0.0014  max mem: 2503
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 0.9995 (1.2561)  Acc@1: 75.0000 (65.8072)  Acc@5: 93.7500 (90.9964)  time: 0.2219  data: 0.0007  max mem: 2503
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 1.0313 (1.2558)  Acc@1: 68.7500 (65.8058)  Acc@5: 93.7500 (90.9936)  time: 0.2228  data: 0.0013  max mem: 2503
Test: [Task 1]  [1340/1627]  eta: 0:01:03  Loss: 1.1409 (1.2560)  Acc@1: 68.7500 (65.8184)  Acc@5: 93.7500 (90.9955)  time: 0.2238  data: 0.0020  max mem: 2503
Test: [Task 1]  [1350/1627]  eta: 0:01:01  Loss: 1.1035 (1.2554)  Acc@1: 68.7500 (65.8309)  Acc@5: 93.7500 (91.0113)  time: 0.2215  data: 0.0014  max mem: 2503
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 1.1339 (1.2550)  Acc@1: 68.7500 (65.8294)  Acc@5: 93.7500 (91.0268)  time: 0.2211  data: 0.0005  max mem: 2503
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 1.1339 (1.2541)  Acc@1: 68.7500 (65.8142)  Acc@5: 93.7500 (91.0421)  time: 0.2226  data: 0.0006  max mem: 2503
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 1.1553 (1.2543)  Acc@1: 62.5000 (65.7857)  Acc@5: 93.7500 (91.0436)  time: 0.2211  data: 0.0006  max mem: 2503
Test: [Task 1]  [1390/1627]  eta: 0:00:52  Loss: 1.3030 (1.2539)  Acc@1: 62.5000 (65.7980)  Acc@5: 93.7500 (91.0496)  time: 0.2201  data: 0.0009  max mem: 2503
Test: [Task 1]  [1400/1627]  eta: 0:00:50  Loss: 1.1657 (1.2541)  Acc@1: 62.5000 (65.8146)  Acc@5: 93.7500 (91.0421)  time: 0.2202  data: 0.0010  max mem: 2503
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 1.1524 (1.2536)  Acc@1: 75.0000 (65.8443)  Acc@5: 93.7500 (91.0613)  time: 0.2202  data: 0.0005  max mem: 2503
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.2292 (1.2529)  Acc@1: 68.7500 (65.8471)  Acc@5: 93.7500 (91.0846)  time: 0.2210  data: 0.0008  max mem: 2503
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.3550 (1.2547)  Acc@1: 62.5000 (65.8325)  Acc@5: 93.7500 (91.0508)  time: 0.2215  data: 0.0008  max mem: 2503
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 1.2947 (1.2540)  Acc@1: 62.5000 (65.8354)  Acc@5: 93.7500 (91.0522)  time: 0.2227  data: 0.0010  max mem: 2503
Test: [Task 1]  [1450/1627]  eta: 0:00:39  Loss: 1.3350 (1.2557)  Acc@1: 62.5000 (65.7736)  Acc@5: 93.7500 (91.0191)  time: 0.2233  data: 0.0017  max mem: 2503
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.3768 (1.2561)  Acc@1: 62.5000 (65.7640)  Acc@5: 93.7500 (91.0207)  time: 0.2214  data: 0.0014  max mem: 2503
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.2694 (1.2566)  Acc@1: 68.7500 (65.7716)  Acc@5: 93.7500 (91.0180)  time: 0.2196  data: 0.0007  max mem: 2503
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 1.3287 (1.2569)  Acc@1: 68.7500 (65.7790)  Acc@5: 87.5000 (91.0111)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 1.3017 (1.2573)  Acc@1: 62.5000 (65.7570)  Acc@5: 87.5000 (91.0127)  time: 0.2216  data: 0.0004  max mem: 2503
Test: [Task 1]  [1500/1627]  eta: 0:00:28  Loss: 1.2732 (1.2573)  Acc@1: 62.5000 (65.7687)  Acc@5: 87.5000 (91.0018)  time: 0.2225  data: 0.0011  max mem: 2503
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.0880 (1.2571)  Acc@1: 68.7500 (65.7718)  Acc@5: 93.7500 (90.9993)  time: 0.2208  data: 0.0015  max mem: 2503
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.0880 (1.2559)  Acc@1: 68.7500 (65.7996)  Acc@5: 93.7500 (91.0215)  time: 0.2203  data: 0.0008  max mem: 2503
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.0241 (1.2554)  Acc@1: 68.7500 (65.7863)  Acc@5: 93.7500 (91.0353)  time: 0.2197  data: 0.0005  max mem: 2503
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 1.0311 (1.2545)  Acc@1: 68.7500 (65.7974)  Acc@5: 93.7500 (91.0569)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 1]  [1550/1627]  eta: 0:00:17  Loss: 1.0708 (1.2541)  Acc@1: 68.7500 (65.7963)  Acc@5: 93.7500 (91.0662)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 1.0708 (1.2531)  Acc@1: 68.7500 (65.8352)  Acc@5: 93.7500 (91.0754)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.1568 (1.2530)  Acc@1: 68.7500 (65.8418)  Acc@5: 93.7500 (91.0885)  time: 0.2222  data: 0.0012  max mem: 2503
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.1654 (1.2533)  Acc@1: 68.7500 (65.8404)  Acc@5: 93.7500 (91.0855)  time: 0.2224  data: 0.0011  max mem: 2503
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.1796 (1.2531)  Acc@1: 62.5000 (65.8391)  Acc@5: 93.7500 (91.1102)  time: 0.2202  data: 0.0005  max mem: 2503
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.2242 (1.2540)  Acc@1: 62.5000 (65.7714)  Acc@5: 93.7500 (91.0915)  time: 0.2212  data: 0.0005  max mem: 2503
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.2825 (1.2533)  Acc@1: 56.2500 (65.7782)  Acc@5: 93.7500 (91.0964)  time: 0.2208  data: 0.0006  max mem: 2503
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.0883 (1.2523)  Acc@1: 68.7500 (65.8159)  Acc@5: 93.7500 (91.1089)  time: 0.2195  data: 0.0005  max mem: 2503
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.1299 (1.2519)  Acc@1: 68.7500 (65.8305)  Acc@5: 93.7500 (91.1071)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 1] Total time: 0:05:59 (0.2210 s / it)
* Acc@1 65.831 Acc@5 91.107 loss 1.252
Test: [Task 2]  [  0/625]  eta: 0:10:24  Loss: 0.2718 (0.2718)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.9989  data: 0.7688  max mem: 2503
Test: [Task 2]  [ 10/625]  eta: 0:02:59  Loss: 0.3988 (0.4040)  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.8636)  time: 0.2916  data: 0.0704  max mem: 2503
Test: [Task 2]  [ 20/625]  eta: 0:02:37  Loss: 0.3669 (0.3840)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (99.4048)  time: 0.2229  data: 0.0025  max mem: 2503
Test: [Task 2]  [ 30/625]  eta: 0:02:26  Loss: 0.3637 (0.4188)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.9919)  time: 0.2220  data: 0.0024  max mem: 2503
Test: [Task 2]  [ 40/625]  eta: 0:02:20  Loss: 0.4301 (0.4184)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.9329)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 2]  [ 50/625]  eta: 0:02:15  Loss: 0.4301 (0.4340)  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (98.8971)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 2]  [ 60/625]  eta: 0:02:11  Loss: 0.4087 (0.4301)  Acc@1: 87.5000 (87.2951)  Acc@5: 100.0000 (98.8730)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 2]  [ 70/625]  eta: 0:02:08  Loss: 0.3886 (0.4256)  Acc@1: 87.5000 (87.2359)  Acc@5: 100.0000 (98.9437)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 2]  [ 80/625]  eta: 0:02:05  Loss: 0.4055 (0.4416)  Acc@1: 81.2500 (86.7284)  Acc@5: 100.0000 (98.6883)  time: 0.2221  data: 0.0010  max mem: 2503
Test: [Task 2]  [ 90/625]  eta: 0:02:02  Loss: 0.3964 (0.4359)  Acc@1: 87.5000 (86.9505)  Acc@5: 100.0000 (98.8324)  time: 0.2243  data: 0.0018  max mem: 2503
Test: [Task 2]  [100/625]  eta: 0:02:00  Loss: 0.3828 (0.4300)  Acc@1: 87.5000 (86.9431)  Acc@5: 100.0000 (98.8861)  time: 0.2226  data: 0.0013  max mem: 2503
Test: [Task 2]  [110/625]  eta: 0:01:57  Loss: 0.3341 (0.4274)  Acc@1: 87.5000 (87.1059)  Acc@5: 100.0000 (98.8739)  time: 0.2204  data: 0.0006  max mem: 2503
Test: [Task 2]  [120/625]  eta: 0:01:54  Loss: 0.3550 (0.4261)  Acc@1: 87.5000 (87.2417)  Acc@5: 100.0000 (98.7603)  time: 0.2205  data: 0.0005  max mem: 2503
Test: [Task 2]  [130/625]  eta: 0:01:52  Loss: 0.4033 (0.4340)  Acc@1: 87.5000 (86.8321)  Acc@5: 100.0000 (98.8550)  time: 0.2198  data: 0.0006  max mem: 2503
Test: [Task 2]  [140/625]  eta: 0:01:49  Loss: 0.3767 (0.4347)  Acc@1: 87.5000 (86.8794)  Acc@5: 100.0000 (98.8475)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 2]  [150/625]  eta: 0:01:47  Loss: 0.3767 (0.4423)  Acc@1: 87.5000 (86.6308)  Acc@5: 100.0000 (98.7997)  time: 0.2186  data: 0.0007  max mem: 2503
Test: [Task 2]  [160/625]  eta: 0:01:44  Loss: 0.4196 (0.4464)  Acc@1: 87.5000 (86.4130)  Acc@5: 100.0000 (98.7189)  time: 0.2210  data: 0.0007  max mem: 2503
Test: [Task 2]  [170/625]  eta: 0:01:42  Loss: 0.3729 (0.4458)  Acc@1: 87.5000 (86.4401)  Acc@5: 100.0000 (98.6842)  time: 0.2220  data: 0.0016  max mem: 2503
Test: [Task 2]  [180/625]  eta: 0:01:40  Loss: 0.3914 (0.4463)  Acc@1: 87.5000 (86.4641)  Acc@5: 100.0000 (98.7224)  time: 0.2201  data: 0.0016  max mem: 2503
Test: [Task 2]  [190/625]  eta: 0:01:37  Loss: 0.3914 (0.4466)  Acc@1: 87.5000 (86.5838)  Acc@5: 100.0000 (98.6584)  time: 0.2194  data: 0.0006  max mem: 2503
Test: [Task 2]  [200/625]  eta: 0:01:35  Loss: 0.3876 (0.4460)  Acc@1: 87.5000 (86.5983)  Acc@5: 100.0000 (98.6940)  time: 0.2194  data: 0.0006  max mem: 2503
Test: [Task 2]  [210/625]  eta: 0:01:33  Loss: 0.4202 (0.4459)  Acc@1: 87.5000 (86.5521)  Acc@5: 100.0000 (98.7263)  time: 0.2188  data: 0.0005  max mem: 2503
Test: [Task 2]  [220/625]  eta: 0:01:30  Loss: 0.3846 (0.4417)  Acc@1: 87.5000 (86.8213)  Acc@5: 100.0000 (98.7274)  time: 0.2194  data: 0.0006  max mem: 2503
Test: [Task 2]  [230/625]  eta: 0:01:28  Loss: 0.3846 (0.4422)  Acc@1: 87.5000 (86.7965)  Acc@5: 100.0000 (98.7284)  time: 0.2194  data: 0.0005  max mem: 2503
Test: [Task 2]  [240/625]  eta: 0:01:26  Loss: 0.4981 (0.4458)  Acc@1: 87.5000 (86.6442)  Acc@5: 100.0000 (98.7293)  time: 0.2185  data: 0.0005  max mem: 2503
Test: [Task 2]  [250/625]  eta: 0:01:23  Loss: 0.4652 (0.4478)  Acc@1: 81.2500 (86.5289)  Acc@5: 100.0000 (98.7052)  time: 0.2182  data: 0.0005  max mem: 2503
Test: [Task 2]  [260/625]  eta: 0:01:21  Loss: 0.4387 (0.4500)  Acc@1: 81.2500 (86.5182)  Acc@5: 100.0000 (98.7308)  time: 0.2180  data: 0.0005  max mem: 2503
Test: [Task 2]  [270/625]  eta: 0:01:19  Loss: 0.4311 (0.4502)  Acc@1: 87.5000 (86.5314)  Acc@5: 100.0000 (98.7315)  time: 0.2174  data: 0.0004  max mem: 2503
Test: [Task 2]  [280/625]  eta: 0:01:16  Loss: 0.4421 (0.4520)  Acc@1: 87.5000 (86.4991)  Acc@5: 100.0000 (98.7100)  time: 0.2174  data: 0.0004  max mem: 2503
Test: [Task 2]  [290/625]  eta: 0:01:14  Loss: 0.4388 (0.4516)  Acc@1: 87.5000 (86.5335)  Acc@5: 100.0000 (98.7113)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 2]  [300/625]  eta: 0:01:12  Loss: 0.4388 (0.4505)  Acc@1: 87.5000 (86.5241)  Acc@5: 100.0000 (98.7542)  time: 0.2174  data: 0.0004  max mem: 2503
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 0.4509 (0.4529)  Acc@1: 81.2500 (86.3344)  Acc@5: 100.0000 (98.7540)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 0.2765 (0.4450)  Acc@1: 93.7500 (86.5849)  Acc@5: 100.0000 (98.7928)  time: 0.2185  data: 0.0005  max mem: 2503
Test: [Task 2]  [330/625]  eta: 0:01:05  Loss: 0.2417 (0.4398)  Acc@1: 93.7500 (86.7447)  Acc@5: 100.0000 (98.8293)  time: 0.2175  data: 0.0004  max mem: 2503
Test: [Task 2]  [340/625]  eta: 0:01:03  Loss: 0.1425 (0.4302)  Acc@1: 93.7500 (87.0968)  Acc@5: 100.0000 (98.8636)  time: 0.2175  data: 0.0004  max mem: 2503
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.1022 (0.4233)  Acc@1: 100.0000 (87.3219)  Acc@5: 100.0000 (98.8960)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 0.2974 (0.4237)  Acc@1: 93.7500 (87.3442)  Acc@5: 100.0000 (98.9093)  time: 0.2178  data: 0.0004  max mem: 2503
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 0.2968 (0.4185)  Acc@1: 93.7500 (87.5168)  Acc@5: 100.0000 (98.9387)  time: 0.2184  data: 0.0005  max mem: 2503
Test: [Task 2]  [380/625]  eta: 0:00:54  Loss: 0.2968 (0.4194)  Acc@1: 93.7500 (87.5328)  Acc@5: 100.0000 (98.8681)  time: 0.2186  data: 0.0005  max mem: 2503
Test: [Task 2]  [390/625]  eta: 0:00:52  Loss: 0.3009 (0.4170)  Acc@1: 93.7500 (87.6279)  Acc@5: 100.0000 (98.8491)  time: 0.2178  data: 0.0004  max mem: 2503
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.1483 (0.4106)  Acc@1: 93.7500 (87.8585)  Acc@5: 100.0000 (98.8778)  time: 0.2174  data: 0.0004  max mem: 2503
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 0.1425 (0.4089)  Acc@1: 93.7500 (87.9410)  Acc@5: 100.0000 (98.8595)  time: 0.2179  data: 0.0004  max mem: 2503
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 0.1984 (0.4100)  Acc@1: 93.7500 (87.8563)  Acc@5: 100.0000 (98.8717)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 2]  [430/625]  eta: 0:00:43  Loss: 0.2804 (0.4077)  Acc@1: 93.7500 (87.9205)  Acc@5: 100.0000 (98.8834)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.1272 (0.4014)  Acc@1: 100.0000 (88.1519)  Acc@5: 100.0000 (98.9087)  time: 0.2207  data: 0.0010  max mem: 2503
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.1312 (0.3962)  Acc@1: 100.0000 (88.3038)  Acc@5: 100.0000 (98.9329)  time: 0.2210  data: 0.0009  max mem: 2503
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 0.1312 (0.3915)  Acc@1: 93.7500 (88.4761)  Acc@5: 100.0000 (98.9561)  time: 0.2234  data: 0.0008  max mem: 2503
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 0.2324 (0.3908)  Acc@1: 93.7500 (88.4289)  Acc@5: 100.0000 (98.9782)  time: 0.2236  data: 0.0008  max mem: 2503
Test: [Task 2]  [480/625]  eta: 0:00:32  Loss: 0.3591 (0.3898)  Acc@1: 87.5000 (88.4226)  Acc@5: 100.0000 (98.9995)  time: 0.2204  data: 0.0013  max mem: 2503
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.2993 (0.3865)  Acc@1: 93.7500 (88.5438)  Acc@5: 100.0000 (99.0199)  time: 0.2195  data: 0.0013  max mem: 2503
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1762 (0.3837)  Acc@1: 93.7500 (88.6602)  Acc@5: 100.0000 (99.0394)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.2548 (0.3840)  Acc@1: 87.5000 (88.6130)  Acc@5: 100.0000 (99.0338)  time: 0.2202  data: 0.0006  max mem: 2503
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 0.4900 (0.3872)  Acc@1: 81.2500 (88.3877)  Acc@5: 100.0000 (99.0523)  time: 0.2223  data: 0.0006  max mem: 2503
Test: [Task 2]  [530/625]  eta: 0:00:21  Loss: 0.3220 (0.3851)  Acc@1: 81.2500 (88.3710)  Acc@5: 100.0000 (99.0702)  time: 0.2210  data: 0.0004  max mem: 2503
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.2713 (0.3827)  Acc@1: 93.7500 (88.4358)  Acc@5: 100.0000 (99.0873)  time: 0.2222  data: 0.0004  max mem: 2503
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.1423 (0.3776)  Acc@1: 93.7500 (88.6116)  Acc@5: 100.0000 (99.1039)  time: 0.2243  data: 0.0005  max mem: 2503
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0754 (0.3729)  Acc@1: 100.0000 (88.7589)  Acc@5: 100.0000 (99.1199)  time: 0.2208  data: 0.0006  max mem: 2503
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 0.1138 (0.3729)  Acc@1: 93.7500 (88.7478)  Acc@5: 100.0000 (99.1353)  time: 0.2183  data: 0.0005  max mem: 2503
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.2301 (0.3697)  Acc@1: 93.7500 (88.8339)  Acc@5: 100.0000 (99.1502)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1896 (0.3679)  Acc@1: 93.7500 (88.8854)  Acc@5: 100.0000 (99.1646)  time: 0.2213  data: 0.0006  max mem: 2503
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.3348 (0.3696)  Acc@1: 87.5000 (88.7583)  Acc@5: 100.0000 (99.1681)  time: 0.2216  data: 0.0006  max mem: 2503
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.5639 (0.3780)  Acc@1: 75.0000 (88.4615)  Acc@5: 100.0000 (99.1305)  time: 0.2202  data: 0.0005  max mem: 2503
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.5146 (0.3788)  Acc@1: 81.2500 (88.4259)  Acc@5: 100.0000 (99.1345)  time: 0.2196  data: 0.0005  max mem: 2503
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.4081 (0.3785)  Acc@1: 87.5000 (88.4300)  Acc@5: 100.0000 (99.1400)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 2] Total time: 0:02:18 (0.2214 s / it)
* Acc@1 88.430 Acc@5 99.140 loss 0.378
Test: [Task 3]  [  0/625]  eta: 0:09:18  Loss: 0.2649 (0.2649)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.8939  data: 0.6764  max mem: 2503
Test: [Task 3]  [ 10/625]  eta: 0:02:53  Loss: 0.2649 (0.2869)  Acc@1: 100.0000 (95.4545)  Acc@5: 100.0000 (98.2955)  time: 0.2824  data: 0.0621  max mem: 2503
Test: [Task 3]  [ 20/625]  eta: 0:02:33  Loss: 0.2361 (0.2866)  Acc@1: 93.7500 (95.2381)  Acc@5: 100.0000 (98.5119)  time: 0.2223  data: 0.0025  max mem: 2503
Test: [Task 3]  [ 30/625]  eta: 0:02:24  Loss: 0.2333 (0.2795)  Acc@1: 93.7500 (95.3629)  Acc@5: 100.0000 (98.7903)  time: 0.2210  data: 0.0023  max mem: 2503
Test: [Task 3]  [ 40/625]  eta: 0:02:18  Loss: 0.1695 (0.2482)  Acc@1: 100.0000 (96.0366)  Acc@5: 100.0000 (99.0854)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 50/625]  eta: 0:02:14  Loss: 0.1417 (0.2425)  Acc@1: 100.0000 (96.3235)  Acc@5: 100.0000 (99.0196)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 60/625]  eta: 0:02:10  Loss: 0.2167 (0.2357)  Acc@1: 100.0000 (96.6189)  Acc@5: 100.0000 (99.1803)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 70/625]  eta: 0:02:07  Loss: 0.1631 (0.2232)  Acc@1: 100.0000 (96.8310)  Acc@5: 100.0000 (99.2077)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 80/625]  eta: 0:02:04  Loss: 0.1520 (0.2269)  Acc@1: 100.0000 (96.7593)  Acc@5: 100.0000 (99.2284)  time: 0.2196  data: 0.0007  max mem: 2503
Test: [Task 3]  [ 90/625]  eta: 0:02:01  Loss: 0.1925 (0.2274)  Acc@1: 100.0000 (96.7033)  Acc@5: 100.0000 (99.2445)  time: 0.2194  data: 0.0007  max mem: 2503
Test: [Task 3]  [100/625]  eta: 0:01:59  Loss: 0.1821 (0.2228)  Acc@1: 100.0000 (96.9059)  Acc@5: 100.0000 (99.3193)  time: 0.2210  data: 0.0013  max mem: 2503
Test: [Task 3]  [110/625]  eta: 0:01:56  Loss: 0.1802 (0.2173)  Acc@1: 100.0000 (97.1284)  Acc@5: 100.0000 (99.3806)  time: 0.2215  data: 0.0014  max mem: 2503
Test: [Task 3]  [120/625]  eta: 0:01:53  Loss: 0.1936 (0.2193)  Acc@1: 100.0000 (97.0041)  Acc@5: 100.0000 (99.4318)  time: 0.2197  data: 0.0006  max mem: 2503
Test: [Task 3]  [130/625]  eta: 0:01:51  Loss: 0.1957 (0.2185)  Acc@1: 100.0000 (97.0897)  Acc@5: 100.0000 (99.4275)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 3]  [140/625]  eta: 0:01:48  Loss: 0.1959 (0.2240)  Acc@1: 100.0000 (96.8972)  Acc@5: 100.0000 (99.2908)  time: 0.2181  data: 0.0004  max mem: 2503
Test: [Task 3]  [150/625]  eta: 0:01:46  Loss: 0.2325 (0.2273)  Acc@1: 93.7500 (96.7715)  Acc@5: 100.0000 (99.2964)  time: 0.2193  data: 0.0005  max mem: 2503
Test: [Task 3]  [160/625]  eta: 0:01:44  Loss: 0.1862 (0.2292)  Acc@1: 93.7500 (96.7003)  Acc@5: 100.0000 (99.2624)  time: 0.2232  data: 0.0014  max mem: 2503
Test: [Task 3]  [170/625]  eta: 0:01:42  Loss: 0.1624 (0.2284)  Acc@1: 100.0000 (96.7105)  Acc@5: 100.0000 (99.3056)  time: 0.2229  data: 0.0014  max mem: 2503
Test: [Task 3]  [180/625]  eta: 0:01:39  Loss: 0.2652 (0.2326)  Acc@1: 93.7500 (96.6160)  Acc@5: 100.0000 (99.2403)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 3]  [190/625]  eta: 0:01:37  Loss: 0.2012 (0.2308)  Acc@1: 93.7500 (96.5969)  Acc@5: 100.0000 (99.2474)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [200/625]  eta: 0:01:34  Loss: 0.2175 (0.2350)  Acc@1: 93.7500 (96.4863)  Acc@5: 100.0000 (99.2537)  time: 0.2196  data: 0.0005  max mem: 2503
Test: [Task 3]  [210/625]  eta: 0:01:32  Loss: 0.2126 (0.2369)  Acc@1: 93.7500 (96.4159)  Acc@5: 100.0000 (99.2002)  time: 0.2189  data: 0.0005  max mem: 2503
Test: [Task 3]  [220/625]  eta: 0:01:30  Loss: 0.1834 (0.2382)  Acc@1: 100.0000 (96.3801)  Acc@5: 100.0000 (99.2081)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 3]  [230/625]  eta: 0:01:28  Loss: 0.1976 (0.2379)  Acc@1: 100.0000 (96.4015)  Acc@5: 100.0000 (99.2154)  time: 0.2207  data: 0.0006  max mem: 2503
Test: [Task 3]  [240/625]  eta: 0:01:25  Loss: 0.1814 (0.2398)  Acc@1: 93.7500 (96.3434)  Acc@5: 100.0000 (99.1961)  time: 0.2207  data: 0.0007  max mem: 2503
Test: [Task 3]  [250/625]  eta: 0:01:23  Loss: 0.1814 (0.2379)  Acc@1: 93.7500 (96.3396)  Acc@5: 100.0000 (99.2281)  time: 0.2194  data: 0.0005  max mem: 2503
Test: [Task 3]  [260/625]  eta: 0:01:21  Loss: 0.1655 (0.2357)  Acc@1: 100.0000 (96.4080)  Acc@5: 100.0000 (99.2337)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.1475 (0.2350)  Acc@1: 100.0000 (96.3792)  Acc@5: 100.0000 (99.2389)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 3]  [280/625]  eta: 0:01:16  Loss: 0.2000 (0.2340)  Acc@1: 100.0000 (96.3968)  Acc@5: 100.0000 (99.2438)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 3]  [290/625]  eta: 0:01:14  Loss: 0.2000 (0.2350)  Acc@1: 93.7500 (96.3703)  Acc@5: 100.0000 (99.2483)  time: 0.2204  data: 0.0011  max mem: 2503
Test: [Task 3]  [300/625]  eta: 0:01:12  Loss: 0.1963 (0.2396)  Acc@1: 100.0000 (96.2417)  Acc@5: 100.0000 (99.1694)  time: 0.2213  data: 0.0012  max mem: 2503
Test: [Task 3]  [310/625]  eta: 0:01:10  Loss: 0.1654 (0.2416)  Acc@1: 100.0000 (96.2018)  Acc@5: 100.0000 (99.1158)  time: 0.2236  data: 0.0017  max mem: 2503
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.1953 (0.2409)  Acc@1: 93.7500 (96.2227)  Acc@5: 100.0000 (99.1044)  time: 0.2230  data: 0.0016  max mem: 2503
Test: [Task 3]  [330/625]  eta: 0:01:05  Loss: 0.2106 (0.2416)  Acc@1: 93.7500 (96.1858)  Acc@5: 100.0000 (99.1125)  time: 0.2198  data: 0.0007  max mem: 2503
Test: [Task 3]  [340/625]  eta: 0:01:03  Loss: 0.1780 (0.2398)  Acc@1: 100.0000 (96.2427)  Acc@5: 100.0000 (99.1202)  time: 0.2211  data: 0.0019  max mem: 2503
Test: [Task 3]  [350/625]  eta: 0:01:01  Loss: 0.1645 (0.2403)  Acc@1: 100.0000 (96.2251)  Acc@5: 100.0000 (99.1097)  time: 0.2208  data: 0.0023  max mem: 2503
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.2210 (0.2409)  Acc@1: 93.7500 (96.1738)  Acc@5: 100.0000 (99.1170)  time: 0.2192  data: 0.0009  max mem: 2503
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.2213 (0.2418)  Acc@1: 93.7500 (96.1253)  Acc@5: 100.0000 (99.1071)  time: 0.2205  data: 0.0011  max mem: 2503
Test: [Task 3]  [380/625]  eta: 0:00:54  Loss: 0.2213 (0.2403)  Acc@1: 93.7500 (96.1614)  Acc@5: 100.0000 (99.1306)  time: 0.2229  data: 0.0025  max mem: 2503
Test: [Task 3]  [390/625]  eta: 0:00:52  Loss: 0.1777 (0.2412)  Acc@1: 100.0000 (96.1157)  Acc@5: 100.0000 (99.1208)  time: 0.2231  data: 0.0020  max mem: 2503
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.1831 (0.2404)  Acc@1: 100.0000 (96.1191)  Acc@5: 100.0000 (99.1272)  time: 0.2217  data: 0.0012  max mem: 2503
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.2006 (0.2411)  Acc@1: 100.0000 (96.1071)  Acc@5: 100.0000 (99.1332)  time: 0.2219  data: 0.0012  max mem: 2503
Test: [Task 3]  [420/625]  eta: 0:00:45  Loss: 0.2006 (0.2409)  Acc@1: 93.7500 (96.1105)  Acc@5: 100.0000 (99.1390)  time: 0.2216  data: 0.0009  max mem: 2503
Test: [Task 3]  [430/625]  eta: 0:00:43  Loss: 0.1780 (0.2406)  Acc@1: 100.0000 (96.1137)  Acc@5: 100.0000 (99.1299)  time: 0.2218  data: 0.0007  max mem: 2503
Test: [Task 3]  [440/625]  eta: 0:00:41  Loss: 0.1948 (0.2419)  Acc@1: 93.7500 (96.0601)  Acc@5: 100.0000 (99.1213)  time: 0.2217  data: 0.0004  max mem: 2503
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.2159 (0.2418)  Acc@1: 100.0000 (96.0782)  Acc@5: 100.0000 (99.1269)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.1514 (0.2409)  Acc@1: 100.0000 (96.0819)  Acc@5: 100.0000 (99.1323)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.1625 (0.2406)  Acc@1: 93.7500 (96.0456)  Acc@5: 100.0000 (99.1375)  time: 0.2193  data: 0.0005  max mem: 2503
Test: [Task 3]  [480/625]  eta: 0:00:32  Loss: 0.2025 (0.2414)  Acc@1: 93.7500 (96.0499)  Acc@5: 100.0000 (99.1424)  time: 0.2218  data: 0.0006  max mem: 2503
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2165 (0.2415)  Acc@1: 100.0000 (96.0667)  Acc@5: 100.0000 (99.1344)  time: 0.2211  data: 0.0006  max mem: 2503
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2114 (0.2409)  Acc@1: 93.7500 (96.0579)  Acc@5: 100.0000 (99.1517)  time: 0.2187  data: 0.0004  max mem: 2503
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.1599 (0.2403)  Acc@1: 100.0000 (96.0861)  Acc@5: 100.0000 (99.1683)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.2148 (0.2402)  Acc@1: 100.0000 (96.1012)  Acc@5: 100.0000 (99.1843)  time: 0.2198  data: 0.0007  max mem: 2503
Test: [Task 3]  [530/625]  eta: 0:00:21  Loss: 0.2148 (0.2409)  Acc@1: 93.7500 (96.0805)  Acc@5: 100.0000 (99.1879)  time: 0.2200  data: 0.0007  max mem: 2503
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2445 (0.2419)  Acc@1: 93.7500 (96.0605)  Acc@5: 100.0000 (99.1682)  time: 0.2199  data: 0.0005  max mem: 2503
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2078 (0.2427)  Acc@1: 100.0000 (96.0753)  Acc@5: 100.0000 (99.1493)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2175 (0.2427)  Acc@1: 100.0000 (96.0784)  Acc@5: 100.0000 (99.1533)  time: 0.2201  data: 0.0014  max mem: 2503
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.2175 (0.2420)  Acc@1: 93.7500 (96.1033)  Acc@5: 100.0000 (99.1572)  time: 0.2198  data: 0.0014  max mem: 2503
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.1790 (0.2432)  Acc@1: 93.7500 (96.0413)  Acc@5: 100.0000 (99.1609)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1856 (0.2425)  Acc@1: 100.0000 (96.0977)  Acc@5: 100.0000 (99.1751)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1869 (0.2421)  Acc@1: 100.0000 (96.1106)  Acc@5: 100.0000 (99.1681)  time: 0.2222  data: 0.0007  max mem: 2503
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.2051 (0.2415)  Acc@1: 100.0000 (96.1334)  Acc@5: 100.0000 (99.1714)  time: 0.2224  data: 0.0007  max mem: 2503
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2149 (0.2424)  Acc@1: 93.7500 (96.1051)  Acc@5: 100.0000 (99.1546)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.2013 (0.2419)  Acc@1: 100.0000 (96.1300)  Acc@5: 100.0000 (99.1600)  time: 0.2207  data: 0.0004  max mem: 2503
Test: [Task 3] Total time: 0:02:18 (0.2219 s / it)
* Acc@1 96.130 Acc@5 99.160 loss 0.242
Test: [Task 4]  [ 0/29]  eta: 0:00:26  Loss: 2.5226 (2.5226)  Acc@1: 18.7500 (18.7500)  Acc@5: 81.2500 (81.2500)  time: 0.9054  data: 0.6806  max mem: 2503
Test: [Task 4]  [10/29]  eta: 0:00:05  Loss: 2.1092 (2.1495)  Acc@1: 50.0000 (44.8864)  Acc@5: 81.2500 (76.7045)  time: 0.2831  data: 0.0629  max mem: 2503
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.9369 (1.9958)  Acc@1: 50.0000 (50.8929)  Acc@5: 81.2500 (78.5714)  time: 0.2206  data: 0.0008  max mem: 2503
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.6204 (1.8306)  Acc@1: 62.5000 (55.5556)  Acc@5: 81.2500 (80.3922)  time: 0.2166  data: 0.0004  max mem: 2503
Test: [Task 4] Total time: 0:00:07 (0.2465 s / it)
* Acc@1 55.556 Acc@5 80.392 loss 1.831
Test: [Task 5]  [  0/625]  eta: 0:07:08  Loss: 0.1860 (0.1860)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6861  data: 0.4642  max mem: 2503
Test: [Task 5]  [ 10/625]  eta: 0:02:40  Loss: 0.3825 (0.4578)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (99.4318)  time: 0.2618  data: 0.0426  max mem: 2503
Test: [Task 5]  [ 20/625]  eta: 0:02:26  Loss: 0.3825 (0.3997)  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (99.4048)  time: 0.2192  data: 0.0005  max mem: 2503
Test: [Task 5]  [ 30/625]  eta: 0:02:19  Loss: 0.4621 (0.4501)  Acc@1: 93.7500 (89.7177)  Acc@5: 100.0000 (98.9919)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 40/625]  eta: 0:02:15  Loss: 0.4927 (0.4372)  Acc@1: 87.5000 (89.9390)  Acc@5: 100.0000 (98.9329)  time: 0.2214  data: 0.0019  max mem: 2503
Test: [Task 5]  [ 50/625]  eta: 0:02:11  Loss: 0.4643 (0.4560)  Acc@1: 87.5000 (89.4608)  Acc@5: 100.0000 (98.4069)  time: 0.2215  data: 0.0019  max mem: 2503
Test: [Task 5]  [ 60/625]  eta: 0:02:08  Loss: 0.4643 (0.4496)  Acc@1: 87.5000 (89.1393)  Acc@5: 100.0000 (98.4631)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 70/625]  eta: 0:02:05  Loss: 0.4062 (0.4528)  Acc@1: 87.5000 (88.8204)  Acc@5: 100.0000 (98.3275)  time: 0.2190  data: 0.0005  max mem: 2503
Test: [Task 5]  [ 80/625]  eta: 0:02:02  Loss: 0.4275 (0.4574)  Acc@1: 81.2500 (88.4259)  Acc@5: 100.0000 (98.2253)  time: 0.2194  data: 0.0005  max mem: 2503
Test: [Task 5]  [ 90/625]  eta: 0:02:00  Loss: 0.3594 (0.4466)  Acc@1: 87.5000 (88.6676)  Acc@5: 100.0000 (98.3516)  time: 0.2196  data: 0.0005  max mem: 2503
Test: [Task 5]  [100/625]  eta: 0:01:58  Loss: 0.3723 (0.4528)  Acc@1: 87.5000 (88.3663)  Acc@5: 100.0000 (98.3911)  time: 0.2237  data: 0.0017  max mem: 2503
Test: [Task 5]  [110/625]  eta: 0:01:55  Loss: 0.4267 (0.4522)  Acc@1: 87.5000 (88.4009)  Acc@5: 100.0000 (98.4797)  time: 0.2231  data: 0.0017  max mem: 2503
Test: [Task 5]  [120/625]  eta: 0:01:53  Loss: 0.3292 (0.4433)  Acc@1: 87.5000 (88.5847)  Acc@5: 100.0000 (98.5021)  time: 0.2196  data: 0.0012  max mem: 2503
Test: [Task 5]  [130/625]  eta: 0:01:50  Loss: 0.4319 (0.4478)  Acc@1: 87.5000 (88.3111)  Acc@5: 100.0000 (98.4256)  time: 0.2216  data: 0.0015  max mem: 2503
Test: [Task 5]  [140/625]  eta: 0:01:48  Loss: 0.5010 (0.4449)  Acc@1: 87.5000 (88.4309)  Acc@5: 100.0000 (98.4043)  time: 0.2208  data: 0.0007  max mem: 2503
Test: [Task 5]  [150/625]  eta: 0:01:46  Loss: 0.4249 (0.4492)  Acc@1: 87.5000 (88.2036)  Acc@5: 100.0000 (98.3858)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [160/625]  eta: 0:01:43  Loss: 0.4720 (0.4539)  Acc@1: 87.5000 (88.0435)  Acc@5: 100.0000 (98.2919)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [170/625]  eta: 0:01:41  Loss: 0.5326 (0.4596)  Acc@1: 87.5000 (87.7558)  Acc@5: 100.0000 (98.3187)  time: 0.2191  data: 0.0009  max mem: 2503
Test: [Task 5]  [180/625]  eta: 0:01:39  Loss: 0.4957 (0.4630)  Acc@1: 87.5000 (87.7417)  Acc@5: 100.0000 (98.2390)  time: 0.2193  data: 0.0009  max mem: 2503
Test: [Task 5]  [190/625]  eta: 0:01:36  Loss: 0.5101 (0.4746)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (98.0366)  time: 0.2193  data: 0.0006  max mem: 2503
Test: [Task 5]  [200/625]  eta: 0:01:34  Loss: 0.4789 (0.4727)  Acc@1: 87.5000 (87.5622)  Acc@5: 100.0000 (98.0100)  time: 0.2186  data: 0.0005  max mem: 2503
Test: [Task 5]  [210/625]  eta: 0:01:32  Loss: 0.4817 (0.4787)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.9562)  time: 0.2198  data: 0.0005  max mem: 2503
Test: [Task 5]  [220/625]  eta: 0:01:30  Loss: 0.5271 (0.4791)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.9638)  time: 0.2216  data: 0.0011  max mem: 2503
Test: [Task 5]  [230/625]  eta: 0:01:27  Loss: 0.4520 (0.4786)  Acc@1: 87.5000 (87.5541)  Acc@5: 100.0000 (97.9708)  time: 0.2197  data: 0.0009  max mem: 2503
Test: [Task 5]  [240/625]  eta: 0:01:25  Loss: 0.3935 (0.4793)  Acc@1: 87.5000 (87.5519)  Acc@5: 100.0000 (98.0031)  time: 0.2181  data: 0.0004  max mem: 2503
Test: [Task 5]  [250/625]  eta: 0:01:23  Loss: 0.5057 (0.4807)  Acc@1: 87.5000 (87.4751)  Acc@5: 100.0000 (97.9582)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 5]  [260/625]  eta: 0:01:20  Loss: 0.5057 (0.4817)  Acc@1: 87.5000 (87.3563)  Acc@5: 100.0000 (97.9167)  time: 0.2210  data: 0.0005  max mem: 2503
Test: [Task 5]  [270/625]  eta: 0:01:18  Loss: 0.4217 (0.4801)  Acc@1: 87.5000 (87.4769)  Acc@5: 100.0000 (97.9013)  time: 0.2214  data: 0.0005  max mem: 2503
Test: [Task 5]  [280/625]  eta: 0:01:16  Loss: 0.3978 (0.4771)  Acc@1: 87.5000 (87.5890)  Acc@5: 100.0000 (97.9537)  time: 0.2189  data: 0.0005  max mem: 2503
Test: [Task 5]  [290/625]  eta: 0:01:14  Loss: 0.4143 (0.4754)  Acc@1: 87.5000 (87.6933)  Acc@5: 100.0000 (97.9596)  time: 0.2185  data: 0.0005  max mem: 2503
Test: [Task 5]  [300/625]  eta: 0:01:11  Loss: 0.4771 (0.4784)  Acc@1: 87.5000 (87.5208)  Acc@5: 100.0000 (97.9444)  time: 0.2181  data: 0.0005  max mem: 2503
Test: [Task 5]  [310/625]  eta: 0:01:09  Loss: 0.5761 (0.4793)  Acc@1: 81.2500 (87.4397)  Acc@5: 100.0000 (97.9502)  time: 0.2186  data: 0.0005  max mem: 2503
Test: [Task 5]  [320/625]  eta: 0:01:07  Loss: 0.5654 (0.4801)  Acc@1: 87.5000 (87.5389)  Acc@5: 100.0000 (97.9945)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [330/625]  eta: 0:01:05  Loss: 0.4270 (0.4791)  Acc@1: 87.5000 (87.5755)  Acc@5: 100.0000 (98.0363)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [340/625]  eta: 0:01:03  Loss: 0.3538 (0.4750)  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.0205)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 5]  [350/625]  eta: 0:01:00  Loss: 0.4427 (0.4807)  Acc@1: 87.5000 (87.5356)  Acc@5: 100.0000 (98.0057)  time: 0.2188  data: 0.0005  max mem: 2503
Test: [Task 5]  [360/625]  eta: 0:00:58  Loss: 0.4546 (0.4789)  Acc@1: 81.2500 (87.5693)  Acc@5: 100.0000 (98.0263)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 5]  [370/625]  eta: 0:00:56  Loss: 0.3533 (0.4770)  Acc@1: 87.5000 (87.6011)  Acc@5: 100.0000 (98.0290)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 5]  [380/625]  eta: 0:00:54  Loss: 0.4255 (0.4783)  Acc@1: 87.5000 (87.5164)  Acc@5: 100.0000 (98.0315)  time: 0.2201  data: 0.0004  max mem: 2503
Test: [Task 5]  [390/625]  eta: 0:00:51  Loss: 0.4911 (0.4793)  Acc@1: 81.2500 (87.4520)  Acc@5: 100.0000 (98.0659)  time: 0.2201  data: 0.0004  max mem: 2503
Test: [Task 5]  [400/625]  eta: 0:00:49  Loss: 0.4314 (0.4782)  Acc@1: 87.5000 (87.4532)  Acc@5: 100.0000 (98.0985)  time: 0.2201  data: 0.0005  max mem: 2503
Test: [Task 5]  [410/625]  eta: 0:00:47  Loss: 0.4869 (0.4793)  Acc@1: 87.5000 (87.4544)  Acc@5: 100.0000 (98.0383)  time: 0.2196  data: 0.0005  max mem: 2503
Test: [Task 5]  [420/625]  eta: 0:00:45  Loss: 0.5318 (0.4805)  Acc@1: 87.5000 (87.3812)  Acc@5: 93.7500 (98.0404)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 5]  [430/625]  eta: 0:00:43  Loss: 0.4222 (0.4787)  Acc@1: 87.5000 (87.4565)  Acc@5: 100.0000 (98.0713)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 5]  [440/625]  eta: 0:00:40  Loss: 0.3903 (0.4784)  Acc@1: 87.5000 (87.4433)  Acc@5: 100.0000 (98.0726)  time: 0.2189  data: 0.0005  max mem: 2503
Test: [Task 5]  [450/625]  eta: 0:00:38  Loss: 0.4338 (0.4776)  Acc@1: 87.5000 (87.4307)  Acc@5: 100.0000 (98.1014)  time: 0.2197  data: 0.0005  max mem: 2503
Test: [Task 5]  [460/625]  eta: 0:00:36  Loss: 0.4269 (0.4769)  Acc@1: 87.5000 (87.4322)  Acc@5: 100.0000 (98.1155)  time: 0.2199  data: 0.0006  max mem: 2503
Test: [Task 5]  [470/625]  eta: 0:00:34  Loss: 0.3968 (0.4735)  Acc@1: 87.5000 (87.5531)  Acc@5: 100.0000 (98.1423)  time: 0.2207  data: 0.0009  max mem: 2503
Test: [Task 5]  [480/625]  eta: 0:00:32  Loss: 0.3828 (0.4732)  Acc@1: 87.5000 (87.5650)  Acc@5: 100.0000 (98.1549)  time: 0.2206  data: 0.0008  max mem: 2503
Test: [Task 5]  [490/625]  eta: 0:00:29  Loss: 0.4028 (0.4729)  Acc@1: 87.5000 (87.5636)  Acc@5: 100.0000 (98.1415)  time: 0.2222  data: 0.0013  max mem: 2503
Test: [Task 5]  [500/625]  eta: 0:00:27  Loss: 0.4530 (0.4733)  Acc@1: 87.5000 (87.5125)  Acc@5: 100.0000 (98.1412)  time: 0.2224  data: 0.0012  max mem: 2503
Test: [Task 5]  [510/625]  eta: 0:00:25  Loss: 0.5293 (0.4741)  Acc@1: 87.5000 (87.5245)  Acc@5: 100.0000 (98.1287)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 5]  [520/625]  eta: 0:00:23  Loss: 0.4809 (0.4733)  Acc@1: 87.5000 (87.5600)  Acc@5: 100.0000 (98.1286)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [530/625]  eta: 0:00:20  Loss: 0.4023 (0.4715)  Acc@1: 87.5000 (87.6177)  Acc@5: 100.0000 (98.1403)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [540/625]  eta: 0:00:18  Loss: 0.3483 (0.4700)  Acc@1: 93.7500 (87.6733)  Acc@5: 100.0000 (98.1400)  time: 0.2205  data: 0.0008  max mem: 2503
Test: [Task 5]  [550/625]  eta: 0:00:16  Loss: 0.3543 (0.4721)  Acc@1: 87.5000 (87.6248)  Acc@5: 100.0000 (98.1171)  time: 0.2210  data: 0.0009  max mem: 2503
Test: [Task 5]  [560/625]  eta: 0:00:14  Loss: 0.4401 (0.4721)  Acc@1: 87.5000 (87.6114)  Acc@5: 100.0000 (98.1283)  time: 0.2204  data: 0.0005  max mem: 2503
Test: [Task 5]  [570/625]  eta: 0:00:12  Loss: 0.3787 (0.4708)  Acc@1: 87.5000 (87.6313)  Acc@5: 100.0000 (98.1502)  time: 0.2205  data: 0.0005  max mem: 2503
Test: [Task 5]  [580/625]  eta: 0:00:09  Loss: 0.4719 (0.4723)  Acc@1: 87.5000 (87.6398)  Acc@5: 100.0000 (98.1390)  time: 0.2204  data: 0.0007  max mem: 2503
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 0.5287 (0.4714)  Acc@1: 87.5000 (87.6692)  Acc@5: 100.0000 (98.1493)  time: 0.2201  data: 0.0006  max mem: 2503
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 0.3654 (0.4699)  Acc@1: 87.5000 (87.7288)  Acc@5: 100.0000 (98.1489)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.3578 (0.4697)  Acc@1: 87.5000 (87.7455)  Acc@5: 100.0000 (98.1485)  time: 0.2203  data: 0.0006  max mem: 2503
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.3473 (0.4679)  Acc@1: 93.7500 (87.8321)  Acc@5: 100.0000 (98.1582)  time: 0.2204  data: 0.0006  max mem: 2503
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.3578 (0.4683)  Acc@1: 87.5000 (87.8100)  Acc@5: 100.0000 (98.1600)  time: 0.2201  data: 0.0004  max mem: 2503
Test: [Task 5] Total time: 0:02:18 (0.2211 s / it)
* Acc@1 87.810 Acc@5 98.160 loss 0.468
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 176, 5: 176, 6: 176, 7: 176, 8: 0, 9: 0, 10: 0, 11: 0, 12: 283, 13: 283, 14: 283, 15: 283, 16: 0, 17: 0, 18: 0, 19: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000}}
[Average accuracy till task5]	Acc@1: 78.7512	Acc@5: 93.5919	Loss: 0.8342	Forgetting: 7.7224	Backward: -7.7224
Total training time: 9:58:21
