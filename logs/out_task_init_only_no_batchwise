/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_task_init_only', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=False, embedding_key='cls', predefined_key='', pull_constraint=False, pull_constraint_coeff=0.0, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=False, train_type='l2p', eval_task_id=False, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=True, prompts_per_task=4, prompts_per_class=1)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 207410
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 2:27:45  Lr: 0.001875  Loss: 2.2939  Acc@1: 12.5000 (12.5000)  Acc@5: 62.5000 (62.5000)  time: 1.9361  data: 0.5214  max mem: 2497
Train: Epoch[1/5]  [  10/4579]  eta: 0:37:04  Lr: 0.001875  Loss: 2.1986  Acc@1: 18.7500 (15.3409)  Acc@5: 50.0000 (56.8182)  time: 0.4869  data: 0.0478  max mem: 2500
Train: Epoch[1/5]  [  20/4579]  eta: 0:31:45  Lr: 0.001875  Loss: 2.4943  Acc@1: 18.7500 (15.4762)  Acc@5: 56.2500 (60.1190)  time: 0.3422  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  30/4579]  eta: 0:29:54  Lr: 0.001875  Loss: 2.0139  Acc@1: 18.7500 (18.1452)  Acc@5: 62.5000 (60.8871)  time: 0.3436  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [  40/4579]  eta: 0:28:52  Lr: 0.001875  Loss: 2.1005  Acc@1: 25.0000 (19.6646)  Acc@5: 68.7500 (63.4146)  time: 0.3436  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [  50/4579]  eta: 0:28:14  Lr: 0.001875  Loss: 2.0157  Acc@1: 25.0000 (20.8333)  Acc@5: 68.7500 (63.2353)  time: 0.3427  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  60/4579]  eta: 0:27:48  Lr: 0.001875  Loss: 2.2753  Acc@1: 31.2500 (22.3361)  Acc@5: 68.7500 (64.7541)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  70/4579]  eta: 0:27:27  Lr: 0.001875  Loss: 2.1136  Acc@1: 31.2500 (23.2394)  Acc@5: 75.0000 (65.4930)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  80/4579]  eta: 0:27:12  Lr: 0.001875  Loss: 2.0463  Acc@1: 31.2500 (24.5370)  Acc@5: 75.0000 (66.6667)  time: 0.3433  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  90/4579]  eta: 0:27:00  Lr: 0.001875  Loss: 2.0901  Acc@1: 31.2500 (24.8626)  Acc@5: 75.0000 (67.7885)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 100/4579]  eta: 0:26:48  Lr: 0.001875  Loss: 2.1191  Acc@1: 31.2500 (25.5569)  Acc@5: 75.0000 (68.3787)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 110/4579]  eta: 0:26:39  Lr: 0.001875  Loss: 1.9102  Acc@1: 31.2500 (26.2950)  Acc@5: 75.0000 (69.1441)  time: 0.3439  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 120/4579]  eta: 0:26:30  Lr: 0.001875  Loss: 1.9250  Acc@1: 31.2500 (26.3946)  Acc@5: 75.0000 (69.3182)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 130/4579]  eta: 0:26:22  Lr: 0.001875  Loss: 1.8910  Acc@1: 31.2500 (26.4790)  Acc@5: 75.0000 (69.6088)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 140/4579]  eta: 0:26:15  Lr: 0.001875  Loss: 2.1764  Acc@1: 31.2500 (26.7730)  Acc@5: 75.0000 (70.0355)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 150/4579]  eta: 0:26:08  Lr: 0.001875  Loss: 1.6347  Acc@1: 31.2500 (27.3179)  Acc@5: 75.0000 (70.9437)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 160/4579]  eta: 0:26:02  Lr: 0.001875  Loss: 2.0611  Acc@1: 31.2500 (27.8339)  Acc@5: 81.2500 (71.3898)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 170/4579]  eta: 0:25:56  Lr: 0.001875  Loss: 2.0465  Acc@1: 31.2500 (27.9605)  Acc@5: 81.2500 (71.9298)  time: 0.3434  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 180/4579]  eta: 0:25:49  Lr: 0.001875  Loss: 2.1023  Acc@1: 31.2500 (28.2113)  Acc@5: 81.2500 (72.2721)  time: 0.3429  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 190/4579]  eta: 0:25:44  Lr: 0.001875  Loss: 1.7596  Acc@1: 37.5000 (28.8285)  Acc@5: 81.2500 (72.9385)  time: 0.3428  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 200/4579]  eta: 0:25:39  Lr: 0.001875  Loss: 2.0180  Acc@1: 37.5000 (29.2600)  Acc@5: 75.0000 (72.9789)  time: 0.3444  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 210/4579]  eta: 0:25:34  Lr: 0.001875  Loss: 1.9108  Acc@1: 37.5000 (29.3543)  Acc@5: 75.0000 (73.2524)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 220/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 1.9344  Acc@1: 37.5000 (29.6380)  Acc@5: 81.2500 (73.6991)  time: 0.3442  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 230/4579]  eta: 0:25:24  Lr: 0.001875  Loss: 1.9005  Acc@1: 31.2500 (29.7348)  Acc@5: 81.2500 (73.9719)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 240/4579]  eta: 0:25:20  Lr: 0.001875  Loss: 2.1825  Acc@1: 31.2500 (29.8496)  Acc@5: 75.0000 (73.9367)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 250/4579]  eta: 0:25:16  Lr: 0.001875  Loss: 1.8376  Acc@1: 31.2500 (29.9552)  Acc@5: 75.0000 (74.1783)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 260/4579]  eta: 0:25:11  Lr: 0.001875  Loss: 2.0819  Acc@1: 31.2500 (29.9808)  Acc@5: 81.2500 (74.5450)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 270/4579]  eta: 0:25:07  Lr: 0.001875  Loss: 1.7577  Acc@1: 31.2500 (30.0507)  Acc@5: 81.2500 (74.6310)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 280/4579]  eta: 0:25:03  Lr: 0.001875  Loss: 1.7926  Acc@1: 31.2500 (30.2491)  Acc@5: 75.0000 (74.7109)  time: 0.3453  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 290/4579]  eta: 0:24:59  Lr: 0.001875  Loss: 1.8642  Acc@1: 37.5000 (30.6701)  Acc@5: 81.2500 (74.9785)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 300/4579]  eta: 0:24:55  Lr: 0.001875  Loss: 1.7888  Acc@1: 37.5000 (30.9385)  Acc@5: 81.2500 (75.3115)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 310/4579]  eta: 0:24:51  Lr: 0.001875  Loss: 2.0264  Acc@1: 37.5000 (31.1696)  Acc@5: 87.5000 (75.7235)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 320/4579]  eta: 0:24:47  Lr: 0.001875  Loss: 1.6359  Acc@1: 37.5000 (31.3474)  Acc@5: 87.5000 (76.0514)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 330/4579]  eta: 0:24:42  Lr: 0.001875  Loss: 1.3643  Acc@1: 37.5000 (31.5899)  Acc@5: 81.2500 (76.2085)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 340/4579]  eta: 0:24:38  Lr: 0.001875  Loss: 1.6677  Acc@1: 37.5000 (31.7815)  Acc@5: 81.2500 (76.5396)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 350/4579]  eta: 0:24:34  Lr: 0.001875  Loss: 1.3446  Acc@1: 37.5000 (31.8910)  Acc@5: 87.5000 (76.7094)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 360/4579]  eta: 0:24:31  Lr: 0.001875  Loss: 2.1811  Acc@1: 37.5000 (32.0810)  Acc@5: 81.2500 (76.8698)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 370/4579]  eta: 0:24:27  Lr: 0.001875  Loss: 1.9226  Acc@1: 37.5000 (32.3956)  Acc@5: 81.2500 (76.9710)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 380/4579]  eta: 0:24:23  Lr: 0.001875  Loss: 2.1129  Acc@1: 37.5000 (32.5951)  Acc@5: 81.2500 (76.9849)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 390/4579]  eta: 0:24:19  Lr: 0.001875  Loss: 1.2861  Acc@1: 43.7500 (32.8964)  Acc@5: 81.2500 (77.1419)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 400/4579]  eta: 0:24:15  Lr: 0.001875  Loss: 1.3936  Acc@1: 43.7500 (33.2606)  Acc@5: 87.5000 (77.3535)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 410/4579]  eta: 0:24:11  Lr: 0.001875  Loss: 1.5560  Acc@1: 43.7500 (33.5006)  Acc@5: 87.5000 (77.5700)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 420/4579]  eta: 0:24:08  Lr: 0.001875  Loss: 1.7483  Acc@1: 43.7500 (33.6550)  Acc@5: 87.5000 (77.6277)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 430/4579]  eta: 0:24:04  Lr: 0.001875  Loss: 1.8152  Acc@1: 43.7500 (33.9037)  Acc@5: 81.2500 (77.8132)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 440/4579]  eta: 0:24:00  Lr: 0.001875  Loss: 1.2759  Acc@1: 43.7500 (34.1553)  Acc@5: 87.5000 (78.0471)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 450/4579]  eta: 0:23:57  Lr: 0.001875  Loss: 1.4932  Acc@1: 43.7500 (34.4374)  Acc@5: 93.7500 (78.3675)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 460/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 1.6894  Acc@1: 43.7500 (34.6800)  Acc@5: 93.7500 (78.5927)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 470/4579]  eta: 0:23:49  Lr: 0.001875  Loss: 1.7608  Acc@1: 43.7500 (34.7930)  Acc@5: 87.5000 (78.7288)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 480/4579]  eta: 0:23:46  Lr: 0.001875  Loss: 1.7362  Acc@1: 37.5000 (34.9532)  Acc@5: 81.2500 (78.8332)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 490/4579]  eta: 0:23:42  Lr: 0.001875  Loss: 1.6803  Acc@1: 43.7500 (35.1324)  Acc@5: 81.2500 (78.8569)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 500/4579]  eta: 0:23:38  Lr: 0.001875  Loss: 1.6142  Acc@1: 43.7500 (35.2171)  Acc@5: 81.2500 (78.9296)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 510/4579]  eta: 0:23:35  Lr: 0.001875  Loss: 1.9116  Acc@1: 43.7500 (35.4452)  Acc@5: 87.5000 (79.0484)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 520/4579]  eta: 0:23:31  Lr: 0.001875  Loss: 1.1195  Acc@1: 43.7500 (35.7246)  Acc@5: 87.5000 (79.2226)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 530/4579]  eta: 0:23:27  Lr: 0.001875  Loss: 1.5421  Acc@1: 43.7500 (35.8639)  Acc@5: 81.2500 (79.2373)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 540/4579]  eta: 0:23:24  Lr: 0.001875  Loss: 1.6156  Acc@1: 43.7500 (36.1021)  Acc@5: 81.2500 (79.3207)  time: 0.3457  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 550/4579]  eta: 0:23:20  Lr: 0.001875  Loss: 1.8649  Acc@1: 43.7500 (36.2409)  Acc@5: 87.5000 (79.3330)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 560/4579]  eta: 0:23:17  Lr: 0.001875  Loss: 1.8568  Acc@1: 43.7500 (36.3636)  Acc@5: 87.5000 (79.5009)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 570/4579]  eta: 0:23:13  Lr: 0.001875  Loss: 1.6506  Acc@1: 50.0000 (36.5696)  Acc@5: 87.5000 (79.6410)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 580/4579]  eta: 0:23:10  Lr: 0.001875  Loss: 1.6833  Acc@1: 43.7500 (36.6717)  Acc@5: 87.5000 (79.7332)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 590/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 1.7601  Acc@1: 43.7500 (36.8549)  Acc@5: 87.5000 (79.8118)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 600/4579]  eta: 0:23:02  Lr: 0.001875  Loss: 1.4603  Acc@1: 50.0000 (37.1256)  Acc@5: 87.5000 (79.9501)  time: 0.3457  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 610/4579]  eta: 0:22:59  Lr: 0.001875  Loss: 1.4079  Acc@1: 50.0000 (37.1624)  Acc@5: 87.5000 (79.9509)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 620/4579]  eta: 0:22:55  Lr: 0.001875  Loss: 1.9564  Acc@1: 43.7500 (37.2886)  Acc@5: 87.5000 (80.0825)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 630/4579]  eta: 0:22:52  Lr: 0.001875  Loss: 1.7483  Acc@1: 43.7500 (37.3712)  Acc@5: 87.5000 (80.1307)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 640/4579]  eta: 0:22:48  Lr: 0.001875  Loss: 1.2075  Acc@1: 43.7500 (37.4902)  Acc@5: 87.5000 (80.2652)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 650/4579]  eta: 0:22:44  Lr: 0.001875  Loss: 1.6280  Acc@1: 50.0000 (37.6248)  Acc@5: 87.5000 (80.3283)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 660/4579]  eta: 0:22:41  Lr: 0.001875  Loss: 1.8531  Acc@1: 43.7500 (37.6891)  Acc@5: 81.2500 (80.3517)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 670/4579]  eta: 0:22:37  Lr: 0.001875  Loss: 1.8292  Acc@1: 43.7500 (37.7887)  Acc@5: 87.5000 (80.4396)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 680/4579]  eta: 0:22:34  Lr: 0.001875  Loss: 1.6504  Acc@1: 43.7500 (37.9130)  Acc@5: 87.5000 (80.5892)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 690/4579]  eta: 0:22:30  Lr: 0.001875  Loss: 1.5001  Acc@1: 50.0000 (38.0517)  Acc@5: 87.5000 (80.6711)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 700/4579]  eta: 0:22:26  Lr: 0.001875  Loss: 1.5795  Acc@1: 43.7500 (38.1063)  Acc@5: 87.5000 (80.7775)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 710/4579]  eta: 0:22:23  Lr: 0.001875  Loss: 1.5685  Acc@1: 37.5000 (38.1241)  Acc@5: 87.5000 (80.7929)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 720/4579]  eta: 0:22:19  Lr: 0.001875  Loss: 1.5916  Acc@1: 37.5000 (38.2021)  Acc@5: 81.2500 (80.8512)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 730/4579]  eta: 0:22:16  Lr: 0.001875  Loss: 1.6048  Acc@1: 43.7500 (38.2780)  Acc@5: 87.5000 (80.9422)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 740/4579]  eta: 0:22:12  Lr: 0.001875  Loss: 1.5762  Acc@1: 50.0000 (38.4868)  Acc@5: 87.5000 (81.0138)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 750/4579]  eta: 0:22:08  Lr: 0.001875  Loss: 1.8335  Acc@1: 50.0000 (38.5985)  Acc@5: 87.5000 (81.1168)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 760/4579]  eta: 0:22:05  Lr: 0.001875  Loss: 1.5239  Acc@1: 43.7500 (38.7155)  Acc@5: 87.5000 (81.2254)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 770/4579]  eta: 0:22:01  Lr: 0.001875  Loss: 1.6854  Acc@1: 43.7500 (38.7808)  Acc@5: 87.5000 (81.2824)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 780/4579]  eta: 0:21:58  Lr: 0.001875  Loss: 1.8525  Acc@1: 43.7500 (38.9725)  Acc@5: 87.5000 (81.2820)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 790/4579]  eta: 0:21:54  Lr: 0.001875  Loss: 1.3098  Acc@1: 43.7500 (39.0645)  Acc@5: 81.2500 (81.3211)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 800/4579]  eta: 0:21:51  Lr: 0.001875  Loss: 1.7098  Acc@1: 43.7500 (39.1932)  Acc@5: 87.5000 (81.4451)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 810/4579]  eta: 0:21:47  Lr: 0.001875  Loss: 1.4990  Acc@1: 50.0000 (39.2725)  Acc@5: 93.7500 (81.5351)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 820/4579]  eta: 0:21:44  Lr: 0.001875  Loss: 1.4270  Acc@1: 50.0000 (39.4488)  Acc@5: 87.5000 (81.5850)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 830/4579]  eta: 0:21:40  Lr: 0.001875  Loss: 1.1469  Acc@1: 56.2500 (39.5984)  Acc@5: 87.5000 (81.6561)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 840/4579]  eta: 0:21:37  Lr: 0.001875  Loss: 1.9160  Acc@1: 56.2500 (39.7295)  Acc@5: 87.5000 (81.7331)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 850/4579]  eta: 0:21:33  Lr: 0.001875  Loss: 1.6219  Acc@1: 43.7500 (39.7767)  Acc@5: 87.5000 (81.8155)  time: 0.3454  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 860/4579]  eta: 0:21:29  Lr: 0.001875  Loss: 1.6502  Acc@1: 43.7500 (39.8810)  Acc@5: 87.5000 (81.8452)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 870/4579]  eta: 0:21:26  Lr: 0.001875  Loss: 1.2888  Acc@1: 50.0000 (39.9110)  Acc@5: 87.5000 (81.8958)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 880/4579]  eta: 0:21:22  Lr: 0.001875  Loss: 1.7051  Acc@1: 50.0000 (40.0043)  Acc@5: 87.5000 (81.9665)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 890/4579]  eta: 0:21:19  Lr: 0.001875  Loss: 1.6124  Acc@1: 50.0000 (40.1024)  Acc@5: 87.5000 (82.0216)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 900/4579]  eta: 0:21:15  Lr: 0.001875  Loss: 1.6758  Acc@1: 50.0000 (40.2678)  Acc@5: 87.5000 (82.0755)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 910/4579]  eta: 0:21:12  Lr: 0.001875  Loss: 1.6365  Acc@1: 50.0000 (40.3403)  Acc@5: 87.5000 (82.1556)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 920/4579]  eta: 0:21:08  Lr: 0.001875  Loss: 1.8299  Acc@1: 43.7500 (40.3230)  Acc@5: 87.5000 (82.1933)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 930/4579]  eta: 0:21:04  Lr: 0.001875  Loss: 1.9123  Acc@1: 37.5000 (40.3195)  Acc@5: 87.5000 (82.2637)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 940/4579]  eta: 0:21:01  Lr: 0.001875  Loss: 1.2271  Acc@1: 43.7500 (40.4490)  Acc@5: 87.5000 (82.3260)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 950/4579]  eta: 0:20:58  Lr: 0.001875  Loss: 1.3197  Acc@1: 43.7500 (40.4048)  Acc@5: 81.2500 (82.3278)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 960/4579]  eta: 0:20:54  Lr: 0.001875  Loss: 1.4202  Acc@1: 37.5000 (40.4396)  Acc@5: 81.2500 (82.3686)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 970/4579]  eta: 0:20:50  Lr: 0.001875  Loss: 1.3908  Acc@1: 50.0000 (40.5252)  Acc@5: 81.2500 (82.4086)  time: 0.3454  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 980/4579]  eta: 0:20:47  Lr: 0.001875  Loss: 1.7068  Acc@1: 50.0000 (40.6154)  Acc@5: 87.5000 (82.4924)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 990/4579]  eta: 0:20:43  Lr: 0.001875  Loss: 1.8617  Acc@1: 43.7500 (40.6849)  Acc@5: 87.5000 (82.5492)  time: 0.3438  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1000/4579]  eta: 0:20:40  Lr: 0.001875  Loss: 1.2021  Acc@1: 50.0000 (40.7842)  Acc@5: 87.5000 (82.5862)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1010/4579]  eta: 0:20:36  Lr: 0.001875  Loss: 1.3906  Acc@1: 50.0000 (40.8568)  Acc@5: 87.5000 (82.6409)  time: 0.3455  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1020/4579]  eta: 0:20:33  Lr: 0.001875  Loss: 1.6583  Acc@1: 43.7500 (40.9770)  Acc@5: 87.5000 (82.6702)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1030/4579]  eta: 0:20:29  Lr: 0.001875  Loss: 2.0405  Acc@1: 50.0000 (41.0706)  Acc@5: 87.5000 (82.7049)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1040/4579]  eta: 0:20:26  Lr: 0.001875  Loss: 1.9663  Acc@1: 50.0000 (41.1924)  Acc@5: 87.5000 (82.7570)  time: 0.3446  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1050/4579]  eta: 0:20:22  Lr: 0.001875  Loss: 1.4275  Acc@1: 50.0000 (41.2643)  Acc@5: 87.5000 (82.7843)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1060/4579]  eta: 0:20:19  Lr: 0.001875  Loss: 1.1634  Acc@1: 50.0000 (41.3466)  Acc@5: 87.5000 (82.8346)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1070/4579]  eta: 0:20:15  Lr: 0.001875  Loss: 1.2682  Acc@1: 50.0000 (41.4391)  Acc@5: 87.5000 (82.9073)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1080/4579]  eta: 0:20:12  Lr: 0.001875  Loss: 1.4284  Acc@1: 56.2500 (41.5587)  Acc@5: 93.7500 (82.9556)  time: 0.3463  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1090/4579]  eta: 0:20:08  Lr: 0.001875  Loss: 1.3776  Acc@1: 50.0000 (41.6819)  Acc@5: 87.5000 (82.9973)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1100/4579]  eta: 0:20:05  Lr: 0.001875  Loss: 1.8041  Acc@1: 50.0000 (41.7745)  Acc@5: 87.5000 (83.0268)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1110/4579]  eta: 0:20:01  Lr: 0.001875  Loss: 1.2533  Acc@1: 50.0000 (41.8936)  Acc@5: 87.5000 (83.0333)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1120/4579]  eta: 0:19:58  Lr: 0.001875  Loss: 1.3700  Acc@1: 56.2500 (41.9938)  Acc@5: 87.5000 (83.0955)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1130/4579]  eta: 0:19:54  Lr: 0.001875  Loss: 1.3439  Acc@1: 50.0000 (42.0424)  Acc@5: 87.5000 (83.1454)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1140/4579]  eta: 0:19:51  Lr: 0.001875  Loss: 1.2144  Acc@1: 43.7500 (42.1012)  Acc@5: 87.5000 (83.2000)  time: 0.3449  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1150/4579]  eta: 0:19:47  Lr: 0.001875  Loss: 1.4291  Acc@1: 50.0000 (42.1807)  Acc@5: 87.5000 (83.2265)  time: 0.3449  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1160/4579]  eta: 0:19:44  Lr: 0.001875  Loss: 1.0481  Acc@1: 56.2500 (42.3342)  Acc@5: 87.5000 (83.2849)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1170/4579]  eta: 0:19:40  Lr: 0.001875  Loss: 1.2253  Acc@1: 56.2500 (42.3836)  Acc@5: 87.5000 (83.3049)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1180/4579]  eta: 0:19:37  Lr: 0.001875  Loss: 1.7821  Acc@1: 43.7500 (42.4534)  Acc@5: 87.5000 (83.3563)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1190/4579]  eta: 0:19:33  Lr: 0.001875  Loss: 1.4370  Acc@1: 43.7500 (42.4643)  Acc@5: 87.5000 (83.3701)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1200/4579]  eta: 0:19:30  Lr: 0.001875  Loss: 1.9758  Acc@1: 50.0000 (42.5531)  Acc@5: 87.5000 (83.3993)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1210/4579]  eta: 0:19:26  Lr: 0.001875  Loss: 1.4440  Acc@1: 56.2500 (42.6713)  Acc@5: 93.7500 (83.4641)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1220/4579]  eta: 0:19:23  Lr: 0.001875  Loss: 1.5507  Acc@1: 56.2500 (42.7877)  Acc@5: 87.5000 (83.5176)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1230/4579]  eta: 0:19:19  Lr: 0.001875  Loss: 1.1675  Acc@1: 56.2500 (42.8767)  Acc@5: 93.7500 (83.5855)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1240/4579]  eta: 0:19:16  Lr: 0.001875  Loss: 1.5215  Acc@1: 56.2500 (42.9341)  Acc@5: 93.7500 (83.6120)  time: 0.3437  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1250/4579]  eta: 0:19:12  Lr: 0.001875  Loss: 1.8071  Acc@1: 43.7500 (42.9606)  Acc@5: 87.5000 (83.6331)  time: 0.3450  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1260/4579]  eta: 0:19:09  Lr: 0.001875  Loss: 1.3973  Acc@1: 43.7500 (42.9768)  Acc@5: 87.5000 (83.6588)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1270/4579]  eta: 0:19:05  Lr: 0.001875  Loss: 1.4548  Acc@1: 50.0000 (43.0566)  Acc@5: 87.5000 (83.6890)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1280/4579]  eta: 0:19:02  Lr: 0.001875  Loss: 1.4544  Acc@1: 56.2500 (43.1548)  Acc@5: 87.5000 (83.7188)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1290/4579]  eta: 0:18:58  Lr: 0.001875  Loss: 1.2229  Acc@1: 56.2500 (43.2368)  Acc@5: 87.5000 (83.7626)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1300/4579]  eta: 0:18:55  Lr: 0.001875  Loss: 0.9092  Acc@1: 50.0000 (43.2552)  Acc@5: 87.5000 (83.7865)  time: 0.3451  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1310/4579]  eta: 0:18:51  Lr: 0.001875  Loss: 1.3401  Acc@1: 50.0000 (43.3781)  Acc@5: 87.5000 (83.8101)  time: 0.3454  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1320/4579]  eta: 0:18:48  Lr: 0.001875  Loss: 1.2337  Acc@1: 56.2500 (43.4425)  Acc@5: 87.5000 (83.8569)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1330/4579]  eta: 0:18:44  Lr: 0.001875  Loss: 0.8319  Acc@1: 56.2500 (43.5293)  Acc@5: 93.7500 (83.9172)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1340/4579]  eta: 0:18:41  Lr: 0.001875  Loss: 1.6398  Acc@1: 43.7500 (43.5636)  Acc@5: 93.7500 (83.9765)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1350/4579]  eta: 0:18:37  Lr: 0.001875  Loss: 1.4536  Acc@1: 43.7500 (43.5835)  Acc@5: 93.7500 (83.9980)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1360/4579]  eta: 0:18:34  Lr: 0.001875  Loss: 1.6112  Acc@1: 50.0000 (43.6306)  Acc@5: 87.5000 (84.0375)  time: 0.3452  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1370/4579]  eta: 0:18:30  Lr: 0.001875  Loss: 1.2955  Acc@1: 50.0000 (43.6953)  Acc@5: 93.7500 (84.0855)  time: 0.3461  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1380/4579]  eta: 0:18:27  Lr: 0.001875  Loss: 1.2366  Acc@1: 56.2500 (43.7636)  Acc@5: 93.7500 (84.1419)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1390/4579]  eta: 0:18:23  Lr: 0.001875  Loss: 1.5123  Acc@1: 50.0000 (43.8174)  Acc@5: 93.7500 (84.2110)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1400/4579]  eta: 0:18:20  Lr: 0.001875  Loss: 1.7180  Acc@1: 50.0000 (43.8615)  Acc@5: 93.7500 (84.2612)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1410/4579]  eta: 0:18:16  Lr: 0.001875  Loss: 1.2695  Acc@1: 43.7500 (43.8873)  Acc@5: 87.5000 (84.2931)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1420/4579]  eta: 0:18:13  Lr: 0.001875  Loss: 1.4725  Acc@1: 56.2500 (43.9567)  Acc@5: 87.5000 (84.3420)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1430/4579]  eta: 0:18:09  Lr: 0.001875  Loss: 1.5291  Acc@1: 50.0000 (43.9902)  Acc@5: 87.5000 (84.3597)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1440/4579]  eta: 0:18:06  Lr: 0.001875  Loss: 1.1498  Acc@1: 50.0000 (44.0623)  Acc@5: 87.5000 (84.4032)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1450/4579]  eta: 0:18:02  Lr: 0.001875  Loss: 1.1672  Acc@1: 56.2500 (44.1506)  Acc@5: 87.5000 (84.4030)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1460/4579]  eta: 0:17:59  Lr: 0.001875  Loss: 1.1970  Acc@1: 50.0000 (44.1564)  Acc@5: 87.5000 (84.4242)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1470/4579]  eta: 0:17:55  Lr: 0.001875  Loss: 0.9466  Acc@1: 50.0000 (44.2896)  Acc@5: 87.5000 (84.4833)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1480/4579]  eta: 0:17:52  Lr: 0.001875  Loss: 1.3120  Acc@1: 56.2500 (44.3535)  Acc@5: 87.5000 (84.4826)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1490/4579]  eta: 0:17:48  Lr: 0.001875  Loss: 1.1124  Acc@1: 50.0000 (44.3704)  Acc@5: 87.5000 (84.5238)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1500/4579]  eta: 0:17:45  Lr: 0.001875  Loss: 1.3860  Acc@1: 50.0000 (44.4204)  Acc@5: 87.5000 (84.5436)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1510/4579]  eta: 0:17:41  Lr: 0.001875  Loss: 1.0873  Acc@1: 50.0000 (44.5111)  Acc@5: 93.7500 (84.5922)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1520/4579]  eta: 0:17:38  Lr: 0.001875  Loss: 1.2992  Acc@1: 50.0000 (44.5595)  Acc@5: 93.7500 (84.6318)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1530/4579]  eta: 0:17:34  Lr: 0.001875  Loss: 1.3660  Acc@1: 50.0000 (44.5787)  Acc@5: 87.5000 (84.6383)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1540/4579]  eta: 0:17:31  Lr: 0.001875  Loss: 1.1080  Acc@1: 50.0000 (44.5896)  Acc@5: 87.5000 (84.6528)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1550/4579]  eta: 0:17:27  Lr: 0.001875  Loss: 1.2174  Acc@1: 56.2500 (44.6809)  Acc@5: 87.5000 (84.6873)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1560/4579]  eta: 0:17:24  Lr: 0.001875  Loss: 1.4644  Acc@1: 62.5000 (44.7910)  Acc@5: 87.5000 (84.7213)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1570/4579]  eta: 0:17:20  Lr: 0.001875  Loss: 1.7514  Acc@1: 56.2500 (44.7844)  Acc@5: 87.5000 (84.7430)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1580/4579]  eta: 0:17:17  Lr: 0.001875  Loss: 1.2006  Acc@1: 50.0000 (44.8450)  Acc@5: 87.5000 (84.7486)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1590/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 1.3231  Acc@1: 50.0000 (44.9089)  Acc@5: 87.5000 (84.7855)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1600/4579]  eta: 0:17:10  Lr: 0.001875  Loss: 1.3585  Acc@1: 50.0000 (44.9563)  Acc@5: 87.5000 (84.7908)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1610/4579]  eta: 0:17:06  Lr: 0.001875  Loss: 1.7928  Acc@1: 56.2500 (45.0186)  Acc@5: 87.5000 (84.8076)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1620/4579]  eta: 0:17:03  Lr: 0.001875  Loss: 1.7229  Acc@1: 50.0000 (45.0416)  Acc@5: 87.5000 (84.8242)  time: 0.3439  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1630/4579]  eta: 0:16:59  Lr: 0.001875  Loss: 1.2858  Acc@1: 56.2500 (45.1065)  Acc@5: 87.5000 (84.8483)  time: 0.3438  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1640/4579]  eta: 0:16:56  Lr: 0.001875  Loss: 1.3727  Acc@1: 56.2500 (45.1287)  Acc@5: 93.7500 (84.9025)  time: 0.3444  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1650/4579]  eta: 0:16:52  Lr: 0.001875  Loss: 0.9901  Acc@1: 56.2500 (45.1885)  Acc@5: 93.7500 (84.9144)  time: 0.3446  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1660/4579]  eta: 0:16:49  Lr: 0.001875  Loss: 1.6074  Acc@1: 50.0000 (45.2137)  Acc@5: 87.5000 (84.9564)  time: 0.3437  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1670/4579]  eta: 0:16:45  Lr: 0.001875  Loss: 1.0256  Acc@1: 56.2500 (45.2873)  Acc@5: 93.7500 (84.9940)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1680/4579]  eta: 0:16:42  Lr: 0.001875  Loss: 1.6614  Acc@1: 56.2500 (45.3004)  Acc@5: 87.5000 (84.9941)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1690/4579]  eta: 0:16:39  Lr: 0.001875  Loss: 1.1281  Acc@1: 50.0000 (45.3652)  Acc@5: 87.5000 (85.0052)  time: 0.3445  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1700/4579]  eta: 0:16:35  Lr: 0.001875  Loss: 1.3735  Acc@1: 56.2500 (45.4328)  Acc@5: 87.5000 (85.0309)  time: 0.3442  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1710/4579]  eta: 0:16:31  Lr: 0.001875  Loss: 1.8799  Acc@1: 50.0000 (45.4303)  Acc@5: 87.5000 (85.0161)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1720/4579]  eta: 0:16:28  Lr: 0.001875  Loss: 0.8224  Acc@1: 50.0000 (45.4895)  Acc@5: 81.2500 (85.0269)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1730/4579]  eta: 0:16:25  Lr: 0.001875  Loss: 1.3707  Acc@1: 56.2500 (45.5445)  Acc@5: 87.5000 (85.0520)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1740/4579]  eta: 0:16:21  Lr: 0.001875  Loss: 1.3400  Acc@1: 56.2500 (45.5844)  Acc@5: 87.5000 (85.0732)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1750/4579]  eta: 0:16:18  Lr: 0.001875  Loss: 1.9809  Acc@1: 56.2500 (45.6739)  Acc@5: 87.5000 (85.1049)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1760/4579]  eta: 0:16:14  Lr: 0.001875  Loss: 1.3837  Acc@1: 62.5000 (45.7482)  Acc@5: 87.5000 (85.1292)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1770/4579]  eta: 0:16:11  Lr: 0.001875  Loss: 1.2242  Acc@1: 62.5000 (45.8145)  Acc@5: 87.5000 (85.1602)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1780/4579]  eta: 0:16:07  Lr: 0.001875  Loss: 1.2171  Acc@1: 56.2500 (45.8485)  Acc@5: 87.5000 (85.1874)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1790/4579]  eta: 0:16:04  Lr: 0.001875  Loss: 1.5176  Acc@1: 50.0000 (45.9031)  Acc@5: 87.5000 (85.1968)  time: 0.3436  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1800/4579]  eta: 0:16:00  Lr: 0.001875  Loss: 1.5382  Acc@1: 56.2500 (45.9675)  Acc@5: 93.7500 (85.2235)  time: 0.3436  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1810/4579]  eta: 0:15:57  Lr: 0.001875  Loss: 1.8501  Acc@1: 56.2500 (45.9932)  Acc@5: 87.5000 (85.2395)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1820/4579]  eta: 0:15:53  Lr: 0.001875  Loss: 1.3324  Acc@1: 50.0000 (46.0118)  Acc@5: 87.5000 (85.2759)  time: 0.3449  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1830/4579]  eta: 0:15:50  Lr: 0.001875  Loss: 1.0949  Acc@1: 56.2500 (46.0711)  Acc@5: 87.5000 (85.3052)  time: 0.3441  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1840/4579]  eta: 0:15:46  Lr: 0.001875  Loss: 1.5553  Acc@1: 56.2500 (46.1502)  Acc@5: 93.7500 (85.3510)  time: 0.3435  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1850/4579]  eta: 0:15:43  Lr: 0.001875  Loss: 1.4721  Acc@1: 56.2500 (46.2014)  Acc@5: 93.7500 (85.3728)  time: 0.3432  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1860/4579]  eta: 0:15:39  Lr: 0.001875  Loss: 1.6342  Acc@1: 56.2500 (46.2419)  Acc@5: 87.5000 (85.3909)  time: 0.3432  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1870/4579]  eta: 0:15:36  Lr: 0.001875  Loss: 0.8981  Acc@1: 56.2500 (46.3389)  Acc@5: 93.7500 (85.4256)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1880/4579]  eta: 0:15:32  Lr: 0.001875  Loss: 0.9574  Acc@1: 56.2500 (46.3749)  Acc@5: 93.7500 (85.4499)  time: 0.3438  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1890/4579]  eta: 0:15:29  Lr: 0.001875  Loss: 0.9559  Acc@1: 50.0000 (46.4371)  Acc@5: 87.5000 (85.4607)  time: 0.3439  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1900/4579]  eta: 0:15:25  Lr: 0.001875  Loss: 1.2882  Acc@1: 56.2500 (46.4755)  Acc@5: 87.5000 (85.4583)  time: 0.3430  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1910/4579]  eta: 0:15:22  Lr: 0.001875  Loss: 1.7621  Acc@1: 50.0000 (46.5038)  Acc@5: 87.5000 (85.4625)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1920/4579]  eta: 0:15:18  Lr: 0.001875  Loss: 1.4547  Acc@1: 50.0000 (46.5480)  Acc@5: 87.5000 (85.4633)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1930/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 1.0085  Acc@1: 56.2500 (46.6015)  Acc@5: 87.5000 (85.4771)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1940/4579]  eta: 0:15:11  Lr: 0.001875  Loss: 1.4018  Acc@1: 56.2500 (46.6512)  Acc@5: 87.5000 (85.4746)  time: 0.3432  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1950/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 1.4162  Acc@1: 56.2500 (46.7036)  Acc@5: 87.5000 (85.4946)  time: 0.3442  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1960/4579]  eta: 0:15:04  Lr: 0.001875  Loss: 1.2803  Acc@1: 56.2500 (46.7650)  Acc@5: 87.5000 (85.5112)  time: 0.3443  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1970/4579]  eta: 0:15:01  Lr: 0.001875  Loss: 1.5772  Acc@1: 56.2500 (46.7973)  Acc@5: 87.5000 (85.5403)  time: 0.3431  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1980/4579]  eta: 0:14:57  Lr: 0.001875  Loss: 1.5748  Acc@1: 50.0000 (46.8356)  Acc@5: 93.7500 (85.5723)  time: 0.3430  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1990/4579]  eta: 0:14:54  Lr: 0.001875  Loss: 1.3003  Acc@1: 50.0000 (46.8609)  Acc@5: 87.5000 (85.5820)  time: 0.3438  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2000/4579]  eta: 0:14:51  Lr: 0.001875  Loss: 1.4842  Acc@1: 56.2500 (46.9172)  Acc@5: 87.5000 (85.6072)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2010/4579]  eta: 0:14:47  Lr: 0.001875  Loss: 1.3734  Acc@1: 50.0000 (46.9232)  Acc@5: 87.5000 (85.6197)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2020/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 2.2053  Acc@1: 43.7500 (46.9446)  Acc@5: 87.5000 (85.6259)  time: 0.3437  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2030/4579]  eta: 0:14:40  Lr: 0.001875  Loss: 1.2776  Acc@1: 50.0000 (47.0058)  Acc@5: 87.5000 (85.6444)  time: 0.3441  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2040/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 1.7070  Acc@1: 56.2500 (47.0327)  Acc@5: 87.5000 (85.6229)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2050/4579]  eta: 0:14:33  Lr: 0.001875  Loss: 1.3149  Acc@1: 56.2500 (47.1020)  Acc@5: 87.5000 (85.6564)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2060/4579]  eta: 0:14:30  Lr: 0.001875  Loss: 1.5046  Acc@1: 56.2500 (47.1494)  Acc@5: 87.5000 (85.6684)  time: 0.3441  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2070/4579]  eta: 0:14:26  Lr: 0.001875  Loss: 0.9168  Acc@1: 50.0000 (47.1692)  Acc@5: 87.5000 (85.6953)  time: 0.3434  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2080/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 1.5765  Acc@1: 50.0000 (47.1979)  Acc@5: 93.7500 (85.7130)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2090/4579]  eta: 0:14:19  Lr: 0.001875  Loss: 1.6896  Acc@1: 56.2500 (47.2232)  Acc@5: 87.5000 (85.7245)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2100/4579]  eta: 0:14:16  Lr: 0.001875  Loss: 1.7522  Acc@1: 50.0000 (47.2662)  Acc@5: 87.5000 (85.7300)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2110/4579]  eta: 0:14:12  Lr: 0.001875  Loss: 1.6464  Acc@1: 50.0000 (47.3295)  Acc@5: 87.5000 (85.7473)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2120/4579]  eta: 0:14:09  Lr: 0.001875  Loss: 1.2455  Acc@1: 56.2500 (47.3450)  Acc@5: 93.7500 (85.7644)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2130/4579]  eta: 0:14:05  Lr: 0.001875  Loss: 1.5233  Acc@1: 50.0000 (47.3692)  Acc@5: 93.7500 (85.7813)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2140/4579]  eta: 0:14:02  Lr: 0.001875  Loss: 1.8683  Acc@1: 50.0000 (47.3932)  Acc@5: 87.5000 (85.7952)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2150/4579]  eta: 0:13:58  Lr: 0.001875  Loss: 1.2284  Acc@1: 62.5000 (47.4547)  Acc@5: 87.5000 (85.8031)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2160/4579]  eta: 0:13:55  Lr: 0.001875  Loss: 1.4071  Acc@1: 62.5000 (47.5069)  Acc@5: 87.5000 (85.8312)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2170/4579]  eta: 0:13:52  Lr: 0.001875  Loss: 1.3770  Acc@1: 50.0000 (47.5271)  Acc@5: 87.5000 (85.8389)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2180/4579]  eta: 0:13:48  Lr: 0.001875  Loss: 1.2485  Acc@1: 56.2500 (47.5785)  Acc@5: 87.5000 (85.8436)  time: 0.3453  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2190/4579]  eta: 0:13:45  Lr: 0.001875  Loss: 1.2694  Acc@1: 56.2500 (47.6152)  Acc@5: 87.5000 (85.8455)  time: 0.3449  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2200/4579]  eta: 0:13:41  Lr: 0.001875  Loss: 1.0208  Acc@1: 56.2500 (47.6744)  Acc@5: 87.5000 (85.8757)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2210/4579]  eta: 0:13:38  Lr: 0.001875  Loss: 1.5010  Acc@1: 56.2500 (47.7131)  Acc@5: 87.5000 (85.8774)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2220/4579]  eta: 0:13:34  Lr: 0.001875  Loss: 1.5293  Acc@1: 56.2500 (47.7544)  Acc@5: 81.2500 (85.8763)  time: 0.3450  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2230/4579]  eta: 0:13:31  Lr: 0.001875  Loss: 1.1083  Acc@1: 56.2500 (47.7869)  Acc@5: 87.5000 (85.8948)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2240/4579]  eta: 0:13:27  Lr: 0.001875  Loss: 1.7973  Acc@1: 56.2500 (47.8191)  Acc@5: 87.5000 (85.8964)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2250/4579]  eta: 0:13:24  Lr: 0.001875  Loss: 1.0574  Acc@1: 56.2500 (47.8565)  Acc@5: 87.5000 (85.9174)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2260/4579]  eta: 0:13:20  Lr: 0.001875  Loss: 1.4030  Acc@1: 50.0000 (47.8660)  Acc@5: 87.5000 (85.9188)  time: 0.3450  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2270/4579]  eta: 0:13:17  Lr: 0.001875  Loss: 1.3868  Acc@1: 50.0000 (47.8864)  Acc@5: 87.5000 (85.9258)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2280/4579]  eta: 0:13:14  Lr: 0.001875  Loss: 1.6491  Acc@1: 50.0000 (47.8820)  Acc@5: 87.5000 (85.9382)  time: 0.3450  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2290/4579]  eta: 0:13:10  Lr: 0.001875  Loss: 1.5662  Acc@1: 50.0000 (47.8939)  Acc@5: 87.5000 (85.9341)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2300/4579]  eta: 0:13:07  Lr: 0.001875  Loss: 1.1610  Acc@1: 50.0000 (47.9384)  Acc@5: 87.5000 (85.9463)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2310/4579]  eta: 0:13:03  Lr: 0.001875  Loss: 0.8167  Acc@1: 56.2500 (47.9771)  Acc@5: 93.7500 (85.9693)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2320/4579]  eta: 0:13:00  Lr: 0.001875  Loss: 1.7059  Acc@1: 56.2500 (47.9939)  Acc@5: 87.5000 (85.9678)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2330/4579]  eta: 0:12:56  Lr: 0.001875  Loss: 1.4615  Acc@1: 56.2500 (48.0212)  Acc@5: 87.5000 (85.9824)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2340/4579]  eta: 0:12:53  Lr: 0.001875  Loss: 1.4453  Acc@1: 50.0000 (48.0510)  Acc@5: 93.7500 (86.0103)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2350/4579]  eta: 0:12:49  Lr: 0.001875  Loss: 1.1891  Acc@1: 56.2500 (48.0992)  Acc@5: 93.7500 (86.0272)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2360/4579]  eta: 0:12:46  Lr: 0.001875  Loss: 1.2106  Acc@1: 56.2500 (48.1443)  Acc@5: 93.7500 (86.0520)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2370/4579]  eta: 0:12:42  Lr: 0.001875  Loss: 1.5596  Acc@1: 56.2500 (48.1811)  Acc@5: 87.5000 (86.0555)  time: 0.3452  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2380/4579]  eta: 0:12:39  Lr: 0.001875  Loss: 0.8488  Acc@1: 56.2500 (48.2229)  Acc@5: 87.5000 (86.0694)  time: 0.3453  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2390/4579]  eta: 0:12:36  Lr: 0.001875  Loss: 1.2019  Acc@1: 56.2500 (48.2408)  Acc@5: 87.5000 (86.0754)  time: 0.3439  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2400/4579]  eta: 0:12:32  Lr: 0.001875  Loss: 0.9848  Acc@1: 56.2500 (48.2976)  Acc@5: 93.7500 (86.1152)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2410/4579]  eta: 0:12:29  Lr: 0.001875  Loss: 1.4132  Acc@1: 56.2500 (48.3150)  Acc@5: 93.7500 (86.1235)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2420/4579]  eta: 0:12:25  Lr: 0.001875  Loss: 0.8567  Acc@1: 56.2500 (48.3633)  Acc@5: 87.5000 (86.1343)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2430/4579]  eta: 0:12:22  Lr: 0.001875  Loss: 1.9712  Acc@1: 56.2500 (48.3752)  Acc@5: 87.5000 (86.1425)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2440/4579]  eta: 0:12:18  Lr: 0.001875  Loss: 1.5406  Acc@1: 56.2500 (48.4151)  Acc@5: 87.5000 (86.1481)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2450/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 0.9072  Acc@1: 62.5000 (48.4751)  Acc@5: 93.7500 (86.1766)  time: 0.3440  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2460/4579]  eta: 0:12:11  Lr: 0.001875  Loss: 1.5459  Acc@1: 56.2500 (48.4788)  Acc@5: 93.7500 (86.1743)  time: 0.3445  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2470/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 0.8704  Acc@1: 50.0000 (48.5102)  Acc@5: 87.5000 (86.1721)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2480/4579]  eta: 0:12:04  Lr: 0.001875  Loss: 1.2192  Acc@1: 56.2500 (48.5540)  Acc@5: 87.5000 (86.1850)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2490/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 1.1271  Acc@1: 62.5000 (48.6251)  Acc@5: 93.7500 (86.2204)  time: 0.3438  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2500/4579]  eta: 0:11:57  Lr: 0.001875  Loss: 1.4663  Acc@1: 62.5000 (48.6755)  Acc@5: 93.7500 (86.2455)  time: 0.3433  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2510/4579]  eta: 0:11:54  Lr: 0.001875  Loss: 1.1042  Acc@1: 56.2500 (48.7107)  Acc@5: 93.7500 (86.2654)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2520/4579]  eta: 0:11:51  Lr: 0.001875  Loss: 1.1219  Acc@1: 56.2500 (48.7654)  Acc@5: 87.5000 (86.2753)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2530/4579]  eta: 0:11:47  Lr: 0.001875  Loss: 1.0552  Acc@1: 56.2500 (48.8295)  Acc@5: 87.5000 (86.2974)  time: 0.3438  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2540/4579]  eta: 0:11:44  Lr: 0.001875  Loss: 1.3647  Acc@1: 56.2500 (48.8538)  Acc@5: 93.7500 (86.3144)  time: 0.3446  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2550/4579]  eta: 0:11:40  Lr: 0.001875  Loss: 0.8969  Acc@1: 56.2500 (48.8828)  Acc@5: 87.5000 (86.3289)  time: 0.3446  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2560/4579]  eta: 0:11:37  Lr: 0.001875  Loss: 1.9054  Acc@1: 56.2500 (48.9189)  Acc@5: 87.5000 (86.3286)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2570/4579]  eta: 0:11:33  Lr: 0.001875  Loss: 1.0395  Acc@1: 56.2500 (48.9498)  Acc@5: 87.5000 (86.3356)  time: 0.3454  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2580/4579]  eta: 0:11:30  Lr: 0.001875  Loss: 1.1441  Acc@1: 56.2500 (48.9757)  Acc@5: 87.5000 (86.3449)  time: 0.3458  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2590/4579]  eta: 0:11:26  Lr: 0.001875  Loss: 1.6518  Acc@1: 56.2500 (49.0014)  Acc@5: 87.5000 (86.3421)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2600/4579]  eta: 0:11:23  Lr: 0.001875  Loss: 1.1294  Acc@1: 50.0000 (49.0076)  Acc@5: 87.5000 (86.3538)  time: 0.3438  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2610/4579]  eta: 0:11:19  Lr: 0.001875  Loss: 1.3146  Acc@1: 50.0000 (49.0329)  Acc@5: 87.5000 (86.3606)  time: 0.3434  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2620/4579]  eta: 0:11:16  Lr: 0.001875  Loss: 1.1035  Acc@1: 56.2500 (49.0700)  Acc@5: 87.5000 (86.3697)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2630/4579]  eta: 0:11:12  Lr: 0.001875  Loss: 1.4666  Acc@1: 56.2500 (49.0973)  Acc@5: 87.5000 (86.3788)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2640/4579]  eta: 0:11:09  Lr: 0.001875  Loss: 1.8479  Acc@1: 56.2500 (49.1220)  Acc@5: 87.5000 (86.4019)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2650/4579]  eta: 0:11:06  Lr: 0.001875  Loss: 1.1586  Acc@1: 56.2500 (49.1442)  Acc@5: 87.5000 (86.4037)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2660/4579]  eta: 0:11:02  Lr: 0.001875  Loss: 0.8042  Acc@1: 62.5000 (49.1991)  Acc@5: 87.5000 (86.4172)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2670/4579]  eta: 0:10:59  Lr: 0.001875  Loss: 0.9876  Acc@1: 62.5000 (49.2185)  Acc@5: 93.7500 (86.4306)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2680/4579]  eta: 0:10:55  Lr: 0.001875  Loss: 0.9389  Acc@1: 50.0000 (49.2470)  Acc@5: 93.7500 (86.4579)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2690/4579]  eta: 0:10:52  Lr: 0.001875  Loss: 2.0799  Acc@1: 50.0000 (49.2475)  Acc@5: 87.5000 (86.4641)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2700/4579]  eta: 0:10:48  Lr: 0.001875  Loss: 1.3168  Acc@1: 50.0000 (49.2642)  Acc@5: 87.5000 (86.4633)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2710/4579]  eta: 0:10:45  Lr: 0.001875  Loss: 1.5808  Acc@1: 56.2500 (49.2830)  Acc@5: 81.2500 (86.4579)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2720/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 1.3471  Acc@1: 56.2500 (49.3293)  Acc@5: 87.5000 (86.4618)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2730/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 1.6202  Acc@1: 56.2500 (49.3363)  Acc@5: 87.5000 (86.4564)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2740/4579]  eta: 0:10:34  Lr: 0.001875  Loss: 1.8813  Acc@1: 50.0000 (49.3524)  Acc@5: 87.5000 (86.4671)  time: 0.3461  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2750/4579]  eta: 0:10:31  Lr: 0.001875  Loss: 1.3081  Acc@1: 56.2500 (49.3798)  Acc@5: 87.5000 (86.4663)  time: 0.3455  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2760/4579]  eta: 0:10:28  Lr: 0.001875  Loss: 1.3134  Acc@1: 56.2500 (49.3956)  Acc@5: 87.5000 (86.4768)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2770/4579]  eta: 0:10:24  Lr: 0.001875  Loss: 1.6228  Acc@1: 50.0000 (49.4000)  Acc@5: 87.5000 (86.4737)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2780/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 1.2177  Acc@1: 56.2500 (49.4426)  Acc@5: 87.5000 (86.4932)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2790/4579]  eta: 0:10:17  Lr: 0.001875  Loss: 1.3740  Acc@1: 50.0000 (49.4402)  Acc@5: 87.5000 (86.4945)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2800/4579]  eta: 0:10:14  Lr: 0.001875  Loss: 1.3290  Acc@1: 50.0000 (49.4511)  Acc@5: 87.5000 (86.5004)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2810/4579]  eta: 0:10:10  Lr: 0.001875  Loss: 1.2523  Acc@1: 56.2500 (49.4908)  Acc@5: 87.5000 (86.5128)  time: 0.3457  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2820/4579]  eta: 0:10:07  Lr: 0.001875  Loss: 1.2799  Acc@1: 62.5000 (49.5325)  Acc@5: 87.5000 (86.5296)  time: 0.3460  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2830/4579]  eta: 0:10:03  Lr: 0.001875  Loss: 1.1496  Acc@1: 62.5000 (49.5496)  Acc@5: 87.5000 (86.5330)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2840/4579]  eta: 0:10:00  Lr: 0.001875  Loss: 1.3877  Acc@1: 62.5000 (49.5974)  Acc@5: 87.5000 (86.5408)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2850/4579]  eta: 0:09:56  Lr: 0.001875  Loss: 1.1938  Acc@1: 62.5000 (49.6361)  Acc@5: 93.7500 (86.5595)  time: 0.3450  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2860/4579]  eta: 0:09:53  Lr: 0.001875  Loss: 0.9278  Acc@1: 56.2500 (49.6548)  Acc@5: 93.7500 (86.5585)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2870/4579]  eta: 0:09:50  Lr: 0.001875  Loss: 1.5759  Acc@1: 56.2500 (49.6909)  Acc@5: 87.5000 (86.5704)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2880/4579]  eta: 0:09:46  Lr: 0.001875  Loss: 0.9960  Acc@1: 56.2500 (49.7028)  Acc@5: 87.5000 (86.5585)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2890/4579]  eta: 0:09:43  Lr: 0.001875  Loss: 0.6070  Acc@1: 50.0000 (49.7384)  Acc@5: 93.7500 (86.5769)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2900/4579]  eta: 0:09:39  Lr: 0.001875  Loss: 1.3994  Acc@1: 62.5000 (49.7738)  Acc@5: 87.5000 (86.5736)  time: 0.3467  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2910/4579]  eta: 0:09:36  Lr: 0.001875  Loss: 1.2140  Acc@1: 62.5000 (49.8089)  Acc@5: 87.5000 (86.5768)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2920/4579]  eta: 0:09:32  Lr: 0.001875  Loss: 1.2535  Acc@1: 56.2500 (49.8267)  Acc@5: 87.5000 (86.5949)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2930/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 1.7153  Acc@1: 56.2500 (49.8443)  Acc@5: 93.7500 (86.6065)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2940/4579]  eta: 0:09:25  Lr: 0.001875  Loss: 1.1520  Acc@1: 62.5000 (49.8916)  Acc@5: 93.7500 (86.6244)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2950/4579]  eta: 0:09:22  Lr: 0.001875  Loss: 1.3100  Acc@1: 62.5000 (49.9195)  Acc@5: 87.5000 (86.6295)  time: 0.3454  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2960/4579]  eta: 0:09:19  Lr: 0.001875  Loss: 1.2192  Acc@1: 56.2500 (49.9536)  Acc@5: 87.5000 (86.6388)  time: 0.3457  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2970/4579]  eta: 0:09:15  Lr: 0.001875  Loss: 1.1621  Acc@1: 56.2500 (49.9958)  Acc@5: 87.5000 (86.6438)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2980/4579]  eta: 0:09:12  Lr: 0.001875  Loss: 1.8369  Acc@1: 56.2500 (50.0231)  Acc@5: 87.5000 (86.6509)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2990/4579]  eta: 0:09:08  Lr: 0.001875  Loss: 0.9903  Acc@1: 62.5000 (50.0648)  Acc@5: 93.7500 (86.6600)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3000/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 1.3890  Acc@1: 56.2500 (50.0750)  Acc@5: 87.5000 (86.6649)  time: 0.3446  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3010/4579]  eta: 0:09:01  Lr: 0.001875  Loss: 1.2392  Acc@1: 56.2500 (50.1142)  Acc@5: 93.7500 (86.6780)  time: 0.3447  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3020/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.9344  Acc@1: 62.5000 (50.1386)  Acc@5: 93.7500 (86.6807)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3030/4579]  eta: 0:08:54  Lr: 0.001875  Loss: 1.4291  Acc@1: 62.5000 (50.1711)  Acc@5: 87.5000 (86.6855)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3040/4579]  eta: 0:08:51  Lr: 0.001875  Loss: 1.2878  Acc@1: 62.5000 (50.1973)  Acc@5: 87.5000 (86.6882)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3050/4579]  eta: 0:08:47  Lr: 0.001875  Loss: 1.1176  Acc@1: 56.2500 (50.2253)  Acc@5: 87.5000 (86.7052)  time: 0.3445  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3060/4579]  eta: 0:08:44  Lr: 0.001875  Loss: 1.4869  Acc@1: 62.5000 (50.2859)  Acc@5: 93.7500 (86.7323)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3070/4579]  eta: 0:08:41  Lr: 0.001875  Loss: 1.5403  Acc@1: 56.2500 (50.2951)  Acc@5: 93.7500 (86.7368)  time: 0.3444  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3080/4579]  eta: 0:08:37  Lr: 0.001875  Loss: 1.2556  Acc@1: 50.0000 (50.3225)  Acc@5: 87.5000 (86.7474)  time: 0.3451  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3090/4579]  eta: 0:08:34  Lr: 0.001875  Loss: 0.7307  Acc@1: 62.5000 (50.3559)  Acc@5: 87.5000 (86.7559)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3100/4579]  eta: 0:08:30  Lr: 0.001875  Loss: 0.8375  Acc@1: 62.5000 (50.3809)  Acc@5: 93.7500 (86.7704)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3110/4579]  eta: 0:08:27  Lr: 0.001875  Loss: 1.5652  Acc@1: 56.2500 (50.3938)  Acc@5: 93.7500 (86.7808)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3120/4579]  eta: 0:08:23  Lr: 0.001875  Loss: 0.8139  Acc@1: 56.2500 (50.4346)  Acc@5: 93.7500 (86.8031)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3130/4579]  eta: 0:08:20  Lr: 0.001875  Loss: 1.3691  Acc@1: 56.2500 (50.4372)  Acc@5: 93.7500 (86.8113)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3140/4579]  eta: 0:08:16  Lr: 0.001875  Loss: 1.2112  Acc@1: 43.7500 (50.4238)  Acc@5: 87.5000 (86.8095)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3150/4579]  eta: 0:08:13  Lr: 0.001875  Loss: 1.6370  Acc@1: 50.0000 (50.4344)  Acc@5: 87.5000 (86.8137)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3160/4579]  eta: 0:08:09  Lr: 0.001875  Loss: 1.3553  Acc@1: 56.2500 (50.4627)  Acc@5: 93.7500 (86.8357)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3170/4579]  eta: 0:08:06  Lr: 0.001875  Loss: 1.3429  Acc@1: 56.2500 (50.4809)  Acc@5: 87.5000 (86.8240)  time: 0.3463  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3180/4579]  eta: 0:08:03  Lr: 0.001875  Loss: 1.0135  Acc@1: 50.0000 (50.4971)  Acc@5: 87.5000 (86.8261)  time: 0.3465  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3190/4579]  eta: 0:07:59  Lr: 0.001875  Loss: 1.6152  Acc@1: 50.0000 (50.4975)  Acc@5: 87.5000 (86.8341)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3200/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 0.8724  Acc@1: 50.0000 (50.5135)  Acc@5: 87.5000 (86.8400)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3210/4579]  eta: 0:07:52  Lr: 0.001875  Loss: 1.3396  Acc@1: 56.2500 (50.5528)  Acc@5: 87.5000 (86.8596)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3220/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 1.0081  Acc@1: 68.7500 (50.6015)  Acc@5: 87.5000 (86.8694)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3230/4579]  eta: 0:07:45  Lr: 0.001875  Loss: 1.3019  Acc@1: 62.5000 (50.6345)  Acc@5: 87.5000 (86.8771)  time: 0.3469  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3240/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 1.1397  Acc@1: 62.5000 (50.6672)  Acc@5: 87.5000 (86.8906)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3250/4579]  eta: 0:07:38  Lr: 0.001875  Loss: 1.2004  Acc@1: 62.5000 (50.7171)  Acc@5: 93.7500 (86.9098)  time: 0.3447  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3260/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 1.1388  Acc@1: 62.5000 (50.7494)  Acc@5: 87.5000 (86.9154)  time: 0.3451  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3270/4579]  eta: 0:07:31  Lr: 0.001875  Loss: 0.9957  Acc@1: 56.2500 (50.7796)  Acc@5: 87.5000 (86.9325)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3280/4579]  eta: 0:07:28  Lr: 0.001875  Loss: 1.5849  Acc@1: 56.2500 (50.7982)  Acc@5: 93.7500 (86.9361)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3290/4579]  eta: 0:07:25  Lr: 0.001875  Loss: 0.9463  Acc@1: 56.2500 (50.8128)  Acc@5: 81.2500 (86.9284)  time: 0.3448  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3300/4579]  eta: 0:07:21  Lr: 0.001875  Loss: 1.7095  Acc@1: 56.2500 (50.8388)  Acc@5: 87.5000 (86.9434)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3310/4579]  eta: 0:07:18  Lr: 0.001875  Loss: 1.1082  Acc@1: 62.5000 (50.8702)  Acc@5: 93.7500 (86.9488)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3320/4579]  eta: 0:07:14  Lr: 0.001875  Loss: 1.2190  Acc@1: 56.2500 (50.8921)  Acc@5: 87.5000 (86.9542)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3330/4579]  eta: 0:07:11  Lr: 0.001875  Loss: 0.5246  Acc@1: 62.5000 (50.9363)  Acc@5: 93.7500 (86.9615)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3340/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 1.2924  Acc@1: 56.2500 (50.9316)  Acc@5: 87.5000 (86.9687)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3350/4579]  eta: 0:07:04  Lr: 0.001875  Loss: 1.0052  Acc@1: 56.2500 (50.9605)  Acc@5: 87.5000 (86.9722)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3360/4579]  eta: 0:07:00  Lr: 0.001875  Loss: 0.8788  Acc@1: 62.5000 (50.9800)  Acc@5: 87.5000 (86.9775)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3370/4579]  eta: 0:06:57  Lr: 0.001875  Loss: 1.3286  Acc@1: 56.2500 (50.9993)  Acc@5: 87.5000 (86.9809)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3380/4579]  eta: 0:06:53  Lr: 0.001875  Loss: 1.1117  Acc@1: 56.2500 (51.0278)  Acc@5: 87.5000 (86.9824)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3390/4579]  eta: 0:06:50  Lr: 0.001875  Loss: 0.7446  Acc@1: 56.2500 (51.0543)  Acc@5: 87.5000 (86.9876)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3400/4579]  eta: 0:06:47  Lr: 0.001875  Loss: 1.4871  Acc@1: 56.2500 (51.0677)  Acc@5: 87.5000 (87.0001)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/4579]  eta: 0:06:43  Lr: 0.001875  Loss: 1.1222  Acc@1: 56.2500 (51.0811)  Acc@5: 87.5000 (86.9961)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3420/4579]  eta: 0:06:40  Lr: 0.001875  Loss: 1.1197  Acc@1: 56.2500 (51.1090)  Acc@5: 87.5000 (87.0086)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3430/4579]  eta: 0:06:36  Lr: 0.001875  Loss: 0.7866  Acc@1: 62.5000 (51.1440)  Acc@5: 93.7500 (87.0209)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3440/4579]  eta: 0:06:33  Lr: 0.001875  Loss: 1.1197  Acc@1: 56.2500 (51.1497)  Acc@5: 87.5000 (87.0169)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3450/4579]  eta: 0:06:29  Lr: 0.001875  Loss: 1.2199  Acc@1: 56.2500 (51.1718)  Acc@5: 87.5000 (87.0255)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3460/4579]  eta: 0:06:26  Lr: 0.001875  Loss: 1.0490  Acc@1: 56.2500 (51.1864)  Acc@5: 87.5000 (87.0269)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3470/4579]  eta: 0:06:22  Lr: 0.001875  Loss: 1.6131  Acc@1: 62.5000 (51.2064)  Acc@5: 87.5000 (87.0372)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3480/4579]  eta: 0:06:19  Lr: 0.001875  Loss: 1.3648  Acc@1: 50.0000 (51.2048)  Acc@5: 87.5000 (87.0332)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3490/4579]  eta: 0:06:15  Lr: 0.001875  Loss: 0.9952  Acc@1: 50.0000 (51.2210)  Acc@5: 87.5000 (87.0435)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3500/4579]  eta: 0:06:12  Lr: 0.001875  Loss: 1.4366  Acc@1: 56.2500 (51.2550)  Acc@5: 87.5000 (87.0555)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3510/4579]  eta: 0:06:09  Lr: 0.001875  Loss: 1.4291  Acc@1: 56.2500 (51.2585)  Acc@5: 87.5000 (87.0657)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3520/4579]  eta: 0:06:05  Lr: 0.001875  Loss: 1.4518  Acc@1: 56.2500 (51.2905)  Acc@5: 93.7500 (87.0758)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3530/4579]  eta: 0:06:02  Lr: 0.001875  Loss: 1.1242  Acc@1: 56.2500 (51.3045)  Acc@5: 93.7500 (87.0894)  time: 0.3440  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3540/4579]  eta: 0:05:58  Lr: 0.001875  Loss: 0.9959  Acc@1: 56.2500 (51.3185)  Acc@5: 93.7500 (87.1029)  time: 0.3444  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3550/4579]  eta: 0:05:55  Lr: 0.001875  Loss: 1.8710  Acc@1: 56.2500 (51.3394)  Acc@5: 93.7500 (87.1110)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3560/4579]  eta: 0:05:51  Lr: 0.001875  Loss: 1.3937  Acc@1: 56.2500 (51.3602)  Acc@5: 93.7500 (87.1209)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3570/4579]  eta: 0:05:48  Lr: 0.001875  Loss: 2.0511  Acc@1: 50.0000 (51.3704)  Acc@5: 93.7500 (87.1202)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3580/4579]  eta: 0:05:44  Lr: 0.001875  Loss: 1.0659  Acc@1: 50.0000 (51.3823)  Acc@5: 93.7500 (87.1265)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3590/4579]  eta: 0:05:41  Lr: 0.001875  Loss: 0.9060  Acc@1: 56.2500 (51.3976)  Acc@5: 93.7500 (87.1345)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3600/4579]  eta: 0:05:37  Lr: 0.001875  Loss: 1.2147  Acc@1: 56.2500 (51.4250)  Acc@5: 87.5000 (87.1407)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3610/4579]  eta: 0:05:34  Lr: 0.001875  Loss: 1.1107  Acc@1: 62.5000 (51.4556)  Acc@5: 93.7500 (87.1573)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3620/4579]  eta: 0:05:31  Lr: 0.001875  Loss: 1.7856  Acc@1: 56.2500 (51.4516)  Acc@5: 93.7500 (87.1600)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3630/4579]  eta: 0:05:27  Lr: 0.001875  Loss: 1.3416  Acc@1: 56.2500 (51.4683)  Acc@5: 93.7500 (87.1747)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3640/4579]  eta: 0:05:24  Lr: 0.001875  Loss: 1.2863  Acc@1: 62.5000 (51.4951)  Acc@5: 93.7500 (87.1790)  time: 0.3450  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3650/4579]  eta: 0:05:20  Lr: 0.001875  Loss: 1.1675  Acc@1: 56.2500 (51.5064)  Acc@5: 93.7500 (87.1884)  time: 0.3449  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3660/4579]  eta: 0:05:17  Lr: 0.001875  Loss: 1.1279  Acc@1: 62.5000 (51.5365)  Acc@5: 93.7500 (87.2081)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3670/4579]  eta: 0:05:13  Lr: 0.001875  Loss: 2.1972  Acc@1: 62.5000 (51.5561)  Acc@5: 93.7500 (87.2140)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3680/4579]  eta: 0:05:10  Lr: 0.001875  Loss: 0.9267  Acc@1: 62.5000 (51.5909)  Acc@5: 93.7500 (87.2300)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3690/4579]  eta: 0:05:06  Lr: 0.001875  Loss: 0.9761  Acc@1: 62.5000 (51.6154)  Acc@5: 93.7500 (87.2392)  time: 0.3445  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3700/4579]  eta: 0:05:03  Lr: 0.001875  Loss: 1.4861  Acc@1: 56.2500 (51.6296)  Acc@5: 87.5000 (87.2433)  time: 0.3455  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3710/4579]  eta: 0:04:59  Lr: 0.001875  Loss: 1.2933  Acc@1: 56.2500 (51.6454)  Acc@5: 87.5000 (87.2474)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3720/4579]  eta: 0:04:56  Lr: 0.001875  Loss: 1.0073  Acc@1: 56.2500 (51.6595)  Acc@5: 87.5000 (87.2581)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3730/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 1.3175  Acc@1: 62.5000 (51.6768)  Acc@5: 93.7500 (87.2638)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3740/4579]  eta: 0:04:49  Lr: 0.001875  Loss: 1.1802  Acc@1: 62.5000 (51.7024)  Acc@5: 93.7500 (87.2728)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3750/4579]  eta: 0:04:46  Lr: 0.001875  Loss: 1.7072  Acc@1: 56.2500 (51.7012)  Acc@5: 87.5000 (87.2734)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3760/4579]  eta: 0:04:42  Lr: 0.001875  Loss: 1.1887  Acc@1: 56.2500 (51.7166)  Acc@5: 93.7500 (87.2890)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3770/4579]  eta: 0:04:39  Lr: 0.001875  Loss: 0.8896  Acc@1: 62.5000 (51.7369)  Acc@5: 93.7500 (87.2928)  time: 0.3454  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3780/4579]  eta: 0:04:35  Lr: 0.001875  Loss: 1.2251  Acc@1: 62.5000 (51.7654)  Acc@5: 93.7500 (87.3132)  time: 0.3486  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [3790/4579]  eta: 0:04:32  Lr: 0.001875  Loss: 1.3673  Acc@1: 56.2500 (51.7838)  Acc@5: 93.7500 (87.3302)  time: 0.3479  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3800/4579]  eta: 0:04:28  Lr: 0.001875  Loss: 1.2631  Acc@1: 56.2500 (51.8022)  Acc@5: 93.7500 (87.3405)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3810/4579]  eta: 0:04:25  Lr: 0.001875  Loss: 2.0340  Acc@1: 56.2500 (51.8122)  Acc@5: 87.5000 (87.3458)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3820/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 0.9004  Acc@1: 56.2500 (51.8205)  Acc@5: 87.5000 (87.3544)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3830/4579]  eta: 0:04:18  Lr: 0.001875  Loss: 1.2374  Acc@1: 56.2500 (51.8354)  Acc@5: 93.7500 (87.3679)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3840/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 0.9725  Acc@1: 62.5000 (51.8713)  Acc@5: 93.7500 (87.3780)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3850/4579]  eta: 0:04:11  Lr: 0.001875  Loss: 1.8337  Acc@1: 62.5000 (51.8826)  Acc@5: 93.7500 (87.3929)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3860/4579]  eta: 0:04:08  Lr: 0.001875  Loss: 0.9053  Acc@1: 56.2500 (51.9020)  Acc@5: 87.5000 (87.3932)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:04  Lr: 0.001875  Loss: 1.0876  Acc@1: 56.2500 (51.9197)  Acc@5: 87.5000 (87.3999)  time: 0.3455  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:01  Lr: 0.001875  Loss: 1.2271  Acc@1: 62.5000 (51.9438)  Acc@5: 93.7500 (87.4066)  time: 0.3455  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3890/4579]  eta: 0:03:57  Lr: 0.001875  Loss: 1.3374  Acc@1: 56.2500 (51.9420)  Acc@5: 87.5000 (87.4052)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3900/4579]  eta: 0:03:54  Lr: 0.001875  Loss: 0.9153  Acc@1: 56.2500 (51.9658)  Acc@5: 93.7500 (87.4151)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3910/4579]  eta: 0:03:50  Lr: 0.001875  Loss: 1.1685  Acc@1: 62.5000 (51.9848)  Acc@5: 93.7500 (87.4201)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3920/4579]  eta: 0:03:47  Lr: 0.001875  Loss: 1.2836  Acc@1: 56.2500 (51.9749)  Acc@5: 87.5000 (87.4219)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3930/4579]  eta: 0:03:44  Lr: 0.001875  Loss: 1.3409  Acc@1: 50.0000 (51.9699)  Acc@5: 87.5000 (87.4237)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3940/4579]  eta: 0:03:40  Lr: 0.001875  Loss: 1.1191  Acc@1: 50.0000 (51.9871)  Acc@5: 93.7500 (87.4382)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3950/4579]  eta: 0:03:37  Lr: 0.001875  Loss: 0.6594  Acc@1: 50.0000 (51.9916)  Acc@5: 93.7500 (87.4336)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3960/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 0.9578  Acc@1: 50.0000 (52.0213)  Acc@5: 93.7500 (87.4527)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3970/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 1.3638  Acc@1: 62.5000 (52.0461)  Acc@5: 93.7500 (87.4575)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3980/4579]  eta: 0:03:26  Lr: 0.001875  Loss: 1.6033  Acc@1: 62.5000 (52.0739)  Acc@5: 87.5000 (87.4655)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3990/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 1.3352  Acc@1: 56.2500 (52.0828)  Acc@5: 93.7500 (87.4687)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4000/4579]  eta: 0:03:19  Lr: 0.001875  Loss: 1.3081  Acc@1: 56.2500 (52.1010)  Acc@5: 87.5000 (87.4813)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:16  Lr: 0.001875  Loss: 1.6946  Acc@1: 56.2500 (52.1161)  Acc@5: 87.5000 (87.4875)  time: 0.3463  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:12  Lr: 0.001875  Loss: 0.9641  Acc@1: 56.2500 (52.1388)  Acc@5: 93.7500 (87.4969)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 0.9522  Acc@1: 62.5000 (52.1552)  Acc@5: 93.7500 (87.5047)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:06  Lr: 0.001875  Loss: 1.9055  Acc@1: 62.5000 (52.1715)  Acc@5: 93.7500 (87.5108)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 1.6565  Acc@1: 56.2500 (52.1785)  Acc@5: 93.7500 (87.5123)  time: 0.3445  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4060/4579]  eta: 0:02:59  Lr: 0.001875  Loss: 1.8816  Acc@1: 56.2500 (52.1854)  Acc@5: 87.5000 (87.5108)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4070/4579]  eta: 0:02:55  Lr: 0.001875  Loss: 1.0818  Acc@1: 56.2500 (52.2031)  Acc@5: 87.5000 (87.5154)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4080/4579]  eta: 0:02:52  Lr: 0.001875  Loss: 1.7103  Acc@1: 56.2500 (52.2145)  Acc@5: 87.5000 (87.5168)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4090/4579]  eta: 0:02:48  Lr: 0.001875  Loss: 1.1164  Acc@1: 56.2500 (52.2320)  Acc@5: 93.7500 (87.5244)  time: 0.3455  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4100/4579]  eta: 0:02:45  Lr: 0.001875  Loss: 1.0926  Acc@1: 62.5000 (52.2540)  Acc@5: 93.7500 (87.5396)  time: 0.3471  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4110/4579]  eta: 0:02:41  Lr: 0.001875  Loss: 1.3499  Acc@1: 56.2500 (52.2698)  Acc@5: 87.5000 (87.5410)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4120/4579]  eta: 0:02:38  Lr: 0.001875  Loss: 1.0774  Acc@1: 56.2500 (52.2734)  Acc@5: 87.5000 (87.5440)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4130/4579]  eta: 0:02:35  Lr: 0.001875  Loss: 0.6780  Acc@1: 56.2500 (52.2906)  Acc@5: 87.5000 (87.5499)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4140/4579]  eta: 0:02:31  Lr: 0.001875  Loss: 0.7868  Acc@1: 62.5000 (52.3198)  Acc@5: 93.7500 (87.5649)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:28  Lr: 0.001875  Loss: 1.5844  Acc@1: 68.7500 (52.3383)  Acc@5: 93.7500 (87.5738)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:24  Lr: 0.001875  Loss: 1.0709  Acc@1: 56.2500 (52.3567)  Acc@5: 87.5000 (87.5766)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:21  Lr: 0.001875  Loss: 1.6065  Acc@1: 56.2500 (52.3645)  Acc@5: 87.5000 (87.5704)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:17  Lr: 0.001875  Loss: 1.3024  Acc@1: 56.2500 (52.3798)  Acc@5: 87.5000 (87.5792)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:14  Lr: 0.001875  Loss: 1.3781  Acc@1: 62.5000 (52.3995)  Acc@5: 93.7500 (87.5910)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:10  Lr: 0.001875  Loss: 1.3290  Acc@1: 56.2500 (52.3938)  Acc@5: 93.7500 (87.5922)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:07  Lr: 0.001875  Loss: 2.4294  Acc@1: 56.2500 (52.4178)  Acc@5: 87.5000 (87.5935)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:03  Lr: 0.001875  Loss: 1.3184  Acc@1: 62.5000 (52.4446)  Acc@5: 87.5000 (87.5992)  time: 0.3455  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:00  Lr: 0.001875  Loss: 1.1339  Acc@1: 62.5000 (52.4566)  Acc@5: 93.7500 (87.6093)  time: 0.3462  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 1.3847  Acc@1: 62.5000 (52.4744)  Acc@5: 93.7500 (87.6164)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4250/4579]  eta: 0:01:53  Lr: 0.001875  Loss: 1.5449  Acc@1: 56.2500 (52.4803)  Acc@5: 87.5000 (87.6147)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: 0.7027  Acc@1: 56.2500 (52.5067)  Acc@5: 87.5000 (87.6173)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4270/4579]  eta: 0:01:46  Lr: 0.001875  Loss: 0.7069  Acc@1: 62.5000 (52.5389)  Acc@5: 93.7500 (87.6273)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: 0.9026  Acc@1: 68.7500 (52.5710)  Acc@5: 93.7500 (87.6402)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:39  Lr: 0.001875  Loss: 1.0609  Acc@1: 62.5000 (52.5810)  Acc@5: 93.7500 (87.6529)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 0.5760  Acc@1: 56.2500 (52.6084)  Acc@5: 93.7500 (87.6569)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:32  Lr: 0.001875  Loss: 0.7961  Acc@1: 56.2500 (52.6140)  Acc@5: 87.5000 (87.6609)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:29  Lr: 0.001875  Loss: 1.7101  Acc@1: 56.2500 (52.6325)  Acc@5: 87.5000 (87.6606)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:25  Lr: 0.001875  Loss: 1.3396  Acc@1: 56.2500 (52.6466)  Acc@5: 87.5000 (87.6732)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:22  Lr: 0.001875  Loss: 0.6936  Acc@1: 56.2500 (52.6664)  Acc@5: 93.7500 (87.6828)  time: 0.3461  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: 1.4147  Acc@1: 62.5000 (52.6890)  Acc@5: 93.7500 (87.6910)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:15  Lr: 0.001875  Loss: 1.3455  Acc@1: 62.5000 (52.7115)  Acc@5: 93.7500 (87.6949)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: 1.1583  Acc@1: 56.2500 (52.7239)  Acc@5: 87.5000 (87.6945)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:08  Lr: 0.001875  Loss: 0.8018  Acc@1: 56.2500 (52.7191)  Acc@5: 87.5000 (87.6954)  time: 0.3451  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 0.6559  Acc@1: 56.2500 (52.7371)  Acc@5: 93.7500 (87.7050)  time: 0.3452  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:01  Lr: 0.001875  Loss: 1.2350  Acc@1: 56.2500 (52.7522)  Acc@5: 87.5000 (87.7073)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: 1.4435  Acc@1: 62.5000 (52.7686)  Acc@5: 87.5000 (87.7168)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4420/4579]  eta: 0:00:54  Lr: 0.001875  Loss: 1.2036  Acc@1: 62.5000 (52.7878)  Acc@5: 87.5000 (87.7220)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 1.6496  Acc@1: 62.5000 (52.7858)  Acc@5: 87.5000 (87.7299)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:47  Lr: 0.001875  Loss: 1.1424  Acc@1: 56.2500 (52.8105)  Acc@5: 93.7500 (87.7308)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 1.4674  Acc@1: 68.7500 (52.8308)  Acc@5: 93.7500 (87.7359)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 1.1293  Acc@1: 62.5000 (52.8371)  Acc@5: 87.5000 (87.7326)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: 0.8688  Acc@1: 50.0000 (52.8321)  Acc@5: 87.5000 (87.7432)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: 0.7775  Acc@1: 50.0000 (52.8523)  Acc@5: 93.7500 (87.7552)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: 0.9223  Acc@1: 62.5000 (52.8724)  Acc@5: 87.5000 (87.7547)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: 1.4748  Acc@1: 56.2500 (52.8841)  Acc@5: 87.5000 (87.7569)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: 1.3629  Acc@1: 56.2500 (52.8902)  Acc@5: 87.5000 (87.7605)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 1.2083  Acc@1: 56.2500 (52.9045)  Acc@5: 87.5000 (87.7696)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:16  Lr: 0.001875  Loss: 1.6309  Acc@1: 56.2500 (52.9077)  Acc@5: 93.7500 (87.7704)  time: 0.3454  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 1.3206  Acc@1: 56.2500 (52.9192)  Acc@5: 87.5000 (87.7753)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 0.9182  Acc@1: 56.2500 (52.9375)  Acc@5: 87.5000 (87.7802)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 1.1395  Acc@1: 56.2500 (52.9434)  Acc@5: 87.5000 (87.7809)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 1.4656  Acc@1: 56.2500 (52.9616)  Acc@5: 93.7500 (87.7953)  time: 0.3463  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 2.2498  Acc@1: 56.2500 (52.9642)  Acc@5: 93.7500 (87.7991)  time: 0.3475  data: 0.0017  max mem: 2500
Train: Epoch[1/5] Total time: 0:26:21 (0.3454 s / it)
Averaged stats: Lr: 0.001875  Loss: 2.2498  Acc@1: 56.2500 (52.9642)  Acc@5: 93.7500 (87.7991)
Train: Epoch[2/5]  [   0/4579]  eta: 0:52:09  Lr: 0.001875  Loss: 1.0549  Acc@1: 56.2500 (56.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6834  data: 0.3349  max mem: 2500
Train: Epoch[2/5]  [  10/4579]  eta: 0:28:35  Lr: 0.001875  Loss: 0.9707  Acc@1: 56.2500 (56.8182)  Acc@5: 87.5000 (89.2045)  time: 0.3754  data: 0.0311  max mem: 2500
Train: Epoch[2/5]  [  20/4579]  eta: 0:27:29  Lr: 0.001875  Loss: 0.9293  Acc@1: 56.2500 (59.2262)  Acc@5: 87.5000 (90.1786)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  30/4579]  eta: 0:27:00  Lr: 0.001875  Loss: 1.8329  Acc@1: 56.2500 (57.6613)  Acc@5: 93.7500 (90.3226)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  40/4579]  eta: 0:26:46  Lr: 0.001875  Loss: 1.5241  Acc@1: 50.0000 (57.6220)  Acc@5: 87.5000 (90.0915)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  50/4579]  eta: 0:26:34  Lr: 0.001875  Loss: 1.1716  Acc@1: 56.2500 (57.8431)  Acc@5: 87.5000 (89.8284)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  60/4579]  eta: 0:26:25  Lr: 0.001875  Loss: 1.2209  Acc@1: 62.5000 (58.4016)  Acc@5: 87.5000 (89.9590)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [  70/4579]  eta: 0:26:18  Lr: 0.001875  Loss: 1.2751  Acc@1: 62.5000 (58.2746)  Acc@5: 93.7500 (89.9648)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [  80/4579]  eta: 0:26:11  Lr: 0.001875  Loss: 1.8966  Acc@1: 56.2500 (58.1019)  Acc@5: 93.7500 (89.7377)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  90/4579]  eta: 0:26:05  Lr: 0.001875  Loss: 1.2678  Acc@1: 56.2500 (58.3104)  Acc@5: 93.7500 (89.9725)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 100/4579]  eta: 0:26:00  Lr: 0.001875  Loss: 0.9468  Acc@1: 62.5000 (58.8490)  Acc@5: 93.7500 (90.2228)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 110/4579]  eta: 0:25:55  Lr: 0.001875  Loss: 1.1182  Acc@1: 62.5000 (58.6712)  Acc@5: 93.7500 (90.1464)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 120/4579]  eta: 0:25:51  Lr: 0.001875  Loss: 1.5473  Acc@1: 56.2500 (58.6777)  Acc@5: 87.5000 (89.9277)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 130/4579]  eta: 0:25:46  Lr: 0.001875  Loss: 1.2850  Acc@1: 56.2500 (58.3015)  Acc@5: 87.5000 (89.8378)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 140/4579]  eta: 0:25:41  Lr: 0.001875  Loss: 1.0671  Acc@1: 56.2500 (58.4220)  Acc@5: 87.5000 (89.7606)  time: 0.3436  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 150/4579]  eta: 0:25:38  Lr: 0.001875  Loss: 1.0145  Acc@1: 62.5000 (58.4437)  Acc@5: 87.5000 (89.9007)  time: 0.3454  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 160/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 1.2903  Acc@1: 50.0000 (58.0357)  Acc@5: 93.7500 (90.0233)  time: 0.3459  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 170/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 1.2894  Acc@1: 50.0000 (57.8947)  Acc@5: 87.5000 (89.9854)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 180/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 1.6842  Acc@1: 62.5000 (58.2528)  Acc@5: 87.5000 (90.0552)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 190/4579]  eta: 0:25:21  Lr: 0.001875  Loss: 1.2819  Acc@1: 62.5000 (58.3442)  Acc@5: 87.5000 (89.9869)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 200/4579]  eta: 0:25:17  Lr: 0.001875  Loss: 1.2411  Acc@1: 56.2500 (58.3644)  Acc@5: 87.5000 (89.9876)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 210/4579]  eta: 0:25:13  Lr: 0.001875  Loss: 1.4076  Acc@1: 62.5000 (58.6789)  Acc@5: 87.5000 (90.0474)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 220/4579]  eta: 0:25:09  Lr: 0.001875  Loss: 1.5255  Acc@1: 62.5000 (58.9084)  Acc@5: 87.5000 (89.9604)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 230/4579]  eta: 0:25:06  Lr: 0.001875  Loss: 0.9012  Acc@1: 62.5000 (59.1721)  Acc@5: 93.7500 (90.1515)  time: 0.3451  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 240/4579]  eta: 0:25:02  Lr: 0.001875  Loss: 0.7027  Acc@1: 68.7500 (59.4658)  Acc@5: 93.7500 (90.1712)  time: 0.3468  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 250/4579]  eta: 0:24:59  Lr: 0.001875  Loss: 1.5552  Acc@1: 62.5000 (59.4124)  Acc@5: 93.7500 (90.1145)  time: 0.3459  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 260/4579]  eta: 0:24:55  Lr: 0.001875  Loss: 1.0284  Acc@1: 62.5000 (59.6025)  Acc@5: 93.7500 (90.3257)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 270/4579]  eta: 0:24:52  Lr: 0.001875  Loss: 1.1405  Acc@1: 62.5000 (59.6172)  Acc@5: 93.7500 (90.4059)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 280/4579]  eta: 0:24:48  Lr: 0.001875  Loss: 1.2061  Acc@1: 62.5000 (59.8532)  Acc@5: 93.7500 (90.3692)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 290/4579]  eta: 0:24:45  Lr: 0.001875  Loss: 1.3839  Acc@1: 62.5000 (59.9442)  Acc@5: 93.7500 (90.3136)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 300/4579]  eta: 0:24:41  Lr: 0.001875  Loss: 1.1772  Acc@1: 62.5000 (60.0498)  Acc@5: 93.7500 (90.3654)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 310/4579]  eta: 0:24:37  Lr: 0.001875  Loss: 1.1987  Acc@1: 62.5000 (60.2492)  Acc@5: 93.7500 (90.4140)  time: 0.3452  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 320/4579]  eta: 0:24:34  Lr: 0.001875  Loss: 1.2479  Acc@1: 56.2500 (59.9883)  Acc@5: 93.7500 (90.3816)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 330/4579]  eta: 0:24:30  Lr: 0.001875  Loss: 1.0987  Acc@1: 56.2500 (60.0831)  Acc@5: 93.7500 (90.3701)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 340/4579]  eta: 0:24:27  Lr: 0.001875  Loss: 1.2034  Acc@1: 62.5000 (59.9157)  Acc@5: 87.5000 (90.3409)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 350/4579]  eta: 0:24:23  Lr: 0.001875  Loss: 1.2008  Acc@1: 56.2500 (59.8647)  Acc@5: 93.7500 (90.4380)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 360/4579]  eta: 0:24:20  Lr: 0.001875  Loss: 1.3954  Acc@1: 56.2500 (59.8338)  Acc@5: 93.7500 (90.4259)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 370/4579]  eta: 0:24:16  Lr: 0.001875  Loss: 1.4019  Acc@1: 62.5000 (59.9225)  Acc@5: 87.5000 (90.4481)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 380/4579]  eta: 0:24:13  Lr: 0.001875  Loss: 1.4509  Acc@1: 56.2500 (59.9245)  Acc@5: 93.7500 (90.4856)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 390/4579]  eta: 0:24:09  Lr: 0.001875  Loss: 1.6795  Acc@1: 56.2500 (59.9425)  Acc@5: 87.5000 (90.4412)  time: 0.3457  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 400/4579]  eta: 0:24:05  Lr: 0.001875  Loss: 0.5712  Acc@1: 56.2500 (60.0530)  Acc@5: 93.7500 (90.4925)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 410/4579]  eta: 0:24:02  Lr: 0.001875  Loss: 0.9255  Acc@1: 62.5000 (60.2494)  Acc@5: 93.7500 (90.5262)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 420/4579]  eta: 0:23:59  Lr: 0.001875  Loss: 1.2292  Acc@1: 62.5000 (60.2286)  Acc@5: 87.5000 (90.4543)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 430/4579]  eta: 0:23:55  Lr: 0.001875  Loss: 1.5502  Acc@1: 62.5000 (60.1798)  Acc@5: 87.5000 (90.4582)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 440/4579]  eta: 0:23:51  Lr: 0.001875  Loss: 1.0684  Acc@1: 62.5000 (60.2891)  Acc@5: 93.7500 (90.5329)  time: 0.3441  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 450/4579]  eta: 0:23:48  Lr: 0.001875  Loss: 0.9699  Acc@1: 62.5000 (60.2688)  Acc@5: 93.7500 (90.5072)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 460/4579]  eta: 0:23:44  Lr: 0.001875  Loss: 0.9580  Acc@1: 62.5000 (60.4121)  Acc@5: 87.5000 (90.4962)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 470/4579]  eta: 0:23:41  Lr: 0.001875  Loss: 1.8611  Acc@1: 62.5000 (60.4299)  Acc@5: 87.5000 (90.5122)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 480/4579]  eta: 0:23:37  Lr: 0.001875  Loss: 0.6549  Acc@1: 68.7500 (60.5639)  Acc@5: 93.7500 (90.5275)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 490/4579]  eta: 0:23:34  Lr: 0.001875  Loss: 1.1586  Acc@1: 62.5000 (60.5906)  Acc@5: 93.7500 (90.5041)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 500/4579]  eta: 0:23:30  Lr: 0.001875  Loss: 0.9810  Acc@1: 62.5000 (60.5289)  Acc@5: 87.5000 (90.4940)  time: 0.3444  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 510/4579]  eta: 0:23:27  Lr: 0.001875  Loss: 1.4516  Acc@1: 56.2500 (60.4452)  Acc@5: 93.7500 (90.5088)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 520/4579]  eta: 0:23:23  Lr: 0.001875  Loss: 1.6020  Acc@1: 56.2500 (60.4367)  Acc@5: 87.5000 (90.4391)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 530/4579]  eta: 0:23:19  Lr: 0.001875  Loss: 1.8894  Acc@1: 62.5000 (60.3814)  Acc@5: 81.2500 (90.3249)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 540/4579]  eta: 0:23:16  Lr: 0.001875  Loss: 1.1328  Acc@1: 62.5000 (60.4090)  Acc@5: 87.5000 (90.3189)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 550/4579]  eta: 0:23:13  Lr: 0.001875  Loss: 0.8380  Acc@1: 62.5000 (60.4696)  Acc@5: 87.5000 (90.3131)  time: 0.3460  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 560/4579]  eta: 0:23:09  Lr: 0.001875  Loss: 1.6598  Acc@1: 62.5000 (60.4612)  Acc@5: 93.7500 (90.3186)  time: 0.3463  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 570/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 1.1749  Acc@1: 62.5000 (60.5517)  Acc@5: 93.7500 (90.3240)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 580/4579]  eta: 0:23:02  Lr: 0.001875  Loss: 1.3659  Acc@1: 62.5000 (60.4991)  Acc@5: 93.7500 (90.2861)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 590/4579]  eta: 0:22:58  Lr: 0.001875  Loss: 1.4258  Acc@1: 56.2500 (60.4061)  Acc@5: 87.5000 (90.2707)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 600/4579]  eta: 0:22:55  Lr: 0.001875  Loss: 1.7049  Acc@1: 56.2500 (60.4305)  Acc@5: 93.7500 (90.2974)  time: 0.3454  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 610/4579]  eta: 0:22:52  Lr: 0.001875  Loss: 0.5140  Acc@1: 62.5000 (60.5667)  Acc@5: 93.7500 (90.3130)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 620/4579]  eta: 0:22:48  Lr: 0.001875  Loss: 1.2224  Acc@1: 68.7500 (60.6683)  Acc@5: 93.7500 (90.3885)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 630/4579]  eta: 0:22:45  Lr: 0.001875  Loss: 0.9927  Acc@1: 62.5000 (60.6577)  Acc@5: 93.7500 (90.4319)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 640/4579]  eta: 0:22:41  Lr: 0.001875  Loss: 0.9363  Acc@1: 62.5000 (60.6767)  Acc@5: 93.7500 (90.4544)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 650/4579]  eta: 0:22:38  Lr: 0.001875  Loss: 1.4675  Acc@1: 62.5000 (60.6759)  Acc@5: 93.7500 (90.4570)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 660/4579]  eta: 0:22:34  Lr: 0.001875  Loss: 1.5286  Acc@1: 56.2500 (60.5333)  Acc@5: 87.5000 (90.4123)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 670/4579]  eta: 0:22:31  Lr: 0.001875  Loss: 1.2925  Acc@1: 62.5000 (60.6092)  Acc@5: 87.5000 (90.4434)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 680/4579]  eta: 0:22:28  Lr: 0.001875  Loss: 0.8417  Acc@1: 68.7500 (60.7012)  Acc@5: 93.7500 (90.4827)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 690/4579]  eta: 0:22:24  Lr: 0.001875  Loss: 0.5692  Acc@1: 68.7500 (60.8267)  Acc@5: 93.7500 (90.4938)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 700/4579]  eta: 0:22:21  Lr: 0.001875  Loss: 0.7670  Acc@1: 68.7500 (60.9486)  Acc@5: 93.7500 (90.5225)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 710/4579]  eta: 0:22:17  Lr: 0.001875  Loss: 1.7155  Acc@1: 68.7500 (60.9617)  Acc@5: 93.7500 (90.5239)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 720/4579]  eta: 0:22:14  Lr: 0.001875  Loss: 1.0981  Acc@1: 56.2500 (60.9310)  Acc@5: 93.7500 (90.5426)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 730/4579]  eta: 0:22:10  Lr: 0.001875  Loss: 1.2708  Acc@1: 56.2500 (60.8670)  Acc@5: 93.7500 (90.5523)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 740/4579]  eta: 0:22:07  Lr: 0.001875  Loss: 0.7499  Acc@1: 56.2500 (60.8300)  Acc@5: 87.5000 (90.5280)  time: 0.3442  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 750/4579]  eta: 0:22:03  Lr: 0.001875  Loss: 1.6715  Acc@1: 56.2500 (60.7856)  Acc@5: 87.5000 (90.5126)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 760/4579]  eta: 0:22:00  Lr: 0.001875  Loss: 0.6516  Acc@1: 62.5000 (60.7342)  Acc@5: 87.5000 (90.4977)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 770/4579]  eta: 0:21:56  Lr: 0.001875  Loss: 1.8693  Acc@1: 56.2500 (60.7247)  Acc@5: 87.5000 (90.4831)  time: 0.3445  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 780/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 1.2005  Acc@1: 56.2500 (60.7234)  Acc@5: 87.5000 (90.4930)  time: 0.3439  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 790/4579]  eta: 0:21:49  Lr: 0.001875  Loss: 1.0719  Acc@1: 56.2500 (60.7143)  Acc@5: 87.5000 (90.4630)  time: 0.3449  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 800/4579]  eta: 0:21:46  Lr: 0.001875  Loss: 0.8365  Acc@1: 62.5000 (60.7678)  Acc@5: 93.7500 (90.4963)  time: 0.3452  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 810/4579]  eta: 0:21:42  Lr: 0.001875  Loss: 1.2515  Acc@1: 62.5000 (60.6967)  Acc@5: 87.5000 (90.4516)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 820/4579]  eta: 0:21:39  Lr: 0.001875  Loss: 0.8739  Acc@1: 62.5000 (60.7719)  Acc@5: 87.5000 (90.4689)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 830/4579]  eta: 0:21:35  Lr: 0.001875  Loss: 1.2969  Acc@1: 68.7500 (60.7476)  Acc@5: 87.5000 (90.4031)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 840/4579]  eta: 0:21:32  Lr: 0.001875  Loss: 1.7726  Acc@1: 62.5000 (60.7759)  Acc@5: 87.5000 (90.3835)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 850/4579]  eta: 0:21:28  Lr: 0.001875  Loss: 1.4458  Acc@1: 62.5000 (60.8035)  Acc@5: 87.5000 (90.3569)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 860/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 1.3147  Acc@1: 62.5000 (60.8014)  Acc@5: 87.5000 (90.3383)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 870/4579]  eta: 0:21:21  Lr: 0.001875  Loss: 1.2709  Acc@1: 56.2500 (60.7563)  Acc@5: 87.5000 (90.3129)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 880/4579]  eta: 0:21:18  Lr: 0.001875  Loss: 1.4190  Acc@1: 62.5000 (60.7477)  Acc@5: 93.7500 (90.3590)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 890/4579]  eta: 0:21:14  Lr: 0.001875  Loss: 1.2834  Acc@1: 56.2500 (60.7043)  Acc@5: 93.7500 (90.3479)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 900/4579]  eta: 0:21:11  Lr: 0.001875  Loss: 1.1875  Acc@1: 56.2500 (60.7103)  Acc@5: 87.5000 (90.3441)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 910/4579]  eta: 0:21:07  Lr: 0.001875  Loss: 1.3619  Acc@1: 62.5000 (60.7025)  Acc@5: 87.5000 (90.3060)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 920/4579]  eta: 0:21:04  Lr: 0.001875  Loss: 1.4831  Acc@1: 62.5000 (60.7356)  Acc@5: 93.7500 (90.3637)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 930/4579]  eta: 0:21:00  Lr: 0.001875  Loss: 1.3701  Acc@1: 62.5000 (60.7479)  Acc@5: 93.7500 (90.3934)  time: 0.3453  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 940/4579]  eta: 0:20:57  Lr: 0.001875  Loss: 1.5522  Acc@1: 62.5000 (60.8063)  Acc@5: 93.7500 (90.3826)  time: 0.3447  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 950/4579]  eta: 0:20:53  Lr: 0.001875  Loss: 0.8562  Acc@1: 68.7500 (60.8964)  Acc@5: 93.7500 (90.3851)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 960/4579]  eta: 0:20:50  Lr: 0.001875  Loss: 1.2826  Acc@1: 68.7500 (60.9001)  Acc@5: 93.7500 (90.4006)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 970/4579]  eta: 0:20:46  Lr: 0.001875  Loss: 0.7297  Acc@1: 56.2500 (60.8973)  Acc@5: 93.7500 (90.3836)  time: 0.3446  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 980/4579]  eta: 0:20:43  Lr: 0.001875  Loss: 1.0661  Acc@1: 62.5000 (60.9264)  Acc@5: 93.7500 (90.4052)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 990/4579]  eta: 0:20:39  Lr: 0.001875  Loss: 1.8292  Acc@1: 62.5000 (60.8918)  Acc@5: 93.7500 (90.3696)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1000/4579]  eta: 0:20:36  Lr: 0.001875  Loss: 1.8016  Acc@1: 56.2500 (60.8704)  Acc@5: 87.5000 (90.3721)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1010/4579]  eta: 0:20:32  Lr: 0.001875  Loss: 0.9476  Acc@1: 68.7500 (60.9174)  Acc@5: 93.7500 (90.3870)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1020/4579]  eta: 0:20:29  Lr: 0.001875  Loss: 1.0314  Acc@1: 68.7500 (60.9452)  Acc@5: 93.7500 (90.3954)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1030/4579]  eta: 0:20:26  Lr: 0.001875  Loss: 0.9735  Acc@1: 62.5000 (60.9784)  Acc@5: 93.7500 (90.3855)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1040/4579]  eta: 0:20:22  Lr: 0.001875  Loss: 1.0076  Acc@1: 62.5000 (60.9930)  Acc@5: 93.7500 (90.3818)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1050/4579]  eta: 0:20:19  Lr: 0.001875  Loss: 1.5145  Acc@1: 56.2500 (60.9539)  Acc@5: 93.7500 (90.3961)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1060/4579]  eta: 0:20:15  Lr: 0.001875  Loss: 0.8112  Acc@1: 56.2500 (60.9625)  Acc@5: 93.7500 (90.4159)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1070/4579]  eta: 0:20:12  Lr: 0.001875  Loss: 1.4904  Acc@1: 56.2500 (60.9535)  Acc@5: 93.7500 (90.4237)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1080/4579]  eta: 0:20:08  Lr: 0.001875  Loss: 1.5466  Acc@1: 56.2500 (60.9447)  Acc@5: 93.7500 (90.4198)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1090/4579]  eta: 0:20:05  Lr: 0.001875  Loss: 1.2475  Acc@1: 56.2500 (60.9533)  Acc@5: 87.5000 (90.4102)  time: 0.3451  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1100/4579]  eta: 0:20:01  Lr: 0.001875  Loss: 1.2266  Acc@1: 62.5000 (61.0297)  Acc@5: 87.5000 (90.3951)  time: 0.3455  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1110/4579]  eta: 0:19:58  Lr: 0.001875  Loss: 0.8032  Acc@1: 68.7500 (61.1161)  Acc@5: 93.7500 (90.4365)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1120/4579]  eta: 0:19:54  Lr: 0.001875  Loss: 1.0423  Acc@1: 62.5000 (61.0671)  Acc@5: 93.7500 (90.4159)  time: 0.3441  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1130/4579]  eta: 0:19:51  Lr: 0.001875  Loss: 1.7726  Acc@1: 56.2500 (61.0411)  Acc@5: 87.5000 (90.3625)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1140/4579]  eta: 0:19:47  Lr: 0.001875  Loss: 0.9548  Acc@1: 62.5000 (61.0429)  Acc@5: 87.5000 (90.3812)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1150/4579]  eta: 0:19:44  Lr: 0.001875  Loss: 1.1678  Acc@1: 62.5000 (61.0610)  Acc@5: 93.7500 (90.3942)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1160/4579]  eta: 0:19:40  Lr: 0.001875  Loss: 1.3277  Acc@1: 62.5000 (61.0573)  Acc@5: 87.5000 (90.3801)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1170/4579]  eta: 0:19:37  Lr: 0.001875  Loss: 1.3939  Acc@1: 62.5000 (61.0749)  Acc@5: 87.5000 (90.3768)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1180/4579]  eta: 0:19:34  Lr: 0.001875  Loss: 1.4828  Acc@1: 62.5000 (61.0500)  Acc@5: 87.5000 (90.3895)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1190/4579]  eta: 0:19:30  Lr: 0.001875  Loss: 1.1689  Acc@1: 62.5000 (61.1146)  Acc@5: 93.7500 (90.3915)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1200/4579]  eta: 0:19:27  Lr: 0.001875  Loss: 2.0749  Acc@1: 62.5000 (61.0845)  Acc@5: 87.5000 (90.3570)  time: 0.3457  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1210/4579]  eta: 0:19:23  Lr: 0.001875  Loss: 1.0595  Acc@1: 62.5000 (61.0859)  Acc@5: 93.7500 (90.3799)  time: 0.3457  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1220/4579]  eta: 0:19:20  Lr: 0.001875  Loss: 1.4052  Acc@1: 62.5000 (61.0565)  Acc@5: 93.7500 (90.3819)  time: 0.3448  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1230/4579]  eta: 0:19:16  Lr: 0.001875  Loss: 1.0225  Acc@1: 56.2500 (61.0479)  Acc@5: 93.7500 (90.4041)  time: 0.3455  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1240/4579]  eta: 0:19:13  Lr: 0.001875  Loss: 1.1897  Acc@1: 62.5000 (61.0596)  Acc@5: 93.7500 (90.4110)  time: 0.3448  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1250/4579]  eta: 0:19:09  Lr: 0.001875  Loss: 1.0994  Acc@1: 62.5000 (61.0562)  Acc@5: 93.7500 (90.4177)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1260/4579]  eta: 0:19:06  Lr: 0.001875  Loss: 1.9304  Acc@1: 62.5000 (61.0577)  Acc@5: 87.5000 (90.3747)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1270/4579]  eta: 0:19:02  Lr: 0.001875  Loss: 1.5543  Acc@1: 62.5000 (61.0641)  Acc@5: 87.5000 (90.3816)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1280/4579]  eta: 0:18:59  Lr: 0.001875  Loss: 1.0666  Acc@1: 62.5000 (61.0412)  Acc@5: 87.5000 (90.3932)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1290/4579]  eta: 0:18:55  Lr: 0.001875  Loss: 0.9018  Acc@1: 62.5000 (61.1203)  Acc@5: 87.5000 (90.4047)  time: 0.3453  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1300/4579]  eta: 0:18:52  Lr: 0.001875  Loss: 0.8891  Acc@1: 68.7500 (61.1645)  Acc@5: 93.7500 (90.4352)  time: 0.3459  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [1310/4579]  eta: 0:18:49  Lr: 0.001875  Loss: 1.2511  Acc@1: 68.7500 (61.1604)  Acc@5: 93.7500 (90.4415)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1320/4579]  eta: 0:18:45  Lr: 0.001875  Loss: 1.4186  Acc@1: 68.7500 (61.2178)  Acc@5: 93.7500 (90.4476)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1330/4579]  eta: 0:18:42  Lr: 0.001875  Loss: 1.6711  Acc@1: 56.2500 (61.1570)  Acc@5: 93.7500 (90.4489)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1340/4579]  eta: 0:18:38  Lr: 0.001875  Loss: 1.7938  Acc@1: 56.2500 (61.1717)  Acc@5: 93.7500 (90.4595)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1350/4579]  eta: 0:18:35  Lr: 0.001875  Loss: 1.2058  Acc@1: 62.5000 (61.1630)  Acc@5: 93.7500 (90.4746)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1360/4579]  eta: 0:18:31  Lr: 0.001875  Loss: 0.4102  Acc@1: 62.5000 (61.1729)  Acc@5: 93.7500 (90.4849)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1370/4579]  eta: 0:18:28  Lr: 0.001875  Loss: 1.4856  Acc@1: 56.2500 (61.1552)  Acc@5: 87.5000 (90.4404)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1380/4579]  eta: 0:18:24  Lr: 0.001875  Loss: 1.3227  Acc@1: 56.2500 (61.1468)  Acc@5: 87.5000 (90.4553)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1390/4579]  eta: 0:18:21  Lr: 0.001875  Loss: 1.8169  Acc@1: 62.5000 (61.1655)  Acc@5: 93.7500 (90.4969)  time: 0.3454  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1400/4579]  eta: 0:18:17  Lr: 0.001875  Loss: 1.1532  Acc@1: 62.5000 (61.1617)  Acc@5: 93.7500 (90.4889)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1410/4579]  eta: 0:18:14  Lr: 0.001875  Loss: 1.8105  Acc@1: 56.2500 (61.1401)  Acc@5: 87.5000 (90.4722)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1420/4579]  eta: 0:18:10  Lr: 0.001875  Loss: 1.2060  Acc@1: 56.2500 (61.1145)  Acc@5: 93.7500 (90.4952)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1430/4579]  eta: 0:18:07  Lr: 0.001875  Loss: 1.5125  Acc@1: 62.5000 (61.0980)  Acc@5: 93.7500 (90.5093)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1440/4579]  eta: 0:18:03  Lr: 0.001875  Loss: 1.4487  Acc@1: 62.5000 (61.1381)  Acc@5: 87.5000 (90.5014)  time: 0.3437  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1450/4579]  eta: 0:18:00  Lr: 0.001875  Loss: 0.9269  Acc@1: 62.5000 (61.0829)  Acc@5: 93.7500 (90.5152)  time: 0.3435  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1460/4579]  eta: 0:17:57  Lr: 0.001875  Loss: 0.9766  Acc@1: 56.2500 (61.0926)  Acc@5: 93.7500 (90.5245)  time: 0.3455  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1470/4579]  eta: 0:17:53  Lr: 0.001875  Loss: 1.4260  Acc@1: 56.2500 (61.0682)  Acc@5: 87.5000 (90.5082)  time: 0.3456  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1480/4579]  eta: 0:17:50  Lr: 0.001875  Loss: 0.8270  Acc@1: 56.2500 (61.0694)  Acc@5: 87.5000 (90.4921)  time: 0.3447  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1490/4579]  eta: 0:17:46  Lr: 0.001875  Loss: 1.1670  Acc@1: 56.2500 (61.0287)  Acc@5: 87.5000 (90.4888)  time: 0.3441  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1500/4579]  eta: 0:17:43  Lr: 0.001875  Loss: 0.9210  Acc@1: 56.2500 (61.0385)  Acc@5: 87.5000 (90.4813)  time: 0.3452  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [1510/4579]  eta: 0:17:39  Lr: 0.001875  Loss: 0.7866  Acc@1: 68.7500 (61.0730)  Acc@5: 93.7500 (90.4906)  time: 0.3459  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1520/4579]  eta: 0:17:36  Lr: 0.001875  Loss: 1.5079  Acc@1: 62.5000 (61.0577)  Acc@5: 93.7500 (90.4832)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1530/4579]  eta: 0:17:32  Lr: 0.001875  Loss: 1.0873  Acc@1: 62.5000 (61.0957)  Acc@5: 93.7500 (90.4964)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1540/4579]  eta: 0:17:29  Lr: 0.001875  Loss: 0.9308  Acc@1: 68.7500 (61.1129)  Acc@5: 93.7500 (90.4972)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1550/4579]  eta: 0:17:25  Lr: 0.001875  Loss: 1.0401  Acc@1: 68.7500 (61.1541)  Acc@5: 93.7500 (90.5142)  time: 0.3452  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1560/4579]  eta: 0:17:22  Lr: 0.001875  Loss: 1.1833  Acc@1: 62.5000 (61.1467)  Acc@5: 93.7500 (90.5429)  time: 0.3458  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1570/4579]  eta: 0:17:18  Lr: 0.001875  Loss: 0.9437  Acc@1: 56.2500 (61.1434)  Acc@5: 93.7500 (90.5395)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1580/4579]  eta: 0:17:15  Lr: 0.001875  Loss: 1.6944  Acc@1: 56.2500 (61.1282)  Acc@5: 93.7500 (90.5637)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1590/4579]  eta: 0:17:12  Lr: 0.001875  Loss: 0.6594  Acc@1: 62.5000 (61.1879)  Acc@5: 93.7500 (90.5759)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1600/4579]  eta: 0:17:08  Lr: 0.001875  Loss: 0.9171  Acc@1: 62.5000 (61.2000)  Acc@5: 93.7500 (90.5918)  time: 0.3449  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1610/4579]  eta: 0:17:05  Lr: 0.001875  Loss: 0.9645  Acc@1: 62.5000 (61.1848)  Acc@5: 93.7500 (90.5687)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1620/4579]  eta: 0:17:01  Lr: 0.001875  Loss: 1.3072  Acc@1: 56.2500 (61.1968)  Acc@5: 93.7500 (90.5807)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1630/4579]  eta: 0:16:58  Lr: 0.001875  Loss: 0.9077  Acc@1: 62.5000 (61.2010)  Acc@5: 93.7500 (90.5924)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1640/4579]  eta: 0:16:54  Lr: 0.001875  Loss: 1.3124  Acc@1: 62.5000 (61.2089)  Acc@5: 93.7500 (90.6002)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1650/4579]  eta: 0:16:51  Lr: 0.001875  Loss: 1.0796  Acc@1: 62.5000 (61.2280)  Acc@5: 93.7500 (90.6080)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1660/4579]  eta: 0:16:47  Lr: 0.001875  Loss: 1.3661  Acc@1: 68.7500 (61.2846)  Acc@5: 93.7500 (90.6231)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1670/4579]  eta: 0:16:44  Lr: 0.001875  Loss: 0.8752  Acc@1: 68.7500 (61.3069)  Acc@5: 93.7500 (90.6381)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1680/4579]  eta: 0:16:41  Lr: 0.001875  Loss: 1.1848  Acc@1: 62.5000 (61.2842)  Acc@5: 93.7500 (90.6380)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1690/4579]  eta: 0:16:37  Lr: 0.001875  Loss: 0.7694  Acc@1: 56.2500 (61.2729)  Acc@5: 93.7500 (90.6416)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1700/4579]  eta: 0:16:34  Lr: 0.001875  Loss: 0.6659  Acc@1: 56.2500 (61.2324)  Acc@5: 93.7500 (90.6195)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1710/4579]  eta: 0:16:30  Lr: 0.001875  Loss: 1.1464  Acc@1: 56.2500 (61.2398)  Acc@5: 87.5000 (90.6195)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1720/4579]  eta: 0:16:27  Lr: 0.001875  Loss: 1.1573  Acc@1: 62.5000 (61.2253)  Acc@5: 87.5000 (90.6050)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1730/4579]  eta: 0:16:23  Lr: 0.001875  Loss: 1.1312  Acc@1: 56.2500 (61.2146)  Acc@5: 87.5000 (90.6124)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1740/4579]  eta: 0:16:20  Lr: 0.001875  Loss: 0.6276  Acc@1: 56.2500 (61.2364)  Acc@5: 93.7500 (90.6232)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1750/4579]  eta: 0:16:16  Lr: 0.001875  Loss: 0.6529  Acc@1: 62.5000 (61.2614)  Acc@5: 87.5000 (90.6161)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1760/4579]  eta: 0:16:13  Lr: 0.001875  Loss: 1.1142  Acc@1: 62.5000 (61.2933)  Acc@5: 93.7500 (90.6481)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1770/4579]  eta: 0:16:10  Lr: 0.001875  Loss: 1.6198  Acc@1: 62.5000 (61.2860)  Acc@5: 93.7500 (90.5985)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1780/4579]  eta: 0:16:06  Lr: 0.001875  Loss: 0.6999  Acc@1: 62.5000 (61.2963)  Acc@5: 87.5000 (90.6022)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1790/4579]  eta: 0:16:03  Lr: 0.001875  Loss: 0.9424  Acc@1: 62.5000 (61.2926)  Acc@5: 93.7500 (90.6058)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1800/4579]  eta: 0:15:59  Lr: 0.001875  Loss: 0.7759  Acc@1: 56.2500 (61.2542)  Acc@5: 93.7500 (90.6059)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1810/4579]  eta: 0:15:56  Lr: 0.001875  Loss: 1.1709  Acc@1: 56.2500 (61.2472)  Acc@5: 87.5000 (90.5750)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1820/4579]  eta: 0:15:52  Lr: 0.001875  Loss: 1.2555  Acc@1: 62.5000 (61.2644)  Acc@5: 93.7500 (90.5890)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1830/4579]  eta: 0:15:49  Lr: 0.001875  Loss: 1.0382  Acc@1: 62.5000 (61.2677)  Acc@5: 93.7500 (90.5755)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1840/4579]  eta: 0:15:45  Lr: 0.001875  Loss: 1.1319  Acc@1: 62.5000 (61.2948)  Acc@5: 87.5000 (90.5792)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1850/4579]  eta: 0:15:42  Lr: 0.001875  Loss: 1.2122  Acc@1: 56.2500 (61.2405)  Acc@5: 87.5000 (90.5625)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1860/4579]  eta: 0:15:39  Lr: 0.001875  Loss: 1.2373  Acc@1: 56.2500 (61.2171)  Acc@5: 87.5000 (90.5595)  time: 0.3477  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1870/4579]  eta: 0:15:35  Lr: 0.001875  Loss: 1.1454  Acc@1: 56.2500 (61.1939)  Acc@5: 93.7500 (90.5665)  time: 0.3455  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1880/4579]  eta: 0:15:32  Lr: 0.001875  Loss: 1.3556  Acc@1: 56.2500 (61.2174)  Acc@5: 93.7500 (90.5669)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1890/4579]  eta: 0:15:28  Lr: 0.001875  Loss: 1.0459  Acc@1: 62.5000 (61.2077)  Acc@5: 87.5000 (90.5374)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1900/4579]  eta: 0:15:25  Lr: 0.001875  Loss: 1.7162  Acc@1: 62.5000 (61.2112)  Acc@5: 87.5000 (90.5477)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1910/4579]  eta: 0:15:21  Lr: 0.001875  Loss: 1.4329  Acc@1: 56.2500 (61.2016)  Acc@5: 87.5000 (90.5285)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1920/4579]  eta: 0:15:18  Lr: 0.001875  Loss: 1.0990  Acc@1: 56.2500 (61.2051)  Acc@5: 87.5000 (90.5225)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1930/4579]  eta: 0:15:14  Lr: 0.001875  Loss: 0.9467  Acc@1: 62.5000 (61.1924)  Acc@5: 87.5000 (90.5263)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1940/4579]  eta: 0:15:11  Lr: 0.001875  Loss: 1.2556  Acc@1: 62.5000 (61.1734)  Acc@5: 87.5000 (90.5204)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1950/4579]  eta: 0:15:07  Lr: 0.001875  Loss: 0.6705  Acc@1: 56.2500 (61.1738)  Acc@5: 93.7500 (90.5433)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1960/4579]  eta: 0:15:04  Lr: 0.001875  Loss: 0.8726  Acc@1: 62.5000 (61.1837)  Acc@5: 93.7500 (90.5533)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1970/4579]  eta: 0:15:00  Lr: 0.001875  Loss: 1.0970  Acc@1: 68.7500 (61.1936)  Acc@5: 93.7500 (90.5632)  time: 0.3439  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1980/4579]  eta: 0:14:57  Lr: 0.001875  Loss: 1.3562  Acc@1: 62.5000 (61.1907)  Acc@5: 93.7500 (90.5509)  time: 0.3446  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1990/4579]  eta: 0:14:53  Lr: 0.001875  Loss: 1.0077  Acc@1: 62.5000 (61.2098)  Acc@5: 87.5000 (90.5481)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2000/4579]  eta: 0:14:50  Lr: 0.001875  Loss: 1.1826  Acc@1: 56.2500 (61.2006)  Acc@5: 87.5000 (90.5329)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2010/4579]  eta: 0:14:47  Lr: 0.001875  Loss: 1.1135  Acc@1: 56.2500 (61.2040)  Acc@5: 93.7500 (90.5364)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2020/4579]  eta: 0:14:43  Lr: 0.001875  Loss: 1.1896  Acc@1: 62.5000 (61.2259)  Acc@5: 93.7500 (90.5338)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2030/4579]  eta: 0:14:40  Lr: 0.001875  Loss: 2.0381  Acc@1: 62.5000 (61.1891)  Acc@5: 87.5000 (90.5158)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2040/4579]  eta: 0:14:36  Lr: 0.001875  Loss: 1.4331  Acc@1: 56.2500 (61.1741)  Acc@5: 87.5000 (90.4887)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2050/4579]  eta: 0:14:33  Lr: 0.001875  Loss: 0.7122  Acc@1: 56.2500 (61.1561)  Acc@5: 87.5000 (90.4955)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2060/4579]  eta: 0:14:29  Lr: 0.001875  Loss: 1.3298  Acc@1: 56.2500 (61.1596)  Acc@5: 93.7500 (90.4961)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2070/4579]  eta: 0:14:26  Lr: 0.001875  Loss: 0.8580  Acc@1: 56.2500 (61.1570)  Acc@5: 87.5000 (90.4907)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2080/4579]  eta: 0:14:22  Lr: 0.001875  Loss: 1.5322  Acc@1: 62.5000 (61.1845)  Acc@5: 93.7500 (90.5034)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2090/4579]  eta: 0:14:19  Lr: 0.001875  Loss: 0.6193  Acc@1: 68.7500 (61.2117)  Acc@5: 93.7500 (90.5099)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2100/4579]  eta: 0:14:15  Lr: 0.001875  Loss: 0.8251  Acc@1: 62.5000 (61.2089)  Acc@5: 87.5000 (90.5075)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2110/4579]  eta: 0:14:12  Lr: 0.001875  Loss: 0.7113  Acc@1: 62.5000 (61.2417)  Acc@5: 93.7500 (90.5169)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2120/4579]  eta: 0:14:09  Lr: 0.001875  Loss: 0.5428  Acc@1: 68.7500 (61.2771)  Acc@5: 93.7500 (90.5381)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2130/4579]  eta: 0:14:05  Lr: 0.001875  Loss: 1.5974  Acc@1: 62.5000 (61.2740)  Acc@5: 93.7500 (90.5297)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2140/4579]  eta: 0:14:02  Lr: 0.001875  Loss: 1.2635  Acc@1: 56.2500 (61.2447)  Acc@5: 87.5000 (90.5155)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2150/4579]  eta: 0:13:58  Lr: 0.001875  Loss: 0.5885  Acc@1: 56.2500 (61.2215)  Acc@5: 87.5000 (90.5073)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2160/4579]  eta: 0:13:55  Lr: 0.001875  Loss: 1.5407  Acc@1: 56.2500 (61.2361)  Acc@5: 87.5000 (90.5050)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2170/4579]  eta: 0:13:51  Lr: 0.001875  Loss: 1.5466  Acc@1: 56.2500 (61.2160)  Acc@5: 87.5000 (90.4940)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2180/4579]  eta: 0:13:48  Lr: 0.001875  Loss: 0.9567  Acc@1: 56.2500 (61.1990)  Acc@5: 87.5000 (90.4717)  time: 0.3459  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2190/4579]  eta: 0:13:44  Lr: 0.001875  Loss: 0.9750  Acc@1: 62.5000 (61.2106)  Acc@5: 87.5000 (90.4781)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2200/4579]  eta: 0:13:41  Lr: 0.001875  Loss: 1.2280  Acc@1: 62.5000 (61.2108)  Acc@5: 93.7500 (90.4759)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2210/4579]  eta: 0:13:38  Lr: 0.001875  Loss: 1.2781  Acc@1: 62.5000 (61.2393)  Acc@5: 93.7500 (90.4907)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2220/4579]  eta: 0:13:34  Lr: 0.001875  Loss: 1.6032  Acc@1: 62.5000 (61.2168)  Acc@5: 93.7500 (90.4688)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2230/4579]  eta: 0:13:31  Lr: 0.001875  Loss: 0.8039  Acc@1: 62.5000 (61.2281)  Acc@5: 87.5000 (90.4555)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2240/4579]  eta: 0:13:27  Lr: 0.001875  Loss: 1.6648  Acc@1: 62.5000 (61.2115)  Acc@5: 87.5000 (90.4507)  time: 0.3466  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2250/4579]  eta: 0:13:24  Lr: 0.001875  Loss: 0.9516  Acc@1: 56.2500 (61.2034)  Acc@5: 87.5000 (90.4487)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2260/4579]  eta: 0:13:20  Lr: 0.001875  Loss: 1.0661  Acc@1: 56.2500 (61.2036)  Acc@5: 87.5000 (90.4356)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2270/4579]  eta: 0:13:17  Lr: 0.001875  Loss: 1.0072  Acc@1: 56.2500 (61.1955)  Acc@5: 87.5000 (90.4420)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2280/4579]  eta: 0:13:13  Lr: 0.001875  Loss: 0.8809  Acc@1: 62.5000 (61.2040)  Acc@5: 93.7500 (90.4428)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2290/4579]  eta: 0:13:10  Lr: 0.001875  Loss: 0.8036  Acc@1: 62.5000 (61.2069)  Acc@5: 93.7500 (90.4463)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2300/4579]  eta: 0:13:06  Lr: 0.001875  Loss: 0.6526  Acc@1: 62.5000 (61.2179)  Acc@5: 93.7500 (90.4498)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2310/4579]  eta: 0:13:03  Lr: 0.001875  Loss: 0.7853  Acc@1: 62.5000 (61.2343)  Acc@5: 93.7500 (90.4641)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2320/4579]  eta: 0:13:00  Lr: 0.001875  Loss: 1.3098  Acc@1: 62.5000 (61.2344)  Acc@5: 93.7500 (90.4702)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2330/4579]  eta: 0:12:56  Lr: 0.001875  Loss: 1.2992  Acc@1: 62.5000 (61.2371)  Acc@5: 93.7500 (90.4735)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2340/4579]  eta: 0:12:53  Lr: 0.001875  Loss: 1.6518  Acc@1: 56.2500 (61.2425)  Acc@5: 93.7500 (90.4768)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2350/4579]  eta: 0:12:49  Lr: 0.001875  Loss: 1.0806  Acc@1: 56.2500 (61.2452)  Acc@5: 87.5000 (90.4748)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2360/4579]  eta: 0:12:46  Lr: 0.001875  Loss: 0.6476  Acc@1: 56.2500 (61.2664)  Acc@5: 93.7500 (90.4966)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2370/4579]  eta: 0:12:42  Lr: 0.001875  Loss: 1.2781  Acc@1: 62.5000 (61.2874)  Acc@5: 93.7500 (90.5051)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2380/4579]  eta: 0:12:39  Lr: 0.001875  Loss: 1.1726  Acc@1: 62.5000 (61.2689)  Acc@5: 93.7500 (90.5029)  time: 0.3450  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2390/4579]  eta: 0:12:35  Lr: 0.001875  Loss: 0.9666  Acc@1: 56.2500 (61.2584)  Acc@5: 87.5000 (90.4982)  time: 0.3452  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2400/4579]  eta: 0:12:32  Lr: 0.001875  Loss: 1.0786  Acc@1: 62.5000 (61.2844)  Acc@5: 93.7500 (90.5066)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2410/4579]  eta: 0:12:29  Lr: 0.001875  Loss: 1.2904  Acc@1: 62.5000 (61.2661)  Acc@5: 93.7500 (90.5096)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2420/4579]  eta: 0:12:25  Lr: 0.001875  Loss: 0.9170  Acc@1: 62.5000 (61.2944)  Acc@5: 93.7500 (90.5230)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2430/4579]  eta: 0:12:22  Lr: 0.001875  Loss: 1.1810  Acc@1: 62.5000 (61.2788)  Acc@5: 93.7500 (90.5209)  time: 0.3456  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2440/4579]  eta: 0:12:18  Lr: 0.001875  Loss: 1.7950  Acc@1: 62.5000 (61.2736)  Acc@5: 87.5000 (90.5264)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2450/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 1.4638  Acc@1: 62.5000 (61.2709)  Acc@5: 87.5000 (90.5192)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2460/4579]  eta: 0:12:11  Lr: 0.001875  Loss: 0.6981  Acc@1: 62.5000 (61.2911)  Acc@5: 93.7500 (90.5247)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2470/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 1.3121  Acc@1: 62.5000 (61.3036)  Acc@5: 93.7500 (90.5226)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2480/4579]  eta: 0:12:04  Lr: 0.001875  Loss: 1.1680  Acc@1: 62.5000 (61.3084)  Acc@5: 93.7500 (90.5255)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2490/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 1.1015  Acc@1: 62.5000 (61.3258)  Acc@5: 93.7500 (90.5309)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2500/4579]  eta: 0:11:57  Lr: 0.001875  Loss: 1.0458  Acc@1: 62.5000 (61.3430)  Acc@5: 93.7500 (90.5388)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2510/4579]  eta: 0:11:54  Lr: 0.001875  Loss: 1.3667  Acc@1: 62.5000 (61.3376)  Acc@5: 93.7500 (90.5391)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2520/4579]  eta: 0:11:51  Lr: 0.001875  Loss: 1.6030  Acc@1: 56.2500 (61.3298)  Acc@5: 93.7500 (90.5444)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2530/4579]  eta: 0:11:47  Lr: 0.001875  Loss: 1.0229  Acc@1: 62.5000 (61.3147)  Acc@5: 93.7500 (90.5447)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2540/4579]  eta: 0:11:44  Lr: 0.001875  Loss: 0.9663  Acc@1: 62.5000 (61.3292)  Acc@5: 93.7500 (90.5475)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2550/4579]  eta: 0:11:40  Lr: 0.001875  Loss: 1.8727  Acc@1: 62.5000 (61.3264)  Acc@5: 87.5000 (90.5331)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2560/4579]  eta: 0:11:37  Lr: 0.001875  Loss: 1.2291  Acc@1: 56.2500 (61.2993)  Acc@5: 87.5000 (90.5359)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2570/4579]  eta: 0:11:33  Lr: 0.001875  Loss: 1.3718  Acc@1: 56.2500 (61.2918)  Acc@5: 93.7500 (90.5411)  time: 0.3466  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2580/4579]  eta: 0:11:30  Lr: 0.001875  Loss: 1.4465  Acc@1: 62.5000 (61.2892)  Acc@5: 93.7500 (90.5487)  time: 0.3455  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2590/4579]  eta: 0:11:26  Lr: 0.001875  Loss: 1.0600  Acc@1: 62.5000 (61.3036)  Acc@5: 93.7500 (90.5587)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2600/4579]  eta: 0:11:23  Lr: 0.001875  Loss: 1.0265  Acc@1: 62.5000 (61.3033)  Acc@5: 93.7500 (90.5493)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2610/4579]  eta: 0:11:19  Lr: 0.001875  Loss: 1.2953  Acc@1: 68.7500 (61.3367)  Acc@5: 93.7500 (90.5520)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2620/4579]  eta: 0:11:16  Lr: 0.001875  Loss: 1.5952  Acc@1: 68.7500 (61.3339)  Acc@5: 93.7500 (90.5547)  time: 0.3449  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2630/4579]  eta: 0:11:13  Lr: 0.001875  Loss: 1.3227  Acc@1: 56.2500 (61.3099)  Acc@5: 87.5000 (90.5525)  time: 0.3439  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2640/4579]  eta: 0:11:09  Lr: 0.001875  Loss: 0.9900  Acc@1: 56.2500 (61.3096)  Acc@5: 87.5000 (90.5552)  time: 0.3445  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2650/4579]  eta: 0:11:06  Lr: 0.001875  Loss: 0.7105  Acc@1: 62.5000 (61.3212)  Acc@5: 93.7500 (90.5625)  time: 0.3455  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2660/4579]  eta: 0:11:02  Lr: 0.001875  Loss: 1.3197  Acc@1: 62.5000 (61.3233)  Acc@5: 93.7500 (90.5581)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2670/4579]  eta: 0:10:59  Lr: 0.001875  Loss: 1.3429  Acc@1: 56.2500 (61.3160)  Acc@5: 87.5000 (90.5490)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2680/4579]  eta: 0:10:55  Lr: 0.001875  Loss: 1.4522  Acc@1: 56.2500 (61.3227)  Acc@5: 87.5000 (90.5516)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2690/4579]  eta: 0:10:52  Lr: 0.001875  Loss: 1.4667  Acc@1: 56.2500 (61.3039)  Acc@5: 87.5000 (90.5518)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2700/4579]  eta: 0:10:48  Lr: 0.001875  Loss: 0.9522  Acc@1: 56.2500 (61.3222)  Acc@5: 87.5000 (90.5498)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2710/4579]  eta: 0:10:45  Lr: 0.001875  Loss: 1.1108  Acc@1: 62.5000 (61.3196)  Acc@5: 93.7500 (90.5593)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2720/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 1.0877  Acc@1: 62.5000 (61.3309)  Acc@5: 93.7500 (90.5458)  time: 0.3449  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2730/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 1.5132  Acc@1: 62.5000 (61.3237)  Acc@5: 93.7500 (90.5552)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2740/4579]  eta: 0:10:35  Lr: 0.001875  Loss: 1.3494  Acc@1: 56.2500 (61.3097)  Acc@5: 87.5000 (90.5441)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2750/4579]  eta: 0:10:31  Lr: 0.001875  Loss: 1.9580  Acc@1: 56.2500 (61.2913)  Acc@5: 87.5000 (90.5421)  time: 0.3448  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2760/4579]  eta: 0:10:28  Lr: 0.001875  Loss: 0.3470  Acc@1: 62.5000 (61.3093)  Acc@5: 87.5000 (90.5492)  time: 0.3457  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2770/4579]  eta: 0:10:24  Lr: 0.001875  Loss: 1.2288  Acc@1: 62.5000 (61.3001)  Acc@5: 87.5000 (90.5449)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2780/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 1.5394  Acc@1: 62.5000 (61.2999)  Acc@5: 93.7500 (90.5497)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2790/4579]  eta: 0:10:17  Lr: 0.001875  Loss: 1.1195  Acc@1: 62.5000 (61.2840)  Acc@5: 87.5000 (90.5455)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2800/4579]  eta: 0:10:14  Lr: 0.001875  Loss: 1.3326  Acc@1: 62.5000 (61.2884)  Acc@5: 93.7500 (90.5547)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2810/4579]  eta: 0:10:10  Lr: 0.001875  Loss: 0.6792  Acc@1: 62.5000 (61.3105)  Acc@5: 93.7500 (90.5683)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2820/4579]  eta: 0:10:07  Lr: 0.001875  Loss: 0.9630  Acc@1: 68.7500 (61.3191)  Acc@5: 93.7500 (90.5663)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2830/4579]  eta: 0:10:04  Lr: 0.001875  Loss: 0.9347  Acc@1: 68.7500 (61.3387)  Acc@5: 93.7500 (90.5731)  time: 0.3477  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2840/4579]  eta: 0:10:00  Lr: 0.001875  Loss: 0.8532  Acc@1: 62.5000 (61.3384)  Acc@5: 93.7500 (90.5667)  time: 0.3475  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2850/4579]  eta: 0:09:57  Lr: 0.001875  Loss: 0.6783  Acc@1: 62.5000 (61.3557)  Acc@5: 87.5000 (90.5669)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2860/4579]  eta: 0:09:53  Lr: 0.001875  Loss: 1.5626  Acc@1: 62.5000 (61.3662)  Acc@5: 87.5000 (90.5540)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2870/4579]  eta: 0:09:50  Lr: 0.001875  Loss: 1.8062  Acc@1: 62.5000 (61.3702)  Acc@5: 87.5000 (90.5542)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2880/4579]  eta: 0:09:46  Lr: 0.001875  Loss: 1.1321  Acc@1: 62.5000 (61.3698)  Acc@5: 93.7500 (90.5675)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2890/4579]  eta: 0:09:43  Lr: 0.001875  Loss: 0.9346  Acc@1: 62.5000 (61.3693)  Acc@5: 93.7500 (90.5591)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2900/4579]  eta: 0:09:39  Lr: 0.001875  Loss: 1.2630  Acc@1: 62.5000 (61.3797)  Acc@5: 87.5000 (90.5528)  time: 0.3465  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2910/4579]  eta: 0:09:36  Lr: 0.001875  Loss: 0.9557  Acc@1: 68.7500 (61.3750)  Acc@5: 93.7500 (90.5617)  time: 0.3464  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2920/4579]  eta: 0:09:32  Lr: 0.001875  Loss: 1.1477  Acc@1: 68.7500 (61.3745)  Acc@5: 93.7500 (90.5597)  time: 0.3475  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2930/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 1.0865  Acc@1: 62.5000 (61.3762)  Acc@5: 87.5000 (90.5536)  time: 0.3471  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2940/4579]  eta: 0:09:26  Lr: 0.001875  Loss: 1.5438  Acc@1: 56.2500 (61.3546)  Acc@5: 93.7500 (90.5559)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2950/4579]  eta: 0:09:22  Lr: 0.001875  Loss: 1.3080  Acc@1: 56.2500 (61.3436)  Acc@5: 87.5000 (90.5519)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2960/4579]  eta: 0:09:19  Lr: 0.001875  Loss: 0.6663  Acc@1: 62.5000 (61.3581)  Acc@5: 87.5000 (90.5522)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2970/4579]  eta: 0:09:15  Lr: 0.001875  Loss: 0.5372  Acc@1: 62.5000 (61.3703)  Acc@5: 93.7500 (90.5545)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2980/4579]  eta: 0:09:12  Lr: 0.001875  Loss: 1.0107  Acc@1: 56.2500 (61.3699)  Acc@5: 93.7500 (90.5652)  time: 0.3457  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2990/4579]  eta: 0:09:08  Lr: 0.001875  Loss: 0.9474  Acc@1: 62.5000 (61.3716)  Acc@5: 93.7500 (90.5717)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3000/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 0.9744  Acc@1: 62.5000 (61.3816)  Acc@5: 93.7500 (90.5844)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3010/4579]  eta: 0:09:01  Lr: 0.001875  Loss: 1.1522  Acc@1: 62.5000 (61.3791)  Acc@5: 93.7500 (90.5824)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3020/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.7809  Acc@1: 62.5000 (61.3745)  Acc@5: 87.5000 (90.5764)  time: 0.3469  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3030/4579]  eta: 0:08:54  Lr: 0.001875  Loss: 1.1012  Acc@1: 62.5000 (61.3968)  Acc@5: 93.7500 (90.5827)  time: 0.3464  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3040/4579]  eta: 0:08:51  Lr: 0.001875  Loss: 1.0072  Acc@1: 68.7500 (61.4025)  Acc@5: 93.7500 (90.5931)  time: 0.3462  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3050/4579]  eta: 0:08:48  Lr: 0.001875  Loss: 1.4162  Acc@1: 62.5000 (61.4040)  Acc@5: 93.7500 (90.5932)  time: 0.3461  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3060/4579]  eta: 0:08:44  Lr: 0.001875  Loss: 0.8728  Acc@1: 62.5000 (61.4178)  Acc@5: 93.7500 (90.6015)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3070/4579]  eta: 0:08:41  Lr: 0.001875  Loss: 0.5029  Acc@1: 62.5000 (61.4275)  Acc@5: 93.7500 (90.6016)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3080/4579]  eta: 0:08:37  Lr: 0.001875  Loss: 1.0602  Acc@1: 62.5000 (61.4309)  Acc@5: 93.7500 (90.6057)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3090/4579]  eta: 0:08:34  Lr: 0.001875  Loss: 1.0439  Acc@1: 56.2500 (61.4203)  Acc@5: 87.5000 (90.6038)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3100/4579]  eta: 0:08:30  Lr: 0.001875  Loss: 0.7782  Acc@1: 62.5000 (61.4137)  Acc@5: 87.5000 (90.6018)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3110/4579]  eta: 0:08:27  Lr: 0.001875  Loss: 1.3245  Acc@1: 62.5000 (61.4171)  Acc@5: 87.5000 (90.6039)  time: 0.3451  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3120/4579]  eta: 0:08:23  Lr: 0.001875  Loss: 1.3614  Acc@1: 62.5000 (61.4086)  Acc@5: 93.7500 (90.6060)  time: 0.3444  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3130/4579]  eta: 0:08:20  Lr: 0.001875  Loss: 0.9309  Acc@1: 62.5000 (61.4021)  Acc@5: 93.7500 (90.6080)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3140/4579]  eta: 0:08:17  Lr: 0.001875  Loss: 1.0152  Acc@1: 62.5000 (61.4255)  Acc@5: 93.7500 (90.6200)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3150/4579]  eta: 0:08:13  Lr: 0.001875  Loss: 1.6173  Acc@1: 62.5000 (61.4111)  Acc@5: 93.7500 (90.6141)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3160/4579]  eta: 0:08:10  Lr: 0.001875  Loss: 0.7294  Acc@1: 62.5000 (61.4165)  Acc@5: 87.5000 (90.6141)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3170/4579]  eta: 0:08:06  Lr: 0.001875  Loss: 0.9931  Acc@1: 62.5000 (61.4337)  Acc@5: 87.5000 (90.6122)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3180/4579]  eta: 0:08:03  Lr: 0.001875  Loss: 1.7569  Acc@1: 62.5000 (61.4292)  Acc@5: 93.7500 (90.6240)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3190/4579]  eta: 0:07:59  Lr: 0.001875  Loss: 0.8825  Acc@1: 56.2500 (61.4325)  Acc@5: 93.7500 (90.6240)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3200/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 0.8290  Acc@1: 62.5000 (61.4456)  Acc@5: 93.7500 (90.6279)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3210/4579]  eta: 0:07:52  Lr: 0.001875  Loss: 0.5401  Acc@1: 62.5000 (61.4528)  Acc@5: 93.7500 (90.6318)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3220/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.8966  Acc@1: 62.5000 (61.4522)  Acc@5: 93.7500 (90.6396)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3230/4579]  eta: 0:07:45  Lr: 0.001875  Loss: 1.1334  Acc@1: 62.5000 (61.4477)  Acc@5: 93.7500 (90.6414)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3240/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 1.6515  Acc@1: 62.5000 (61.4490)  Acc@5: 93.7500 (90.6375)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3250/4579]  eta: 0:07:38  Lr: 0.001875  Loss: 1.3317  Acc@1: 62.5000 (61.4465)  Acc@5: 93.7500 (90.6375)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3260/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 0.9322  Acc@1: 62.5000 (61.4401)  Acc@5: 87.5000 (90.6298)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3270/4579]  eta: 0:07:32  Lr: 0.001875  Loss: 1.1518  Acc@1: 62.5000 (61.4338)  Acc@5: 87.5000 (90.6355)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3280/4579]  eta: 0:07:28  Lr: 0.001875  Loss: 1.2126  Acc@1: 62.5000 (61.4409)  Acc@5: 93.7500 (90.6450)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3290/4579]  eta: 0:07:25  Lr: 0.001875  Loss: 1.2715  Acc@1: 62.5000 (61.4460)  Acc@5: 93.7500 (90.6506)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3300/4579]  eta: 0:07:21  Lr: 0.001875  Loss: 1.0127  Acc@1: 62.5000 (61.4511)  Acc@5: 93.7500 (90.6525)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3310/4579]  eta: 0:07:18  Lr: 0.001875  Loss: 1.7476  Acc@1: 68.7500 (61.4599)  Acc@5: 93.7500 (90.6561)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3320/4579]  eta: 0:07:14  Lr: 0.001875  Loss: 0.5748  Acc@1: 68.7500 (61.4819)  Acc@5: 93.7500 (90.6598)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3330/4579]  eta: 0:07:11  Lr: 0.001875  Loss: 1.0131  Acc@1: 68.7500 (61.4924)  Acc@5: 93.7500 (90.6635)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3340/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.8390  Acc@1: 68.7500 (61.5067)  Acc@5: 87.5000 (90.6596)  time: 0.3459  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3350/4579]  eta: 0:07:04  Lr: 0.001875  Loss: 1.4431  Acc@1: 62.5000 (61.5096)  Acc@5: 93.7500 (90.6688)  time: 0.3447  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:00  Lr: 0.001875  Loss: 1.3220  Acc@1: 56.2500 (61.5051)  Acc@5: 87.5000 (90.6538)  time: 0.3443  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3370/4579]  eta: 0:06:57  Lr: 0.001875  Loss: 1.6363  Acc@1: 56.2500 (61.5062)  Acc@5: 87.5000 (90.6537)  time: 0.3443  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3380/4579]  eta: 0:06:54  Lr: 0.001875  Loss: 0.8158  Acc@1: 56.2500 (61.5073)  Acc@5: 87.5000 (90.6370)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3390/4579]  eta: 0:06:50  Lr: 0.001875  Loss: 1.5207  Acc@1: 56.2500 (61.5029)  Acc@5: 87.5000 (90.6222)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3400/4579]  eta: 0:06:47  Lr: 0.001875  Loss: 1.3910  Acc@1: 62.5000 (61.5058)  Acc@5: 93.7500 (90.6259)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3410/4579]  eta: 0:06:43  Lr: 0.001875  Loss: 0.9318  Acc@1: 62.5000 (61.4996)  Acc@5: 93.7500 (90.6168)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3420/4579]  eta: 0:06:40  Lr: 0.001875  Loss: 1.0795  Acc@1: 62.5000 (61.5171)  Acc@5: 93.7500 (90.6296)  time: 0.3460  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3430/4579]  eta: 0:06:36  Lr: 0.001875  Loss: 1.3614  Acc@1: 62.5000 (61.5109)  Acc@5: 93.7500 (90.6259)  time: 0.3455  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3440/4579]  eta: 0:06:33  Lr: 0.001875  Loss: 1.1026  Acc@1: 56.2500 (61.5119)  Acc@5: 87.5000 (90.6205)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3450/4579]  eta: 0:06:29  Lr: 0.001875  Loss: 1.0473  Acc@1: 62.5000 (61.5220)  Acc@5: 87.5000 (90.6259)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3460/4579]  eta: 0:06:26  Lr: 0.001875  Loss: 1.1047  Acc@1: 62.5000 (61.5321)  Acc@5: 93.7500 (90.6313)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3470/4579]  eta: 0:06:22  Lr: 0.001875  Loss: 1.7720  Acc@1: 62.5000 (61.5115)  Acc@5: 87.5000 (90.6187)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3480/4579]  eta: 0:06:19  Lr: 0.001875  Loss: 1.3404  Acc@1: 50.0000 (61.4910)  Acc@5: 87.5000 (90.6061)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3490/4579]  eta: 0:06:16  Lr: 0.001875  Loss: 0.9819  Acc@1: 56.2500 (61.5010)  Acc@5: 87.5000 (90.6116)  time: 0.3443  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3500/4579]  eta: 0:06:12  Lr: 0.001875  Loss: 1.4869  Acc@1: 56.2500 (61.4664)  Acc@5: 93.7500 (90.6045)  time: 0.3442  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3510/4579]  eta: 0:06:09  Lr: 0.001875  Loss: 1.3600  Acc@1: 56.2500 (61.4836)  Acc@5: 93.7500 (90.6099)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:05  Lr: 0.001875  Loss: 1.6085  Acc@1: 62.5000 (61.4793)  Acc@5: 93.7500 (90.6081)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:02  Lr: 0.001875  Loss: 0.7117  Acc@1: 56.2500 (61.4840)  Acc@5: 87.5000 (90.5993)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3540/4579]  eta: 0:05:58  Lr: 0.001875  Loss: 1.3872  Acc@1: 68.7500 (61.5116)  Acc@5: 93.7500 (90.6118)  time: 0.3468  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3550/4579]  eta: 0:05:55  Lr: 0.001875  Loss: 1.0720  Acc@1: 62.5000 (61.4950)  Acc@5: 93.7500 (90.6136)  time: 0.3455  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3560/4579]  eta: 0:05:51  Lr: 0.001875  Loss: 1.2863  Acc@1: 62.5000 (61.5048)  Acc@5: 93.7500 (90.6206)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3570/4579]  eta: 0:05:48  Lr: 0.001875  Loss: 0.9323  Acc@1: 62.5000 (61.5076)  Acc@5: 93.7500 (90.6171)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3580/4579]  eta: 0:05:45  Lr: 0.001875  Loss: 1.2324  Acc@1: 62.5000 (61.5087)  Acc@5: 87.5000 (90.6154)  time: 0.3463  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3590/4579]  eta: 0:05:41  Lr: 0.001875  Loss: 1.3791  Acc@1: 56.2500 (61.4975)  Acc@5: 87.5000 (90.6154)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3600/4579]  eta: 0:05:38  Lr: 0.001875  Loss: 1.5078  Acc@1: 56.2500 (61.4847)  Acc@5: 87.5000 (90.6102)  time: 0.3446  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3610/4579]  eta: 0:05:34  Lr: 0.001875  Loss: 1.0112  Acc@1: 62.5000 (61.5013)  Acc@5: 87.5000 (90.6120)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3620/4579]  eta: 0:05:31  Lr: 0.001875  Loss: 1.2530  Acc@1: 62.5000 (61.4989)  Acc@5: 93.7500 (90.6190)  time: 0.3455  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3630/4579]  eta: 0:05:27  Lr: 0.001875  Loss: 1.0441  Acc@1: 62.5000 (61.4896)  Acc@5: 93.7500 (90.6190)  time: 0.3461  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3640/4579]  eta: 0:05:24  Lr: 0.001875  Loss: 0.8935  Acc@1: 62.5000 (61.5130)  Acc@5: 93.7500 (90.6224)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3650/4579]  eta: 0:05:20  Lr: 0.001875  Loss: 1.0463  Acc@1: 62.5000 (61.5140)  Acc@5: 93.7500 (90.6259)  time: 0.3455  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3660/4579]  eta: 0:05:17  Lr: 0.001875  Loss: 1.9235  Acc@1: 56.2500 (61.4996)  Acc@5: 93.7500 (90.6156)  time: 0.3463  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:13  Lr: 0.001875  Loss: 1.0035  Acc@1: 56.2500 (61.5006)  Acc@5: 87.5000 (90.6105)  time: 0.3476  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:10  Lr: 0.001875  Loss: 1.3469  Acc@1: 62.5000 (61.4999)  Acc@5: 93.7500 (90.6157)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:07  Lr: 0.001875  Loss: 1.1160  Acc@1: 62.5000 (61.5043)  Acc@5: 93.7500 (90.6258)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:03  Lr: 0.001875  Loss: 0.8047  Acc@1: 62.5000 (61.5053)  Acc@5: 93.7500 (90.6258)  time: 0.3462  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3710/4579]  eta: 0:05:00  Lr: 0.001875  Loss: 1.1129  Acc@1: 62.5000 (61.5164)  Acc@5: 87.5000 (90.6225)  time: 0.3464  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3720/4579]  eta: 0:04:56  Lr: 0.001875  Loss: 1.2481  Acc@1: 62.5000 (61.5208)  Acc@5: 93.7500 (90.6292)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3730/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 1.1975  Acc@1: 62.5000 (61.5167)  Acc@5: 93.7500 (90.6309)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3740/4579]  eta: 0:04:49  Lr: 0.001875  Loss: 1.0404  Acc@1: 62.5000 (61.5176)  Acc@5: 93.7500 (90.6308)  time: 0.3437  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3750/4579]  eta: 0:04:46  Lr: 0.001875  Loss: 1.1478  Acc@1: 62.5000 (61.5269)  Acc@5: 93.7500 (90.6392)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3760/4579]  eta: 0:04:42  Lr: 0.001875  Loss: 1.3121  Acc@1: 68.7500 (61.5395)  Acc@5: 93.7500 (90.6408)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3770/4579]  eta: 0:04:39  Lr: 0.001875  Loss: 0.9534  Acc@1: 62.5000 (61.5420)  Acc@5: 93.7500 (90.6490)  time: 0.3447  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3780/4579]  eta: 0:04:35  Lr: 0.001875  Loss: 0.8405  Acc@1: 56.2500 (61.5330)  Acc@5: 93.7500 (90.6523)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3790/4579]  eta: 0:04:32  Lr: 0.001875  Loss: 1.4143  Acc@1: 56.2500 (61.5290)  Acc@5: 93.7500 (90.6571)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3800/4579]  eta: 0:04:29  Lr: 0.001875  Loss: 1.2588  Acc@1: 56.2500 (61.5151)  Acc@5: 93.7500 (90.6686)  time: 0.3453  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3810/4579]  eta: 0:04:25  Lr: 0.001875  Loss: 0.6902  Acc@1: 56.2500 (61.5127)  Acc@5: 93.7500 (90.6619)  time: 0.3451  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 1.1804  Acc@1: 62.5000 (61.5169)  Acc@5: 93.7500 (90.6602)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:18  Lr: 0.001875  Loss: 1.3112  Acc@1: 62.5000 (61.5130)  Acc@5: 93.7500 (90.6568)  time: 0.3457  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 1.2894  Acc@1: 62.5000 (61.5123)  Acc@5: 87.5000 (90.6551)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:11  Lr: 0.001875  Loss: 1.3323  Acc@1: 62.5000 (61.5246)  Acc@5: 87.5000 (90.6550)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:08  Lr: 0.001875  Loss: 1.6990  Acc@1: 68.7500 (61.5352)  Acc@5: 87.5000 (90.6436)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:04  Lr: 0.001875  Loss: 1.3890  Acc@1: 68.7500 (61.5619)  Acc@5: 93.7500 (90.6500)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:01  Lr: 0.001875  Loss: 1.2094  Acc@1: 75.0000 (61.5837)  Acc@5: 93.7500 (90.6596)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3890/4579]  eta: 0:03:57  Lr: 0.001875  Loss: 1.1541  Acc@1: 68.7500 (61.5925)  Acc@5: 93.7500 (90.6547)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3900/4579]  eta: 0:03:54  Lr: 0.001875  Loss: 1.0241  Acc@1: 62.5000 (61.5884)  Acc@5: 87.5000 (90.6562)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3910/4579]  eta: 0:03:51  Lr: 0.001875  Loss: 1.0881  Acc@1: 62.5000 (61.5971)  Acc@5: 87.5000 (90.6530)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3920/4579]  eta: 0:03:47  Lr: 0.001875  Loss: 1.2319  Acc@1: 62.5000 (61.5962)  Acc@5: 87.5000 (90.6513)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3930/4579]  eta: 0:03:44  Lr: 0.001875  Loss: 0.8913  Acc@1: 62.5000 (61.5969)  Acc@5: 87.5000 (90.6512)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3940/4579]  eta: 0:03:40  Lr: 0.001875  Loss: 0.8335  Acc@1: 68.7500 (61.6056)  Acc@5: 93.7500 (90.6559)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3950/4579]  eta: 0:03:37  Lr: 0.001875  Loss: 1.0600  Acc@1: 68.7500 (61.6126)  Acc@5: 93.7500 (90.6558)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3960/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 1.5486  Acc@1: 62.5000 (61.6117)  Acc@5: 87.5000 (90.6526)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 0.9318  Acc@1: 62.5000 (61.6170)  Acc@5: 93.7500 (90.6557)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:26  Lr: 0.001875  Loss: 0.9413  Acc@1: 62.5000 (61.6161)  Acc@5: 93.7500 (90.6556)  time: 0.3473  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 1.1655  Acc@1: 56.2500 (61.6105)  Acc@5: 87.5000 (90.6555)  time: 0.3475  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:19  Lr: 0.001875  Loss: 0.6721  Acc@1: 56.2500 (61.6143)  Acc@5: 93.7500 (90.6617)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:16  Lr: 0.001875  Loss: 1.4546  Acc@1: 62.5000 (61.6243)  Acc@5: 93.7500 (90.6632)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:13  Lr: 0.001875  Loss: 1.4275  Acc@1: 62.5000 (61.6234)  Acc@5: 93.7500 (90.6662)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 1.0685  Acc@1: 62.5000 (61.6395)  Acc@5: 93.7500 (90.6707)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:06  Lr: 0.001875  Loss: 0.8592  Acc@1: 62.5000 (61.6493)  Acc@5: 93.7500 (90.6706)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 0.7700  Acc@1: 68.7500 (61.6592)  Acc@5: 93.7500 (90.6736)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4060/4579]  eta: 0:02:59  Lr: 0.001875  Loss: 1.3092  Acc@1: 68.7500 (61.6582)  Acc@5: 93.7500 (90.6781)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4070/4579]  eta: 0:02:55  Lr: 0.001875  Loss: 1.1715  Acc@1: 56.2500 (61.6525)  Acc@5: 93.7500 (90.6826)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4080/4579]  eta: 0:02:52  Lr: 0.001875  Loss: 1.2747  Acc@1: 56.2500 (61.6531)  Acc@5: 93.7500 (90.6870)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4090/4579]  eta: 0:02:48  Lr: 0.001875  Loss: 1.3192  Acc@1: 62.5000 (61.6628)  Acc@5: 93.7500 (90.6915)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4100/4579]  eta: 0:02:45  Lr: 0.001875  Loss: 1.4542  Acc@1: 62.5000 (61.6603)  Acc@5: 87.5000 (90.6852)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4110/4579]  eta: 0:02:41  Lr: 0.001875  Loss: 1.1326  Acc@1: 62.5000 (61.6760)  Acc@5: 87.5000 (90.6820)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4120/4579]  eta: 0:02:38  Lr: 0.001875  Loss: 0.5765  Acc@1: 62.5000 (61.6750)  Acc@5: 87.5000 (90.6834)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:35  Lr: 0.001875  Loss: 1.4143  Acc@1: 56.2500 (61.6649)  Acc@5: 87.5000 (90.6757)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:31  Lr: 0.001875  Loss: 1.0490  Acc@1: 68.7500 (61.6835)  Acc@5: 93.7500 (90.6816)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:28  Lr: 0.001875  Loss: 0.9380  Acc@1: 62.5000 (61.6764)  Acc@5: 93.7500 (90.6800)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:24  Lr: 0.001875  Loss: 0.8434  Acc@1: 62.5000 (61.6919)  Acc@5: 93.7500 (90.6783)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:21  Lr: 0.001875  Loss: 1.2071  Acc@1: 68.7500 (61.6998)  Acc@5: 93.7500 (90.6842)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:17  Lr: 0.001875  Loss: 0.9457  Acc@1: 62.5000 (61.7092)  Acc@5: 93.7500 (90.6840)  time: 0.3469  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:14  Lr: 0.001875  Loss: 1.2667  Acc@1: 56.2500 (61.7081)  Acc@5: 93.7500 (90.6794)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:10  Lr: 0.001875  Loss: 1.1230  Acc@1: 56.2500 (61.6981)  Acc@5: 87.5000 (90.6778)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:07  Lr: 0.001875  Loss: 1.3693  Acc@1: 56.2500 (61.6807)  Acc@5: 87.5000 (90.6599)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:03  Lr: 0.001875  Loss: 0.9032  Acc@1: 56.2500 (61.6930)  Acc@5: 87.5000 (90.6687)  time: 0.3451  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:00  Lr: 0.001875  Loss: 0.9478  Acc@1: 68.7500 (61.7082)  Acc@5: 93.7500 (90.6701)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 1.1660  Acc@1: 62.5000 (61.7130)  Acc@5: 93.7500 (90.6699)  time: 0.3463  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [4250/4579]  eta: 0:01:53  Lr: 0.001875  Loss: 1.6967  Acc@1: 62.5000 (61.7031)  Acc@5: 87.5000 (90.6713)  time: 0.3469  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: 1.1725  Acc@1: 62.5000 (61.7021)  Acc@5: 87.5000 (90.6683)  time: 0.3448  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4270/4579]  eta: 0:01:46  Lr: 0.001875  Loss: 1.4645  Acc@1: 62.5000 (61.7025)  Acc@5: 87.5000 (90.6740)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: 1.0149  Acc@1: 62.5000 (61.6912)  Acc@5: 87.5000 (90.6695)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:39  Lr: 0.001875  Loss: 0.8987  Acc@1: 62.5000 (61.6814)  Acc@5: 93.7500 (90.6753)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 1.1925  Acc@1: 62.5000 (61.6848)  Acc@5: 93.7500 (90.6650)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:32  Lr: 0.001875  Loss: 0.7914  Acc@1: 62.5000 (61.6751)  Acc@5: 87.5000 (90.6591)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:29  Lr: 0.001875  Loss: 0.9552  Acc@1: 62.5000 (61.6813)  Acc@5: 87.5000 (90.6518)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:25  Lr: 0.001875  Loss: 0.9498  Acc@1: 68.7500 (61.6890)  Acc@5: 87.5000 (90.6531)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:22  Lr: 0.001875  Loss: 0.8089  Acc@1: 68.7500 (61.6995)  Acc@5: 87.5000 (90.6502)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: 1.2839  Acc@1: 62.5000 (61.7056)  Acc@5: 87.5000 (90.6516)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:15  Lr: 0.001875  Loss: 1.3666  Acc@1: 62.5000 (61.7017)  Acc@5: 93.7500 (90.6529)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: 1.2958  Acc@1: 62.5000 (61.7121)  Acc@5: 93.7500 (90.6600)  time: 0.3447  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:08  Lr: 0.001875  Loss: 0.9477  Acc@1: 62.5000 (61.6997)  Acc@5: 93.7500 (90.6642)  time: 0.3449  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 1.4404  Acc@1: 62.5000 (61.6986)  Acc@5: 93.7500 (90.6613)  time: 0.3438  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:01  Lr: 0.001875  Loss: 0.7767  Acc@1: 62.5000 (61.7047)  Acc@5: 93.7500 (90.6641)  time: 0.3440  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: 1.0667  Acc@1: 62.5000 (61.7094)  Acc@5: 93.7500 (90.6625)  time: 0.3447  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4420/4579]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6960  Acc@1: 62.5000 (61.7097)  Acc@5: 93.7500 (90.6766)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 1.0784  Acc@1: 62.5000 (61.7101)  Acc@5: 93.7500 (90.6779)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7346  Acc@1: 62.5000 (61.7231)  Acc@5: 93.7500 (90.6792)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 0.8811  Acc@1: 62.5000 (61.7347)  Acc@5: 93.7500 (90.6791)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 1.0955  Acc@1: 68.7500 (61.7547)  Acc@5: 93.7500 (90.6817)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: 0.7850  Acc@1: 68.7500 (61.7759)  Acc@5: 93.7500 (90.6900)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: 1.2650  Acc@1: 68.7500 (61.7873)  Acc@5: 93.7500 (90.6913)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: 0.9163  Acc@1: 68.7500 (61.7958)  Acc@5: 93.7500 (90.6869)  time: 0.3452  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: 0.8392  Acc@1: 62.5000 (61.7904)  Acc@5: 87.5000 (90.6771)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: 1.2627  Acc@1: 62.5000 (61.8059)  Acc@5: 87.5000 (90.6811)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 1.2970  Acc@1: 62.5000 (61.8033)  Acc@5: 93.7500 (90.6865)  time: 0.3454  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:16  Lr: 0.001875  Loss: 1.1803  Acc@1: 62.5000 (61.8117)  Acc@5: 93.7500 (90.6836)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 1.1320  Acc@1: 68.7500 (61.8242)  Acc@5: 87.5000 (90.6862)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 0.7954  Acc@1: 62.5000 (61.8298)  Acc@5: 93.7500 (90.6889)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 1.8695  Acc@1: 62.5000 (61.8299)  Acc@5: 87.5000 (90.6819)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 1.1126  Acc@1: 62.5000 (61.8259)  Acc@5: 87.5000 (90.6804)  time: 0.3465  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.9700  Acc@1: 62.5000 (61.8303)  Acc@5: 93.7500 (90.6821)  time: 0.3389  data: 0.0015  max mem: 2500
Train: Epoch[2/5] Total time: 0:26:22 (0.3455 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.9700  Acc@1: 62.5000 (61.8303)  Acc@5: 93.7500 (90.6821)
Train: Epoch[3/5]  [   0/4579]  eta: 0:51:45  Lr: 0.001875  Loss: 1.3584  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 0.6782  data: 0.3303  max mem: 2500
Train: Epoch[3/5]  [  10/4579]  eta: 0:28:47  Lr: 0.001875  Loss: 1.0105  Acc@1: 68.7500 (69.3182)  Acc@5: 93.7500 (92.6136)  time: 0.3780  data: 0.0304  max mem: 2500
Train: Epoch[3/5]  [  20/4579]  eta: 0:27:44  Lr: 0.001875  Loss: 1.3039  Acc@1: 62.5000 (66.0714)  Acc@5: 87.5000 (88.9881)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  30/4579]  eta: 0:27:12  Lr: 0.001875  Loss: 1.2829  Acc@1: 62.5000 (66.5323)  Acc@5: 87.5000 (89.7177)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  40/4579]  eta: 0:26:54  Lr: 0.001875  Loss: 0.5883  Acc@1: 62.5000 (65.3963)  Acc@5: 93.7500 (89.9390)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  50/4579]  eta: 0:26:41  Lr: 0.001875  Loss: 1.3880  Acc@1: 56.2500 (63.1127)  Acc@5: 87.5000 (89.2157)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  60/4579]  eta: 0:26:33  Lr: 0.001875  Loss: 1.0712  Acc@1: 62.5000 (64.4467)  Acc@5: 87.5000 (89.4467)  time: 0.3463  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [  70/4579]  eta: 0:26:25  Lr: 0.001875  Loss: 1.3171  Acc@1: 62.5000 (63.5563)  Acc@5: 87.5000 (89.3486)  time: 0.3464  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [  80/4579]  eta: 0:26:18  Lr: 0.001875  Loss: 0.7441  Acc@1: 62.5000 (63.7346)  Acc@5: 87.5000 (89.6605)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  90/4579]  eta: 0:26:13  Lr: 0.001875  Loss: 0.9907  Acc@1: 62.5000 (63.8049)  Acc@5: 93.7500 (89.6291)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 100/4579]  eta: 0:26:08  Lr: 0.001875  Loss: 0.7354  Acc@1: 62.5000 (63.7376)  Acc@5: 93.7500 (90.0371)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 110/4579]  eta: 0:26:03  Lr: 0.001875  Loss: 1.0011  Acc@1: 62.5000 (63.8514)  Acc@5: 93.7500 (90.0901)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 120/4579]  eta: 0:25:58  Lr: 0.001875  Loss: 1.2299  Acc@1: 62.5000 (63.8946)  Acc@5: 93.7500 (90.5475)  time: 0.3457  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 130/4579]  eta: 0:25:54  Lr: 0.001875  Loss: 0.9763  Acc@1: 62.5000 (63.9790)  Acc@5: 93.7500 (90.6966)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 140/4579]  eta: 0:25:49  Lr: 0.001875  Loss: 1.1205  Acc@1: 62.5000 (63.7855)  Acc@5: 93.7500 (90.9574)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 150/4579]  eta: 0:25:44  Lr: 0.001875  Loss: 0.6400  Acc@1: 62.5000 (63.9487)  Acc@5: 93.7500 (90.9768)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 160/4579]  eta: 0:25:40  Lr: 0.001875  Loss: 1.2570  Acc@1: 62.5000 (64.1693)  Acc@5: 87.5000 (90.9161)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 170/4579]  eta: 0:25:35  Lr: 0.001875  Loss: 0.9743  Acc@1: 62.5000 (64.3275)  Acc@5: 93.7500 (91.0088)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 180/4579]  eta: 0:25:31  Lr: 0.001875  Loss: 0.8240  Acc@1: 68.7500 (64.6754)  Acc@5: 93.7500 (91.2638)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 190/4579]  eta: 0:25:27  Lr: 0.001875  Loss: 0.9678  Acc@1: 62.5000 (64.4961)  Acc@5: 93.7500 (91.1322)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 200/4579]  eta: 0:25:22  Lr: 0.001875  Loss: 0.8579  Acc@1: 62.5000 (64.4900)  Acc@5: 93.7500 (91.2624)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 210/4579]  eta: 0:25:18  Lr: 0.001875  Loss: 0.9415  Acc@1: 68.7500 (64.6623)  Acc@5: 93.7500 (91.3211)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 220/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 1.5768  Acc@1: 68.7500 (64.5079)  Acc@5: 93.7500 (91.4027)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 230/4579]  eta: 0:25:10  Lr: 0.001875  Loss: 0.6097  Acc@1: 62.5000 (64.5292)  Acc@5: 93.7500 (91.4232)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 240/4579]  eta: 0:25:06  Lr: 0.001875  Loss: 0.7705  Acc@1: 68.7500 (64.5747)  Acc@5: 87.5000 (91.4160)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 250/4579]  eta: 0:25:02  Lr: 0.001875  Loss: 1.0449  Acc@1: 62.5000 (64.3177)  Acc@5: 93.7500 (91.3845)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 260/4579]  eta: 0:24:58  Lr: 0.001875  Loss: 0.6888  Acc@1: 62.5000 (64.3439)  Acc@5: 93.7500 (91.4272)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 270/4579]  eta: 0:24:54  Lr: 0.001875  Loss: 1.0958  Acc@1: 62.5000 (64.2989)  Acc@5: 93.7500 (91.4668)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 280/4579]  eta: 0:24:50  Lr: 0.001875  Loss: 1.1758  Acc@1: 62.5000 (64.3016)  Acc@5: 93.7500 (91.4591)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 290/4579]  eta: 0:24:47  Lr: 0.001875  Loss: 0.8582  Acc@1: 62.5000 (64.2397)  Acc@5: 93.7500 (91.6022)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 300/4579]  eta: 0:24:43  Lr: 0.001875  Loss: 1.0844  Acc@1: 62.5000 (64.0781)  Acc@5: 93.7500 (91.4244)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 310/4579]  eta: 0:24:39  Lr: 0.001875  Loss: 1.5469  Acc@1: 56.2500 (63.9670)  Acc@5: 87.5000 (91.3786)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 320/4579]  eta: 0:24:36  Lr: 0.001875  Loss: 1.2883  Acc@1: 62.5000 (64.0771)  Acc@5: 87.5000 (91.3941)  time: 0.3445  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 330/4579]  eta: 0:24:32  Lr: 0.001875  Loss: 1.2784  Acc@1: 62.5000 (63.9162)  Acc@5: 87.5000 (91.2198)  time: 0.3462  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 340/4579]  eta: 0:24:29  Lr: 0.001875  Loss: 1.5253  Acc@1: 62.5000 (63.8563)  Acc@5: 87.5000 (91.1840)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 350/4579]  eta: 0:24:25  Lr: 0.001875  Loss: 0.9692  Acc@1: 62.5000 (63.8355)  Acc@5: 93.7500 (91.1681)  time: 0.3438  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 360/4579]  eta: 0:24:21  Lr: 0.001875  Loss: 1.3744  Acc@1: 62.5000 (63.7812)  Acc@5: 93.7500 (91.1877)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 370/4579]  eta: 0:24:18  Lr: 0.001875  Loss: 0.9876  Acc@1: 56.2500 (63.6961)  Acc@5: 93.7500 (91.2062)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 380/4579]  eta: 0:24:14  Lr: 0.001875  Loss: 0.8578  Acc@1: 62.5000 (63.8615)  Acc@5: 93.7500 (91.2894)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 390/4579]  eta: 0:24:10  Lr: 0.001875  Loss: 0.6427  Acc@1: 68.7500 (63.8427)  Acc@5: 93.7500 (91.3043)  time: 0.3440  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 400/4579]  eta: 0:24:06  Lr: 0.001875  Loss: 1.4559  Acc@1: 68.7500 (63.8716)  Acc@5: 93.7500 (91.3965)  time: 0.3444  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 410/4579]  eta: 0:24:03  Lr: 0.001875  Loss: 0.7641  Acc@1: 68.7500 (64.1271)  Acc@5: 93.7500 (91.4386)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 420/4579]  eta: 0:23:59  Lr: 0.001875  Loss: 1.0814  Acc@1: 68.7500 (64.1330)  Acc@5: 93.7500 (91.4638)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 430/4579]  eta: 0:23:56  Lr: 0.001875  Loss: 0.8237  Acc@1: 56.2500 (64.0371)  Acc@5: 93.7500 (91.4588)  time: 0.3455  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 440/4579]  eta: 0:23:52  Lr: 0.001875  Loss: 1.0717  Acc@1: 56.2500 (64.0023)  Acc@5: 87.5000 (91.4257)  time: 0.3456  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 450/4579]  eta: 0:23:48  Lr: 0.001875  Loss: 0.8739  Acc@1: 68.7500 (64.1214)  Acc@5: 87.5000 (91.3941)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 460/4579]  eta: 0:23:45  Lr: 0.001875  Loss: 1.5645  Acc@1: 68.7500 (64.0456)  Acc@5: 87.5000 (91.3774)  time: 0.3451  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 470/4579]  eta: 0:23:41  Lr: 0.001875  Loss: 1.4672  Acc@1: 56.2500 (63.9597)  Acc@5: 93.7500 (91.4411)  time: 0.3452  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 480/4579]  eta: 0:23:38  Lr: 0.001875  Loss: 0.8236  Acc@1: 62.5000 (63.9683)  Acc@5: 93.7500 (91.4241)  time: 0.3452  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 490/4579]  eta: 0:23:34  Lr: 0.001875  Loss: 1.5384  Acc@1: 62.5000 (63.9511)  Acc@5: 93.7500 (91.3824)  time: 0.3455  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 500/4579]  eta: 0:23:31  Lr: 0.001875  Loss: 1.1652  Acc@1: 62.5000 (63.9346)  Acc@5: 93.7500 (91.4296)  time: 0.3443  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 510/4579]  eta: 0:23:27  Lr: 0.001875  Loss: 1.3665  Acc@1: 56.2500 (63.7965)  Acc@5: 93.7500 (91.4750)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 520/4579]  eta: 0:23:23  Lr: 0.001875  Loss: 1.3733  Acc@1: 62.5000 (63.8556)  Acc@5: 93.7500 (91.4347)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 530/4579]  eta: 0:23:20  Lr: 0.001875  Loss: 1.1473  Acc@1: 68.7500 (63.9242)  Acc@5: 93.7500 (91.4901)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 540/4579]  eta: 0:23:16  Lr: 0.001875  Loss: 1.1133  Acc@1: 68.7500 (63.9556)  Acc@5: 93.7500 (91.5319)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 550/4579]  eta: 0:23:13  Lr: 0.001875  Loss: 1.0692  Acc@1: 68.7500 (63.9179)  Acc@5: 93.7500 (91.5154)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 560/4579]  eta: 0:23:09  Lr: 0.001875  Loss: 0.9927  Acc@1: 62.5000 (63.8815)  Acc@5: 93.7500 (91.5330)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 570/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 0.7226  Acc@1: 62.5000 (63.9339)  Acc@5: 93.7500 (91.5609)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 580/4579]  eta: 0:23:03  Lr: 0.001875  Loss: 1.3127  Acc@1: 56.2500 (63.8447)  Acc@5: 87.5000 (91.5340)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 590/4579]  eta: 0:22:59  Lr: 0.001875  Loss: 0.8740  Acc@1: 62.5000 (63.8325)  Acc@5: 87.5000 (91.5080)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 600/4579]  eta: 0:22:56  Lr: 0.001875  Loss: 1.5827  Acc@1: 62.5000 (63.8207)  Acc@5: 87.5000 (91.4829)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 610/4579]  eta: 0:22:52  Lr: 0.001875  Loss: 0.9914  Acc@1: 62.5000 (63.7275)  Acc@5: 87.5000 (91.4587)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 620/4579]  eta: 0:22:48  Lr: 0.001875  Loss: 1.6053  Acc@1: 56.2500 (63.6876)  Acc@5: 93.7500 (91.4553)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 630/4579]  eta: 0:22:45  Lr: 0.001875  Loss: 1.2318  Acc@1: 68.7500 (63.7876)  Acc@5: 93.7500 (91.5016)  time: 0.3458  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 640/4579]  eta: 0:22:42  Lr: 0.001875  Loss: 0.7135  Acc@1: 68.7500 (63.7578)  Acc@5: 93.7500 (91.4489)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 650/4579]  eta: 0:22:38  Lr: 0.001875  Loss: 1.1092  Acc@1: 68.7500 (63.8441)  Acc@5: 87.5000 (91.3978)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 660/4579]  eta: 0:22:35  Lr: 0.001875  Loss: 1.1247  Acc@1: 68.7500 (63.8427)  Acc@5: 87.5000 (91.3672)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 670/4579]  eta: 0:22:31  Lr: 0.001875  Loss: 0.9572  Acc@1: 62.5000 (63.8133)  Acc@5: 87.5000 (91.3282)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 680/4579]  eta: 0:22:28  Lr: 0.001875  Loss: 0.9719  Acc@1: 68.7500 (63.9134)  Acc@5: 93.7500 (91.3730)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 690/4579]  eta: 0:22:24  Lr: 0.001875  Loss: 0.8133  Acc@1: 68.7500 (63.8748)  Acc@5: 93.7500 (91.3802)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 700/4579]  eta: 0:22:21  Lr: 0.001875  Loss: 0.9971  Acc@1: 68.7500 (63.8998)  Acc@5: 93.7500 (91.3962)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 710/4579]  eta: 0:22:17  Lr: 0.001875  Loss: 0.9853  Acc@1: 68.7500 (63.9944)  Acc@5: 93.7500 (91.4293)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 720/4579]  eta: 0:22:14  Lr: 0.001875  Loss: 1.1437  Acc@1: 68.7500 (63.9997)  Acc@5: 93.7500 (91.4875)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 730/4579]  eta: 0:22:10  Lr: 0.001875  Loss: 1.0524  Acc@1: 62.5000 (64.0048)  Acc@5: 93.7500 (91.5014)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 740/4579]  eta: 0:22:07  Lr: 0.001875  Loss: 1.0216  Acc@1: 62.5000 (64.0182)  Acc@5: 93.7500 (91.5148)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 750/4579]  eta: 0:22:03  Lr: 0.001875  Loss: 1.0752  Acc@1: 62.5000 (63.9564)  Acc@5: 93.7500 (91.5363)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 760/4579]  eta: 0:22:00  Lr: 0.001875  Loss: 1.0892  Acc@1: 56.2500 (63.8633)  Acc@5: 87.5000 (91.4915)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 770/4579]  eta: 0:21:57  Lr: 0.001875  Loss: 1.1658  Acc@1: 56.2500 (63.8375)  Acc@5: 87.5000 (91.4964)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 780/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 0.9285  Acc@1: 62.5000 (63.7964)  Acc@5: 93.7500 (91.5253)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 790/4579]  eta: 0:21:50  Lr: 0.001875  Loss: 0.9677  Acc@1: 62.5000 (63.8116)  Acc@5: 93.7500 (91.5139)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 800/4579]  eta: 0:21:46  Lr: 0.001875  Loss: 0.9339  Acc@1: 62.5000 (63.8109)  Acc@5: 93.7500 (91.5340)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 810/4579]  eta: 0:21:43  Lr: 0.001875  Loss: 0.7988  Acc@1: 62.5000 (63.7716)  Acc@5: 93.7500 (91.5536)  time: 0.3472  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 820/4579]  eta: 0:21:39  Lr: 0.001875  Loss: 0.9139  Acc@1: 56.2500 (63.7028)  Acc@5: 93.7500 (91.5880)  time: 0.3465  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 830/4579]  eta: 0:21:36  Lr: 0.001875  Loss: 1.6161  Acc@1: 62.5000 (63.6733)  Acc@5: 93.7500 (91.5915)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 840/4579]  eta: 0:21:32  Lr: 0.001875  Loss: 1.4832  Acc@1: 62.5000 (63.6296)  Acc@5: 93.7500 (91.5948)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 850/4579]  eta: 0:21:29  Lr: 0.001875  Loss: 1.0641  Acc@1: 68.7500 (63.6604)  Acc@5: 93.7500 (91.6055)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 860/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 1.3329  Acc@1: 62.5000 (63.6614)  Acc@5: 93.7500 (91.6376)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 870/4579]  eta: 0:21:22  Lr: 0.001875  Loss: 1.2713  Acc@1: 62.5000 (63.6122)  Acc@5: 93.7500 (91.6045)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 880/4579]  eta: 0:21:19  Lr: 0.001875  Loss: 0.8479  Acc@1: 62.5000 (63.6351)  Acc@5: 93.7500 (91.5792)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 890/4579]  eta: 0:21:15  Lr: 0.001875  Loss: 1.1330  Acc@1: 68.7500 (63.6995)  Acc@5: 93.7500 (91.5825)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 900/4579]  eta: 0:21:11  Lr: 0.001875  Loss: 1.1024  Acc@1: 68.7500 (63.7486)  Acc@5: 93.7500 (91.6274)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 910/4579]  eta: 0:21:08  Lr: 0.001875  Loss: 0.6308  Acc@1: 62.5000 (63.6937)  Acc@5: 93.7500 (91.5752)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 920/4579]  eta: 0:21:05  Lr: 0.001875  Loss: 0.9870  Acc@1: 62.5000 (63.6469)  Acc@5: 93.7500 (91.5784)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 930/4579]  eta: 0:21:01  Lr: 0.001875  Loss: 0.8695  Acc@1: 62.5000 (63.6748)  Acc@5: 93.7500 (91.5816)  time: 0.3456  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 940/4579]  eta: 0:20:58  Lr: 0.001875  Loss: 1.6911  Acc@1: 62.5000 (63.6623)  Acc@5: 93.7500 (91.5648)  time: 0.3448  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 950/4579]  eta: 0:20:54  Lr: 0.001875  Loss: 1.1754  Acc@1: 62.5000 (63.6632)  Acc@5: 87.5000 (91.5615)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 960/4579]  eta: 0:20:51  Lr: 0.001875  Loss: 1.3949  Acc@1: 62.5000 (63.6576)  Acc@5: 93.7500 (91.5713)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 970/4579]  eta: 0:20:47  Lr: 0.001875  Loss: 1.1029  Acc@1: 62.5000 (63.6972)  Acc@5: 93.7500 (91.6259)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 980/4579]  eta: 0:20:44  Lr: 0.001875  Loss: 1.0659  Acc@1: 68.7500 (63.6914)  Acc@5: 93.7500 (91.6221)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 990/4579]  eta: 0:20:40  Lr: 0.001875  Loss: 0.6260  Acc@1: 62.5000 (63.6604)  Acc@5: 93.7500 (91.6057)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1000/4579]  eta: 0:20:37  Lr: 0.001875  Loss: 1.0015  Acc@1: 56.2500 (63.6176)  Acc@5: 93.7500 (91.5709)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1010/4579]  eta: 0:20:33  Lr: 0.001875  Loss: 0.7438  Acc@1: 62.5000 (63.6189)  Acc@5: 87.5000 (91.5554)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1020/4579]  eta: 0:20:30  Lr: 0.001875  Loss: 1.3619  Acc@1: 62.5000 (63.6080)  Acc@5: 93.7500 (91.5891)  time: 0.3449  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1030/4579]  eta: 0:20:26  Lr: 0.001875  Loss: 0.7866  Acc@1: 62.5000 (63.6094)  Acc@5: 93.7500 (91.5737)  time: 0.3449  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1040/4579]  eta: 0:20:23  Lr: 0.001875  Loss: 1.3080  Acc@1: 56.2500 (63.5927)  Acc@5: 93.7500 (91.5946)  time: 0.3454  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1050/4579]  eta: 0:20:19  Lr: 0.001875  Loss: 1.1051  Acc@1: 62.5000 (63.6001)  Acc@5: 93.7500 (91.5913)  time: 0.3453  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1060/4579]  eta: 0:20:16  Lr: 0.001875  Loss: 0.9438  Acc@1: 68.7500 (63.6192)  Acc@5: 87.5000 (91.6058)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1070/4579]  eta: 0:20:13  Lr: 0.001875  Loss: 1.6999  Acc@1: 68.7500 (63.6438)  Acc@5: 93.7500 (91.6025)  time: 0.3458  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1080/4579]  eta: 0:20:09  Lr: 0.001875  Loss: 1.2741  Acc@1: 62.5000 (63.5870)  Acc@5: 93.7500 (91.6281)  time: 0.3459  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1090/4579]  eta: 0:20:05  Lr: 0.001875  Loss: 0.4418  Acc@1: 62.5000 (63.6114)  Acc@5: 93.7500 (91.6476)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1100/4579]  eta: 0:20:02  Lr: 0.001875  Loss: 1.2337  Acc@1: 62.5000 (63.6240)  Acc@5: 93.7500 (91.6553)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1110/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 1.2026  Acc@1: 62.5000 (63.5857)  Acc@5: 93.7500 (91.6573)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1120/4579]  eta: 0:19:55  Lr: 0.001875  Loss: 0.8001  Acc@1: 56.2500 (63.5983)  Acc@5: 93.7500 (91.6369)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1130/4579]  eta: 0:19:52  Lr: 0.001875  Loss: 0.8329  Acc@1: 62.5000 (63.5831)  Acc@5: 93.7500 (91.6777)  time: 0.3454  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1140/4579]  eta: 0:19:48  Lr: 0.001875  Loss: 0.7470  Acc@1: 68.7500 (63.6394)  Acc@5: 93.7500 (91.7014)  time: 0.3469  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1150/4579]  eta: 0:19:45  Lr: 0.001875  Loss: 0.8951  Acc@1: 68.7500 (63.6783)  Acc@5: 93.7500 (91.6866)  time: 0.3458  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1160/4579]  eta: 0:19:41  Lr: 0.001875  Loss: 0.9416  Acc@1: 62.5000 (63.6413)  Acc@5: 93.7500 (91.6990)  time: 0.3440  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1170/4579]  eta: 0:19:38  Lr: 0.001875  Loss: 0.8457  Acc@1: 62.5000 (63.6689)  Acc@5: 93.7500 (91.6898)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1180/4579]  eta: 0:19:34  Lr: 0.001875  Loss: 0.9352  Acc@1: 62.5000 (63.7119)  Acc@5: 93.7500 (91.7231)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1190/4579]  eta: 0:19:31  Lr: 0.001875  Loss: 1.1563  Acc@1: 62.5000 (63.7122)  Acc@5: 93.7500 (91.7139)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1200/4579]  eta: 0:19:27  Lr: 0.001875  Loss: 0.8504  Acc@1: 62.5000 (63.7021)  Acc@5: 93.7500 (91.6996)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1210/4579]  eta: 0:19:24  Lr: 0.001875  Loss: 0.5003  Acc@1: 62.5000 (63.7077)  Acc@5: 93.7500 (91.7011)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1220/4579]  eta: 0:19:20  Lr: 0.001875  Loss: 1.4569  Acc@1: 62.5000 (63.6927)  Acc@5: 93.7500 (91.6923)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1230/4579]  eta: 0:19:17  Lr: 0.001875  Loss: 0.7792  Acc@1: 62.5000 (63.6982)  Acc@5: 87.5000 (91.6887)  time: 0.3471  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1240/4579]  eta: 0:19:14  Lr: 0.001875  Loss: 1.1257  Acc@1: 62.5000 (63.7137)  Acc@5: 87.5000 (91.6751)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1250/4579]  eta: 0:19:10  Lr: 0.001875  Loss: 0.8388  Acc@1: 62.5000 (63.7090)  Acc@5: 87.5000 (91.6567)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1260/4579]  eta: 0:19:07  Lr: 0.001875  Loss: 1.3237  Acc@1: 62.5000 (63.6945)  Acc@5: 87.5000 (91.6435)  time: 0.3472  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1270/4579]  eta: 0:19:03  Lr: 0.001875  Loss: 1.3779  Acc@1: 62.5000 (63.6802)  Acc@5: 87.5000 (91.6257)  time: 0.3465  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1280/4579]  eta: 0:19:00  Lr: 0.001875  Loss: 1.1502  Acc@1: 56.2500 (63.6758)  Acc@5: 87.5000 (91.6179)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1290/4579]  eta: 0:18:56  Lr: 0.001875  Loss: 1.1289  Acc@1: 62.5000 (63.7006)  Acc@5: 93.7500 (91.6150)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1300/4579]  eta: 0:18:53  Lr: 0.001875  Loss: 1.3140  Acc@1: 62.5000 (63.6722)  Acc@5: 93.7500 (91.5930)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1310/4579]  eta: 0:18:49  Lr: 0.001875  Loss: 1.8159  Acc@1: 62.5000 (63.6299)  Acc@5: 87.5000 (91.5809)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1320/4579]  eta: 0:18:46  Lr: 0.001875  Loss: 1.2494  Acc@1: 62.5000 (63.5977)  Acc@5: 87.5000 (91.5216)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1330/4579]  eta: 0:18:42  Lr: 0.001875  Loss: 0.9854  Acc@1: 62.5000 (63.5753)  Acc@5: 87.5000 (91.5336)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1340/4579]  eta: 0:18:39  Lr: 0.001875  Loss: 1.1563  Acc@1: 56.2500 (63.5300)  Acc@5: 93.7500 (91.5175)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1350/4579]  eta: 0:18:36  Lr: 0.001875  Loss: 1.0220  Acc@1: 56.2500 (63.5270)  Acc@5: 93.7500 (91.5387)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1360/4579]  eta: 0:18:32  Lr: 0.001875  Loss: 1.1563  Acc@1: 56.2500 (63.4873)  Acc@5: 93.7500 (91.5228)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1370/4579]  eta: 0:18:29  Lr: 0.001875  Loss: 0.9479  Acc@1: 62.5000 (63.5029)  Acc@5: 93.7500 (91.5071)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1380/4579]  eta: 0:18:25  Lr: 0.001875  Loss: 1.1302  Acc@1: 68.7500 (63.5319)  Acc@5: 93.7500 (91.5188)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1390/4579]  eta: 0:18:22  Lr: 0.001875  Loss: 1.1625  Acc@1: 62.5000 (63.5199)  Acc@5: 93.7500 (91.5573)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1400/4579]  eta: 0:18:18  Lr: 0.001875  Loss: 1.2284  Acc@1: 62.5000 (63.4859)  Acc@5: 93.7500 (91.5150)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1410/4579]  eta: 0:18:15  Lr: 0.001875  Loss: 1.3033  Acc@1: 62.5000 (63.4701)  Acc@5: 87.5000 (91.4954)  time: 0.3469  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1420/4579]  eta: 0:18:11  Lr: 0.001875  Loss: 1.2901  Acc@1: 62.5000 (63.4368)  Acc@5: 87.5000 (91.4673)  time: 0.3479  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [1430/4579]  eta: 0:18:08  Lr: 0.001875  Loss: 0.9183  Acc@1: 62.5000 (63.4609)  Acc@5: 87.5000 (91.4745)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1440/4579]  eta: 0:18:04  Lr: 0.001875  Loss: 1.4026  Acc@1: 62.5000 (63.4715)  Acc@5: 93.7500 (91.4903)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1450/4579]  eta: 0:18:01  Lr: 0.001875  Loss: 1.3627  Acc@1: 62.5000 (63.4605)  Acc@5: 93.7500 (91.4886)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1460/4579]  eta: 0:17:58  Lr: 0.001875  Loss: 0.7727  Acc@1: 62.5000 (63.4582)  Acc@5: 93.7500 (91.4699)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1470/4579]  eta: 0:17:54  Lr: 0.001875  Loss: 0.6399  Acc@1: 62.5000 (63.4645)  Acc@5: 93.7500 (91.4684)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1480/4579]  eta: 0:17:51  Lr: 0.001875  Loss: 1.4007  Acc@1: 68.7500 (63.4706)  Acc@5: 87.5000 (91.4585)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1490/4579]  eta: 0:17:47  Lr: 0.001875  Loss: 1.0664  Acc@1: 68.7500 (63.5060)  Acc@5: 87.5000 (91.4445)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1500/4579]  eta: 0:17:44  Lr: 0.001875  Loss: 0.8836  Acc@1: 62.5000 (63.4868)  Acc@5: 93.7500 (91.4557)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1510/4579]  eta: 0:17:40  Lr: 0.001875  Loss: 0.8885  Acc@1: 62.5000 (63.4638)  Acc@5: 87.5000 (91.4419)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1520/4579]  eta: 0:17:37  Lr: 0.001875  Loss: 0.4592  Acc@1: 62.5000 (63.4985)  Acc@5: 87.5000 (91.4489)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1530/4579]  eta: 0:17:33  Lr: 0.001875  Loss: 1.2009  Acc@1: 62.5000 (63.5247)  Acc@5: 93.7500 (91.4476)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1540/4579]  eta: 0:17:30  Lr: 0.001875  Loss: 1.0838  Acc@1: 62.5000 (63.5058)  Acc@5: 87.5000 (91.4260)  time: 0.3477  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1550/4579]  eta: 0:17:27  Lr: 0.001875  Loss: 0.9010  Acc@1: 68.7500 (63.5397)  Acc@5: 87.5000 (91.4289)  time: 0.3476  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1560/4579]  eta: 0:17:23  Lr: 0.001875  Loss: 0.4711  Acc@1: 68.7500 (63.5690)  Acc@5: 93.7500 (91.4358)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1570/4579]  eta: 0:17:20  Lr: 0.001875  Loss: 1.3227  Acc@1: 68.7500 (63.5940)  Acc@5: 87.5000 (91.4028)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/4579]  eta: 0:17:16  Lr: 0.001875  Loss: 1.3336  Acc@1: 68.7500 (63.5792)  Acc@5: 87.5000 (91.3978)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1590/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 0.9847  Acc@1: 62.5000 (63.5685)  Acc@5: 93.7500 (91.4008)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1600/4579]  eta: 0:17:09  Lr: 0.001875  Loss: 1.1011  Acc@1: 62.5000 (63.5540)  Acc@5: 87.5000 (91.3765)  time: 0.3467  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1610/4579]  eta: 0:17:06  Lr: 0.001875  Loss: 1.0642  Acc@1: 62.5000 (63.5281)  Acc@5: 87.5000 (91.3563)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1620/4579]  eta: 0:17:02  Lr: 0.001875  Loss: 1.1627  Acc@1: 62.5000 (63.5102)  Acc@5: 87.5000 (91.3402)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1630/4579]  eta: 0:16:59  Lr: 0.001875  Loss: 1.3033  Acc@1: 62.5000 (63.5040)  Acc@5: 93.7500 (91.3320)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1640/4579]  eta: 0:16:56  Lr: 0.001875  Loss: 0.9780  Acc@1: 62.5000 (63.5055)  Acc@5: 93.7500 (91.3239)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1650/4579]  eta: 0:16:52  Lr: 0.001875  Loss: 1.3085  Acc@1: 62.5000 (63.4843)  Acc@5: 93.7500 (91.3272)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1660/4579]  eta: 0:16:49  Lr: 0.001875  Loss: 1.0171  Acc@1: 68.7500 (63.4971)  Acc@5: 93.7500 (91.3230)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1670/4579]  eta: 0:16:45  Lr: 0.001875  Loss: 1.2393  Acc@1: 68.7500 (63.5099)  Acc@5: 93.7500 (91.3151)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1680/4579]  eta: 0:16:42  Lr: 0.001875  Loss: 0.6410  Acc@1: 68.7500 (63.5299)  Acc@5: 93.7500 (91.3147)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1690/4579]  eta: 0:16:38  Lr: 0.001875  Loss: 0.9570  Acc@1: 68.7500 (63.5460)  Acc@5: 87.5000 (91.2958)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1700/4579]  eta: 0:16:35  Lr: 0.001875  Loss: 0.4177  Acc@1: 62.5000 (63.5435)  Acc@5: 87.5000 (91.2956)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1710/4579]  eta: 0:16:31  Lr: 0.001875  Loss: 0.4943  Acc@1: 62.5000 (63.5630)  Acc@5: 87.5000 (91.2807)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1720/4579]  eta: 0:16:28  Lr: 0.001875  Loss: 1.5664  Acc@1: 68.7500 (63.5677)  Acc@5: 93.7500 (91.2841)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1730/4579]  eta: 0:16:24  Lr: 0.001875  Loss: 1.3281  Acc@1: 62.5000 (63.5435)  Acc@5: 93.7500 (91.2948)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1740/4579]  eta: 0:16:21  Lr: 0.001875  Loss: 1.0765  Acc@1: 62.5000 (63.5554)  Acc@5: 93.7500 (91.2766)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1750/4579]  eta: 0:16:18  Lr: 0.001875  Loss: 0.8999  Acc@1: 62.5000 (63.5530)  Acc@5: 87.5000 (91.2550)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1760/4579]  eta: 0:16:14  Lr: 0.001875  Loss: 1.1546  Acc@1: 62.5000 (63.5647)  Acc@5: 87.5000 (91.2479)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1770/4579]  eta: 0:16:11  Lr: 0.001875  Loss: 1.3754  Acc@1: 62.5000 (63.5411)  Acc@5: 87.5000 (91.2444)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1780/4579]  eta: 0:16:07  Lr: 0.001875  Loss: 1.6309  Acc@1: 56.2500 (63.5352)  Acc@5: 93.7500 (91.2444)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1790/4579]  eta: 0:16:04  Lr: 0.001875  Loss: 1.4064  Acc@1: 56.2500 (63.5295)  Acc@5: 93.7500 (91.2549)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1800/4579]  eta: 0:16:00  Lr: 0.001875  Loss: 0.8985  Acc@1: 62.5000 (63.5480)  Acc@5: 93.7500 (91.2514)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1810/4579]  eta: 0:15:57  Lr: 0.001875  Loss: 1.3142  Acc@1: 62.5000 (63.5526)  Acc@5: 93.7500 (91.2583)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1820/4579]  eta: 0:15:53  Lr: 0.001875  Loss: 1.9010  Acc@1: 62.5000 (63.5125)  Acc@5: 93.7500 (91.2548)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1830/4579]  eta: 0:15:50  Lr: 0.001875  Loss: 0.9403  Acc@1: 62.5000 (63.5343)  Acc@5: 87.5000 (91.2377)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1840/4579]  eta: 0:15:46  Lr: 0.001875  Loss: 1.3257  Acc@1: 62.5000 (63.4947)  Acc@5: 87.5000 (91.2310)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1850/4579]  eta: 0:15:43  Lr: 0.001875  Loss: 1.4899  Acc@1: 56.2500 (63.4893)  Acc@5: 93.7500 (91.2277)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1860/4579]  eta: 0:15:40  Lr: 0.001875  Loss: 0.9499  Acc@1: 68.7500 (63.4974)  Acc@5: 93.7500 (91.2110)  time: 0.3455  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1870/4579]  eta: 0:15:36  Lr: 0.001875  Loss: 1.0412  Acc@1: 62.5000 (63.4788)  Acc@5: 87.5000 (91.2012)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1880/4579]  eta: 0:15:33  Lr: 0.001875  Loss: 1.5327  Acc@1: 62.5000 (63.4736)  Acc@5: 93.7500 (91.2081)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1890/4579]  eta: 0:15:29  Lr: 0.001875  Loss: 0.9482  Acc@1: 62.5000 (63.4717)  Acc@5: 93.7500 (91.2117)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1900/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 1.1305  Acc@1: 62.5000 (63.4633)  Acc@5: 93.7500 (91.2151)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1910/4579]  eta: 0:15:22  Lr: 0.001875  Loss: 1.0972  Acc@1: 62.5000 (63.4910)  Acc@5: 93.7500 (91.2219)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1920/4579]  eta: 0:15:19  Lr: 0.001875  Loss: 1.2835  Acc@1: 62.5000 (63.4891)  Acc@5: 93.7500 (91.2253)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1930/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 1.4483  Acc@1: 62.5000 (63.5098)  Acc@5: 87.5000 (91.2222)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1940/4579]  eta: 0:15:12  Lr: 0.001875  Loss: 0.8180  Acc@1: 68.7500 (63.5304)  Acc@5: 87.5000 (91.2094)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1950/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 0.7431  Acc@1: 68.7500 (63.5283)  Acc@5: 87.5000 (91.2064)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1960/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 1.5155  Acc@1: 68.7500 (63.5294)  Acc@5: 93.7500 (91.2067)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1970/4579]  eta: 0:15:01  Lr: 0.001875  Loss: 1.1877  Acc@1: 68.7500 (63.5369)  Acc@5: 93.7500 (91.2164)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1980/4579]  eta: 0:14:58  Lr: 0.001875  Loss: 0.9656  Acc@1: 68.7500 (63.5569)  Acc@5: 93.7500 (91.2386)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1990/4579]  eta: 0:14:55  Lr: 0.001875  Loss: 1.2810  Acc@1: 62.5000 (63.5391)  Acc@5: 93.7500 (91.2387)  time: 0.3445  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2000/4579]  eta: 0:14:51  Lr: 0.001875  Loss: 2.6243  Acc@1: 62.5000 (63.5339)  Acc@5: 93.7500 (91.2388)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2010/4579]  eta: 0:14:48  Lr: 0.001875  Loss: 1.1651  Acc@1: 68.7500 (63.5443)  Acc@5: 93.7500 (91.2295)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2020/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 0.9554  Acc@1: 68.7500 (63.5484)  Acc@5: 87.5000 (91.2141)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2030/4579]  eta: 0:14:41  Lr: 0.001875  Loss: 1.0509  Acc@1: 68.7500 (63.5647)  Acc@5: 87.5000 (91.2174)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2040/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 0.9629  Acc@1: 68.7500 (63.5779)  Acc@5: 93.7500 (91.2237)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2050/4579]  eta: 0:14:34  Lr: 0.001875  Loss: 0.6205  Acc@1: 68.7500 (63.5787)  Acc@5: 93.7500 (91.2207)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2060/4579]  eta: 0:14:30  Lr: 0.001875  Loss: 0.9670  Acc@1: 68.7500 (63.5917)  Acc@5: 93.7500 (91.2027)  time: 0.3448  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2070/4579]  eta: 0:14:27  Lr: 0.001875  Loss: 1.0612  Acc@1: 68.7500 (63.6226)  Acc@5: 93.7500 (91.2120)  time: 0.3452  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2080/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 1.4954  Acc@1: 68.7500 (63.6082)  Acc@5: 93.7500 (91.2031)  time: 0.3469  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2090/4579]  eta: 0:14:20  Lr: 0.001875  Loss: 1.2038  Acc@1: 56.2500 (63.6298)  Acc@5: 87.5000 (91.1974)  time: 0.3463  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2100/4579]  eta: 0:14:16  Lr: 0.001875  Loss: 0.7455  Acc@1: 68.7500 (63.6483)  Acc@5: 93.7500 (91.2066)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2110/4579]  eta: 0:14:13  Lr: 0.001875  Loss: 1.0087  Acc@1: 68.7500 (63.6635)  Acc@5: 93.7500 (91.2127)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2120/4579]  eta: 0:14:09  Lr: 0.001875  Loss: 0.9528  Acc@1: 62.5000 (63.6640)  Acc@5: 87.5000 (91.2070)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2130/4579]  eta: 0:14:06  Lr: 0.001875  Loss: 1.1789  Acc@1: 62.5000 (63.6380)  Acc@5: 87.5000 (91.1954)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2140/4579]  eta: 0:14:03  Lr: 0.001875  Loss: 0.5594  Acc@1: 62.5000 (63.6472)  Acc@5: 93.7500 (91.2132)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2150/4579]  eta: 0:13:59  Lr: 0.001875  Loss: 1.5806  Acc@1: 62.5000 (63.6448)  Acc@5: 93.7500 (91.2105)  time: 0.3451  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2160/4579]  eta: 0:13:56  Lr: 0.001875  Loss: 0.9854  Acc@1: 56.2500 (63.6308)  Acc@5: 93.7500 (91.2193)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2170/4579]  eta: 0:13:52  Lr: 0.001875  Loss: 0.8228  Acc@1: 56.2500 (63.6487)  Acc@5: 93.7500 (91.2281)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2180/4579]  eta: 0:13:49  Lr: 0.001875  Loss: 1.1916  Acc@1: 62.5000 (63.6405)  Acc@5: 93.7500 (91.2196)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2190/4579]  eta: 0:13:45  Lr: 0.001875  Loss: 0.6013  Acc@1: 62.5000 (63.6553)  Acc@5: 87.5000 (91.2169)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2200/4579]  eta: 0:13:42  Lr: 0.001875  Loss: 1.3521  Acc@1: 68.7500 (63.6444)  Acc@5: 93.7500 (91.2085)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2210/4579]  eta: 0:13:38  Lr: 0.001875  Loss: 0.9376  Acc@1: 62.5000 (63.6477)  Acc@5: 93.7500 (91.2144)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2220/4579]  eta: 0:13:35  Lr: 0.001875  Loss: 1.2001  Acc@1: 62.5000 (63.6453)  Acc@5: 93.7500 (91.2202)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2230/4579]  eta: 0:13:31  Lr: 0.001875  Loss: 0.7641  Acc@1: 62.5000 (63.6458)  Acc@5: 93.7500 (91.2427)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2240/4579]  eta: 0:13:28  Lr: 0.001875  Loss: 1.8355  Acc@1: 62.5000 (63.6630)  Acc@5: 93.7500 (91.2427)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2250/4579]  eta: 0:13:24  Lr: 0.001875  Loss: 1.1962  Acc@1: 62.5000 (63.6634)  Acc@5: 93.7500 (91.2372)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2260/4579]  eta: 0:13:21  Lr: 0.001875  Loss: 0.6961  Acc@1: 62.5000 (63.6665)  Acc@5: 93.7500 (91.2345)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2270/4579]  eta: 0:13:18  Lr: 0.001875  Loss: 1.2309  Acc@1: 56.2500 (63.6421)  Acc@5: 87.5000 (91.2181)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2280/4579]  eta: 0:13:14  Lr: 0.001875  Loss: 1.1855  Acc@1: 56.2500 (63.6262)  Acc@5: 87.5000 (91.2018)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2290/4579]  eta: 0:13:11  Lr: 0.001875  Loss: 1.3126  Acc@1: 62.5000 (63.6403)  Acc@5: 87.5000 (91.1993)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2300/4579]  eta: 0:13:07  Lr: 0.001875  Loss: 0.7024  Acc@1: 68.7500 (63.6462)  Acc@5: 93.7500 (91.1968)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2310/4579]  eta: 0:13:04  Lr: 0.001875  Loss: 0.4845  Acc@1: 68.7500 (63.6521)  Acc@5: 93.7500 (91.1970)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2320/4579]  eta: 0:13:00  Lr: 0.001875  Loss: 1.0954  Acc@1: 62.5000 (63.6391)  Acc@5: 93.7500 (91.2107)  time: 0.3463  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2330/4579]  eta: 0:12:57  Lr: 0.001875  Loss: 1.0088  Acc@1: 62.5000 (63.6342)  Acc@5: 93.7500 (91.2082)  time: 0.3456  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2340/4579]  eta: 0:12:53  Lr: 0.001875  Loss: 0.9269  Acc@1: 62.5000 (63.6427)  Acc@5: 87.5000 (91.1897)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2350/4579]  eta: 0:12:50  Lr: 0.001875  Loss: 1.8968  Acc@1: 62.5000 (63.6484)  Acc@5: 93.7500 (91.1979)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2360/4579]  eta: 0:12:46  Lr: 0.001875  Loss: 1.6506  Acc@1: 68.7500 (63.6648)  Acc@5: 93.7500 (91.1849)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2370/4579]  eta: 0:12:43  Lr: 0.001875  Loss: 1.0029  Acc@1: 68.7500 (63.6941)  Acc@5: 87.5000 (91.1825)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2380/4579]  eta: 0:12:39  Lr: 0.001875  Loss: 1.4847  Acc@1: 68.7500 (63.6891)  Acc@5: 87.5000 (91.1723)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2390/4579]  eta: 0:12:36  Lr: 0.001875  Loss: 1.0584  Acc@1: 62.5000 (63.6841)  Acc@5: 87.5000 (91.1700)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2400/4579]  eta: 0:12:33  Lr: 0.001875  Loss: 1.1000  Acc@1: 62.5000 (63.6792)  Acc@5: 93.7500 (91.1729)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2410/4579]  eta: 0:12:29  Lr: 0.001875  Loss: 1.2957  Acc@1: 62.5000 (63.6665)  Acc@5: 93.7500 (91.1733)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2420/4579]  eta: 0:12:26  Lr: 0.001875  Loss: 1.3250  Acc@1: 62.5000 (63.6720)  Acc@5: 87.5000 (91.1633)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2430/4579]  eta: 0:12:22  Lr: 0.001875  Loss: 1.1872  Acc@1: 62.5000 (63.6646)  Acc@5: 87.5000 (91.1662)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2440/4579]  eta: 0:12:19  Lr: 0.001875  Loss: 1.0636  Acc@1: 62.5000 (63.6676)  Acc@5: 93.7500 (91.1614)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2450/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 1.3151  Acc@1: 68.7500 (63.6755)  Acc@5: 87.5000 (91.1592)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2460/4579]  eta: 0:12:12  Lr: 0.001875  Loss: 0.9232  Acc@1: 62.5000 (63.6733)  Acc@5: 87.5000 (91.1545)  time: 0.3450  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2470/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 1.3402  Acc@1: 62.5000 (63.6610)  Acc@5: 93.7500 (91.1600)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2480/4579]  eta: 0:12:05  Lr: 0.001875  Loss: 1.2251  Acc@1: 62.5000 (63.6638)  Acc@5: 93.7500 (91.1553)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2490/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 1.1873  Acc@1: 68.7500 (63.6692)  Acc@5: 87.5000 (91.1481)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2500/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 1.5302  Acc@1: 68.7500 (63.6795)  Acc@5: 87.5000 (91.1385)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2510/4579]  eta: 0:11:55  Lr: 0.001875  Loss: 1.4961  Acc@1: 68.7500 (63.6798)  Acc@5: 93.7500 (91.1440)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2520/4579]  eta: 0:11:51  Lr: 0.001875  Loss: 1.4387  Acc@1: 62.5000 (63.6801)  Acc@5: 93.7500 (91.1469)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2530/4579]  eta: 0:11:48  Lr: 0.001875  Loss: 1.1147  Acc@1: 62.5000 (63.6976)  Acc@5: 93.7500 (91.1572)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2540/4579]  eta: 0:11:44  Lr: 0.001875  Loss: 1.8374  Acc@1: 62.5000 (63.7003)  Acc@5: 93.7500 (91.1649)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2550/4579]  eta: 0:11:41  Lr: 0.001875  Loss: 1.3524  Acc@1: 62.5000 (63.6883)  Acc@5: 93.7500 (91.1603)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2560/4579]  eta: 0:11:37  Lr: 0.001875  Loss: 0.9865  Acc@1: 62.5000 (63.7031)  Acc@5: 87.5000 (91.1558)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2570/4579]  eta: 0:11:34  Lr: 0.001875  Loss: 1.0041  Acc@1: 68.7500 (63.7252)  Acc@5: 87.5000 (91.1610)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2580/4579]  eta: 0:11:30  Lr: 0.001875  Loss: 1.1162  Acc@1: 68.7500 (63.7132)  Acc@5: 87.5000 (91.1565)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2590/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 1.1815  Acc@1: 62.5000 (63.7037)  Acc@5: 87.5000 (91.1593)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2600/4579]  eta: 0:11:23  Lr: 0.001875  Loss: 0.4316  Acc@1: 68.7500 (63.7375)  Acc@5: 93.7500 (91.1645)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2610/4579]  eta: 0:11:20  Lr: 0.001875  Loss: 1.6061  Acc@1: 68.7500 (63.7208)  Acc@5: 93.7500 (91.1528)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2620/4579]  eta: 0:11:16  Lr: 0.001875  Loss: 0.7084  Acc@1: 62.5000 (63.7471)  Acc@5: 87.5000 (91.1484)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2630/4579]  eta: 0:11:13  Lr: 0.001875  Loss: 0.8553  Acc@1: 68.7500 (63.7709)  Acc@5: 93.7500 (91.1369)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2640/4579]  eta: 0:11:10  Lr: 0.001875  Loss: 0.9832  Acc@1: 62.5000 (63.7543)  Acc@5: 87.5000 (91.1232)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2650/4579]  eta: 0:11:06  Lr: 0.001875  Loss: 1.6215  Acc@1: 62.5000 (63.7684)  Acc@5: 87.5000 (91.1213)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2660/4579]  eta: 0:11:03  Lr: 0.001875  Loss: 0.9843  Acc@1: 62.5000 (63.7566)  Acc@5: 93.7500 (91.1312)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2670/4579]  eta: 0:10:59  Lr: 0.001875  Loss: 0.6805  Acc@1: 62.5000 (63.7753)  Acc@5: 93.7500 (91.1433)  time: 0.3444  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2680/4579]  eta: 0:10:56  Lr: 0.001875  Loss: 1.1924  Acc@1: 68.7500 (63.7775)  Acc@5: 93.7500 (91.1414)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2690/4579]  eta: 0:10:52  Lr: 0.001875  Loss: 0.5811  Acc@1: 68.7500 (63.7867)  Acc@5: 93.7500 (91.1511)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2700/4579]  eta: 0:10:49  Lr: 0.001875  Loss: 1.0845  Acc@1: 68.7500 (63.8074)  Acc@5: 93.7500 (91.1537)  time: 0.3434  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2710/4579]  eta: 0:10:45  Lr: 0.001875  Loss: 0.7451  Acc@1: 68.7500 (63.7980)  Acc@5: 93.7500 (91.1610)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2720/4579]  eta: 0:10:42  Lr: 0.001875  Loss: 0.9705  Acc@1: 62.5000 (63.7932)  Acc@5: 93.7500 (91.1521)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2730/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 1.3854  Acc@1: 56.2500 (63.7679)  Acc@5: 93.7500 (91.1548)  time: 0.3464  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2740/4579]  eta: 0:10:35  Lr: 0.001875  Loss: 0.8611  Acc@1: 56.2500 (63.7541)  Acc@5: 93.7500 (91.1529)  time: 0.3475  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2750/4579]  eta: 0:10:32  Lr: 0.001875  Loss: 1.2549  Acc@1: 62.5000 (63.7450)  Acc@5: 87.5000 (91.1441)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2760/4579]  eta: 0:10:28  Lr: 0.001875  Loss: 1.8756  Acc@1: 62.5000 (63.7246)  Acc@5: 87.5000 (91.1355)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2770/4579]  eta: 0:10:25  Lr: 0.001875  Loss: 1.3345  Acc@1: 62.5000 (63.7202)  Acc@5: 87.5000 (91.1426)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2780/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 1.2978  Acc@1: 62.5000 (63.7226)  Acc@5: 93.7500 (91.1453)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2790/4579]  eta: 0:10:18  Lr: 0.001875  Loss: 1.2655  Acc@1: 62.5000 (63.7115)  Acc@5: 93.7500 (91.1389)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2800/4579]  eta: 0:10:14  Lr: 0.001875  Loss: 1.1593  Acc@1: 62.5000 (63.7250)  Acc@5: 87.5000 (91.1349)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2810/4579]  eta: 0:10:11  Lr: 0.001875  Loss: 0.6507  Acc@1: 62.5000 (63.7318)  Acc@5: 93.7500 (91.1419)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2820/4579]  eta: 0:10:07  Lr: 0.001875  Loss: 1.1771  Acc@1: 62.5000 (63.7274)  Acc@5: 87.5000 (91.1445)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2830/4579]  eta: 0:10:04  Lr: 0.001875  Loss: 1.7185  Acc@1: 68.7500 (63.7385)  Acc@5: 93.7500 (91.1449)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2840/4579]  eta: 0:10:00  Lr: 0.001875  Loss: 0.6686  Acc@1: 68.7500 (63.7430)  Acc@5: 93.7500 (91.1431)  time: 0.3458  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2850/4579]  eta: 0:09:57  Lr: 0.001875  Loss: 0.9049  Acc@1: 68.7500 (63.7539)  Acc@5: 87.5000 (91.1369)  time: 0.3456  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2860/4579]  eta: 0:09:53  Lr: 0.001875  Loss: 0.9583  Acc@1: 68.7500 (63.7670)  Acc@5: 93.7500 (91.1395)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2870/4579]  eta: 0:09:50  Lr: 0.001875  Loss: 1.0238  Acc@1: 68.7500 (63.7822)  Acc@5: 93.7500 (91.1486)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2880/4579]  eta: 0:09:47  Lr: 0.001875  Loss: 1.0152  Acc@1: 68.7500 (63.7821)  Acc@5: 87.5000 (91.1337)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2890/4579]  eta: 0:09:43  Lr: 0.001875  Loss: 1.1301  Acc@1: 62.5000 (63.7798)  Acc@5: 87.5000 (91.1255)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2900/4579]  eta: 0:09:40  Lr: 0.001875  Loss: 1.3033  Acc@1: 62.5000 (63.7754)  Acc@5: 87.5000 (91.1194)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2910/4579]  eta: 0:09:36  Lr: 0.001875  Loss: 1.2171  Acc@1: 56.2500 (63.7582)  Acc@5: 93.7500 (91.1220)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2920/4579]  eta: 0:09:33  Lr: 0.001875  Loss: 1.3298  Acc@1: 56.2500 (63.7453)  Acc@5: 93.7500 (91.1096)  time: 0.3457  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2930/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 0.9605  Acc@1: 56.2500 (63.7346)  Acc@5: 87.5000 (91.1080)  time: 0.3463  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2940/4579]  eta: 0:09:26  Lr: 0.001875  Loss: 1.1489  Acc@1: 62.5000 (63.7347)  Acc@5: 93.7500 (91.1000)  time: 0.3461  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2950/4579]  eta: 0:09:22  Lr: 0.001875  Loss: 1.0879  Acc@1: 68.7500 (63.7432)  Acc@5: 93.7500 (91.1089)  time: 0.3461  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2960/4579]  eta: 0:09:19  Lr: 0.001875  Loss: 1.3960  Acc@1: 68.7500 (63.7559)  Acc@5: 93.7500 (91.1179)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2970/4579]  eta: 0:09:15  Lr: 0.001875  Loss: 1.2227  Acc@1: 68.7500 (63.7643)  Acc@5: 93.7500 (91.1225)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2980/4579]  eta: 0:09:12  Lr: 0.001875  Loss: 1.5135  Acc@1: 68.7500 (63.7580)  Acc@5: 93.7500 (91.1292)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2990/4579]  eta: 0:09:09  Lr: 0.001875  Loss: 1.3408  Acc@1: 62.5000 (63.7559)  Acc@5: 93.7500 (91.1275)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3000/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 2.0376  Acc@1: 62.5000 (63.7621)  Acc@5: 93.7500 (91.1238)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3010/4579]  eta: 0:09:02  Lr: 0.001875  Loss: 1.7802  Acc@1: 62.5000 (63.7683)  Acc@5: 93.7500 (91.1201)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3020/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.4578  Acc@1: 62.5000 (63.7806)  Acc@5: 93.7500 (91.1329)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3030/4579]  eta: 0:08:55  Lr: 0.001875  Loss: 1.3060  Acc@1: 62.5000 (63.7743)  Acc@5: 93.7500 (91.1189)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3040/4579]  eta: 0:08:51  Lr: 0.001875  Loss: 0.9709  Acc@1: 62.5000 (63.7804)  Acc@5: 87.5000 (91.1193)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3050/4579]  eta: 0:08:48  Lr: 0.001875  Loss: 1.2014  Acc@1: 68.7500 (63.7680)  Acc@5: 93.7500 (91.1156)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3060/4579]  eta: 0:08:44  Lr: 0.001875  Loss: 0.9125  Acc@1: 68.7500 (63.7618)  Acc@5: 93.7500 (91.1140)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3070/4579]  eta: 0:08:41  Lr: 0.001875  Loss: 1.7349  Acc@1: 68.7500 (63.7781)  Acc@5: 93.7500 (91.1165)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3080/4579]  eta: 0:08:37  Lr: 0.001875  Loss: 1.1032  Acc@1: 75.0000 (63.8105)  Acc@5: 93.7500 (91.1190)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3090/4579]  eta: 0:08:34  Lr: 0.001875  Loss: 0.4018  Acc@1: 68.7500 (63.8244)  Acc@5: 93.7500 (91.1174)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3100/4579]  eta: 0:08:31  Lr: 0.001875  Loss: 1.1378  Acc@1: 62.5000 (63.8121)  Acc@5: 93.7500 (91.1319)  time: 0.3453  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3110/4579]  eta: 0:08:27  Lr: 0.001875  Loss: 0.7916  Acc@1: 62.5000 (63.8340)  Acc@5: 93.7500 (91.1504)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3120/4579]  eta: 0:08:24  Lr: 0.001875  Loss: 0.5458  Acc@1: 68.7500 (63.8337)  Acc@5: 93.7500 (91.1427)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3130/4579]  eta: 0:08:20  Lr: 0.001875  Loss: 1.4497  Acc@1: 62.5000 (63.8314)  Acc@5: 93.7500 (91.1570)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3140/4579]  eta: 0:08:17  Lr: 0.001875  Loss: 0.6859  Acc@1: 62.5000 (63.8391)  Acc@5: 93.7500 (91.1593)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3150/4579]  eta: 0:08:13  Lr: 0.001875  Loss: 0.9582  Acc@1: 62.5000 (63.8428)  Acc@5: 93.7500 (91.1615)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3160/4579]  eta: 0:08:10  Lr: 0.001875  Loss: 1.0657  Acc@1: 62.5000 (63.8504)  Acc@5: 93.7500 (91.1638)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3170/4579]  eta: 0:08:06  Lr: 0.001875  Loss: 0.7417  Acc@1: 62.5000 (63.8403)  Acc@5: 87.5000 (91.1522)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3180/4579]  eta: 0:08:03  Lr: 0.001875  Loss: 0.9147  Acc@1: 62.5000 (63.8498)  Acc@5: 87.5000 (91.1486)  time: 0.3442  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3190/4579]  eta: 0:07:59  Lr: 0.001875  Loss: 0.5768  Acc@1: 68.7500 (63.8710)  Acc@5: 93.7500 (91.1568)  time: 0.3458  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3200/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 0.6551  Acc@1: 68.7500 (63.8668)  Acc@5: 93.7500 (91.1571)  time: 0.3460  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3210/4579]  eta: 0:07:53  Lr: 0.001875  Loss: 1.1660  Acc@1: 62.5000 (63.8606)  Acc@5: 87.5000 (91.1593)  time: 0.3464  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3220/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.5538  Acc@1: 62.5000 (63.8719)  Acc@5: 87.5000 (91.1596)  time: 0.3470  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3230/4579]  eta: 0:07:46  Lr: 0.001875  Loss: 1.1385  Acc@1: 68.7500 (63.8812)  Acc@5: 93.7500 (91.1637)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3240/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 1.0637  Acc@1: 62.5000 (63.8807)  Acc@5: 93.7500 (91.1659)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3250/4579]  eta: 0:07:39  Lr: 0.001875  Loss: 1.0424  Acc@1: 62.5000 (63.8900)  Acc@5: 93.7500 (91.1681)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3260/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 0.7334  Acc@1: 62.5000 (63.8876)  Acc@5: 87.5000 (91.1569)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3270/4579]  eta: 0:07:32  Lr: 0.001875  Loss: 1.4834  Acc@1: 62.5000 (63.8891)  Acc@5: 87.5000 (91.1571)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3280/4579]  eta: 0:07:28  Lr: 0.001875  Loss: 1.0655  Acc@1: 62.5000 (63.8887)  Acc@5: 87.5000 (91.1517)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3290/4579]  eta: 0:07:25  Lr: 0.001875  Loss: 1.1703  Acc@1: 62.5000 (63.8997)  Acc@5: 87.5000 (91.1501)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3300/4579]  eta: 0:07:21  Lr: 0.001875  Loss: 0.7230  Acc@1: 68.7500 (63.9049)  Acc@5: 93.7500 (91.1542)  time: 0.3472  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3310/4579]  eta: 0:07:18  Lr: 0.001875  Loss: 0.8924  Acc@1: 56.2500 (63.8799)  Acc@5: 93.7500 (91.1432)  time: 0.3477  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3320/4579]  eta: 0:07:15  Lr: 0.001875  Loss: 0.9324  Acc@1: 56.2500 (63.8832)  Acc@5: 93.7500 (91.1491)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3330/4579]  eta: 0:07:11  Lr: 0.001875  Loss: 1.5707  Acc@1: 62.5000 (63.8866)  Acc@5: 87.5000 (91.1344)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3340/4579]  eta: 0:07:08  Lr: 0.001875  Loss: 0.9578  Acc@1: 62.5000 (63.8993)  Acc@5: 87.5000 (91.1385)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3350/4579]  eta: 0:07:04  Lr: 0.001875  Loss: 1.2383  Acc@1: 68.7500 (63.8914)  Acc@5: 93.7500 (91.1444)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3360/4579]  eta: 0:07:01  Lr: 0.001875  Loss: 1.4632  Acc@1: 62.5000 (63.8817)  Acc@5: 93.7500 (91.1392)  time: 0.3464  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3370/4579]  eta: 0:06:57  Lr: 0.001875  Loss: 1.1891  Acc@1: 68.7500 (63.9017)  Acc@5: 87.5000 (91.1302)  time: 0.3456  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3380/4579]  eta: 0:06:54  Lr: 0.001875  Loss: 1.2511  Acc@1: 62.5000 (63.8920)  Acc@5: 93.7500 (91.1380)  time: 0.3452  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3390/4579]  eta: 0:06:50  Lr: 0.001875  Loss: 1.1203  Acc@1: 62.5000 (63.8989)  Acc@5: 93.7500 (91.1328)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3400/4579]  eta: 0:06:47  Lr: 0.001875  Loss: 1.2675  Acc@1: 62.5000 (63.9022)  Acc@5: 93.7500 (91.1313)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3410/4579]  eta: 0:06:43  Lr: 0.001875  Loss: 1.2541  Acc@1: 68.7500 (63.9017)  Acc@5: 87.5000 (91.1243)  time: 0.3448  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3420/4579]  eta: 0:06:40  Lr: 0.001875  Loss: 1.4579  Acc@1: 68.7500 (63.9122)  Acc@5: 87.5000 (91.1283)  time: 0.3449  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3430/4579]  eta: 0:06:37  Lr: 0.001875  Loss: 0.8791  Acc@1: 68.7500 (63.9227)  Acc@5: 93.7500 (91.1360)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3440/4579]  eta: 0:06:33  Lr: 0.001875  Loss: 1.5902  Acc@1: 68.7500 (63.9295)  Acc@5: 93.7500 (91.1345)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3450/4579]  eta: 0:06:30  Lr: 0.001875  Loss: 0.9956  Acc@1: 68.7500 (63.9452)  Acc@5: 93.7500 (91.1421)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3460/4579]  eta: 0:06:26  Lr: 0.001875  Loss: 1.0657  Acc@1: 68.7500 (63.9555)  Acc@5: 93.7500 (91.1496)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3470/4579]  eta: 0:06:23  Lr: 0.001875  Loss: 1.1776  Acc@1: 62.5000 (63.9387)  Acc@5: 93.7500 (91.1481)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3480/4579]  eta: 0:06:19  Lr: 0.001875  Loss: 0.9688  Acc@1: 62.5000 (63.9525)  Acc@5: 93.7500 (91.1520)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3490/4579]  eta: 0:06:16  Lr: 0.001875  Loss: 0.7421  Acc@1: 62.5000 (63.9609)  Acc@5: 93.7500 (91.1576)  time: 0.3458  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3500/4579]  eta: 0:06:12  Lr: 0.001875  Loss: 1.3872  Acc@1: 62.5000 (63.9424)  Acc@5: 87.5000 (91.1436)  time: 0.3441  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3510/4579]  eta: 0:06:09  Lr: 0.001875  Loss: 1.1438  Acc@1: 62.5000 (63.9668)  Acc@5: 93.7500 (91.1546)  time: 0.3459  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3520/4579]  eta: 0:06:05  Lr: 0.001875  Loss: 1.1181  Acc@1: 68.7500 (63.9804)  Acc@5: 93.7500 (91.1549)  time: 0.3468  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3530/4579]  eta: 0:06:02  Lr: 0.001875  Loss: 0.9490  Acc@1: 62.5000 (63.9709)  Acc@5: 87.5000 (91.1427)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3540/4579]  eta: 0:05:59  Lr: 0.001875  Loss: 1.1311  Acc@1: 62.5000 (63.9809)  Acc@5: 87.5000 (91.1448)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3550/4579]  eta: 0:05:55  Lr: 0.001875  Loss: 1.2524  Acc@1: 62.5000 (63.9714)  Acc@5: 87.5000 (91.1433)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3560/4579]  eta: 0:05:52  Lr: 0.001875  Loss: 1.1068  Acc@1: 62.5000 (63.9690)  Acc@5: 93.7500 (91.1507)  time: 0.3455  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3570/4579]  eta: 0:05:48  Lr: 0.001875  Loss: 1.2970  Acc@1: 62.5000 (63.9527)  Acc@5: 87.5000 (91.1404)  time: 0.3452  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3580/4579]  eta: 0:05:45  Lr: 0.001875  Loss: 1.1296  Acc@1: 62.5000 (63.9591)  Acc@5: 93.7500 (91.1495)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3590/4579]  eta: 0:05:41  Lr: 0.001875  Loss: 1.1974  Acc@1: 62.5000 (63.9620)  Acc@5: 93.7500 (91.1602)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3600/4579]  eta: 0:05:38  Lr: 0.001875  Loss: 1.1496  Acc@1: 62.5000 (63.9649)  Acc@5: 93.7500 (91.1518)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3610/4579]  eta: 0:05:34  Lr: 0.001875  Loss: 1.4475  Acc@1: 68.7500 (63.9747)  Acc@5: 93.7500 (91.1607)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3620/4579]  eta: 0:05:31  Lr: 0.001875  Loss: 1.4072  Acc@1: 68.7500 (63.9809)  Acc@5: 93.7500 (91.1627)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3630/4579]  eta: 0:05:27  Lr: 0.001875  Loss: 0.7721  Acc@1: 62.5000 (63.9838)  Acc@5: 93.7500 (91.1715)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3640/4579]  eta: 0:05:24  Lr: 0.001875  Loss: 1.9579  Acc@1: 68.7500 (64.0003)  Acc@5: 93.7500 (91.1717)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3650/4579]  eta: 0:05:20  Lr: 0.001875  Loss: 0.8617  Acc@1: 62.5000 (63.9927)  Acc@5: 93.7500 (91.1737)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3660/4579]  eta: 0:05:17  Lr: 0.001875  Loss: 0.6145  Acc@1: 62.5000 (64.0006)  Acc@5: 93.7500 (91.1722)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3670/4579]  eta: 0:05:14  Lr: 0.001875  Loss: 1.8142  Acc@1: 62.5000 (63.9778)  Acc@5: 87.5000 (91.1621)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3680/4579]  eta: 0:05:10  Lr: 0.001875  Loss: 1.4121  Acc@1: 68.7500 (63.9976)  Acc@5: 87.5000 (91.1675)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3690/4579]  eta: 0:05:07  Lr: 0.001875  Loss: 1.0156  Acc@1: 68.7500 (64.0087)  Acc@5: 93.7500 (91.1779)  time: 0.3443  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:03  Lr: 0.001875  Loss: 1.2727  Acc@1: 62.5000 (64.0080)  Acc@5: 93.7500 (91.1730)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3710/4579]  eta: 0:05:00  Lr: 0.001875  Loss: 0.5831  Acc@1: 62.5000 (63.9922)  Acc@5: 87.5000 (91.1698)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3720/4579]  eta: 0:04:56  Lr: 0.001875  Loss: 1.0036  Acc@1: 62.5000 (63.9882)  Acc@5: 87.5000 (91.1667)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3730/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 0.7645  Acc@1: 62.5000 (63.9859)  Acc@5: 87.5000 (91.1719)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3740/4579]  eta: 0:04:49  Lr: 0.001875  Loss: 1.5598  Acc@1: 56.2500 (63.9669)  Acc@5: 87.5000 (91.1554)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3750/4579]  eta: 0:04:46  Lr: 0.001875  Loss: 0.4816  Acc@1: 62.5000 (63.9879)  Acc@5: 87.5000 (91.1557)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3760/4579]  eta: 0:04:42  Lr: 0.001875  Loss: 0.8366  Acc@1: 62.5000 (63.9790)  Acc@5: 93.7500 (91.1576)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3770/4579]  eta: 0:04:39  Lr: 0.001875  Loss: 1.0043  Acc@1: 62.5000 (63.9800)  Acc@5: 93.7500 (91.1695)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3780/4579]  eta: 0:04:36  Lr: 0.001875  Loss: 0.9670  Acc@1: 62.5000 (63.9794)  Acc@5: 93.7500 (91.1713)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3790/4579]  eta: 0:04:32  Lr: 0.001875  Loss: 1.2024  Acc@1: 68.7500 (63.9986)  Acc@5: 93.7500 (91.1699)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3800/4579]  eta: 0:04:29  Lr: 0.001875  Loss: 0.7695  Acc@1: 68.7500 (63.9914)  Acc@5: 93.7500 (91.1750)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3810/4579]  eta: 0:04:25  Lr: 0.001875  Loss: 0.7968  Acc@1: 62.5000 (64.0055)  Acc@5: 93.7500 (91.1752)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3820/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 1.3867  Acc@1: 68.7500 (64.0097)  Acc@5: 93.7500 (91.1754)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3830/4579]  eta: 0:04:18  Lr: 0.001875  Loss: 0.7355  Acc@1: 68.7500 (64.0156)  Acc@5: 93.7500 (91.1936)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3840/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 1.1201  Acc@1: 62.5000 (63.9970)  Acc@5: 100.0000 (91.1921)  time: 0.3437  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3850/4579]  eta: 0:04:11  Lr: 0.001875  Loss: 1.1300  Acc@1: 62.5000 (64.0012)  Acc@5: 87.5000 (91.1874)  time: 0.3448  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:08  Lr: 0.001875  Loss: 1.7883  Acc@1: 68.7500 (64.0038)  Acc@5: 93.7500 (91.1827)  time: 0.3465  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:04  Lr: 0.001875  Loss: 1.0418  Acc@1: 62.5000 (63.9983)  Acc@5: 93.7500 (91.1780)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:01  Lr: 0.001875  Loss: 1.0884  Acc@1: 62.5000 (63.9945)  Acc@5: 93.7500 (91.1814)  time: 0.3438  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3890/4579]  eta: 0:03:58  Lr: 0.001875  Loss: 0.5052  Acc@1: 62.5000 (64.0051)  Acc@5: 93.7500 (91.1864)  time: 0.3446  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3900/4579]  eta: 0:03:54  Lr: 0.001875  Loss: 0.6718  Acc@1: 75.0000 (64.0252)  Acc@5: 93.7500 (91.1882)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3910/4579]  eta: 0:03:51  Lr: 0.001875  Loss: 1.8142  Acc@1: 68.7500 (64.0245)  Acc@5: 93.7500 (91.1883)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3920/4579]  eta: 0:03:47  Lr: 0.001875  Loss: 0.9581  Acc@1: 56.2500 (64.0191)  Acc@5: 93.7500 (91.1821)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3930/4579]  eta: 0:03:44  Lr: 0.001875  Loss: 1.4003  Acc@1: 68.7500 (64.0231)  Acc@5: 87.5000 (91.1839)  time: 0.3448  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3940/4579]  eta: 0:03:40  Lr: 0.001875  Loss: 0.8391  Acc@1: 62.5000 (64.0114)  Acc@5: 87.5000 (91.1809)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3950/4579]  eta: 0:03:37  Lr: 0.001875  Loss: 0.7357  Acc@1: 62.5000 (64.0328)  Acc@5: 87.5000 (91.1842)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3960/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 1.7132  Acc@1: 68.7500 (64.0274)  Acc@5: 93.7500 (91.1796)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3970/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 1.3642  Acc@1: 62.5000 (64.0251)  Acc@5: 93.7500 (91.1845)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3980/4579]  eta: 0:03:26  Lr: 0.001875  Loss: 1.2272  Acc@1: 62.5000 (64.0291)  Acc@5: 93.7500 (91.1847)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3990/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 1.2697  Acc@1: 62.5000 (64.0222)  Acc@5: 87.5000 (91.1849)  time: 0.3447  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4000/4579]  eta: 0:03:20  Lr: 0.001875  Loss: 1.7111  Acc@1: 62.5000 (64.0246)  Acc@5: 87.5000 (91.1741)  time: 0.3447  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:16  Lr: 0.001875  Loss: 1.2886  Acc@1: 68.7500 (64.0224)  Acc@5: 87.5000 (91.1743)  time: 0.3445  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:13  Lr: 0.001875  Loss: 1.0676  Acc@1: 62.5000 (64.0326)  Acc@5: 93.7500 (91.1714)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 1.4624  Acc@1: 62.5000 (64.0210)  Acc@5: 93.7500 (91.1715)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:06  Lr: 0.001875  Loss: 1.0997  Acc@1: 56.2500 (64.0250)  Acc@5: 93.7500 (91.1779)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 1.3175  Acc@1: 62.5000 (64.0289)  Acc@5: 93.7500 (91.1827)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4060/4579]  eta: 0:02:59  Lr: 0.001875  Loss: 1.0956  Acc@1: 62.5000 (64.0298)  Acc@5: 93.7500 (91.1829)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4070/4579]  eta: 0:02:55  Lr: 0.001875  Loss: 1.3106  Acc@1: 56.2500 (64.0045)  Acc@5: 93.7500 (91.1831)  time: 0.3446  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4080/4579]  eta: 0:02:52  Lr: 0.001875  Loss: 1.4622  Acc@1: 56.2500 (64.0116)  Acc@5: 93.7500 (91.1894)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [4090/4579]  eta: 0:02:48  Lr: 0.001875  Loss: 1.3033  Acc@1: 68.7500 (64.0109)  Acc@5: 93.7500 (91.1849)  time: 0.3442  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4100/4579]  eta: 0:02:45  Lr: 0.001875  Loss: 0.9811  Acc@1: 62.5000 (64.0118)  Acc@5: 93.7500 (91.1851)  time: 0.3443  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4110/4579]  eta: 0:02:42  Lr: 0.001875  Loss: 1.3679  Acc@1: 62.5000 (64.0173)  Acc@5: 93.7500 (91.1837)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4120/4579]  eta: 0:02:38  Lr: 0.001875  Loss: 0.8255  Acc@1: 62.5000 (64.0181)  Acc@5: 93.7500 (91.1869)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4130/4579]  eta: 0:02:35  Lr: 0.001875  Loss: 0.8185  Acc@1: 62.5000 (64.0130)  Acc@5: 93.7500 (91.1840)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4140/4579]  eta: 0:02:31  Lr: 0.001875  Loss: 1.2083  Acc@1: 62.5000 (64.0123)  Acc@5: 93.7500 (91.1842)  time: 0.3470  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:28  Lr: 0.001875  Loss: 0.5626  Acc@1: 68.7500 (64.0267)  Acc@5: 93.7500 (91.1844)  time: 0.3477  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:24  Lr: 0.001875  Loss: 1.0744  Acc@1: 62.5000 (64.0306)  Acc@5: 93.7500 (91.1890)  time: 0.3470  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:21  Lr: 0.001875  Loss: 1.1216  Acc@1: 62.5000 (64.0299)  Acc@5: 87.5000 (91.1817)  time: 0.3472  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:17  Lr: 0.001875  Loss: 1.1033  Acc@1: 62.5000 (64.0233)  Acc@5: 87.5000 (91.1759)  time: 0.3461  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:14  Lr: 0.001875  Loss: 0.9032  Acc@1: 62.5000 (64.0271)  Acc@5: 87.5000 (91.1790)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:10  Lr: 0.001875  Loss: 0.9516  Acc@1: 68.7500 (64.0220)  Acc@5: 93.7500 (91.1747)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:07  Lr: 0.001875  Loss: 1.2894  Acc@1: 56.2500 (64.0124)  Acc@5: 93.7500 (91.1749)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:04  Lr: 0.001875  Loss: 1.4170  Acc@1: 62.5000 (64.0207)  Acc@5: 93.7500 (91.1780)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:00  Lr: 0.001875  Loss: 0.8788  Acc@1: 62.5000 (64.0259)  Acc@5: 93.7500 (91.1841)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 1.6015  Acc@1: 68.7500 (64.0312)  Acc@5: 93.7500 (91.1857)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4250/4579]  eta: 0:01:53  Lr: 0.001875  Loss: 1.0593  Acc@1: 62.5000 (64.0276)  Acc@5: 93.7500 (91.1874)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: 0.7336  Acc@1: 62.5000 (64.0401)  Acc@5: 93.7500 (91.1919)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4270/4579]  eta: 0:01:46  Lr: 0.001875  Loss: 1.3201  Acc@1: 62.5000 (64.0277)  Acc@5: 93.7500 (91.1921)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: 1.3489  Acc@1: 62.5000 (64.0242)  Acc@5: 87.5000 (91.1849)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:39  Lr: 0.001875  Loss: 0.6487  Acc@1: 62.5000 (64.0265)  Acc@5: 87.5000 (91.1894)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 0.8635  Acc@1: 68.7500 (64.0432)  Acc@5: 93.7500 (91.1954)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:32  Lr: 0.001875  Loss: 1.4554  Acc@1: 62.5000 (64.0397)  Acc@5: 93.7500 (91.2042)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:29  Lr: 0.001875  Loss: 1.1911  Acc@1: 56.2500 (64.0347)  Acc@5: 93.7500 (91.2028)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: 1.1873  Acc@1: 62.5000 (64.0311)  Acc@5: 87.5000 (91.2015)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:22  Lr: 0.001875  Loss: 1.2094  Acc@1: 68.7500 (64.0405)  Acc@5: 93.7500 (91.2088)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: 1.1197  Acc@1: 68.7500 (64.0212)  Acc@5: 93.7500 (91.2060)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:15  Lr: 0.001875  Loss: 0.8937  Acc@1: 62.5000 (64.0220)  Acc@5: 93.7500 (91.2061)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: 0.8780  Acc@1: 56.2500 (64.0014)  Acc@5: 93.7500 (91.2062)  time: 0.3453  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:08  Lr: 0.001875  Loss: 1.1463  Acc@1: 62.5000 (64.0022)  Acc@5: 87.5000 (91.2006)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 1.4912  Acc@1: 62.5000 (64.0102)  Acc@5: 93.7500 (91.2050)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:01  Lr: 0.001875  Loss: 1.2195  Acc@1: 68.7500 (64.0124)  Acc@5: 93.7500 (91.2080)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: 0.6391  Acc@1: 68.7500 (64.0076)  Acc@5: 93.7500 (91.2066)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4420/4579]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6811  Acc@1: 56.2500 (63.9943)  Acc@5: 87.5000 (91.2053)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 0.8984  Acc@1: 56.2500 (63.9867)  Acc@5: 87.5000 (91.1970)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 1.2558  Acc@1: 62.5000 (63.9974)  Acc@5: 87.5000 (91.1957)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 1.6925  Acc@1: 68.7500 (63.9997)  Acc@5: 93.7500 (91.2014)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 0.9144  Acc@1: 62.5000 (64.0061)  Acc@5: 93.7500 (91.1945)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: 0.6951  Acc@1: 68.7500 (64.0167)  Acc@5: 93.7500 (91.1988)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: 0.7321  Acc@1: 68.7500 (64.0287)  Acc@5: 93.7500 (91.2003)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: 0.8811  Acc@1: 62.5000 (64.0225)  Acc@5: 87.5000 (91.2018)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: 0.7298  Acc@1: 62.5000 (64.0163)  Acc@5: 87.5000 (91.2033)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: 1.4581  Acc@1: 62.5000 (64.0199)  Acc@5: 87.5000 (91.2021)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.5856  Acc@1: 68.7500 (64.0290)  Acc@5: 93.7500 (91.2063)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:16  Lr: 0.001875  Loss: 0.9504  Acc@1: 68.7500 (64.0394)  Acc@5: 93.7500 (91.2133)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.7976  Acc@1: 68.7500 (64.0539)  Acc@5: 93.7500 (91.2161)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 1.1166  Acc@1: 68.7500 (64.0450)  Acc@5: 93.7500 (91.2148)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 1.4393  Acc@1: 62.5000 (64.0457)  Acc@5: 93.7500 (91.2122)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.9230  Acc@1: 68.7500 (64.0464)  Acc@5: 87.5000 (91.2150)  time: 0.3462  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4854  Acc@1: 68.7500 (64.0512)  Acc@5: 93.7500 (91.2159)  time: 0.3387  data: 0.0013  max mem: 2500
Train: Epoch[3/5] Total time: 0:26:22 (0.3456 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.4854  Acc@1: 68.7500 (64.0512)  Acc@5: 93.7500 (91.2159)
Train: Epoch[4/5]  [   0/4579]  eta: 0:53:06  Lr: 0.001875  Loss: 1.0805  Acc@1: 68.7500 (68.7500)  Acc@5: 87.5000 (87.5000)  time: 0.6958  data: 0.3503  max mem: 2500
Train: Epoch[4/5]  [  10/4579]  eta: 0:28:49  Lr: 0.001875  Loss: 1.4448  Acc@1: 68.7500 (64.7727)  Acc@5: 93.7500 (93.1818)  time: 0.3786  data: 0.0332  max mem: 2500
Train: Epoch[4/5]  [  20/4579]  eta: 0:27:35  Lr: 0.001875  Loss: 0.6945  Acc@1: 68.7500 (65.4762)  Acc@5: 93.7500 (92.8571)  time: 0.3464  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [  30/4579]  eta: 0:27:06  Lr: 0.001875  Loss: 1.1490  Acc@1: 68.7500 (66.5323)  Acc@5: 93.7500 (93.1452)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  40/4579]  eta: 0:26:49  Lr: 0.001875  Loss: 1.5765  Acc@1: 68.7500 (64.6341)  Acc@5: 93.7500 (91.9207)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  50/4579]  eta: 0:26:39  Lr: 0.001875  Loss: 0.6937  Acc@1: 62.5000 (65.6863)  Acc@5: 93.7500 (92.4020)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [  60/4579]  eta: 0:26:29  Lr: 0.001875  Loss: 1.1018  Acc@1: 68.7500 (66.2910)  Acc@5: 93.7500 (92.2131)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [  70/4579]  eta: 0:26:21  Lr: 0.001875  Loss: 0.7792  Acc@1: 68.7500 (65.8451)  Acc@5: 87.5000 (91.9894)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  80/4579]  eta: 0:26:16  Lr: 0.001875  Loss: 1.5665  Acc@1: 68.7500 (65.8951)  Acc@5: 93.7500 (92.1296)  time: 0.3463  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [  90/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 1.2144  Acc@1: 62.5000 (65.1786)  Acc@5: 93.7500 (92.1016)  time: 0.3461  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 100/4579]  eta: 0:26:04  Lr: 0.001875  Loss: 1.1103  Acc@1: 68.7500 (65.6559)  Acc@5: 93.7500 (91.8317)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 110/4579]  eta: 0:25:59  Lr: 0.001875  Loss: 1.5147  Acc@1: 68.7500 (65.5968)  Acc@5: 93.7500 (91.6667)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 120/4579]  eta: 0:25:54  Lr: 0.001875  Loss: 1.0027  Acc@1: 62.5000 (64.9793)  Acc@5: 93.7500 (91.6839)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 130/4579]  eta: 0:25:51  Lr: 0.001875  Loss: 0.6643  Acc@1: 62.5000 (65.1240)  Acc@5: 100.0000 (92.2233)  time: 0.3462  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [ 140/4579]  eta: 0:25:46  Lr: 0.001875  Loss: 1.0019  Acc@1: 68.7500 (65.2926)  Acc@5: 93.7500 (92.2429)  time: 0.3469  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [ 150/4579]  eta: 0:25:42  Lr: 0.001875  Loss: 1.0746  Acc@1: 68.7500 (65.3974)  Acc@5: 93.7500 (92.2185)  time: 0.3459  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 160/4579]  eta: 0:25:38  Lr: 0.001875  Loss: 1.3387  Acc@1: 68.7500 (65.5280)  Acc@5: 87.5000 (92.0031)  time: 0.3457  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 170/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 1.2557  Acc@1: 68.7500 (65.3143)  Acc@5: 87.5000 (91.8129)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 180/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 1.0280  Acc@1: 62.5000 (65.3660)  Acc@5: 87.5000 (91.6782)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 190/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 1.5888  Acc@1: 62.5000 (65.3796)  Acc@5: 87.5000 (91.5576)  time: 0.3461  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 200/4579]  eta: 0:25:22  Lr: 0.001875  Loss: 1.3722  Acc@1: 62.5000 (65.3918)  Acc@5: 93.7500 (91.5423)  time: 0.3467  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 210/4579]  eta: 0:25:18  Lr: 0.001875  Loss: 1.0592  Acc@1: 68.7500 (65.6102)  Acc@5: 93.7500 (91.7358)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 220/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 1.7981  Acc@1: 68.7500 (65.5260)  Acc@5: 93.7500 (91.7986)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 230/4579]  eta: 0:25:10  Lr: 0.001875  Loss: 1.0218  Acc@1: 62.5000 (65.3409)  Acc@5: 93.7500 (91.8290)  time: 0.3448  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 240/4579]  eta: 0:25:06  Lr: 0.001875  Loss: 1.2460  Acc@1: 62.5000 (65.5602)  Acc@5: 93.7500 (91.8568)  time: 0.3451  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 250/4579]  eta: 0:25:03  Lr: 0.001875  Loss: 1.7464  Acc@1: 68.7500 (65.4880)  Acc@5: 93.7500 (91.9074)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 260/4579]  eta: 0:24:59  Lr: 0.001875  Loss: 1.0483  Acc@1: 68.7500 (65.5651)  Acc@5: 93.7500 (92.0019)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 270/4579]  eta: 0:24:55  Lr: 0.001875  Loss: 2.0034  Acc@1: 62.5000 (65.1983)  Acc@5: 93.7500 (91.7897)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 280/4579]  eta: 0:24:51  Lr: 0.001875  Loss: 0.7260  Acc@1: 62.5000 (65.3915)  Acc@5: 87.5000 (91.8149)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 290/4579]  eta: 0:24:48  Lr: 0.001875  Loss: 1.8041  Acc@1: 68.7500 (65.2491)  Acc@5: 93.7500 (91.7096)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 300/4579]  eta: 0:24:44  Lr: 0.001875  Loss: 1.5320  Acc@1: 62.5000 (65.1993)  Acc@5: 87.5000 (91.7151)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 310/4579]  eta: 0:24:40  Lr: 0.001875  Loss: 0.8657  Acc@1: 62.5000 (65.1929)  Acc@5: 87.5000 (91.6600)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 320/4579]  eta: 0:24:37  Lr: 0.001875  Loss: 1.1697  Acc@1: 68.7500 (65.3816)  Acc@5: 87.5000 (91.6472)  time: 0.3461  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 330/4579]  eta: 0:24:33  Lr: 0.001875  Loss: 1.3068  Acc@1: 68.7500 (65.2002)  Acc@5: 87.5000 (91.4464)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 340/4579]  eta: 0:24:30  Lr: 0.001875  Loss: 1.1326  Acc@1: 62.5000 (65.2859)  Acc@5: 87.5000 (91.4406)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 350/4579]  eta: 0:24:26  Lr: 0.001875  Loss: 0.9478  Acc@1: 68.7500 (65.4202)  Acc@5: 87.5000 (91.4886)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 360/4579]  eta: 0:24:22  Lr: 0.001875  Loss: 1.1246  Acc@1: 68.7500 (65.4259)  Acc@5: 87.5000 (91.3781)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 370/4579]  eta: 0:24:18  Lr: 0.001875  Loss: 1.1329  Acc@1: 62.5000 (65.4818)  Acc@5: 87.5000 (91.3073)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 380/4579]  eta: 0:24:15  Lr: 0.001875  Loss: 1.2517  Acc@1: 62.5000 (65.4364)  Acc@5: 87.5000 (91.2730)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 390/4579]  eta: 0:24:11  Lr: 0.001875  Loss: 0.8569  Acc@1: 62.5000 (65.3613)  Acc@5: 87.5000 (91.1765)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 400/4579]  eta: 0:24:08  Lr: 0.001875  Loss: 1.2951  Acc@1: 62.5000 (65.3211)  Acc@5: 87.5000 (91.1315)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 410/4579]  eta: 0:24:04  Lr: 0.001875  Loss: 1.1470  Acc@1: 62.5000 (65.4045)  Acc@5: 93.7500 (91.2257)  time: 0.3453  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 420/4579]  eta: 0:24:01  Lr: 0.001875  Loss: 0.8042  Acc@1: 68.7500 (65.4246)  Acc@5: 93.7500 (91.2856)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 430/4579]  eta: 0:23:57  Lr: 0.001875  Loss: 1.0162  Acc@1: 68.7500 (65.5452)  Acc@5: 93.7500 (91.2993)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 440/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 0.6452  Acc@1: 68.7500 (65.6746)  Acc@5: 93.7500 (91.3832)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 450/4579]  eta: 0:23:50  Lr: 0.001875  Loss: 1.0405  Acc@1: 62.5000 (65.6042)  Acc@5: 93.7500 (91.3664)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 460/4579]  eta: 0:23:46  Lr: 0.001875  Loss: 0.8557  Acc@1: 62.5000 (65.6047)  Acc@5: 93.7500 (91.4317)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 470/4579]  eta: 0:23:43  Lr: 0.001875  Loss: 1.5509  Acc@1: 56.2500 (65.4061)  Acc@5: 93.7500 (91.3880)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 480/4579]  eta: 0:23:39  Lr: 0.001875  Loss: 1.4026  Acc@1: 56.2500 (65.3846)  Acc@5: 93.7500 (91.4111)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 490/4579]  eta: 0:23:36  Lr: 0.001875  Loss: 1.2818  Acc@1: 56.2500 (65.1731)  Acc@5: 93.7500 (91.3569)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 500/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 1.0018  Acc@1: 56.2500 (65.0699)  Acc@5: 93.7500 (91.3548)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 510/4579]  eta: 0:23:29  Lr: 0.001875  Loss: 1.1715  Acc@1: 62.5000 (64.9706)  Acc@5: 93.7500 (91.3527)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 520/4579]  eta: 0:23:25  Lr: 0.001875  Loss: 1.4031  Acc@1: 62.5000 (65.0192)  Acc@5: 93.7500 (91.3868)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 530/4579]  eta: 0:23:22  Lr: 0.001875  Loss: 0.4368  Acc@1: 62.5000 (65.0306)  Acc@5: 93.7500 (91.4195)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 540/4579]  eta: 0:23:18  Lr: 0.001875  Loss: 0.6569  Acc@1: 62.5000 (65.0416)  Acc@5: 93.7500 (91.4164)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 550/4579]  eta: 0:23:15  Lr: 0.001875  Loss: 0.7239  Acc@1: 62.5000 (65.0181)  Acc@5: 87.5000 (91.3907)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 560/4579]  eta: 0:23:11  Lr: 0.001875  Loss: 1.0315  Acc@1: 62.5000 (64.9844)  Acc@5: 87.5000 (91.3436)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 570/4579]  eta: 0:23:08  Lr: 0.001875  Loss: 1.2599  Acc@1: 62.5000 (64.8862)  Acc@5: 87.5000 (91.3419)  time: 0.3460  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 580/4579]  eta: 0:23:04  Lr: 0.001875  Loss: 1.0459  Acc@1: 62.5000 (64.8989)  Acc@5: 93.7500 (91.3511)  time: 0.3455  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 590/4579]  eta: 0:23:01  Lr: 0.001875  Loss: 1.1313  Acc@1: 62.5000 (64.9006)  Acc@5: 93.7500 (91.4129)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 600/4579]  eta: 0:22:57  Lr: 0.001875  Loss: 0.5726  Acc@1: 62.5000 (64.8814)  Acc@5: 93.7500 (91.4101)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 610/4579]  eta: 0:22:53  Lr: 0.001875  Loss: 1.6411  Acc@1: 62.5000 (64.9038)  Acc@5: 93.7500 (91.4178)  time: 0.3450  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 620/4579]  eta: 0:22:50  Lr: 0.001875  Loss: 1.2280  Acc@1: 62.5000 (64.8752)  Acc@5: 87.5000 (91.3446)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 630/4579]  eta: 0:22:47  Lr: 0.001875  Loss: 0.9392  Acc@1: 68.7500 (64.8970)  Acc@5: 87.5000 (91.3728)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 640/4579]  eta: 0:22:43  Lr: 0.001875  Loss: 1.0306  Acc@1: 62.5000 (64.8888)  Acc@5: 93.7500 (91.4002)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 650/4579]  eta: 0:22:39  Lr: 0.001875  Loss: 1.0297  Acc@1: 62.5000 (64.8810)  Acc@5: 93.7500 (91.3978)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 660/4579]  eta: 0:22:36  Lr: 0.001875  Loss: 1.0288  Acc@1: 62.5000 (64.9017)  Acc@5: 93.7500 (91.4051)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 670/4579]  eta: 0:22:32  Lr: 0.001875  Loss: 1.3451  Acc@1: 68.7500 (64.9124)  Acc@5: 93.7500 (91.4307)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 680/4579]  eta: 0:22:29  Lr: 0.001875  Loss: 1.6516  Acc@1: 62.5000 (64.8678)  Acc@5: 93.7500 (91.4464)  time: 0.3453  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 690/4579]  eta: 0:22:25  Lr: 0.001875  Loss: 0.7207  Acc@1: 62.5000 (64.8878)  Acc@5: 93.7500 (91.4255)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 700/4579]  eta: 0:22:22  Lr: 0.001875  Loss: 1.1526  Acc@1: 62.5000 (64.8805)  Acc@5: 93.7500 (91.4586)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 710/4579]  eta: 0:22:19  Lr: 0.001875  Loss: 1.6141  Acc@1: 62.5000 (64.8822)  Acc@5: 93.7500 (91.4821)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 720/4579]  eta: 0:22:15  Lr: 0.001875  Loss: 0.6197  Acc@1: 62.5000 (64.9012)  Acc@5: 93.7500 (91.4702)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 730/4579]  eta: 0:22:11  Lr: 0.001875  Loss: 1.6721  Acc@1: 62.5000 (64.9367)  Acc@5: 93.7500 (91.5099)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 740/4579]  eta: 0:22:08  Lr: 0.001875  Loss: 0.7101  Acc@1: 62.5000 (64.9038)  Acc@5: 93.7500 (91.5486)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 750/4579]  eta: 0:22:05  Lr: 0.001875  Loss: 1.4432  Acc@1: 56.2500 (64.8802)  Acc@5: 93.7500 (91.5613)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 760/4579]  eta: 0:22:01  Lr: 0.001875  Loss: 1.5570  Acc@1: 62.5000 (64.9474)  Acc@5: 93.7500 (91.5818)  time: 0.3463  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 770/4579]  eta: 0:21:58  Lr: 0.001875  Loss: 0.6764  Acc@1: 62.5000 (64.8752)  Acc@5: 93.7500 (91.5532)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 780/4579]  eta: 0:21:54  Lr: 0.001875  Loss: 1.6525  Acc@1: 62.5000 (64.8047)  Acc@5: 87.5000 (91.5253)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 790/4579]  eta: 0:21:51  Lr: 0.001875  Loss: 1.2523  Acc@1: 62.5000 (64.8467)  Acc@5: 87.5000 (91.5376)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 800/4579]  eta: 0:21:47  Lr: 0.001875  Loss: 0.9093  Acc@1: 62.5000 (64.8174)  Acc@5: 93.7500 (91.4950)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 810/4579]  eta: 0:21:44  Lr: 0.001875  Loss: 0.6636  Acc@1: 62.5000 (64.7965)  Acc@5: 87.5000 (91.4535)  time: 0.3460  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 820/4579]  eta: 0:21:40  Lr: 0.001875  Loss: 0.7155  Acc@1: 68.7500 (64.8599)  Acc@5: 93.7500 (91.4586)  time: 0.3463  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 830/4579]  eta: 0:21:37  Lr: 0.001875  Loss: 1.0816  Acc@1: 68.7500 (64.8541)  Acc@5: 93.7500 (91.4335)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 840/4579]  eta: 0:21:33  Lr: 0.001875  Loss: 0.4432  Acc@1: 68.7500 (64.9004)  Acc@5: 87.5000 (91.4313)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 850/4579]  eta: 0:21:30  Lr: 0.001875  Loss: 0.9694  Acc@1: 62.5000 (64.8355)  Acc@5: 87.5000 (91.4072)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 860/4579]  eta: 0:21:26  Lr: 0.001875  Loss: 1.0853  Acc@1: 62.5000 (64.9027)  Acc@5: 93.7500 (91.4562)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 870/4579]  eta: 0:21:23  Lr: 0.001875  Loss: 1.3348  Acc@1: 68.7500 (65.0115)  Acc@5: 93.7500 (91.4897)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 880/4579]  eta: 0:21:19  Lr: 0.001875  Loss: 1.0786  Acc@1: 68.7500 (64.9688)  Acc@5: 93.7500 (91.4657)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 890/4579]  eta: 0:21:16  Lr: 0.001875  Loss: 1.6479  Acc@1: 62.5000 (64.9481)  Acc@5: 93.7500 (91.4703)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 900/4579]  eta: 0:21:12  Lr: 0.001875  Loss: 1.3024  Acc@1: 62.5000 (64.9972)  Acc@5: 93.7500 (91.5025)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 910/4579]  eta: 0:21:09  Lr: 0.001875  Loss: 0.5174  Acc@1: 68.7500 (65.0796)  Acc@5: 93.7500 (91.5134)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 920/4579]  eta: 0:21:06  Lr: 0.001875  Loss: 1.0606  Acc@1: 68.7500 (65.0787)  Acc@5: 93.7500 (91.5038)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 930/4579]  eta: 0:21:02  Lr: 0.001875  Loss: 0.7348  Acc@1: 62.5000 (65.0175)  Acc@5: 93.7500 (91.5145)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 940/4579]  eta: 0:20:59  Lr: 0.001875  Loss: 0.9307  Acc@1: 62.5000 (65.0837)  Acc@5: 93.7500 (91.5117)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 950/4579]  eta: 0:20:55  Lr: 0.001875  Loss: 1.3701  Acc@1: 62.5000 (65.0171)  Acc@5: 93.7500 (91.5155)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 960/4579]  eta: 0:20:52  Lr: 0.001875  Loss: 0.8931  Acc@1: 62.5000 (65.0429)  Acc@5: 93.7500 (91.5258)  time: 0.3471  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 970/4579]  eta: 0:20:48  Lr: 0.001875  Loss: 0.9877  Acc@1: 68.7500 (65.0296)  Acc@5: 93.7500 (91.5036)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 980/4579]  eta: 0:20:45  Lr: 0.001875  Loss: 0.9250  Acc@1: 68.7500 (65.0357)  Acc@5: 93.7500 (91.4946)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 990/4579]  eta: 0:20:41  Lr: 0.001875  Loss: 0.7407  Acc@1: 68.7500 (65.0858)  Acc@5: 93.7500 (91.4859)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1000/4579]  eta: 0:20:38  Lr: 0.001875  Loss: 1.2799  Acc@1: 68.7500 (65.0412)  Acc@5: 87.5000 (91.4648)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1010/4579]  eta: 0:20:34  Lr: 0.001875  Loss: 1.4469  Acc@1: 56.2500 (65.0099)  Acc@5: 87.5000 (91.4503)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1020/4579]  eta: 0:20:31  Lr: 0.001875  Loss: 0.9927  Acc@1: 62.5000 (65.0037)  Acc@5: 87.5000 (91.4606)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1030/4579]  eta: 0:20:27  Lr: 0.001875  Loss: 1.0236  Acc@1: 62.5000 (65.0158)  Acc@5: 93.7500 (91.4707)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1040/4579]  eta: 0:20:24  Lr: 0.001875  Loss: 1.0584  Acc@1: 62.5000 (64.9736)  Acc@5: 93.7500 (91.4625)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1050/4579]  eta: 0:20:20  Lr: 0.001875  Loss: 1.4473  Acc@1: 56.2500 (64.9025)  Acc@5: 87.5000 (91.4367)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1060/4579]  eta: 0:20:17  Lr: 0.001875  Loss: 0.9847  Acc@1: 62.5000 (64.8916)  Acc@5: 87.5000 (91.4585)  time: 0.3453  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1070/4579]  eta: 0:20:13  Lr: 0.001875  Loss: 0.9252  Acc@1: 62.5000 (64.9043)  Acc@5: 93.7500 (91.4799)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1080/4579]  eta: 0:20:10  Lr: 0.001875  Loss: 0.9086  Acc@1: 68.7500 (64.9225)  Acc@5: 93.7500 (91.4836)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1090/4579]  eta: 0:20:06  Lr: 0.001875  Loss: 0.9585  Acc@1: 62.5000 (64.8717)  Acc@5: 87.5000 (91.4413)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1100/4579]  eta: 0:20:03  Lr: 0.001875  Loss: 0.6735  Acc@1: 56.2500 (64.7990)  Acc@5: 93.7500 (91.4680)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1110/4579]  eta: 0:20:00  Lr: 0.001875  Loss: 0.9378  Acc@1: 62.5000 (64.8121)  Acc@5: 93.7500 (91.4604)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1120/4579]  eta: 0:19:56  Lr: 0.001875  Loss: 1.3995  Acc@1: 62.5000 (64.8249)  Acc@5: 93.7500 (91.4864)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1130/4579]  eta: 0:19:53  Lr: 0.001875  Loss: 1.1661  Acc@1: 62.5000 (64.8210)  Acc@5: 93.7500 (91.4954)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1140/4579]  eta: 0:19:49  Lr: 0.001875  Loss: 1.4046  Acc@1: 62.5000 (64.8006)  Acc@5: 93.7500 (91.4713)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1150/4579]  eta: 0:19:46  Lr: 0.001875  Loss: 1.1283  Acc@1: 62.5000 (64.7698)  Acc@5: 93.7500 (91.4694)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1160/4579]  eta: 0:19:42  Lr: 0.001875  Loss: 1.5278  Acc@1: 62.5000 (64.7664)  Acc@5: 87.5000 (91.4567)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1170/4579]  eta: 0:19:39  Lr: 0.001875  Loss: 0.8761  Acc@1: 62.5000 (64.7257)  Acc@5: 87.5000 (91.4443)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1180/4579]  eta: 0:19:35  Lr: 0.001875  Loss: 1.4834  Acc@1: 62.5000 (64.7386)  Acc@5: 87.5000 (91.4373)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1190/4579]  eta: 0:19:32  Lr: 0.001875  Loss: 1.2870  Acc@1: 68.7500 (64.7827)  Acc@5: 93.7500 (91.4568)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1200/4579]  eta: 0:19:28  Lr: 0.001875  Loss: 0.9399  Acc@1: 68.7500 (64.8158)  Acc@5: 93.7500 (91.4759)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1210/4579]  eta: 0:19:25  Lr: 0.001875  Loss: 0.9357  Acc@1: 68.7500 (64.8173)  Acc@5: 93.7500 (91.4998)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1220/4579]  eta: 0:19:21  Lr: 0.001875  Loss: 0.7274  Acc@1: 62.5000 (64.8188)  Acc@5: 93.7500 (91.4977)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1230/4579]  eta: 0:19:18  Lr: 0.001875  Loss: 0.4077  Acc@1: 62.5000 (64.8457)  Acc@5: 87.5000 (91.5160)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1240/4579]  eta: 0:19:14  Lr: 0.001875  Loss: 1.1272  Acc@1: 62.5000 (64.8268)  Acc@5: 93.7500 (91.5542)  time: 0.3465  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1250/4579]  eta: 0:19:11  Lr: 0.001875  Loss: 1.2303  Acc@1: 62.5000 (64.8331)  Acc@5: 93.7500 (91.5767)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1260/4579]  eta: 0:19:07  Lr: 0.001875  Loss: 1.3462  Acc@1: 68.7500 (64.8543)  Acc@5: 93.7500 (91.5940)  time: 0.3451  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1270/4579]  eta: 0:19:04  Lr: 0.001875  Loss: 1.1343  Acc@1: 62.5000 (64.8702)  Acc@5: 93.7500 (91.5913)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1280/4579]  eta: 0:19:00  Lr: 0.001875  Loss: 1.5090  Acc@1: 62.5000 (64.8858)  Acc@5: 93.7500 (91.5886)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1290/4579]  eta: 0:18:57  Lr: 0.001875  Loss: 1.2618  Acc@1: 62.5000 (64.8770)  Acc@5: 93.7500 (91.5569)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1300/4579]  eta: 0:18:54  Lr: 0.001875  Loss: 0.9579  Acc@1: 62.5000 (64.8924)  Acc@5: 87.5000 (91.5594)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1310/4579]  eta: 0:18:50  Lr: 0.001875  Loss: 0.7773  Acc@1: 62.5000 (64.8789)  Acc@5: 93.7500 (91.5570)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1320/4579]  eta: 0:18:47  Lr: 0.001875  Loss: 0.7928  Acc@1: 62.5000 (64.9129)  Acc@5: 93.7500 (91.5925)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1330/4579]  eta: 0:18:43  Lr: 0.001875  Loss: 1.4556  Acc@1: 75.0000 (64.9371)  Acc@5: 93.7500 (91.5853)  time: 0.3446  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1340/4579]  eta: 0:18:40  Lr: 0.001875  Loss: 1.5614  Acc@1: 62.5000 (64.8770)  Acc@5: 93.7500 (91.5874)  time: 0.3458  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1350/4579]  eta: 0:18:36  Lr: 0.001875  Loss: 1.2933  Acc@1: 68.7500 (64.9241)  Acc@5: 93.7500 (91.5757)  time: 0.3459  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1360/4579]  eta: 0:18:33  Lr: 0.001875  Loss: 1.3589  Acc@1: 68.7500 (64.8971)  Acc@5: 87.5000 (91.5687)  time: 0.3445  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1370/4579]  eta: 0:18:29  Lr: 0.001875  Loss: 1.3332  Acc@1: 62.5000 (64.9116)  Acc@5: 87.5000 (91.5527)  time: 0.3449  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1380/4579]  eta: 0:18:26  Lr: 0.001875  Loss: 0.8345  Acc@1: 68.7500 (64.9031)  Acc@5: 87.5000 (91.5415)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1390/4579]  eta: 0:18:22  Lr: 0.001875  Loss: 0.7971  Acc@1: 62.5000 (64.8904)  Acc@5: 87.5000 (91.5214)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1400/4579]  eta: 0:18:19  Lr: 0.001875  Loss: 1.7935  Acc@1: 56.2500 (64.8644)  Acc@5: 87.5000 (91.5061)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1410/4579]  eta: 0:18:15  Lr: 0.001875  Loss: 1.2874  Acc@1: 56.2500 (64.8653)  Acc@5: 93.7500 (91.5131)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1420/4579]  eta: 0:18:12  Lr: 0.001875  Loss: 1.0429  Acc@1: 56.2500 (64.8135)  Acc@5: 93.7500 (91.4849)  time: 0.3451  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1430/4579]  eta: 0:18:08  Lr: 0.001875  Loss: 0.6257  Acc@1: 68.7500 (64.8498)  Acc@5: 93.7500 (91.5094)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1440/4579]  eta: 0:18:05  Lr: 0.001875  Loss: 0.8792  Acc@1: 68.7500 (64.8812)  Acc@5: 93.7500 (91.5380)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1450/4579]  eta: 0:18:01  Lr: 0.001875  Loss: 1.4415  Acc@1: 68.7500 (64.8432)  Acc@5: 93.7500 (91.4972)  time: 0.3467  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1460/4579]  eta: 0:17:58  Lr: 0.001875  Loss: 0.8511  Acc@1: 68.7500 (64.8956)  Acc@5: 93.7500 (91.5169)  time: 0.3453  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1470/4579]  eta: 0:17:54  Lr: 0.001875  Loss: 1.1912  Acc@1: 68.7500 (64.8878)  Acc@5: 93.7500 (91.4981)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1480/4579]  eta: 0:17:51  Lr: 0.001875  Loss: 0.9296  Acc@1: 62.5000 (64.8295)  Acc@5: 93.7500 (91.4880)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1490/4579]  eta: 0:17:48  Lr: 0.001875  Loss: 0.4593  Acc@1: 62.5000 (64.8642)  Acc@5: 93.7500 (91.4864)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1500/4579]  eta: 0:17:44  Lr: 0.001875  Loss: 1.1523  Acc@1: 68.7500 (64.8693)  Acc@5: 87.5000 (91.4973)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1510/4579]  eta: 0:17:41  Lr: 0.001875  Loss: 1.2406  Acc@1: 62.5000 (64.8908)  Acc@5: 87.5000 (91.4957)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1520/4579]  eta: 0:17:37  Lr: 0.001875  Loss: 1.1163  Acc@1: 62.5000 (64.8792)  Acc@5: 93.7500 (91.4900)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1530/4579]  eta: 0:17:34  Lr: 0.001875  Loss: 0.8390  Acc@1: 62.5000 (64.8800)  Acc@5: 93.7500 (91.4884)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1540/4579]  eta: 0:17:30  Lr: 0.001875  Loss: 0.6621  Acc@1: 68.7500 (64.9010)  Acc@5: 93.7500 (91.5152)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1550/4579]  eta: 0:17:27  Lr: 0.001875  Loss: 1.5362  Acc@1: 62.5000 (64.8735)  Acc@5: 93.7500 (91.5095)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1560/4579]  eta: 0:17:23  Lr: 0.001875  Loss: 1.9042  Acc@1: 56.2500 (64.8262)  Acc@5: 93.7500 (91.5078)  time: 0.3445  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1570/4579]  eta: 0:17:20  Lr: 0.001875  Loss: 0.9703  Acc@1: 62.5000 (64.8154)  Acc@5: 93.7500 (91.4982)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1580/4579]  eta: 0:17:16  Lr: 0.001875  Loss: 0.3923  Acc@1: 68.7500 (64.8601)  Acc@5: 93.7500 (91.5085)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1590/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 1.4451  Acc@1: 68.7500 (64.8452)  Acc@5: 93.7500 (91.4755)  time: 0.3466  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1600/4579]  eta: 0:17:09  Lr: 0.001875  Loss: 0.9536  Acc@1: 62.5000 (64.8111)  Acc@5: 87.5000 (91.4702)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1610/4579]  eta: 0:17:06  Lr: 0.001875  Loss: 1.3199  Acc@1: 62.5000 (64.8277)  Acc@5: 93.7500 (91.4843)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1620/4579]  eta: 0:17:03  Lr: 0.001875  Loss: 0.5726  Acc@1: 62.5000 (64.8211)  Acc@5: 93.7500 (91.4559)  time: 0.3462  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1630/4579]  eta: 0:16:59  Lr: 0.001875  Loss: 1.7240  Acc@1: 68.7500 (64.8375)  Acc@5: 93.7500 (91.4623)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1640/4579]  eta: 0:16:56  Lr: 0.001875  Loss: 0.7087  Acc@1: 68.7500 (64.7966)  Acc@5: 93.7500 (91.4420)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1650/4579]  eta: 0:16:52  Lr: 0.001875  Loss: 1.0507  Acc@1: 62.5000 (64.7978)  Acc@5: 93.7500 (91.4408)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1660/4579]  eta: 0:16:49  Lr: 0.001875  Loss: 1.3045  Acc@1: 68.7500 (64.7915)  Acc@5: 93.7500 (91.4434)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1670/4579]  eta: 0:16:45  Lr: 0.001875  Loss: 1.2457  Acc@1: 68.7500 (64.7853)  Acc@5: 93.7500 (91.4535)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1680/4579]  eta: 0:16:42  Lr: 0.001875  Loss: 1.4880  Acc@1: 56.2500 (64.7457)  Acc@5: 93.7500 (91.4448)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1690/4579]  eta: 0:16:38  Lr: 0.001875  Loss: 0.5373  Acc@1: 56.2500 (64.7324)  Acc@5: 87.5000 (91.4437)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1700/4579]  eta: 0:16:35  Lr: 0.001875  Loss: 0.8193  Acc@1: 68.7500 (64.7781)  Acc@5: 93.7500 (91.4646)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1710/4579]  eta: 0:16:32  Lr: 0.001875  Loss: 1.1140  Acc@1: 68.7500 (64.8122)  Acc@5: 93.7500 (91.4706)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1720/4579]  eta: 0:16:28  Lr: 0.001875  Loss: 1.3115  Acc@1: 68.7500 (64.8424)  Acc@5: 93.7500 (91.4693)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1730/4579]  eta: 0:16:25  Lr: 0.001875  Loss: 0.9154  Acc@1: 68.7500 (64.8686)  Acc@5: 93.7500 (91.4717)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1740/4579]  eta: 0:16:21  Lr: 0.001875  Loss: 1.2727  Acc@1: 62.5000 (64.8765)  Acc@5: 93.7500 (91.4632)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1750/4579]  eta: 0:16:18  Lr: 0.001875  Loss: 0.7870  Acc@1: 62.5000 (64.8522)  Acc@5: 93.7500 (91.4620)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1760/4579]  eta: 0:16:14  Lr: 0.001875  Loss: 1.2284  Acc@1: 62.5000 (64.8637)  Acc@5: 93.7500 (91.4644)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1770/4579]  eta: 0:16:11  Lr: 0.001875  Loss: 1.3832  Acc@1: 68.7500 (64.8821)  Acc@5: 93.7500 (91.4632)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1780/4579]  eta: 0:16:07  Lr: 0.001875  Loss: 1.1352  Acc@1: 68.7500 (64.9179)  Acc@5: 93.7500 (91.4620)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1790/4579]  eta: 0:16:04  Lr: 0.001875  Loss: 1.4749  Acc@1: 62.5000 (64.8939)  Acc@5: 93.7500 (91.4678)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1800/4579]  eta: 0:16:00  Lr: 0.001875  Loss: 1.2054  Acc@1: 56.2500 (64.8806)  Acc@5: 93.7500 (91.4527)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1810/4579]  eta: 0:15:57  Lr: 0.001875  Loss: 1.3680  Acc@1: 62.5000 (64.8744)  Acc@5: 87.5000 (91.4446)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1820/4579]  eta: 0:15:53  Lr: 0.001875  Loss: 2.1338  Acc@1: 62.5000 (64.8510)  Acc@5: 87.5000 (91.4230)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1830/4579]  eta: 0:15:50  Lr: 0.001875  Loss: 1.2731  Acc@1: 62.5000 (64.8450)  Acc@5: 87.5000 (91.4050)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1840/4579]  eta: 0:15:46  Lr: 0.001875  Loss: 1.3379  Acc@1: 62.5000 (64.8323)  Acc@5: 93.7500 (91.4211)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1850/4579]  eta: 0:15:43  Lr: 0.001875  Loss: 1.0738  Acc@1: 68.7500 (64.8535)  Acc@5: 93.7500 (91.4303)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1860/4579]  eta: 0:15:40  Lr: 0.001875  Loss: 1.2270  Acc@1: 68.7500 (64.8878)  Acc@5: 93.7500 (91.4361)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1870/4579]  eta: 0:15:36  Lr: 0.001875  Loss: 1.1776  Acc@1: 68.7500 (64.8851)  Acc@5: 93.7500 (91.4518)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1880/4579]  eta: 0:15:33  Lr: 0.001875  Loss: 0.5183  Acc@1: 62.5000 (64.8791)  Acc@5: 93.7500 (91.4640)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1890/4579]  eta: 0:15:29  Lr: 0.001875  Loss: 1.4092  Acc@1: 62.5000 (64.8499)  Acc@5: 93.7500 (91.4629)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1900/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 1.1032  Acc@1: 62.5000 (64.8573)  Acc@5: 93.7500 (91.4617)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1910/4579]  eta: 0:15:22  Lr: 0.001875  Loss: 0.7362  Acc@1: 62.5000 (64.8515)  Acc@5: 87.5000 (91.4410)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1920/4579]  eta: 0:15:19  Lr: 0.001875  Loss: 0.8089  Acc@1: 62.5000 (64.8458)  Acc@5: 87.5000 (91.4465)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1930/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 0.7901  Acc@1: 62.5000 (64.8433)  Acc@5: 93.7500 (91.4487)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1940/4579]  eta: 0:15:12  Lr: 0.001875  Loss: 1.3302  Acc@1: 62.5000 (64.8570)  Acc@5: 93.7500 (91.4638)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1950/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 1.3745  Acc@1: 62.5000 (64.8578)  Acc@5: 93.7500 (91.4691)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1960/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 1.1165  Acc@1: 62.5000 (64.8585)  Acc@5: 93.7500 (91.4712)  time: 0.3458  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1970/4579]  eta: 0:15:01  Lr: 0.001875  Loss: 1.3704  Acc@1: 68.7500 (64.8592)  Acc@5: 87.5000 (91.4637)  time: 0.3458  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1980/4579]  eta: 0:14:58  Lr: 0.001875  Loss: 0.7923  Acc@1: 68.7500 (64.8536)  Acc@5: 93.7500 (91.4784)  time: 0.3461  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1990/4579]  eta: 0:14:55  Lr: 0.001875  Loss: 0.6624  Acc@1: 68.7500 (64.8669)  Acc@5: 93.7500 (91.4804)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2000/4579]  eta: 0:14:51  Lr: 0.001875  Loss: 1.6225  Acc@1: 68.7500 (64.8707)  Acc@5: 93.7500 (91.4824)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2010/4579]  eta: 0:14:48  Lr: 0.001875  Loss: 0.8512  Acc@1: 62.5000 (64.8682)  Acc@5: 93.7500 (91.4843)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2020/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 0.8295  Acc@1: 62.5000 (64.8596)  Acc@5: 93.7500 (91.4863)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2030/4579]  eta: 0:14:41  Lr: 0.001875  Loss: 0.6294  Acc@1: 62.5000 (64.8695)  Acc@5: 93.7500 (91.4790)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2040/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 0.7453  Acc@1: 68.7500 (64.8855)  Acc@5: 93.7500 (91.4931)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2050/4579]  eta: 0:14:34  Lr: 0.001875  Loss: 1.3829  Acc@1: 68.7500 (64.9013)  Acc@5: 93.7500 (91.4920)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2060/4579]  eta: 0:14:30  Lr: 0.001875  Loss: 0.6469  Acc@1: 68.7500 (64.9108)  Acc@5: 93.7500 (91.4938)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2070/4579]  eta: 0:14:27  Lr: 0.001875  Loss: 1.1989  Acc@1: 68.7500 (64.9052)  Acc@5: 93.7500 (91.5017)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2080/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 1.3450  Acc@1: 68.7500 (64.9177)  Acc@5: 93.7500 (91.5005)  time: 0.3467  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2090/4579]  eta: 0:14:20  Lr: 0.001875  Loss: 1.2082  Acc@1: 62.5000 (64.8882)  Acc@5: 93.7500 (91.4993)  time: 0.3467  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2100/4579]  eta: 0:14:17  Lr: 0.001875  Loss: 1.8361  Acc@1: 62.5000 (64.8739)  Acc@5: 93.7500 (91.5070)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2110/4579]  eta: 0:14:13  Lr: 0.001875  Loss: 0.7945  Acc@1: 62.5000 (64.8478)  Acc@5: 87.5000 (91.4792)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2120/4579]  eta: 0:14:10  Lr: 0.001875  Loss: 0.8398  Acc@1: 62.5000 (64.8868)  Acc@5: 87.5000 (91.4869)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2130/4579]  eta: 0:14:06  Lr: 0.001875  Loss: 1.2729  Acc@1: 68.7500 (64.8991)  Acc@5: 93.7500 (91.4770)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2140/4579]  eta: 0:14:03  Lr: 0.001875  Loss: 0.6922  Acc@1: 68.7500 (64.9083)  Acc@5: 93.7500 (91.4789)  time: 0.3464  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2150/4579]  eta: 0:13:59  Lr: 0.001875  Loss: 1.2094  Acc@1: 68.7500 (64.9059)  Acc@5: 93.7500 (91.4720)  time: 0.3458  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2160/4579]  eta: 0:13:56  Lr: 0.001875  Loss: 1.2621  Acc@1: 68.7500 (64.9150)  Acc@5: 93.7500 (91.4825)  time: 0.3458  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2170/4579]  eta: 0:13:52  Lr: 0.001875  Loss: 1.4333  Acc@1: 62.5000 (64.8866)  Acc@5: 93.7500 (91.4671)  time: 0.3468  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2180/4579]  eta: 0:13:49  Lr: 0.001875  Loss: 1.4937  Acc@1: 62.5000 (64.8900)  Acc@5: 87.5000 (91.4632)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2190/4579]  eta: 0:13:45  Lr: 0.001875  Loss: 1.0749  Acc@1: 62.5000 (64.8848)  Acc@5: 93.7500 (91.4879)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2200/4579]  eta: 0:13:42  Lr: 0.001875  Loss: 0.7070  Acc@1: 62.5000 (64.8881)  Acc@5: 93.7500 (91.4840)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2210/4579]  eta: 0:13:39  Lr: 0.001875  Loss: 1.2999  Acc@1: 68.7500 (64.9056)  Acc@5: 93.7500 (91.4971)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2220/4579]  eta: 0:13:35  Lr: 0.001875  Loss: 0.5254  Acc@1: 68.7500 (64.9342)  Acc@5: 93.7500 (91.4988)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2230/4579]  eta: 0:13:32  Lr: 0.001875  Loss: 0.8153  Acc@1: 68.7500 (64.9260)  Acc@5: 93.7500 (91.4836)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2240/4579]  eta: 0:13:28  Lr: 0.001875  Loss: 0.7844  Acc@1: 56.2500 (64.9041)  Acc@5: 87.5000 (91.4687)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2250/4579]  eta: 0:13:25  Lr: 0.001875  Loss: 0.7219  Acc@1: 56.2500 (64.8934)  Acc@5: 87.5000 (91.4649)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2260/4579]  eta: 0:13:21  Lr: 0.001875  Loss: 1.1004  Acc@1: 62.5000 (64.8939)  Acc@5: 87.5000 (91.4612)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2270/4579]  eta: 0:13:18  Lr: 0.001875  Loss: 0.9460  Acc@1: 62.5000 (64.8943)  Acc@5: 87.5000 (91.4575)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2280/4579]  eta: 0:13:14  Lr: 0.001875  Loss: 1.1792  Acc@1: 68.7500 (64.9167)  Acc@5: 93.7500 (91.4621)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2290/4579]  eta: 0:13:11  Lr: 0.001875  Loss: 0.9402  Acc@1: 68.7500 (64.9389)  Acc@5: 93.7500 (91.4666)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2300/4579]  eta: 0:13:07  Lr: 0.001875  Loss: 0.9436  Acc@1: 68.7500 (64.9392)  Acc@5: 93.7500 (91.4847)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2310/4579]  eta: 0:13:04  Lr: 0.001875  Loss: 0.9013  Acc@1: 62.5000 (64.9178)  Acc@5: 93.7500 (91.4756)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2320/4579]  eta: 0:13:00  Lr: 0.001875  Loss: 0.7541  Acc@1: 68.7500 (64.9397)  Acc@5: 93.7500 (91.4773)  time: 0.3449  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2330/4579]  eta: 0:12:57  Lr: 0.001875  Loss: 0.7990  Acc@1: 62.5000 (64.9346)  Acc@5: 93.7500 (91.4763)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2340/4579]  eta: 0:12:54  Lr: 0.001875  Loss: 0.8456  Acc@1: 62.5000 (64.9509)  Acc@5: 93.7500 (91.4807)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2350/4579]  eta: 0:12:50  Lr: 0.001875  Loss: 1.7303  Acc@1: 68.7500 (64.9591)  Acc@5: 93.7500 (91.4770)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2360/4579]  eta: 0:12:47  Lr: 0.001875  Loss: 1.4434  Acc@1: 68.7500 (64.9460)  Acc@5: 93.7500 (91.4787)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2370/4579]  eta: 0:12:43  Lr: 0.001875  Loss: 0.9538  Acc@1: 62.5000 (64.9462)  Acc@5: 93.7500 (91.4698)  time: 0.3452  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2380/4579]  eta: 0:12:40  Lr: 0.001875  Loss: 0.8122  Acc@1: 62.5000 (64.9517)  Acc@5: 93.7500 (91.4742)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2390/4579]  eta: 0:12:36  Lr: 0.001875  Loss: 0.9813  Acc@1: 68.7500 (64.9650)  Acc@5: 93.7500 (91.4811)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2400/4579]  eta: 0:12:33  Lr: 0.001875  Loss: 0.8233  Acc@1: 68.7500 (64.9859)  Acc@5: 93.7500 (91.4801)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2410/4579]  eta: 0:12:29  Lr: 0.001875  Loss: 1.5397  Acc@1: 68.7500 (64.9886)  Acc@5: 93.7500 (91.4740)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2420/4579]  eta: 0:12:26  Lr: 0.001875  Loss: 0.9746  Acc@1: 68.7500 (65.0119)  Acc@5: 93.7500 (91.4860)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2430/4579]  eta: 0:12:22  Lr: 0.001875  Loss: 0.8014  Acc@1: 68.7500 (65.0221)  Acc@5: 93.7500 (91.4824)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2440/4579]  eta: 0:12:19  Lr: 0.001875  Loss: 1.2827  Acc@1: 62.5000 (64.9990)  Acc@5: 93.7500 (91.4763)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2450/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 0.9731  Acc@1: 62.5000 (65.0015)  Acc@5: 93.7500 (91.4882)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2460/4579]  eta: 0:12:12  Lr: 0.001875  Loss: 1.0554  Acc@1: 68.7500 (65.0041)  Acc@5: 93.7500 (91.4897)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2470/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 0.5985  Acc@1: 62.5000 (65.0167)  Acc@5: 93.7500 (91.4938)  time: 0.3446  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2480/4579]  eta: 0:12:05  Lr: 0.001875  Loss: 0.5843  Acc@1: 62.5000 (65.0141)  Acc@5: 93.7500 (91.5004)  time: 0.3458  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2490/4579]  eta: 0:12:02  Lr: 0.001875  Loss: 0.5593  Acc@1: 68.7500 (65.0517)  Acc@5: 93.7500 (91.5069)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2500/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 1.0272  Acc@1: 68.7500 (65.0440)  Acc@5: 93.7500 (91.5084)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2510/4579]  eta: 0:11:55  Lr: 0.001875  Loss: 1.1081  Acc@1: 62.5000 (65.0339)  Acc@5: 93.7500 (91.5099)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2520/4579]  eta: 0:11:51  Lr: 0.001875  Loss: 1.3261  Acc@1: 68.7500 (65.0362)  Acc@5: 87.5000 (91.4964)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2530/4579]  eta: 0:11:48  Lr: 0.001875  Loss: 1.7362  Acc@1: 68.7500 (65.0311)  Acc@5: 93.7500 (91.5004)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2540/4579]  eta: 0:11:44  Lr: 0.001875  Loss: 1.3804  Acc@1: 62.5000 (65.0310)  Acc@5: 93.7500 (91.5019)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2550/4579]  eta: 0:11:41  Lr: 0.001875  Loss: 1.1555  Acc@1: 68.7500 (65.0554)  Acc@5: 93.7500 (91.5009)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2560/4579]  eta: 0:11:37  Lr: 0.001875  Loss: 0.8076  Acc@1: 68.7500 (65.0552)  Acc@5: 93.7500 (91.5023)  time: 0.3443  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2570/4579]  eta: 0:11:34  Lr: 0.001875  Loss: 1.0171  Acc@1: 68.7500 (65.0574)  Acc@5: 93.7500 (91.5087)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2580/4579]  eta: 0:11:30  Lr: 0.001875  Loss: 0.5234  Acc@1: 68.7500 (65.0717)  Acc@5: 93.7500 (91.5052)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2590/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 0.8855  Acc@1: 68.7500 (65.0883)  Acc@5: 93.7500 (91.5139)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2600/4579]  eta: 0:11:24  Lr: 0.001875  Loss: 0.9346  Acc@1: 62.5000 (65.0783)  Acc@5: 93.7500 (91.5153)  time: 0.3456  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2610/4579]  eta: 0:11:20  Lr: 0.001875  Loss: 0.8635  Acc@1: 62.5000 (65.0613)  Acc@5: 93.7500 (91.5191)  time: 0.3460  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2620/4579]  eta: 0:11:17  Lr: 0.001875  Loss: 1.7225  Acc@1: 56.2500 (65.0396)  Acc@5: 93.7500 (91.5180)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2630/4579]  eta: 0:11:13  Lr: 0.001875  Loss: 1.3051  Acc@1: 62.5000 (65.0584)  Acc@5: 93.7500 (91.5265)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2640/4579]  eta: 0:11:10  Lr: 0.001875  Loss: 0.6903  Acc@1: 68.7500 (65.0653)  Acc@5: 93.7500 (91.5231)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2650/4579]  eta: 0:11:06  Lr: 0.001875  Loss: 1.0299  Acc@1: 68.7500 (65.0934)  Acc@5: 93.7500 (91.5244)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2660/4579]  eta: 0:11:03  Lr: 0.001875  Loss: 0.9961  Acc@1: 68.7500 (65.0883)  Acc@5: 93.7500 (91.5234)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2670/4579]  eta: 0:10:59  Lr: 0.001875  Loss: 1.2891  Acc@1: 62.5000 (65.0856)  Acc@5: 93.7500 (91.5411)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2680/4579]  eta: 0:10:56  Lr: 0.001875  Loss: 0.8983  Acc@1: 62.5000 (65.0713)  Acc@5: 93.7500 (91.5377)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2690/4579]  eta: 0:10:52  Lr: 0.001875  Loss: 0.6902  Acc@1: 62.5000 (65.0780)  Acc@5: 93.7500 (91.5436)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2700/4579]  eta: 0:10:49  Lr: 0.001875  Loss: 0.8501  Acc@1: 62.5000 (65.0777)  Acc@5: 93.7500 (91.5402)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2710/4579]  eta: 0:10:45  Lr: 0.001875  Loss: 1.1021  Acc@1: 68.7500 (65.0890)  Acc@5: 93.7500 (91.5345)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2720/4579]  eta: 0:10:42  Lr: 0.001875  Loss: 1.3923  Acc@1: 62.5000 (65.0611)  Acc@5: 93.7500 (91.5266)  time: 0.3447  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2730/4579]  eta: 0:10:39  Lr: 0.001875  Loss: 0.6725  Acc@1: 56.2500 (65.0449)  Acc@5: 93.7500 (91.5141)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2740/4579]  eta: 0:10:35  Lr: 0.001875  Loss: 1.0334  Acc@1: 62.5000 (65.0629)  Acc@5: 93.7500 (91.5131)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2750/4579]  eta: 0:10:32  Lr: 0.001875  Loss: 1.3046  Acc@1: 68.7500 (65.0627)  Acc@5: 93.7500 (91.5076)  time: 0.3456  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2760/4579]  eta: 0:10:28  Lr: 0.001875  Loss: 1.5649  Acc@1: 62.5000 (65.0715)  Acc@5: 93.7500 (91.5203)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2770/4579]  eta: 0:10:25  Lr: 0.001875  Loss: 0.8776  Acc@1: 62.5000 (65.0826)  Acc@5: 93.7500 (91.5193)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2780/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 0.8700  Acc@1: 68.7500 (65.1182)  Acc@5: 93.7500 (91.5251)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2790/4579]  eta: 0:10:18  Lr: 0.001875  Loss: 0.7273  Acc@1: 68.7500 (65.1088)  Acc@5: 93.7500 (91.5196)  time: 0.3466  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2800/4579]  eta: 0:10:14  Lr: 0.001875  Loss: 1.0667  Acc@1: 68.7500 (65.1151)  Acc@5: 93.7500 (91.5187)  time: 0.3469  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2810/4579]  eta: 0:10:11  Lr: 0.001875  Loss: 1.1552  Acc@1: 62.5000 (65.1081)  Acc@5: 93.7500 (91.5244)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2820/4579]  eta: 0:10:07  Lr: 0.001875  Loss: 1.4146  Acc@1: 62.5000 (65.1077)  Acc@5: 93.7500 (91.5456)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2830/4579]  eta: 0:10:04  Lr: 0.001875  Loss: 0.9354  Acc@1: 68.7500 (65.1117)  Acc@5: 93.7500 (91.5313)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2840/4579]  eta: 0:10:01  Lr: 0.001875  Loss: 0.7183  Acc@1: 68.7500 (65.1179)  Acc@5: 87.5000 (91.5325)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2850/4579]  eta: 0:09:57  Lr: 0.001875  Loss: 0.6762  Acc@1: 68.7500 (65.1328)  Acc@5: 93.7500 (91.5402)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2860/4579]  eta: 0:09:54  Lr: 0.001875  Loss: 1.4845  Acc@1: 56.2500 (65.1105)  Acc@5: 87.5000 (91.5283)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2870/4579]  eta: 0:09:50  Lr: 0.001875  Loss: 1.7073  Acc@1: 56.2500 (65.1036)  Acc@5: 87.5000 (91.5165)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2880/4579]  eta: 0:09:47  Lr: 0.001875  Loss: 1.0643  Acc@1: 68.7500 (65.1206)  Acc@5: 87.5000 (91.5177)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2890/4579]  eta: 0:09:43  Lr: 0.001875  Loss: 0.4112  Acc@1: 68.7500 (65.1375)  Acc@5: 93.7500 (91.5233)  time: 0.3467  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2900/4579]  eta: 0:09:40  Lr: 0.001875  Loss: 1.2305  Acc@1: 68.7500 (65.1413)  Acc@5: 93.7500 (91.5331)  time: 0.3456  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2910/4579]  eta: 0:09:36  Lr: 0.001875  Loss: 1.6512  Acc@1: 68.7500 (65.1494)  Acc@5: 93.7500 (91.5386)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2920/4579]  eta: 0:09:33  Lr: 0.001875  Loss: 0.8198  Acc@1: 68.7500 (65.1682)  Acc@5: 93.7500 (91.5397)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2930/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 1.4461  Acc@1: 68.7500 (65.1399)  Acc@5: 93.7500 (91.5451)  time: 0.3467  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2940/4579]  eta: 0:09:26  Lr: 0.001875  Loss: 1.2906  Acc@1: 62.5000 (65.1479)  Acc@5: 93.7500 (91.5399)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2950/4579]  eta: 0:09:23  Lr: 0.001875  Loss: 0.7797  Acc@1: 62.5000 (65.1453)  Acc@5: 93.7500 (91.5474)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2960/4579]  eta: 0:09:19  Lr: 0.001875  Loss: 0.5078  Acc@1: 68.7500 (65.1575)  Acc@5: 93.7500 (91.5442)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2970/4579]  eta: 0:09:16  Lr: 0.001875  Loss: 1.0230  Acc@1: 68.7500 (65.1569)  Acc@5: 87.5000 (91.5348)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2980/4579]  eta: 0:09:12  Lr: 0.001875  Loss: 0.7141  Acc@1: 62.5000 (65.1585)  Acc@5: 87.5000 (91.5318)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2990/4579]  eta: 0:09:09  Lr: 0.001875  Loss: 0.4858  Acc@1: 62.5000 (65.1663)  Acc@5: 87.5000 (91.5267)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3000/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 0.9676  Acc@1: 68.7500 (65.1720)  Acc@5: 93.7500 (91.5195)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3010/4579]  eta: 0:09:02  Lr: 0.001875  Loss: 1.4859  Acc@1: 68.7500 (65.1922)  Acc@5: 93.7500 (91.5248)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3020/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.8791  Acc@1: 68.7500 (65.2061)  Acc@5: 93.7500 (91.5425)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3030/4579]  eta: 0:08:55  Lr: 0.001875  Loss: 1.0974  Acc@1: 68.7500 (65.2177)  Acc@5: 93.7500 (91.5395)  time: 0.3452  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3040/4579]  eta: 0:08:51  Lr: 0.001875  Loss: 1.4962  Acc@1: 62.5000 (65.2170)  Acc@5: 93.7500 (91.5468)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3050/4579]  eta: 0:08:48  Lr: 0.001875  Loss: 0.4261  Acc@1: 68.7500 (65.2266)  Acc@5: 93.7500 (91.5458)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3060/4579]  eta: 0:08:45  Lr: 0.001875  Loss: 0.5763  Acc@1: 68.7500 (65.2360)  Acc@5: 93.7500 (91.5448)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3070/4579]  eta: 0:08:41  Lr: 0.001875  Loss: 1.3443  Acc@1: 62.5000 (65.2292)  Acc@5: 93.7500 (91.5459)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3080/4579]  eta: 0:08:38  Lr: 0.001875  Loss: 1.0746  Acc@1: 62.5000 (65.2223)  Acc@5: 93.7500 (91.5490)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3090/4579]  eta: 0:08:34  Lr: 0.001875  Loss: 1.5991  Acc@1: 62.5000 (65.2378)  Acc@5: 93.7500 (91.5440)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3100/4579]  eta: 0:08:31  Lr: 0.001875  Loss: 0.9816  Acc@1: 68.7500 (65.2310)  Acc@5: 93.7500 (91.5551)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3110/4579]  eta: 0:08:27  Lr: 0.001875  Loss: 0.6054  Acc@1: 68.7500 (65.2322)  Acc@5: 93.7500 (91.5522)  time: 0.3448  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3120/4579]  eta: 0:08:24  Lr: 0.001875  Loss: 0.8988  Acc@1: 68.7500 (65.2355)  Acc@5: 87.5000 (91.5492)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3130/4579]  eta: 0:08:20  Lr: 0.001875  Loss: 0.6764  Acc@1: 68.7500 (65.2567)  Acc@5: 93.7500 (91.5522)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3140/4579]  eta: 0:08:17  Lr: 0.001875  Loss: 0.7724  Acc@1: 68.7500 (65.2539)  Acc@5: 93.7500 (91.5473)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3150/4579]  eta: 0:08:13  Lr: 0.001875  Loss: 0.9094  Acc@1: 62.5000 (65.2471)  Acc@5: 93.7500 (91.5503)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3160/4579]  eta: 0:08:10  Lr: 0.001875  Loss: 1.2547  Acc@1: 62.5000 (65.2523)  Acc@5: 93.7500 (91.5454)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3170/4579]  eta: 0:08:06  Lr: 0.001875  Loss: 1.0782  Acc@1: 62.5000 (65.2416)  Acc@5: 93.7500 (91.5425)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3180/4579]  eta: 0:08:03  Lr: 0.001875  Loss: 0.6156  Acc@1: 62.5000 (65.2330)  Acc@5: 87.5000 (91.5435)  time: 0.3447  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3190/4579]  eta: 0:08:00  Lr: 0.001875  Loss: 0.5117  Acc@1: 62.5000 (65.2480)  Acc@5: 93.7500 (91.5563)  time: 0.3454  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3200/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 0.5974  Acc@1: 62.5000 (65.2452)  Acc@5: 93.7500 (91.5593)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3210/4579]  eta: 0:07:53  Lr: 0.001875  Loss: 0.9438  Acc@1: 62.5000 (65.2328)  Acc@5: 87.5000 (91.5525)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3220/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 1.3776  Acc@1: 62.5000 (65.2340)  Acc@5: 93.7500 (91.5515)  time: 0.3444  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3230/4579]  eta: 0:07:46  Lr: 0.001875  Loss: 0.7272  Acc@1: 62.5000 (65.2314)  Acc@5: 93.7500 (91.5525)  time: 0.3453  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3240/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 1.6606  Acc@1: 62.5000 (65.2075)  Acc@5: 87.5000 (91.5323)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3250/4579]  eta: 0:07:39  Lr: 0.001875  Loss: 1.0080  Acc@1: 62.5000 (65.2107)  Acc@5: 93.7500 (91.5430)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3260/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 1.4246  Acc@1: 62.5000 (65.1832)  Acc@5: 93.7500 (91.5306)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3270/4579]  eta: 0:07:32  Lr: 0.001875  Loss: 1.3330  Acc@1: 56.2500 (65.1674)  Acc@5: 87.5000 (91.5336)  time: 0.3447  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3280/4579]  eta: 0:07:28  Lr: 0.001875  Loss: 1.0712  Acc@1: 62.5000 (65.1669)  Acc@5: 93.7500 (91.5365)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3290/4579]  eta: 0:07:25  Lr: 0.001875  Loss: 1.1366  Acc@1: 62.5000 (65.1664)  Acc@5: 87.5000 (91.5337)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3300/4579]  eta: 0:07:22  Lr: 0.001875  Loss: 1.0390  Acc@1: 68.7500 (65.1753)  Acc@5: 93.7500 (91.5329)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3310/4579]  eta: 0:07:18  Lr: 0.001875  Loss: 1.2418  Acc@1: 68.7500 (65.1672)  Acc@5: 93.7500 (91.5301)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3320/4579]  eta: 0:07:15  Lr: 0.001875  Loss: 0.9511  Acc@1: 62.5000 (65.1705)  Acc@5: 93.7500 (91.5312)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3330/4579]  eta: 0:07:11  Lr: 0.001875  Loss: 1.2232  Acc@1: 68.7500 (65.1813)  Acc@5: 93.7500 (91.5172)  time: 0.3471  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3340/4579]  eta: 0:07:08  Lr: 0.001875  Loss: 0.9223  Acc@1: 68.7500 (65.1938)  Acc@5: 93.7500 (91.5201)  time: 0.3467  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3350/4579]  eta: 0:07:04  Lr: 0.001875  Loss: 0.8108  Acc@1: 68.7500 (65.1988)  Acc@5: 93.7500 (91.5212)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3360/4579]  eta: 0:07:01  Lr: 0.001875  Loss: 1.4280  Acc@1: 62.5000 (65.2112)  Acc@5: 93.7500 (91.5185)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3370/4579]  eta: 0:06:57  Lr: 0.001875  Loss: 1.7451  Acc@1: 68.7500 (65.2013)  Acc@5: 93.7500 (91.5140)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3380/4579]  eta: 0:06:54  Lr: 0.001875  Loss: 0.7958  Acc@1: 68.7500 (65.1989)  Acc@5: 93.7500 (91.5188)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3390/4579]  eta: 0:06:50  Lr: 0.001875  Loss: 1.4075  Acc@1: 62.5000 (65.1965)  Acc@5: 93.7500 (91.5290)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3400/4579]  eta: 0:06:47  Lr: 0.001875  Loss: 1.3809  Acc@1: 62.5000 (65.1904)  Acc@5: 93.7500 (91.5264)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3410/4579]  eta: 0:06:44  Lr: 0.001875  Loss: 0.8716  Acc@1: 62.5000 (65.1843)  Acc@5: 93.7500 (91.5384)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3420/4579]  eta: 0:06:40  Lr: 0.001875  Loss: 0.9204  Acc@1: 62.5000 (65.2039)  Acc@5: 100.0000 (91.5504)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3430/4579]  eta: 0:06:37  Lr: 0.001875  Loss: 1.1006  Acc@1: 68.7500 (65.1960)  Acc@5: 93.7500 (91.5495)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3440/4579]  eta: 0:06:33  Lr: 0.001875  Loss: 0.8904  Acc@1: 62.5000 (65.1991)  Acc@5: 87.5000 (91.5450)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3450/4579]  eta: 0:06:30  Lr: 0.001875  Loss: 1.4844  Acc@1: 62.5000 (65.1931)  Acc@5: 93.7500 (91.5550)  time: 0.3460  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3460/4579]  eta: 0:06:26  Lr: 0.001875  Loss: 0.9138  Acc@1: 62.5000 (65.1979)  Acc@5: 93.7500 (91.5559)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3470/4579]  eta: 0:06:23  Lr: 0.001875  Loss: 1.5423  Acc@1: 62.5000 (65.1955)  Acc@5: 93.7500 (91.5586)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3480/4579]  eta: 0:06:19  Lr: 0.001875  Loss: 0.7184  Acc@1: 62.5000 (65.2004)  Acc@5: 93.7500 (91.5577)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3490/4579]  eta: 0:06:16  Lr: 0.001875  Loss: 1.6473  Acc@1: 62.5000 (65.2105)  Acc@5: 93.7500 (91.5604)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3500/4579]  eta: 0:06:12  Lr: 0.001875  Loss: 1.0772  Acc@1: 68.7500 (65.2278)  Acc@5: 93.7500 (91.5613)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3510/4579]  eta: 0:06:09  Lr: 0.001875  Loss: 1.2416  Acc@1: 68.7500 (65.2360)  Acc@5: 93.7500 (91.5622)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3520/4579]  eta: 0:06:06  Lr: 0.001875  Loss: 0.9398  Acc@1: 62.5000 (65.2229)  Acc@5: 93.7500 (91.5667)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3530/4579]  eta: 0:06:02  Lr: 0.001875  Loss: 0.6395  Acc@1: 62.5000 (65.2312)  Acc@5: 93.7500 (91.5693)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3540/4579]  eta: 0:05:59  Lr: 0.001875  Loss: 1.4517  Acc@1: 62.5000 (65.2199)  Acc@5: 93.7500 (91.5684)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3550/4579]  eta: 0:05:55  Lr: 0.001875  Loss: 0.8235  Acc@1: 68.7500 (65.2334)  Acc@5: 93.7500 (91.5816)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3560/4579]  eta: 0:05:52  Lr: 0.001875  Loss: 1.1439  Acc@1: 68.7500 (65.2240)  Acc@5: 93.7500 (91.5772)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3570/4579]  eta: 0:05:48  Lr: 0.001875  Loss: 0.9971  Acc@1: 62.5000 (65.2181)  Acc@5: 87.5000 (91.5710)  time: 0.3468  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [3580/4579]  eta: 0:05:45  Lr: 0.001875  Loss: 0.5513  Acc@1: 62.5000 (65.2332)  Acc@5: 93.7500 (91.5718)  time: 0.3469  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3590/4579]  eta: 0:05:41  Lr: 0.001875  Loss: 0.8437  Acc@1: 68.7500 (65.2569)  Acc@5: 93.7500 (91.5779)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3600/4579]  eta: 0:05:38  Lr: 0.001875  Loss: 1.2617  Acc@1: 68.7500 (65.2423)  Acc@5: 93.7500 (91.5753)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3610/4579]  eta: 0:05:34  Lr: 0.001875  Loss: 0.8898  Acc@1: 62.5000 (65.2382)  Acc@5: 93.7500 (91.5692)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3620/4579]  eta: 0:05:31  Lr: 0.001875  Loss: 0.5022  Acc@1: 68.7500 (65.2513)  Acc@5: 87.5000 (91.5666)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3630/4579]  eta: 0:05:28  Lr: 0.001875  Loss: 0.7580  Acc@1: 68.7500 (65.2541)  Acc@5: 87.5000 (91.5674)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3640/4579]  eta: 0:05:24  Lr: 0.001875  Loss: 1.1620  Acc@1: 68.7500 (65.2671)  Acc@5: 93.7500 (91.5734)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3650/4579]  eta: 0:05:21  Lr: 0.001875  Loss: 1.3761  Acc@1: 68.7500 (65.2492)  Acc@5: 93.7500 (91.5759)  time: 0.3472  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3660/4579]  eta: 0:05:17  Lr: 0.001875  Loss: 0.8707  Acc@1: 68.7500 (65.2622)  Acc@5: 93.7500 (91.5853)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3670/4579]  eta: 0:05:14  Lr: 0.001875  Loss: 1.2831  Acc@1: 68.7500 (65.2598)  Acc@5: 93.7500 (91.5844)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3680/4579]  eta: 0:05:10  Lr: 0.001875  Loss: 0.7409  Acc@1: 68.7500 (65.2693)  Acc@5: 93.7500 (91.5869)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3690/4579]  eta: 0:05:07  Lr: 0.001875  Loss: 1.0280  Acc@1: 62.5000 (65.2618)  Acc@5: 93.7500 (91.5961)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3700/4579]  eta: 0:05:03  Lr: 0.001875  Loss: 1.0741  Acc@1: 62.5000 (65.2611)  Acc@5: 93.7500 (91.6002)  time: 0.3485  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3710/4579]  eta: 0:05:00  Lr: 0.001875  Loss: 1.4579  Acc@1: 62.5000 (65.2536)  Acc@5: 93.7500 (91.5976)  time: 0.3484  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3720/4579]  eta: 0:04:56  Lr: 0.001875  Loss: 1.1250  Acc@1: 62.5000 (65.2513)  Acc@5: 87.5000 (91.5933)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3730/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 1.1658  Acc@1: 62.5000 (65.2389)  Acc@5: 87.5000 (91.5874)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3740/4579]  eta: 0:04:50  Lr: 0.001875  Loss: 0.4704  Acc@1: 62.5000 (65.2399)  Acc@5: 93.7500 (91.5881)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3750/4579]  eta: 0:04:46  Lr: 0.001875  Loss: 1.3480  Acc@1: 62.5000 (65.2226)  Acc@5: 93.7500 (91.5906)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3760/4579]  eta: 0:04:43  Lr: 0.001875  Loss: 1.2457  Acc@1: 62.5000 (65.2154)  Acc@5: 93.7500 (91.5830)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3770/4579]  eta: 0:04:39  Lr: 0.001875  Loss: 1.0768  Acc@1: 68.7500 (65.2231)  Acc@5: 93.7500 (91.5904)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3780/4579]  eta: 0:04:36  Lr: 0.001875  Loss: 0.8293  Acc@1: 68.7500 (65.2258)  Acc@5: 93.7500 (91.5945)  time: 0.3466  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3790/4579]  eta: 0:04:32  Lr: 0.001875  Loss: 1.2117  Acc@1: 68.7500 (65.2269)  Acc@5: 93.7500 (91.5952)  time: 0.3470  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [3800/4579]  eta: 0:04:29  Lr: 0.001875  Loss: 1.8115  Acc@1: 68.7500 (65.2378)  Acc@5: 93.7500 (91.5943)  time: 0.3465  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3810/4579]  eta: 0:04:25  Lr: 0.001875  Loss: 0.8902  Acc@1: 68.7500 (65.2552)  Acc@5: 93.7500 (91.6016)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3820/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 1.0319  Acc@1: 68.7500 (65.2643)  Acc@5: 93.7500 (91.6007)  time: 0.3446  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3830/4579]  eta: 0:04:18  Lr: 0.001875  Loss: 1.0218  Acc@1: 62.5000 (65.2571)  Acc@5: 93.7500 (91.5998)  time: 0.3454  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3840/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 1.0147  Acc@1: 62.5000 (65.2564)  Acc@5: 93.7500 (91.5989)  time: 0.3451  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3850/4579]  eta: 0:04:11  Lr: 0.001875  Loss: 0.7635  Acc@1: 68.7500 (65.2753)  Acc@5: 93.7500 (91.6061)  time: 0.3443  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3860/4579]  eta: 0:04:08  Lr: 0.001875  Loss: 1.0516  Acc@1: 68.7500 (65.2762)  Acc@5: 93.7500 (91.6052)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3870/4579]  eta: 0:04:05  Lr: 0.001875  Loss: 1.2344  Acc@1: 68.7500 (65.2867)  Acc@5: 93.7500 (91.6010)  time: 0.3469  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3880/4579]  eta: 0:04:01  Lr: 0.001875  Loss: 1.6975  Acc@1: 68.7500 (65.2892)  Acc@5: 93.7500 (91.6001)  time: 0.3458  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3890/4579]  eta: 0:03:58  Lr: 0.001875  Loss: 0.9926  Acc@1: 68.7500 (65.3126)  Acc@5: 93.7500 (91.6056)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3900/4579]  eta: 0:03:54  Lr: 0.001875  Loss: 1.4309  Acc@1: 68.7500 (65.3262)  Acc@5: 93.7500 (91.6095)  time: 0.3458  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3910/4579]  eta: 0:03:51  Lr: 0.001875  Loss: 1.1061  Acc@1: 75.0000 (65.3429)  Acc@5: 87.5000 (91.6054)  time: 0.3455  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3920/4579]  eta: 0:03:47  Lr: 0.001875  Loss: 0.7698  Acc@1: 68.7500 (65.3469)  Acc@5: 93.7500 (91.6077)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3930/4579]  eta: 0:03:44  Lr: 0.001875  Loss: 0.8067  Acc@1: 62.5000 (65.3396)  Acc@5: 93.7500 (91.6147)  time: 0.3444  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3940/4579]  eta: 0:03:40  Lr: 0.001875  Loss: 0.7877  Acc@1: 62.5000 (65.3419)  Acc@5: 93.7500 (91.6138)  time: 0.3460  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3950/4579]  eta: 0:03:37  Lr: 0.001875  Loss: 1.5462  Acc@1: 62.5000 (65.3426)  Acc@5: 87.5000 (91.6034)  time: 0.3464  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3960/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 0.8842  Acc@1: 62.5000 (65.3497)  Acc@5: 93.7500 (91.6120)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3970/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 1.3732  Acc@1: 68.7500 (65.3551)  Acc@5: 93.7500 (91.6189)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3980/4579]  eta: 0:03:27  Lr: 0.001875  Loss: 1.2248  Acc@1: 62.5000 (65.3526)  Acc@5: 93.7500 (91.6227)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3990/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 0.7630  Acc@1: 68.7500 (65.3455)  Acc@5: 87.5000 (91.6218)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4000/4579]  eta: 0:03:20  Lr: 0.001875  Loss: 1.2141  Acc@1: 62.5000 (65.3321)  Acc@5: 87.5000 (91.6240)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4010/4579]  eta: 0:03:16  Lr: 0.001875  Loss: 1.0111  Acc@1: 56.2500 (65.3250)  Acc@5: 93.7500 (91.6293)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4020/4579]  eta: 0:03:13  Lr: 0.001875  Loss: 0.9945  Acc@1: 62.5000 (65.3258)  Acc@5: 93.7500 (91.6423)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4030/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 0.7319  Acc@1: 68.7500 (65.3451)  Acc@5: 93.7500 (91.6491)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4040/4579]  eta: 0:03:06  Lr: 0.001875  Loss: 1.2827  Acc@1: 68.7500 (65.3396)  Acc@5: 93.7500 (91.6512)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4050/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 0.9999  Acc@1: 68.7500 (65.3403)  Acc@5: 87.5000 (91.6471)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4060/4579]  eta: 0:02:59  Lr: 0.001875  Loss: 1.4665  Acc@1: 62.5000 (65.3380)  Acc@5: 87.5000 (91.6446)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4070/4579]  eta: 0:02:55  Lr: 0.001875  Loss: 1.5386  Acc@1: 62.5000 (65.3279)  Acc@5: 87.5000 (91.6329)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4080/4579]  eta: 0:02:52  Lr: 0.001875  Loss: 1.4435  Acc@1: 62.5000 (65.3256)  Acc@5: 93.7500 (91.6427)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4090/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 1.1101  Acc@1: 62.5000 (65.3263)  Acc@5: 93.7500 (91.6448)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4100/4579]  eta: 0:02:45  Lr: 0.001875  Loss: 0.8403  Acc@1: 62.5000 (65.3301)  Acc@5: 93.7500 (91.6484)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4110/4579]  eta: 0:02:42  Lr: 0.001875  Loss: 1.0673  Acc@1: 62.5000 (65.3263)  Acc@5: 93.7500 (91.6413)  time: 0.3458  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4120/4579]  eta: 0:02:38  Lr: 0.001875  Loss: 0.4447  Acc@1: 62.5000 (65.3240)  Acc@5: 93.7500 (91.6495)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4130/4579]  eta: 0:02:35  Lr: 0.001875  Loss: 1.4873  Acc@1: 62.5000 (65.3156)  Acc@5: 93.7500 (91.6440)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4140/4579]  eta: 0:02:31  Lr: 0.001875  Loss: 0.9362  Acc@1: 62.5000 (65.3284)  Acc@5: 93.7500 (91.6506)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4150/4579]  eta: 0:02:28  Lr: 0.001875  Loss: 1.3686  Acc@1: 62.5000 (65.3261)  Acc@5: 93.7500 (91.6496)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4160/4579]  eta: 0:02:24  Lr: 0.001875  Loss: 1.1642  Acc@1: 62.5000 (65.3193)  Acc@5: 93.7500 (91.6486)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4170/4579]  eta: 0:02:21  Lr: 0.001875  Loss: 1.0715  Acc@1: 62.5000 (65.3156)  Acc@5: 93.7500 (91.6477)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4180/4579]  eta: 0:02:17  Lr: 0.001875  Loss: 0.7516  Acc@1: 62.5000 (65.3178)  Acc@5: 93.7500 (91.6527)  time: 0.3470  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4190/4579]  eta: 0:02:14  Lr: 0.001875  Loss: 0.8312  Acc@1: 62.5000 (65.3111)  Acc@5: 93.7500 (91.6413)  time: 0.3460  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4200/4579]  eta: 0:02:11  Lr: 0.001875  Loss: 0.9965  Acc@1: 62.5000 (65.3089)  Acc@5: 87.5000 (91.6419)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4210/4579]  eta: 0:02:07  Lr: 0.001875  Loss: 0.7712  Acc@1: 62.5000 (65.2977)  Acc@5: 93.7500 (91.6335)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:04  Lr: 0.001875  Loss: 1.4967  Acc@1: 62.5000 (65.2970)  Acc@5: 93.7500 (91.6311)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:00  Lr: 0.001875  Loss: 0.9133  Acc@1: 62.5000 (65.2904)  Acc@5: 93.7500 (91.6391)  time: 0.3464  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 1.1578  Acc@1: 62.5000 (65.2897)  Acc@5: 93.7500 (91.6396)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4250/4579]  eta: 0:01:53  Lr: 0.001875  Loss: 0.8664  Acc@1: 62.5000 (65.2788)  Acc@5: 93.7500 (91.6446)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: 0.8794  Acc@1: 56.2500 (65.2737)  Acc@5: 93.7500 (91.6393)  time: 0.3473  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [4270/4579]  eta: 0:01:46  Lr: 0.001875  Loss: 0.9485  Acc@1: 62.5000 (65.2657)  Acc@5: 87.5000 (91.6384)  time: 0.3471  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: 1.0763  Acc@1: 62.5000 (65.2534)  Acc@5: 93.7500 (91.6433)  time: 0.3468  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [4290/4579]  eta: 0:01:39  Lr: 0.001875  Loss: 1.3817  Acc@1: 56.2500 (65.2441)  Acc@5: 87.5000 (91.6278)  time: 0.3459  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 1.3928  Acc@1: 62.5000 (65.2406)  Acc@5: 87.5000 (91.6269)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4310/4579]  eta: 0:01:32  Lr: 0.001875  Loss: 1.1913  Acc@1: 62.5000 (65.2270)  Acc@5: 87.5000 (91.6188)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4320/4579]  eta: 0:01:29  Lr: 0.001875  Loss: 0.6054  Acc@1: 62.5000 (65.2337)  Acc@5: 87.5000 (91.6151)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: 1.5317  Acc@1: 68.7500 (65.2361)  Acc@5: 87.5000 (91.6157)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4340/4579]  eta: 0:01:22  Lr: 0.001875  Loss: 1.0491  Acc@1: 62.5000 (65.2283)  Acc@5: 93.7500 (91.6163)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: 1.3975  Acc@1: 62.5000 (65.2364)  Acc@5: 93.7500 (91.6169)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:15  Lr: 0.001875  Loss: 1.3575  Acc@1: 68.7500 (65.2359)  Acc@5: 93.7500 (91.6146)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: 0.9117  Acc@1: 62.5000 (65.2211)  Acc@5: 93.7500 (91.6123)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:08  Lr: 0.001875  Loss: 0.8283  Acc@1: 62.5000 (65.2291)  Acc@5: 93.7500 (91.6172)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 0.9896  Acc@1: 62.5000 (65.2300)  Acc@5: 93.7500 (91.6178)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:01  Lr: 0.001875  Loss: 0.6097  Acc@1: 62.5000 (65.2323)  Acc@5: 93.7500 (91.6184)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: 0.9463  Acc@1: 62.5000 (65.2276)  Acc@5: 93.7500 (91.6190)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4420/4579]  eta: 0:00:54  Lr: 0.001875  Loss: 0.9528  Acc@1: 62.5000 (65.2171)  Acc@5: 93.7500 (91.6210)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 1.2951  Acc@1: 62.5000 (65.2110)  Acc@5: 93.7500 (91.6286)  time: 0.3448  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 1.1953  Acc@1: 62.5000 (65.2077)  Acc@5: 93.7500 (91.6334)  time: 0.3440  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 1.4760  Acc@1: 62.5000 (65.2059)  Acc@5: 87.5000 (91.6255)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 1.1684  Acc@1: 68.7500 (65.2236)  Acc@5: 93.7500 (91.6302)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: 0.7745  Acc@1: 68.7500 (65.2259)  Acc@5: 93.7500 (91.6322)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: 0.6841  Acc@1: 68.7500 (65.2421)  Acc@5: 93.7500 (91.6355)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: 1.1120  Acc@1: 68.7500 (65.2472)  Acc@5: 93.7500 (91.6374)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: 0.9421  Acc@1: 68.7500 (65.2522)  Acc@5: 93.7500 (91.6407)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: 0.8133  Acc@1: 62.5000 (65.2488)  Acc@5: 93.7500 (91.6413)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 1.3470  Acc@1: 62.5000 (65.2497)  Acc@5: 93.7500 (91.6404)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:16  Lr: 0.001875  Loss: 1.2636  Acc@1: 62.5000 (65.2491)  Acc@5: 93.7500 (91.6395)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.9547  Acc@1: 62.5000 (65.2486)  Acc@5: 87.5000 (91.6373)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 1.2110  Acc@1: 62.5000 (65.2549)  Acc@5: 93.7500 (91.6406)  time: 0.3480  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 1.1321  Acc@1: 62.5000 (65.2612)  Acc@5: 93.7500 (91.6383)  time: 0.3478  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 1.8859  Acc@1: 62.5000 (65.2538)  Acc@5: 93.7500 (91.6416)  time: 0.3461  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 1.3464  Acc@1: 62.5000 (65.2538)  Acc@5: 93.7500 (91.6390)  time: 0.3378  data: 0.0008  max mem: 2500
Train: Epoch[4/5] Total time: 0:26:23 (0.3458 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.3464  Acc@1: 62.5000 (65.2538)  Acc@5: 93.7500 (91.6390)
Train: Epoch[5/5]  [   0/4579]  eta: 0:49:00  Lr: 0.001875  Loss: 1.0498  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6421  data: 0.2937  max mem: 2500
Train: Epoch[5/5]  [  10/4579]  eta: 0:28:20  Lr: 0.001875  Loss: 0.8795  Acc@1: 68.7500 (59.6591)  Acc@5: 93.7500 (90.3409)  time: 0.3722  data: 0.0271  max mem: 2500
Train: Epoch[5/5]  [  20/4579]  eta: 0:27:16  Lr: 0.001875  Loss: 1.3587  Acc@1: 56.2500 (58.9286)  Acc@5: 93.7500 (90.7738)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  30/4579]  eta: 0:26:50  Lr: 0.001875  Loss: 0.8155  Acc@1: 62.5000 (61.6935)  Acc@5: 93.7500 (90.5242)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  40/4579]  eta: 0:26:37  Lr: 0.001875  Loss: 0.9937  Acc@1: 68.7500 (64.1768)  Acc@5: 93.7500 (91.0061)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  50/4579]  eta: 0:26:28  Lr: 0.001875  Loss: 0.6706  Acc@1: 68.7500 (65.4412)  Acc@5: 93.7500 (91.1765)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [  60/4579]  eta: 0:26:22  Lr: 0.001875  Loss: 1.1985  Acc@1: 68.7500 (65.7787)  Acc@5: 93.7500 (90.7787)  time: 0.3465  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [  70/4579]  eta: 0:26:14  Lr: 0.001875  Loss: 1.2998  Acc@1: 68.7500 (65.9331)  Acc@5: 93.7500 (91.0211)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  80/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 0.9394  Acc@1: 62.5000 (65.6636)  Acc@5: 93.7500 (91.5123)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  90/4579]  eta: 0:26:03  Lr: 0.001875  Loss: 1.1549  Acc@1: 62.5000 (65.1786)  Acc@5: 93.7500 (91.4835)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 100/4579]  eta: 0:25:58  Lr: 0.001875  Loss: 1.3548  Acc@1: 68.7500 (65.4084)  Acc@5: 87.5000 (91.4604)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 110/4579]  eta: 0:25:54  Lr: 0.001875  Loss: 0.6804  Acc@1: 68.7500 (65.8221)  Acc@5: 93.7500 (91.7230)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 120/4579]  eta: 0:25:50  Lr: 0.001875  Loss: 0.9905  Acc@1: 68.7500 (65.8058)  Acc@5: 93.7500 (91.6839)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 130/4579]  eta: 0:25:46  Lr: 0.001875  Loss: 0.8646  Acc@1: 62.5000 (65.5534)  Acc@5: 93.7500 (91.6031)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 140/4579]  eta: 0:25:43  Lr: 0.001875  Loss: 1.3220  Acc@1: 62.5000 (65.7801)  Acc@5: 93.7500 (91.7110)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 150/4579]  eta: 0:25:39  Lr: 0.001875  Loss: 1.6489  Acc@1: 62.5000 (65.4801)  Acc@5: 93.7500 (91.7219)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 160/4579]  eta: 0:25:35  Lr: 0.001875  Loss: 0.8816  Acc@1: 68.7500 (65.5668)  Acc@5: 93.7500 (91.7314)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 170/4579]  eta: 0:25:31  Lr: 0.001875  Loss: 0.9008  Acc@1: 68.7500 (65.7895)  Acc@5: 93.7500 (91.7032)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 180/4579]  eta: 0:25:27  Lr: 0.001875  Loss: 1.3487  Acc@1: 68.7500 (65.6423)  Acc@5: 93.7500 (91.4710)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 190/4579]  eta: 0:25:23  Lr: 0.001875  Loss: 1.7646  Acc@1: 62.5000 (65.6741)  Acc@5: 87.5000 (91.5576)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 200/4579]  eta: 0:25:19  Lr: 0.001875  Loss: 1.1257  Acc@1: 62.5000 (65.6405)  Acc@5: 87.5000 (91.3868)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 210/4579]  eta: 0:25:15  Lr: 0.001875  Loss: 1.6035  Acc@1: 62.5000 (65.4917)  Acc@5: 87.5000 (91.4396)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 220/4579]  eta: 0:25:11  Lr: 0.001875  Loss: 0.9271  Acc@1: 62.5000 (65.3563)  Acc@5: 93.7500 (91.4027)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 230/4579]  eta: 0:25:08  Lr: 0.001875  Loss: 1.5506  Acc@1: 62.5000 (65.3950)  Acc@5: 93.7500 (91.4232)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 240/4579]  eta: 0:25:04  Lr: 0.001875  Loss: 0.7410  Acc@1: 68.7500 (65.5083)  Acc@5: 93.7500 (91.5456)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 250/4579]  eta: 0:25:01  Lr: 0.001875  Loss: 0.9596  Acc@1: 68.7500 (65.6125)  Acc@5: 93.7500 (91.6833)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 260/4579]  eta: 0:24:57  Lr: 0.001875  Loss: 0.8729  Acc@1: 68.7500 (65.5891)  Acc@5: 93.7500 (91.6188)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 270/4579]  eta: 0:24:53  Lr: 0.001875  Loss: 0.6082  Acc@1: 62.5000 (65.6596)  Acc@5: 93.7500 (91.7666)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 280/4579]  eta: 0:24:50  Lr: 0.001875  Loss: 0.9232  Acc@1: 62.5000 (65.5249)  Acc@5: 93.7500 (91.6815)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 290/4579]  eta: 0:24:46  Lr: 0.001875  Loss: 0.7554  Acc@1: 62.5000 (65.4424)  Acc@5: 93.7500 (91.7096)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 300/4579]  eta: 0:24:42  Lr: 0.001875  Loss: 0.9099  Acc@1: 68.7500 (65.6977)  Acc@5: 93.7500 (91.8605)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 310/4579]  eta: 0:24:39  Lr: 0.001875  Loss: 0.7937  Acc@1: 68.7500 (65.6953)  Acc@5: 93.7500 (91.8408)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 320/4579]  eta: 0:24:35  Lr: 0.001875  Loss: 1.3795  Acc@1: 62.5000 (65.6737)  Acc@5: 87.5000 (91.7640)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 330/4579]  eta: 0:24:32  Lr: 0.001875  Loss: 1.4123  Acc@1: 62.5000 (65.7100)  Acc@5: 87.5000 (91.7674)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 340/4579]  eta: 0:24:28  Lr: 0.001875  Loss: 0.5705  Acc@1: 62.5000 (65.5792)  Acc@5: 87.5000 (91.7522)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 350/4579]  eta: 0:24:25  Lr: 0.001875  Loss: 1.4025  Acc@1: 68.7500 (65.4558)  Acc@5: 87.5000 (91.7379)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 360/4579]  eta: 0:24:21  Lr: 0.001875  Loss: 0.9701  Acc@1: 68.7500 (65.4605)  Acc@5: 93.7500 (91.6898)  time: 0.3463  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 370/4579]  eta: 0:24:18  Lr: 0.001875  Loss: 1.0043  Acc@1: 62.5000 (65.2291)  Acc@5: 93.7500 (91.6274)  time: 0.3477  data: 0.0023  max mem: 2500
Train: Epoch[5/5]  [ 380/4579]  eta: 0:24:15  Lr: 0.001875  Loss: 1.3838  Acc@1: 56.2500 (65.3215)  Acc@5: 93.7500 (91.6339)  time: 0.3477  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 390/4579]  eta: 0:24:11  Lr: 0.001875  Loss: 1.0214  Acc@1: 56.2500 (65.1375)  Acc@5: 87.5000 (91.5441)  time: 0.3453  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 400/4579]  eta: 0:24:07  Lr: 0.001875  Loss: 0.3996  Acc@1: 62.5000 (65.1496)  Acc@5: 87.5000 (91.5056)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 410/4579]  eta: 0:24:03  Lr: 0.001875  Loss: 1.2047  Acc@1: 68.7500 (65.2828)  Acc@5: 87.5000 (91.4234)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 420/4579]  eta: 0:24:00  Lr: 0.001875  Loss: 0.8262  Acc@1: 68.7500 (65.2613)  Acc@5: 87.5000 (91.3153)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 430/4579]  eta: 0:23:56  Lr: 0.001875  Loss: 0.5521  Acc@1: 68.7500 (65.3277)  Acc@5: 93.7500 (91.3428)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 440/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 1.3442  Acc@1: 68.7500 (65.3486)  Acc@5: 93.7500 (91.3832)  time: 0.3459  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 450/4579]  eta: 0:23:49  Lr: 0.001875  Loss: 0.7890  Acc@1: 68.7500 (65.5626)  Acc@5: 93.7500 (91.4357)  time: 0.3467  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 460/4579]  eta: 0:23:46  Lr: 0.001875  Loss: 0.9202  Acc@1: 68.7500 (65.5369)  Acc@5: 93.7500 (91.4317)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 470/4579]  eta: 0:23:42  Lr: 0.001875  Loss: 0.8768  Acc@1: 56.2500 (65.4857)  Acc@5: 93.7500 (91.3747)  time: 0.3462  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 480/4579]  eta: 0:23:39  Lr: 0.001875  Loss: 1.7392  Acc@1: 62.5000 (65.5275)  Acc@5: 93.7500 (91.3591)  time: 0.3462  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [ 490/4579]  eta: 0:23:35  Lr: 0.001875  Loss: 1.1925  Acc@1: 68.7500 (65.6186)  Acc@5: 93.7500 (91.3951)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 500/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 0.8893  Acc@1: 68.7500 (65.6188)  Acc@5: 93.7500 (91.4421)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 510/4579]  eta: 0:23:28  Lr: 0.001875  Loss: 0.9473  Acc@1: 62.5000 (65.4477)  Acc@5: 93.7500 (91.4017)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 520/4579]  eta: 0:23:25  Lr: 0.001875  Loss: 0.9204  Acc@1: 62.5000 (65.4031)  Acc@5: 93.7500 (91.4347)  time: 0.3453  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 530/4579]  eta: 0:23:21  Lr: 0.001875  Loss: 1.5098  Acc@1: 62.5000 (65.3955)  Acc@5: 93.7500 (91.4783)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 540/4579]  eta: 0:23:18  Lr: 0.001875  Loss: 1.0313  Acc@1: 62.5000 (65.2495)  Acc@5: 87.5000 (91.4164)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 550/4579]  eta: 0:23:14  Lr: 0.001875  Loss: 0.7494  Acc@1: 62.5000 (65.1996)  Acc@5: 87.5000 (91.4360)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 560/4579]  eta: 0:23:11  Lr: 0.001875  Loss: 0.8734  Acc@1: 62.5000 (65.1849)  Acc@5: 93.7500 (91.4661)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 570/4579]  eta: 0:23:07  Lr: 0.001875  Loss: 1.0840  Acc@1: 62.5000 (65.1160)  Acc@5: 93.7500 (91.4733)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 580/4579]  eta: 0:23:04  Lr: 0.001875  Loss: 0.7291  Acc@1: 62.5000 (65.0387)  Acc@5: 93.7500 (91.4802)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 590/4579]  eta: 0:23:00  Lr: 0.001875  Loss: 1.1228  Acc@1: 56.2500 (64.9217)  Acc@5: 93.7500 (91.4975)  time: 0.3445  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 600/4579]  eta: 0:22:57  Lr: 0.001875  Loss: 0.9110  Acc@1: 56.2500 (64.9334)  Acc@5: 93.7500 (91.4829)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 610/4579]  eta: 0:22:53  Lr: 0.001875  Loss: 0.9821  Acc@1: 68.7500 (64.9448)  Acc@5: 87.5000 (91.4587)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 620/4579]  eta: 0:22:50  Lr: 0.001875  Loss: 0.6021  Acc@1: 62.5000 (64.9356)  Acc@5: 93.7500 (91.4553)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 630/4579]  eta: 0:22:46  Lr: 0.001875  Loss: 1.0102  Acc@1: 62.5000 (64.9465)  Acc@5: 93.7500 (91.4422)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 640/4579]  eta: 0:22:43  Lr: 0.001875  Loss: 1.6600  Acc@1: 68.7500 (65.0741)  Acc@5: 93.7500 (91.4587)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 650/4579]  eta: 0:22:39  Lr: 0.001875  Loss: 1.0740  Acc@1: 75.0000 (65.1210)  Acc@5: 93.7500 (91.4843)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 660/4579]  eta: 0:22:36  Lr: 0.001875  Loss: 0.9279  Acc@1: 62.5000 (65.1002)  Acc@5: 93.7500 (91.4902)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 670/4579]  eta: 0:22:32  Lr: 0.001875  Loss: 1.0053  Acc@1: 62.5000 (65.1639)  Acc@5: 93.7500 (91.5238)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 680/4579]  eta: 0:22:29  Lr: 0.001875  Loss: 0.9677  Acc@1: 62.5000 (65.0881)  Acc@5: 93.7500 (91.4556)  time: 0.3468  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 690/4579]  eta: 0:22:25  Lr: 0.001875  Loss: 1.3571  Acc@1: 62.5000 (65.0778)  Acc@5: 87.5000 (91.4164)  time: 0.3456  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 700/4579]  eta: 0:22:22  Lr: 0.001875  Loss: 1.3712  Acc@1: 62.5000 (65.0945)  Acc@5: 87.5000 (91.3962)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 710/4579]  eta: 0:22:18  Lr: 0.001875  Loss: 0.9006  Acc@1: 62.5000 (65.0229)  Acc@5: 93.7500 (91.3766)  time: 0.3473  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 720/4579]  eta: 0:22:15  Lr: 0.001875  Loss: 1.4418  Acc@1: 62.5000 (64.9705)  Acc@5: 93.7500 (91.3662)  time: 0.3470  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [ 730/4579]  eta: 0:22:12  Lr: 0.001875  Loss: 1.2963  Acc@1: 62.5000 (65.0222)  Acc@5: 93.7500 (91.3304)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 740/4579]  eta: 0:22:08  Lr: 0.001875  Loss: 0.7048  Acc@1: 68.7500 (65.0894)  Acc@5: 93.7500 (91.3462)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 750/4579]  eta: 0:22:05  Lr: 0.001875  Loss: 1.1871  Acc@1: 68.7500 (65.1132)  Acc@5: 93.7500 (91.3698)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 760/4579]  eta: 0:22:01  Lr: 0.001875  Loss: 1.1438  Acc@1: 62.5000 (65.1117)  Acc@5: 93.7500 (91.4011)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 770/4579]  eta: 0:21:58  Lr: 0.001875  Loss: 0.8721  Acc@1: 68.7500 (65.1670)  Acc@5: 93.7500 (91.4154)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 780/4579]  eta: 0:21:54  Lr: 0.001875  Loss: 1.5091  Acc@1: 68.7500 (65.2529)  Acc@5: 93.7500 (91.4453)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 790/4579]  eta: 0:21:51  Lr: 0.001875  Loss: 1.0088  Acc@1: 62.5000 (65.1628)  Acc@5: 87.5000 (91.3954)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 800/4579]  eta: 0:21:47  Lr: 0.001875  Loss: 1.7120  Acc@1: 62.5000 (65.1919)  Acc@5: 93.7500 (91.4092)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 810/4579]  eta: 0:21:44  Lr: 0.001875  Loss: 1.3368  Acc@1: 62.5000 (65.1665)  Acc@5: 87.5000 (91.3610)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 820/4579]  eta: 0:21:40  Lr: 0.001875  Loss: 0.4341  Acc@1: 62.5000 (65.2177)  Acc@5: 87.5000 (91.3520)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 830/4579]  eta: 0:21:37  Lr: 0.001875  Loss: 0.8672  Acc@1: 62.5000 (65.2151)  Acc@5: 93.7500 (91.3733)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 840/4579]  eta: 0:21:33  Lr: 0.001875  Loss: 0.6485  Acc@1: 62.5000 (65.2274)  Acc@5: 87.5000 (91.3496)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 850/4579]  eta: 0:21:30  Lr: 0.001875  Loss: 0.7975  Acc@1: 68.7500 (65.2541)  Acc@5: 93.7500 (91.3778)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 860/4579]  eta: 0:21:26  Lr: 0.001875  Loss: 0.8830  Acc@1: 68.7500 (65.2512)  Acc@5: 93.7500 (91.4053)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 870/4579]  eta: 0:21:23  Lr: 0.001875  Loss: 0.8977  Acc@1: 62.5000 (65.1909)  Acc@5: 93.7500 (91.4107)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 880/4579]  eta: 0:21:19  Lr: 0.001875  Loss: 1.8053  Acc@1: 62.5000 (65.1320)  Acc@5: 87.5000 (91.3663)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 890/4579]  eta: 0:21:16  Lr: 0.001875  Loss: 0.6373  Acc@1: 62.5000 (65.1445)  Acc@5: 87.5000 (91.3300)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 900/4579]  eta: 0:21:12  Lr: 0.001875  Loss: 1.4645  Acc@1: 62.5000 (65.0527)  Acc@5: 87.5000 (91.3083)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 910/4579]  eta: 0:21:09  Lr: 0.001875  Loss: 1.0521  Acc@1: 62.5000 (65.1070)  Acc@5: 93.7500 (91.3557)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 920/4579]  eta: 0:21:05  Lr: 0.001875  Loss: 0.8758  Acc@1: 68.7500 (65.0991)  Acc@5: 93.7500 (91.3274)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 930/4579]  eta: 0:21:02  Lr: 0.001875  Loss: 0.7942  Acc@1: 68.7500 (65.2121)  Acc@5: 93.7500 (91.3869)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 940/4579]  eta: 0:20:58  Lr: 0.001875  Loss: 1.2253  Acc@1: 68.7500 (65.1501)  Acc@5: 93.7500 (91.3722)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 950/4579]  eta: 0:20:55  Lr: 0.001875  Loss: 1.7264  Acc@1: 62.5000 (65.1420)  Acc@5: 87.5000 (91.3512)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 960/4579]  eta: 0:20:51  Lr: 0.001875  Loss: 0.5262  Acc@1: 62.5000 (65.1990)  Acc@5: 93.7500 (91.3632)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 970/4579]  eta: 0:20:48  Lr: 0.001875  Loss: 0.6672  Acc@1: 62.5000 (65.1583)  Acc@5: 93.7500 (91.3491)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 980/4579]  eta: 0:20:44  Lr: 0.001875  Loss: 0.5648  Acc@1: 62.5000 (65.1631)  Acc@5: 93.7500 (91.3736)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 990/4579]  eta: 0:20:41  Lr: 0.001875  Loss: 1.3347  Acc@1: 62.5000 (65.1299)  Acc@5: 93.7500 (91.3534)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1000/4579]  eta: 0:20:37  Lr: 0.001875  Loss: 1.0812  Acc@1: 62.5000 (65.0849)  Acc@5: 87.5000 (91.3274)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1010/4579]  eta: 0:20:34  Lr: 0.001875  Loss: 1.3004  Acc@1: 62.5000 (65.1335)  Acc@5: 93.7500 (91.3267)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1020/4579]  eta: 0:20:30  Lr: 0.001875  Loss: 0.7587  Acc@1: 68.7500 (65.1322)  Acc@5: 93.7500 (91.3443)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1030/4579]  eta: 0:20:27  Lr: 0.001875  Loss: 1.3495  Acc@1: 62.5000 (65.1370)  Acc@5: 93.7500 (91.3312)  time: 0.3463  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1040/4579]  eta: 0:20:24  Lr: 0.001875  Loss: 1.5260  Acc@1: 62.5000 (65.0937)  Acc@5: 87.5000 (91.3004)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1050/4579]  eta: 0:20:20  Lr: 0.001875  Loss: 0.4249  Acc@1: 62.5000 (65.0987)  Acc@5: 87.5000 (91.2821)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1060/4579]  eta: 0:20:16  Lr: 0.001875  Loss: 1.3031  Acc@1: 68.7500 (65.1567)  Acc@5: 93.7500 (91.2995)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1070/4579]  eta: 0:20:13  Lr: 0.001875  Loss: 0.9931  Acc@1: 68.7500 (65.2253)  Acc@5: 93.7500 (91.3340)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1080/4579]  eta: 0:20:09  Lr: 0.001875  Loss: 1.0831  Acc@1: 75.0000 (65.2926)  Acc@5: 93.7500 (91.3679)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1090/4579]  eta: 0:20:06  Lr: 0.001875  Loss: 0.8240  Acc@1: 68.7500 (65.2784)  Acc@5: 87.5000 (91.3440)  time: 0.3447  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1100/4579]  eta: 0:20:03  Lr: 0.001875  Loss: 0.7778  Acc@1: 62.5000 (65.2929)  Acc@5: 87.5000 (91.3317)  time: 0.3450  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1110/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 1.1502  Acc@1: 68.7500 (65.3578)  Acc@5: 93.7500 (91.3591)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1120/4579]  eta: 0:19:56  Lr: 0.001875  Loss: 0.7568  Acc@1: 68.7500 (65.4048)  Acc@5: 93.7500 (91.3693)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1130/4579]  eta: 0:19:52  Lr: 0.001875  Loss: 1.2406  Acc@1: 62.5000 (65.3625)  Acc@5: 93.7500 (91.3738)  time: 0.3454  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1140/4579]  eta: 0:19:49  Lr: 0.001875  Loss: 0.8654  Acc@1: 62.5000 (65.4032)  Acc@5: 93.7500 (91.4001)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1150/4579]  eta: 0:19:45  Lr: 0.001875  Loss: 0.6533  Acc@1: 68.7500 (65.3888)  Acc@5: 93.7500 (91.4151)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1160/4579]  eta: 0:19:42  Lr: 0.001875  Loss: 0.9690  Acc@1: 62.5000 (65.3585)  Acc@5: 87.5000 (91.3706)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1170/4579]  eta: 0:19:38  Lr: 0.001875  Loss: 0.8287  Acc@1: 62.5000 (65.3341)  Acc@5: 87.5000 (91.3802)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1180/4579]  eta: 0:19:35  Lr: 0.001875  Loss: 0.8399  Acc@1: 68.7500 (65.3895)  Acc@5: 93.7500 (91.4003)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1190/4579]  eta: 0:19:31  Lr: 0.001875  Loss: 1.2433  Acc@1: 62.5000 (65.3338)  Acc@5: 93.7500 (91.4253)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1200/4579]  eta: 0:19:28  Lr: 0.001875  Loss: 1.0556  Acc@1: 62.5000 (65.3518)  Acc@5: 93.7500 (91.4238)  time: 0.3442  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1210/4579]  eta: 0:19:24  Lr: 0.001875  Loss: 1.8123  Acc@1: 68.7500 (65.3644)  Acc@5: 93.7500 (91.4327)  time: 0.3441  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1220/4579]  eta: 0:19:21  Lr: 0.001875  Loss: 1.0200  Acc@1: 68.7500 (65.3563)  Acc@5: 87.5000 (91.3851)  time: 0.3446  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1230/4579]  eta: 0:19:17  Lr: 0.001875  Loss: 1.1202  Acc@1: 62.5000 (65.3991)  Acc@5: 93.7500 (91.4196)  time: 0.3456  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1240/4579]  eta: 0:19:14  Lr: 0.001875  Loss: 0.6476  Acc@1: 68.7500 (65.4311)  Acc@5: 100.0000 (91.4535)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1250/4579]  eta: 0:19:10  Lr: 0.001875  Loss: 0.6230  Acc@1: 62.5000 (65.3727)  Acc@5: 93.7500 (91.4369)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1260/4579]  eta: 0:19:07  Lr: 0.001875  Loss: 0.8076  Acc@1: 62.5000 (65.3648)  Acc@5: 93.7500 (91.4502)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1270/4579]  eta: 0:19:03  Lr: 0.001875  Loss: 0.8828  Acc@1: 68.7500 (65.3865)  Acc@5: 93.7500 (91.4585)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1280/4579]  eta: 0:19:00  Lr: 0.001875  Loss: 0.7696  Acc@1: 62.5000 (65.3542)  Acc@5: 87.5000 (91.4325)  time: 0.3443  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1290/4579]  eta: 0:18:56  Lr: 0.001875  Loss: 1.2250  Acc@1: 68.7500 (65.3950)  Acc@5: 93.7500 (91.4504)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1300/4579]  eta: 0:18:53  Lr: 0.001875  Loss: 1.8589  Acc@1: 68.7500 (65.4304)  Acc@5: 93.7500 (91.4633)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1310/4579]  eta: 0:18:49  Lr: 0.001875  Loss: 0.8057  Acc@1: 68.7500 (65.4653)  Acc@5: 93.7500 (91.4712)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1320/4579]  eta: 0:18:46  Lr: 0.001875  Loss: 0.8999  Acc@1: 62.5000 (65.4192)  Acc@5: 93.7500 (91.4790)  time: 0.3448  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1330/4579]  eta: 0:18:42  Lr: 0.001875  Loss: 1.2807  Acc@1: 62.5000 (65.4020)  Acc@5: 93.7500 (91.4867)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1340/4579]  eta: 0:18:39  Lr: 0.001875  Loss: 1.1181  Acc@1: 62.5000 (65.4036)  Acc@5: 87.5000 (91.4709)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1350/4579]  eta: 0:18:36  Lr: 0.001875  Loss: 1.0126  Acc@1: 62.5000 (65.3914)  Acc@5: 87.5000 (91.4647)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1360/4579]  eta: 0:18:32  Lr: 0.001875  Loss: 0.3873  Acc@1: 62.5000 (65.4206)  Acc@5: 93.7500 (91.4952)  time: 0.3463  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1370/4579]  eta: 0:18:29  Lr: 0.001875  Loss: 1.0556  Acc@1: 62.5000 (65.4221)  Acc@5: 93.7500 (91.4843)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1380/4579]  eta: 0:18:25  Lr: 0.001875  Loss: 0.7738  Acc@1: 68.7500 (65.4689)  Acc@5: 93.7500 (91.5143)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1390/4579]  eta: 0:18:22  Lr: 0.001875  Loss: 0.7313  Acc@1: 62.5000 (65.4385)  Acc@5: 93.7500 (91.5214)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1400/4579]  eta: 0:18:18  Lr: 0.001875  Loss: 0.9661  Acc@1: 62.5000 (65.4622)  Acc@5: 93.7500 (91.5195)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1410/4579]  eta: 0:18:15  Lr: 0.001875  Loss: 1.0869  Acc@1: 68.7500 (65.4589)  Acc@5: 93.7500 (91.5441)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1420/4579]  eta: 0:18:11  Lr: 0.001875  Loss: 1.2640  Acc@1: 62.5000 (65.4513)  Acc@5: 93.7500 (91.5464)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1430/4579]  eta: 0:18:08  Lr: 0.001875  Loss: 1.0540  Acc@1: 62.5000 (65.4350)  Acc@5: 93.7500 (91.5313)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1440/4579]  eta: 0:18:05  Lr: 0.001875  Loss: 0.9010  Acc@1: 68.7500 (65.4754)  Acc@5: 93.7500 (91.5510)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1450/4579]  eta: 0:18:01  Lr: 0.001875  Loss: 0.6848  Acc@1: 68.7500 (65.4764)  Acc@5: 93.7500 (91.5575)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1460/4579]  eta: 0:17:58  Lr: 0.001875  Loss: 1.2196  Acc@1: 68.7500 (65.4774)  Acc@5: 93.7500 (91.5512)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1470/4579]  eta: 0:17:54  Lr: 0.001875  Loss: 0.9405  Acc@1: 62.5000 (65.4359)  Acc@5: 87.5000 (91.5364)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1480/4579]  eta: 0:17:51  Lr: 0.001875  Loss: 0.6242  Acc@1: 68.7500 (65.4963)  Acc@5: 93.7500 (91.5471)  time: 0.3458  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1490/4579]  eta: 0:17:47  Lr: 0.001875  Loss: 1.1532  Acc@1: 68.7500 (65.4846)  Acc@5: 93.7500 (91.5367)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1500/4579]  eta: 0:17:44  Lr: 0.001875  Loss: 1.0644  Acc@1: 62.5000 (65.5022)  Acc@5: 93.7500 (91.5348)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1510/4579]  eta: 0:17:40  Lr: 0.001875  Loss: 0.7583  Acc@1: 68.7500 (65.4947)  Acc@5: 93.7500 (91.5288)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1520/4579]  eta: 0:17:37  Lr: 0.001875  Loss: 1.3684  Acc@1: 68.7500 (65.5079)  Acc@5: 93.7500 (91.5311)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1530/4579]  eta: 0:17:33  Lr: 0.001875  Loss: 1.1426  Acc@1: 68.7500 (65.5005)  Acc@5: 93.7500 (91.5292)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1540/4579]  eta: 0:17:30  Lr: 0.001875  Loss: 0.7313  Acc@1: 68.7500 (65.5216)  Acc@5: 93.7500 (91.5355)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1550/4579]  eta: 0:17:27  Lr: 0.001875  Loss: 0.9203  Acc@1: 68.7500 (65.5343)  Acc@5: 93.7500 (91.5538)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1560/4579]  eta: 0:17:23  Lr: 0.001875  Loss: 1.1743  Acc@1: 62.5000 (65.4949)  Acc@5: 87.5000 (91.5279)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1570/4579]  eta: 0:17:20  Lr: 0.001875  Loss: 1.2134  Acc@1: 56.2500 (65.4599)  Acc@5: 87.5000 (91.5301)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1580/4579]  eta: 0:17:16  Lr: 0.001875  Loss: 1.2564  Acc@1: 62.5000 (65.4451)  Acc@5: 87.5000 (91.5244)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1590/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 1.5232  Acc@1: 56.2500 (65.3677)  Acc@5: 87.5000 (91.5069)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1600/4579]  eta: 0:17:09  Lr: 0.001875  Loss: 1.7392  Acc@1: 56.2500 (65.3303)  Acc@5: 87.5000 (91.4780)  time: 0.3446  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1610/4579]  eta: 0:17:06  Lr: 0.001875  Loss: 0.9662  Acc@1: 62.5000 (65.3166)  Acc@5: 93.7500 (91.4960)  time: 0.3462  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1620/4579]  eta: 0:17:02  Lr: 0.001875  Loss: 1.0588  Acc@1: 62.5000 (65.3300)  Acc@5: 93.7500 (91.4983)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1630/4579]  eta: 0:16:59  Lr: 0.001875  Loss: 1.5252  Acc@1: 62.5000 (65.3089)  Acc@5: 93.7500 (91.4929)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1640/4579]  eta: 0:16:55  Lr: 0.001875  Loss: 0.6161  Acc@1: 62.5000 (65.3222)  Acc@5: 93.7500 (91.4991)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1650/4579]  eta: 0:16:52  Lr: 0.001875  Loss: 0.4513  Acc@1: 68.7500 (65.3581)  Acc@5: 93.7500 (91.5241)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1660/4579]  eta: 0:16:48  Lr: 0.001875  Loss: 1.4051  Acc@1: 68.7500 (65.3484)  Acc@5: 93.7500 (91.5187)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1670/4579]  eta: 0:16:45  Lr: 0.001875  Loss: 1.0735  Acc@1: 68.7500 (65.3576)  Acc@5: 87.5000 (91.5058)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1680/4579]  eta: 0:16:42  Lr: 0.001875  Loss: 0.8606  Acc@1: 62.5000 (65.3369)  Acc@5: 93.7500 (91.5341)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1690/4579]  eta: 0:16:38  Lr: 0.001875  Loss: 1.2079  Acc@1: 62.5000 (65.3201)  Acc@5: 93.7500 (91.5435)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1700/4579]  eta: 0:16:35  Lr: 0.001875  Loss: 1.0324  Acc@1: 62.5000 (65.3035)  Acc@5: 93.7500 (91.5454)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1710/4579]  eta: 0:16:31  Lr: 0.001875  Loss: 0.8646  Acc@1: 62.5000 (65.3200)  Acc@5: 93.7500 (91.5546)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1720/4579]  eta: 0:16:28  Lr: 0.001875  Loss: 1.1266  Acc@1: 68.7500 (65.3218)  Acc@5: 93.7500 (91.5710)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1730/4579]  eta: 0:16:24  Lr: 0.001875  Loss: 1.5346  Acc@1: 56.2500 (65.2766)  Acc@5: 87.5000 (91.5439)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1740/4579]  eta: 0:16:21  Lr: 0.001875  Loss: 1.1868  Acc@1: 56.2500 (65.2786)  Acc@5: 87.5000 (91.5530)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1750/4579]  eta: 0:16:17  Lr: 0.001875  Loss: 0.7573  Acc@1: 62.5000 (65.2698)  Acc@5: 93.7500 (91.5513)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1760/4579]  eta: 0:16:14  Lr: 0.001875  Loss: 1.2966  Acc@1: 62.5000 (65.2541)  Acc@5: 93.7500 (91.5531)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1770/4579]  eta: 0:16:10  Lr: 0.001875  Loss: 0.9685  Acc@1: 62.5000 (65.2527)  Acc@5: 93.7500 (91.5549)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1780/4579]  eta: 0:16:07  Lr: 0.001875  Loss: 0.8104  Acc@1: 68.7500 (65.3039)  Acc@5: 93.7500 (91.5813)  time: 0.3455  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1790/4579]  eta: 0:16:03  Lr: 0.001875  Loss: 0.8540  Acc@1: 68.7500 (65.3057)  Acc@5: 93.7500 (91.5829)  time: 0.3456  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1800/4579]  eta: 0:16:00  Lr: 0.001875  Loss: 1.3029  Acc@1: 62.5000 (65.3179)  Acc@5: 93.7500 (91.5984)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1810/4579]  eta: 0:15:57  Lr: 0.001875  Loss: 1.0614  Acc@1: 62.5000 (65.2782)  Acc@5: 87.5000 (91.5896)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1820/4579]  eta: 0:15:53  Lr: 0.001875  Loss: 1.0948  Acc@1: 62.5000 (65.2972)  Acc@5: 87.5000 (91.5980)  time: 0.3455  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1830/4579]  eta: 0:15:50  Lr: 0.001875  Loss: 1.1741  Acc@1: 68.7500 (65.3024)  Acc@5: 93.7500 (91.6029)  time: 0.3454  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1840/4579]  eta: 0:15:46  Lr: 0.001875  Loss: 0.9118  Acc@1: 62.5000 (65.3178)  Acc@5: 93.7500 (91.6112)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1850/4579]  eta: 0:15:43  Lr: 0.001875  Loss: 1.2248  Acc@1: 62.5000 (65.2823)  Acc@5: 93.7500 (91.6126)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1860/4579]  eta: 0:15:39  Lr: 0.001875  Loss: 0.8945  Acc@1: 62.5000 (65.3009)  Acc@5: 93.7500 (91.6073)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1870/4579]  eta: 0:15:36  Lr: 0.001875  Loss: 0.9499  Acc@1: 68.7500 (65.3494)  Acc@5: 93.7500 (91.6288)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1880/4579]  eta: 0:15:32  Lr: 0.001875  Loss: 0.5957  Acc@1: 68.7500 (65.3542)  Acc@5: 93.7500 (91.6368)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1890/4579]  eta: 0:15:29  Lr: 0.001875  Loss: 1.1301  Acc@1: 62.5000 (65.3391)  Acc@5: 93.7500 (91.6413)  time: 0.3458  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1900/4579]  eta: 0:15:25  Lr: 0.001875  Loss: 0.9338  Acc@1: 68.7500 (65.3735)  Acc@5: 93.7500 (91.6557)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1910/4579]  eta: 0:15:22  Lr: 0.001875  Loss: 0.8136  Acc@1: 68.7500 (65.3748)  Acc@5: 93.7500 (91.6536)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1920/4579]  eta: 0:15:18  Lr: 0.001875  Loss: 1.5233  Acc@1: 68.7500 (65.3663)  Acc@5: 87.5000 (91.6450)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1930/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 0.6106  Acc@1: 68.7500 (65.3871)  Acc@5: 93.7500 (91.6656)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1940/4579]  eta: 0:15:12  Lr: 0.001875  Loss: 1.0360  Acc@1: 62.5000 (65.3819)  Acc@5: 93.7500 (91.6731)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1950/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 1.0372  Acc@1: 62.5000 (65.3543)  Acc@5: 93.7500 (91.6773)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1960/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 1.2517  Acc@1: 62.5000 (65.3876)  Acc@5: 93.7500 (91.6784)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1970/4579]  eta: 0:15:01  Lr: 0.001875  Loss: 0.7330  Acc@1: 68.7500 (65.3856)  Acc@5: 93.7500 (91.6825)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/4579]  eta: 0:14:58  Lr: 0.001875  Loss: 0.9301  Acc@1: 68.7500 (65.3963)  Acc@5: 87.5000 (91.6740)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1990/4579]  eta: 0:14:54  Lr: 0.001875  Loss: 0.6230  Acc@1: 68.7500 (65.4068)  Acc@5: 93.7500 (91.6813)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2000/4579]  eta: 0:14:51  Lr: 0.001875  Loss: 1.0213  Acc@1: 68.7500 (65.4110)  Acc@5: 93.7500 (91.6792)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2010/4579]  eta: 0:14:47  Lr: 0.001875  Loss: 1.2956  Acc@1: 68.7500 (65.4525)  Acc@5: 93.7500 (91.6770)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2020/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 0.6311  Acc@1: 75.0000 (65.4719)  Acc@5: 93.7500 (91.6842)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2030/4579]  eta: 0:14:40  Lr: 0.001875  Loss: 1.0572  Acc@1: 68.7500 (65.4696)  Acc@5: 93.7500 (91.7036)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2040/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 1.2842  Acc@1: 62.5000 (65.4918)  Acc@5: 93.7500 (91.7167)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2050/4579]  eta: 0:14:34  Lr: 0.001875  Loss: 0.7293  Acc@1: 62.5000 (65.4742)  Acc@5: 93.7500 (91.7175)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2060/4579]  eta: 0:14:30  Lr: 0.001875  Loss: 0.7995  Acc@1: 62.5000 (65.5022)  Acc@5: 93.7500 (91.7213)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2070/4579]  eta: 0:14:27  Lr: 0.001875  Loss: 0.6443  Acc@1: 68.7500 (65.4877)  Acc@5: 93.7500 (91.7069)  time: 0.3489  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2080/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 0.9158  Acc@1: 62.5000 (65.5034)  Acc@5: 93.7500 (91.7167)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2090/4579]  eta: 0:14:20  Lr: 0.001875  Loss: 0.4927  Acc@1: 62.5000 (65.5159)  Acc@5: 93.7500 (91.7175)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2100/4579]  eta: 0:14:16  Lr: 0.001875  Loss: 1.0554  Acc@1: 68.7500 (65.5164)  Acc@5: 93.7500 (91.7420)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2110/4579]  eta: 0:14:13  Lr: 0.001875  Loss: 2.2125  Acc@1: 56.2500 (65.4992)  Acc@5: 93.7500 (91.7279)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2120/4579]  eta: 0:14:09  Lr: 0.001875  Loss: 0.8887  Acc@1: 56.2500 (65.4939)  Acc@5: 93.7500 (91.7433)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2130/4579]  eta: 0:14:06  Lr: 0.001875  Loss: 1.6356  Acc@1: 62.5000 (65.4710)  Acc@5: 93.7500 (91.7468)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2140/4579]  eta: 0:14:03  Lr: 0.001875  Loss: 0.8349  Acc@1: 62.5000 (65.4659)  Acc@5: 87.5000 (91.7182)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2150/4579]  eta: 0:13:59  Lr: 0.001875  Loss: 1.2595  Acc@1: 62.5000 (65.4637)  Acc@5: 87.5000 (91.7219)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2160/4579]  eta: 0:13:56  Lr: 0.001875  Loss: 0.7649  Acc@1: 62.5000 (65.4529)  Acc@5: 93.7500 (91.7284)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2170/4579]  eta: 0:13:52  Lr: 0.001875  Loss: 1.3272  Acc@1: 62.5000 (65.4566)  Acc@5: 93.7500 (91.7377)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2180/4579]  eta: 0:13:49  Lr: 0.001875  Loss: 1.1403  Acc@1: 62.5000 (65.4402)  Acc@5: 93.7500 (91.7326)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2190/4579]  eta: 0:13:45  Lr: 0.001875  Loss: 1.4646  Acc@1: 62.5000 (65.4325)  Acc@5: 93.7500 (91.7389)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2200/4579]  eta: 0:13:42  Lr: 0.001875  Loss: 1.3644  Acc@1: 68.7500 (65.4248)  Acc@5: 93.7500 (91.7339)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2210/4579]  eta: 0:13:38  Lr: 0.001875  Loss: 1.0380  Acc@1: 62.5000 (65.4059)  Acc@5: 87.5000 (91.7345)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2220/4579]  eta: 0:13:35  Lr: 0.001875  Loss: 1.0521  Acc@1: 62.5000 (65.4013)  Acc@5: 93.7500 (91.7295)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2230/4579]  eta: 0:13:31  Lr: 0.001875  Loss: 0.8172  Acc@1: 68.7500 (65.4219)  Acc@5: 87.5000 (91.7050)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2240/4579]  eta: 0:13:28  Lr: 0.001875  Loss: 0.7704  Acc@1: 62.5000 (65.4061)  Acc@5: 87.5000 (91.7001)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2250/4579]  eta: 0:13:24  Lr: 0.001875  Loss: 1.9248  Acc@1: 62.5000 (65.3737)  Acc@5: 93.7500 (91.6898)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2260/4579]  eta: 0:13:21  Lr: 0.001875  Loss: 0.7666  Acc@1: 62.5000 (65.3859)  Acc@5: 93.7500 (91.6934)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2270/4579]  eta: 0:13:18  Lr: 0.001875  Loss: 0.9270  Acc@1: 68.7500 (65.3897)  Acc@5: 93.7500 (91.6914)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2280/4579]  eta: 0:13:14  Lr: 0.001875  Loss: 1.1362  Acc@1: 68.7500 (65.4099)  Acc@5: 93.7500 (91.6977)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2290/4579]  eta: 0:13:11  Lr: 0.001875  Loss: 1.3966  Acc@1: 62.5000 (65.3808)  Acc@5: 93.7500 (91.6930)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2300/4579]  eta: 0:13:07  Lr: 0.001875  Loss: 1.4159  Acc@1: 62.5000 (65.3873)  Acc@5: 87.5000 (91.6911)  time: 0.3462  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2310/4579]  eta: 0:13:04  Lr: 0.001875  Loss: 0.5063  Acc@1: 75.0000 (65.4154)  Acc@5: 93.7500 (91.6892)  time: 0.3480  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [2320/4579]  eta: 0:13:00  Lr: 0.001875  Loss: 0.5090  Acc@1: 68.7500 (65.4217)  Acc@5: 93.7500 (91.6900)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2330/4579]  eta: 0:12:57  Lr: 0.001875  Loss: 0.9261  Acc@1: 62.5000 (65.4306)  Acc@5: 93.7500 (91.6881)  time: 0.3445  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2340/4579]  eta: 0:12:53  Lr: 0.001875  Loss: 1.3210  Acc@1: 62.5000 (65.4421)  Acc@5: 93.7500 (91.6969)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2350/4579]  eta: 0:12:50  Lr: 0.001875  Loss: 0.8293  Acc@1: 62.5000 (65.4323)  Acc@5: 93.7500 (91.6844)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2360/4579]  eta: 0:12:46  Lr: 0.001875  Loss: 0.7132  Acc@1: 62.5000 (65.4357)  Acc@5: 93.7500 (91.6905)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2370/4579]  eta: 0:12:43  Lr: 0.001875  Loss: 0.9175  Acc@1: 68.7500 (65.4602)  Acc@5: 93.7500 (91.6886)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2380/4579]  eta: 0:12:40  Lr: 0.001875  Loss: 0.6116  Acc@1: 68.7500 (65.4583)  Acc@5: 93.7500 (91.6868)  time: 0.3448  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2390/4579]  eta: 0:12:36  Lr: 0.001875  Loss: 0.8787  Acc@1: 62.5000 (65.4538)  Acc@5: 93.7500 (91.6850)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2400/4579]  eta: 0:12:33  Lr: 0.001875  Loss: 0.6771  Acc@1: 68.7500 (65.4675)  Acc@5: 93.7500 (91.6884)  time: 0.3454  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2410/4579]  eta: 0:12:29  Lr: 0.001875  Loss: 0.6785  Acc@1: 68.7500 (65.4837)  Acc@5: 93.7500 (91.6917)  time: 0.3463  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2420/4579]  eta: 0:12:26  Lr: 0.001875  Loss: 0.4313  Acc@1: 62.5000 (65.4817)  Acc@5: 93.7500 (91.7002)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2430/4579]  eta: 0:12:22  Lr: 0.001875  Loss: 0.8958  Acc@1: 62.5000 (65.4900)  Acc@5: 93.7500 (91.7087)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2440/4579]  eta: 0:12:19  Lr: 0.001875  Loss: 0.6509  Acc@1: 68.7500 (65.5136)  Acc@5: 93.7500 (91.7119)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2450/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 1.1388  Acc@1: 62.5000 (65.5013)  Acc@5: 93.7500 (91.7049)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2460/4579]  eta: 0:12:12  Lr: 0.001875  Loss: 0.8114  Acc@1: 62.5000 (65.5247)  Acc@5: 93.7500 (91.7107)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2470/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 1.2209  Acc@1: 68.7500 (65.5301)  Acc@5: 93.7500 (91.7114)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2480/4579]  eta: 0:12:05  Lr: 0.001875  Loss: 0.3862  Acc@1: 62.5000 (65.5381)  Acc@5: 93.7500 (91.7145)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2490/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 1.1711  Acc@1: 62.5000 (65.5460)  Acc@5: 93.7500 (91.7252)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2500/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 0.8455  Acc@1: 68.7500 (65.5588)  Acc@5: 93.7500 (91.7308)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2510/4579]  eta: 0:11:55  Lr: 0.001875  Loss: 1.5891  Acc@1: 62.5000 (65.5516)  Acc@5: 93.7500 (91.7314)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2520/4579]  eta: 0:11:51  Lr: 0.001875  Loss: 1.0977  Acc@1: 62.5000 (65.5618)  Acc@5: 93.7500 (91.7369)  time: 0.3483  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [2530/4579]  eta: 0:11:48  Lr: 0.001875  Loss: 1.2267  Acc@1: 62.5000 (65.5349)  Acc@5: 93.7500 (91.7350)  time: 0.3492  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [2540/4579]  eta: 0:11:44  Lr: 0.001875  Loss: 1.1950  Acc@1: 62.5000 (65.5377)  Acc@5: 93.7500 (91.7282)  time: 0.3469  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2550/4579]  eta: 0:11:41  Lr: 0.001875  Loss: 1.1876  Acc@1: 68.7500 (65.5356)  Acc@5: 93.7500 (91.7336)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2560/4579]  eta: 0:11:37  Lr: 0.001875  Loss: 0.8762  Acc@1: 62.5000 (65.5384)  Acc@5: 93.7500 (91.7391)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2570/4579]  eta: 0:11:34  Lr: 0.001875  Loss: 0.7696  Acc@1: 62.5000 (65.5290)  Acc@5: 93.7500 (91.7347)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2580/4579]  eta: 0:11:30  Lr: 0.001875  Loss: 0.6983  Acc@1: 62.5000 (65.5342)  Acc@5: 93.7500 (91.7474)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2590/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 0.7760  Acc@1: 62.5000 (65.5225)  Acc@5: 93.7500 (91.7382)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2600/4579]  eta: 0:11:24  Lr: 0.001875  Loss: 1.1255  Acc@1: 62.5000 (65.5085)  Acc@5: 93.7500 (91.7412)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2610/4579]  eta: 0:11:20  Lr: 0.001875  Loss: 1.1680  Acc@1: 62.5000 (65.5017)  Acc@5: 93.7500 (91.7512)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2620/4579]  eta: 0:11:17  Lr: 0.001875  Loss: 0.7525  Acc@1: 62.5000 (65.4855)  Acc@5: 93.7500 (91.7374)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2630/4579]  eta: 0:11:13  Lr: 0.001875  Loss: 0.7623  Acc@1: 68.7500 (65.5122)  Acc@5: 93.7500 (91.7474)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2640/4579]  eta: 0:11:10  Lr: 0.001875  Loss: 1.3530  Acc@1: 75.0000 (65.5386)  Acc@5: 93.7500 (91.7527)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2650/4579]  eta: 0:11:06  Lr: 0.001875  Loss: 1.0721  Acc@1: 75.0000 (65.5625)  Acc@5: 93.7500 (91.7555)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2660/4579]  eta: 0:11:03  Lr: 0.001875  Loss: 1.1846  Acc@1: 62.5000 (65.5440)  Acc@5: 93.7500 (91.7559)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2670/4579]  eta: 0:10:59  Lr: 0.001875  Loss: 0.5269  Acc@1: 62.5000 (65.5583)  Acc@5: 93.7500 (91.7704)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2680/4579]  eta: 0:10:56  Lr: 0.001875  Loss: 0.9457  Acc@1: 62.5000 (65.5376)  Acc@5: 93.7500 (91.7685)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2690/4579]  eta: 0:10:52  Lr: 0.001875  Loss: 1.7264  Acc@1: 68.7500 (65.5402)  Acc@5: 93.7500 (91.7665)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2700/4579]  eta: 0:10:49  Lr: 0.001875  Loss: 0.7306  Acc@1: 68.7500 (65.5382)  Acc@5: 93.7500 (91.7669)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2710/4579]  eta: 0:10:46  Lr: 0.001875  Loss: 1.0624  Acc@1: 68.7500 (65.5478)  Acc@5: 93.7500 (91.7719)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2720/4579]  eta: 0:10:42  Lr: 0.001875  Loss: 1.1548  Acc@1: 68.7500 (65.5802)  Acc@5: 93.7500 (91.7838)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2730/4579]  eta: 0:10:39  Lr: 0.001875  Loss: 1.1664  Acc@1: 68.7500 (65.5598)  Acc@5: 93.7500 (91.7727)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2740/4579]  eta: 0:10:35  Lr: 0.001875  Loss: 0.9115  Acc@1: 62.5000 (65.5669)  Acc@5: 93.7500 (91.7776)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2750/4579]  eta: 0:10:32  Lr: 0.001875  Loss: 1.1488  Acc@1: 68.7500 (65.5921)  Acc@5: 87.5000 (91.7666)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2760/4579]  eta: 0:10:28  Lr: 0.001875  Loss: 0.8237  Acc@1: 62.5000 (65.5763)  Acc@5: 87.5000 (91.7602)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2770/4579]  eta: 0:10:25  Lr: 0.001875  Loss: 0.4923  Acc@1: 62.5000 (65.5765)  Acc@5: 93.7500 (91.7652)  time: 0.3462  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2780/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 0.9776  Acc@1: 62.5000 (65.5632)  Acc@5: 93.7500 (91.7633)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2790/4579]  eta: 0:10:18  Lr: 0.001875  Loss: 1.3313  Acc@1: 62.5000 (65.5746)  Acc@5: 93.7500 (91.7727)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2800/4579]  eta: 0:10:14  Lr: 0.001875  Loss: 1.0732  Acc@1: 68.7500 (65.5793)  Acc@5: 93.7500 (91.7686)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2810/4579]  eta: 0:10:11  Lr: 0.001875  Loss: 1.7508  Acc@1: 62.5000 (65.5572)  Acc@5: 93.7500 (91.7667)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2820/4579]  eta: 0:10:08  Lr: 0.001875  Loss: 1.4254  Acc@1: 62.5000 (65.5796)  Acc@5: 93.7500 (91.7760)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2830/4579]  eta: 0:10:04  Lr: 0.001875  Loss: 1.3127  Acc@1: 68.7500 (65.5797)  Acc@5: 93.7500 (91.7741)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2840/4579]  eta: 0:10:01  Lr: 0.001875  Loss: 0.6691  Acc@1: 62.5000 (65.5821)  Acc@5: 93.7500 (91.7811)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2850/4579]  eta: 0:09:57  Lr: 0.001875  Loss: 0.7585  Acc@1: 62.5000 (65.5801)  Acc@5: 93.7500 (91.7792)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2860/4579]  eta: 0:09:54  Lr: 0.001875  Loss: 0.8878  Acc@1: 62.5000 (65.5846)  Acc@5: 93.7500 (91.7730)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2870/4579]  eta: 0:09:50  Lr: 0.001875  Loss: 1.4476  Acc@1: 62.5000 (65.5804)  Acc@5: 93.7500 (91.7712)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2880/4579]  eta: 0:09:47  Lr: 0.001875  Loss: 1.3524  Acc@1: 62.5000 (65.5762)  Acc@5: 93.7500 (91.7672)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2890/4579]  eta: 0:09:43  Lr: 0.001875  Loss: 0.8942  Acc@1: 62.5000 (65.5915)  Acc@5: 93.7500 (91.7719)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2900/4579]  eta: 0:09:40  Lr: 0.001875  Loss: 0.6012  Acc@1: 75.0000 (65.6239)  Acc@5: 93.7500 (91.7873)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2910/4579]  eta: 0:09:36  Lr: 0.001875  Loss: 0.7003  Acc@1: 75.0000 (65.6347)  Acc@5: 93.7500 (91.7876)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2920/4579]  eta: 0:09:33  Lr: 0.001875  Loss: 0.7238  Acc@1: 62.5000 (65.6303)  Acc@5: 93.7500 (91.7879)  time: 0.3449  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2930/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 0.6822  Acc@1: 56.2500 (65.6047)  Acc@5: 93.7500 (91.7839)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2940/4579]  eta: 0:09:26  Lr: 0.001875  Loss: 1.2988  Acc@1: 56.2500 (65.5942)  Acc@5: 93.7500 (91.7821)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2950/4579]  eta: 0:09:23  Lr: 0.001875  Loss: 1.3033  Acc@1: 62.5000 (65.5901)  Acc@5: 93.7500 (91.7803)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2960/4579]  eta: 0:09:19  Lr: 0.001875  Loss: 1.8212  Acc@1: 62.5000 (65.5733)  Acc@5: 87.5000 (91.7701)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2970/4579]  eta: 0:09:16  Lr: 0.001875  Loss: 1.0723  Acc@1: 62.5000 (65.5756)  Acc@5: 87.5000 (91.7704)  time: 0.3443  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2980/4579]  eta: 0:09:12  Lr: 0.001875  Loss: 1.6090  Acc@1: 68.7500 (65.5904)  Acc@5: 93.7500 (91.7750)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2990/4579]  eta: 0:09:09  Lr: 0.001875  Loss: 1.3772  Acc@1: 62.5000 (65.5634)  Acc@5: 93.7500 (91.7711)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3000/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 1.0647  Acc@1: 56.2500 (65.5531)  Acc@5: 87.5000 (91.7548)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3010/4579]  eta: 0:09:02  Lr: 0.001875  Loss: 0.8283  Acc@1: 68.7500 (65.5741)  Acc@5: 87.5000 (91.7552)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3020/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.8833  Acc@1: 68.7500 (65.5867)  Acc@5: 93.7500 (91.7598)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3030/4579]  eta: 0:08:55  Lr: 0.001875  Loss: 1.1404  Acc@1: 68.7500 (65.5786)  Acc@5: 93.7500 (91.7581)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3040/4579]  eta: 0:08:51  Lr: 0.001875  Loss: 1.2510  Acc@1: 62.5000 (65.5644)  Acc@5: 93.7500 (91.7585)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3050/4579]  eta: 0:08:48  Lr: 0.001875  Loss: 1.2230  Acc@1: 62.5000 (65.5523)  Acc@5: 93.7500 (91.7507)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3060/4579]  eta: 0:08:45  Lr: 0.001875  Loss: 1.0093  Acc@1: 62.5000 (65.5546)  Acc@5: 93.7500 (91.7633)  time: 0.3455  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3070/4579]  eta: 0:08:41  Lr: 0.001875  Loss: 0.9628  Acc@1: 62.5000 (65.5528)  Acc@5: 93.7500 (91.7535)  time: 0.3459  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3080/4579]  eta: 0:08:38  Lr: 0.001875  Loss: 1.5876  Acc@1: 62.5000 (65.5591)  Acc@5: 87.5000 (91.7438)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3090/4579]  eta: 0:08:34  Lr: 0.001875  Loss: 0.9697  Acc@1: 68.7500 (65.5512)  Acc@5: 87.5000 (91.7341)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3100/4579]  eta: 0:08:31  Lr: 0.001875  Loss: 1.0440  Acc@1: 62.5000 (65.5353)  Acc@5: 93.7500 (91.7345)  time: 0.3443  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3110/4579]  eta: 0:08:27  Lr: 0.001875  Loss: 1.3328  Acc@1: 62.5000 (65.5316)  Acc@5: 93.7500 (91.7410)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3120/4579]  eta: 0:08:24  Lr: 0.001875  Loss: 1.3345  Acc@1: 62.5000 (65.5259)  Acc@5: 93.7500 (91.7414)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3130/4579]  eta: 0:08:20  Lr: 0.001875  Loss: 1.2924  Acc@1: 62.5000 (65.5142)  Acc@5: 93.7500 (91.7439)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3140/4579]  eta: 0:08:17  Lr: 0.001875  Loss: 0.9497  Acc@1: 62.5000 (65.5166)  Acc@5: 93.7500 (91.7463)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3150/4579]  eta: 0:08:13  Lr: 0.001875  Loss: 0.8767  Acc@1: 62.5000 (65.5169)  Acc@5: 93.7500 (91.7387)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3160/4579]  eta: 0:08:10  Lr: 0.001875  Loss: 0.9551  Acc@1: 62.5000 (65.5172)  Acc@5: 87.5000 (91.7352)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3170/4579]  eta: 0:08:06  Lr: 0.001875  Loss: 1.2089  Acc@1: 62.5000 (65.5018)  Acc@5: 93.7500 (91.7416)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3180/4579]  eta: 0:08:03  Lr: 0.001875  Loss: 1.1473  Acc@1: 62.5000 (65.5101)  Acc@5: 93.7500 (91.7557)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3190/4579]  eta: 0:08:00  Lr: 0.001875  Loss: 0.9932  Acc@1: 62.5000 (65.4889)  Acc@5: 93.7500 (91.7639)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3200/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 1.3061  Acc@1: 62.5000 (65.4873)  Acc@5: 93.7500 (91.7682)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3210/4579]  eta: 0:07:53  Lr: 0.001875  Loss: 0.7181  Acc@1: 62.5000 (65.4956)  Acc@5: 93.7500 (91.7802)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3220/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.7441  Acc@1: 68.7500 (65.4940)  Acc@5: 93.7500 (91.7766)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3230/4579]  eta: 0:07:46  Lr: 0.001875  Loss: 1.6171  Acc@1: 56.2500 (65.4809)  Acc@5: 87.5000 (91.7653)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3240/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 1.1483  Acc@1: 62.5000 (65.4794)  Acc@5: 87.5000 (91.7637)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3250/4579]  eta: 0:07:39  Lr: 0.001875  Loss: 1.0455  Acc@1: 62.5000 (65.4760)  Acc@5: 93.7500 (91.7622)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3260/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 1.0713  Acc@1: 68.7500 (65.4745)  Acc@5: 87.5000 (91.7472)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3270/4579]  eta: 0:07:32  Lr: 0.001875  Loss: 0.8711  Acc@1: 68.7500 (65.5037)  Acc@5: 87.5000 (91.7514)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3280/4579]  eta: 0:07:28  Lr: 0.001875  Loss: 0.8991  Acc@1: 68.7500 (65.5098)  Acc@5: 93.7500 (91.7556)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3290/4579]  eta: 0:07:25  Lr: 0.001875  Loss: 0.9103  Acc@1: 68.7500 (65.5272)  Acc@5: 93.7500 (91.7635)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3300/4579]  eta: 0:07:21  Lr: 0.001875  Loss: 0.8218  Acc@1: 75.0000 (65.5464)  Acc@5: 93.7500 (91.7695)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3310/4579]  eta: 0:07:18  Lr: 0.001875  Loss: 1.1089  Acc@1: 75.0000 (65.5542)  Acc@5: 93.7500 (91.7642)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3320/4579]  eta: 0:07:15  Lr: 0.001875  Loss: 0.7940  Acc@1: 62.5000 (65.5450)  Acc@5: 87.5000 (91.7702)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3330/4579]  eta: 0:07:11  Lr: 0.001875  Loss: 1.2099  Acc@1: 56.2500 (65.5434)  Acc@5: 93.7500 (91.7686)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/4579]  eta: 0:07:08  Lr: 0.001875  Loss: 0.8395  Acc@1: 62.5000 (65.5343)  Acc@5: 93.7500 (91.7764)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3350/4579]  eta: 0:07:04  Lr: 0.001875  Loss: 0.6265  Acc@1: 68.7500 (65.5644)  Acc@5: 93.7500 (91.7842)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3360/4579]  eta: 0:07:01  Lr: 0.001875  Loss: 0.8908  Acc@1: 68.7500 (65.5701)  Acc@5: 93.7500 (91.7807)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3370/4579]  eta: 0:06:57  Lr: 0.001875  Loss: 1.1251  Acc@1: 62.5000 (65.5536)  Acc@5: 87.5000 (91.7754)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3380/4579]  eta: 0:06:54  Lr: 0.001875  Loss: 1.1767  Acc@1: 62.5000 (65.5483)  Acc@5: 87.5000 (91.7720)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3390/4579]  eta: 0:06:50  Lr: 0.001875  Loss: 0.7650  Acc@1: 62.5000 (65.5411)  Acc@5: 93.7500 (91.7705)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3400/4579]  eta: 0:06:47  Lr: 0.001875  Loss: 0.9546  Acc@1: 62.5000 (65.5432)  Acc@5: 93.7500 (91.7726)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3410/4579]  eta: 0:06:43  Lr: 0.001875  Loss: 1.1671  Acc@1: 68.7500 (65.5545)  Acc@5: 93.7500 (91.7803)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3420/4579]  eta: 0:06:40  Lr: 0.001875  Loss: 1.5601  Acc@1: 62.5000 (65.5382)  Acc@5: 93.7500 (91.7824)  time: 0.3456  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3430/4579]  eta: 0:06:37  Lr: 0.001875  Loss: 1.4577  Acc@1: 62.5000 (65.5385)  Acc@5: 93.7500 (91.7863)  time: 0.3460  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3440/4579]  eta: 0:06:33  Lr: 0.001875  Loss: 0.8604  Acc@1: 62.5000 (65.5333)  Acc@5: 87.5000 (91.7756)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3450/4579]  eta: 0:06:30  Lr: 0.001875  Loss: 1.1910  Acc@1: 68.7500 (65.5535)  Acc@5: 87.5000 (91.7796)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3460/4579]  eta: 0:06:26  Lr: 0.001875  Loss: 0.8360  Acc@1: 68.7500 (65.5392)  Acc@5: 93.7500 (91.7798)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3470/4579]  eta: 0:06:23  Lr: 0.001875  Loss: 1.5303  Acc@1: 56.2500 (65.5251)  Acc@5: 93.7500 (91.7819)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3480/4579]  eta: 0:06:19  Lr: 0.001875  Loss: 1.1307  Acc@1: 62.5000 (65.5289)  Acc@5: 93.7500 (91.7894)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3490/4579]  eta: 0:06:16  Lr: 0.001875  Loss: 0.9866  Acc@1: 68.7500 (65.5382)  Acc@5: 93.7500 (91.7968)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3500/4579]  eta: 0:06:12  Lr: 0.001875  Loss: 1.4930  Acc@1: 62.5000 (65.5331)  Acc@5: 93.7500 (91.7934)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3510/4579]  eta: 0:06:09  Lr: 0.001875  Loss: 1.6571  Acc@1: 62.5000 (65.5280)  Acc@5: 87.5000 (91.7883)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3520/4579]  eta: 0:06:05  Lr: 0.001875  Loss: 1.6362  Acc@1: 62.5000 (65.5265)  Acc@5: 87.5000 (91.7726)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3530/4579]  eta: 0:06:02  Lr: 0.001875  Loss: 1.1587  Acc@1: 62.5000 (65.5303)  Acc@5: 87.5000 (91.7711)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3540/4579]  eta: 0:05:59  Lr: 0.001875  Loss: 0.6221  Acc@1: 62.5000 (65.5165)  Acc@5: 93.7500 (91.7643)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3550/4579]  eta: 0:05:55  Lr: 0.001875  Loss: 1.3557  Acc@1: 62.5000 (65.4939)  Acc@5: 87.5000 (91.7558)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3560/4579]  eta: 0:05:52  Lr: 0.001875  Loss: 1.2377  Acc@1: 62.5000 (65.4855)  Acc@5: 87.5000 (91.7492)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3570/4579]  eta: 0:05:48  Lr: 0.001875  Loss: 1.0253  Acc@1: 68.7500 (65.4964)  Acc@5: 93.7500 (91.7548)  time: 0.3469  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [3580/4579]  eta: 0:05:45  Lr: 0.001875  Loss: 0.8825  Acc@1: 68.7500 (65.5002)  Acc@5: 93.7500 (91.7551)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3590/4579]  eta: 0:05:41  Lr: 0.001875  Loss: 1.3045  Acc@1: 62.5000 (65.4919)  Acc@5: 93.7500 (91.7485)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3600/4579]  eta: 0:05:38  Lr: 0.001875  Loss: 0.8779  Acc@1: 62.5000 (65.4905)  Acc@5: 93.7500 (91.7506)  time: 0.3449  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3610/4579]  eta: 0:05:34  Lr: 0.001875  Loss: 1.1536  Acc@1: 62.5000 (65.4891)  Acc@5: 93.7500 (91.7526)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3620/4579]  eta: 0:05:31  Lr: 0.001875  Loss: 0.8315  Acc@1: 62.5000 (65.4912)  Acc@5: 93.7500 (91.7564)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3630/4579]  eta: 0:05:27  Lr: 0.001875  Loss: 1.3211  Acc@1: 68.7500 (65.4985)  Acc@5: 93.7500 (91.7602)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3640/4579]  eta: 0:05:24  Lr: 0.001875  Loss: 0.4838  Acc@1: 62.5000 (65.4937)  Acc@5: 93.7500 (91.7657)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3650/4579]  eta: 0:05:21  Lr: 0.001875  Loss: 1.3733  Acc@1: 62.5000 (65.4752)  Acc@5: 93.7500 (91.7625)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3660/4579]  eta: 0:05:17  Lr: 0.001875  Loss: 1.1588  Acc@1: 62.5000 (65.4756)  Acc@5: 93.7500 (91.7645)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3670/4579]  eta: 0:05:14  Lr: 0.001875  Loss: 0.8411  Acc@1: 62.5000 (65.4726)  Acc@5: 93.7500 (91.7717)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3680/4579]  eta: 0:05:10  Lr: 0.001875  Loss: 0.9021  Acc@1: 62.5000 (65.4764)  Acc@5: 93.7500 (91.7736)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3690/4579]  eta: 0:05:07  Lr: 0.001875  Loss: 1.2628  Acc@1: 62.5000 (65.4802)  Acc@5: 93.7500 (91.7756)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3700/4579]  eta: 0:05:03  Lr: 0.001875  Loss: 1.2742  Acc@1: 68.7500 (65.4907)  Acc@5: 93.7500 (91.7759)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3710/4579]  eta: 0:05:00  Lr: 0.001875  Loss: 0.8035  Acc@1: 62.5000 (65.4827)  Acc@5: 93.7500 (91.7711)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3720/4579]  eta: 0:04:56  Lr: 0.001875  Loss: 1.3691  Acc@1: 62.5000 (65.4831)  Acc@5: 93.7500 (91.7781)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3730/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 1.1583  Acc@1: 68.7500 (65.4935)  Acc@5: 93.7500 (91.7716)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3740/4579]  eta: 0:04:49  Lr: 0.001875  Loss: 1.4213  Acc@1: 68.7500 (65.4955)  Acc@5: 93.7500 (91.7769)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3750/4579]  eta: 0:04:46  Lr: 0.001875  Loss: 1.0494  Acc@1: 68.7500 (65.5025)  Acc@5: 93.7500 (91.7755)  time: 0.3459  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3760/4579]  eta: 0:04:43  Lr: 0.001875  Loss: 1.4883  Acc@1: 62.5000 (65.4862)  Acc@5: 87.5000 (91.7691)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3770/4579]  eta: 0:04:39  Lr: 0.001875  Loss: 0.6479  Acc@1: 62.5000 (65.4999)  Acc@5: 93.7500 (91.7645)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3780/4579]  eta: 0:04:36  Lr: 0.001875  Loss: 0.7959  Acc@1: 68.7500 (65.5002)  Acc@5: 93.7500 (91.7664)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3790/4579]  eta: 0:04:32  Lr: 0.001875  Loss: 0.8658  Acc@1: 68.7500 (65.4972)  Acc@5: 93.7500 (91.7667)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3800/4579]  eta: 0:04:29  Lr: 0.001875  Loss: 0.6146  Acc@1: 68.7500 (65.5124)  Acc@5: 93.7500 (91.7653)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3810/4579]  eta: 0:04:25  Lr: 0.001875  Loss: 1.1650  Acc@1: 62.5000 (65.5061)  Acc@5: 87.5000 (91.7656)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3820/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 1.1862  Acc@1: 62.5000 (65.5015)  Acc@5: 87.5000 (91.7577)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3830/4579]  eta: 0:04:18  Lr: 0.001875  Loss: 1.0715  Acc@1: 62.5000 (65.5051)  Acc@5: 87.5000 (91.7613)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3840/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 0.9932  Acc@1: 68.7500 (65.5119)  Acc@5: 93.7500 (91.7600)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3850/4579]  eta: 0:04:11  Lr: 0.001875  Loss: 1.0575  Acc@1: 68.7500 (65.5025)  Acc@5: 93.7500 (91.7651)  time: 0.3456  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3860/4579]  eta: 0:04:08  Lr: 0.001875  Loss: 0.9655  Acc@1: 68.7500 (65.5174)  Acc@5: 93.7500 (91.7719)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3870/4579]  eta: 0:04:05  Lr: 0.001875  Loss: 0.7950  Acc@1: 75.0000 (65.5370)  Acc@5: 93.7500 (91.7786)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3880/4579]  eta: 0:04:01  Lr: 0.001875  Loss: 0.8850  Acc@1: 62.5000 (65.5324)  Acc@5: 93.7500 (91.7837)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3890/4579]  eta: 0:03:58  Lr: 0.001875  Loss: 0.8123  Acc@1: 62.5000 (65.5471)  Acc@5: 93.7500 (91.7936)  time: 0.3457  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3900/4579]  eta: 0:03:54  Lr: 0.001875  Loss: 0.7979  Acc@1: 75.0000 (65.5681)  Acc@5: 93.7500 (91.7970)  time: 0.3451  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3910/4579]  eta: 0:03:51  Lr: 0.001875  Loss: 1.1146  Acc@1: 68.7500 (65.5651)  Acc@5: 93.7500 (91.7924)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3920/4579]  eta: 0:03:47  Lr: 0.001875  Loss: 0.9377  Acc@1: 62.5000 (65.5796)  Acc@5: 93.7500 (91.7926)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3930/4579]  eta: 0:03:44  Lr: 0.001875  Loss: 1.3218  Acc@1: 68.7500 (65.5940)  Acc@5: 93.7500 (91.7976)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3940/4579]  eta: 0:03:40  Lr: 0.001875  Loss: 1.3847  Acc@1: 68.7500 (65.5941)  Acc@5: 93.7500 (91.8009)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3950/4579]  eta: 0:03:37  Lr: 0.001875  Loss: 0.6933  Acc@1: 68.7500 (65.6100)  Acc@5: 93.7500 (91.7995)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3960/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 0.9012  Acc@1: 62.5000 (65.6132)  Acc@5: 93.7500 (91.7903)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3970/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 0.6164  Acc@1: 62.5000 (65.6132)  Acc@5: 93.7500 (91.7968)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3980/4579]  eta: 0:03:26  Lr: 0.001875  Loss: 1.6373  Acc@1: 68.7500 (65.6289)  Acc@5: 93.7500 (91.8017)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3990/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 1.6505  Acc@1: 68.7500 (65.6180)  Acc@5: 93.7500 (91.8003)  time: 0.3458  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4000/4579]  eta: 0:03:20  Lr: 0.001875  Loss: 0.9148  Acc@1: 62.5000 (65.6133)  Acc@5: 87.5000 (91.7927)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4010/4579]  eta: 0:03:16  Lr: 0.001875  Loss: 0.9617  Acc@1: 75.0000 (65.6398)  Acc@5: 93.7500 (91.8007)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4020/4579]  eta: 0:03:13  Lr: 0.001875  Loss: 1.1447  Acc@1: 75.0000 (65.6569)  Acc@5: 93.7500 (91.7993)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4030/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 1.2699  Acc@1: 62.5000 (65.6459)  Acc@5: 87.5000 (91.7917)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4040/4579]  eta: 0:03:06  Lr: 0.001875  Loss: 0.8453  Acc@1: 62.5000 (65.6474)  Acc@5: 93.7500 (91.7966)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4050/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 0.5214  Acc@1: 68.7500 (65.6643)  Acc@5: 93.7500 (91.7983)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4060/4579]  eta: 0:02:59  Lr: 0.001875  Loss: 1.0482  Acc@1: 68.7500 (65.6612)  Acc@5: 87.5000 (91.7877)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4070/4579]  eta: 0:02:55  Lr: 0.001875  Loss: 0.9824  Acc@1: 68.7500 (65.6565)  Acc@5: 93.7500 (91.7910)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4080/4579]  eta: 0:02:52  Lr: 0.001875  Loss: 0.9853  Acc@1: 68.7500 (65.6625)  Acc@5: 93.7500 (91.8019)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4090/4579]  eta: 0:02:48  Lr: 0.001875  Loss: 1.1633  Acc@1: 62.5000 (65.6533)  Acc@5: 93.7500 (91.7930)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4100/4579]  eta: 0:02:45  Lr: 0.001875  Loss: 1.5513  Acc@1: 62.5000 (65.6471)  Acc@5: 93.7500 (91.7886)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4110/4579]  eta: 0:02:42  Lr: 0.001875  Loss: 1.4967  Acc@1: 62.5000 (65.6577)  Acc@5: 93.7500 (91.7873)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4120/4579]  eta: 0:02:38  Lr: 0.001875  Loss: 0.8937  Acc@1: 68.7500 (65.6622)  Acc@5: 93.7500 (91.7875)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4130/4579]  eta: 0:02:35  Lr: 0.001875  Loss: 1.1641  Acc@1: 62.5000 (65.6545)  Acc@5: 93.7500 (91.7907)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4140/4579]  eta: 0:02:31  Lr: 0.001875  Loss: 0.7009  Acc@1: 68.7500 (65.6650)  Acc@5: 93.7500 (91.7970)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4150/4579]  eta: 0:02:28  Lr: 0.001875  Loss: 1.0258  Acc@1: 68.7500 (65.6694)  Acc@5: 93.7500 (91.7987)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4160/4579]  eta: 0:02:24  Lr: 0.001875  Loss: 1.0903  Acc@1: 62.5000 (65.6738)  Acc@5: 93.7500 (91.8034)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4170/4579]  eta: 0:02:21  Lr: 0.001875  Loss: 1.4136  Acc@1: 62.5000 (65.6602)  Acc@5: 93.7500 (91.8005)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4180/4579]  eta: 0:02:17  Lr: 0.001875  Loss: 1.8792  Acc@1: 56.2500 (65.6362)  Acc@5: 87.5000 (91.7843)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4190/4579]  eta: 0:02:14  Lr: 0.001875  Loss: 1.2940  Acc@1: 62.5000 (65.6362)  Acc@5: 87.5000 (91.7800)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4200/4579]  eta: 0:02:10  Lr: 0.001875  Loss: 0.6943  Acc@1: 62.5000 (65.6391)  Acc@5: 93.7500 (91.7847)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4210/4579]  eta: 0:02:07  Lr: 0.001875  Loss: 0.9729  Acc@1: 68.7500 (65.6376)  Acc@5: 93.7500 (91.7864)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4220/4579]  eta: 0:02:04  Lr: 0.001875  Loss: 1.1918  Acc@1: 62.5000 (65.6361)  Acc@5: 93.7500 (91.7792)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4230/4579]  eta: 0:02:00  Lr: 0.001875  Loss: 1.1460  Acc@1: 68.7500 (65.6553)  Acc@5: 93.7500 (91.7853)  time: 0.3451  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 1.1534  Acc@1: 68.7500 (65.6449)  Acc@5: 93.7500 (91.7885)  time: 0.3455  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4250/4579]  eta: 0:01:53  Lr: 0.001875  Loss: 1.0600  Acc@1: 62.5000 (65.6522)  Acc@5: 93.7500 (91.7843)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: 0.5347  Acc@1: 68.7500 (65.6653)  Acc@5: 93.7500 (91.7889)  time: 0.3457  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4270/4579]  eta: 0:01:46  Lr: 0.001875  Loss: 0.6824  Acc@1: 68.7500 (65.6696)  Acc@5: 93.7500 (91.7891)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: 1.9077  Acc@1: 68.7500 (65.6637)  Acc@5: 87.5000 (91.7776)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4290/4579]  eta: 0:01:39  Lr: 0.001875  Loss: 1.0814  Acc@1: 62.5000 (65.6665)  Acc@5: 87.5000 (91.7749)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 0.6596  Acc@1: 68.7500 (65.6679)  Acc@5: 93.7500 (91.7781)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4310/4579]  eta: 0:01:32  Lr: 0.001875  Loss: 1.2774  Acc@1: 62.5000 (65.6504)  Acc@5: 87.5000 (91.7667)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4320/4579]  eta: 0:01:29  Lr: 0.001875  Loss: 1.2063  Acc@1: 62.5000 (65.6460)  Acc@5: 93.7500 (91.7670)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: 0.9365  Acc@1: 68.7500 (65.6575)  Acc@5: 93.7500 (91.7672)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4340/4579]  eta: 0:01:22  Lr: 0.001875  Loss: 1.0138  Acc@1: 68.7500 (65.6574)  Acc@5: 93.7500 (91.7703)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: 0.5117  Acc@1: 68.7500 (65.6789)  Acc@5: 93.7500 (91.7663)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4360/4579]  eta: 0:01:15  Lr: 0.001875  Loss: 0.8635  Acc@1: 62.5000 (65.6787)  Acc@5: 93.7500 (91.7593)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: 0.9518  Acc@1: 62.5000 (65.6843)  Acc@5: 93.7500 (91.7668)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:08  Lr: 0.001875  Loss: 0.8316  Acc@1: 68.7500 (65.6956)  Acc@5: 93.7500 (91.7699)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 1.0075  Acc@1: 62.5000 (65.6912)  Acc@5: 93.7500 (91.7715)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:01  Lr: 0.001875  Loss: 1.2654  Acc@1: 62.5000 (65.6882)  Acc@5: 87.5000 (91.7647)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: 0.8815  Acc@1: 62.5000 (65.6753)  Acc@5: 87.5000 (91.7564)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4420/4579]  eta: 0:00:54  Lr: 0.001875  Loss: 1.3960  Acc@1: 62.5000 (65.6893)  Acc@5: 93.7500 (91.7623)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 1.2499  Acc@1: 75.0000 (65.7047)  Acc@5: 93.7500 (91.7682)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 1.7257  Acc@1: 68.7500 (65.7031)  Acc@5: 93.7500 (91.7642)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 1.2412  Acc@1: 68.7500 (65.7184)  Acc@5: 93.7500 (91.7603)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 0.6608  Acc@1: 68.7500 (65.7238)  Acc@5: 93.7500 (91.7661)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: 1.0682  Acc@1: 68.7500 (65.7319)  Acc@5: 93.7500 (91.7664)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: 0.9809  Acc@1: 68.7500 (65.7429)  Acc@5: 93.7500 (91.7694)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: 0.8359  Acc@1: 68.7500 (65.7384)  Acc@5: 93.7500 (91.7669)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: 0.7793  Acc@1: 62.5000 (65.7382)  Acc@5: 93.7500 (91.7657)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: 0.7645  Acc@1: 68.7500 (65.7351)  Acc@5: 93.7500 (91.7687)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 1.1612  Acc@1: 68.7500 (65.7432)  Acc@5: 93.7500 (91.7690)  time: 0.3461  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:16  Lr: 0.001875  Loss: 0.4880  Acc@1: 62.5000 (65.7360)  Acc@5: 93.7500 (91.7623)  time: 0.3447  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.8668  Acc@1: 62.5000 (65.7207)  Acc@5: 87.5000 (91.7584)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 2.3304  Acc@1: 62.5000 (65.7053)  Acc@5: 87.5000 (91.7532)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.6981  Acc@1: 62.5000 (65.7065)  Acc@5: 87.5000 (91.7521)  time: 0.3458  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.9711  Acc@1: 62.5000 (65.7064)  Acc@5: 93.7500 (91.7469)  time: 0.3468  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 1.1656  Acc@1: 68.7500 (65.7084)  Acc@5: 93.7500 (91.7482)  time: 0.3380  data: 0.0012  max mem: 2500
Train: Epoch[5/5] Total time: 0:26:22 (0.3457 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.1656  Acc@1: 68.7500 (65.7084)  Acc@5: 93.7500 (91.7482)
Test: [Task 1]  [   0/1627]  eta: 0:15:27  Loss: 1.1259 (1.1259)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5700  data: 0.3549  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:39  Loss: 0.8293 (0.8222)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  time: 0.2471  data: 0.0326  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:13  Loss: 0.8171 (0.8097)  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (97.9167)  time: 0.2153  data: 0.0006  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:01  Loss: 0.8154 (0.8301)  Acc@1: 81.2500 (84.8790)  Acc@5: 100.0000 (97.9839)  time: 0.2153  data: 0.0006  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:55  Loss: 0.9673 (0.8497)  Acc@1: 81.2500 (83.8415)  Acc@5: 100.0000 (97.5610)  time: 0.2157  data: 0.0010  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:50  Loss: 0.8918 (0.8401)  Acc@1: 81.2500 (84.6814)  Acc@5: 100.0000 (97.3039)  time: 0.2162  data: 0.0017  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:46  Loss: 0.8325 (0.8435)  Acc@1: 87.5000 (84.7336)  Acc@5: 93.7500 (97.1311)  time: 0.2157  data: 0.0012  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:43  Loss: 0.7575 (0.8347)  Acc@1: 87.5000 (84.5070)  Acc@5: 100.0000 (97.3592)  time: 0.2157  data: 0.0007  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:40  Loss: 0.6265 (0.8154)  Acc@1: 87.5000 (84.8765)  Acc@5: 100.0000 (97.6852)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:37  Loss: 0.7738 (0.8280)  Acc@1: 87.5000 (84.6154)  Acc@5: 100.0000 (97.3901)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:34  Loss: 0.9673 (0.8511)  Acc@1: 81.2500 (84.0965)  Acc@5: 93.7500 (97.1535)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:31  Loss: 0.8809 (0.8462)  Acc@1: 81.2500 (84.2342)  Acc@5: 100.0000 (97.2410)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:29  Loss: 0.8308 (0.8496)  Acc@1: 87.5000 (84.3492)  Acc@5: 100.0000 (97.1074)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:26  Loss: 0.8300 (0.8546)  Acc@1: 87.5000 (84.3034)  Acc@5: 100.0000 (97.1374)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:23  Loss: 0.7926 (0.8495)  Acc@1: 81.2500 (84.3972)  Acc@5: 100.0000 (97.1188)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:21  Loss: 0.6134 (0.8364)  Acc@1: 87.5000 (84.6440)  Acc@5: 100.0000 (97.1854)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:19  Loss: 0.6206 (0.8299)  Acc@1: 87.5000 (84.7050)  Acc@5: 100.0000 (97.2050)  time: 0.2159  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:16  Loss: 0.7052 (0.8238)  Acc@1: 87.5000 (84.9050)  Acc@5: 100.0000 (97.2953)  time: 0.2156  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:14  Loss: 0.6914 (0.8308)  Acc@1: 87.5000 (84.9102)  Acc@5: 100.0000 (97.2721)  time: 0.2150  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:12  Loss: 0.8887 (0.8280)  Acc@1: 87.5000 (84.9476)  Acc@5: 100.0000 (97.3168)  time: 0.2158  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:09  Loss: 0.8887 (0.8280)  Acc@1: 87.5000 (84.9192)  Acc@5: 100.0000 (97.3881)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:07  Loss: 0.7708 (0.8273)  Acc@1: 81.2500 (85.0118)  Acc@5: 100.0000 (97.3637)  time: 0.2154  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:05  Loss: 0.6769 (0.8313)  Acc@1: 81.2500 (84.8133)  Acc@5: 100.0000 (97.3699)  time: 0.2154  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:03  Loss: 0.6880 (0.8258)  Acc@1: 87.5000 (84.9838)  Acc@5: 100.0000 (97.3755)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:00  Loss: 0.7353 (0.8248)  Acc@1: 87.5000 (85.0363)  Acc@5: 100.0000 (97.3548)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:04:58  Loss: 0.8566 (0.8300)  Acc@1: 87.5000 (85.1594)  Acc@5: 100.0000 (97.2610)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:56  Loss: 0.8730 (0.8290)  Acc@1: 87.5000 (85.1293)  Acc@5: 100.0000 (97.2701)  time: 0.2154  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:54  Loss: 0.7147 (0.8233)  Acc@1: 87.5000 (85.1937)  Acc@5: 100.0000 (97.3247)  time: 0.2153  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:51  Loss: 0.7531 (0.8268)  Acc@1: 81.2500 (85.0756)  Acc@5: 100.0000 (97.3532)  time: 0.2153  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:49  Loss: 0.7572 (0.8242)  Acc@1: 87.5000 (85.2448)  Acc@5: 100.0000 (97.3368)  time: 0.2146  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:47  Loss: 0.7218 (0.8226)  Acc@1: 87.5000 (85.2159)  Acc@5: 100.0000 (97.3422)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:45  Loss: 0.7218 (0.8226)  Acc@1: 81.2500 (85.2894)  Acc@5: 100.0000 (97.3674)  time: 0.2151  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:42  Loss: 0.7544 (0.8208)  Acc@1: 87.5000 (85.3972)  Acc@5: 100.0000 (97.4299)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:40  Loss: 0.7286 (0.8187)  Acc@1: 87.5000 (85.4796)  Acc@5: 100.0000 (97.4320)  time: 0.2179  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:38  Loss: 0.6826 (0.8191)  Acc@1: 87.5000 (85.5022)  Acc@5: 100.0000 (97.4340)  time: 0.2165  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:36  Loss: 0.6887 (0.8201)  Acc@1: 87.5000 (85.5057)  Acc@5: 100.0000 (97.3825)  time: 0.2150  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:34  Loss: 0.6887 (0.8184)  Acc@1: 87.5000 (85.4224)  Acc@5: 100.0000 (97.4204)  time: 0.2151  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 0.7550 (0.8177)  Acc@1: 87.5000 (85.4616)  Acc@5: 100.0000 (97.4730)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:29  Loss: 0.7304 (0.8168)  Acc@1: 87.5000 (85.4659)  Acc@5: 100.0000 (97.4902)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:27  Loss: 0.7792 (0.8171)  Acc@1: 87.5000 (85.5019)  Acc@5: 100.0000 (97.5384)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:25  Loss: 0.8067 (0.8173)  Acc@1: 87.5000 (85.5673)  Acc@5: 100.0000 (97.5374)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:23  Loss: 0.6921 (0.8168)  Acc@1: 87.5000 (85.6448)  Acc@5: 100.0000 (97.4757)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:20  Loss: 0.6829 (0.8164)  Acc@1: 87.5000 (85.6295)  Acc@5: 100.0000 (97.5059)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:18  Loss: 0.6664 (0.8136)  Acc@1: 87.5000 (85.6729)  Acc@5: 100.0000 (97.5203)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:16  Loss: 0.7150 (0.8134)  Acc@1: 87.5000 (85.6293)  Acc@5: 100.0000 (97.5482)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:14  Loss: 0.8711 (0.8156)  Acc@1: 81.2500 (85.5460)  Acc@5: 100.0000 (97.5471)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 0.8456 (0.8147)  Acc@1: 81.2500 (85.5613)  Acc@5: 100.0000 (97.5868)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:09  Loss: 0.5642 (0.8114)  Acc@1: 87.5000 (85.6555)  Acc@5: 100.0000 (97.6115)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:07  Loss: 0.7358 (0.8146)  Acc@1: 87.5000 (85.6159)  Acc@5: 100.0000 (97.6221)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 0.7358 (0.8144)  Acc@1: 87.5000 (85.6161)  Acc@5: 100.0000 (97.6324)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 0.7271 (0.8160)  Acc@1: 87.5000 (85.6038)  Acc@5: 100.0000 (97.6297)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:01  Loss: 0.9404 (0.8214)  Acc@1: 81.2500 (85.5308)  Acc@5: 100.0000 (97.5783)  time: 0.2151  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 1.0516 (0.8283)  Acc@1: 87.5000 (85.4846)  Acc@5: 93.7500 (97.5288)  time: 0.2157  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:56  Loss: 0.8190 (0.8244)  Acc@1: 87.5000 (85.5697)  Acc@5: 100.0000 (97.5636)  time: 0.2167  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 0.7317 (0.8238)  Acc@1: 87.5000 (85.5938)  Acc@5: 100.0000 (97.5624)  time: 0.2158  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 0.8735 (0.8257)  Acc@1: 87.5000 (85.6171)  Acc@5: 100.0000 (97.5499)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 0.9032 (0.8276)  Acc@1: 87.5000 (85.5838)  Acc@5: 100.0000 (97.5713)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:48  Loss: 0.8378 (0.8249)  Acc@1: 87.5000 (85.6283)  Acc@5: 100.0000 (97.5591)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:46  Loss: 0.8018 (0.8263)  Acc@1: 87.5000 (85.6175)  Acc@5: 100.0000 (97.5688)  time: 0.2153  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:43  Loss: 0.7588 (0.8235)  Acc@1: 87.5000 (85.7339)  Acc@5: 100.0000 (97.5994)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 0.6891 (0.8262)  Acc@1: 93.7500 (85.7113)  Acc@5: 100.0000 (97.5978)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 0.8815 (0.8253)  Acc@1: 87.5000 (85.7508)  Acc@5: 100.0000 (97.5859)  time: 0.2171  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 0.8016 (0.8270)  Acc@1: 87.5000 (85.6884)  Acc@5: 100.0000 (97.5745)  time: 0.2185  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 0.8016 (0.8274)  Acc@1: 87.5000 (85.6874)  Acc@5: 100.0000 (97.5634)  time: 0.2179  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 0.7184 (0.8288)  Acc@1: 87.5000 (85.6279)  Acc@5: 100.0000 (97.5527)  time: 0.2158  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:31  Loss: 0.6915 (0.8279)  Acc@1: 81.2500 (85.5895)  Acc@5: 100.0000 (97.5614)  time: 0.2150  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 0.7378 (0.8263)  Acc@1: 87.5000 (85.6089)  Acc@5: 100.0000 (97.5700)  time: 0.2153  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 0.7885 (0.8263)  Acc@1: 87.5000 (85.5999)  Acc@5: 100.0000 (97.5317)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 0.7851 (0.8257)  Acc@1: 87.5000 (85.6461)  Acc@5: 100.0000 (97.5404)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 0.7184 (0.8243)  Acc@1: 87.5000 (85.6458)  Acc@5: 100.0000 (97.5488)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 0.7914 (0.8243)  Acc@1: 87.5000 (85.6723)  Acc@5: 100.0000 (97.5392)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 0.7367 (0.8225)  Acc@1: 87.5000 (85.7507)  Acc@5: 100.0000 (97.5563)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 0.7367 (0.8209)  Acc@1: 87.5000 (85.7836)  Acc@5: 100.0000 (97.5641)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 0.7921 (0.8214)  Acc@1: 87.5000 (85.7900)  Acc@5: 100.0000 (97.5462)  time: 0.2153  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 0.7921 (0.8221)  Acc@1: 87.5000 (85.7878)  Acc@5: 100.0000 (97.5371)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 0.7641 (0.8216)  Acc@1: 81.2500 (85.8106)  Acc@5: 100.0000 (97.5616)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 0.8421 (0.8244)  Acc@1: 81.2500 (85.7999)  Acc@5: 100.0000 (97.5279)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 0.7121 (0.8217)  Acc@1: 87.5000 (85.8706)  Acc@5: 93.7500 (97.5357)  time: 0.2154  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:02  Loss: 0.6129 (0.8203)  Acc@1: 87.5000 (85.9075)  Acc@5: 100.0000 (97.5352)  time: 0.2158  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 0.7116 (0.8216)  Acc@1: 87.5000 (85.9039)  Acc@5: 100.0000 (97.5190)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 0.7376 (0.8210)  Acc@1: 87.5000 (85.9160)  Acc@5: 100.0000 (97.5421)  time: 0.2152  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 0.6888 (0.8203)  Acc@1: 87.5000 (85.9356)  Acc@5: 100.0000 (97.5339)  time: 0.2149  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 0.6637 (0.8197)  Acc@1: 87.5000 (85.9622)  Acc@5: 100.0000 (97.5411)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 0.6094 (0.8194)  Acc@1: 87.5000 (85.9732)  Acc@5: 100.0000 (97.5481)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 0.5567 (0.8169)  Acc@1: 93.7500 (86.0285)  Acc@5: 100.0000 (97.5699)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 0.6509 (0.8175)  Acc@1: 87.5000 (86.0238)  Acc@5: 100.0000 (97.5837)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 0.6285 (0.8162)  Acc@1: 93.7500 (86.0772)  Acc@5: 100.0000 (97.5973)  time: 0.2151  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 0.5836 (0.8150)  Acc@1: 93.7500 (86.1223)  Acc@5: 100.0000 (97.6033)  time: 0.2150  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 0.8772 (0.8167)  Acc@1: 87.5000 (86.1308)  Acc@5: 100.0000 (97.6093)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 0.9052 (0.8186)  Acc@1: 87.5000 (86.1251)  Acc@5: 100.0000 (97.5870)  time: 0.2161  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:36  Loss: 0.8476 (0.8187)  Acc@1: 87.5000 (86.1127)  Acc@5: 100.0000 (97.5860)  time: 0.2166  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 0.8276 (0.8194)  Acc@1: 87.5000 (86.1142)  Acc@5: 100.0000 (97.5714)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 0.7580 (0.8187)  Acc@1: 87.5000 (86.1224)  Acc@5: 100.0000 (97.5706)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 0.7550 (0.8185)  Acc@1: 87.5000 (86.1372)  Acc@5: 100.0000 (97.5765)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 0.7921 (0.8174)  Acc@1: 87.5000 (86.1583)  Acc@5: 100.0000 (97.5824)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 0.8278 (0.8180)  Acc@1: 87.5000 (86.1133)  Acc@5: 100.0000 (97.6012)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:23  Loss: 0.8248 (0.8170)  Acc@1: 81.2500 (86.0887)  Acc@5: 100.0000 (97.6067)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 0.6668 (0.8164)  Acc@1: 87.5000 (86.1032)  Acc@5: 100.0000 (97.6056)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 0.7779 (0.8169)  Acc@1: 87.5000 (86.0856)  Acc@5: 100.0000 (97.5917)  time: 0.2156  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 0.9311 (0.8193)  Acc@1: 87.5000 (86.0810)  Acc@5: 100.0000 (97.5845)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 0.9575 (0.8200)  Acc@1: 81.2500 (86.0452)  Acc@5: 100.0000 (97.5712)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 0.8953 (0.8202)  Acc@1: 81.2500 (86.0410)  Acc@5: 100.0000 (97.5643)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 0.8314 (0.8197)  Acc@1: 87.5000 (86.0615)  Acc@5: 100.0000 (97.5698)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 0.6008 (0.8174)  Acc@1: 87.5000 (86.1178)  Acc@5: 100.0000 (97.5873)  time: 0.2171  data: 0.0004  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.5900 (0.8167)  Acc@1: 87.5000 (86.1191)  Acc@5: 100.0000 (97.5925)  time: 0.2167  data: 0.0003  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.6751 (0.8151)  Acc@1: 87.5000 (86.1382)  Acc@5: 100.0000 (97.5856)  time: 0.2158  data: 0.0006  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 0.7581 (0.8157)  Acc@1: 87.5000 (86.1216)  Acc@5: 93.7500 (97.5672)  time: 0.2153  data: 0.0006  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 0.8289 (0.8165)  Acc@1: 81.2500 (86.1286)  Acc@5: 93.7500 (97.5432)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 0.7686 (0.8168)  Acc@1: 87.5000 (86.1413)  Acc@5: 100.0000 (97.5370)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 0.7804 (0.8170)  Acc@1: 87.5000 (86.1423)  Acc@5: 100.0000 (97.5481)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 0.7520 (0.8154)  Acc@1: 87.5000 (86.1546)  Acc@5: 100.0000 (97.5647)  time: 0.2163  data: 0.0010  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 0.7223 (0.8158)  Acc@1: 87.5000 (86.1667)  Acc@5: 100.0000 (97.5529)  time: 0.2163  data: 0.0010  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 0.7261 (0.8166)  Acc@1: 87.5000 (86.1452)  Acc@5: 100.0000 (97.5468)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 0.7772 (0.8165)  Acc@1: 81.2500 (86.1516)  Acc@5: 100.0000 (97.5409)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 0.8896 (0.8178)  Acc@1: 81.2500 (86.1251)  Acc@5: 100.0000 (97.5351)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 0.9998 (0.8187)  Acc@1: 81.2500 (86.0936)  Acc@5: 100.0000 (97.5348)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 0.8149 (0.8176)  Acc@1: 81.2500 (86.1273)  Acc@5: 100.0000 (97.5398)  time: 0.2171  data: 0.0003  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 0.7192 (0.8168)  Acc@1: 93.7500 (86.1443)  Acc@5: 100.0000 (97.5555)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 0.7831 (0.8173)  Acc@1: 87.5000 (86.1346)  Acc@5: 100.0000 (97.5656)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 0.8519 (0.8177)  Acc@1: 81.2500 (86.1304)  Acc@5: 100.0000 (97.5703)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 0.8720 (0.8178)  Acc@1: 87.5000 (86.1418)  Acc@5: 100.0000 (97.5749)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 0.6732 (0.8183)  Acc@1: 87.5000 (86.0962)  Acc@5: 100.0000 (97.5743)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 0.6538 (0.8175)  Acc@1: 87.5000 (86.0923)  Acc@5: 100.0000 (97.5839)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 0.7892 (0.8182)  Acc@1: 81.2500 (86.0378)  Acc@5: 100.0000 (97.5985)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 0.7892 (0.8179)  Acc@1: 81.2500 (86.0546)  Acc@5: 100.0000 (97.5977)  time: 0.2154  data: 0.0010  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 0.8773 (0.8183)  Acc@1: 87.5000 (86.0412)  Acc@5: 100.0000 (97.5919)  time: 0.2154  data: 0.0010  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 0.8192 (0.8185)  Acc@1: 87.5000 (86.0329)  Acc@5: 100.0000 (97.5813)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 0.7125 (0.8186)  Acc@1: 87.5000 (86.0248)  Acc@5: 100.0000 (97.5954)  time: 0.2158  data: 0.0012  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 0.6935 (0.8171)  Acc@1: 87.5000 (86.0265)  Acc@5: 100.0000 (97.6142)  time: 0.2164  data: 0.0012  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 0.7101 (0.8175)  Acc@1: 81.2500 (86.0089)  Acc@5: 100.0000 (97.6181)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 0.8774 (0.8164)  Acc@1: 87.5000 (86.0396)  Acc@5: 100.0000 (97.6172)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.5569 (0.8149)  Acc@1: 87.5000 (86.0650)  Acc@5: 100.0000 (97.6163)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.5183 (0.8134)  Acc@1: 93.7500 (86.1185)  Acc@5: 100.0000 (97.6202)  time: 0.2153  data: 0.0008  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.6735 (0.8139)  Acc@1: 87.5000 (86.0913)  Acc@5: 100.0000 (97.6193)  time: 0.2161  data: 0.0008  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 0.8511 (0.8147)  Acc@1: 81.2500 (86.0645)  Acc@5: 100.0000 (97.6184)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 0.7043 (0.8140)  Acc@1: 87.5000 (86.0890)  Acc@5: 100.0000 (97.6221)  time: 0.2157  data: 0.0006  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.7662 (0.8136)  Acc@1: 87.5000 (86.0902)  Acc@5: 100.0000 (97.6396)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.7767 (0.8130)  Acc@1: 81.2500 (86.1005)  Acc@5: 100.0000 (97.6431)  time: 0.2164  data: 0.0005  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 0.7767 (0.8133)  Acc@1: 87.5000 (86.0789)  Acc@5: 100.0000 (97.6331)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 0.8171 (0.8126)  Acc@1: 87.5000 (86.0936)  Acc@5: 100.0000 (97.6366)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 0.6549 (0.8131)  Acc@1: 87.5000 (86.0724)  Acc@5: 100.0000 (97.6356)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 0.6549 (0.8128)  Acc@1: 87.5000 (86.0959)  Acc@5: 100.0000 (97.6391)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.6863 (0.8124)  Acc@1: 87.5000 (86.1145)  Acc@5: 100.0000 (97.6469)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 0.8785 (0.8145)  Acc@1: 81.2500 (86.0718)  Acc@5: 100.0000 (97.6066)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 0.8785 (0.8144)  Acc@1: 81.2500 (86.0644)  Acc@5: 93.7500 (97.6102)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 0.9708 (0.8156)  Acc@1: 87.5000 (86.0570)  Acc@5: 100.0000 (97.6051)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 0.9744 (0.8157)  Acc@1: 81.2500 (86.0370)  Acc@5: 100.0000 (97.5915)  time: 0.2164  data: 0.0013  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 0.7290 (0.8159)  Acc@1: 81.2500 (86.0257)  Acc@5: 100.0000 (97.5952)  time: 0.2159  data: 0.0013  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 0.7676 (0.8163)  Acc@1: 87.5000 (86.0356)  Acc@5: 100.0000 (97.5903)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 0.8234 (0.8167)  Acc@1: 87.5000 (86.0371)  Acc@5: 100.0000 (97.5855)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.7824 (0.8169)  Acc@1: 87.5000 (86.0343)  Acc@5: 100.0000 (97.5808)  time: 0.2160  data: 0.0012  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.7054 (0.8170)  Acc@1: 93.7500 (86.0481)  Acc@5: 100.0000 (97.5761)  time: 0.2159  data: 0.0012  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.6343 (0.8157)  Acc@1: 93.7500 (86.0823)  Acc@5: 100.0000 (97.5838)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.6417 (0.8155)  Acc@1: 87.5000 (86.0712)  Acc@5: 100.0000 (97.5874)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.6417 (0.8143)  Acc@1: 93.7500 (86.1089)  Acc@5: 100.0000 (97.5990)  time: 0.2165  data: 0.0010  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.5755 (0.8137)  Acc@1: 93.7500 (86.1259)  Acc@5: 100.0000 (97.5983)  time: 0.2175  data: 0.0013  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.6118 (0.8128)  Acc@1: 87.5000 (86.1427)  Acc@5: 100.0000 (97.6057)  time: 0.2156  data: 0.0006  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.6810 (0.8127)  Acc@1: 93.7500 (86.1673)  Acc@5: 100.0000 (97.6011)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.7852 (0.8128)  Acc@1: 87.5000 (86.1678)  Acc@5: 100.0000 (97.5965)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 0.7347 (0.8125)  Acc@1: 87.5000 (86.1683)  Acc@5: 100.0000 (97.5998)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 0.7736 (0.8134)  Acc@1: 81.2500 (86.1337)  Acc@5: 100.0000 (97.5953)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.7736 (0.8129)  Acc@1: 81.2500 (86.1499)  Acc@5: 100.0000 (97.6024)  time: 0.2151  data: 0.0009  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.6991 (0.8122)  Acc@1: 87.5000 (86.1544)  Acc@5: 100.0000 (97.6018)  time: 0.2159  data: 0.0012  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.6768 (0.8117)  Acc@1: 87.5000 (86.1670)  Acc@5: 100.0000 (97.6030)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1] Total time: 0:05:51 (0.2158 s / it)
* Acc@1 86.167 Acc@5 97.603 loss 0.812
{0: {0: 25002, 1: 25002, 2: 25002, 3: 25002, 4: 25, 5: 25, 6: 25, 7: 25, 8: 146, 9: 146, 10: 146, 11: 146, 12: 67, 13: 67, 14: 67, 15: 67, 16: 792, 17: 792, 18: 792, 19: 792}}
[Average accuracy till task1]	Acc@1: 86.1670	Acc@5: 97.6030	Loss: 0.8117
Train: Epoch[1/5]  [   0/3750]  eta: 0:42:28  Lr: 0.001875  Loss: 2.2811  Acc@1: 12.5000 (12.5000)  Acc@5: 56.2500 (56.2500)  time: 0.6796  data: 0.3224  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:23:21  Lr: 0.001875  Loss: 1.9203  Acc@1: 18.7500 (23.8636)  Acc@5: 56.2500 (61.9318)  time: 0.3748  data: 0.0297  max mem: 2500
Train: Epoch[1/5]  [  20/3750]  eta: 0:22:24  Lr: 0.001875  Loss: 2.0511  Acc@1: 25.0000 (26.4881)  Acc@5: 68.7500 (67.8571)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:06  Lr: 0.001875  Loss: 1.8561  Acc@1: 37.5000 (32.2581)  Acc@5: 81.2500 (72.9839)  time: 0.3464  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [  40/3750]  eta: 0:21:53  Lr: 0.001875  Loss: 1.8947  Acc@1: 50.0000 (36.8902)  Acc@5: 87.5000 (77.4390)  time: 0.3472  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [  50/3750]  eta: 0:21:43  Lr: 0.001875  Loss: 1.5797  Acc@1: 56.2500 (40.1961)  Acc@5: 93.7500 (79.2892)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:35  Lr: 0.001875  Loss: 1.4935  Acc@1: 50.0000 (42.4180)  Acc@5: 87.5000 (81.3525)  time: 0.3454  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:29  Lr: 0.001875  Loss: 1.9351  Acc@1: 56.2500 (44.1901)  Acc@5: 93.7500 (82.7465)  time: 0.3458  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:23  Lr: 0.001875  Loss: 0.9904  Acc@1: 62.5000 (46.4506)  Acc@5: 93.7500 (84.1821)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:17  Lr: 0.001875  Loss: 1.4382  Acc@1: 62.5000 (47.9396)  Acc@5: 93.7500 (84.8901)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:13  Lr: 0.001875  Loss: 1.0581  Acc@1: 68.7500 (50.0000)  Acc@5: 93.7500 (85.8911)  time: 0.3452  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:09  Lr: 0.001875  Loss: 1.3528  Acc@1: 68.7500 (51.7455)  Acc@5: 93.7500 (86.6554)  time: 0.3470  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:04  Lr: 0.001875  Loss: 1.1829  Acc@1: 68.7500 (52.8926)  Acc@5: 93.7500 (87.3450)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:00  Lr: 0.001875  Loss: 1.1503  Acc@1: 62.5000 (53.7214)  Acc@5: 93.7500 (87.8817)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 140/3750]  eta: 0:20:56  Lr: 0.001875  Loss: 1.0369  Acc@1: 68.7500 (54.9645)  Acc@5: 93.7500 (88.2979)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 150/3750]  eta: 0:20:52  Lr: 0.001875  Loss: 1.4206  Acc@1: 68.7500 (55.7533)  Acc@5: 93.7500 (88.7003)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 160/3750]  eta: 0:20:47  Lr: 0.001875  Loss: 1.0196  Acc@1: 68.7500 (56.7158)  Acc@5: 100.0000 (89.0916)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 170/3750]  eta: 0:20:44  Lr: 0.001875  Loss: 1.5708  Acc@1: 68.7500 (57.2003)  Acc@5: 93.7500 (89.4371)  time: 0.3455  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:40  Lr: 0.001875  Loss: 0.9939  Acc@1: 68.7500 (58.1837)  Acc@5: 93.7500 (89.6754)  time: 0.3465  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:36  Lr: 0.001875  Loss: 1.3740  Acc@1: 68.7500 (58.4097)  Acc@5: 93.7500 (89.6924)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:32  Lr: 0.001875  Loss: 1.0198  Acc@1: 68.7500 (59.1107)  Acc@5: 93.7500 (90.0808)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:28  Lr: 0.001875  Loss: 0.8614  Acc@1: 68.7500 (59.6564)  Acc@5: 93.7500 (90.2547)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:25  Lr: 0.001875  Loss: 1.1830  Acc@1: 68.7500 (60.1527)  Acc@5: 93.7500 (90.4412)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:21  Lr: 0.001875  Loss: 1.1133  Acc@1: 68.7500 (60.4978)  Acc@5: 93.7500 (90.4221)  time: 0.3470  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:18  Lr: 0.001875  Loss: 1.2248  Acc@1: 68.7500 (60.7624)  Acc@5: 93.7500 (90.5602)  time: 0.3477  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:15  Lr: 0.001875  Loss: 0.9817  Acc@1: 68.7500 (61.3795)  Acc@5: 93.7500 (90.6624)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:11  Lr: 0.001875  Loss: 0.8437  Acc@1: 75.0000 (61.9492)  Acc@5: 93.7500 (90.8764)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:07  Lr: 0.001875  Loss: 0.8198  Acc@1: 75.0000 (62.2694)  Acc@5: 100.0000 (91.1208)  time: 0.3456  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:04  Lr: 0.001875  Loss: 1.2444  Acc@1: 68.7500 (62.3443)  Acc@5: 93.7500 (91.1922)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:00  Lr: 0.001875  Loss: 1.0113  Acc@1: 62.5000 (62.5215)  Acc@5: 93.7500 (91.2586)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 300/3750]  eta: 0:19:57  Lr: 0.001875  Loss: 0.9165  Acc@1: 68.7500 (62.8530)  Acc@5: 93.7500 (91.2998)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 310/3750]  eta: 0:19:53  Lr: 0.001875  Loss: 0.5073  Acc@1: 68.7500 (63.1431)  Acc@5: 93.7500 (91.4389)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 320/3750]  eta: 0:19:49  Lr: 0.001875  Loss: 1.0741  Acc@1: 75.0000 (63.4735)  Acc@5: 93.7500 (91.5693)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 330/3750]  eta: 0:19:46  Lr: 0.001875  Loss: 1.0803  Acc@1: 75.0000 (63.6329)  Acc@5: 93.7500 (91.6163)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:42  Lr: 0.001875  Loss: 0.9060  Acc@1: 75.0000 (63.8746)  Acc@5: 93.7500 (91.6056)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:39  Lr: 0.001875  Loss: 1.1306  Acc@1: 68.7500 (64.0670)  Acc@5: 93.7500 (91.7023)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:35  Lr: 0.001875  Loss: 1.5574  Acc@1: 68.7500 (64.1620)  Acc@5: 93.7500 (91.7244)  time: 0.3463  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:31  Lr: 0.001875  Loss: 1.1796  Acc@1: 68.7500 (64.3194)  Acc@5: 93.7500 (91.7621)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:28  Lr: 0.001875  Loss: 0.5302  Acc@1: 68.7500 (64.5669)  Acc@5: 93.7500 (91.8307)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:24  Lr: 0.001875  Loss: 0.3513  Acc@1: 68.7500 (64.7698)  Acc@5: 93.7500 (91.8958)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:21  Lr: 0.001875  Loss: 1.2297  Acc@1: 75.0000 (65.0405)  Acc@5: 93.7500 (91.9732)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:17  Lr: 0.001875  Loss: 1.2389  Acc@1: 75.0000 (65.2220)  Acc@5: 93.7500 (92.0773)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:14  Lr: 0.001875  Loss: 0.8389  Acc@1: 75.0000 (65.4394)  Acc@5: 93.7500 (92.1615)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:10  Lr: 0.001875  Loss: 0.8059  Acc@1: 75.0000 (65.5452)  Acc@5: 93.7500 (92.1404)  time: 0.3463  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:07  Lr: 0.001875  Loss: 0.8342  Acc@1: 68.7500 (65.7455)  Acc@5: 93.7500 (92.1910)  time: 0.3457  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:03  Lr: 0.001875  Loss: 0.6084  Acc@1: 75.0000 (65.9229)  Acc@5: 93.7500 (92.2949)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 460/3750]  eta: 0:18:59  Lr: 0.001875  Loss: 0.8827  Acc@1: 75.0000 (66.1198)  Acc@5: 100.0000 (92.3807)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 470/3750]  eta: 0:18:56  Lr: 0.001875  Loss: 1.3620  Acc@1: 68.7500 (66.2420)  Acc@5: 93.7500 (92.3169)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 480/3750]  eta: 0:18:52  Lr: 0.001875  Loss: 1.2103  Acc@1: 75.0000 (66.5541)  Acc@5: 93.7500 (92.3597)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 490/3750]  eta: 0:18:49  Lr: 0.001875  Loss: 1.2380  Acc@1: 75.0000 (66.5860)  Acc@5: 93.7500 (92.4134)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:46  Lr: 0.001875  Loss: 0.6159  Acc@1: 62.5000 (66.6292)  Acc@5: 93.7500 (92.4401)  time: 0.3469  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:42  Lr: 0.001875  Loss: 0.8580  Acc@1: 68.7500 (66.7931)  Acc@5: 93.7500 (92.4658)  time: 0.3467  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:39  Lr: 0.001875  Loss: 0.6562  Acc@1: 75.0000 (66.9146)  Acc@5: 93.7500 (92.4784)  time: 0.3472  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:35  Lr: 0.001875  Loss: 0.8337  Acc@1: 75.0000 (67.1022)  Acc@5: 93.7500 (92.5494)  time: 0.3475  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:32  Lr: 0.001875  Loss: 1.1823  Acc@1: 75.0000 (67.2713)  Acc@5: 100.0000 (92.6294)  time: 0.3460  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:29  Lr: 0.001875  Loss: 0.6477  Acc@1: 75.0000 (67.2527)  Acc@5: 93.7500 (92.6384)  time: 0.3488  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:25  Lr: 0.001875  Loss: 0.7275  Acc@1: 75.0000 (67.3908)  Acc@5: 93.7500 (92.7028)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:22  Lr: 0.001875  Loss: 0.6228  Acc@1: 75.0000 (67.5131)  Acc@5: 100.0000 (92.7211)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:18  Lr: 0.001875  Loss: 1.2021  Acc@1: 68.7500 (67.5344)  Acc@5: 93.7500 (92.7603)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:14  Lr: 0.001875  Loss: 0.7794  Acc@1: 68.7500 (67.6925)  Acc@5: 93.7500 (92.8088)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:11  Lr: 0.001875  Loss: 0.7455  Acc@1: 68.7500 (67.7101)  Acc@5: 93.7500 (92.8349)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:07  Lr: 0.001875  Loss: 0.5539  Acc@1: 68.7500 (67.7578)  Acc@5: 93.7500 (92.8703)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:04  Lr: 0.001875  Loss: 0.8486  Acc@1: 68.7500 (67.7436)  Acc@5: 93.7500 (92.8945)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:00  Lr: 0.001875  Loss: 0.8452  Acc@1: 68.7500 (67.8586)  Acc@5: 93.7500 (92.8883)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 640/3750]  eta: 0:17:57  Lr: 0.001875  Loss: 0.9682  Acc@1: 68.7500 (67.7847)  Acc@5: 87.5000 (92.8140)  time: 0.3454  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 650/3750]  eta: 0:17:53  Lr: 0.001875  Loss: 1.0719  Acc@1: 68.7500 (67.9435)  Acc@5: 93.7500 (92.8667)  time: 0.3445  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 660/3750]  eta: 0:17:50  Lr: 0.001875  Loss: 0.9226  Acc@1: 75.0000 (68.0503)  Acc@5: 100.0000 (92.9179)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:46  Lr: 0.001875  Loss: 0.7540  Acc@1: 75.0000 (68.1446)  Acc@5: 100.0000 (92.9769)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:43  Lr: 0.001875  Loss: 0.8840  Acc@1: 75.0000 (68.2085)  Acc@5: 93.7500 (92.9699)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:39  Lr: 0.001875  Loss: 0.9318  Acc@1: 68.7500 (68.2254)  Acc@5: 93.7500 (92.9721)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:36  Lr: 0.001875  Loss: 0.7111  Acc@1: 68.7500 (68.2507)  Acc@5: 93.7500 (92.9832)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:32  Lr: 0.001875  Loss: 0.6748  Acc@1: 75.0000 (68.4160)  Acc@5: 93.7500 (93.0292)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:29  Lr: 0.001875  Loss: 1.0135  Acc@1: 75.0000 (68.4726)  Acc@5: 93.7500 (93.0479)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:25  Lr: 0.001875  Loss: 0.4384  Acc@1: 68.7500 (68.5021)  Acc@5: 93.7500 (93.0489)  time: 0.3453  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:22  Lr: 0.001875  Loss: 0.7880  Acc@1: 75.0000 (68.6150)  Acc@5: 93.7500 (93.1005)  time: 0.3456  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:18  Lr: 0.001875  Loss: 0.7109  Acc@1: 75.0000 (68.7084)  Acc@5: 93.7500 (93.0925)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:15  Lr: 0.001875  Loss: 0.4297  Acc@1: 81.2500 (68.8075)  Acc@5: 93.7500 (93.0930)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:11  Lr: 0.001875  Loss: 0.6970  Acc@1: 75.0000 (68.9202)  Acc@5: 93.7500 (93.1501)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:08  Lr: 0.001875  Loss: 1.3411  Acc@1: 75.0000 (68.9901)  Acc@5: 100.0000 (93.2058)  time: 0.3465  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:04  Lr: 0.001875  Loss: 0.4653  Acc@1: 75.0000 (69.0028)  Acc@5: 93.7500 (93.2285)  time: 0.3455  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:01  Lr: 0.001875  Loss: 0.3368  Acc@1: 68.7500 (69.0855)  Acc@5: 93.7500 (93.2584)  time: 0.3450  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 810/3750]  eta: 0:16:57  Lr: 0.001875  Loss: 1.0960  Acc@1: 68.7500 (69.1507)  Acc@5: 93.7500 (93.2414)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 820/3750]  eta: 0:16:54  Lr: 0.001875  Loss: 0.4964  Acc@1: 81.2500 (69.2905)  Acc@5: 93.7500 (93.2704)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 830/3750]  eta: 0:16:50  Lr: 0.001875  Loss: 0.6539  Acc@1: 75.0000 (69.2840)  Acc@5: 93.7500 (93.2536)  time: 0.3463  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:47  Lr: 0.001875  Loss: 0.8156  Acc@1: 68.7500 (69.3222)  Acc@5: 93.7500 (93.2744)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:43  Lr: 0.001875  Loss: 0.8011  Acc@1: 68.7500 (69.4183)  Acc@5: 93.7500 (93.3020)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:40  Lr: 0.001875  Loss: 0.6921  Acc@1: 75.0000 (69.4541)  Acc@5: 93.7500 (93.3217)  time: 0.3458  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:36  Lr: 0.001875  Loss: 0.9338  Acc@1: 75.0000 (69.4819)  Acc@5: 93.7500 (93.3410)  time: 0.3467  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:33  Lr: 0.001875  Loss: 0.5825  Acc@1: 75.0000 (69.5375)  Acc@5: 100.0000 (93.3740)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:29  Lr: 0.001875  Loss: 0.6678  Acc@1: 75.0000 (69.6409)  Acc@5: 100.0000 (93.4273)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:26  Lr: 0.001875  Loss: 0.8551  Acc@1: 75.0000 (69.7003)  Acc@5: 100.0000 (93.4309)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:23  Lr: 0.001875  Loss: 0.4466  Acc@1: 75.0000 (69.7654)  Acc@5: 93.7500 (93.4550)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:19  Lr: 0.001875  Loss: 0.9830  Acc@1: 75.0000 (69.8154)  Acc@5: 93.7500 (93.4786)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:16  Lr: 0.001875  Loss: 0.5375  Acc@1: 68.7500 (69.8980)  Acc@5: 93.7500 (93.4949)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:12  Lr: 0.001875  Loss: 0.5600  Acc@1: 75.0000 (69.9987)  Acc@5: 93.7500 (93.4976)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:09  Lr: 0.001875  Loss: 1.1899  Acc@1: 75.0000 (70.0775)  Acc@5: 93.7500 (93.5266)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:05  Lr: 0.001875  Loss: 1.0173  Acc@1: 81.2500 (70.1938)  Acc@5: 100.0000 (93.5549)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:02  Lr: 0.001875  Loss: 0.7775  Acc@1: 75.0000 (70.2304)  Acc@5: 93.7500 (93.5698)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 980/3750]  eta: 0:15:58  Lr: 0.001875  Loss: 0.9690  Acc@1: 75.0000 (70.2791)  Acc@5: 93.7500 (93.5907)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 990/3750]  eta: 0:15:55  Lr: 0.001875  Loss: 0.6647  Acc@1: 75.0000 (70.3330)  Acc@5: 93.7500 (93.6113)  time: 0.3475  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1000/3750]  eta: 0:15:51  Lr: 0.001875  Loss: 0.8997  Acc@1: 75.0000 (70.3796)  Acc@5: 93.7500 (93.6126)  time: 0.3476  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:48  Lr: 0.001875  Loss: 0.7371  Acc@1: 75.0000 (70.3697)  Acc@5: 93.7500 (93.5955)  time: 0.3467  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:44  Lr: 0.001875  Loss: 0.6994  Acc@1: 75.0000 (70.4334)  Acc@5: 93.7500 (93.6337)  time: 0.3463  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:41  Lr: 0.001875  Loss: 0.5566  Acc@1: 75.0000 (70.4959)  Acc@5: 100.0000 (93.6348)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:37  Lr: 0.001875  Loss: 0.7597  Acc@1: 75.0000 (70.5752)  Acc@5: 93.7500 (93.6539)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:34  Lr: 0.001875  Loss: 0.5257  Acc@1: 75.0000 (70.6054)  Acc@5: 100.0000 (93.6846)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:31  Lr: 0.001875  Loss: 0.6852  Acc@1: 75.0000 (70.6115)  Acc@5: 100.0000 (93.6911)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:27  Lr: 0.001875  Loss: 0.5023  Acc@1: 75.0000 (70.6466)  Acc@5: 93.7500 (93.7208)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:24  Lr: 0.001875  Loss: 0.3019  Acc@1: 68.7500 (70.6522)  Acc@5: 100.0000 (93.7558)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:20  Lr: 0.001875  Loss: 0.1812  Acc@1: 68.7500 (70.7149)  Acc@5: 100.0000 (93.7672)  time: 0.3469  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:17  Lr: 0.001875  Loss: 0.8833  Acc@1: 75.0000 (70.7312)  Acc@5: 93.7500 (93.7727)  time: 0.3466  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:13  Lr: 0.001875  Loss: 0.6124  Acc@1: 75.0000 (70.8146)  Acc@5: 93.7500 (93.7950)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:10  Lr: 0.001875  Loss: 0.8942  Acc@1: 81.2500 (70.8854)  Acc@5: 93.7500 (93.8113)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:06  Lr: 0.001875  Loss: 0.7381  Acc@1: 81.2500 (70.9715)  Acc@5: 100.0000 (93.8384)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:03  Lr: 0.001875  Loss: 0.9310  Acc@1: 75.0000 (70.9849)  Acc@5: 93.7500 (93.8486)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1150/3750]  eta: 0:14:59  Lr: 0.001875  Loss: 0.9679  Acc@1: 75.0000 (71.0361)  Acc@5: 93.7500 (93.8695)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1160/3750]  eta: 0:14:56  Lr: 0.001875  Loss: 0.7168  Acc@1: 75.0000 (71.0325)  Acc@5: 93.7500 (93.8738)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1170/3750]  eta: 0:14:53  Lr: 0.001875  Loss: 0.9106  Acc@1: 75.0000 (71.0771)  Acc@5: 93.7500 (93.8834)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:49  Lr: 0.001875  Loss: 0.7995  Acc@1: 75.0000 (71.1315)  Acc@5: 93.7500 (93.8982)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:46  Lr: 0.001875  Loss: 1.1007  Acc@1: 75.0000 (71.1639)  Acc@5: 93.7500 (93.9127)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:42  Lr: 0.001875  Loss: 0.8103  Acc@1: 81.2500 (71.2687)  Acc@5: 93.7500 (93.9269)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:39  Lr: 0.001875  Loss: 0.8411  Acc@1: 81.2500 (71.2789)  Acc@5: 93.7500 (93.9358)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:35  Lr: 0.001875  Loss: 0.5431  Acc@1: 75.0000 (71.3350)  Acc@5: 93.7500 (93.9548)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:32  Lr: 0.001875  Loss: 0.7485  Acc@1: 81.2500 (71.3698)  Acc@5: 93.7500 (93.9480)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:28  Lr: 0.001875  Loss: 0.7137  Acc@1: 81.2500 (71.4041)  Acc@5: 93.7500 (93.9817)  time: 0.3447  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:25  Lr: 0.001875  Loss: 1.3251  Acc@1: 75.0000 (71.3829)  Acc@5: 100.0000 (93.9898)  time: 0.3455  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:21  Lr: 0.001875  Loss: 0.7632  Acc@1: 75.0000 (71.4413)  Acc@5: 93.7500 (94.0077)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:18  Lr: 0.001875  Loss: 0.6419  Acc@1: 81.2500 (71.4742)  Acc@5: 93.7500 (94.0155)  time: 0.3461  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:14  Lr: 0.001875  Loss: 0.3898  Acc@1: 81.2500 (71.5505)  Acc@5: 93.7500 (94.0232)  time: 0.3470  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:11  Lr: 0.001875  Loss: 0.9398  Acc@1: 75.0000 (71.5627)  Acc@5: 93.7500 (94.0259)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:07  Lr: 0.001875  Loss: 1.0496  Acc@1: 75.0000 (71.6324)  Acc@5: 93.7500 (94.0430)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:04  Lr: 0.001875  Loss: 0.6128  Acc@1: 81.2500 (71.6867)  Acc@5: 100.0000 (94.0599)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:01  Lr: 0.001875  Loss: 0.6519  Acc@1: 81.2500 (71.7307)  Acc@5: 93.7500 (94.0670)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1330/3750]  eta: 0:13:57  Lr: 0.001875  Loss: 1.2331  Acc@1: 75.0000 (71.7787)  Acc@5: 93.7500 (94.0834)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1340/3750]  eta: 0:13:53  Lr: 0.001875  Loss: 0.5075  Acc@1: 75.0000 (71.7934)  Acc@5: 93.7500 (94.0996)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:50  Lr: 0.001875  Loss: 0.8603  Acc@1: 75.0000 (71.8079)  Acc@5: 93.7500 (94.0877)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:47  Lr: 0.001875  Loss: 0.8204  Acc@1: 75.0000 (71.8452)  Acc@5: 93.7500 (94.1036)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:43  Lr: 0.001875  Loss: 0.6719  Acc@1: 75.0000 (71.8727)  Acc@5: 100.0000 (94.1147)  time: 0.3437  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:40  Lr: 0.001875  Loss: 0.6868  Acc@1: 75.0000 (71.8908)  Acc@5: 100.0000 (94.1347)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:36  Lr: 0.001875  Loss: 0.7987  Acc@1: 75.0000 (71.9177)  Acc@5: 100.0000 (94.1409)  time: 0.3466  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:33  Lr: 0.001875  Loss: 0.4073  Acc@1: 75.0000 (71.9218)  Acc@5: 93.7500 (94.1381)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:29  Lr: 0.001875  Loss: 0.6503  Acc@1: 75.0000 (71.9569)  Acc@5: 93.7500 (94.1442)  time: 0.3450  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:26  Lr: 0.001875  Loss: 1.2079  Acc@1: 81.2500 (71.9784)  Acc@5: 93.7500 (94.1502)  time: 0.3444  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:22  Lr: 0.001875  Loss: 0.4955  Acc@1: 75.0000 (72.0082)  Acc@5: 93.7500 (94.1737)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:19  Lr: 0.001875  Loss: 0.8160  Acc@1: 75.0000 (72.0116)  Acc@5: 100.0000 (94.1924)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:15  Lr: 0.001875  Loss: 0.5659  Acc@1: 81.2500 (72.0624)  Acc@5: 100.0000 (94.2195)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:12  Lr: 0.001875  Loss: 0.4440  Acc@1: 81.2500 (72.1210)  Acc@5: 100.0000 (94.2377)  time: 0.3441  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:08  Lr: 0.001875  Loss: 0.4869  Acc@1: 81.2500 (72.1958)  Acc@5: 100.0000 (94.2599)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:05  Lr: 0.001875  Loss: 0.5698  Acc@1: 81.2500 (72.2569)  Acc@5: 93.7500 (94.2649)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:01  Lr: 0.001875  Loss: 0.8737  Acc@1: 81.2500 (72.3089)  Acc@5: 100.0000 (94.2949)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1500/3750]  eta: 0:12:58  Lr: 0.001875  Loss: 0.9325  Acc@1: 81.2500 (72.3476)  Acc@5: 100.0000 (94.3038)  time: 0.3447  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1510/3750]  eta: 0:12:54  Lr: 0.001875  Loss: 0.6646  Acc@1: 81.2500 (72.3776)  Acc@5: 93.7500 (94.3084)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1520/3750]  eta: 0:12:51  Lr: 0.001875  Loss: 0.8204  Acc@1: 75.0000 (72.3907)  Acc@5: 93.7500 (94.3253)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:47  Lr: 0.001875  Loss: 1.1433  Acc@1: 75.0000 (72.4159)  Acc@5: 93.7500 (94.3297)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:44  Lr: 0.001875  Loss: 0.3060  Acc@1: 75.0000 (72.4408)  Acc@5: 93.7500 (94.3462)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:41  Lr: 0.001875  Loss: 1.2462  Acc@1: 75.0000 (72.4694)  Acc@5: 93.7500 (94.3504)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:37  Lr: 0.001875  Loss: 0.5219  Acc@1: 75.0000 (72.5336)  Acc@5: 100.0000 (94.3626)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:34  Lr: 0.001875  Loss: 0.3259  Acc@1: 81.2500 (72.5812)  Acc@5: 100.0000 (94.3786)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:30  Lr: 0.001875  Loss: 0.8205  Acc@1: 81.2500 (72.5846)  Acc@5: 93.7500 (94.3707)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:27  Lr: 0.001875  Loss: 0.6717  Acc@1: 75.0000 (72.6116)  Acc@5: 93.7500 (94.3825)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:23  Lr: 0.001875  Loss: 0.7028  Acc@1: 75.0000 (72.6304)  Acc@5: 100.0000 (94.3980)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:20  Lr: 0.001875  Loss: 0.8339  Acc@1: 75.0000 (72.6373)  Acc@5: 93.7500 (94.4056)  time: 0.3441  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:16  Lr: 0.001875  Loss: 1.0718  Acc@1: 68.7500 (72.6172)  Acc@5: 93.7500 (94.4055)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:13  Lr: 0.001875  Loss: 1.2119  Acc@1: 75.0000 (72.6357)  Acc@5: 93.7500 (94.4206)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:09  Lr: 0.001875  Loss: 0.6966  Acc@1: 75.0000 (72.6577)  Acc@5: 93.7500 (94.4279)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:06  Lr: 0.001875  Loss: 0.6221  Acc@1: 75.0000 (72.6719)  Acc@5: 100.0000 (94.4390)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:02  Lr: 0.001875  Loss: 0.5400  Acc@1: 75.0000 (72.7009)  Acc@5: 100.0000 (94.4499)  time: 0.3450  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1670/3750]  eta: 0:11:59  Lr: 0.001875  Loss: 0.5663  Acc@1: 75.0000 (72.7297)  Acc@5: 93.7500 (94.4382)  time: 0.3460  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1680/3750]  eta: 0:11:55  Lr: 0.001875  Loss: 0.5953  Acc@1: 75.0000 (72.7543)  Acc@5: 93.7500 (94.4453)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1690/3750]  eta: 0:11:52  Lr: 0.001875  Loss: 0.3404  Acc@1: 81.2500 (72.7824)  Acc@5: 93.7500 (94.4486)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:48  Lr: 0.001875  Loss: 0.6840  Acc@1: 81.2500 (72.8469)  Acc@5: 93.7500 (94.4555)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:45  Lr: 0.001875  Loss: 0.5198  Acc@1: 81.2500 (72.8996)  Acc@5: 100.0000 (94.4696)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:42  Lr: 0.001875  Loss: 0.9961  Acc@1: 75.0000 (72.9264)  Acc@5: 93.7500 (94.4691)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:38  Lr: 0.001875  Loss: 1.0462  Acc@1: 81.2500 (72.9636)  Acc@5: 100.0000 (94.4938)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:35  Lr: 0.001875  Loss: 0.4012  Acc@1: 81.2500 (73.0112)  Acc@5: 100.0000 (94.5003)  time: 0.3463  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:31  Lr: 0.001875  Loss: 0.6154  Acc@1: 81.2500 (73.0832)  Acc@5: 100.0000 (94.5138)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:28  Lr: 0.001875  Loss: 0.3910  Acc@1: 81.2500 (73.0835)  Acc@5: 100.0000 (94.5237)  time: 0.3455  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:24  Lr: 0.001875  Loss: 0.5598  Acc@1: 75.0000 (73.0943)  Acc@5: 100.0000 (94.5335)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:21  Lr: 0.001875  Loss: 0.3815  Acc@1: 75.0000 (73.1120)  Acc@5: 100.0000 (94.5501)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:17  Lr: 0.001875  Loss: 1.0227  Acc@1: 75.0000 (73.1435)  Acc@5: 100.0000 (94.5701)  time: 0.3462  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:14  Lr: 0.001875  Loss: 0.4540  Acc@1: 81.2500 (73.2024)  Acc@5: 100.0000 (94.5863)  time: 0.3458  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:10  Lr: 0.001875  Loss: 0.3581  Acc@1: 81.2500 (73.2123)  Acc@5: 93.7500 (94.5783)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:07  Lr: 0.001875  Loss: 0.6421  Acc@1: 75.0000 (73.2324)  Acc@5: 93.7500 (94.5840)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:03  Lr: 0.001875  Loss: 0.3485  Acc@1: 75.0000 (73.2489)  Acc@5: 93.7500 (94.5897)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:00  Lr: 0.001875  Loss: 0.6749  Acc@1: 81.2500 (73.2890)  Acc@5: 93.7500 (94.5953)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1850/3750]  eta: 0:10:57  Lr: 0.001875  Loss: 0.5148  Acc@1: 75.0000 (73.2780)  Acc@5: 93.7500 (94.6110)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1860/3750]  eta: 0:10:53  Lr: 0.001875  Loss: 0.9198  Acc@1: 68.7500 (73.2503)  Acc@5: 93.7500 (94.6098)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:50  Lr: 0.001875  Loss: 0.4253  Acc@1: 75.0000 (73.2863)  Acc@5: 93.7500 (94.6185)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:46  Lr: 0.001875  Loss: 0.4784  Acc@1: 75.0000 (73.2955)  Acc@5: 100.0000 (94.6338)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:43  Lr: 0.001875  Loss: 1.1942  Acc@1: 75.0000 (73.3144)  Acc@5: 100.0000 (94.6391)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:39  Lr: 0.001875  Loss: 0.3982  Acc@1: 81.2500 (73.3561)  Acc@5: 93.7500 (94.6443)  time: 0.3477  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:36  Lr: 0.001875  Loss: 0.5082  Acc@1: 75.0000 (73.3484)  Acc@5: 93.7500 (94.6429)  time: 0.3483  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:32  Lr: 0.001875  Loss: 1.1776  Acc@1: 75.0000 (73.3667)  Acc@5: 93.7500 (94.6350)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:29  Lr: 0.001875  Loss: 0.6704  Acc@1: 81.2500 (73.3817)  Acc@5: 93.7500 (94.6466)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:26  Lr: 0.001875  Loss: 0.4346  Acc@1: 75.0000 (73.3771)  Acc@5: 100.0000 (94.6516)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:22  Lr: 0.001875  Loss: 0.3763  Acc@1: 75.0000 (73.4079)  Acc@5: 93.7500 (94.6630)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:19  Lr: 0.001875  Loss: 0.8089  Acc@1: 75.0000 (73.4255)  Acc@5: 100.0000 (94.6743)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:15  Lr: 0.001875  Loss: 0.7586  Acc@1: 81.2500 (73.4748)  Acc@5: 100.0000 (94.6791)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:12  Lr: 0.001875  Loss: 0.8129  Acc@1: 81.2500 (73.5014)  Acc@5: 93.7500 (94.6839)  time: 0.3460  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:08  Lr: 0.001875  Loss: 0.9163  Acc@1: 75.0000 (73.4869)  Acc@5: 93.7500 (94.6823)  time: 0.3462  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:05  Lr: 0.001875  Loss: 0.8435  Acc@1: 75.0000 (73.5195)  Acc@5: 93.7500 (94.6839)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:01  Lr: 0.001875  Loss: 0.8820  Acc@1: 75.0000 (73.5424)  Acc@5: 93.7500 (94.6855)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2020/3750]  eta: 0:09:58  Lr: 0.001875  Loss: 0.3197  Acc@1: 81.2500 (73.5805)  Acc@5: 93.7500 (94.6932)  time: 0.3456  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2030/3750]  eta: 0:09:54  Lr: 0.001875  Loss: 0.8539  Acc@1: 81.2500 (73.5814)  Acc@5: 93.7500 (94.6978)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:51  Lr: 0.001875  Loss: 0.9804  Acc@1: 75.0000 (73.6098)  Acc@5: 93.7500 (94.7085)  time: 0.3461  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:47  Lr: 0.001875  Loss: 0.4387  Acc@1: 81.2500 (73.6287)  Acc@5: 100.0000 (94.7221)  time: 0.3461  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:44  Lr: 0.001875  Loss: 0.6630  Acc@1: 75.0000 (73.5990)  Acc@5: 93.7500 (94.7234)  time: 0.3453  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:41  Lr: 0.001875  Loss: 0.6248  Acc@1: 75.0000 (73.6178)  Acc@5: 93.7500 (94.7248)  time: 0.3451  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:37  Lr: 0.001875  Loss: 0.5600  Acc@1: 75.0000 (73.6305)  Acc@5: 100.0000 (94.7471)  time: 0.3462  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:34  Lr: 0.001875  Loss: 0.7481  Acc@1: 75.0000 (73.6370)  Acc@5: 100.0000 (94.7453)  time: 0.3457  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:30  Lr: 0.001875  Loss: 0.4603  Acc@1: 75.0000 (73.6495)  Acc@5: 93.7500 (94.7525)  time: 0.3442  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:27  Lr: 0.001875  Loss: 0.4962  Acc@1: 75.0000 (73.6884)  Acc@5: 93.7500 (94.7507)  time: 0.3443  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:23  Lr: 0.001875  Loss: 1.3417  Acc@1: 75.0000 (73.7005)  Acc@5: 93.7500 (94.7519)  time: 0.3455  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:20  Lr: 0.001875  Loss: 0.5551  Acc@1: 81.2500 (73.7242)  Acc@5: 93.7500 (94.7560)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:16  Lr: 0.001875  Loss: 0.6346  Acc@1: 81.2500 (73.7564)  Acc@5: 93.7500 (94.7484)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:13  Lr: 0.001875  Loss: 0.4551  Acc@1: 75.0000 (73.7680)  Acc@5: 93.7500 (94.7553)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:09  Lr: 0.001875  Loss: 0.5548  Acc@1: 75.0000 (73.7824)  Acc@5: 100.0000 (94.7652)  time: 0.3453  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:06  Lr: 0.001875  Loss: 0.3621  Acc@1: 81.2500 (73.8197)  Acc@5: 100.0000 (94.7778)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:02  Lr: 0.001875  Loss: 0.8262  Acc@1: 81.2500 (73.8279)  Acc@5: 100.0000 (94.7874)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2190/3750]  eta: 0:08:59  Lr: 0.001875  Loss: 0.1605  Acc@1: 75.0000 (73.8618)  Acc@5: 100.0000 (94.7997)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2200/3750]  eta: 0:08:56  Lr: 0.001875  Loss: 0.5360  Acc@1: 81.2500 (73.8982)  Acc@5: 100.0000 (94.8177)  time: 0.3467  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:52  Lr: 0.001875  Loss: 0.8205  Acc@1: 81.2500 (73.9230)  Acc@5: 100.0000 (94.8213)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:49  Lr: 0.001875  Loss: 0.7490  Acc@1: 81.2500 (73.9475)  Acc@5: 100.0000 (94.8278)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:45  Lr: 0.001875  Loss: 0.7386  Acc@1: 75.0000 (73.9663)  Acc@5: 100.0000 (94.8342)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:42  Lr: 0.001875  Loss: 0.7860  Acc@1: 75.0000 (73.9932)  Acc@5: 93.7500 (94.8405)  time: 0.3477  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:38  Lr: 0.001875  Loss: 0.6165  Acc@1: 81.2500 (74.0476)  Acc@5: 100.0000 (94.8551)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:35  Lr: 0.001875  Loss: 0.8765  Acc@1: 81.2500 (74.0602)  Acc@5: 93.7500 (94.8585)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:31  Lr: 0.001875  Loss: 0.5062  Acc@1: 81.2500 (74.0946)  Acc@5: 93.7500 (94.8701)  time: 0.3473  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:28  Lr: 0.001875  Loss: 0.6613  Acc@1: 75.0000 (74.1013)  Acc@5: 100.0000 (94.8679)  time: 0.3463  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:24  Lr: 0.001875  Loss: 0.7696  Acc@1: 75.0000 (74.1352)  Acc@5: 93.7500 (94.8740)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:21  Lr: 0.001875  Loss: 0.4748  Acc@1: 81.2500 (74.1553)  Acc@5: 93.7500 (94.8772)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:18  Lr: 0.001875  Loss: 0.4670  Acc@1: 81.2500 (74.1778)  Acc@5: 93.7500 (94.8805)  time: 0.3458  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:14  Lr: 0.001875  Loss: 0.3457  Acc@1: 81.2500 (74.1949)  Acc@5: 93.7500 (94.8891)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:11  Lr: 0.001875  Loss: 0.5647  Acc@1: 81.2500 (74.2385)  Acc@5: 100.0000 (94.9029)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:07  Lr: 0.001875  Loss: 0.7450  Acc@1: 81.2500 (74.2498)  Acc@5: 100.0000 (94.9114)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:04  Lr: 0.001875  Loss: 0.5440  Acc@1: 81.2500 (74.2822)  Acc@5: 100.0000 (94.9171)  time: 0.3471  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:00  Lr: 0.001875  Loss: 0.4717  Acc@1: 81.2500 (74.3223)  Acc@5: 93.7500 (94.9227)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2370/3750]  eta: 0:07:57  Lr: 0.001875  Loss: 0.4359  Acc@1: 81.2500 (74.3384)  Acc@5: 100.0000 (94.9336)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:53  Lr: 0.001875  Loss: 0.8824  Acc@1: 75.0000 (74.3569)  Acc@5: 100.0000 (94.9286)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:50  Lr: 0.001875  Loss: 0.5349  Acc@1: 81.2500 (74.3831)  Acc@5: 100.0000 (94.9367)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:46  Lr: 0.001875  Loss: 0.4743  Acc@1: 81.2500 (74.3961)  Acc@5: 100.0000 (94.9448)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:43  Lr: 0.001875  Loss: 0.6257  Acc@1: 81.2500 (74.4349)  Acc@5: 100.0000 (94.9580)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:39  Lr: 0.001875  Loss: 1.8793  Acc@1: 81.2500 (74.4321)  Acc@5: 100.0000 (94.9582)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:36  Lr: 0.001875  Loss: 0.3740  Acc@1: 81.2500 (74.4678)  Acc@5: 100.0000 (94.9635)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:33  Lr: 0.001875  Loss: 1.5273  Acc@1: 81.2500 (74.4726)  Acc@5: 100.0000 (94.9611)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:29  Lr: 0.001875  Loss: 0.6623  Acc@1: 81.2500 (74.5079)  Acc@5: 100.0000 (94.9740)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:26  Lr: 0.001875  Loss: 1.4788  Acc@1: 75.0000 (74.4870)  Acc@5: 100.0000 (94.9766)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:22  Lr: 0.001875  Loss: 0.6829  Acc@1: 75.0000 (74.5093)  Acc@5: 100.0000 (94.9894)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:19  Lr: 0.001875  Loss: 0.6439  Acc@1: 81.2500 (74.5516)  Acc@5: 100.0000 (94.9970)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:15  Lr: 0.001875  Loss: 0.8635  Acc@1: 81.2500 (74.5684)  Acc@5: 100.0000 (95.0020)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:12  Lr: 0.001875  Loss: 1.1471  Acc@1: 81.2500 (74.5902)  Acc@5: 100.0000 (95.0095)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:08  Lr: 0.001875  Loss: 0.3642  Acc@1: 81.2500 (74.6018)  Acc@5: 100.0000 (95.0194)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:05  Lr: 0.001875  Loss: 0.7276  Acc@1: 81.2500 (74.6281)  Acc@5: 100.0000 (95.0218)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:01  Lr: 0.001875  Loss: 0.5534  Acc@1: 81.2500 (74.6419)  Acc@5: 93.7500 (95.0143)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2540/3750]  eta: 0:06:58  Lr: 0.001875  Loss: 0.3576  Acc@1: 81.2500 (74.6655)  Acc@5: 93.7500 (95.0241)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:55  Lr: 0.001875  Loss: 0.4371  Acc@1: 81.2500 (74.6864)  Acc@5: 100.0000 (95.0216)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:51  Lr: 0.001875  Loss: 0.7159  Acc@1: 81.2500 (74.7071)  Acc@5: 100.0000 (95.0288)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:48  Lr: 0.001875  Loss: 0.6080  Acc@1: 81.2500 (74.7107)  Acc@5: 100.0000 (95.0287)  time: 0.3469  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:44  Lr: 0.001875  Loss: 0.7219  Acc@1: 81.2500 (74.7288)  Acc@5: 93.7500 (95.0237)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:41  Lr: 0.001875  Loss: 0.4251  Acc@1: 81.2500 (74.7395)  Acc@5: 93.7500 (95.0285)  time: 0.3448  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:37  Lr: 0.001875  Loss: 0.4813  Acc@1: 81.2500 (74.7621)  Acc@5: 93.7500 (95.0332)  time: 0.3452  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:34  Lr: 0.001875  Loss: 1.0206  Acc@1: 81.2500 (74.7678)  Acc@5: 93.7500 (95.0354)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:30  Lr: 0.001875  Loss: 0.8770  Acc@1: 75.0000 (74.7544)  Acc@5: 93.7500 (95.0353)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:27  Lr: 0.001875  Loss: 1.0870  Acc@1: 68.7500 (74.7624)  Acc@5: 100.0000 (95.0423)  time: 0.3457  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:23  Lr: 0.001875  Loss: 0.8056  Acc@1: 81.2500 (74.7799)  Acc@5: 93.7500 (95.0303)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:20  Lr: 0.001875  Loss: 0.3701  Acc@1: 81.2500 (74.8067)  Acc@5: 100.0000 (95.0396)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:16  Lr: 0.001875  Loss: 0.1723  Acc@1: 81.2500 (74.8285)  Acc@5: 100.0000 (95.0489)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:13  Lr: 0.001875  Loss: 0.5662  Acc@1: 81.2500 (74.8339)  Acc@5: 100.0000 (95.0580)  time: 0.3446  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:10  Lr: 0.001875  Loss: 0.8304  Acc@1: 75.0000 (74.8345)  Acc@5: 93.7500 (95.0578)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:06  Lr: 0.001875  Loss: 0.1820  Acc@1: 75.0000 (74.8490)  Acc@5: 93.7500 (95.0646)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:03  Lr: 0.001875  Loss: 0.3699  Acc@1: 75.0000 (74.8588)  Acc@5: 100.0000 (95.0690)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2710/3750]  eta: 0:05:59  Lr: 0.001875  Loss: 0.8320  Acc@1: 75.0000 (74.8525)  Acc@5: 100.0000 (95.0733)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2720/3750]  eta: 0:05:56  Lr: 0.001875  Loss: 0.5492  Acc@1: 75.0000 (74.8507)  Acc@5: 93.7500 (95.0753)  time: 0.3453  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:52  Lr: 0.001875  Loss: 0.8503  Acc@1: 75.0000 (74.8627)  Acc@5: 100.0000 (95.0888)  time: 0.3464  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:49  Lr: 0.001875  Loss: 0.6239  Acc@1: 75.0000 (74.8677)  Acc@5: 100.0000 (95.0862)  time: 0.3463  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:45  Lr: 0.001875  Loss: 0.5593  Acc@1: 81.2500 (74.8819)  Acc@5: 93.7500 (95.0881)  time: 0.3464  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:42  Lr: 0.001875  Loss: 0.4391  Acc@1: 81.2500 (74.9162)  Acc@5: 93.7500 (95.0969)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:38  Lr: 0.001875  Loss: 0.7359  Acc@1: 81.2500 (74.9188)  Acc@5: 100.0000 (95.1010)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:35  Lr: 0.001875  Loss: 0.8724  Acc@1: 75.0000 (74.9191)  Acc@5: 93.7500 (95.1029)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:32  Lr: 0.001875  Loss: 0.6292  Acc@1: 75.0000 (74.9328)  Acc@5: 93.7500 (95.1003)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:28  Lr: 0.001875  Loss: 0.5448  Acc@1: 81.2500 (74.9487)  Acc@5: 93.7500 (95.1044)  time: 0.3459  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:25  Lr: 0.001875  Loss: 0.4446  Acc@1: 81.2500 (74.9600)  Acc@5: 93.7500 (95.1063)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:21  Lr: 0.001875  Loss: 0.5824  Acc@1: 75.0000 (74.9690)  Acc@5: 100.0000 (95.1148)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:18  Lr: 0.001875  Loss: 0.5716  Acc@1: 68.7500 (74.9558)  Acc@5: 100.0000 (95.1210)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:14  Lr: 0.001875  Loss: 0.2853  Acc@1: 68.7500 (74.9560)  Acc@5: 93.7500 (95.1184)  time: 0.3457  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:11  Lr: 0.001875  Loss: 0.7924  Acc@1: 75.0000 (74.9693)  Acc@5: 93.7500 (95.1136)  time: 0.3446  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:07  Lr: 0.001875  Loss: 0.4820  Acc@1: 81.2500 (75.0087)  Acc@5: 100.0000 (95.1197)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:04  Lr: 0.001875  Loss: 0.6268  Acc@1: 87.5000 (75.0283)  Acc@5: 100.0000 (95.1237)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:00  Lr: 0.001875  Loss: 0.2844  Acc@1: 81.2500 (75.0521)  Acc@5: 100.0000 (95.1211)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2890/3750]  eta: 0:04:57  Lr: 0.001875  Loss: 0.6973  Acc@1: 81.2500 (75.0519)  Acc@5: 100.0000 (95.1228)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:53  Lr: 0.001875  Loss: 0.6905  Acc@1: 75.0000 (75.0646)  Acc@5: 100.0000 (95.1288)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:50  Lr: 0.001875  Loss: 0.5461  Acc@1: 81.2500 (75.0923)  Acc@5: 100.0000 (95.1413)  time: 0.3480  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:47  Lr: 0.001875  Loss: 0.5137  Acc@1: 87.5000 (75.1220)  Acc@5: 100.0000 (95.1515)  time: 0.3463  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:43  Lr: 0.001875  Loss: 1.1542  Acc@1: 81.2500 (75.1365)  Acc@5: 93.7500 (95.1488)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:40  Lr: 0.001875  Loss: 0.6841  Acc@1: 75.0000 (75.1318)  Acc@5: 93.7500 (95.1505)  time: 0.3459  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:36  Lr: 0.001875  Loss: 0.4760  Acc@1: 81.2500 (75.1546)  Acc@5: 100.0000 (95.1563)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:33  Lr: 0.001875  Loss: 0.8540  Acc@1: 75.0000 (75.1583)  Acc@5: 100.0000 (95.1642)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:29  Lr: 0.001875  Loss: 0.5112  Acc@1: 75.0000 (75.1725)  Acc@5: 100.0000 (95.1700)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:26  Lr: 0.001875  Loss: 1.0089  Acc@1: 81.2500 (75.1803)  Acc@5: 93.7500 (95.1610)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:22  Lr: 0.001875  Loss: 0.5444  Acc@1: 75.0000 (75.2006)  Acc@5: 93.7500 (95.1626)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:19  Lr: 0.001875  Loss: 0.5522  Acc@1: 75.0000 (75.1999)  Acc@5: 93.7500 (95.1620)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:15  Lr: 0.001875  Loss: 0.7069  Acc@1: 75.0000 (75.2034)  Acc@5: 93.7500 (95.1677)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:12  Lr: 0.001875  Loss: 0.9216  Acc@1: 75.0000 (75.2090)  Acc@5: 100.0000 (95.1734)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:09  Lr: 0.001875  Loss: 0.5295  Acc@1: 75.0000 (75.2186)  Acc@5: 93.7500 (95.1666)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:05  Lr: 0.001875  Loss: 0.3339  Acc@1: 81.2500 (75.2364)  Acc@5: 100.0000 (95.1763)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:02  Lr: 0.001875  Loss: 0.6455  Acc@1: 75.0000 (75.2335)  Acc@5: 93.7500 (95.1758)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3060/3750]  eta: 0:03:58  Lr: 0.001875  Loss: 0.5602  Acc@1: 75.0000 (75.2511)  Acc@5: 93.7500 (95.1854)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:55  Lr: 0.001875  Loss: 0.9843  Acc@1: 81.2500 (75.2503)  Acc@5: 100.0000 (95.1950)  time: 0.3463  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:51  Lr: 0.001875  Loss: 1.2558  Acc@1: 81.2500 (75.2657)  Acc@5: 100.0000 (95.2004)  time: 0.3478  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:48  Lr: 0.001875  Loss: 0.8752  Acc@1: 81.2500 (75.2851)  Acc@5: 100.0000 (95.2079)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:44  Lr: 0.001875  Loss: 0.6770  Acc@1: 81.2500 (75.3124)  Acc@5: 100.0000 (95.2153)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:41  Lr: 0.001875  Loss: 0.2079  Acc@1: 81.2500 (75.3094)  Acc@5: 100.0000 (95.2246)  time: 0.3475  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:37  Lr: 0.001875  Loss: 1.1131  Acc@1: 75.0000 (75.3164)  Acc@5: 100.0000 (95.2319)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:34  Lr: 0.001875  Loss: 1.0568  Acc@1: 75.0000 (75.3294)  Acc@5: 93.7500 (95.2272)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.6540  Acc@1: 81.2500 (75.3442)  Acc@5: 93.7500 (95.2284)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:27  Lr: 0.001875  Loss: 0.6902  Acc@1: 75.0000 (75.3451)  Acc@5: 93.7500 (95.2297)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:24  Lr: 0.001875  Loss: 0.6218  Acc@1: 75.0000 (75.3460)  Acc@5: 100.0000 (95.2349)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:20  Lr: 0.001875  Loss: 0.2797  Acc@1: 81.2500 (75.3686)  Acc@5: 100.0000 (95.2440)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:17  Lr: 0.001875  Loss: 0.6165  Acc@1: 81.2500 (75.3851)  Acc@5: 100.0000 (95.2491)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:13  Lr: 0.001875  Loss: 1.2697  Acc@1: 75.0000 (75.3859)  Acc@5: 93.7500 (95.2464)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:10  Lr: 0.001875  Loss: 0.1676  Acc@1: 75.0000 (75.3983)  Acc@5: 100.0000 (95.2573)  time: 0.3455  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:06  Lr: 0.001875  Loss: 0.9408  Acc@1: 81.2500 (75.4165)  Acc@5: 100.0000 (95.2604)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:03  Lr: 0.001875  Loss: 0.7032  Acc@1: 75.0000 (75.4114)  Acc@5: 100.0000 (95.2674)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 1.0385  Acc@1: 75.0000 (75.4178)  Acc@5: 100.0000 (95.2724)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:56  Lr: 0.001875  Loss: 0.9875  Acc@1: 81.2500 (75.4474)  Acc@5: 100.0000 (95.2734)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.6401  Acc@1: 87.5000 (75.4691)  Acc@5: 100.0000 (95.2803)  time: 0.3464  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:49  Lr: 0.001875  Loss: 0.3783  Acc@1: 81.2500 (75.4887)  Acc@5: 100.0000 (95.2814)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:46  Lr: 0.001875  Loss: 0.6165  Acc@1: 81.2500 (75.5063)  Acc@5: 93.7500 (95.2729)  time: 0.3459  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:42  Lr: 0.001875  Loss: 0.7041  Acc@1: 81.2500 (75.5258)  Acc@5: 93.7500 (95.2835)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:39  Lr: 0.001875  Loss: 0.3647  Acc@1: 81.2500 (75.5469)  Acc@5: 100.0000 (95.2864)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:35  Lr: 0.001875  Loss: 0.7393  Acc@1: 81.2500 (75.5699)  Acc@5: 93.7500 (95.2874)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:32  Lr: 0.001875  Loss: 0.9423  Acc@1: 81.2500 (75.5644)  Acc@5: 93.7500 (95.2865)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.7285  Acc@1: 75.0000 (75.5740)  Acc@5: 93.7500 (95.2876)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:25  Lr: 0.001875  Loss: 0.3255  Acc@1: 81.2500 (75.5929)  Acc@5: 100.0000 (95.2942)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.6216  Acc@1: 75.0000 (75.5893)  Acc@5: 93.7500 (95.2896)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:18  Lr: 0.001875  Loss: 0.2864  Acc@1: 75.0000 (75.5987)  Acc@5: 93.7500 (95.2887)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.5466  Acc@1: 81.2500 (75.6192)  Acc@5: 100.0000 (95.2953)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:11  Lr: 0.001875  Loss: 0.2317  Acc@1: 81.2500 (75.6378)  Acc@5: 100.0000 (95.3018)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.7070  Acc@1: 81.2500 (75.6618)  Acc@5: 93.7500 (95.2991)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:04  Lr: 0.001875  Loss: 0.3785  Acc@1: 81.2500 (75.6783)  Acc@5: 93.7500 (95.3001)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: 1.0313  Acc@1: 81.2500 (75.6910)  Acc@5: 93.7500 (95.3010)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.6348  Acc@1: 75.0000 (75.6999)  Acc@5: 93.7500 (95.3075)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: 0.4883  Acc@1: 81.2500 (75.7198)  Acc@5: 100.0000 (95.3194)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.8770  Acc@1: 81.2500 (75.7250)  Acc@5: 100.0000 (95.3275)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: 0.5339  Acc@1: 75.0000 (75.7320)  Acc@5: 100.0000 (95.3284)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.7582  Acc@1: 81.2500 (75.7534)  Acc@5: 93.7500 (95.3256)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: 0.7828  Acc@1: 75.0000 (75.7422)  Acc@5: 93.7500 (95.3211)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.5254  Acc@1: 68.7500 (75.7491)  Acc@5: 93.7500 (95.3256)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: 0.7775  Acc@1: 81.2500 (75.7541)  Acc@5: 93.7500 (95.3174)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.2520  Acc@1: 81.2500 (75.7663)  Acc@5: 93.7500 (95.3112)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.4189  Acc@1: 81.2500 (75.7783)  Acc@5: 100.0000 (95.3228)  time: 0.3454  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: 0.2745  Acc@1: 81.2500 (75.7886)  Acc@5: 100.0000 (95.3272)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.6178  Acc@1: 81.2500 (75.8165)  Acc@5: 100.0000 (95.3316)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: 0.9639  Acc@1: 81.2500 (75.8124)  Acc@5: 100.0000 (95.3377)  time: 0.3460  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.6137  Acc@1: 75.0000 (75.8207)  Acc@5: 100.0000 (95.3438)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: 0.8600  Acc@1: 75.0000 (75.8184)  Acc@5: 100.0000 (95.3481)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.2433  Acc@1: 75.0000 (75.8196)  Acc@5: 100.0000 (95.3542)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: 0.3410  Acc@1: 87.5000 (75.8576)  Acc@5: 100.0000 (95.3619)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.9015  Acc@1: 87.5000 (75.8587)  Acc@5: 100.0000 (95.3609)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2942  Acc@1: 81.2500 (75.8842)  Acc@5: 100.0000 (95.3669)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.9525  Acc@1: 81.2500 (75.8956)  Acc@5: 100.0000 (95.3693)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2543  Acc@1: 81.2500 (75.9121)  Acc@5: 100.0000 (95.3718)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.9253  Acc@1: 81.2500 (75.9200)  Acc@5: 93.7500 (95.3673)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.7947  Acc@1: 81.2500 (75.9243)  Acc@5: 93.7500 (95.3715)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5728  Acc@1: 81.2500 (75.9218)  Acc@5: 100.0000 (95.3704)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3155  Acc@1: 81.2500 (75.9381)  Acc@5: 93.7500 (95.3746)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: 0.7490  Acc@1: 75.0000 (75.9355)  Acc@5: 100.0000 (95.3752)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 1.4853  Acc@1: 75.0000 (75.9279)  Acc@5: 93.7500 (95.3742)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 1.0036  Acc@1: 75.0000 (75.9322)  Acc@5: 93.7500 (95.3715)  time: 0.3462  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 0.6998  Acc@1: 81.2500 (75.9432)  Acc@5: 93.7500 (95.3756)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.5507  Acc@1: 81.2500 (75.9626)  Acc@5: 100.0000 (95.3813)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.7243  Acc@1: 87.5000 (75.9836)  Acc@5: 100.0000 (95.3887)  time: 0.3454  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.4876  Acc@1: 81.2500 (75.9927)  Acc@5: 93.7500 (95.3826)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.4363  Acc@1: 81.2500 (76.0017)  Acc@5: 93.7500 (95.3833)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.7963  Acc@1: 81.2500 (76.0024)  Acc@5: 93.7500 (95.3839)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 1.0039  Acc@1: 75.0000 (76.0133)  Acc@5: 100.0000 (95.3850)  time: 0.3449  data: 0.0008  max mem: 2500
Train: Epoch[1/5] Total time: 0:21:37 (0.3460 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.0039  Acc@1: 75.0000 (76.0133)  Acc@5: 100.0000 (95.3850)
Train: Epoch[2/5]  [   0/3750]  eta: 0:49:38  Lr: 0.001875  Loss: 0.5614  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7942  data: 0.4520  max mem: 2500
Train: Epoch[2/5]  [  10/3750]  eta: 0:24:08  Lr: 0.001875  Loss: 0.5736  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.0227)  time: 0.3873  data: 0.0426  max mem: 2500
Train: Epoch[2/5]  [  20/3750]  eta: 0:22:47  Lr: 0.001875  Loss: 0.5146  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (96.4286)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:21  Lr: 0.001875  Loss: 0.6847  Acc@1: 81.2500 (81.4516)  Acc@5: 93.7500 (96.1694)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:05  Lr: 0.001875  Loss: 0.4295  Acc@1: 81.2500 (81.4024)  Acc@5: 93.7500 (95.8841)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [  50/3750]  eta: 0:21:52  Lr: 0.001875  Loss: 1.2156  Acc@1: 75.0000 (80.6373)  Acc@5: 93.7500 (95.4657)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:42  Lr: 0.001875  Loss: 0.7148  Acc@1: 75.0000 (79.7131)  Acc@5: 93.7500 (95.5943)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:35  Lr: 0.001875  Loss: 0.5153  Acc@1: 75.0000 (80.1056)  Acc@5: 93.7500 (95.6866)  time: 0.3450  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:29  Lr: 0.001875  Loss: 0.4710  Acc@1: 81.2500 (80.1698)  Acc@5: 100.0000 (95.9877)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:23  Lr: 0.001875  Loss: 0.5399  Acc@1: 81.2500 (79.9451)  Acc@5: 100.0000 (95.8791)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:17  Lr: 0.001875  Loss: 0.8450  Acc@1: 81.2500 (79.8886)  Acc@5: 100.0000 (96.0396)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:12  Lr: 0.001875  Loss: 0.9263  Acc@1: 81.2500 (79.5045)  Acc@5: 100.0000 (96.0586)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:07  Lr: 0.001875  Loss: 0.5476  Acc@1: 81.2500 (79.3388)  Acc@5: 93.7500 (96.0227)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:02  Lr: 0.001875  Loss: 0.3644  Acc@1: 75.0000 (79.1985)  Acc@5: 93.7500 (96.0878)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 140/3750]  eta: 0:20:58  Lr: 0.001875  Loss: 0.7606  Acc@1: 75.0000 (78.5904)  Acc@5: 93.7500 (95.9663)  time: 0.3445  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 150/3750]  eta: 0:20:54  Lr: 0.001875  Loss: 0.8313  Acc@1: 75.0000 (78.8493)  Acc@5: 100.0000 (96.0265)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 160/3750]  eta: 0:20:50  Lr: 0.001875  Loss: 0.5194  Acc@1: 81.2500 (78.9984)  Acc@5: 100.0000 (96.0404)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:46  Lr: 0.001875  Loss: 0.5278  Acc@1: 81.2500 (79.2763)  Acc@5: 93.7500 (96.0526)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:42  Lr: 0.001875  Loss: 0.3928  Acc@1: 81.2500 (79.4199)  Acc@5: 93.7500 (96.0290)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:38  Lr: 0.001875  Loss: 0.3633  Acc@1: 81.2500 (79.6139)  Acc@5: 100.0000 (96.1387)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:34  Lr: 0.001875  Loss: 0.3925  Acc@1: 81.2500 (79.6331)  Acc@5: 100.0000 (96.2065)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:30  Lr: 0.001875  Loss: 0.2956  Acc@1: 81.2500 (79.7690)  Acc@5: 100.0000 (96.0900)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:26  Lr: 0.001875  Loss: 0.2945  Acc@1: 81.2500 (79.8643)  Acc@5: 93.7500 (96.0973)  time: 0.3444  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:22  Lr: 0.001875  Loss: 0.5839  Acc@1: 81.2500 (79.8160)  Acc@5: 100.0000 (96.1039)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:19  Lr: 0.001875  Loss: 0.4175  Acc@1: 81.2500 (79.8237)  Acc@5: 100.0000 (96.0840)  time: 0.3456  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:15  Lr: 0.001875  Loss: 0.6285  Acc@1: 81.2500 (79.9303)  Acc@5: 100.0000 (96.1404)  time: 0.3460  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:11  Lr: 0.001875  Loss: 0.7023  Acc@1: 81.2500 (79.9090)  Acc@5: 100.0000 (96.1446)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:07  Lr: 0.001875  Loss: 0.3373  Acc@1: 75.0000 (79.9354)  Acc@5: 93.7500 (96.1024)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:04  Lr: 0.001875  Loss: 0.4526  Acc@1: 81.2500 (79.8932)  Acc@5: 100.0000 (96.1521)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:00  Lr: 0.001875  Loss: 0.7101  Acc@1: 81.2500 (79.8325)  Acc@5: 100.0000 (96.1125)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 300/3750]  eta: 0:19:56  Lr: 0.001875  Loss: 0.2454  Acc@1: 81.2500 (79.9003)  Acc@5: 100.0000 (96.1379)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 310/3750]  eta: 0:19:53  Lr: 0.001875  Loss: 0.3986  Acc@1: 81.2500 (79.8432)  Acc@5: 100.0000 (96.1616)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 320/3750]  eta: 0:19:49  Lr: 0.001875  Loss: 1.0713  Acc@1: 75.0000 (79.6340)  Acc@5: 100.0000 (96.1059)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:45  Lr: 0.001875  Loss: 0.4736  Acc@1: 75.0000 (79.6073)  Acc@5: 93.7500 (96.0725)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:42  Lr: 0.001875  Loss: 1.0052  Acc@1: 81.2500 (79.5821)  Acc@5: 93.7500 (96.0594)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:38  Lr: 0.001875  Loss: 0.4904  Acc@1: 81.2500 (79.4694)  Acc@5: 93.7500 (96.0826)  time: 0.3463  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:35  Lr: 0.001875  Loss: 0.9270  Acc@1: 75.0000 (79.3629)  Acc@5: 93.7500 (96.0873)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:31  Lr: 0.001875  Loss: 0.2448  Acc@1: 75.0000 (79.2284)  Acc@5: 93.7500 (96.0916)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:28  Lr: 0.001875  Loss: 0.3838  Acc@1: 81.2500 (79.3471)  Acc@5: 100.0000 (96.1286)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:24  Lr: 0.001875  Loss: 0.2406  Acc@1: 87.5000 (79.5237)  Acc@5: 100.0000 (96.1637)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:21  Lr: 0.001875  Loss: 0.3932  Acc@1: 81.2500 (79.4420)  Acc@5: 100.0000 (96.1502)  time: 0.3458  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:17  Lr: 0.001875  Loss: 1.0648  Acc@1: 75.0000 (79.5164)  Acc@5: 93.7500 (96.1679)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:14  Lr: 0.001875  Loss: 0.4329  Acc@1: 81.2500 (79.5279)  Acc@5: 100.0000 (96.1995)  time: 0.3457  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:10  Lr: 0.001875  Loss: 0.8863  Acc@1: 81.2500 (79.5679)  Acc@5: 100.0000 (96.1717)  time: 0.3464  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:07  Lr: 0.001875  Loss: 0.3528  Acc@1: 81.2500 (79.5918)  Acc@5: 93.7500 (96.1451)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:03  Lr: 0.001875  Loss: 0.8207  Acc@1: 81.2500 (79.5316)  Acc@5: 93.7500 (96.1475)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 460/3750]  eta: 0:18:59  Lr: 0.001875  Loss: 0.3697  Acc@1: 81.2500 (79.5824)  Acc@5: 93.7500 (96.1632)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 470/3750]  eta: 0:18:56  Lr: 0.001875  Loss: 0.4987  Acc@1: 81.2500 (79.5913)  Acc@5: 93.7500 (96.1651)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 480/3750]  eta: 0:18:52  Lr: 0.001875  Loss: 0.5484  Acc@1: 81.2500 (79.6648)  Acc@5: 100.0000 (96.1928)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 490/3750]  eta: 0:18:49  Lr: 0.001875  Loss: 1.0383  Acc@1: 81.2500 (79.5952)  Acc@5: 100.0000 (96.1813)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:45  Lr: 0.001875  Loss: 0.2033  Acc@1: 81.2500 (79.6657)  Acc@5: 93.7500 (96.1327)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:42  Lr: 0.001875  Loss: 1.1812  Acc@1: 75.0000 (79.6111)  Acc@5: 93.7500 (96.1228)  time: 0.3466  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:38  Lr: 0.001875  Loss: 0.6362  Acc@1: 75.0000 (79.6785)  Acc@5: 100.0000 (96.1372)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:35  Lr: 0.001875  Loss: 1.0349  Acc@1: 81.2500 (79.6728)  Acc@5: 93.7500 (96.1040)  time: 0.3460  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:32  Lr: 0.001875  Loss: 0.2339  Acc@1: 81.2500 (79.7250)  Acc@5: 100.0000 (96.1414)  time: 0.3472  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:28  Lr: 0.001875  Loss: 0.7575  Acc@1: 81.2500 (79.7527)  Acc@5: 100.0000 (96.1547)  time: 0.3475  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:25  Lr: 0.001875  Loss: 1.0227  Acc@1: 81.2500 (79.7794)  Acc@5: 100.0000 (96.1453)  time: 0.3469  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:21  Lr: 0.001875  Loss: 0.2494  Acc@1: 81.2500 (79.8052)  Acc@5: 100.0000 (96.1143)  time: 0.3456  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:18  Lr: 0.001875  Loss: 0.6428  Acc@1: 75.0000 (79.7870)  Acc@5: 100.0000 (96.0951)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:14  Lr: 0.001875  Loss: 0.3359  Acc@1: 81.2500 (79.7906)  Acc@5: 100.0000 (96.0977)  time: 0.3468  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:11  Lr: 0.001875  Loss: 0.6110  Acc@1: 81.2500 (79.8357)  Acc@5: 100.0000 (96.0795)  time: 0.3468  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:07  Lr: 0.001875  Loss: 0.2912  Acc@1: 75.0000 (79.7668)  Acc@5: 93.7500 (96.0822)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:04  Lr: 0.001875  Loss: 0.4662  Acc@1: 75.0000 (79.7605)  Acc@5: 100.0000 (96.1051)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:00  Lr: 0.001875  Loss: 0.5470  Acc@1: 75.0000 (79.7246)  Acc@5: 100.0000 (96.0975)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 640/3750]  eta: 0:17:57  Lr: 0.001875  Loss: 0.3055  Acc@1: 81.2500 (79.7972)  Acc@5: 100.0000 (96.1291)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 650/3750]  eta: 0:17:53  Lr: 0.001875  Loss: 0.6101  Acc@1: 81.2500 (79.8291)  Acc@5: 100.0000 (96.1406)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 660/3750]  eta: 0:17:49  Lr: 0.001875  Loss: 0.5568  Acc@1: 87.5000 (79.9168)  Acc@5: 100.0000 (96.1517)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:46  Lr: 0.001875  Loss: 0.2707  Acc@1: 87.5000 (79.9739)  Acc@5: 100.0000 (96.1904)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:43  Lr: 0.001875  Loss: 0.8050  Acc@1: 81.2500 (79.8642)  Acc@5: 100.0000 (96.1546)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:39  Lr: 0.001875  Loss: 0.9496  Acc@1: 75.0000 (79.8752)  Acc@5: 93.7500 (96.1378)  time: 0.3458  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:36  Lr: 0.001875  Loss: 0.1381  Acc@1: 81.2500 (79.9572)  Acc@5: 93.7500 (96.1484)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:32  Lr: 0.001875  Loss: 0.5706  Acc@1: 87.5000 (80.0457)  Acc@5: 100.0000 (96.1586)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:29  Lr: 0.001875  Loss: 0.8234  Acc@1: 87.5000 (80.0884)  Acc@5: 93.7500 (96.1512)  time: 0.3457  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:25  Lr: 0.001875  Loss: 0.7095  Acc@1: 81.2500 (80.1129)  Acc@5: 93.7500 (96.1269)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:22  Lr: 0.001875  Loss: 0.4246  Acc@1: 81.2500 (80.1029)  Acc@5: 93.7500 (96.1201)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:18  Lr: 0.001875  Loss: 0.6909  Acc@1: 81.2500 (80.0932)  Acc@5: 100.0000 (96.1468)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:15  Lr: 0.001875  Loss: 0.6441  Acc@1: 81.2500 (80.1166)  Acc@5: 100.0000 (96.1482)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:11  Lr: 0.001875  Loss: 0.4163  Acc@1: 81.2500 (80.1070)  Acc@5: 100.0000 (96.1576)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:08  Lr: 0.001875  Loss: 0.4054  Acc@1: 75.0000 (80.0976)  Acc@5: 100.0000 (96.1828)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:04  Lr: 0.001875  Loss: 0.3949  Acc@1: 81.2500 (80.1280)  Acc@5: 100.0000 (96.2073)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:01  Lr: 0.001875  Loss: 0.4926  Acc@1: 81.2500 (80.1264)  Acc@5: 100.0000 (96.2235)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 810/3750]  eta: 0:16:57  Lr: 0.001875  Loss: 0.8566  Acc@1: 75.0000 (80.0709)  Acc@5: 100.0000 (96.1930)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 820/3750]  eta: 0:16:54  Lr: 0.001875  Loss: 0.5664  Acc@1: 75.0000 (80.0853)  Acc@5: 100.0000 (96.2089)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 830/3750]  eta: 0:16:50  Lr: 0.001875  Loss: 0.8129  Acc@1: 75.0000 (80.0391)  Acc@5: 93.7500 (96.1793)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:47  Lr: 0.001875  Loss: 0.5008  Acc@1: 81.2500 (80.0386)  Acc@5: 93.7500 (96.1950)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:43  Lr: 0.001875  Loss: 0.4290  Acc@1: 81.2500 (80.0088)  Acc@5: 100.0000 (96.1883)  time: 0.3446  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:40  Lr: 0.001875  Loss: 1.4397  Acc@1: 75.0000 (79.9506)  Acc@5: 93.7500 (96.1600)  time: 0.3456  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:36  Lr: 0.001875  Loss: 0.6475  Acc@1: 81.2500 (79.9943)  Acc@5: 100.0000 (96.1825)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:33  Lr: 0.001875  Loss: 0.6670  Acc@1: 81.2500 (80.0014)  Acc@5: 100.0000 (96.2188)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:29  Lr: 0.001875  Loss: 0.2774  Acc@1: 81.2500 (80.0084)  Acc@5: 100.0000 (96.2191)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:26  Lr: 0.001875  Loss: 0.9143  Acc@1: 75.0000 (79.9112)  Acc@5: 93.7500 (96.2056)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:22  Lr: 0.001875  Loss: 0.8242  Acc@1: 81.2500 (79.9259)  Acc@5: 100.0000 (96.2130)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:19  Lr: 0.001875  Loss: 0.3418  Acc@1: 81.2500 (79.8928)  Acc@5: 100.0000 (96.2134)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:15  Lr: 0.001875  Loss: 0.5443  Acc@1: 75.0000 (79.8738)  Acc@5: 93.7500 (96.2070)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:12  Lr: 0.001875  Loss: 0.6657  Acc@1: 81.2500 (79.8486)  Acc@5: 93.7500 (96.2075)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:08  Lr: 0.001875  Loss: 0.3797  Acc@1: 81.2500 (79.8699)  Acc@5: 93.7500 (96.1948)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:05  Lr: 0.001875  Loss: 0.1428  Acc@1: 81.2500 (79.8907)  Acc@5: 100.0000 (96.2214)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:01  Lr: 0.001875  Loss: 0.3189  Acc@1: 81.2500 (79.9305)  Acc@5: 100.0000 (96.2281)  time: 0.3470  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 980/3750]  eta: 0:15:58  Lr: 0.001875  Loss: 0.6014  Acc@1: 81.2500 (79.9758)  Acc@5: 100.0000 (96.2220)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/3750]  eta: 0:15:54  Lr: 0.001875  Loss: 1.1100  Acc@1: 81.2500 (79.9193)  Acc@5: 93.7500 (96.2159)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1000/3750]  eta: 0:15:51  Lr: 0.001875  Loss: 0.1093  Acc@1: 75.0000 (79.9388)  Acc@5: 93.7500 (96.2225)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:47  Lr: 0.001875  Loss: 0.5549  Acc@1: 81.2500 (79.9332)  Acc@5: 100.0000 (96.2166)  time: 0.3446  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:44  Lr: 0.001875  Loss: 0.7118  Acc@1: 81.2500 (79.8910)  Acc@5: 93.7500 (96.2169)  time: 0.3452  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:40  Lr: 0.001875  Loss: 0.4930  Acc@1: 75.0000 (79.8739)  Acc@5: 93.7500 (96.2112)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:37  Lr: 0.001875  Loss: 0.9088  Acc@1: 75.0000 (79.8631)  Acc@5: 93.7500 (96.1695)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:33  Lr: 0.001875  Loss: 0.6682  Acc@1: 81.2500 (79.9120)  Acc@5: 93.7500 (96.1703)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:30  Lr: 0.001875  Loss: 0.3342  Acc@1: 81.2500 (79.9305)  Acc@5: 93.7500 (96.1652)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:26  Lr: 0.001875  Loss: 0.6315  Acc@1: 81.2500 (79.9020)  Acc@5: 93.7500 (96.1368)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:23  Lr: 0.001875  Loss: 0.4873  Acc@1: 75.0000 (79.8797)  Acc@5: 93.7500 (96.1321)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:19  Lr: 0.001875  Loss: 1.0382  Acc@1: 75.0000 (79.8293)  Acc@5: 93.7500 (96.1331)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:16  Lr: 0.001875  Loss: 0.4809  Acc@1: 81.2500 (79.8422)  Acc@5: 100.0000 (96.1342)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:12  Lr: 0.001875  Loss: 0.5902  Acc@1: 75.0000 (79.8042)  Acc@5: 100.0000 (96.1465)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:09  Lr: 0.001875  Loss: 0.4411  Acc@1: 81.2500 (79.8227)  Acc@5: 100.0000 (96.1641)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:06  Lr: 0.001875  Loss: 0.5003  Acc@1: 81.2500 (79.8519)  Acc@5: 100.0000 (96.1649)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:02  Lr: 0.001875  Loss: 0.4626  Acc@1: 81.2500 (79.8587)  Acc@5: 100.0000 (96.1766)  time: 0.3455  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1150/3750]  eta: 0:14:59  Lr: 0.001875  Loss: 0.2957  Acc@1: 87.5000 (79.9414)  Acc@5: 100.0000 (96.1935)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1160/3750]  eta: 0:14:55  Lr: 0.001875  Loss: 0.1706  Acc@1: 87.5000 (79.9742)  Acc@5: 100.0000 (96.2102)  time: 0.3455  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1170/3750]  eta: 0:14:52  Lr: 0.001875  Loss: 0.7835  Acc@1: 81.2500 (79.9690)  Acc@5: 100.0000 (96.2052)  time: 0.3461  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:48  Lr: 0.001875  Loss: 0.7333  Acc@1: 81.2500 (79.9534)  Acc@5: 93.7500 (96.1950)  time: 0.3463  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:45  Lr: 0.001875  Loss: 0.5925  Acc@1: 81.2500 (79.9591)  Acc@5: 100.0000 (96.1902)  time: 0.3459  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:41  Lr: 0.001875  Loss: 0.3856  Acc@1: 81.2500 (79.9958)  Acc@5: 100.0000 (96.2011)  time: 0.3452  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:38  Lr: 0.001875  Loss: 0.5292  Acc@1: 81.2500 (79.9701)  Acc@5: 100.0000 (96.2170)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:34  Lr: 0.001875  Loss: 0.2711  Acc@1: 81.2500 (80.0164)  Acc@5: 100.0000 (96.2377)  time: 0.3458  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:31  Lr: 0.001875  Loss: 0.2734  Acc@1: 81.2500 (80.0162)  Acc@5: 100.0000 (96.2480)  time: 0.3462  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:27  Lr: 0.001875  Loss: 0.7603  Acc@1: 75.0000 (79.9909)  Acc@5: 100.0000 (96.2530)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:24  Lr: 0.001875  Loss: 0.1454  Acc@1: 75.0000 (79.9910)  Acc@5: 100.0000 (96.2630)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:21  Lr: 0.001875  Loss: 0.3890  Acc@1: 81.2500 (79.9812)  Acc@5: 100.0000 (96.2827)  time: 0.3459  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:17  Lr: 0.001875  Loss: 1.0265  Acc@1: 75.0000 (79.9174)  Acc@5: 100.0000 (96.2874)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:14  Lr: 0.001875  Loss: 0.4746  Acc@1: 75.0000 (79.9132)  Acc@5: 100.0000 (96.2920)  time: 0.3464  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:10  Lr: 0.001875  Loss: 0.2574  Acc@1: 81.2500 (79.9526)  Acc@5: 100.0000 (96.2965)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:07  Lr: 0.001875  Loss: 0.5852  Acc@1: 81.2500 (79.9529)  Acc@5: 93.7500 (96.2817)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:03  Lr: 0.001875  Loss: 0.6350  Acc@1: 75.0000 (79.8865)  Acc@5: 93.7500 (96.2767)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:00  Lr: 0.001875  Loss: 0.7903  Acc@1: 68.7500 (79.8685)  Acc@5: 100.0000 (96.2718)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1330/3750]  eta: 0:13:56  Lr: 0.001875  Loss: 0.7842  Acc@1: 81.2500 (79.8789)  Acc@5: 100.0000 (96.2669)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1340/3750]  eta: 0:13:53  Lr: 0.001875  Loss: 0.6266  Acc@1: 87.5000 (79.9077)  Acc@5: 100.0000 (96.2901)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:50  Lr: 0.001875  Loss: 0.5851  Acc@1: 87.5000 (79.9454)  Acc@5: 100.0000 (96.2944)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:46  Lr: 0.001875  Loss: 0.8959  Acc@1: 81.2500 (79.9274)  Acc@5: 93.7500 (96.2987)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:43  Lr: 0.001875  Loss: 0.4627  Acc@1: 81.2500 (79.9416)  Acc@5: 93.7500 (96.2892)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:39  Lr: 0.001875  Loss: 0.9664  Acc@1: 81.2500 (79.9194)  Acc@5: 93.7500 (96.2753)  time: 0.3479  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:36  Lr: 0.001875  Loss: 0.5363  Acc@1: 81.2500 (79.9560)  Acc@5: 93.7500 (96.2797)  time: 0.3476  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:32  Lr: 0.001875  Loss: 0.9493  Acc@1: 81.2500 (79.9340)  Acc@5: 100.0000 (96.2928)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:29  Lr: 0.001875  Loss: 0.1390  Acc@1: 81.2500 (79.9920)  Acc@5: 100.0000 (96.3102)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:25  Lr: 0.001875  Loss: 0.1023  Acc@1: 87.5000 (80.0141)  Acc@5: 100.0000 (96.3186)  time: 0.3450  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:22  Lr: 0.001875  Loss: 0.5523  Acc@1: 87.5000 (80.0533)  Acc@5: 100.0000 (96.3312)  time: 0.3463  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:19  Lr: 0.001875  Loss: 0.5784  Acc@1: 81.2500 (80.0659)  Acc@5: 100.0000 (96.3393)  time: 0.3472  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:15  Lr: 0.001875  Loss: 0.6729  Acc@1: 81.2500 (80.0827)  Acc@5: 100.0000 (96.3473)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:12  Lr: 0.001875  Loss: 0.6105  Acc@1: 81.2500 (80.0821)  Acc@5: 100.0000 (96.3510)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:08  Lr: 0.001875  Loss: 0.5605  Acc@1: 81.2500 (80.0901)  Acc@5: 100.0000 (96.3588)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:05  Lr: 0.001875  Loss: 0.7877  Acc@1: 81.2500 (80.0726)  Acc@5: 100.0000 (96.3496)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:01  Lr: 0.001875  Loss: 0.3519  Acc@1: 81.2500 (80.0763)  Acc@5: 100.0000 (96.3531)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1500/3750]  eta: 0:12:58  Lr: 0.001875  Loss: 0.1971  Acc@1: 81.2500 (80.1133)  Acc@5: 93.7500 (96.3441)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1510/3750]  eta: 0:12:54  Lr: 0.001875  Loss: 0.6854  Acc@1: 81.2500 (80.1001)  Acc@5: 93.7500 (96.3518)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:51  Lr: 0.001875  Loss: 0.7906  Acc@1: 81.2500 (80.1036)  Acc@5: 100.0000 (96.3552)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:47  Lr: 0.001875  Loss: 0.2235  Acc@1: 81.2500 (80.0865)  Acc@5: 100.0000 (96.3463)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:44  Lr: 0.001875  Loss: 0.4563  Acc@1: 81.2500 (80.0860)  Acc@5: 93.7500 (96.3335)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:40  Lr: 0.001875  Loss: 0.5869  Acc@1: 81.2500 (80.0814)  Acc@5: 93.7500 (96.3330)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:37  Lr: 0.001875  Loss: 0.5263  Acc@1: 81.2500 (80.1049)  Acc@5: 100.0000 (96.3365)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:33  Lr: 0.001875  Loss: 0.7913  Acc@1: 81.2500 (80.1042)  Acc@5: 93.7500 (96.3280)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:30  Lr: 0.001875  Loss: 0.3618  Acc@1: 81.2500 (80.1075)  Acc@5: 93.7500 (96.3354)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:26  Lr: 0.001875  Loss: 0.9642  Acc@1: 81.2500 (80.1108)  Acc@5: 93.7500 (96.3191)  time: 0.3455  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:23  Lr: 0.001875  Loss: 0.6871  Acc@1: 81.2500 (80.0906)  Acc@5: 93.7500 (96.3187)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:20  Lr: 0.001875  Loss: 0.1897  Acc@1: 81.2500 (80.1094)  Acc@5: 93.7500 (96.3066)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:16  Lr: 0.001875  Loss: 0.4502  Acc@1: 81.2500 (80.1010)  Acc@5: 93.7500 (96.2986)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:13  Lr: 0.001875  Loss: 0.8200  Acc@1: 75.0000 (80.0544)  Acc@5: 93.7500 (96.2715)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:09  Lr: 0.001875  Loss: 0.3256  Acc@1: 75.0000 (80.0731)  Acc@5: 93.7500 (96.2713)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:06  Lr: 0.001875  Loss: 0.5944  Acc@1: 87.5000 (80.0727)  Acc@5: 93.7500 (96.2598)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:02  Lr: 0.001875  Loss: 1.0709  Acc@1: 75.0000 (80.0497)  Acc@5: 93.7500 (96.2635)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1670/3750]  eta: 0:11:59  Lr: 0.001875  Loss: 0.4237  Acc@1: 81.2500 (80.0681)  Acc@5: 100.0000 (96.2672)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1680/3750]  eta: 0:11:55  Lr: 0.001875  Loss: 0.2566  Acc@1: 81.2500 (80.0602)  Acc@5: 100.0000 (96.2745)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:52  Lr: 0.001875  Loss: 0.4998  Acc@1: 81.2500 (80.0599)  Acc@5: 100.0000 (96.2744)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:48  Lr: 0.001875  Loss: 0.6022  Acc@1: 81.2500 (80.0852)  Acc@5: 93.7500 (96.2779)  time: 0.3454  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:45  Lr: 0.001875  Loss: 0.4772  Acc@1: 81.2500 (80.0628)  Acc@5: 93.7500 (96.2741)  time: 0.3466  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:41  Lr: 0.001875  Loss: 0.9112  Acc@1: 81.2500 (80.0516)  Acc@5: 93.7500 (96.2667)  time: 0.3460  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:38  Lr: 0.001875  Loss: 0.5513  Acc@1: 81.2500 (80.0765)  Acc@5: 93.7500 (96.2594)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:35  Lr: 0.001875  Loss: 0.5408  Acc@1: 81.2500 (80.0689)  Acc@5: 93.7500 (96.2522)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:31  Lr: 0.001875  Loss: 0.3576  Acc@1: 81.2500 (80.0757)  Acc@5: 100.0000 (96.2664)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:28  Lr: 0.001875  Loss: 0.9917  Acc@1: 87.5000 (80.0859)  Acc@5: 93.7500 (96.2486)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:24  Lr: 0.001875  Loss: 0.3011  Acc@1: 81.2500 (80.0713)  Acc@5: 93.7500 (96.2486)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:21  Lr: 0.001875  Loss: 1.0487  Acc@1: 81.2500 (80.0674)  Acc@5: 100.0000 (96.2451)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:17  Lr: 0.001875  Loss: 0.4511  Acc@1: 81.2500 (80.0879)  Acc@5: 100.0000 (96.2556)  time: 0.3458  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:14  Lr: 0.001875  Loss: 0.7585  Acc@1: 81.2500 (80.0944)  Acc@5: 100.0000 (96.2556)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:10  Lr: 0.001875  Loss: 0.2306  Acc@1: 81.2500 (80.1146)  Acc@5: 100.0000 (96.2693)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:07  Lr: 0.001875  Loss: 0.9468  Acc@1: 81.2500 (80.1071)  Acc@5: 100.0000 (96.2761)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:03  Lr: 0.001875  Loss: 0.4136  Acc@1: 75.0000 (80.0826)  Acc@5: 93.7500 (96.2725)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:00  Lr: 0.001875  Loss: 0.3775  Acc@1: 75.0000 (80.0991)  Acc@5: 93.7500 (96.2622)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1850/3750]  eta: 0:10:56  Lr: 0.001875  Loss: 0.3383  Acc@1: 81.2500 (80.1087)  Acc@5: 93.7500 (96.2486)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1860/3750]  eta: 0:10:53  Lr: 0.001875  Loss: 1.1749  Acc@1: 75.0000 (80.0712)  Acc@5: 93.7500 (96.2352)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:50  Lr: 0.001875  Loss: 0.5331  Acc@1: 75.0000 (80.0341)  Acc@5: 93.7500 (96.2119)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:46  Lr: 0.001875  Loss: 0.1490  Acc@1: 75.0000 (80.0339)  Acc@5: 93.7500 (96.2188)  time: 0.3461  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:43  Lr: 0.001875  Loss: 0.6150  Acc@1: 81.2500 (80.0172)  Acc@5: 100.0000 (96.2156)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:39  Lr: 0.001875  Loss: 0.9846  Acc@1: 75.0000 (80.0138)  Acc@5: 100.0000 (96.2158)  time: 0.3463  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:36  Lr: 0.001875  Loss: 1.0852  Acc@1: 75.0000 (79.9843)  Acc@5: 100.0000 (96.2062)  time: 0.3458  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:32  Lr: 0.001875  Loss: 0.8676  Acc@1: 75.0000 (79.9779)  Acc@5: 100.0000 (96.2064)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:29  Lr: 0.001875  Loss: 0.7453  Acc@1: 81.2500 (79.9974)  Acc@5: 93.7500 (96.1969)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:25  Lr: 0.001875  Loss: 0.4861  Acc@1: 81.2500 (80.0071)  Acc@5: 93.7500 (96.1940)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:22  Lr: 0.001875  Loss: 0.8239  Acc@1: 81.2500 (80.0423)  Acc@5: 93.7500 (96.1975)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:18  Lr: 0.001875  Loss: 0.9013  Acc@1: 81.2500 (80.0516)  Acc@5: 100.0000 (96.1977)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:15  Lr: 0.001875  Loss: 0.5982  Acc@1: 81.2500 (80.0323)  Acc@5: 100.0000 (96.1980)  time: 0.3465  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:12  Lr: 0.001875  Loss: 1.0069  Acc@1: 87.5000 (80.0606)  Acc@5: 100.0000 (96.2109)  time: 0.3463  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:08  Lr: 0.001875  Loss: 0.6618  Acc@1: 81.2500 (80.0571)  Acc@5: 100.0000 (96.2142)  time: 0.3452  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:05  Lr: 0.001875  Loss: 0.8198  Acc@1: 81.2500 (80.0662)  Acc@5: 100.0000 (96.2269)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:01  Lr: 0.001875  Loss: 0.6989  Acc@1: 81.2500 (80.0721)  Acc@5: 100.0000 (96.2394)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2020/3750]  eta: 0:09:58  Lr: 0.001875  Loss: 0.5464  Acc@1: 81.2500 (80.0779)  Acc@5: 100.0000 (96.2395)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2030/3750]  eta: 0:09:54  Lr: 0.001875  Loss: 0.5692  Acc@1: 81.2500 (80.1052)  Acc@5: 100.0000 (96.2457)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:51  Lr: 0.001875  Loss: 0.3194  Acc@1: 75.0000 (80.0925)  Acc@5: 100.0000 (96.2518)  time: 0.3462  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:47  Lr: 0.001875  Loss: 1.3159  Acc@1: 75.0000 (80.0646)  Acc@5: 93.7500 (96.2396)  time: 0.3479  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:44  Lr: 0.001875  Loss: 0.3164  Acc@1: 75.0000 (80.0613)  Acc@5: 93.7500 (96.2367)  time: 0.3468  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:40  Lr: 0.001875  Loss: 0.7437  Acc@1: 81.2500 (80.0489)  Acc@5: 93.7500 (96.2367)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:37  Lr: 0.001875  Loss: 0.2035  Acc@1: 81.2500 (80.0457)  Acc@5: 93.7500 (96.2368)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:34  Lr: 0.001875  Loss: 0.6188  Acc@1: 81.2500 (80.0305)  Acc@5: 93.7500 (96.2279)  time: 0.3461  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:30  Lr: 0.001875  Loss: 0.6174  Acc@1: 81.2500 (80.0184)  Acc@5: 93.7500 (96.2339)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:27  Lr: 0.001875  Loss: 0.5601  Acc@1: 81.2500 (80.0420)  Acc@5: 100.0000 (96.2429)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:23  Lr: 0.001875  Loss: 0.3248  Acc@1: 87.5000 (80.0625)  Acc@5: 100.0000 (96.2488)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:20  Lr: 0.001875  Loss: 0.8274  Acc@1: 81.2500 (80.0768)  Acc@5: 100.0000 (96.2547)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:16  Lr: 0.001875  Loss: 0.7409  Acc@1: 81.2500 (80.0765)  Acc@5: 93.7500 (96.2459)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:13  Lr: 0.001875  Loss: 0.7067  Acc@1: 81.2500 (80.1052)  Acc@5: 93.7500 (96.2401)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:09  Lr: 0.001875  Loss: 0.5994  Acc@1: 81.2500 (80.0989)  Acc@5: 93.7500 (96.2460)  time: 0.3479  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:06  Lr: 0.001875  Loss: 0.5526  Acc@1: 81.2500 (80.1244)  Acc@5: 100.0000 (96.2488)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:02  Lr: 0.001875  Loss: 0.9712  Acc@1: 81.2500 (80.1152)  Acc@5: 93.7500 (96.2374)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2190/3750]  eta: 0:08:59  Lr: 0.001875  Loss: 0.5374  Acc@1: 75.0000 (80.1175)  Acc@5: 93.7500 (96.2403)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2200/3750]  eta: 0:08:56  Lr: 0.001875  Loss: 0.3500  Acc@1: 81.2500 (80.1028)  Acc@5: 93.7500 (96.2375)  time: 0.3446  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:52  Lr: 0.001875  Loss: 0.5401  Acc@1: 81.2500 (80.0967)  Acc@5: 93.7500 (96.2347)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:49  Lr: 0.001875  Loss: 1.0735  Acc@1: 75.0000 (80.0962)  Acc@5: 100.0000 (96.2404)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:45  Lr: 0.001875  Loss: 0.4575  Acc@1: 81.2500 (80.1042)  Acc@5: 100.0000 (96.2433)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:42  Lr: 0.001875  Loss: 0.5507  Acc@1: 81.2500 (80.1149)  Acc@5: 100.0000 (96.2489)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:38  Lr: 0.001875  Loss: 0.7169  Acc@1: 81.2500 (80.1005)  Acc@5: 100.0000 (96.2433)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:35  Lr: 0.001875  Loss: 0.8776  Acc@1: 81.2500 (80.1001)  Acc@5: 100.0000 (96.2517)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:31  Lr: 0.001875  Loss: 0.7509  Acc@1: 87.5000 (80.1051)  Acc@5: 100.0000 (96.2544)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:28  Lr: 0.001875  Loss: 0.8657  Acc@1: 81.2500 (80.0992)  Acc@5: 93.7500 (96.2489)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:24  Lr: 0.001875  Loss: 0.3697  Acc@1: 81.2500 (80.1124)  Acc@5: 100.0000 (96.2516)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:21  Lr: 0.001875  Loss: 0.5091  Acc@1: 81.2500 (80.1173)  Acc@5: 100.0000 (96.2571)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:17  Lr: 0.001875  Loss: 0.9062  Acc@1: 81.2500 (80.1358)  Acc@5: 100.0000 (96.2678)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:14  Lr: 0.001875  Loss: 0.9569  Acc@1: 81.2500 (80.1083)  Acc@5: 93.7500 (96.2489)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:10  Lr: 0.001875  Loss: 0.7614  Acc@1: 75.0000 (80.0890)  Acc@5: 93.7500 (96.2543)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:07  Lr: 0.001875  Loss: 0.5148  Acc@1: 81.2500 (80.0860)  Acc@5: 100.0000 (96.2516)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:04  Lr: 0.001875  Loss: 0.6504  Acc@1: 81.2500 (80.0670)  Acc@5: 93.7500 (96.2543)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:00  Lr: 0.001875  Loss: 0.5330  Acc@1: 81.2500 (80.0667)  Acc@5: 100.0000 (96.2542)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2370/3750]  eta: 0:07:57  Lr: 0.001875  Loss: 0.3699  Acc@1: 81.2500 (80.0770)  Acc@5: 100.0000 (96.2569)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:53  Lr: 0.001875  Loss: 0.5412  Acc@1: 81.2500 (80.0976)  Acc@5: 100.0000 (96.2647)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:50  Lr: 0.001875  Loss: 1.0201  Acc@1: 81.2500 (80.0920)  Acc@5: 100.0000 (96.2699)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:46  Lr: 0.001875  Loss: 0.5956  Acc@1: 81.2500 (80.1151)  Acc@5: 100.0000 (96.2776)  time: 0.3450  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:43  Lr: 0.001875  Loss: 0.9285  Acc@1: 81.2500 (80.1120)  Acc@5: 100.0000 (96.2853)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:39  Lr: 0.001875  Loss: 0.7286  Acc@1: 81.2500 (80.1089)  Acc@5: 100.0000 (96.2748)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:36  Lr: 0.001875  Loss: 0.8286  Acc@1: 81.2500 (80.1111)  Acc@5: 93.7500 (96.2747)  time: 0.3466  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:32  Lr: 0.001875  Loss: 0.7646  Acc@1: 81.2500 (80.1106)  Acc@5: 100.0000 (96.2823)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:29  Lr: 0.001875  Loss: 0.7478  Acc@1: 75.0000 (80.1000)  Acc@5: 100.0000 (96.2872)  time: 0.3483  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:26  Lr: 0.001875  Loss: 0.6111  Acc@1: 81.2500 (80.1275)  Acc@5: 100.0000 (96.2845)  time: 0.3487  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:22  Lr: 0.001875  Loss: 0.5703  Acc@1: 81.2500 (80.1320)  Acc@5: 93.7500 (96.2869)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:19  Lr: 0.001875  Loss: 0.3378  Acc@1: 81.2500 (80.1340)  Acc@5: 93.7500 (96.2868)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:15  Lr: 0.001875  Loss: 0.3373  Acc@1: 81.2500 (80.1385)  Acc@5: 100.0000 (96.2916)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:12  Lr: 0.001875  Loss: 0.5425  Acc@1: 81.2500 (80.1554)  Acc@5: 100.0000 (96.2940)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:08  Lr: 0.001875  Loss: 0.8336  Acc@1: 81.2500 (80.1324)  Acc@5: 93.7500 (96.2888)  time: 0.3449  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:05  Lr: 0.001875  Loss: 0.2709  Acc@1: 68.7500 (80.1071)  Acc@5: 93.7500 (96.2788)  time: 0.3444  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:01  Lr: 0.001875  Loss: 0.5073  Acc@1: 75.0000 (80.1166)  Acc@5: 93.7500 (96.2786)  time: 0.3451  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2540/3750]  eta: 0:06:58  Lr: 0.001875  Loss: 0.5469  Acc@1: 81.2500 (80.1210)  Acc@5: 93.7500 (96.2736)  time: 0.3459  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:54  Lr: 0.001875  Loss: 0.3963  Acc@1: 81.2500 (80.1230)  Acc@5: 100.0000 (96.2809)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:51  Lr: 0.001875  Loss: 0.4132  Acc@1: 81.2500 (80.1420)  Acc@5: 100.0000 (96.2881)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:47  Lr: 0.001875  Loss: 0.8215  Acc@1: 81.2500 (80.1415)  Acc@5: 100.0000 (96.2952)  time: 0.3438  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:44  Lr: 0.001875  Loss: 0.3515  Acc@1: 81.2500 (80.1482)  Acc@5: 100.0000 (96.2999)  time: 0.3443  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:41  Lr: 0.001875  Loss: 0.5312  Acc@1: 81.2500 (80.1500)  Acc@5: 100.0000 (96.3021)  time: 0.3450  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:37  Lr: 0.001875  Loss: 0.2476  Acc@1: 81.2500 (80.1591)  Acc@5: 93.7500 (96.2923)  time: 0.3453  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:34  Lr: 0.001875  Loss: 0.6316  Acc@1: 81.2500 (80.1561)  Acc@5: 93.7500 (96.2897)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:30  Lr: 0.001875  Loss: 1.0107  Acc@1: 81.2500 (80.1531)  Acc@5: 93.7500 (96.2824)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:27  Lr: 0.001875  Loss: 0.5944  Acc@1: 81.2500 (80.1739)  Acc@5: 93.7500 (96.2799)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:23  Lr: 0.001875  Loss: 0.9663  Acc@1: 81.2500 (80.1756)  Acc@5: 100.0000 (96.2846)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:20  Lr: 0.001875  Loss: 0.5708  Acc@1: 81.2500 (80.1679)  Acc@5: 100.0000 (96.2844)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:16  Lr: 0.001875  Loss: 0.7688  Acc@1: 75.0000 (80.1696)  Acc@5: 100.0000 (96.2866)  time: 0.3478  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:13  Lr: 0.001875  Loss: 0.5020  Acc@1: 81.2500 (80.1619)  Acc@5: 93.7500 (96.2842)  time: 0.3486  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:09  Lr: 0.001875  Loss: 0.7000  Acc@1: 81.2500 (80.1660)  Acc@5: 93.7500 (96.2840)  time: 0.3465  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:06  Lr: 0.001875  Loss: 0.3303  Acc@1: 81.2500 (80.1700)  Acc@5: 100.0000 (96.2886)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:03  Lr: 0.001875  Loss: 0.8661  Acc@1: 81.2500 (80.1671)  Acc@5: 100.0000 (96.2907)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2710/3750]  eta: 0:05:59  Lr: 0.001875  Loss: 0.3701  Acc@1: 81.2500 (80.1618)  Acc@5: 100.0000 (96.2998)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:56  Lr: 0.001875  Loss: 0.2753  Acc@1: 75.0000 (80.1567)  Acc@5: 100.0000 (96.3065)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:52  Lr: 0.001875  Loss: 0.8067  Acc@1: 81.2500 (80.1652)  Acc@5: 100.0000 (96.3109)  time: 0.3463  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:49  Lr: 0.001875  Loss: 0.8197  Acc@1: 81.2500 (80.1669)  Acc@5: 93.7500 (96.3038)  time: 0.3458  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:45  Lr: 0.001875  Loss: 0.4029  Acc@1: 81.2500 (80.1731)  Acc@5: 93.7500 (96.3059)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:42  Lr: 0.001875  Loss: 0.8384  Acc@1: 81.2500 (80.1748)  Acc@5: 100.0000 (96.3080)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:38  Lr: 0.001875  Loss: 0.8514  Acc@1: 81.2500 (80.1651)  Acc@5: 100.0000 (96.3123)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:35  Lr: 0.001875  Loss: 0.5190  Acc@1: 81.2500 (80.1488)  Acc@5: 93.7500 (96.3053)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:31  Lr: 0.001875  Loss: 0.4169  Acc@1: 81.2500 (80.1639)  Acc@5: 93.7500 (96.3051)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:28  Lr: 0.001875  Loss: 0.8926  Acc@1: 81.2500 (80.1723)  Acc@5: 93.7500 (96.3004)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:24  Lr: 0.001875  Loss: 0.5199  Acc@1: 81.2500 (80.1761)  Acc@5: 93.7500 (96.3025)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:21  Lr: 0.001875  Loss: 0.6809  Acc@1: 75.0000 (80.1666)  Acc@5: 93.7500 (96.2979)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:18  Lr: 0.001875  Loss: 0.6213  Acc@1: 75.0000 (80.1682)  Acc@5: 93.7500 (96.2933)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:14  Lr: 0.001875  Loss: 0.5346  Acc@1: 81.2500 (80.1896)  Acc@5: 100.0000 (96.3019)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:11  Lr: 0.001875  Loss: 0.8003  Acc@1: 81.2500 (80.1999)  Acc@5: 100.0000 (96.2995)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:07  Lr: 0.001875  Loss: 0.2809  Acc@1: 81.2500 (80.2036)  Acc@5: 93.7500 (96.3037)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:04  Lr: 0.001875  Loss: 0.2099  Acc@1: 87.5000 (80.2377)  Acc@5: 100.0000 (96.3079)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:00  Lr: 0.001875  Loss: 0.3329  Acc@1: 87.5000 (80.2347)  Acc@5: 100.0000 (96.3142)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2890/3750]  eta: 0:04:57  Lr: 0.001875  Loss: 0.6911  Acc@1: 81.2500 (80.2404)  Acc@5: 100.0000 (96.3118)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:53  Lr: 0.001875  Loss: 0.3246  Acc@1: 81.2500 (80.2482)  Acc@5: 93.7500 (96.3116)  time: 0.3451  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:50  Lr: 0.001875  Loss: 0.8615  Acc@1: 81.2500 (80.2366)  Acc@5: 93.7500 (96.3071)  time: 0.3461  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:46  Lr: 0.001875  Loss: 0.4451  Acc@1: 81.2500 (80.2465)  Acc@5: 93.7500 (96.2984)  time: 0.3455  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:43  Lr: 0.001875  Loss: 1.1174  Acc@1: 81.2500 (80.2222)  Acc@5: 93.7500 (96.2875)  time: 0.3451  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:40  Lr: 0.001875  Loss: 0.8369  Acc@1: 75.0000 (80.2193)  Acc@5: 93.7500 (96.2895)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:36  Lr: 0.001875  Loss: 0.3592  Acc@1: 81.2500 (80.2334)  Acc@5: 100.0000 (96.2979)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:33  Lr: 0.001875  Loss: 0.5896  Acc@1: 81.2500 (80.2263)  Acc@5: 100.0000 (96.3083)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:29  Lr: 0.001875  Loss: 0.4556  Acc@1: 81.2500 (80.2276)  Acc@5: 100.0000 (96.3102)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:26  Lr: 0.001875  Loss: 0.7654  Acc@1: 81.2500 (80.2185)  Acc@5: 100.0000 (96.3142)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:22  Lr: 0.001875  Loss: 0.2815  Acc@1: 75.0000 (80.2177)  Acc@5: 100.0000 (96.3181)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:19  Lr: 0.001875  Loss: 0.4863  Acc@1: 81.2500 (80.2274)  Acc@5: 100.0000 (96.3200)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:15  Lr: 0.001875  Loss: 0.2511  Acc@1: 81.2500 (80.2350)  Acc@5: 100.0000 (96.3197)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:12  Lr: 0.001875  Loss: 0.5745  Acc@1: 75.0000 (80.2280)  Acc@5: 100.0000 (96.3174)  time: 0.3445  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:08  Lr: 0.001875  Loss: 0.5985  Acc@1: 81.2500 (80.2437)  Acc@5: 93.7500 (96.3152)  time: 0.3440  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:05  Lr: 0.001875  Loss: 0.4943  Acc@1: 81.2500 (80.2388)  Acc@5: 100.0000 (96.3149)  time: 0.3436  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:01  Lr: 0.001875  Loss: 1.0004  Acc@1: 81.2500 (80.2544)  Acc@5: 100.0000 (96.3127)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3060/3750]  eta: 0:03:58  Lr: 0.001875  Loss: 0.3219  Acc@1: 81.2500 (80.2516)  Acc@5: 93.7500 (96.3104)  time: 0.3443  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:55  Lr: 0.001875  Loss: 0.2068  Acc@1: 81.2500 (80.2670)  Acc@5: 100.0000 (96.3102)  time: 0.3452  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:51  Lr: 0.001875  Loss: 0.2294  Acc@1: 87.5000 (80.2743)  Acc@5: 100.0000 (96.3141)  time: 0.3452  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:48  Lr: 0.001875  Loss: 0.5151  Acc@1: 87.5000 (80.2956)  Acc@5: 100.0000 (96.3179)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:44  Lr: 0.001875  Loss: 0.3617  Acc@1: 87.5000 (80.2987)  Acc@5: 100.0000 (96.3218)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:41  Lr: 0.001875  Loss: 0.7300  Acc@1: 87.5000 (80.3239)  Acc@5: 100.0000 (96.3316)  time: 0.3455  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:37  Lr: 0.001875  Loss: 0.6580  Acc@1: 81.2500 (80.3148)  Acc@5: 100.0000 (96.3353)  time: 0.3446  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:34  Lr: 0.001875  Loss: 0.2138  Acc@1: 81.2500 (80.3138)  Acc@5: 100.0000 (96.3390)  time: 0.3446  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.3200  Acc@1: 81.2500 (80.3188)  Acc@5: 100.0000 (96.3368)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:27  Lr: 0.001875  Loss: 0.7768  Acc@1: 81.2500 (80.3059)  Acc@5: 93.7500 (96.3305)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.5088  Acc@1: 81.2500 (80.3227)  Acc@5: 100.0000 (96.3382)  time: 0.3450  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:20  Lr: 0.001875  Loss: 0.4188  Acc@1: 87.5000 (80.3315)  Acc@5: 100.0000 (96.3438)  time: 0.3447  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:17  Lr: 0.001875  Loss: 0.4330  Acc@1: 81.2500 (80.3265)  Acc@5: 100.0000 (96.3455)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:13  Lr: 0.001875  Loss: 0.6362  Acc@1: 81.2500 (80.3353)  Acc@5: 100.0000 (96.3511)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:10  Lr: 0.001875  Loss: 0.3461  Acc@1: 81.2500 (80.3460)  Acc@5: 100.0000 (96.3507)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:06  Lr: 0.001875  Loss: 1.0175  Acc@1: 87.5000 (80.3488)  Acc@5: 100.0000 (96.3524)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:03  Lr: 0.001875  Loss: 0.5632  Acc@1: 81.2500 (80.3535)  Acc@5: 100.0000 (96.3579)  time: 0.3442  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 0.5225  Acc@1: 75.0000 (80.3447)  Acc@5: 100.0000 (96.3576)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:56  Lr: 0.001875  Loss: 0.9531  Acc@1: 75.0000 (80.3359)  Acc@5: 93.7500 (96.3514)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.4302  Acc@1: 81.2500 (80.3234)  Acc@5: 93.7500 (96.3473)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:49  Lr: 0.001875  Loss: 0.9294  Acc@1: 75.0000 (80.3032)  Acc@5: 93.7500 (96.3451)  time: 0.3425  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 0.2688  Acc@1: 75.0000 (80.2927)  Acc@5: 93.7500 (96.3390)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:42  Lr: 0.001875  Loss: 0.4450  Acc@1: 81.2500 (80.2880)  Acc@5: 100.0000 (96.3464)  time: 0.3444  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 0.5553  Acc@1: 81.2500 (80.2871)  Acc@5: 100.0000 (96.3423)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:35  Lr: 0.001875  Loss: 0.6394  Acc@1: 81.2500 (80.2844)  Acc@5: 93.7500 (96.3420)  time: 0.3431  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:32  Lr: 0.001875  Loss: 0.1222  Acc@1: 81.2500 (80.2911)  Acc@5: 100.0000 (96.3399)  time: 0.3431  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.7843  Acc@1: 81.2500 (80.2733)  Acc@5: 100.0000 (96.3433)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:25  Lr: 0.001875  Loss: 0.6088  Acc@1: 75.0000 (80.2631)  Acc@5: 100.0000 (96.3487)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.9247  Acc@1: 75.0000 (80.2492)  Acc@5: 93.7500 (96.3428)  time: 0.3433  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:18  Lr: 0.001875  Loss: 0.6841  Acc@1: 81.2500 (80.2596)  Acc@5: 93.7500 (96.3444)  time: 0.3429  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.2575  Acc@1: 87.5000 (80.2793)  Acc@5: 100.0000 (96.3478)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:11  Lr: 0.001875  Loss: 0.4426  Acc@1: 87.5000 (80.2729)  Acc@5: 93.7500 (96.3438)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.8688  Acc@1: 81.2500 (80.2814)  Acc@5: 93.7500 (96.3361)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:04  Lr: 0.001875  Loss: 0.9239  Acc@1: 81.2500 (80.2676)  Acc@5: 93.7500 (96.3322)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 0.5138  Acc@1: 75.0000 (80.2466)  Acc@5: 93.7500 (96.3301)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 1.1461  Acc@1: 75.0000 (80.2496)  Acc@5: 93.7500 (96.3299)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: 0.6830  Acc@1: 81.2500 (80.2580)  Acc@5: 100.0000 (96.3351)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.4891  Acc@1: 81.2500 (80.2590)  Acc@5: 100.0000 (96.3385)  time: 0.3435  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: 0.2388  Acc@1: 87.5000 (80.2764)  Acc@5: 100.0000 (96.3401)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.5058  Acc@1: 87.5000 (80.2883)  Acc@5: 100.0000 (96.3453)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: 0.4085  Acc@1: 87.5000 (80.3037)  Acc@5: 100.0000 (96.3468)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.5902  Acc@1: 81.2500 (80.2993)  Acc@5: 100.0000 (96.3519)  time: 0.3448  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: 0.4789  Acc@1: 81.2500 (80.3038)  Acc@5: 100.0000 (96.3462)  time: 0.3459  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.2692  Acc@1: 81.2500 (80.3172)  Acc@5: 100.0000 (96.3549)  time: 0.3470  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.4946  Acc@1: 87.5000 (80.3146)  Acc@5: 100.0000 (96.3564)  time: 0.3454  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.6618  Acc@1: 81.2500 (80.3243)  Acc@5: 100.0000 (96.3597)  time: 0.3432  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.8939  Acc@1: 81.2500 (80.3074)  Acc@5: 100.0000 (96.3593)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 0.2570  Acc@1: 75.0000 (80.3083)  Acc@5: 93.7500 (96.3573)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.2625  Acc@1: 87.5000 (80.3216)  Acc@5: 100.0000 (96.3640)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: 0.2242  Acc@1: 87.5000 (80.3260)  Acc@5: 100.0000 (96.3655)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.2418  Acc@1: 81.2500 (80.3321)  Acc@5: 100.0000 (96.3704)  time: 0.3443  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: 0.6061  Acc@1: 81.2500 (80.3329)  Acc@5: 100.0000 (96.3736)  time: 0.3436  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4543  Acc@1: 81.2500 (80.3407)  Acc@5: 100.0000 (96.3715)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.8229  Acc@1: 81.2500 (80.3328)  Acc@5: 93.7500 (96.3711)  time: 0.3427  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.5115  Acc@1: 81.2500 (80.3301)  Acc@5: 93.7500 (96.3725)  time: 0.3435  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7184  Acc@1: 81.2500 (80.3327)  Acc@5: 100.0000 (96.3809)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.6512  Acc@1: 81.2500 (80.3266)  Acc@5: 100.0000 (96.3788)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.6732  Acc@1: 75.0000 (80.3171)  Acc@5: 100.0000 (96.3819)  time: 0.3446  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 0.7522  Acc@1: 81.2500 (80.3145)  Acc@5: 100.0000 (96.3781)  time: 0.3438  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3956  Acc@1: 81.2500 (80.3085)  Acc@5: 100.0000 (96.3828)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: 0.3366  Acc@1: 75.0000 (80.2991)  Acc@5: 100.0000 (96.3791)  time: 0.3450  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.7189  Acc@1: 81.2500 (80.3034)  Acc@5: 93.7500 (96.3787)  time: 0.3439  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.6768  Acc@1: 81.2500 (80.3178)  Acc@5: 100.0000 (96.3835)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 0.1674  Acc@1: 87.5000 (80.3322)  Acc@5: 100.0000 (96.3848)  time: 0.3448  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.6012  Acc@1: 81.2500 (80.3280)  Acc@5: 93.7500 (96.3827)  time: 0.3450  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.7279  Acc@1: 75.0000 (80.3085)  Acc@5: 100.0000 (96.3874)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.6717  Acc@1: 75.0000 (80.3128)  Acc@5: 100.0000 (96.3921)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.5163  Acc@1: 81.2500 (80.3354)  Acc@5: 100.0000 (96.3951)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.7483  Acc@1: 81.2500 (80.3311)  Acc@5: 100.0000 (96.3964)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2447  Acc@1: 81.2500 (80.3400)  Acc@5: 93.7500 (96.3950)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[2/5] Total time: 0:21:35 (0.3456 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2447  Acc@1: 81.2500 (80.3400)  Acc@5: 93.7500 (96.3950)
Train: Epoch[3/5]  [   0/3750]  eta: 0:38:42  Lr: 0.001875  Loss: 0.7062  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6194  data: 0.2762  max mem: 2500
Train: Epoch[3/5]  [  10/3750]  eta: 0:23:04  Lr: 0.001875  Loss: 0.1515  Acc@1: 81.2500 (80.1136)  Acc@5: 93.7500 (96.0227)  time: 0.3703  data: 0.0254  max mem: 2500
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:15  Lr: 0.001875  Loss: 0.7578  Acc@1: 81.2500 (79.4643)  Acc@5: 93.7500 (96.1310)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  30/3750]  eta: 0:21:54  Lr: 0.001875  Loss: 0.4754  Acc@1: 81.2500 (79.6371)  Acc@5: 100.0000 (96.3710)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  40/3750]  eta: 0:21:42  Lr: 0.001875  Loss: 0.2937  Acc@1: 81.2500 (79.2683)  Acc@5: 100.0000 (96.1890)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  50/3750]  eta: 0:21:33  Lr: 0.001875  Loss: 0.6317  Acc@1: 81.2500 (79.9020)  Acc@5: 93.7500 (95.9559)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:26  Lr: 0.001875  Loss: 0.6142  Acc@1: 81.2500 (80.1230)  Acc@5: 93.7500 (96.1066)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:20  Lr: 0.001875  Loss: 0.1772  Acc@1: 81.2500 (81.0739)  Acc@5: 100.0000 (96.2148)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:16  Lr: 0.001875  Loss: 0.4521  Acc@1: 81.2500 (80.8642)  Acc@5: 100.0000 (96.3735)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:10  Lr: 0.001875  Loss: 0.7759  Acc@1: 81.2500 (80.8379)  Acc@5: 100.0000 (96.4286)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:05  Lr: 0.001875  Loss: 0.6599  Acc@1: 81.2500 (81.1881)  Acc@5: 100.0000 (96.5347)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:01  Lr: 0.001875  Loss: 0.5004  Acc@1: 81.2500 (81.7568)  Acc@5: 100.0000 (96.6216)  time: 0.3431  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 120/3750]  eta: 0:20:58  Lr: 0.001875  Loss: 0.1195  Acc@1: 87.5000 (82.0248)  Acc@5: 100.0000 (96.6942)  time: 0.3462  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 130/3750]  eta: 0:20:54  Lr: 0.001875  Loss: 0.6571  Acc@1: 87.5000 (82.2519)  Acc@5: 100.0000 (96.6603)  time: 0.3474  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [ 140/3750]  eta: 0:20:50  Lr: 0.001875  Loss: 0.4656  Acc@1: 87.5000 (82.3582)  Acc@5: 100.0000 (96.7199)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 150/3750]  eta: 0:20:46  Lr: 0.001875  Loss: 0.5192  Acc@1: 81.2500 (82.3262)  Acc@5: 100.0000 (96.6887)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 160/3750]  eta: 0:20:42  Lr: 0.001875  Loss: 0.3475  Acc@1: 81.2500 (82.3758)  Acc@5: 93.7500 (96.7003)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:38  Lr: 0.001875  Loss: 1.2048  Acc@1: 81.2500 (82.1272)  Acc@5: 93.7500 (96.6740)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:34  Lr: 0.001875  Loss: 0.5969  Acc@1: 81.2500 (82.3550)  Acc@5: 100.0000 (96.6851)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:31  Lr: 0.001875  Loss: 0.6237  Acc@1: 87.5000 (82.2317)  Acc@5: 100.0000 (96.6623)  time: 0.3443  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:27  Lr: 0.001875  Loss: 0.6398  Acc@1: 81.2500 (82.1206)  Acc@5: 100.0000 (96.7040)  time: 0.3449  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:23  Lr: 0.001875  Loss: 1.0800  Acc@1: 75.0000 (81.9313)  Acc@5: 93.7500 (96.5640)  time: 0.3442  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:19  Lr: 0.001875  Loss: 0.2531  Acc@1: 75.0000 (81.9005)  Acc@5: 93.7500 (96.4932)  time: 0.3432  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:16  Lr: 0.001875  Loss: 0.5537  Acc@1: 81.2500 (81.6829)  Acc@5: 93.7500 (96.4015)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:12  Lr: 0.001875  Loss: 0.3175  Acc@1: 81.2500 (81.6909)  Acc@5: 93.7500 (96.3693)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:08  Lr: 0.001875  Loss: 0.4226  Acc@1: 81.2500 (81.6982)  Acc@5: 93.7500 (96.2898)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:05  Lr: 0.001875  Loss: 0.3540  Acc@1: 81.2500 (81.8247)  Acc@5: 100.0000 (96.3841)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:01  Lr: 0.001875  Loss: 0.8342  Acc@1: 81.2500 (81.8496)  Acc@5: 100.0000 (96.4022)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 280/3750]  eta: 0:19:57  Lr: 0.001875  Loss: 0.3662  Acc@1: 81.2500 (81.8505)  Acc@5: 100.0000 (96.4858)  time: 0.3432  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 290/3750]  eta: 0:19:54  Lr: 0.001875  Loss: 0.6532  Acc@1: 81.2500 (81.8729)  Acc@5: 100.0000 (96.5636)  time: 0.3427  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 300/3750]  eta: 0:19:50  Lr: 0.001875  Loss: 0.4815  Acc@1: 81.2500 (81.9352)  Acc@5: 100.0000 (96.5739)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 310/3750]  eta: 0:19:46  Lr: 0.001875  Loss: 0.6085  Acc@1: 87.5000 (81.9735)  Acc@5: 93.7500 (96.5233)  time: 0.3431  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 320/3750]  eta: 0:19:43  Lr: 0.001875  Loss: 0.0597  Acc@1: 81.2500 (81.8536)  Acc@5: 93.7500 (96.4953)  time: 0.3434  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:39  Lr: 0.001875  Loss: 0.8366  Acc@1: 75.0000 (81.6654)  Acc@5: 93.7500 (96.4313)  time: 0.3442  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:36  Lr: 0.001875  Loss: 0.1996  Acc@1: 81.2500 (81.7449)  Acc@5: 93.7500 (96.4260)  time: 0.3446  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:32  Lr: 0.001875  Loss: 0.4210  Acc@1: 81.2500 (81.6774)  Acc@5: 100.0000 (96.4209)  time: 0.3438  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:29  Lr: 0.001875  Loss: 0.6773  Acc@1: 81.2500 (81.7348)  Acc@5: 100.0000 (96.4335)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:25  Lr: 0.001875  Loss: 0.5395  Acc@1: 81.2500 (81.7385)  Acc@5: 93.7500 (96.4454)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:21  Lr: 0.001875  Loss: 1.0133  Acc@1: 81.2500 (81.6601)  Acc@5: 93.7500 (96.4403)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:18  Lr: 0.001875  Loss: 0.4602  Acc@1: 81.2500 (81.6017)  Acc@5: 93.7500 (96.3715)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:14  Lr: 0.001875  Loss: 0.7221  Acc@1: 75.0000 (81.4214)  Acc@5: 93.7500 (96.3529)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:11  Lr: 0.001875  Loss: 0.6670  Acc@1: 75.0000 (81.3869)  Acc@5: 100.0000 (96.3808)  time: 0.3432  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:07  Lr: 0.001875  Loss: 0.7564  Acc@1: 81.2500 (81.3242)  Acc@5: 100.0000 (96.3331)  time: 0.3434  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:03  Lr: 0.001875  Loss: 0.7252  Acc@1: 75.0000 (81.2210)  Acc@5: 100.0000 (96.3747)  time: 0.3425  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:00  Lr: 0.001875  Loss: 0.4679  Acc@1: 81.2500 (81.3209)  Acc@5: 100.0000 (96.4286)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 450/3750]  eta: 0:18:56  Lr: 0.001875  Loss: 0.4639  Acc@1: 81.2500 (81.3609)  Acc@5: 100.0000 (96.4939)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 460/3750]  eta: 0:18:53  Lr: 0.001875  Loss: 0.5484  Acc@1: 81.2500 (81.4398)  Acc@5: 100.0000 (96.4615)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 470/3750]  eta: 0:18:49  Lr: 0.001875  Loss: 0.1408  Acc@1: 81.2500 (81.4358)  Acc@5: 93.7500 (96.4703)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 480/3750]  eta: 0:18:46  Lr: 0.001875  Loss: 0.7836  Acc@1: 81.2500 (81.5099)  Acc@5: 100.0000 (96.4917)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 490/3750]  eta: 0:18:43  Lr: 0.001875  Loss: 0.3508  Acc@1: 87.5000 (81.6573)  Acc@5: 100.0000 (96.5122)  time: 0.3444  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:39  Lr: 0.001875  Loss: 0.5996  Acc@1: 81.2500 (81.6367)  Acc@5: 100.0000 (96.5444)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:35  Lr: 0.001875  Loss: 0.6543  Acc@1: 81.2500 (81.5558)  Acc@5: 100.0000 (96.5264)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:32  Lr: 0.001875  Loss: 0.6069  Acc@1: 81.2500 (81.4299)  Acc@5: 93.7500 (96.4611)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:29  Lr: 0.001875  Loss: 0.8640  Acc@1: 81.2500 (81.4383)  Acc@5: 93.7500 (96.4807)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:25  Lr: 0.001875  Loss: 0.2765  Acc@1: 81.2500 (81.3886)  Acc@5: 93.7500 (96.4533)  time: 0.3442  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:22  Lr: 0.001875  Loss: 0.7462  Acc@1: 81.2500 (81.3748)  Acc@5: 93.7500 (96.4270)  time: 0.3461  data: 0.0031  max mem: 2500
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:19  Lr: 0.001875  Loss: 0.3269  Acc@1: 81.2500 (81.3948)  Acc@5: 93.7500 (96.3904)  time: 0.3471  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:15  Lr: 0.001875  Loss: 0.8604  Acc@1: 81.2500 (81.3923)  Acc@5: 93.7500 (96.3989)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:12  Lr: 0.001875  Loss: 0.3359  Acc@1: 81.2500 (81.3361)  Acc@5: 93.7500 (96.3855)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:08  Lr: 0.001875  Loss: 0.3893  Acc@1: 81.2500 (81.3240)  Acc@5: 100.0000 (96.4150)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:05  Lr: 0.001875  Loss: 1.0302  Acc@1: 81.2500 (81.3124)  Acc@5: 100.0000 (96.4018)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:01  Lr: 0.001875  Loss: 0.4771  Acc@1: 81.2500 (81.2807)  Acc@5: 93.7500 (96.4096)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 620/3750]  eta: 0:17:58  Lr: 0.001875  Loss: 0.2202  Acc@1: 81.2500 (81.3003)  Acc@5: 100.0000 (96.4372)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 630/3750]  eta: 0:17:54  Lr: 0.001875  Loss: 0.4852  Acc@1: 87.5000 (81.3986)  Acc@5: 100.0000 (96.4441)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 640/3750]  eta: 0:17:51  Lr: 0.001875  Loss: 0.9435  Acc@1: 87.5000 (81.3865)  Acc@5: 100.0000 (96.4314)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 650/3750]  eta: 0:17:47  Lr: 0.001875  Loss: 0.6286  Acc@1: 81.2500 (81.4132)  Acc@5: 100.0000 (96.4286)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 660/3750]  eta: 0:17:44  Lr: 0.001875  Loss: 0.6298  Acc@1: 81.2500 (81.4675)  Acc@5: 100.0000 (96.4637)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:41  Lr: 0.001875  Loss: 0.7173  Acc@1: 81.2500 (81.4363)  Acc@5: 100.0000 (96.4605)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:37  Lr: 0.001875  Loss: 0.3440  Acc@1: 75.0000 (81.3601)  Acc@5: 93.7500 (96.4391)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:34  Lr: 0.001875  Loss: 0.4394  Acc@1: 75.0000 (81.3404)  Acc@5: 93.7500 (96.4273)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:30  Lr: 0.001875  Loss: 0.1412  Acc@1: 81.2500 (81.3481)  Acc@5: 93.7500 (96.4158)  time: 0.3445  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:27  Lr: 0.001875  Loss: 0.5682  Acc@1: 81.2500 (81.3379)  Acc@5: 93.7500 (96.4135)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:23  Lr: 0.001875  Loss: 0.6475  Acc@1: 81.2500 (81.3887)  Acc@5: 100.0000 (96.4199)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:20  Lr: 0.001875  Loss: 0.4742  Acc@1: 81.2500 (81.3440)  Acc@5: 93.7500 (96.3834)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:16  Lr: 0.001875  Loss: 0.7123  Acc@1: 81.2500 (81.3343)  Acc@5: 93.7500 (96.3478)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:13  Lr: 0.001875  Loss: 0.2474  Acc@1: 87.5000 (81.4331)  Acc@5: 100.0000 (96.3881)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:10  Lr: 0.001875  Loss: 0.3005  Acc@1: 87.5000 (81.4635)  Acc@5: 100.0000 (96.4028)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:06  Lr: 0.001875  Loss: 0.2996  Acc@1: 81.2500 (81.5175)  Acc@5: 100.0000 (96.4251)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:03  Lr: 0.001875  Loss: 0.3233  Acc@1: 87.5000 (81.5861)  Acc@5: 100.0000 (96.4549)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 790/3750]  eta: 0:16:59  Lr: 0.001875  Loss: 0.6978  Acc@1: 87.5000 (81.5819)  Acc@5: 100.0000 (96.4444)  time: 0.3450  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 800/3750]  eta: 0:16:56  Lr: 0.001875  Loss: 0.4932  Acc@1: 81.2500 (81.5387)  Acc@5: 100.0000 (96.4341)  time: 0.3447  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 810/3750]  eta: 0:16:52  Lr: 0.001875  Loss: 0.8618  Acc@1: 81.2500 (81.5197)  Acc@5: 100.0000 (96.4396)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 820/3750]  eta: 0:16:49  Lr: 0.001875  Loss: 0.3420  Acc@1: 81.2500 (81.5317)  Acc@5: 93.7500 (96.4297)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 830/3750]  eta: 0:16:45  Lr: 0.001875  Loss: 0.7612  Acc@1: 81.2500 (81.4982)  Acc@5: 93.7500 (96.4425)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:42  Lr: 0.001875  Loss: 0.9687  Acc@1: 75.0000 (81.4507)  Acc@5: 100.0000 (96.4551)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:39  Lr: 0.001875  Loss: 0.9546  Acc@1: 75.0000 (81.4483)  Acc@5: 100.0000 (96.4600)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:35  Lr: 0.001875  Loss: 0.5502  Acc@1: 81.2500 (81.4387)  Acc@5: 100.0000 (96.4721)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:32  Lr: 0.001875  Loss: 0.5326  Acc@1: 81.2500 (81.4509)  Acc@5: 100.0000 (96.4839)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:28  Lr: 0.001875  Loss: 0.5280  Acc@1: 81.2500 (81.4203)  Acc@5: 100.0000 (96.4742)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:25  Lr: 0.001875  Loss: 0.6788  Acc@1: 75.0000 (81.3833)  Acc@5: 100.0000 (96.4787)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:21  Lr: 0.001875  Loss: 1.1946  Acc@1: 75.0000 (81.3610)  Acc@5: 100.0000 (96.4900)  time: 0.3450  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:18  Lr: 0.001875  Loss: 0.4288  Acc@1: 81.2500 (81.3735)  Acc@5: 100.0000 (96.4942)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:14  Lr: 0.001875  Loss: 0.5300  Acc@1: 81.2500 (81.3789)  Acc@5: 100.0000 (96.5052)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:11  Lr: 0.001875  Loss: 0.1368  Acc@1: 81.2500 (81.3440)  Acc@5: 100.0000 (96.5091)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:08  Lr: 0.001875  Loss: 0.4830  Acc@1: 75.0000 (81.3563)  Acc@5: 100.0000 (96.5064)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:04  Lr: 0.001875  Loss: 0.5962  Acc@1: 81.2500 (81.3617)  Acc@5: 93.7500 (96.5037)  time: 0.3452  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:01  Lr: 0.001875  Loss: 0.6246  Acc@1: 87.5000 (81.3996)  Acc@5: 93.7500 (96.4945)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 970/3750]  eta: 0:15:57  Lr: 0.001875  Loss: 0.1857  Acc@1: 81.2500 (81.4109)  Acc@5: 100.0000 (96.4920)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 980/3750]  eta: 0:15:54  Lr: 0.001875  Loss: 0.3195  Acc@1: 81.2500 (81.3902)  Acc@5: 100.0000 (96.4896)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 990/3750]  eta: 0:15:50  Lr: 0.001875  Loss: 0.5598  Acc@1: 81.2500 (81.4392)  Acc@5: 93.7500 (96.4934)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1000/3750]  eta: 0:15:47  Lr: 0.001875  Loss: 0.4172  Acc@1: 81.2500 (81.4186)  Acc@5: 93.7500 (96.4723)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:43  Lr: 0.001875  Loss: 0.6453  Acc@1: 81.2500 (81.4169)  Acc@5: 93.7500 (96.4639)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:40  Lr: 0.001875  Loss: 0.8632  Acc@1: 81.2500 (81.4520)  Acc@5: 100.0000 (96.4740)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:36  Lr: 0.001875  Loss: 0.3301  Acc@1: 81.2500 (81.4804)  Acc@5: 100.0000 (96.4779)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:33  Lr: 0.001875  Loss: 0.5350  Acc@1: 81.2500 (81.4661)  Acc@5: 93.7500 (96.4517)  time: 0.3432  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:29  Lr: 0.001875  Loss: 0.4912  Acc@1: 81.2500 (81.4284)  Acc@5: 93.7500 (96.4558)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:26  Lr: 0.001875  Loss: 0.2991  Acc@1: 81.2500 (81.4267)  Acc@5: 100.0000 (96.4833)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:23  Lr: 0.001875  Loss: 0.4613  Acc@1: 81.2500 (81.4484)  Acc@5: 100.0000 (96.4928)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:19  Lr: 0.001875  Loss: 0.4478  Acc@1: 81.2500 (81.4581)  Acc@5: 100.0000 (96.5021)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:16  Lr: 0.001875  Loss: 0.3757  Acc@1: 81.2500 (81.4505)  Acc@5: 100.0000 (96.5055)  time: 0.3440  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:12  Lr: 0.001875  Loss: 0.4379  Acc@1: 81.2500 (81.4771)  Acc@5: 100.0000 (96.5089)  time: 0.3434  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:09  Lr: 0.001875  Loss: 0.5795  Acc@1: 81.2500 (81.4750)  Acc@5: 100.0000 (96.5347)  time: 0.3439  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:05  Lr: 0.001875  Loss: 0.8539  Acc@1: 81.2500 (81.4953)  Acc@5: 100.0000 (96.5377)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:02  Lr: 0.001875  Loss: 0.8674  Acc@1: 81.2500 (81.4600)  Acc@5: 100.0000 (96.5351)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1140/3750]  eta: 0:14:58  Lr: 0.001875  Loss: 0.5951  Acc@1: 75.0000 (81.4308)  Acc@5: 100.0000 (96.5381)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1150/3750]  eta: 0:14:55  Lr: 0.001875  Loss: 0.2744  Acc@1: 75.0000 (81.4075)  Acc@5: 100.0000 (96.5356)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1160/3750]  eta: 0:14:51  Lr: 0.001875  Loss: 0.1849  Acc@1: 75.0000 (81.4169)  Acc@5: 100.0000 (96.5332)  time: 0.3432  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1170/3750]  eta: 0:14:48  Lr: 0.001875  Loss: 0.7538  Acc@1: 81.2500 (81.4101)  Acc@5: 93.7500 (96.5201)  time: 0.3436  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:45  Lr: 0.001875  Loss: 0.3290  Acc@1: 81.2500 (81.4141)  Acc@5: 93.7500 (96.5284)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:41  Lr: 0.001875  Loss: 0.3123  Acc@1: 81.2500 (81.4179)  Acc@5: 93.7500 (96.5208)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:38  Lr: 0.001875  Loss: 0.2325  Acc@1: 87.5000 (81.4425)  Acc@5: 93.7500 (96.5237)  time: 0.3428  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:34  Lr: 0.001875  Loss: 0.7471  Acc@1: 87.5000 (81.4306)  Acc@5: 100.0000 (96.5421)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:31  Lr: 0.001875  Loss: 0.1511  Acc@1: 81.2500 (81.4548)  Acc@5: 100.0000 (96.5448)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:27  Lr: 0.001875  Loss: 0.3482  Acc@1: 81.2500 (81.4632)  Acc@5: 100.0000 (96.5323)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:24  Lr: 0.001875  Loss: 0.2751  Acc@1: 81.2500 (81.4263)  Acc@5: 93.7500 (96.5199)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:20  Lr: 0.001875  Loss: 0.4082  Acc@1: 81.2500 (81.4349)  Acc@5: 93.7500 (96.5078)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:17  Lr: 0.001875  Loss: 0.3283  Acc@1: 87.5000 (81.4582)  Acc@5: 100.0000 (96.5157)  time: 0.3431  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:13  Lr: 0.001875  Loss: 0.3665  Acc@1: 81.2500 (81.4516)  Acc@5: 100.0000 (96.5185)  time: 0.3428  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:10  Lr: 0.001875  Loss: 0.4216  Acc@1: 81.2500 (81.4354)  Acc@5: 100.0000 (96.5310)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:07  Lr: 0.001875  Loss: 0.6820  Acc@1: 81.2500 (81.4340)  Acc@5: 100.0000 (96.5240)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:03  Lr: 0.001875  Loss: 0.2907  Acc@1: 81.2500 (81.4085)  Acc@5: 100.0000 (96.5267)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:00  Lr: 0.001875  Loss: 0.6353  Acc@1: 81.2500 (81.4455)  Acc@5: 100.0000 (96.5341)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1320/3750]  eta: 0:13:56  Lr: 0.001875  Loss: 0.9143  Acc@1: 81.2500 (81.4298)  Acc@5: 93.7500 (96.5083)  time: 0.3453  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1330/3750]  eta: 0:13:53  Lr: 0.001875  Loss: 0.6789  Acc@1: 81.2500 (81.4378)  Acc@5: 100.0000 (96.5205)  time: 0.3449  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1340/3750]  eta: 0:13:49  Lr: 0.001875  Loss: 0.4608  Acc@1: 81.2500 (81.4551)  Acc@5: 100.0000 (96.5138)  time: 0.3444  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:46  Lr: 0.001875  Loss: 0.7228  Acc@1: 87.5000 (81.4767)  Acc@5: 100.0000 (96.5165)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:42  Lr: 0.001875  Loss: 1.0226  Acc@1: 81.2500 (81.4796)  Acc@5: 100.0000 (96.5329)  time: 0.3437  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:39  Lr: 0.001875  Loss: 0.6830  Acc@1: 87.5000 (81.5326)  Acc@5: 100.0000 (96.5354)  time: 0.3440  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:36  Lr: 0.001875  Loss: 0.7241  Acc@1: 81.2500 (81.5396)  Acc@5: 100.0000 (96.5378)  time: 0.3459  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:32  Lr: 0.001875  Loss: 0.3113  Acc@1: 81.2500 (81.5600)  Acc@5: 100.0000 (96.5537)  time: 0.3458  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:29  Lr: 0.001875  Loss: 0.5492  Acc@1: 81.2500 (81.5310)  Acc@5: 100.0000 (96.5471)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:25  Lr: 0.001875  Loss: 0.5940  Acc@1: 75.0000 (81.5158)  Acc@5: 93.7500 (96.5406)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:22  Lr: 0.001875  Loss: 0.4178  Acc@1: 81.2500 (81.5491)  Acc@5: 93.7500 (96.5517)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:18  Lr: 0.001875  Loss: 0.5690  Acc@1: 87.5000 (81.5819)  Acc@5: 100.0000 (96.5540)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:15  Lr: 0.001875  Loss: 0.3320  Acc@1: 87.5000 (81.6013)  Acc@5: 100.0000 (96.5562)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:12  Lr: 0.001875  Loss: 0.5707  Acc@1: 81.2500 (81.5860)  Acc@5: 100.0000 (96.5627)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:08  Lr: 0.001875  Loss: 0.4965  Acc@1: 81.2500 (81.6093)  Acc@5: 100.0000 (96.5691)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:05  Lr: 0.001875  Loss: 0.9988  Acc@1: 81.2500 (81.6069)  Acc@5: 100.0000 (96.5755)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:01  Lr: 0.001875  Loss: 0.4560  Acc@1: 81.2500 (81.6129)  Acc@5: 100.0000 (96.5944)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1490/3750]  eta: 0:12:58  Lr: 0.001875  Loss: 0.4638  Acc@1: 81.2500 (81.6021)  Acc@5: 100.0000 (96.5962)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1500/3750]  eta: 0:12:54  Lr: 0.001875  Loss: 0.4120  Acc@1: 87.5000 (81.6248)  Acc@5: 100.0000 (96.5939)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1510/3750]  eta: 0:12:51  Lr: 0.001875  Loss: 0.1806  Acc@1: 81.2500 (81.6181)  Acc@5: 100.0000 (96.5958)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:47  Lr: 0.001875  Loss: 0.6021  Acc@1: 81.2500 (81.6445)  Acc@5: 100.0000 (96.6100)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:44  Lr: 0.001875  Loss: 0.7680  Acc@1: 81.2500 (81.6664)  Acc@5: 100.0000 (96.6035)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:41  Lr: 0.001875  Loss: 0.6667  Acc@1: 81.2500 (81.6880)  Acc@5: 93.7500 (96.6053)  time: 0.3440  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:37  Lr: 0.001875  Loss: 0.2751  Acc@1: 81.2500 (81.6852)  Acc@5: 93.7500 (96.5949)  time: 0.3440  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:34  Lr: 0.001875  Loss: 0.4032  Acc@1: 81.2500 (81.6664)  Acc@5: 93.7500 (96.5847)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:30  Lr: 0.001875  Loss: 0.8497  Acc@1: 81.2500 (81.6598)  Acc@5: 93.7500 (96.5866)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:27  Lr: 0.001875  Loss: 0.6208  Acc@1: 81.2500 (81.6769)  Acc@5: 93.7500 (96.5805)  time: 0.3436  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:23  Lr: 0.001875  Loss: 1.0144  Acc@1: 81.2500 (81.6428)  Acc@5: 100.0000 (96.5902)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:20  Lr: 0.001875  Loss: 0.5495  Acc@1: 81.2500 (81.6443)  Acc@5: 100.0000 (96.5998)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:16  Lr: 0.001875  Loss: 0.4354  Acc@1: 81.2500 (81.6535)  Acc@5: 93.7500 (96.5821)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:13  Lr: 0.001875  Loss: 0.4448  Acc@1: 87.5000 (81.6857)  Acc@5: 93.7500 (96.5839)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:10  Lr: 0.001875  Loss: 0.8051  Acc@1: 81.2500 (81.6600)  Acc@5: 93.7500 (96.5665)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:06  Lr: 0.001875  Loss: 0.4436  Acc@1: 81.2500 (81.6461)  Acc@5: 93.7500 (96.5684)  time: 0.3440  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:03  Lr: 0.001875  Loss: 0.3999  Acc@1: 81.2500 (81.6437)  Acc@5: 100.0000 (96.5703)  time: 0.3451  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1660/3750]  eta: 0:11:59  Lr: 0.001875  Loss: 0.6015  Acc@1: 81.2500 (81.6639)  Acc@5: 100.0000 (96.5721)  time: 0.3454  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1670/3750]  eta: 0:11:56  Lr: 0.001875  Loss: 0.7134  Acc@1: 81.2500 (81.6502)  Acc@5: 100.0000 (96.5776)  time: 0.3444  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1680/3750]  eta: 0:11:52  Lr: 0.001875  Loss: 0.3506  Acc@1: 81.2500 (81.6701)  Acc@5: 100.0000 (96.5869)  time: 0.3449  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1690/3750]  eta: 0:11:49  Lr: 0.001875  Loss: 0.5193  Acc@1: 81.2500 (81.6824)  Acc@5: 100.0000 (96.5886)  time: 0.3450  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:46  Lr: 0.001875  Loss: 0.7175  Acc@1: 81.2500 (81.6689)  Acc@5: 93.7500 (96.5645)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:42  Lr: 0.001875  Loss: 0.6435  Acc@1: 81.2500 (81.6920)  Acc@5: 93.7500 (96.5627)  time: 0.3460  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:39  Lr: 0.001875  Loss: 0.1030  Acc@1: 81.2500 (81.7040)  Acc@5: 100.0000 (96.5681)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:35  Lr: 0.001875  Loss: 0.3767  Acc@1: 81.2500 (81.7013)  Acc@5: 100.0000 (96.5663)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:32  Lr: 0.001875  Loss: 0.8970  Acc@1: 81.2500 (81.6880)  Acc@5: 100.0000 (96.5645)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:28  Lr: 0.001875  Loss: 0.8240  Acc@1: 75.0000 (81.6640)  Acc@5: 100.0000 (96.5698)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:25  Lr: 0.001875  Loss: 0.6420  Acc@1: 81.2500 (81.6830)  Acc@5: 100.0000 (96.5716)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:21  Lr: 0.001875  Loss: 0.4311  Acc@1: 81.2500 (81.6841)  Acc@5: 100.0000 (96.5803)  time: 0.3435  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:18  Lr: 0.001875  Loss: 0.8822  Acc@1: 81.2500 (81.6571)  Acc@5: 93.7500 (96.5714)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:14  Lr: 0.001875  Loss: 1.0373  Acc@1: 87.5000 (81.6967)  Acc@5: 93.7500 (96.5697)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:11  Lr: 0.001875  Loss: 0.9177  Acc@1: 87.5000 (81.7046)  Acc@5: 100.0000 (96.5713)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:08  Lr: 0.001875  Loss: 0.5457  Acc@1: 81.2500 (81.7055)  Acc@5: 100.0000 (96.5799)  time: 0.3440  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:04  Lr: 0.001875  Loss: 0.7952  Acc@1: 81.2500 (81.7168)  Acc@5: 100.0000 (96.5815)  time: 0.3432  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:01  Lr: 0.001875  Loss: 0.3648  Acc@1: 81.2500 (81.7279)  Acc@5: 100.0000 (96.5866)  time: 0.3425  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1840/3750]  eta: 0:10:57  Lr: 0.001875  Loss: 0.4319  Acc@1: 81.2500 (81.7219)  Acc@5: 100.0000 (96.5813)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1850/3750]  eta: 0:10:54  Lr: 0.001875  Loss: 0.2652  Acc@1: 81.2500 (81.7599)  Acc@5: 100.0000 (96.5897)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1860/3750]  eta: 0:10:50  Lr: 0.001875  Loss: 0.7220  Acc@1: 81.2500 (81.7370)  Acc@5: 100.0000 (96.5912)  time: 0.3442  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:47  Lr: 0.001875  Loss: 0.4901  Acc@1: 81.2500 (81.7410)  Acc@5: 100.0000 (96.5961)  time: 0.3442  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:43  Lr: 0.001875  Loss: 0.3842  Acc@1: 81.2500 (81.7251)  Acc@5: 100.0000 (96.5909)  time: 0.3438  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:40  Lr: 0.001875  Loss: 0.8096  Acc@1: 81.2500 (81.7259)  Acc@5: 100.0000 (96.5924)  time: 0.3439  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:37  Lr: 0.001875  Loss: 0.8826  Acc@1: 81.2500 (81.6938)  Acc@5: 93.7500 (96.5840)  time: 0.3438  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:33  Lr: 0.001875  Loss: 0.4540  Acc@1: 81.2500 (81.6752)  Acc@5: 93.7500 (96.5856)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:30  Lr: 0.001875  Loss: 0.3985  Acc@1: 81.2500 (81.6502)  Acc@5: 100.0000 (96.5773)  time: 0.3433  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:26  Lr: 0.001875  Loss: 0.4745  Acc@1: 81.2500 (81.6513)  Acc@5: 93.7500 (96.5756)  time: 0.3434  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:23  Lr: 0.001875  Loss: 0.2013  Acc@1: 81.2500 (81.6783)  Acc@5: 100.0000 (96.5836)  time: 0.3428  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:19  Lr: 0.001875  Loss: 0.3627  Acc@1: 87.5000 (81.6825)  Acc@5: 100.0000 (96.5819)  time: 0.3436  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:16  Lr: 0.001875  Loss: 0.4060  Acc@1: 81.2500 (81.6643)  Acc@5: 93.7500 (96.5802)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:12  Lr: 0.001875  Loss: 0.7731  Acc@1: 81.2500 (81.6559)  Acc@5: 93.7500 (96.5722)  time: 0.3432  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:09  Lr: 0.001875  Loss: 1.2707  Acc@1: 75.0000 (81.6475)  Acc@5: 100.0000 (96.5705)  time: 0.3440  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:05  Lr: 0.001875  Loss: 0.8004  Acc@1: 75.0000 (81.6330)  Acc@5: 93.7500 (96.5658)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:02  Lr: 0.001875  Loss: 0.3810  Acc@1: 81.2500 (81.6217)  Acc@5: 93.7500 (96.5673)  time: 0.3434  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2010/3750]  eta: 0:09:59  Lr: 0.001875  Loss: 0.4557  Acc@1: 81.2500 (81.6043)  Acc@5: 100.0000 (96.5751)  time: 0.3441  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2020/3750]  eta: 0:09:55  Lr: 0.001875  Loss: 0.2711  Acc@1: 81.2500 (81.6118)  Acc@5: 100.0000 (96.5642)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2030/3750]  eta: 0:09:52  Lr: 0.001875  Loss: 0.6022  Acc@1: 81.2500 (81.6224)  Acc@5: 100.0000 (96.5750)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:48  Lr: 0.001875  Loss: 0.5144  Acc@1: 81.2500 (81.6205)  Acc@5: 100.0000 (96.5703)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:45  Lr: 0.001875  Loss: 0.9265  Acc@1: 87.5000 (81.6431)  Acc@5: 100.0000 (96.5809)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:41  Lr: 0.001875  Loss: 0.5914  Acc@1: 87.5000 (81.6503)  Acc@5: 100.0000 (96.5854)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:38  Lr: 0.001875  Loss: 0.4555  Acc@1: 81.2500 (81.6453)  Acc@5: 100.0000 (96.5868)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:34  Lr: 0.001875  Loss: 0.4339  Acc@1: 81.2500 (81.6284)  Acc@5: 100.0000 (96.5792)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:31  Lr: 0.001875  Loss: 0.4672  Acc@1: 81.2500 (81.6356)  Acc@5: 93.7500 (96.5806)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:28  Lr: 0.001875  Loss: 0.9459  Acc@1: 81.2500 (81.6189)  Acc@5: 93.7500 (96.5760)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:24  Lr: 0.001875  Loss: 0.7440  Acc@1: 75.0000 (81.6023)  Acc@5: 100.0000 (96.5775)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:21  Lr: 0.001875  Loss: 0.2839  Acc@1: 81.2500 (81.6066)  Acc@5: 100.0000 (96.5847)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:17  Lr: 0.001875  Loss: 0.8828  Acc@1: 81.2500 (81.6107)  Acc@5: 100.0000 (96.5861)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:14  Lr: 0.001875  Loss: 0.5648  Acc@1: 81.2500 (81.6032)  Acc@5: 93.7500 (96.5729)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:10  Lr: 0.001875  Loss: 0.6129  Acc@1: 81.2500 (81.6161)  Acc@5: 93.7500 (96.5743)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:07  Lr: 0.001875  Loss: 0.8999  Acc@1: 81.2500 (81.6028)  Acc@5: 100.0000 (96.5786)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:03  Lr: 0.001875  Loss: 0.4768  Acc@1: 81.2500 (81.6012)  Acc@5: 100.0000 (96.5799)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:00  Lr: 0.001875  Loss: 0.3258  Acc@1: 81.2500 (81.6053)  Acc@5: 100.0000 (96.5841)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2190/3750]  eta: 0:08:57  Lr: 0.001875  Loss: 0.4518  Acc@1: 81.2500 (81.6123)  Acc@5: 100.0000 (96.5798)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2200/3750]  eta: 0:08:53  Lr: 0.001875  Loss: 0.2840  Acc@1: 81.2500 (81.6192)  Acc@5: 93.7500 (96.5754)  time: 0.3439  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:50  Lr: 0.001875  Loss: 0.6889  Acc@1: 81.2500 (81.6203)  Acc@5: 93.7500 (96.5739)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:46  Lr: 0.001875  Loss: 0.6716  Acc@1: 81.2500 (81.6271)  Acc@5: 100.0000 (96.5781)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:43  Lr: 0.001875  Loss: 0.1605  Acc@1: 81.2500 (81.6226)  Acc@5: 100.0000 (96.5851)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:39  Lr: 0.001875  Loss: 1.0418  Acc@1: 81.2500 (81.5930)  Acc@5: 100.0000 (96.5808)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:36  Lr: 0.001875  Loss: 0.6818  Acc@1: 75.0000 (81.5804)  Acc@5: 93.7500 (96.5821)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:32  Lr: 0.001875  Loss: 0.2838  Acc@1: 81.2500 (81.6011)  Acc@5: 100.0000 (96.5972)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:29  Lr: 0.001875  Loss: 0.7335  Acc@1: 81.2500 (81.5940)  Acc@5: 100.0000 (96.6039)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:26  Lr: 0.001875  Loss: 0.7427  Acc@1: 75.0000 (81.5733)  Acc@5: 93.7500 (96.5887)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:22  Lr: 0.001875  Loss: 0.4282  Acc@1: 81.2500 (81.5801)  Acc@5: 100.0000 (96.5981)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:19  Lr: 0.001875  Loss: 0.7503  Acc@1: 81.2500 (81.5678)  Acc@5: 100.0000 (96.6047)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:15  Lr: 0.001875  Loss: 0.5208  Acc@1: 81.2500 (81.5637)  Acc@5: 100.0000 (96.6032)  time: 0.3477  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:12  Lr: 0.001875  Loss: 0.4864  Acc@1: 81.2500 (81.5704)  Acc@5: 100.0000 (96.6017)  time: 0.3467  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:08  Lr: 0.001875  Loss: 0.4406  Acc@1: 81.2500 (81.5610)  Acc@5: 93.7500 (96.5975)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:05  Lr: 0.001875  Loss: 0.5601  Acc@1: 81.2500 (81.5650)  Acc@5: 93.7500 (96.5987)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:02  Lr: 0.001875  Loss: 0.3838  Acc@1: 81.2500 (81.5610)  Acc@5: 100.0000 (96.6052)  time: 0.3454  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2360/3750]  eta: 0:07:58  Lr: 0.001875  Loss: 0.3798  Acc@1: 81.2500 (81.5730)  Acc@5: 100.0000 (96.6090)  time: 0.3450  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2370/3750]  eta: 0:07:55  Lr: 0.001875  Loss: 0.3419  Acc@1: 81.2500 (81.5663)  Acc@5: 100.0000 (96.6101)  time: 0.3451  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:51  Lr: 0.001875  Loss: 1.0093  Acc@1: 81.2500 (81.5624)  Acc@5: 100.0000 (96.6138)  time: 0.3463  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:48  Lr: 0.001875  Loss: 0.3902  Acc@1: 81.2500 (81.5767)  Acc@5: 100.0000 (96.6201)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:44  Lr: 0.001875  Loss: 0.6842  Acc@1: 81.2500 (81.5728)  Acc@5: 100.0000 (96.6186)  time: 0.3444  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:41  Lr: 0.001875  Loss: 0.3229  Acc@1: 81.2500 (81.5585)  Acc@5: 100.0000 (96.6145)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:37  Lr: 0.001875  Loss: 0.3484  Acc@1: 81.2500 (81.5675)  Acc@5: 93.7500 (96.6130)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:34  Lr: 0.001875  Loss: 0.6466  Acc@1: 81.2500 (81.5457)  Acc@5: 93.7500 (96.5961)  time: 0.3438  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:31  Lr: 0.001875  Loss: 0.4693  Acc@1: 75.0000 (81.5240)  Acc@5: 93.7500 (96.5895)  time: 0.3436  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:27  Lr: 0.001875  Loss: 0.3926  Acc@1: 75.0000 (81.5152)  Acc@5: 93.7500 (96.5805)  time: 0.3445  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:24  Lr: 0.001875  Loss: 1.1132  Acc@1: 81.2500 (81.5167)  Acc@5: 93.7500 (96.5690)  time: 0.3453  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:20  Lr: 0.001875  Loss: 0.6351  Acc@1: 81.2500 (81.5131)  Acc@5: 93.7500 (96.5702)  time: 0.3444  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:17  Lr: 0.001875  Loss: 0.6394  Acc@1: 81.2500 (81.5070)  Acc@5: 93.7500 (96.5639)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:13  Lr: 0.001875  Loss: 0.3590  Acc@1: 81.2500 (81.5034)  Acc@5: 93.7500 (96.5601)  time: 0.3438  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:10  Lr: 0.001875  Loss: 0.4892  Acc@1: 81.2500 (81.4974)  Acc@5: 100.0000 (96.5614)  time: 0.3446  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:06  Lr: 0.001875  Loss: 0.2449  Acc@1: 81.2500 (81.5188)  Acc@5: 100.0000 (96.5601)  time: 0.3444  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:03  Lr: 0.001875  Loss: 0.9721  Acc@1: 87.5000 (81.5227)  Acc@5: 93.7500 (96.5589)  time: 0.3433  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:00  Lr: 0.001875  Loss: 0.4970  Acc@1: 87.5000 (81.5290)  Acc@5: 100.0000 (96.5626)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2540/3750]  eta: 0:06:56  Lr: 0.001875  Loss: 0.5928  Acc@1: 81.2500 (81.5279)  Acc@5: 93.7500 (96.5516)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:53  Lr: 0.001875  Loss: 0.4998  Acc@1: 81.2500 (81.5122)  Acc@5: 100.0000 (96.5577)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:49  Lr: 0.001875  Loss: 0.5895  Acc@1: 75.0000 (81.5038)  Acc@5: 100.0000 (96.5541)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:46  Lr: 0.001875  Loss: 0.6513  Acc@1: 75.0000 (81.4980)  Acc@5: 93.7500 (96.5480)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:42  Lr: 0.001875  Loss: 0.4674  Acc@1: 81.2500 (81.4970)  Acc@5: 93.7500 (96.5493)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:39  Lr: 0.001875  Loss: 0.6381  Acc@1: 81.2500 (81.4985)  Acc@5: 100.0000 (96.5530)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:35  Lr: 0.001875  Loss: 0.2735  Acc@1: 81.2500 (81.5023)  Acc@5: 100.0000 (96.5566)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:32  Lr: 0.001875  Loss: 0.4122  Acc@1: 81.2500 (81.5133)  Acc@5: 100.0000 (96.5578)  time: 0.3429  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:29  Lr: 0.001875  Loss: 0.4152  Acc@1: 87.5000 (81.5290)  Acc@5: 93.7500 (96.5543)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:25  Lr: 0.001875  Loss: 0.3247  Acc@1: 81.2500 (81.5161)  Acc@5: 93.7500 (96.5507)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:22  Lr: 0.001875  Loss: 0.9521  Acc@1: 81.2500 (81.5198)  Acc@5: 93.7500 (96.5496)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:18  Lr: 0.001875  Loss: 0.3863  Acc@1: 81.2500 (81.5376)  Acc@5: 100.0000 (96.5485)  time: 0.3437  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:15  Lr: 0.001875  Loss: 0.3431  Acc@1: 87.5000 (81.5412)  Acc@5: 100.0000 (96.5497)  time: 0.3440  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:11  Lr: 0.001875  Loss: 0.6023  Acc@1: 81.2500 (81.5472)  Acc@5: 100.0000 (96.5533)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:08  Lr: 0.001875  Loss: 0.2345  Acc@1: 87.5000 (81.5554)  Acc@5: 100.0000 (96.5521)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:04  Lr: 0.001875  Loss: 0.6329  Acc@1: 87.5000 (81.5635)  Acc@5: 100.0000 (96.5556)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:01  Lr: 0.001875  Loss: 0.3632  Acc@1: 87.5000 (81.5624)  Acc@5: 100.0000 (96.5453)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2710/3750]  eta: 0:05:58  Lr: 0.001875  Loss: 0.9947  Acc@1: 81.2500 (81.5520)  Acc@5: 100.0000 (96.5465)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:54  Lr: 0.001875  Loss: 0.4638  Acc@1: 81.2500 (81.5601)  Acc@5: 100.0000 (96.5546)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:51  Lr: 0.001875  Loss: 0.3817  Acc@1: 87.5000 (81.5773)  Acc@5: 100.0000 (96.5535)  time: 0.3422  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:47  Lr: 0.001875  Loss: 0.3310  Acc@1: 81.2500 (81.5761)  Acc@5: 93.7500 (96.5501)  time: 0.3422  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:44  Lr: 0.001875  Loss: 0.4865  Acc@1: 81.2500 (81.5794)  Acc@5: 93.7500 (96.5535)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:40  Lr: 0.001875  Loss: 0.7791  Acc@1: 87.5000 (81.5896)  Acc@5: 100.0000 (96.5615)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:37  Lr: 0.001875  Loss: 0.6635  Acc@1: 87.5000 (81.5973)  Acc@5: 100.0000 (96.5581)  time: 0.3437  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:33  Lr: 0.001875  Loss: 0.6220  Acc@1: 87.5000 (81.6118)  Acc@5: 100.0000 (96.5660)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:30  Lr: 0.001875  Loss: 0.5481  Acc@1: 81.2500 (81.6016)  Acc@5: 100.0000 (96.5559)  time: 0.3450  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:27  Lr: 0.001875  Loss: 0.3819  Acc@1: 81.2500 (81.5981)  Acc@5: 93.7500 (96.5503)  time: 0.3447  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:23  Lr: 0.001875  Loss: 0.6006  Acc@1: 81.2500 (81.5813)  Acc@5: 93.7500 (96.5426)  time: 0.3454  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:20  Lr: 0.001875  Loss: 0.2589  Acc@1: 81.2500 (81.5757)  Acc@5: 100.0000 (96.5460)  time: 0.3462  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:16  Lr: 0.001875  Loss: 0.8881  Acc@1: 81.2500 (81.5613)  Acc@5: 100.0000 (96.5405)  time: 0.3448  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:13  Lr: 0.001875  Loss: 0.4709  Acc@1: 81.2500 (81.5558)  Acc@5: 93.7500 (96.5329)  time: 0.3436  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:09  Lr: 0.001875  Loss: 0.3013  Acc@1: 81.2500 (81.5723)  Acc@5: 100.0000 (96.5451)  time: 0.3432  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:06  Lr: 0.001875  Loss: 0.6445  Acc@1: 81.2500 (81.5668)  Acc@5: 100.0000 (96.5397)  time: 0.3435  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:02  Lr: 0.001875  Loss: 0.4448  Acc@1: 81.2500 (81.5809)  Acc@5: 100.0000 (96.5495)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2880/3750]  eta: 0:04:59  Lr: 0.001875  Loss: 0.7787  Acc@1: 81.2500 (81.5841)  Acc@5: 100.0000 (96.5463)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2890/3750]  eta: 0:04:56  Lr: 0.001875  Loss: 0.4558  Acc@1: 81.2500 (81.5959)  Acc@5: 100.0000 (96.5453)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:52  Lr: 0.001875  Loss: 0.5540  Acc@1: 81.2500 (81.6055)  Acc@5: 100.0000 (96.5508)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:49  Lr: 0.001875  Loss: 0.6439  Acc@1: 81.2500 (81.6064)  Acc@5: 100.0000 (96.5519)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:45  Lr: 0.001875  Loss: 0.4428  Acc@1: 81.2500 (81.6052)  Acc@5: 100.0000 (96.5487)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:42  Lr: 0.001875  Loss: 0.9055  Acc@1: 81.2500 (81.5997)  Acc@5: 100.0000 (96.5541)  time: 0.3433  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:38  Lr: 0.001875  Loss: 0.7762  Acc@1: 81.2500 (81.6113)  Acc@5: 100.0000 (96.5509)  time: 0.3436  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:35  Lr: 0.001875  Loss: 0.5499  Acc@1: 87.5000 (81.6206)  Acc@5: 100.0000 (96.5563)  time: 0.3429  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:31  Lr: 0.001875  Loss: 0.5058  Acc@1: 81.2500 (81.6194)  Acc@5: 100.0000 (96.5573)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:28  Lr: 0.001875  Loss: 0.5935  Acc@1: 81.2500 (81.6097)  Acc@5: 100.0000 (96.5584)  time: 0.3424  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:25  Lr: 0.001875  Loss: 0.5525  Acc@1: 81.2500 (81.5938)  Acc@5: 100.0000 (96.5616)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:21  Lr: 0.001875  Loss: 0.3489  Acc@1: 81.2500 (81.5969)  Acc@5: 93.7500 (96.5542)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:18  Lr: 0.001875  Loss: 0.2805  Acc@1: 81.2500 (81.5978)  Acc@5: 100.0000 (96.5616)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:14  Lr: 0.001875  Loss: 0.4970  Acc@1: 81.2500 (81.5904)  Acc@5: 100.0000 (96.5585)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:11  Lr: 0.001875  Loss: 0.5176  Acc@1: 75.0000 (81.5769)  Acc@5: 93.7500 (96.5492)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:07  Lr: 0.001875  Loss: 0.5106  Acc@1: 75.0000 (81.5676)  Acc@5: 93.7500 (96.5482)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:04  Lr: 0.001875  Loss: 0.2826  Acc@1: 81.2500 (81.5706)  Acc@5: 100.0000 (96.5472)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:00  Lr: 0.001875  Loss: 0.6241  Acc@1: 81.2500 (81.5716)  Acc@5: 100.0000 (96.5462)  time: 0.3435  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3060/3750]  eta: 0:03:57  Lr: 0.001875  Loss: 0.7399  Acc@1: 81.2500 (81.5808)  Acc@5: 100.0000 (96.5514)  time: 0.3437  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.4982  Acc@1: 81.2500 (81.5878)  Acc@5: 100.0000 (96.5585)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:50  Lr: 0.001875  Loss: 1.2316  Acc@1: 81.2500 (81.5807)  Acc@5: 100.0000 (96.5555)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:47  Lr: 0.001875  Loss: 0.3571  Acc@1: 81.2500 (81.5755)  Acc@5: 93.7500 (96.5525)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:43  Lr: 0.001875  Loss: 0.4761  Acc@1: 81.2500 (81.5826)  Acc@5: 100.0000 (96.5596)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:40  Lr: 0.001875  Loss: 0.5833  Acc@1: 81.2500 (81.5755)  Acc@5: 100.0000 (96.5566)  time: 0.3442  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:36  Lr: 0.001875  Loss: 0.8993  Acc@1: 75.0000 (81.5684)  Acc@5: 93.7500 (96.5496)  time: 0.3438  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.7024  Acc@1: 75.0000 (81.5574)  Acc@5: 93.7500 (96.5426)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:29  Lr: 0.001875  Loss: 0.3496  Acc@1: 81.2500 (81.5564)  Acc@5: 93.7500 (96.5357)  time: 0.3461  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:26  Lr: 0.001875  Loss: 0.8138  Acc@1: 81.2500 (81.5535)  Acc@5: 100.0000 (96.5447)  time: 0.3452  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.6361  Acc@1: 81.2500 (81.5466)  Acc@5: 100.0000 (96.5458)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:19  Lr: 0.001875  Loss: 0.2124  Acc@1: 81.2500 (81.5575)  Acc@5: 100.0000 (96.5547)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:16  Lr: 0.001875  Loss: 0.1414  Acc@1: 81.2500 (81.5565)  Acc@5: 100.0000 (96.5597)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:12  Lr: 0.001875  Loss: 1.1491  Acc@1: 75.0000 (81.5477)  Acc@5: 100.0000 (96.5567)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:09  Lr: 0.001875  Loss: 0.5575  Acc@1: 75.0000 (81.5351)  Acc@5: 93.7500 (96.5558)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:05  Lr: 0.001875  Loss: 0.6165  Acc@1: 75.0000 (81.5244)  Acc@5: 93.7500 (96.5568)  time: 0.3460  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:02  Lr: 0.001875  Loss: 0.4272  Acc@1: 75.0000 (81.5139)  Acc@5: 100.0000 (96.5539)  time: 0.3446  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3230/3750]  eta: 0:02:58  Lr: 0.001875  Loss: 0.5112  Acc@1: 81.2500 (81.5169)  Acc@5: 100.0000 (96.5549)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:55  Lr: 0.001875  Loss: 0.7702  Acc@1: 81.2500 (81.4988)  Acc@5: 100.0000 (96.5520)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.5727  Acc@1: 81.2500 (81.5057)  Acc@5: 100.0000 (96.5568)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:48  Lr: 0.001875  Loss: 0.5444  Acc@1: 81.2500 (81.4953)  Acc@5: 100.0000 (96.5540)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 0.3213  Acc@1: 81.2500 (81.4946)  Acc@5: 93.7500 (96.5530)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:41  Lr: 0.001875  Loss: 0.5288  Acc@1: 81.2500 (81.4786)  Acc@5: 93.7500 (96.5445)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 0.6822  Acc@1: 81.2500 (81.4760)  Acc@5: 93.7500 (96.5436)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:34  Lr: 0.001875  Loss: 0.4299  Acc@1: 81.2500 (81.4791)  Acc@5: 93.7500 (96.5465)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:31  Lr: 0.001875  Loss: 0.4756  Acc@1: 81.2500 (81.4803)  Acc@5: 100.0000 (96.5399)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.5567  Acc@1: 81.2500 (81.4815)  Acc@5: 100.0000 (96.5428)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:24  Lr: 0.001875  Loss: 0.4189  Acc@1: 81.2500 (81.4695)  Acc@5: 100.0000 (96.5401)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.4425  Acc@1: 81.2500 (81.4726)  Acc@5: 100.0000 (96.5430)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:17  Lr: 0.001875  Loss: 0.7491  Acc@1: 81.2500 (81.4514)  Acc@5: 93.7500 (96.5383)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.6575  Acc@1: 81.2500 (81.4583)  Acc@5: 100.0000 (96.5431)  time: 0.3440  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:10  Lr: 0.001875  Loss: 0.4724  Acc@1: 81.2500 (81.4447)  Acc@5: 93.7500 (96.5311)  time: 0.3442  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.4977  Acc@1: 81.2500 (81.4459)  Acc@5: 93.7500 (96.5339)  time: 0.3449  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:03  Lr: 0.001875  Loss: 0.2763  Acc@1: 81.2500 (81.4417)  Acc@5: 100.0000 (96.5368)  time: 0.3452  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 0.5381  Acc@1: 75.0000 (81.4209)  Acc@5: 100.0000 (96.5378)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.6504  Acc@1: 75.0000 (81.4112)  Acc@5: 100.0000 (96.5388)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 1.1188  Acc@1: 75.0000 (81.4126)  Acc@5: 100.0000 (96.5379)  time: 0.3445  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.9335  Acc@1: 87.5000 (81.4158)  Acc@5: 100.0000 (96.5407)  time: 0.3455  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:46  Lr: 0.001875  Loss: 0.4477  Acc@1: 87.5000 (81.4171)  Acc@5: 100.0000 (96.5417)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.4708  Acc@1: 75.0000 (81.3949)  Acc@5: 100.0000 (96.5390)  time: 0.3443  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:39  Lr: 0.001875  Loss: 0.7724  Acc@1: 75.0000 (81.3927)  Acc@5: 100.0000 (96.5454)  time: 0.3430  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.7563  Acc@1: 81.2500 (81.3904)  Acc@5: 100.0000 (96.5464)  time: 0.3420  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:32  Lr: 0.001875  Loss: 0.5675  Acc@1: 81.2500 (81.4026)  Acc@5: 100.0000 (96.5509)  time: 0.3434  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.3520  Acc@1: 81.2500 (81.4040)  Acc@5: 100.0000 (96.5554)  time: 0.3436  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.5404  Acc@1: 81.2500 (81.4053)  Acc@5: 100.0000 (96.5563)  time: 0.3433  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.4387  Acc@1: 81.2500 (81.4013)  Acc@5: 93.7500 (96.5519)  time: 0.3446  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.6219  Acc@1: 81.2500 (81.4115)  Acc@5: 93.7500 (96.5528)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 1.1081  Acc@1: 75.0000 (81.3987)  Acc@5: 100.0000 (96.5449)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.2361  Acc@1: 75.0000 (81.4053)  Acc@5: 93.7500 (96.5423)  time: 0.3431  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:08  Lr: 0.001875  Loss: 0.6933  Acc@1: 81.2500 (81.4137)  Acc@5: 93.7500 (96.5415)  time: 0.3427  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.2725  Acc@1: 81.2500 (81.4097)  Acc@5: 93.7500 (96.5424)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3712  Acc@1: 81.2500 (81.4198)  Acc@5: 100.0000 (96.5486)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4906  Acc@1: 81.2500 (81.4106)  Acc@5: 100.0000 (96.5443)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 1.3651  Acc@1: 81.2500 (81.4049)  Acc@5: 93.7500 (96.5434)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.6423  Acc@1: 81.2500 (81.4045)  Acc@5: 100.0000 (96.5444)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7474  Acc@1: 75.0000 (81.4040)  Acc@5: 93.7500 (96.5401)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.4085  Acc@1: 81.2500 (81.4036)  Acc@5: 93.7500 (96.5376)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.5185  Acc@1: 81.2500 (81.3980)  Acc@5: 100.0000 (96.5368)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 0.3372  Acc@1: 87.5000 (81.4199)  Acc@5: 100.0000 (96.5428)  time: 0.3432  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.7636  Acc@1: 87.5000 (81.4332)  Acc@5: 100.0000 (96.5403)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3916  Acc@1: 81.2500 (81.4207)  Acc@5: 100.0000 (96.5395)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.6169  Acc@1: 81.2500 (81.4237)  Acc@5: 100.0000 (96.5439)  time: 0.3432  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2257  Acc@1: 81.2500 (81.4317)  Acc@5: 100.0000 (96.5448)  time: 0.3440  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 0.4480  Acc@1: 81.2500 (81.4363)  Acc@5: 93.7500 (96.5440)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2017  Acc@1: 81.2500 (81.4459)  Acc@5: 100.0000 (96.5465)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.5253  Acc@1: 87.5000 (81.4538)  Acc@5: 100.0000 (96.5491)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.4836  Acc@1: 87.5000 (81.4616)  Acc@5: 100.0000 (96.5517)  time: 0.3446  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.6788  Acc@1: 87.5000 (81.4711)  Acc@5: 100.0000 (96.5525)  time: 0.3445  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.8213  Acc@1: 87.5000 (81.4755)  Acc@5: 100.0000 (96.5551)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7407  Acc@1: 81.2500 (81.4650)  Acc@5: 100.0000 (96.5583)  time: 0.3436  data: 0.0006  max mem: 2500
Train: Epoch[3/5] Total time: 0:21:31 (0.3444 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.7407  Acc@1: 81.2500 (81.4650)  Acc@5: 100.0000 (96.5583)
Train: Epoch[4/5]  [   0/3750]  eta: 0:43:49  Lr: 0.001875  Loss: 0.8894  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.7013  data: 0.3531  max mem: 2500
Train: Epoch[4/5]  [  10/3750]  eta: 0:23:29  Lr: 0.001875  Loss: 0.2429  Acc@1: 75.0000 (76.7045)  Acc@5: 100.0000 (96.0227)  time: 0.3768  data: 0.0325  max mem: 2500
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:26  Lr: 0.001875  Loss: 0.7784  Acc@1: 75.0000 (77.9762)  Acc@5: 100.0000 (95.5357)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:03  Lr: 0.001875  Loss: 0.7333  Acc@1: 81.2500 (80.4435)  Acc@5: 93.7500 (95.9677)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  40/3750]  eta: 0:21:50  Lr: 0.001875  Loss: 0.6942  Acc@1: 81.2500 (80.4878)  Acc@5: 100.0000 (96.4939)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  50/3750]  eta: 0:21:39  Lr: 0.001875  Loss: 0.3676  Acc@1: 81.2500 (79.9020)  Acc@5: 100.0000 (96.2010)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:31  Lr: 0.001875  Loss: 0.5663  Acc@1: 81.2500 (79.8156)  Acc@5: 100.0000 (96.3115)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:26  Lr: 0.001875  Loss: 0.2016  Acc@1: 75.0000 (80.2817)  Acc@5: 100.0000 (96.4789)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:19  Lr: 0.001875  Loss: 0.4318  Acc@1: 81.2500 (80.5556)  Acc@5: 100.0000 (96.5278)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:14  Lr: 0.001875  Loss: 0.3025  Acc@1: 81.2500 (80.4945)  Acc@5: 93.7500 (96.4286)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:09  Lr: 0.001875  Loss: 0.1136  Acc@1: 81.2500 (80.9406)  Acc@5: 100.0000 (96.5347)  time: 0.3444  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:05  Lr: 0.001875  Loss: 0.2852  Acc@1: 81.2500 (81.0248)  Acc@5: 100.0000 (96.6779)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:01  Lr: 0.001875  Loss: 1.1769  Acc@1: 81.2500 (81.3533)  Acc@5: 100.0000 (96.6426)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 130/3750]  eta: 0:20:57  Lr: 0.001875  Loss: 0.3961  Acc@1: 81.2500 (81.2977)  Acc@5: 100.0000 (96.7557)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 140/3750]  eta: 0:20:53  Lr: 0.001875  Loss: 0.1581  Acc@1: 87.5000 (81.6933)  Acc@5: 100.0000 (96.7642)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 150/3750]  eta: 0:20:50  Lr: 0.001875  Loss: 0.3093  Acc@1: 87.5000 (81.8709)  Acc@5: 100.0000 (96.7715)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 160/3750]  eta: 0:20:46  Lr: 0.001875  Loss: 0.4976  Acc@1: 81.2500 (81.7935)  Acc@5: 93.7500 (96.7391)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:42  Lr: 0.001875  Loss: 0.3725  Acc@1: 81.2500 (81.6520)  Acc@5: 93.7500 (96.7105)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:38  Lr: 0.001875  Loss: 0.2225  Acc@1: 81.2500 (81.7334)  Acc@5: 93.7500 (96.6506)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:34  Lr: 0.001875  Loss: 0.6622  Acc@1: 81.2500 (81.8063)  Acc@5: 100.0000 (96.7277)  time: 0.3441  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:30  Lr: 0.001875  Loss: 0.3432  Acc@1: 87.5000 (82.1206)  Acc@5: 100.0000 (96.7973)  time: 0.3447  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:27  Lr: 0.001875  Loss: 0.8413  Acc@1: 87.5000 (82.1979)  Acc@5: 100.0000 (96.8306)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:23  Lr: 0.001875  Loss: 0.7692  Acc@1: 81.2500 (82.2964)  Acc@5: 100.0000 (96.7760)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:19  Lr: 0.001875  Loss: 0.3361  Acc@1: 81.2500 (82.1158)  Acc@5: 100.0000 (96.8344)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:15  Lr: 0.001875  Loss: 0.4367  Acc@1: 81.2500 (82.1058)  Acc@5: 100.0000 (96.8880)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:11  Lr: 0.001875  Loss: 0.5076  Acc@1: 81.2500 (82.2460)  Acc@5: 100.0000 (96.9373)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:07  Lr: 0.001875  Loss: 0.5078  Acc@1: 87.5000 (82.2318)  Acc@5: 100.0000 (96.9588)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:04  Lr: 0.001875  Loss: 0.9293  Acc@1: 81.2500 (82.1033)  Acc@5: 93.7500 (96.9327)  time: 0.3445  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:00  Lr: 0.001875  Loss: 0.4428  Acc@1: 81.2500 (82.1842)  Acc@5: 93.7500 (96.8639)  time: 0.3444  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 290/3750]  eta: 0:19:57  Lr: 0.001875  Loss: 0.3808  Acc@1: 81.2500 (81.9373)  Acc@5: 93.7500 (96.7569)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 300/3750]  eta: 0:19:53  Lr: 0.001875  Loss: 0.4733  Acc@1: 81.2500 (82.1013)  Acc@5: 93.7500 (96.7608)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 310/3750]  eta: 0:19:49  Lr: 0.001875  Loss: 0.6557  Acc@1: 87.5000 (82.1342)  Acc@5: 100.0000 (96.7846)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 320/3750]  eta: 0:19:46  Lr: 0.001875  Loss: 0.1647  Acc@1: 81.2500 (82.1651)  Acc@5: 100.0000 (96.8069)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:42  Lr: 0.001875  Loss: 0.5332  Acc@1: 87.5000 (82.3074)  Acc@5: 100.0000 (96.8656)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:38  Lr: 0.001875  Loss: 0.3982  Acc@1: 87.5000 (82.3864)  Acc@5: 100.0000 (96.8658)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:35  Lr: 0.001875  Loss: 0.7677  Acc@1: 81.2500 (82.2472)  Acc@5: 100.0000 (96.8839)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:31  Lr: 0.001875  Loss: 0.1893  Acc@1: 81.2500 (82.2542)  Acc@5: 100.0000 (96.9010)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:28  Lr: 0.001875  Loss: 0.5122  Acc@1: 81.2500 (82.3113)  Acc@5: 100.0000 (96.9003)  time: 0.3438  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:24  Lr: 0.001875  Loss: 0.4999  Acc@1: 81.2500 (82.3655)  Acc@5: 100.0000 (96.9160)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:20  Lr: 0.001875  Loss: 0.7054  Acc@1: 81.2500 (82.2410)  Acc@5: 100.0000 (96.8830)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:17  Lr: 0.001875  Loss: 0.5438  Acc@1: 81.2500 (82.2631)  Acc@5: 93.7500 (96.8516)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:13  Lr: 0.001875  Loss: 0.8810  Acc@1: 81.2500 (82.2689)  Acc@5: 100.0000 (96.9130)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:10  Lr: 0.001875  Loss: 0.5264  Acc@1: 81.2500 (82.2892)  Acc@5: 100.0000 (96.9418)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:06  Lr: 0.001875  Loss: 0.7489  Acc@1: 81.2500 (82.3666)  Acc@5: 93.7500 (96.8968)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:03  Lr: 0.001875  Loss: 0.2718  Acc@1: 87.5000 (82.4546)  Acc@5: 93.7500 (96.9246)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 450/3750]  eta: 0:18:59  Lr: 0.001875  Loss: 0.3596  Acc@1: 81.2500 (82.3309)  Acc@5: 93.7500 (96.8819)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 460/3750]  eta: 0:18:55  Lr: 0.001875  Loss: 0.8040  Acc@1: 75.0000 (82.1719)  Acc@5: 93.7500 (96.8547)  time: 0.3437  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 470/3750]  eta: 0:18:52  Lr: 0.001875  Loss: 0.4719  Acc@1: 75.0000 (82.1789)  Acc@5: 93.7500 (96.8551)  time: 0.3441  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 480/3750]  eta: 0:18:48  Lr: 0.001875  Loss: 0.3435  Acc@1: 87.5000 (82.1726)  Acc@5: 93.7500 (96.8165)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 490/3750]  eta: 0:18:45  Lr: 0.001875  Loss: 0.4622  Acc@1: 81.2500 (82.2174)  Acc@5: 93.7500 (96.7668)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:41  Lr: 0.001875  Loss: 0.6497  Acc@1: 81.2500 (82.1732)  Acc@5: 93.7500 (96.7066)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:38  Lr: 0.001875  Loss: 0.7667  Acc@1: 81.2500 (82.2896)  Acc@5: 100.0000 (96.7466)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:34  Lr: 0.001875  Loss: 0.2784  Acc@1: 81.2500 (82.1977)  Acc@5: 100.0000 (96.7250)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:31  Lr: 0.001875  Loss: 0.3600  Acc@1: 81.2500 (82.1681)  Acc@5: 100.0000 (96.7632)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:27  Lr: 0.001875  Loss: 0.4368  Acc@1: 81.2500 (82.1165)  Acc@5: 100.0000 (96.7075)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:24  Lr: 0.001875  Loss: 0.5834  Acc@1: 87.5000 (82.1915)  Acc@5: 100.0000 (96.7559)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:20  Lr: 0.001875  Loss: 0.8596  Acc@1: 87.5000 (82.2193)  Acc@5: 100.0000 (96.7692)  time: 0.3444  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:17  Lr: 0.001875  Loss: 0.8827  Acc@1: 81.2500 (82.2242)  Acc@5: 100.0000 (96.7820)  time: 0.3442  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:13  Lr: 0.001875  Loss: 0.2763  Acc@1: 81.2500 (82.2504)  Acc@5: 100.0000 (96.7836)  time: 0.3435  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.001875  Loss: 0.4599  Acc@1: 81.2500 (82.2864)  Acc@5: 100.0000 (96.8168)  time: 0.3441  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:06  Lr: 0.001875  Loss: 0.4867  Acc@1: 87.5000 (82.3315)  Acc@5: 100.0000 (96.8386)  time: 0.3438  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:03  Lr: 0.001875  Loss: 0.3857  Acc@1: 75.0000 (82.2320)  Acc@5: 100.0000 (96.8290)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 620/3750]  eta: 0:17:59  Lr: 0.001875  Loss: 0.7769  Acc@1: 75.0000 (82.2262)  Acc@5: 100.0000 (96.8297)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 630/3750]  eta: 0:17:55  Lr: 0.001875  Loss: 0.4087  Acc@1: 87.5000 (82.2999)  Acc@5: 100.0000 (96.8403)  time: 0.3429  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 640/3750]  eta: 0:17:52  Lr: 0.001875  Loss: 0.3133  Acc@1: 87.5000 (82.3615)  Acc@5: 100.0000 (96.8896)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 650/3750]  eta: 0:17:48  Lr: 0.001875  Loss: 0.7703  Acc@1: 87.5000 (82.3541)  Acc@5: 100.0000 (96.9086)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 660/3750]  eta: 0:17:45  Lr: 0.001875  Loss: 0.1465  Acc@1: 87.5000 (82.3752)  Acc@5: 100.0000 (96.9081)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:41  Lr: 0.001875  Loss: 0.5929  Acc@1: 87.5000 (82.3677)  Acc@5: 100.0000 (96.8890)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:38  Lr: 0.001875  Loss: 0.5367  Acc@1: 81.2500 (82.3146)  Acc@5: 93.7500 (96.8429)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:34  Lr: 0.001875  Loss: 0.7652  Acc@1: 81.2500 (82.2811)  Acc@5: 93.7500 (96.8524)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:31  Lr: 0.001875  Loss: 0.3779  Acc@1: 81.2500 (82.2664)  Acc@5: 100.0000 (96.8260)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:28  Lr: 0.001875  Loss: 0.4583  Acc@1: 81.2500 (82.2609)  Acc@5: 93.7500 (96.8267)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:24  Lr: 0.001875  Loss: 0.2957  Acc@1: 81.2500 (82.2469)  Acc@5: 100.0000 (96.8100)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:21  Lr: 0.001875  Loss: 0.5324  Acc@1: 81.2500 (82.2332)  Acc@5: 93.7500 (96.7510)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:17  Lr: 0.001875  Loss: 0.2095  Acc@1: 81.2500 (82.2200)  Acc@5: 93.7500 (96.7443)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:14  Lr: 0.001875  Loss: 0.6917  Acc@1: 81.2500 (82.1821)  Acc@5: 93.7500 (96.7210)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:10  Lr: 0.001875  Loss: 0.2398  Acc@1: 75.0000 (82.1616)  Acc@5: 100.0000 (96.7477)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:07  Lr: 0.001875  Loss: 0.7378  Acc@1: 81.2500 (82.1417)  Acc@5: 100.0000 (96.7331)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:03  Lr: 0.001875  Loss: 0.3530  Acc@1: 81.2500 (82.1303)  Acc@5: 100.0000 (96.7430)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:00  Lr: 0.001875  Loss: 0.4710  Acc@1: 81.2500 (82.1508)  Acc@5: 100.0000 (96.7446)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 800/3750]  eta: 0:16:56  Lr: 0.001875  Loss: 0.3407  Acc@1: 87.5000 (82.1785)  Acc@5: 100.0000 (96.7619)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 810/3750]  eta: 0:16:53  Lr: 0.001875  Loss: 0.5427  Acc@1: 81.2500 (82.1594)  Acc@5: 100.0000 (96.7710)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 820/3750]  eta: 0:16:49  Lr: 0.001875  Loss: 0.3443  Acc@1: 81.2500 (82.1787)  Acc@5: 93.7500 (96.7646)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 830/3750]  eta: 0:16:46  Lr: 0.001875  Loss: 0.2667  Acc@1: 81.2500 (82.1525)  Acc@5: 93.7500 (96.7659)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:43  Lr: 0.001875  Loss: 0.6777  Acc@1: 81.2500 (82.1195)  Acc@5: 100.0000 (96.7672)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:39  Lr: 0.001875  Loss: 0.4596  Acc@1: 81.2500 (82.0873)  Acc@5: 100.0000 (96.7685)  time: 0.3446  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:36  Lr: 0.001875  Loss: 0.3853  Acc@1: 81.2500 (82.1283)  Acc@5: 93.7500 (96.7407)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:32  Lr: 0.001875  Loss: 0.4621  Acc@1: 87.5000 (82.2187)  Acc@5: 93.7500 (96.7423)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:29  Lr: 0.001875  Loss: 0.3487  Acc@1: 87.5000 (82.2290)  Acc@5: 100.0000 (96.7367)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:25  Lr: 0.001875  Loss: 0.8848  Acc@1: 81.2500 (82.2601)  Acc@5: 100.0000 (96.7452)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:22  Lr: 0.001875  Loss: 0.7067  Acc@1: 87.5000 (82.3183)  Acc@5: 100.0000 (96.7675)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:18  Lr: 0.001875  Loss: 0.5970  Acc@1: 81.2500 (82.2516)  Acc@5: 100.0000 (96.7481)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:15  Lr: 0.001875  Loss: 0.2995  Acc@1: 75.0000 (82.1933)  Acc@5: 93.7500 (96.7562)  time: 0.3448  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:11  Lr: 0.001875  Loss: 0.7726  Acc@1: 81.2500 (82.1898)  Acc@5: 93.7500 (96.7172)  time: 0.3450  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:08  Lr: 0.001875  Loss: 0.8116  Acc@1: 81.2500 (82.1467)  Acc@5: 93.7500 (96.7123)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:05  Lr: 0.001875  Loss: 0.2956  Acc@1: 81.2500 (82.1832)  Acc@5: 100.0000 (96.7206)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:01  Lr: 0.001875  Loss: 0.6962  Acc@1: 87.5000 (82.1865)  Acc@5: 100.0000 (96.7352)  time: 0.3445  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 970/3750]  eta: 0:15:58  Lr: 0.001875  Loss: 0.2686  Acc@1: 87.5000 (82.2606)  Acc@5: 100.0000 (96.7495)  time: 0.3434  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 980/3750]  eta: 0:15:54  Lr: 0.001875  Loss: 0.2436  Acc@1: 87.5000 (82.2821)  Acc@5: 100.0000 (96.7508)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 990/3750]  eta: 0:15:51  Lr: 0.001875  Loss: 0.5247  Acc@1: 81.2500 (82.2275)  Acc@5: 100.0000 (96.7457)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1000/3750]  eta: 0:15:47  Lr: 0.001875  Loss: 0.6833  Acc@1: 75.0000 (82.2178)  Acc@5: 100.0000 (96.7720)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:44  Lr: 0.001875  Loss: 0.3030  Acc@1: 81.2500 (82.2329)  Acc@5: 100.0000 (96.7730)  time: 0.3439  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:40  Lr: 0.001875  Loss: 0.3937  Acc@1: 87.5000 (82.2478)  Acc@5: 100.0000 (96.7740)  time: 0.3437  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:37  Lr: 0.001875  Loss: 0.8493  Acc@1: 87.5000 (82.2502)  Acc@5: 100.0000 (96.7810)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:33  Lr: 0.001875  Loss: 0.1321  Acc@1: 81.2500 (82.2286)  Acc@5: 100.0000 (96.7879)  time: 0.3454  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:30  Lr: 0.001875  Loss: 0.2870  Acc@1: 81.2500 (82.2609)  Acc@5: 100.0000 (96.7828)  time: 0.3452  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:26  Lr: 0.001875  Loss: 0.9266  Acc@1: 81.2500 (82.2691)  Acc@5: 100.0000 (96.7837)  time: 0.3436  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:23  Lr: 0.001875  Loss: 0.7381  Acc@1: 81.2500 (82.2829)  Acc@5: 100.0000 (96.7729)  time: 0.3434  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:20  Lr: 0.001875  Loss: 0.3554  Acc@1: 81.2500 (82.2560)  Acc@5: 100.0000 (96.7796)  time: 0.3434  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:16  Lr: 0.001875  Loss: 0.3590  Acc@1: 75.0000 (82.2296)  Acc@5: 93.7500 (96.7576)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:13  Lr: 0.001875  Loss: 0.7831  Acc@1: 75.0000 (82.1639)  Acc@5: 93.7500 (96.7473)  time: 0.3444  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:09  Lr: 0.001875  Loss: 0.2210  Acc@1: 81.2500 (82.1782)  Acc@5: 93.7500 (96.7315)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:06  Lr: 0.001875  Loss: 0.9087  Acc@1: 81.2500 (82.1588)  Acc@5: 100.0000 (96.7217)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:02  Lr: 0.001875  Loss: 0.2327  Acc@1: 81.2500 (82.1673)  Acc@5: 100.0000 (96.7451)  time: 0.3445  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1140/3750]  eta: 0:14:59  Lr: 0.001875  Loss: 0.4060  Acc@1: 87.5000 (82.1648)  Acc@5: 100.0000 (96.7572)  time: 0.3448  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1150/3750]  eta: 0:14:55  Lr: 0.001875  Loss: 0.4269  Acc@1: 81.2500 (82.1568)  Acc@5: 100.0000 (96.7583)  time: 0.3440  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1160/3750]  eta: 0:14:52  Lr: 0.001875  Loss: 0.2048  Acc@1: 81.2500 (82.1975)  Acc@5: 100.0000 (96.7754)  time: 0.3460  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1170/3750]  eta: 0:14:49  Lr: 0.001875  Loss: 0.3299  Acc@1: 81.2500 (82.2054)  Acc@5: 100.0000 (96.7816)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:45  Lr: 0.001875  Loss: 0.4453  Acc@1: 81.2500 (82.1761)  Acc@5: 93.7500 (96.7665)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:42  Lr: 0.001875  Loss: 0.5549  Acc@1: 81.2500 (82.1421)  Acc@5: 93.7500 (96.7727)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:38  Lr: 0.001875  Loss: 0.0757  Acc@1: 81.2500 (82.1399)  Acc@5: 100.0000 (96.7943)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:35  Lr: 0.001875  Loss: 0.6021  Acc@1: 87.5000 (82.1841)  Acc@5: 100.0000 (96.7950)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:31  Lr: 0.001875  Loss: 0.4756  Acc@1: 87.5000 (82.1714)  Acc@5: 100.0000 (96.7905)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:28  Lr: 0.001875  Loss: 0.6256  Acc@1: 81.2500 (82.1131)  Acc@5: 93.7500 (96.7658)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:24  Lr: 0.001875  Loss: 0.8062  Acc@1: 81.2500 (82.1062)  Acc@5: 100.0000 (96.7818)  time: 0.3422  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:21  Lr: 0.001875  Loss: 0.8512  Acc@1: 81.2500 (82.1043)  Acc@5: 100.0000 (96.7876)  time: 0.3423  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:17  Lr: 0.001875  Loss: 0.1516  Acc@1: 87.5000 (82.1570)  Acc@5: 100.0000 (96.8031)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:14  Lr: 0.001875  Loss: 0.1723  Acc@1: 87.5000 (82.1204)  Acc@5: 100.0000 (96.7988)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:10  Lr: 0.001875  Loss: 0.8037  Acc@1: 81.2500 (82.1331)  Acc@5: 93.7500 (96.7896)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:07  Lr: 0.001875  Loss: 0.3592  Acc@1: 81.2500 (82.1359)  Acc@5: 93.7500 (96.7758)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:03  Lr: 0.001875  Loss: 0.6720  Acc@1: 81.2500 (82.1387)  Acc@5: 100.0000 (96.7717)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:00  Lr: 0.001875  Loss: 0.8172  Acc@1: 81.2500 (82.1224)  Acc@5: 100.0000 (96.7725)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1320/3750]  eta: 0:13:57  Lr: 0.001875  Loss: 0.6163  Acc@1: 81.2500 (82.1347)  Acc@5: 93.7500 (96.7591)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1330/3750]  eta: 0:13:53  Lr: 0.001875  Loss: 0.6961  Acc@1: 81.2500 (82.1281)  Acc@5: 93.7500 (96.7506)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1340/3750]  eta: 0:13:50  Lr: 0.001875  Loss: 0.3527  Acc@1: 81.2500 (82.1402)  Acc@5: 100.0000 (96.7701)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:46  Lr: 0.001875  Loss: 1.0027  Acc@1: 87.5000 (82.1521)  Acc@5: 100.0000 (96.7755)  time: 0.3441  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:43  Lr: 0.001875  Loss: 0.4612  Acc@1: 81.2500 (82.1455)  Acc@5: 100.0000 (96.7809)  time: 0.3468  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:39  Lr: 0.001875  Loss: 0.5941  Acc@1: 81.2500 (82.1207)  Acc@5: 100.0000 (96.7724)  time: 0.3458  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:36  Lr: 0.001875  Loss: 0.4520  Acc@1: 81.2500 (82.1099)  Acc@5: 100.0000 (96.7686)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:33  Lr: 0.001875  Loss: 0.2830  Acc@1: 81.2500 (82.1217)  Acc@5: 93.7500 (96.7514)  time: 0.3458  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:29  Lr: 0.001875  Loss: 0.3106  Acc@1: 81.2500 (82.1155)  Acc@5: 93.7500 (96.7300)  time: 0.3451  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:26  Lr: 0.001875  Loss: 0.7478  Acc@1: 81.2500 (82.1093)  Acc@5: 93.7500 (96.7266)  time: 0.3444  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:22  Lr: 0.001875  Loss: 0.5794  Acc@1: 81.2500 (82.1077)  Acc@5: 93.7500 (96.7233)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:19  Lr: 0.001875  Loss: 0.3768  Acc@1: 81.2500 (82.0842)  Acc@5: 93.7500 (96.7112)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:15  Lr: 0.001875  Loss: 0.2725  Acc@1: 81.2500 (82.0871)  Acc@5: 93.7500 (96.7124)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:12  Lr: 0.001875  Loss: 0.9750  Acc@1: 81.2500 (82.1115)  Acc@5: 100.0000 (96.7135)  time: 0.3450  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:08  Lr: 0.001875  Loss: 0.5184  Acc@1: 81.2500 (82.1099)  Acc@5: 100.0000 (96.7146)  time: 0.3451  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:05  Lr: 0.001875  Loss: 0.3562  Acc@1: 81.2500 (82.1125)  Acc@5: 100.0000 (96.7157)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:02  Lr: 0.001875  Loss: 0.4750  Acc@1: 81.2500 (82.0856)  Acc@5: 100.0000 (96.6999)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1490/3750]  eta: 0:12:58  Lr: 0.001875  Loss: 0.2645  Acc@1: 75.0000 (82.0758)  Acc@5: 93.7500 (96.7052)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1500/3750]  eta: 0:12:55  Lr: 0.001875  Loss: 0.1943  Acc@1: 81.2500 (82.0953)  Acc@5: 100.0000 (96.7147)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1510/3750]  eta: 0:12:51  Lr: 0.001875  Loss: 0.6439  Acc@1: 81.2500 (82.0897)  Acc@5: 100.0000 (96.7282)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:48  Lr: 0.001875  Loss: 0.5289  Acc@1: 81.2500 (82.1006)  Acc@5: 100.0000 (96.7291)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:44  Lr: 0.001875  Loss: 0.3746  Acc@1: 87.5000 (82.1604)  Acc@5: 100.0000 (96.7382)  time: 0.3443  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:41  Lr: 0.001875  Loss: 0.4147  Acc@1: 87.5000 (82.1585)  Acc@5: 100.0000 (96.7351)  time: 0.3440  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:37  Lr: 0.001875  Loss: 0.8321  Acc@1: 81.2500 (82.1607)  Acc@5: 100.0000 (96.7400)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:34  Lr: 0.001875  Loss: 0.1776  Acc@1: 81.2500 (82.1589)  Acc@5: 100.0000 (96.7289)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:31  Lr: 0.001875  Loss: 0.8434  Acc@1: 81.2500 (82.1372)  Acc@5: 100.0000 (96.7377)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:27  Lr: 0.001875  Loss: 0.5004  Acc@1: 81.2500 (82.1434)  Acc@5: 100.0000 (96.7386)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:24  Lr: 0.001875  Loss: 0.6098  Acc@1: 87.5000 (82.1496)  Acc@5: 100.0000 (96.7355)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:20  Lr: 0.001875  Loss: 0.4047  Acc@1: 81.2500 (82.1557)  Acc@5: 100.0000 (96.7403)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:17  Lr: 0.001875  Loss: 0.4999  Acc@1: 81.2500 (82.1384)  Acc@5: 100.0000 (96.7334)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:13  Lr: 0.001875  Loss: 0.4847  Acc@1: 81.2500 (82.1522)  Acc@5: 100.0000 (96.7381)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:10  Lr: 0.001875  Loss: 0.2586  Acc@1: 87.5000 (82.1658)  Acc@5: 100.0000 (96.7313)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:06  Lr: 0.001875  Loss: 0.9998  Acc@1: 87.5000 (82.1755)  Acc@5: 93.7500 (96.7246)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:03  Lr: 0.001875  Loss: 0.1730  Acc@1: 87.5000 (82.1964)  Acc@5: 100.0000 (96.7406)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:00  Lr: 0.001875  Loss: 0.4837  Acc@1: 87.5000 (82.1945)  Acc@5: 100.0000 (96.7377)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1670/3750]  eta: 0:11:56  Lr: 0.001875  Loss: 0.7945  Acc@1: 81.2500 (82.1813)  Acc@5: 100.0000 (96.7347)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1680/3750]  eta: 0:11:53  Lr: 0.001875  Loss: 0.3164  Acc@1: 81.2500 (82.2018)  Acc@5: 100.0000 (96.7356)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:49  Lr: 0.001875  Loss: 0.8209  Acc@1: 75.0000 (82.1629)  Acc@5: 100.0000 (96.7438)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:46  Lr: 0.001875  Loss: 0.3418  Acc@1: 75.0000 (82.1833)  Acc@5: 100.0000 (96.7556)  time: 0.3445  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:42  Lr: 0.001875  Loss: 0.6506  Acc@1: 81.2500 (82.1742)  Acc@5: 100.0000 (96.7526)  time: 0.3446  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:39  Lr: 0.001875  Loss: 0.3757  Acc@1: 81.2500 (82.1724)  Acc@5: 100.0000 (96.7679)  time: 0.3441  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:35  Lr: 0.001875  Loss: 0.7304  Acc@1: 81.2500 (82.1563)  Acc@5: 100.0000 (96.7721)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:32  Lr: 0.001875  Loss: 0.8033  Acc@1: 81.2500 (82.1403)  Acc@5: 93.7500 (96.7583)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:29  Lr: 0.001875  Loss: 0.6950  Acc@1: 81.2500 (82.1388)  Acc@5: 93.7500 (96.7590)  time: 0.3436  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:25  Lr: 0.001875  Loss: 0.4484  Acc@1: 87.5000 (82.1444)  Acc@5: 100.0000 (96.7526)  time: 0.3443  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:22  Lr: 0.001875  Loss: 0.3036  Acc@1: 87.5000 (82.1711)  Acc@5: 100.0000 (96.7603)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:18  Lr: 0.001875  Loss: 0.6379  Acc@1: 87.5000 (82.1764)  Acc@5: 100.0000 (96.7609)  time: 0.3448  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:15  Lr: 0.001875  Loss: 0.3091  Acc@1: 81.2500 (82.1678)  Acc@5: 93.7500 (96.7581)  time: 0.3452  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:11  Lr: 0.001875  Loss: 0.8581  Acc@1: 81.2500 (82.1453)  Acc@5: 93.7500 (96.7449)  time: 0.3441  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:08  Lr: 0.001875  Loss: 0.8835  Acc@1: 81.2500 (82.1507)  Acc@5: 93.7500 (96.7387)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:04  Lr: 0.001875  Loss: 0.8252  Acc@1: 81.2500 (82.1492)  Acc@5: 100.0000 (96.7429)  time: 0.3435  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:01  Lr: 0.001875  Loss: 0.5298  Acc@1: 81.2500 (82.1580)  Acc@5: 100.0000 (96.7504)  time: 0.3444  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1840/3750]  eta: 0:10:57  Lr: 0.001875  Loss: 0.5004  Acc@1: 81.2500 (82.1463)  Acc@5: 93.7500 (96.7375)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1850/3750]  eta: 0:10:54  Lr: 0.001875  Loss: 1.1575  Acc@1: 81.2500 (82.1549)  Acc@5: 93.7500 (96.7416)  time: 0.3434  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:51  Lr: 0.001875  Loss: 0.3790  Acc@1: 81.2500 (82.1635)  Acc@5: 100.0000 (96.7423)  time: 0.3437  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:47  Lr: 0.001875  Loss: 0.3281  Acc@1: 81.2500 (82.1920)  Acc@5: 93.7500 (96.7431)  time: 0.3427  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:44  Lr: 0.001875  Loss: 0.5885  Acc@1: 81.2500 (82.1903)  Acc@5: 100.0000 (96.7471)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:40  Lr: 0.001875  Loss: 0.4977  Acc@1: 81.2500 (82.1854)  Acc@5: 100.0000 (96.7444)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:37  Lr: 0.001875  Loss: 0.5195  Acc@1: 81.2500 (82.2002)  Acc@5: 93.7500 (96.7386)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:33  Lr: 0.001875  Loss: 0.6211  Acc@1: 81.2500 (82.1723)  Acc@5: 100.0000 (96.7458)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:30  Lr: 0.001875  Loss: 0.4585  Acc@1: 81.2500 (82.1870)  Acc@5: 100.0000 (96.7497)  time: 0.3435  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:26  Lr: 0.001875  Loss: 0.9303  Acc@1: 81.2500 (82.1789)  Acc@5: 100.0000 (96.7472)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:23  Lr: 0.001875  Loss: 0.6556  Acc@1: 81.2500 (82.1419)  Acc@5: 100.0000 (96.7478)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:19  Lr: 0.001875  Loss: 0.6304  Acc@1: 81.2500 (82.1406)  Acc@5: 100.0000 (96.7581)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:16  Lr: 0.001875  Loss: 0.5845  Acc@1: 81.2500 (82.1488)  Acc@5: 100.0000 (96.7619)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:13  Lr: 0.001875  Loss: 0.6727  Acc@1: 81.2500 (82.1474)  Acc@5: 100.0000 (96.7624)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:09  Lr: 0.001875  Loss: 0.3868  Acc@1: 81.2500 (82.1523)  Acc@5: 100.0000 (96.7693)  time: 0.3436  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:06  Lr: 0.001875  Loss: 0.9189  Acc@1: 81.2500 (82.1603)  Acc@5: 100.0000 (96.7667)  time: 0.3433  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:02  Lr: 0.001875  Loss: 0.4251  Acc@1: 81.2500 (82.1527)  Acc@5: 100.0000 (96.7672)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2010/3750]  eta: 0:09:59  Lr: 0.001875  Loss: 0.6561  Acc@1: 75.0000 (82.1389)  Acc@5: 100.0000 (96.7647)  time: 0.3435  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2020/3750]  eta: 0:09:55  Lr: 0.001875  Loss: 0.5075  Acc@1: 81.2500 (82.1345)  Acc@5: 100.0000 (96.7776)  time: 0.3437  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2030/3750]  eta: 0:09:52  Lr: 0.001875  Loss: 0.3528  Acc@1: 81.2500 (82.1516)  Acc@5: 100.0000 (96.7842)  time: 0.3446  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:48  Lr: 0.001875  Loss: 0.5643  Acc@1: 75.0000 (82.1258)  Acc@5: 100.0000 (96.7847)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:45  Lr: 0.001875  Loss: 0.6420  Acc@1: 81.2500 (82.1185)  Acc@5: 100.0000 (96.7821)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:42  Lr: 0.001875  Loss: 0.2827  Acc@1: 81.2500 (82.1143)  Acc@5: 100.0000 (96.7825)  time: 0.3429  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:38  Lr: 0.001875  Loss: 0.3218  Acc@1: 81.2500 (82.1101)  Acc@5: 100.0000 (96.7799)  time: 0.3426  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:35  Lr: 0.001875  Loss: 0.3691  Acc@1: 81.2500 (82.1090)  Acc@5: 100.0000 (96.7804)  time: 0.3439  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:31  Lr: 0.001875  Loss: 0.7465  Acc@1: 81.2500 (82.1019)  Acc@5: 100.0000 (96.7838)  time: 0.3439  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:28  Lr: 0.001875  Loss: 1.1238  Acc@1: 81.2500 (82.1097)  Acc@5: 100.0000 (96.7872)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:24  Lr: 0.001875  Loss: 0.3203  Acc@1: 87.5000 (82.1441)  Acc@5: 100.0000 (96.7965)  time: 0.3437  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:21  Lr: 0.001875  Loss: 0.3344  Acc@1: 87.5000 (82.1252)  Acc@5: 100.0000 (96.8028)  time: 0.3447  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:17  Lr: 0.001875  Loss: 0.6192  Acc@1: 81.2500 (82.1064)  Acc@5: 100.0000 (96.8031)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:14  Lr: 0.001875  Loss: 0.2237  Acc@1: 81.2500 (82.1199)  Acc@5: 100.0000 (96.7976)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:10  Lr: 0.001875  Loss: 0.3606  Acc@1: 81.2500 (82.1101)  Acc@5: 100.0000 (96.7951)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:07  Lr: 0.001875  Loss: 0.6076  Acc@1: 75.0000 (82.0772)  Acc@5: 100.0000 (96.8012)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:04  Lr: 0.001875  Loss: 0.5118  Acc@1: 81.2500 (82.0849)  Acc@5: 100.0000 (96.8073)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:00  Lr: 0.001875  Loss: 0.8085  Acc@1: 87.5000 (82.0982)  Acc@5: 100.0000 (96.8077)  time: 0.3447  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2190/3750]  eta: 0:08:57  Lr: 0.001875  Loss: 0.4426  Acc@1: 87.5000 (82.1001)  Acc@5: 100.0000 (96.8137)  time: 0.3452  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2200/3750]  eta: 0:08:53  Lr: 0.001875  Loss: 0.4538  Acc@1: 81.2500 (82.0763)  Acc@5: 100.0000 (96.8083)  time: 0.3452  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:50  Lr: 0.001875  Loss: 0.6112  Acc@1: 81.2500 (82.0839)  Acc@5: 100.0000 (96.8114)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:46  Lr: 0.001875  Loss: 0.8383  Acc@1: 87.5000 (82.0886)  Acc@5: 100.0000 (96.8004)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:43  Lr: 0.001875  Loss: 0.1702  Acc@1: 81.2500 (82.0876)  Acc@5: 93.7500 (96.7896)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:40  Lr: 0.001875  Loss: 0.0617  Acc@1: 81.2500 (82.0895)  Acc@5: 100.0000 (96.7899)  time: 0.3441  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:36  Lr: 0.001875  Loss: 0.1969  Acc@1: 81.2500 (82.0913)  Acc@5: 100.0000 (96.7959)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:33  Lr: 0.001875  Loss: 0.2922  Acc@1: 81.2500 (82.0876)  Acc@5: 100.0000 (96.7962)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:29  Lr: 0.001875  Loss: 0.7044  Acc@1: 81.2500 (82.0646)  Acc@5: 93.7500 (96.7856)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:26  Lr: 0.001875  Loss: 0.5847  Acc@1: 81.2500 (82.0857)  Acc@5: 93.7500 (96.7914)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:22  Lr: 0.001875  Loss: 0.6978  Acc@1: 81.2500 (82.0657)  Acc@5: 100.0000 (96.7918)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:19  Lr: 0.001875  Loss: 0.6037  Acc@1: 75.0000 (82.0540)  Acc@5: 100.0000 (96.7894)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:15  Lr: 0.001875  Loss: 0.4762  Acc@1: 81.2500 (82.0532)  Acc@5: 100.0000 (96.7844)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:12  Lr: 0.001875  Loss: 0.2817  Acc@1: 87.5000 (82.0740)  Acc@5: 100.0000 (96.7794)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:09  Lr: 0.001875  Loss: 0.8223  Acc@1: 87.5000 (82.0651)  Acc@5: 100.0000 (96.7798)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:05  Lr: 0.001875  Loss: 0.5953  Acc@1: 81.2500 (82.0723)  Acc@5: 100.0000 (96.7829)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:02  Lr: 0.001875  Loss: 0.8095  Acc@1: 81.2500 (82.0661)  Acc@5: 100.0000 (96.7886)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2360/3750]  eta: 0:07:58  Lr: 0.001875  Loss: 0.8990  Acc@1: 81.2500 (82.0627)  Acc@5: 100.0000 (96.7916)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2370/3750]  eta: 0:07:55  Lr: 0.001875  Loss: 0.2313  Acc@1: 81.2500 (82.0672)  Acc@5: 100.0000 (96.7893)  time: 0.3437  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:51  Lr: 0.001875  Loss: 0.4303  Acc@1: 87.5000 (82.0821)  Acc@5: 100.0000 (96.7897)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:48  Lr: 0.001875  Loss: 0.9130  Acc@1: 87.5000 (82.0812)  Acc@5: 93.7500 (96.7874)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:44  Lr: 0.001875  Loss: 0.1740  Acc@1: 81.2500 (82.0752)  Acc@5: 93.7500 (96.7826)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:41  Lr: 0.001875  Loss: 0.5343  Acc@1: 75.0000 (82.0562)  Acc@5: 93.7500 (96.7674)  time: 0.3448  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:38  Lr: 0.001875  Loss: 0.2981  Acc@1: 81.2500 (82.0684)  Acc@5: 100.0000 (96.7756)  time: 0.3458  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:34  Lr: 0.001875  Loss: 0.7076  Acc@1: 81.2500 (82.0599)  Acc@5: 100.0000 (96.7734)  time: 0.3455  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:31  Lr: 0.001875  Loss: 0.3417  Acc@1: 81.2500 (82.0770)  Acc@5: 100.0000 (96.7739)  time: 0.3453  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:27  Lr: 0.001875  Loss: 0.6455  Acc@1: 87.5000 (82.0838)  Acc@5: 100.0000 (96.7717)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:24  Lr: 0.001875  Loss: 0.4910  Acc@1: 87.5000 (82.1059)  Acc@5: 100.0000 (96.7772)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:20  Lr: 0.001875  Loss: 0.3437  Acc@1: 87.5000 (82.1429)  Acc@5: 100.0000 (96.7852)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:17  Lr: 0.001875  Loss: 0.1480  Acc@1: 87.5000 (82.1594)  Acc@5: 100.0000 (96.7856)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:13  Lr: 0.001875  Loss: 0.5392  Acc@1: 81.2500 (82.1432)  Acc@5: 93.7500 (96.7809)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:10  Lr: 0.001875  Loss: 0.4980  Acc@1: 81.2500 (82.1496)  Acc@5: 100.0000 (96.7888)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:07  Lr: 0.001875  Loss: 0.1036  Acc@1: 87.5000 (82.1660)  Acc@5: 100.0000 (96.7866)  time: 0.3443  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:03  Lr: 0.001875  Loss: 0.5224  Acc@1: 81.2500 (82.1524)  Acc@5: 100.0000 (96.7919)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:00  Lr: 0.001875  Loss: 0.5709  Acc@1: 81.2500 (82.1538)  Acc@5: 100.0000 (96.7923)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2540/3750]  eta: 0:06:56  Lr: 0.001875  Loss: 0.3766  Acc@1: 81.2500 (82.1429)  Acc@5: 93.7500 (96.7877)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:53  Lr: 0.001875  Loss: 0.6364  Acc@1: 81.2500 (82.1565)  Acc@5: 100.0000 (96.7856)  time: 0.3448  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:49  Lr: 0.001875  Loss: 0.6413  Acc@1: 81.2500 (82.1383)  Acc@5: 100.0000 (96.7908)  time: 0.3441  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:46  Lr: 0.001875  Loss: 0.3265  Acc@1: 75.0000 (82.1300)  Acc@5: 100.0000 (96.7936)  time: 0.3436  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:42  Lr: 0.001875  Loss: 0.4543  Acc@1: 81.2500 (82.1411)  Acc@5: 100.0000 (96.7987)  time: 0.3446  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:39  Lr: 0.001875  Loss: 0.3278  Acc@1: 81.2500 (82.1305)  Acc@5: 100.0000 (96.7918)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:36  Lr: 0.001875  Loss: 0.7339  Acc@1: 81.2500 (82.1391)  Acc@5: 100.0000 (96.7993)  time: 0.3438  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:32  Lr: 0.001875  Loss: 0.6385  Acc@1: 81.2500 (82.1261)  Acc@5: 100.0000 (96.8020)  time: 0.3450  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:29  Lr: 0.001875  Loss: 0.6527  Acc@1: 75.0000 (82.0751)  Acc@5: 100.0000 (96.7975)  time: 0.3442  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:25  Lr: 0.001875  Loss: 0.0835  Acc@1: 75.0000 (82.0743)  Acc@5: 93.7500 (96.7907)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:22  Lr: 0.001875  Loss: 0.6795  Acc@1: 81.2500 (82.0807)  Acc@5: 93.7500 (96.7863)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:18  Lr: 0.001875  Loss: 0.6383  Acc@1: 81.2500 (82.0917)  Acc@5: 93.7500 (96.7842)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:15  Lr: 0.001875  Loss: 0.3683  Acc@1: 87.5000 (82.1214)  Acc@5: 100.0000 (96.7893)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:11  Lr: 0.001875  Loss: 0.4500  Acc@1: 87.5000 (82.1251)  Acc@5: 100.0000 (96.7943)  time: 0.3460  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:08  Lr: 0.001875  Loss: 0.6788  Acc@1: 81.2500 (82.1405)  Acc@5: 100.0000 (96.7992)  time: 0.3455  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:05  Lr: 0.001875  Loss: 0.7783  Acc@1: 81.2500 (82.1465)  Acc@5: 100.0000 (96.7972)  time: 0.3438  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:01  Lr: 0.001875  Loss: 0.1999  Acc@1: 81.2500 (82.1617)  Acc@5: 100.0000 (96.7998)  time: 0.3434  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2710/3750]  eta: 0:05:58  Lr: 0.001875  Loss: 0.8208  Acc@1: 87.5000 (82.1837)  Acc@5: 100.0000 (96.8001)  time: 0.3429  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:54  Lr: 0.001875  Loss: 0.7456  Acc@1: 87.5000 (82.1734)  Acc@5: 100.0000 (96.7958)  time: 0.3440  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:51  Lr: 0.001875  Loss: 0.3953  Acc@1: 75.0000 (82.1540)  Acc@5: 100.0000 (96.7846)  time: 0.3434  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:47  Lr: 0.001875  Loss: 0.4656  Acc@1: 81.2500 (82.1621)  Acc@5: 100.0000 (96.7872)  time: 0.3425  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:44  Lr: 0.001875  Loss: 0.3243  Acc@1: 81.2500 (82.1406)  Acc@5: 100.0000 (96.7875)  time: 0.3424  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:40  Lr: 0.001875  Loss: 0.3405  Acc@1: 81.2500 (82.1555)  Acc@5: 100.0000 (96.7901)  time: 0.3431  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:37  Lr: 0.001875  Loss: 0.6387  Acc@1: 81.2500 (82.1454)  Acc@5: 100.0000 (96.7904)  time: 0.3429  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:34  Lr: 0.001875  Loss: 0.2437  Acc@1: 81.2500 (82.1490)  Acc@5: 100.0000 (96.7930)  time: 0.3427  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:30  Lr: 0.001875  Loss: 0.1481  Acc@1: 81.2500 (82.1569)  Acc@5: 100.0000 (96.7910)  time: 0.3433  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:27  Lr: 0.001875  Loss: 0.1261  Acc@1: 87.5000 (82.1782)  Acc@5: 100.0000 (96.8002)  time: 0.3442  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:23  Lr: 0.001875  Loss: 0.9970  Acc@1: 87.5000 (82.1749)  Acc@5: 100.0000 (96.7983)  time: 0.3442  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:20  Lr: 0.001875  Loss: 0.8620  Acc@1: 81.2500 (82.1606)  Acc@5: 100.0000 (96.7986)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:16  Lr: 0.001875  Loss: 0.8361  Acc@1: 81.2500 (82.1596)  Acc@5: 100.0000 (96.7944)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:13  Lr: 0.001875  Loss: 0.4421  Acc@1: 81.2500 (82.1674)  Acc@5: 93.7500 (96.7969)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:09  Lr: 0.001875  Loss: 0.5395  Acc@1: 87.5000 (82.1795)  Acc@5: 100.0000 (96.7928)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:06  Lr: 0.001875  Loss: 0.6834  Acc@1: 81.2500 (82.1806)  Acc@5: 100.0000 (96.7931)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:02  Lr: 0.001875  Loss: 0.5864  Acc@1: 81.2500 (82.1643)  Acc@5: 100.0000 (96.7934)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2880/3750]  eta: 0:04:59  Lr: 0.001875  Loss: 0.8484  Acc@1: 81.2500 (82.1720)  Acc@5: 100.0000 (96.7893)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2890/3750]  eta: 0:04:56  Lr: 0.001875  Loss: 0.5548  Acc@1: 81.2500 (82.1753)  Acc@5: 100.0000 (96.7896)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:52  Lr: 0.001875  Loss: 0.7234  Acc@1: 81.2500 (82.1527)  Acc@5: 93.7500 (96.7770)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:49  Lr: 0.001875  Loss: 0.1727  Acc@1: 75.0000 (82.1324)  Acc@5: 93.7500 (96.7816)  time: 0.3458  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:45  Lr: 0.001875  Loss: 0.5941  Acc@1: 75.0000 (82.1166)  Acc@5: 100.0000 (96.7776)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:42  Lr: 0.001875  Loss: 0.1057  Acc@1: 81.2500 (82.1243)  Acc@5: 100.0000 (96.7801)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:38  Lr: 0.001875  Loss: 0.3589  Acc@1: 87.5000 (82.1319)  Acc@5: 100.0000 (96.7826)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:35  Lr: 0.001875  Loss: 0.3516  Acc@1: 87.5000 (82.1353)  Acc@5: 100.0000 (96.7850)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:32  Lr: 0.001875  Loss: 0.5721  Acc@1: 81.2500 (82.1239)  Acc@5: 100.0000 (96.7874)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:28  Lr: 0.001875  Loss: 0.4872  Acc@1: 81.2500 (82.1167)  Acc@5: 93.7500 (96.7835)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:25  Lr: 0.001875  Loss: 0.5138  Acc@1: 81.2500 (82.1012)  Acc@5: 93.7500 (96.7817)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:21  Lr: 0.001875  Loss: 0.5270  Acc@1: 75.0000 (82.0942)  Acc@5: 93.7500 (96.7820)  time: 0.3453  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:18  Lr: 0.001875  Loss: 0.9497  Acc@1: 75.0000 (82.0789)  Acc@5: 93.7500 (96.7823)  time: 0.3444  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:14  Lr: 0.001875  Loss: 0.8457  Acc@1: 75.0000 (82.0803)  Acc@5: 93.7500 (96.7826)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:11  Lr: 0.001875  Loss: 0.5782  Acc@1: 87.5000 (82.0858)  Acc@5: 93.7500 (96.7705)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:07  Lr: 0.001875  Loss: 0.6095  Acc@1: 81.2500 (82.0789)  Acc@5: 93.7500 (96.7750)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:04  Lr: 0.001875  Loss: 0.5982  Acc@1: 81.2500 (82.0844)  Acc@5: 100.0000 (96.7712)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:01  Lr: 0.001875  Loss: 1.0588  Acc@1: 87.5000 (82.0858)  Acc@5: 100.0000 (96.7756)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3060/3750]  eta: 0:03:57  Lr: 0.001875  Loss: 0.7808  Acc@1: 87.5000 (82.1014)  Acc@5: 100.0000 (96.7801)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.5006  Acc@1: 87.5000 (82.1170)  Acc@5: 100.0000 (96.7804)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:50  Lr: 0.001875  Loss: 0.6026  Acc@1: 87.5000 (82.1284)  Acc@5: 100.0000 (96.7847)  time: 0.3452  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:47  Lr: 0.001875  Loss: 0.4903  Acc@1: 81.2500 (82.1296)  Acc@5: 100.0000 (96.7850)  time: 0.3448  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:43  Lr: 0.001875  Loss: 0.2493  Acc@1: 87.5000 (82.1449)  Acc@5: 100.0000 (96.7914)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:40  Lr: 0.001875  Loss: 1.2588  Acc@1: 81.2500 (82.1480)  Acc@5: 100.0000 (96.7956)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:36  Lr: 0.001875  Loss: 0.5277  Acc@1: 81.2500 (82.1331)  Acc@5: 100.0000 (96.7919)  time: 0.3434  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.7690  Acc@1: 75.0000 (82.1283)  Acc@5: 100.0000 (96.7942)  time: 0.3437  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.5934  Acc@1: 81.2500 (82.1215)  Acc@5: 93.7500 (96.7805)  time: 0.3440  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:26  Lr: 0.001875  Loss: 0.7476  Acc@1: 81.2500 (82.1346)  Acc@5: 100.0000 (96.7867)  time: 0.3434  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.3922  Acc@1: 81.2500 (82.1279)  Acc@5: 100.0000 (96.7910)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:19  Lr: 0.001875  Loss: 0.8461  Acc@1: 81.2500 (82.1172)  Acc@5: 100.0000 (96.7893)  time: 0.3430  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:16  Lr: 0.001875  Loss: 0.5871  Acc@1: 81.2500 (82.1342)  Acc@5: 100.0000 (96.7935)  time: 0.3437  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:12  Lr: 0.001875  Loss: 0.3260  Acc@1: 87.5000 (82.1510)  Acc@5: 100.0000 (96.7976)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:09  Lr: 0.001875  Loss: 0.5926  Acc@1: 81.2500 (82.1599)  Acc@5: 100.0000 (96.7940)  time: 0.3439  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:05  Lr: 0.001875  Loss: 0.5005  Acc@1: 81.2500 (82.1687)  Acc@5: 100.0000 (96.8001)  time: 0.3428  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:02  Lr: 0.001875  Loss: 0.7303  Acc@1: 81.2500 (82.1620)  Acc@5: 100.0000 (96.8003)  time: 0.3424  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 0.5828  Acc@1: 81.2500 (82.1650)  Acc@5: 100.0000 (96.8063)  time: 0.3425  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:55  Lr: 0.001875  Loss: 0.4601  Acc@1: 81.2500 (82.1525)  Acc@5: 100.0000 (96.8104)  time: 0.3428  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.5913  Acc@1: 81.2500 (82.1593)  Acc@5: 100.0000 (96.8087)  time: 0.3425  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:48  Lr: 0.001875  Loss: 0.6304  Acc@1: 81.2500 (82.1623)  Acc@5: 93.7500 (96.8070)  time: 0.3438  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 1.1166  Acc@1: 81.2500 (82.1576)  Acc@5: 100.0000 (96.8072)  time: 0.3442  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:41  Lr: 0.001875  Loss: 0.4496  Acc@1: 81.2500 (82.1682)  Acc@5: 100.0000 (96.8055)  time: 0.3431  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 0.8039  Acc@1: 81.2500 (82.1578)  Acc@5: 93.7500 (96.8038)  time: 0.3445  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:34  Lr: 0.001875  Loss: 0.1406  Acc@1: 81.2500 (82.1550)  Acc@5: 93.7500 (96.8021)  time: 0.3443  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:31  Lr: 0.001875  Loss: 0.3915  Acc@1: 81.2500 (82.1636)  Acc@5: 100.0000 (96.8061)  time: 0.3425  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.5629  Acc@1: 81.2500 (82.1740)  Acc@5: 100.0000 (96.8138)  time: 0.3425  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:24  Lr: 0.001875  Loss: 0.2931  Acc@1: 81.2500 (82.1694)  Acc@5: 100.0000 (96.8065)  time: 0.3419  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.9991  Acc@1: 75.0000 (82.1554)  Acc@5: 93.7500 (96.8086)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:17  Lr: 0.001875  Loss: 0.2110  Acc@1: 81.2500 (82.1732)  Acc@5: 100.0000 (96.8125)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.2633  Acc@1: 87.5000 (82.1835)  Acc@5: 100.0000 (96.8108)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:10  Lr: 0.001875  Loss: 0.3228  Acc@1: 81.2500 (82.1863)  Acc@5: 100.0000 (96.8185)  time: 0.3451  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.5839  Acc@1: 81.2500 (82.1854)  Acc@5: 100.0000 (96.8149)  time: 0.3456  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:03  Lr: 0.001875  Loss: 0.5047  Acc@1: 87.5000 (82.1845)  Acc@5: 100.0000 (96.8206)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 0.4807  Acc@1: 87.5000 (82.1946)  Acc@5: 100.0000 (96.8226)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.9055  Acc@1: 87.5000 (82.1918)  Acc@5: 100.0000 (96.8228)  time: 0.3448  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 0.4333  Acc@1: 81.2500 (82.1781)  Acc@5: 100.0000 (96.8175)  time: 0.3437  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.6457  Acc@1: 75.0000 (82.1645)  Acc@5: 93.7500 (96.8176)  time: 0.3435  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:46  Lr: 0.001875  Loss: 0.1567  Acc@1: 81.2500 (82.1727)  Acc@5: 100.0000 (96.8214)  time: 0.3434  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.9150  Acc@1: 87.5000 (82.1863)  Acc@5: 100.0000 (96.8234)  time: 0.3433  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:39  Lr: 0.001875  Loss: 0.4296  Acc@1: 87.5000 (82.1981)  Acc@5: 100.0000 (96.8199)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.5043  Acc@1: 87.5000 (82.2025)  Acc@5: 100.0000 (96.8201)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:32  Lr: 0.001875  Loss: 0.4548  Acc@1: 81.2500 (82.1980)  Acc@5: 100.0000 (96.8166)  time: 0.3427  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.5873  Acc@1: 81.2500 (82.2132)  Acc@5: 100.0000 (96.8240)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.2452  Acc@1: 81.2500 (82.2069)  Acc@5: 100.0000 (96.8241)  time: 0.3443  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.5933  Acc@1: 81.2500 (82.2113)  Acc@5: 100.0000 (96.8225)  time: 0.3451  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.5976  Acc@1: 81.2500 (82.2156)  Acc@5: 100.0000 (96.8244)  time: 0.3447  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 0.8393  Acc@1: 81.2500 (82.2253)  Acc@5: 100.0000 (96.8263)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.2709  Acc@1: 81.2500 (82.2119)  Acc@5: 100.0000 (96.8247)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:08  Lr: 0.001875  Loss: 0.8865  Acc@1: 81.2500 (82.2057)  Acc@5: 93.7500 (96.8213)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.7845  Acc@1: 81.2500 (82.2030)  Acc@5: 100.0000 (96.8232)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2301  Acc@1: 81.2500 (82.1986)  Acc@5: 100.0000 (96.8216)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4953  Acc@1: 81.2500 (82.1960)  Acc@5: 93.7500 (96.8183)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.6112  Acc@1: 81.2500 (82.1898)  Acc@5: 100.0000 (96.8237)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.8747  Acc@1: 81.2500 (82.1855)  Acc@5: 100.0000 (96.8203)  time: 0.3444  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2571  Acc@1: 81.2500 (82.1846)  Acc@5: 93.7500 (96.8205)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3229  Acc@1: 87.5000 (82.1976)  Acc@5: 100.0000 (96.8224)  time: 0.3447  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.8120  Acc@1: 87.5000 (82.1984)  Acc@5: 93.7500 (96.8191)  time: 0.3456  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 0.3658  Acc@1: 81.2500 (82.1872)  Acc@5: 100.0000 (96.8175)  time: 0.3453  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.8727  Acc@1: 75.0000 (82.1761)  Acc@5: 100.0000 (96.8142)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3787  Acc@1: 75.0000 (82.1702)  Acc@5: 100.0000 (96.8144)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.4040  Acc@1: 81.2500 (82.1660)  Acc@5: 93.7500 (96.8077)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.9013  Acc@1: 81.2500 (82.1652)  Acc@5: 93.7500 (96.8045)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 0.7961  Acc@1: 81.2500 (82.1491)  Acc@5: 93.7500 (96.7980)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.8546  Acc@1: 81.2500 (82.1552)  Acc@5: 93.7500 (96.7999)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 1.3802  Acc@1: 87.5000 (82.1578)  Acc@5: 100.0000 (96.7984)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.3245  Acc@1: 87.5000 (82.1604)  Acc@5: 100.0000 (96.7986)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.4676  Acc@1: 87.5000 (82.1730)  Acc@5: 100.0000 (96.8005)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.2538  Acc@1: 81.2500 (82.1739)  Acc@5: 100.0000 (96.8040)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4728  Acc@1: 81.2500 (82.1683)  Acc@5: 100.0000 (96.8050)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[4/5] Total time: 0:21:31 (0.3444 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.4728  Acc@1: 81.2500 (82.1683)  Acc@5: 100.0000 (96.8050)
Train: Epoch[5/5]  [   0/3750]  eta: 0:48:03  Lr: 0.001875  Loss: 0.5558  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7688  data: 0.4236  max mem: 2500
Train: Epoch[5/5]  [  10/3750]  eta: 0:23:56  Lr: 0.001875  Loss: 0.5686  Acc@1: 75.0000 (76.7045)  Acc@5: 100.0000 (96.5909)  time: 0.3840  data: 0.0387  max mem: 2500
Train: Epoch[5/5]  [  20/3750]  eta: 0:22:41  Lr: 0.001875  Loss: 0.2628  Acc@1: 81.2500 (80.9524)  Acc@5: 100.0000 (96.1310)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:12  Lr: 0.001875  Loss: 0.4793  Acc@1: 87.5000 (81.0484)  Acc@5: 93.7500 (95.7661)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  40/3750]  eta: 0:21:56  Lr: 0.001875  Loss: 0.6024  Acc@1: 81.2500 (81.7073)  Acc@5: 100.0000 (96.3415)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  50/3750]  eta: 0:21:44  Lr: 0.001875  Loss: 0.8458  Acc@1: 81.2500 (81.0049)  Acc@5: 100.0000 (96.5686)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:34  Lr: 0.001875  Loss: 0.4163  Acc@1: 81.2500 (80.4303)  Acc@5: 100.0000 (96.5164)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:27  Lr: 0.001875  Loss: 0.3954  Acc@1: 81.2500 (81.0739)  Acc@5: 100.0000 (96.8310)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:20  Lr: 0.001875  Loss: 0.1272  Acc@1: 87.5000 (81.0185)  Acc@5: 100.0000 (96.7593)  time: 0.3425  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:15  Lr: 0.001875  Loss: 0.8023  Acc@1: 81.2500 (81.1813)  Acc@5: 100.0000 (96.7720)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:11  Lr: 0.001875  Loss: 0.2632  Acc@1: 81.2500 (81.7450)  Acc@5: 100.0000 (96.7822)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:07  Lr: 0.001875  Loss: 0.8632  Acc@1: 87.5000 (81.9257)  Acc@5: 93.7500 (96.7342)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:02  Lr: 0.001875  Loss: 0.4891  Acc@1: 81.2500 (81.9215)  Acc@5: 93.7500 (96.7975)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 130/3750]  eta: 0:20:58  Lr: 0.001875  Loss: 0.5078  Acc@1: 81.2500 (81.8702)  Acc@5: 93.7500 (96.7080)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 140/3750]  eta: 0:20:53  Lr: 0.001875  Loss: 0.0778  Acc@1: 87.5000 (82.3582)  Acc@5: 100.0000 (96.8528)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 150/3750]  eta: 0:20:49  Lr: 0.001875  Loss: 0.3161  Acc@1: 87.5000 (82.3675)  Acc@5: 100.0000 (96.9371)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 160/3750]  eta: 0:20:45  Lr: 0.001875  Loss: 0.0220  Acc@1: 81.2500 (82.4922)  Acc@5: 100.0000 (97.0497)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:41  Lr: 0.001875  Loss: 0.3347  Acc@1: 87.5000 (82.5292)  Acc@5: 100.0000 (97.1126)  time: 0.3434  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:37  Lr: 0.001875  Loss: 0.3314  Acc@1: 81.2500 (82.4240)  Acc@5: 100.0000 (97.0649)  time: 0.3442  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:33  Lr: 0.001875  Loss: 0.4153  Acc@1: 81.2500 (82.5262)  Acc@5: 100.0000 (97.1531)  time: 0.3446  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:29  Lr: 0.001875  Loss: 0.6626  Acc@1: 81.2500 (82.3072)  Acc@5: 100.0000 (97.1393)  time: 0.3446  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:25  Lr: 0.001875  Loss: 0.6228  Acc@1: 81.2500 (82.3756)  Acc@5: 100.0000 (97.0972)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:22  Lr: 0.001875  Loss: 0.7210  Acc@1: 81.2500 (82.1550)  Acc@5: 93.7500 (97.0023)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:18  Lr: 0.001875  Loss: 0.3578  Acc@1: 81.2500 (82.1970)  Acc@5: 100.0000 (97.0509)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:14  Lr: 0.001875  Loss: 0.5967  Acc@1: 81.2500 (82.0280)  Acc@5: 100.0000 (96.9917)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:11  Lr: 0.001875  Loss: 0.6282  Acc@1: 81.2500 (82.0219)  Acc@5: 100.0000 (97.0120)  time: 0.3457  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:07  Lr: 0.001875  Loss: 0.2873  Acc@1: 81.2500 (82.0642)  Acc@5: 100.0000 (97.0546)  time: 0.3451  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:03  Lr: 0.001875  Loss: 0.5813  Acc@1: 87.5000 (82.1725)  Acc@5: 100.0000 (97.0018)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:00  Lr: 0.001875  Loss: 0.7152  Acc@1: 81.2500 (82.0952)  Acc@5: 93.7500 (96.9528)  time: 0.3447  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 290/3750]  eta: 0:19:56  Lr: 0.001875  Loss: 0.4558  Acc@1: 81.2500 (82.1091)  Acc@5: 93.7500 (96.8857)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 300/3750]  eta: 0:19:52  Lr: 0.001875  Loss: 0.6602  Acc@1: 81.2500 (82.1429)  Acc@5: 93.7500 (96.8646)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 310/3750]  eta: 0:19:49  Lr: 0.001875  Loss: 0.3545  Acc@1: 81.2500 (82.0539)  Acc@5: 100.0000 (96.8650)  time: 0.3441  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 320/3750]  eta: 0:19:45  Lr: 0.001875  Loss: 0.4471  Acc@1: 81.2500 (82.0678)  Acc@5: 100.0000 (96.8653)  time: 0.3444  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:41  Lr: 0.001875  Loss: 0.6742  Acc@1: 87.5000 (82.0997)  Acc@5: 100.0000 (96.9033)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:38  Lr: 0.001875  Loss: 0.4063  Acc@1: 81.2500 (82.0931)  Acc@5: 100.0000 (96.9391)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:34  Lr: 0.001875  Loss: 0.5364  Acc@1: 81.2500 (82.0869)  Acc@5: 100.0000 (96.9195)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:31  Lr: 0.001875  Loss: 0.5002  Acc@1: 81.2500 (82.0983)  Acc@5: 93.7500 (96.9183)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:27  Lr: 0.001875  Loss: 1.0100  Acc@1: 81.2500 (82.0418)  Acc@5: 100.0000 (96.9340)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:24  Lr: 0.001875  Loss: 0.8643  Acc@1: 81.2500 (82.0702)  Acc@5: 100.0000 (96.9488)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:20  Lr: 0.001875  Loss: 1.0122  Acc@1: 81.2500 (81.9693)  Acc@5: 100.0000 (96.9469)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:17  Lr: 0.001875  Loss: 0.2285  Acc@1: 81.2500 (82.0761)  Acc@5: 100.0000 (96.9140)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:13  Lr: 0.001875  Loss: 0.3596  Acc@1: 87.5000 (82.1320)  Acc@5: 93.7500 (96.9130)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:10  Lr: 0.001875  Loss: 0.4721  Acc@1: 87.5000 (82.2298)  Acc@5: 100.0000 (96.9863)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:06  Lr: 0.001875  Loss: 0.8084  Acc@1: 87.5000 (82.2651)  Acc@5: 100.0000 (96.9693)  time: 0.3451  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:03  Lr: 0.001875  Loss: 0.4628  Acc@1: 81.2500 (82.1712)  Acc@5: 93.7500 (96.9246)  time: 0.3456  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 450/3750]  eta: 0:18:59  Lr: 0.001875  Loss: 0.4129  Acc@1: 81.2500 (82.2339)  Acc@5: 93.7500 (96.9096)  time: 0.3444  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 460/3750]  eta: 0:18:56  Lr: 0.001875  Loss: 0.6112  Acc@1: 87.5000 (82.3075)  Acc@5: 100.0000 (96.9225)  time: 0.3429  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 470/3750]  eta: 0:18:52  Lr: 0.001875  Loss: 0.7080  Acc@1: 81.2500 (82.3514)  Acc@5: 100.0000 (96.8949)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 480/3750]  eta: 0:18:49  Lr: 0.001875  Loss: 0.4799  Acc@1: 81.2500 (82.4194)  Acc@5: 100.0000 (96.9465)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:45  Lr: 0.001875  Loss: 0.8268  Acc@1: 81.2500 (82.4720)  Acc@5: 100.0000 (96.9705)  time: 0.3450  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:42  Lr: 0.001875  Loss: 0.7694  Acc@1: 81.2500 (82.3478)  Acc@5: 100.0000 (97.0060)  time: 0.3444  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:38  Lr: 0.001875  Loss: 0.5511  Acc@1: 81.2500 (82.3875)  Acc@5: 100.0000 (97.0279)  time: 0.3445  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:35  Lr: 0.001875  Loss: 0.0122  Acc@1: 87.5000 (82.4856)  Acc@5: 100.0000 (97.0010)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:31  Lr: 0.001875  Loss: 0.6125  Acc@1: 81.2500 (82.5330)  Acc@5: 93.7500 (97.0104)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:28  Lr: 0.001875  Loss: 0.1842  Acc@1: 81.2500 (82.4861)  Acc@5: 100.0000 (97.0194)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:24  Lr: 0.001875  Loss: 0.6826  Acc@1: 81.2500 (82.4070)  Acc@5: 93.7500 (96.9714)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:21  Lr: 0.001875  Loss: 0.1126  Acc@1: 81.2500 (82.3641)  Acc@5: 93.7500 (96.9586)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:17  Lr: 0.001875  Loss: 0.7761  Acc@1: 81.2500 (82.2351)  Acc@5: 100.0000 (96.9899)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:14  Lr: 0.001875  Loss: 0.6010  Acc@1: 81.2500 (82.2289)  Acc@5: 100.0000 (96.9987)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.001875  Loss: 0.6745  Acc@1: 81.2500 (82.2335)  Acc@5: 100.0000 (96.9966)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:07  Lr: 0.001875  Loss: 0.4966  Acc@1: 81.2500 (82.2275)  Acc@5: 100.0000 (97.0154)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:03  Lr: 0.001875  Loss: 0.5790  Acc@1: 81.2500 (82.2218)  Acc@5: 100.0000 (97.0336)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:00  Lr: 0.001875  Loss: 0.3493  Acc@1: 81.2500 (82.2363)  Acc@5: 100.0000 (97.0511)  time: 0.3440  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 630/3750]  eta: 0:17:56  Lr: 0.001875  Loss: 0.5691  Acc@1: 81.2500 (82.2405)  Acc@5: 93.7500 (96.9988)  time: 0.3449  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 640/3750]  eta: 0:17:53  Lr: 0.001875  Loss: 0.3371  Acc@1: 87.5000 (82.2933)  Acc@5: 93.7500 (96.9969)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 650/3750]  eta: 0:17:49  Lr: 0.001875  Loss: 0.7352  Acc@1: 87.5000 (82.2869)  Acc@5: 100.0000 (97.0046)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:46  Lr: 0.001875  Loss: 0.4717  Acc@1: 81.2500 (82.3279)  Acc@5: 100.0000 (97.0121)  time: 0.3436  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:42  Lr: 0.001875  Loss: 0.1630  Acc@1: 81.2500 (82.3677)  Acc@5: 100.0000 (97.0007)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:39  Lr: 0.001875  Loss: 0.3156  Acc@1: 81.2500 (82.3789)  Acc@5: 100.0000 (96.9805)  time: 0.3430  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:35  Lr: 0.001875  Loss: 0.5696  Acc@1: 81.2500 (82.3535)  Acc@5: 100.0000 (96.9971)  time: 0.3437  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:32  Lr: 0.001875  Loss: 0.4605  Acc@1: 81.2500 (82.2842)  Acc@5: 100.0000 (96.9864)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:28  Lr: 0.001875  Loss: 1.0064  Acc@1: 81.2500 (82.2433)  Acc@5: 100.0000 (96.9849)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:25  Lr: 0.001875  Loss: 0.2855  Acc@1: 87.5000 (82.3249)  Acc@5: 100.0000 (97.0007)  time: 0.3450  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:22  Lr: 0.001875  Loss: 0.0801  Acc@1: 87.5000 (82.3529)  Acc@5: 100.0000 (96.9904)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:18  Lr: 0.001875  Loss: 0.6582  Acc@1: 81.2500 (82.3381)  Acc@5: 100.0000 (97.0057)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:15  Lr: 0.001875  Loss: 0.6865  Acc@1: 81.2500 (82.2903)  Acc@5: 100.0000 (97.0290)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:11  Lr: 0.001875  Loss: 0.5196  Acc@1: 81.2500 (82.3177)  Acc@5: 100.0000 (97.0598)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:08  Lr: 0.001875  Loss: 0.2530  Acc@1: 81.2500 (82.3281)  Acc@5: 100.0000 (97.0493)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:04  Lr: 0.001875  Loss: 0.5959  Acc@1: 81.2500 (82.2983)  Acc@5: 100.0000 (97.0711)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.001875  Loss: 0.6311  Acc@1: 81.2500 (82.3167)  Acc@5: 100.0000 (97.0844)  time: 0.3430  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 800/3750]  eta: 0:16:57  Lr: 0.001875  Loss: 0.3433  Acc@1: 81.2500 (82.2644)  Acc@5: 100.0000 (97.0818)  time: 0.3430  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.001875  Loss: 0.9247  Acc@1: 81.2500 (82.2210)  Acc@5: 100.0000 (97.0869)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 820/3750]  eta: 0:16:50  Lr: 0.001875  Loss: 0.6531  Acc@1: 81.2500 (82.1711)  Acc@5: 100.0000 (97.0843)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 830/3750]  eta: 0:16:46  Lr: 0.001875  Loss: 0.5430  Acc@1: 81.2500 (82.1676)  Acc@5: 100.0000 (97.0969)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:43  Lr: 0.001875  Loss: 0.2077  Acc@1: 81.2500 (82.1864)  Acc@5: 100.0000 (97.0868)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:39  Lr: 0.001875  Loss: 0.1004  Acc@1: 87.5000 (82.2268)  Acc@5: 100.0000 (97.0917)  time: 0.3430  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:36  Lr: 0.001875  Loss: 0.5638  Acc@1: 87.5000 (82.2735)  Acc@5: 100.0000 (97.0891)  time: 0.3427  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:32  Lr: 0.001875  Loss: 0.2279  Acc@1: 87.5000 (82.3335)  Acc@5: 100.0000 (97.1010)  time: 0.3425  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:29  Lr: 0.001875  Loss: 0.5847  Acc@1: 87.5000 (82.3283)  Acc@5: 100.0000 (97.0843)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:25  Lr: 0.001875  Loss: 0.5818  Acc@1: 81.2500 (82.3443)  Acc@5: 93.7500 (97.0749)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:22  Lr: 0.001875  Loss: 0.5509  Acc@1: 81.2500 (82.3113)  Acc@5: 93.7500 (97.0311)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:19  Lr: 0.001875  Loss: 0.9432  Acc@1: 81.2500 (82.2997)  Acc@5: 93.7500 (97.0019)  time: 0.3448  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:15  Lr: 0.001875  Loss: 0.3389  Acc@1: 81.2500 (82.2815)  Acc@5: 93.7500 (97.0073)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:12  Lr: 0.001875  Loss: 0.3610  Acc@1: 81.2500 (82.2771)  Acc@5: 100.0000 (97.0126)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:08  Lr: 0.001875  Loss: 0.5482  Acc@1: 81.2500 (82.2861)  Acc@5: 100.0000 (97.0444)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:05  Lr: 0.001875  Loss: 0.4924  Acc@1: 81.2500 (82.2555)  Acc@5: 100.0000 (97.0492)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:01  Lr: 0.001875  Loss: 0.5163  Acc@1: 81.2500 (82.2451)  Acc@5: 100.0000 (97.0408)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 970/3750]  eta: 0:15:58  Lr: 0.001875  Loss: 0.8395  Acc@1: 81.2500 (82.2155)  Acc@5: 93.7500 (97.0391)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 980/3750]  eta: 0:15:54  Lr: 0.001875  Loss: 0.1598  Acc@1: 81.2500 (82.2248)  Acc@5: 100.0000 (97.0311)  time: 0.3431  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 990/3750]  eta: 0:15:51  Lr: 0.001875  Loss: 0.8966  Acc@1: 81.2500 (82.2339)  Acc@5: 100.0000 (97.0295)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1000/3750]  eta: 0:15:47  Lr: 0.001875  Loss: 0.4033  Acc@1: 81.2500 (82.2615)  Acc@5: 100.0000 (97.0280)  time: 0.3432  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:44  Lr: 0.001875  Loss: 0.8926  Acc@1: 81.2500 (82.2515)  Acc@5: 100.0000 (97.0326)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:41  Lr: 0.001875  Loss: 0.4307  Acc@1: 81.2500 (82.2845)  Acc@5: 100.0000 (97.0372)  time: 0.3463  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:37  Lr: 0.001875  Loss: 0.5519  Acc@1: 81.2500 (82.2745)  Acc@5: 100.0000 (97.0478)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:34  Lr: 0.001875  Loss: 0.7752  Acc@1: 81.2500 (82.1866)  Acc@5: 93.7500 (97.0161)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:30  Lr: 0.001875  Loss: 0.3760  Acc@1: 75.0000 (82.1658)  Acc@5: 93.7500 (97.0326)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:27  Lr: 0.001875  Loss: 0.4146  Acc@1: 81.2500 (82.1572)  Acc@5: 100.0000 (97.0488)  time: 0.3441  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:23  Lr: 0.001875  Loss: 0.7766  Acc@1: 81.2500 (82.1779)  Acc@5: 100.0000 (97.0238)  time: 0.3442  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:20  Lr: 0.001875  Loss: 0.1087  Acc@1: 81.2500 (82.1751)  Acc@5: 93.7500 (97.0051)  time: 0.3449  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:16  Lr: 0.001875  Loss: 0.5780  Acc@1: 81.2500 (82.1494)  Acc@5: 93.7500 (97.0039)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:13  Lr: 0.001875  Loss: 0.5993  Acc@1: 81.2500 (82.1583)  Acc@5: 100.0000 (97.0084)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:09  Lr: 0.001875  Loss: 0.5052  Acc@1: 81.2500 (82.1332)  Acc@5: 100.0000 (97.0128)  time: 0.3440  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:06  Lr: 0.001875  Loss: 1.1120  Acc@1: 81.2500 (82.1421)  Acc@5: 100.0000 (97.0116)  time: 0.3453  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:03  Lr: 0.001875  Loss: 0.4418  Acc@1: 81.2500 (82.1342)  Acc@5: 100.0000 (97.0159)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1140/3750]  eta: 0:14:59  Lr: 0.001875  Loss: 1.0165  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (97.0202)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1150/3750]  eta: 0:14:56  Lr: 0.001875  Loss: 0.4502  Acc@1: 81.2500 (82.1785)  Acc@5: 100.0000 (97.0460)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1160/3750]  eta: 0:14:52  Lr: 0.001875  Loss: 0.1962  Acc@1: 81.2500 (82.1975)  Acc@5: 100.0000 (97.0392)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1170/3750]  eta: 0:14:49  Lr: 0.001875  Loss: 0.3709  Acc@1: 81.2500 (82.1787)  Acc@5: 100.0000 (97.0485)  time: 0.3445  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:45  Lr: 0.001875  Loss: 0.2680  Acc@1: 81.2500 (82.2343)  Acc@5: 100.0000 (97.0576)  time: 0.3441  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:42  Lr: 0.001875  Loss: 0.6953  Acc@1: 81.2500 (82.2051)  Acc@5: 93.7500 (97.0403)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:38  Lr: 0.001875  Loss: 0.2688  Acc@1: 81.2500 (82.2075)  Acc@5: 93.7500 (97.0441)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:35  Lr: 0.001875  Loss: 0.9110  Acc@1: 87.5000 (82.2151)  Acc@5: 93.7500 (97.0273)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:31  Lr: 0.001875  Loss: 0.2701  Acc@1: 81.2500 (82.1867)  Acc@5: 93.7500 (97.0158)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:28  Lr: 0.001875  Loss: 0.3751  Acc@1: 81.2500 (82.2197)  Acc@5: 100.0000 (97.0248)  time: 0.3446  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:25  Lr: 0.001875  Loss: 0.4651  Acc@1: 81.2500 (82.1867)  Acc@5: 100.0000 (97.0336)  time: 0.3444  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:21  Lr: 0.001875  Loss: 0.2952  Acc@1: 81.2500 (82.2242)  Acc@5: 100.0000 (97.0424)  time: 0.3439  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:18  Lr: 0.001875  Loss: 0.3232  Acc@1: 81.2500 (82.2115)  Acc@5: 100.0000 (97.0410)  time: 0.3444  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:14  Lr: 0.001875  Loss: 0.6290  Acc@1: 81.2500 (82.2187)  Acc@5: 100.0000 (97.0348)  time: 0.3437  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:11  Lr: 0.001875  Loss: 0.4430  Acc@1: 81.2500 (82.2502)  Acc@5: 100.0000 (97.0580)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:07  Lr: 0.001875  Loss: 0.5252  Acc@1: 87.5000 (82.2424)  Acc@5: 100.0000 (97.0323)  time: 0.3437  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:04  Lr: 0.001875  Loss: 1.0048  Acc@1: 81.2500 (82.2348)  Acc@5: 100.0000 (97.0359)  time: 0.3437  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:00  Lr: 0.001875  Loss: 0.4741  Acc@1: 81.2500 (82.2464)  Acc@5: 100.0000 (97.0299)  time: 0.3433  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1320/3750]  eta: 0:13:57  Lr: 0.001875  Loss: 0.4829  Acc@1: 81.2500 (82.2625)  Acc@5: 100.0000 (97.0240)  time: 0.3426  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1330/3750]  eta: 0:13:53  Lr: 0.001875  Loss: 0.1231  Acc@1: 87.5000 (82.2924)  Acc@5: 100.0000 (97.0417)  time: 0.3430  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1340/3750]  eta: 0:13:50  Lr: 0.001875  Loss: 0.4080  Acc@1: 87.5000 (82.3313)  Acc@5: 100.0000 (97.0451)  time: 0.3431  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:46  Lr: 0.001875  Loss: 0.2748  Acc@1: 87.5000 (82.3464)  Acc@5: 100.0000 (97.0439)  time: 0.3429  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:43  Lr: 0.001875  Loss: 1.1344  Acc@1: 81.2500 (82.3200)  Acc@5: 100.0000 (97.0334)  time: 0.3431  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:39  Lr: 0.001875  Loss: 0.3764  Acc@1: 81.2500 (82.3623)  Acc@5: 100.0000 (97.0414)  time: 0.3431  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:36  Lr: 0.001875  Loss: 0.4840  Acc@1: 81.2500 (82.3497)  Acc@5: 100.0000 (97.0583)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:33  Lr: 0.001875  Loss: 0.4663  Acc@1: 81.2500 (82.3643)  Acc@5: 100.0000 (97.0749)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:29  Lr: 0.001875  Loss: 0.8749  Acc@1: 81.2500 (82.3340)  Acc@5: 100.0000 (97.0646)  time: 0.3449  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:26  Lr: 0.001875  Loss: 0.3940  Acc@1: 81.2500 (82.3131)  Acc@5: 93.7500 (97.0633)  time: 0.3445  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:22  Lr: 0.001875  Loss: 0.8226  Acc@1: 81.2500 (82.3188)  Acc@5: 100.0000 (97.0751)  time: 0.3443  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:19  Lr: 0.001875  Loss: 0.2436  Acc@1: 81.2500 (82.3070)  Acc@5: 100.0000 (97.0825)  time: 0.3440  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:15  Lr: 0.001875  Loss: 0.4472  Acc@1: 81.2500 (82.2953)  Acc@5: 100.0000 (97.0810)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:12  Lr: 0.001875  Loss: 0.2160  Acc@1: 81.2500 (82.3053)  Acc@5: 100.0000 (97.0882)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:08  Lr: 0.001875  Loss: 0.6206  Acc@1: 81.2500 (82.3195)  Acc@5: 100.0000 (97.0996)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:05  Lr: 0.001875  Loss: 0.0835  Acc@1: 81.2500 (82.3462)  Acc@5: 100.0000 (97.1023)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:01  Lr: 0.001875  Loss: 0.7455  Acc@1: 87.5000 (82.3599)  Acc@5: 100.0000 (97.1008)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1490/3750]  eta: 0:12:58  Lr: 0.001875  Loss: 0.6138  Acc@1: 81.2500 (82.3357)  Acc@5: 100.0000 (97.0909)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1500/3750]  eta: 0:12:55  Lr: 0.001875  Loss: 0.3865  Acc@1: 81.2500 (82.3368)  Acc@5: 93.7500 (97.0853)  time: 0.3444  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1510/3750]  eta: 0:12:51  Lr: 0.001875  Loss: 0.6529  Acc@1: 81.2500 (82.3089)  Acc@5: 93.7500 (97.0715)  time: 0.3451  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:48  Lr: 0.001875  Loss: 0.5735  Acc@1: 68.7500 (82.2650)  Acc@5: 93.7500 (97.0620)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:44  Lr: 0.001875  Loss: 1.0603  Acc@1: 81.2500 (82.2542)  Acc@5: 100.0000 (97.0607)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:41  Lr: 0.001875  Loss: 0.5352  Acc@1: 81.2500 (82.2761)  Acc@5: 100.0000 (97.0514)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:37  Lr: 0.001875  Loss: 1.1450  Acc@1: 87.5000 (82.3017)  Acc@5: 93.7500 (97.0301)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:34  Lr: 0.001875  Loss: 0.3673  Acc@1: 87.5000 (82.3190)  Acc@5: 100.0000 (97.0412)  time: 0.3435  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:30  Lr: 0.001875  Loss: 0.7253  Acc@1: 87.5000 (82.3401)  Acc@5: 100.0000 (97.0481)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:27  Lr: 0.001875  Loss: 0.4391  Acc@1: 87.5000 (82.3490)  Acc@5: 100.0000 (97.0549)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:24  Lr: 0.001875  Loss: 0.1352  Acc@1: 81.2500 (82.3382)  Acc@5: 100.0000 (97.0537)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:20  Lr: 0.001875  Loss: 0.6378  Acc@1: 81.2500 (82.3118)  Acc@5: 93.7500 (97.0370)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:17  Lr: 0.001875  Loss: 0.4887  Acc@1: 81.2500 (82.3091)  Acc@5: 93.7500 (97.0244)  time: 0.3451  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:13  Lr: 0.001875  Loss: 0.5183  Acc@1: 87.5000 (82.3219)  Acc@5: 100.0000 (97.0350)  time: 0.3448  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:10  Lr: 0.001875  Loss: 0.7702  Acc@1: 81.2500 (82.3038)  Acc@5: 100.0000 (97.0494)  time: 0.3469  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:06  Lr: 0.001875  Loss: 0.5538  Acc@1: 81.2500 (82.2898)  Acc@5: 100.0000 (97.0597)  time: 0.3459  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:03  Lr: 0.001875  Loss: 0.2022  Acc@1: 81.2500 (82.2986)  Acc@5: 100.0000 (97.0662)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1660/3750]  eta: 0:11:59  Lr: 0.001875  Loss: 0.3169  Acc@1: 81.2500 (82.2923)  Acc@5: 100.0000 (97.0613)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1670/3750]  eta: 0:11:56  Lr: 0.001875  Loss: 0.4970  Acc@1: 81.2500 (82.2898)  Acc@5: 100.0000 (97.0639)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1680/3750]  eta: 0:11:53  Lr: 0.001875  Loss: 0.8770  Acc@1: 87.5000 (82.3208)  Acc@5: 100.0000 (97.0814)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:49  Lr: 0.001875  Loss: 0.9722  Acc@1: 87.5000 (82.3034)  Acc@5: 100.0000 (97.0727)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:46  Lr: 0.001875  Loss: 0.7650  Acc@1: 75.0000 (82.2788)  Acc@5: 100.0000 (97.0642)  time: 0.3458  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:42  Lr: 0.001875  Loss: 0.2743  Acc@1: 81.2500 (82.3130)  Acc@5: 100.0000 (97.0595)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:39  Lr: 0.001875  Loss: 0.3073  Acc@1: 87.5000 (82.3431)  Acc@5: 100.0000 (97.0693)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:35  Lr: 0.001875  Loss: 0.7949  Acc@1: 87.5000 (82.3512)  Acc@5: 100.0000 (97.0573)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:32  Lr: 0.001875  Loss: 0.6210  Acc@1: 81.2500 (82.3270)  Acc@5: 93.7500 (97.0563)  time: 0.3437  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:28  Lr: 0.001875  Loss: 0.3261  Acc@1: 81.2500 (82.3494)  Acc@5: 100.0000 (97.0624)  time: 0.3441  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:25  Lr: 0.001875  Loss: 0.4494  Acc@1: 87.5000 (82.3502)  Acc@5: 100.0000 (97.0542)  time: 0.3442  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:22  Lr: 0.001875  Loss: 0.7765  Acc@1: 81.2500 (82.3334)  Acc@5: 100.0000 (97.0532)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:18  Lr: 0.001875  Loss: 0.4856  Acc@1: 81.2500 (82.3484)  Acc@5: 100.0000 (97.0557)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:15  Lr: 0.001875  Loss: 0.4842  Acc@1: 87.5000 (82.3737)  Acc@5: 100.0000 (97.0582)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:11  Lr: 0.001875  Loss: 0.6342  Acc@1: 87.5000 (82.3778)  Acc@5: 93.7500 (97.0537)  time: 0.3432  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:08  Lr: 0.001875  Loss: 1.2535  Acc@1: 87.5000 (82.3889)  Acc@5: 93.7500 (97.0493)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:04  Lr: 0.001875  Loss: 0.7585  Acc@1: 81.2500 (82.3826)  Acc@5: 100.0000 (97.0483)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:01  Lr: 0.001875  Loss: 0.3250  Acc@1: 81.2500 (82.3969)  Acc@5: 100.0000 (97.0508)  time: 0.3442  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1840/3750]  eta: 0:10:57  Lr: 0.001875  Loss: 0.2677  Acc@1: 81.2500 (82.3839)  Acc@5: 100.0000 (97.0464)  time: 0.3451  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1850/3750]  eta: 0:10:54  Lr: 0.001875  Loss: 0.9070  Acc@1: 81.2500 (82.3474)  Acc@5: 100.0000 (97.0421)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:51  Lr: 0.001875  Loss: 0.6913  Acc@1: 81.2500 (82.3448)  Acc@5: 100.0000 (97.0412)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:47  Lr: 0.001875  Loss: 0.4460  Acc@1: 81.2500 (82.3056)  Acc@5: 93.7500 (97.0303)  time: 0.3437  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:44  Lr: 0.001875  Loss: 0.6292  Acc@1: 81.2500 (82.3099)  Acc@5: 93.7500 (97.0195)  time: 0.3439  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:40  Lr: 0.001875  Loss: 0.4756  Acc@1: 87.5000 (82.3341)  Acc@5: 100.0000 (97.0221)  time: 0.3442  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:37  Lr: 0.001875  Loss: 1.1617  Acc@1: 87.5000 (82.3218)  Acc@5: 100.0000 (97.0180)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:33  Lr: 0.001875  Loss: 0.5682  Acc@1: 81.2500 (82.3391)  Acc@5: 93.7500 (97.0140)  time: 0.3426  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:30  Lr: 0.001875  Loss: 0.2820  Acc@1: 87.5000 (82.3497)  Acc@5: 100.0000 (97.0198)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:26  Lr: 0.001875  Loss: 0.5403  Acc@1: 81.2500 (82.3569)  Acc@5: 100.0000 (97.0255)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:23  Lr: 0.001875  Loss: 0.4474  Acc@1: 81.2500 (82.3738)  Acc@5: 100.0000 (97.0215)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:19  Lr: 0.001875  Loss: 0.4030  Acc@1: 87.5000 (82.3744)  Acc@5: 100.0000 (97.0272)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:16  Lr: 0.001875  Loss: 0.4584  Acc@1: 81.2500 (82.3814)  Acc@5: 100.0000 (97.0232)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:13  Lr: 0.001875  Loss: 0.4499  Acc@1: 81.2500 (82.3757)  Acc@5: 93.7500 (97.0193)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:09  Lr: 0.001875  Loss: 0.3597  Acc@1: 81.2500 (82.3700)  Acc@5: 100.0000 (97.0312)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:06  Lr: 0.001875  Loss: 0.4318  Acc@1: 81.2500 (82.3707)  Acc@5: 100.0000 (97.0304)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:02  Lr: 0.001875  Loss: 0.3146  Acc@1: 87.5000 (82.3869)  Acc@5: 100.0000 (97.0327)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2010/3750]  eta: 0:09:59  Lr: 0.001875  Loss: 0.4650  Acc@1: 81.2500 (82.3688)  Acc@5: 100.0000 (97.0288)  time: 0.3427  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2020/3750]  eta: 0:09:55  Lr: 0.001875  Loss: 0.7228  Acc@1: 87.5000 (82.3881)  Acc@5: 100.0000 (97.0374)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2030/3750]  eta: 0:09:52  Lr: 0.001875  Loss: 0.5275  Acc@1: 87.5000 (82.3886)  Acc@5: 100.0000 (97.0366)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:48  Lr: 0.001875  Loss: 0.4450  Acc@1: 87.5000 (82.4075)  Acc@5: 100.0000 (97.0358)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:45  Lr: 0.001875  Loss: 0.4365  Acc@1: 87.5000 (82.4141)  Acc@5: 100.0000 (97.0137)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:41  Lr: 0.001875  Loss: 0.8110  Acc@1: 81.2500 (82.4205)  Acc@5: 93.7500 (97.0069)  time: 0.3423  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:38  Lr: 0.001875  Loss: 0.5665  Acc@1: 81.2500 (82.4149)  Acc@5: 100.0000 (97.0033)  time: 0.3424  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:35  Lr: 0.001875  Loss: 0.7948  Acc@1: 81.2500 (82.4003)  Acc@5: 100.0000 (97.0117)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:31  Lr: 0.001875  Loss: 0.2197  Acc@1: 75.0000 (82.3888)  Acc@5: 100.0000 (97.0050)  time: 0.3446  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:28  Lr: 0.001875  Loss: 0.4159  Acc@1: 81.2500 (82.3834)  Acc@5: 93.7500 (97.0074)  time: 0.3445  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:24  Lr: 0.001875  Loss: 0.8222  Acc@1: 81.2500 (82.3810)  Acc@5: 93.7500 (96.9979)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:21  Lr: 0.001875  Loss: 0.2045  Acc@1: 81.2500 (82.3845)  Acc@5: 93.7500 (96.9884)  time: 0.3448  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:17  Lr: 0.001875  Loss: 0.7200  Acc@1: 81.2500 (82.3938)  Acc@5: 100.0000 (96.9938)  time: 0.3439  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:14  Lr: 0.001875  Loss: 0.6798  Acc@1: 81.2500 (82.3885)  Acc@5: 100.0000 (96.9961)  time: 0.3443  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:10  Lr: 0.001875  Loss: 0.5608  Acc@1: 81.2500 (82.3832)  Acc@5: 100.0000 (96.9927)  time: 0.3441  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:07  Lr: 0.001875  Loss: 0.7304  Acc@1: 81.2500 (82.3780)  Acc@5: 100.0000 (96.9950)  time: 0.3431  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:04  Lr: 0.001875  Loss: 0.4124  Acc@1: 81.2500 (82.3958)  Acc@5: 100.0000 (97.0031)  time: 0.3426  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:00  Lr: 0.001875  Loss: 0.6769  Acc@1: 81.2500 (82.3705)  Acc@5: 100.0000 (96.9939)  time: 0.3444  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2190/3750]  eta: 0:08:57  Lr: 0.001875  Loss: 0.3980  Acc@1: 81.2500 (82.3625)  Acc@5: 100.0000 (96.9991)  time: 0.3463  data: 0.0032  max mem: 2500
Train: Epoch[5/5]  [2200/3750]  eta: 0:08:53  Lr: 0.001875  Loss: 0.7899  Acc@1: 81.2500 (82.3546)  Acc@5: 100.0000 (96.9985)  time: 0.3455  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:50  Lr: 0.001875  Loss: 0.5325  Acc@1: 81.2500 (82.3666)  Acc@5: 100.0000 (97.0036)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:46  Lr: 0.001875  Loss: 0.5956  Acc@1: 81.2500 (82.3728)  Acc@5: 100.0000 (97.0115)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:43  Lr: 0.001875  Loss: 0.2848  Acc@1: 81.2500 (82.3846)  Acc@5: 100.0000 (97.0081)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:40  Lr: 0.001875  Loss: 0.1373  Acc@1: 87.5000 (82.3990)  Acc@5: 100.0000 (97.0103)  time: 0.3464  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:36  Lr: 0.001875  Loss: 0.1883  Acc@1: 87.5000 (82.4134)  Acc@5: 100.0000 (97.0069)  time: 0.3457  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:33  Lr: 0.001875  Loss: 1.0340  Acc@1: 87.5000 (82.4138)  Acc@5: 100.0000 (97.0063)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:29  Lr: 0.001875  Loss: 0.3195  Acc@1: 87.5000 (82.4279)  Acc@5: 100.0000 (97.0112)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:26  Lr: 0.001875  Loss: 0.6718  Acc@1: 87.5000 (82.4255)  Acc@5: 100.0000 (97.0079)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:22  Lr: 0.001875  Loss: 0.8480  Acc@1: 81.2500 (82.4231)  Acc@5: 100.0000 (97.0155)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:19  Lr: 0.001875  Loss: 0.4204  Acc@1: 81.2500 (82.4261)  Acc@5: 100.0000 (97.0203)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:15  Lr: 0.001875  Loss: 0.2260  Acc@1: 81.2500 (82.4183)  Acc@5: 100.0000 (97.0278)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:12  Lr: 0.001875  Loss: 0.4886  Acc@1: 81.2500 (82.4348)  Acc@5: 100.0000 (97.0298)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:08  Lr: 0.001875  Loss: 0.3192  Acc@1: 81.2500 (82.4432)  Acc@5: 100.0000 (97.0345)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:05  Lr: 0.001875  Loss: 0.3207  Acc@1: 87.5000 (82.4648)  Acc@5: 100.0000 (97.0365)  time: 0.3455  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:02  Lr: 0.001875  Loss: 0.7654  Acc@1: 81.2500 (82.4410)  Acc@5: 100.0000 (97.0305)  time: 0.3459  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2360/3750]  eta: 0:07:58  Lr: 0.001875  Loss: 0.7943  Acc@1: 81.2500 (82.4518)  Acc@5: 100.0000 (97.0325)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2370/3750]  eta: 0:07:55  Lr: 0.001875  Loss: 0.9620  Acc@1: 87.5000 (82.4468)  Acc@5: 100.0000 (97.0345)  time: 0.3429  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:51  Lr: 0.001875  Loss: 0.2200  Acc@1: 81.2500 (82.4417)  Acc@5: 100.0000 (97.0391)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:48  Lr: 0.001875  Loss: 0.2122  Acc@1: 81.2500 (82.4289)  Acc@5: 100.0000 (97.0253)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:44  Lr: 0.001875  Loss: 1.0249  Acc@1: 81.2500 (82.4240)  Acc@5: 100.0000 (97.0351)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:41  Lr: 0.001875  Loss: 0.2866  Acc@1: 81.2500 (82.4191)  Acc@5: 100.0000 (97.0396)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:38  Lr: 0.001875  Loss: 0.3897  Acc@1: 81.2500 (82.4272)  Acc@5: 100.0000 (97.0389)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:34  Lr: 0.001875  Loss: 0.7534  Acc@1: 81.2500 (82.4275)  Acc@5: 100.0000 (97.0408)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:31  Lr: 0.001875  Loss: 1.2053  Acc@1: 81.2500 (82.4150)  Acc@5: 93.7500 (97.0248)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:27  Lr: 0.001875  Loss: 0.4101  Acc@1: 81.2500 (82.4077)  Acc@5: 93.7500 (97.0089)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:24  Lr: 0.001875  Loss: 0.1109  Acc@1: 81.2500 (82.4030)  Acc@5: 93.7500 (97.0083)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:20  Lr: 0.001875  Loss: 0.2375  Acc@1: 81.2500 (82.4236)  Acc@5: 100.0000 (97.0053)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:17  Lr: 0.001875  Loss: 0.5218  Acc@1: 87.5000 (82.4365)  Acc@5: 100.0000 (97.0098)  time: 0.3450  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:13  Lr: 0.001875  Loss: 0.9294  Acc@1: 81.2500 (82.4092)  Acc@5: 100.0000 (96.9967)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:10  Lr: 0.001875  Loss: 0.5190  Acc@1: 81.2500 (82.4070)  Acc@5: 93.7500 (96.9887)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:07  Lr: 0.001875  Loss: 0.3062  Acc@1: 81.2500 (82.4149)  Acc@5: 100.0000 (96.9957)  time: 0.3438  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:03  Lr: 0.001875  Loss: 0.4455  Acc@1: 81.2500 (82.4103)  Acc@5: 100.0000 (96.9952)  time: 0.3439  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:00  Lr: 0.001875  Loss: 0.1369  Acc@1: 81.2500 (82.4230)  Acc@5: 100.0000 (96.9972)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2540/3750]  eta: 0:06:56  Lr: 0.001875  Loss: 0.3232  Acc@1: 87.5000 (82.4183)  Acc@5: 100.0000 (97.0041)  time: 0.3454  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:53  Lr: 0.001875  Loss: 0.2439  Acc@1: 87.5000 (82.4505)  Acc@5: 100.0000 (97.0036)  time: 0.3464  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:49  Lr: 0.001875  Loss: 0.2831  Acc@1: 87.5000 (82.4361)  Acc@5: 100.0000 (97.0104)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:46  Lr: 0.001875  Loss: 0.5296  Acc@1: 81.2500 (82.4290)  Acc@5: 100.0000 (97.0075)  time: 0.3437  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:42  Lr: 0.001875  Loss: 0.2903  Acc@1: 87.5000 (82.4487)  Acc@5: 100.0000 (97.0070)  time: 0.3438  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:39  Lr: 0.001875  Loss: 0.6886  Acc@1: 87.5000 (82.4561)  Acc@5: 100.0000 (97.0113)  time: 0.3438  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:36  Lr: 0.001875  Loss: 0.8110  Acc@1: 81.2500 (82.4082)  Acc@5: 100.0000 (97.0036)  time: 0.3446  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:32  Lr: 0.001875  Loss: 0.3919  Acc@1: 81.2500 (82.4205)  Acc@5: 100.0000 (97.0031)  time: 0.3446  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:29  Lr: 0.001875  Loss: 0.2774  Acc@1: 81.2500 (82.4161)  Acc@5: 100.0000 (97.0073)  time: 0.3441  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:25  Lr: 0.001875  Loss: 0.5087  Acc@1: 81.2500 (82.4259)  Acc@5: 100.0000 (97.0092)  time: 0.3438  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:22  Lr: 0.001875  Loss: 0.5606  Acc@1: 81.2500 (82.4238)  Acc@5: 100.0000 (97.0134)  time: 0.3434  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:18  Lr: 0.001875  Loss: 0.5882  Acc@1: 81.2500 (82.4076)  Acc@5: 100.0000 (97.0129)  time: 0.3430  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:15  Lr: 0.001875  Loss: 0.4403  Acc@1: 81.2500 (82.4220)  Acc@5: 100.0000 (97.0171)  time: 0.3425  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:11  Lr: 0.001875  Loss: 0.2718  Acc@1: 81.2500 (82.4106)  Acc@5: 100.0000 (97.0166)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:08  Lr: 0.001875  Loss: 0.3774  Acc@1: 81.2500 (82.4226)  Acc@5: 100.0000 (97.0160)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:05  Lr: 0.001875  Loss: 1.1857  Acc@1: 81.2500 (82.4229)  Acc@5: 100.0000 (97.0109)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:01  Lr: 0.001875  Loss: 0.4462  Acc@1: 81.2500 (82.4324)  Acc@5: 93.7500 (97.0104)  time: 0.3429  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2710/3750]  eta: 0:05:58  Lr: 0.001875  Loss: 0.4503  Acc@1: 87.5000 (82.4258)  Acc@5: 93.7500 (97.0006)  time: 0.3434  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:54  Lr: 0.001875  Loss: 0.2535  Acc@1: 81.2500 (82.4352)  Acc@5: 100.0000 (97.0002)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:51  Lr: 0.001875  Loss: 0.3537  Acc@1: 87.5000 (82.4492)  Acc@5: 100.0000 (97.0066)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:47  Lr: 0.001875  Loss: 0.7111  Acc@1: 87.5000 (82.4425)  Acc@5: 100.0000 (97.0038)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:44  Lr: 0.001875  Loss: 0.2410  Acc@1: 87.5000 (82.4632)  Acc@5: 100.0000 (97.0056)  time: 0.3424  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:40  Lr: 0.001875  Loss: 0.4431  Acc@1: 81.2500 (82.4611)  Acc@5: 100.0000 (97.0074)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:37  Lr: 0.001875  Loss: 0.2370  Acc@1: 81.2500 (82.4589)  Acc@5: 100.0000 (97.0069)  time: 0.3432  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:33  Lr: 0.001875  Loss: 0.6395  Acc@1: 81.2500 (82.4636)  Acc@5: 100.0000 (97.0020)  time: 0.3429  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:30  Lr: 0.001875  Loss: 0.5512  Acc@1: 81.2500 (82.4637)  Acc@5: 100.0000 (97.0015)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:27  Lr: 0.001875  Loss: 0.7302  Acc@1: 81.2500 (82.4482)  Acc@5: 100.0000 (97.0011)  time: 0.3438  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:23  Lr: 0.001875  Loss: 0.4367  Acc@1: 81.2500 (82.4551)  Acc@5: 100.0000 (97.0006)  time: 0.3437  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:20  Lr: 0.001875  Loss: 0.1718  Acc@1: 81.2500 (82.4530)  Acc@5: 100.0000 (97.0024)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:16  Lr: 0.001875  Loss: 0.3965  Acc@1: 81.2500 (82.4576)  Acc@5: 100.0000 (96.9975)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:13  Lr: 0.001875  Loss: 0.4627  Acc@1: 81.2500 (82.4710)  Acc@5: 100.0000 (97.0037)  time: 0.3434  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:09  Lr: 0.001875  Loss: 0.7001  Acc@1: 81.2500 (82.4689)  Acc@5: 100.0000 (97.0098)  time: 0.3444  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:06  Lr: 0.001875  Loss: 0.6292  Acc@1: 81.2500 (82.4602)  Acc@5: 100.0000 (97.0093)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:02  Lr: 0.001875  Loss: 0.3260  Acc@1: 81.2500 (82.4604)  Acc@5: 100.0000 (97.0176)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2880/3750]  eta: 0:04:59  Lr: 0.001875  Loss: 0.9441  Acc@1: 81.2500 (82.4605)  Acc@5: 100.0000 (97.0106)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2890/3750]  eta: 0:04:56  Lr: 0.001875  Loss: 0.3244  Acc@1: 81.2500 (82.4628)  Acc@5: 93.7500 (97.0123)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:52  Lr: 0.001875  Loss: 0.6307  Acc@1: 87.5000 (82.4716)  Acc@5: 93.7500 (97.0075)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:49  Lr: 0.001875  Loss: 0.3786  Acc@1: 81.2500 (82.4738)  Acc@5: 93.7500 (97.0049)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:45  Lr: 0.001875  Loss: 0.4878  Acc@1: 81.2500 (82.4718)  Acc@5: 93.7500 (97.0023)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:42  Lr: 0.001875  Loss: 0.4217  Acc@1: 81.2500 (82.4655)  Acc@5: 93.7500 (97.0019)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:38  Lr: 0.001875  Loss: 0.1843  Acc@1: 81.2500 (82.4528)  Acc@5: 100.0000 (97.0099)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:35  Lr: 0.001875  Loss: 0.1722  Acc@1: 81.2500 (82.4720)  Acc@5: 100.0000 (97.0116)  time: 0.3458  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:31  Lr: 0.001875  Loss: 0.4140  Acc@1: 87.5000 (82.4764)  Acc@5: 100.0000 (97.0111)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:28  Lr: 0.001875  Loss: 0.2459  Acc@1: 87.5000 (82.4806)  Acc@5: 100.0000 (97.0065)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:25  Lr: 0.001875  Loss: 0.9004  Acc@1: 81.2500 (82.4744)  Acc@5: 100.0000 (97.0039)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:21  Lr: 0.001875  Loss: 0.7292  Acc@1: 81.2500 (82.4703)  Acc@5: 100.0000 (96.9993)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:18  Lr: 0.001875  Loss: 0.4505  Acc@1: 81.2500 (82.4808)  Acc@5: 100.0000 (97.0031)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:14  Lr: 0.001875  Loss: 0.1610  Acc@1: 87.5000 (82.4830)  Acc@5: 100.0000 (97.0027)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:11  Lr: 0.001875  Loss: 0.6743  Acc@1: 81.2500 (82.4934)  Acc@5: 93.7500 (97.0002)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:07  Lr: 0.001875  Loss: 0.2757  Acc@1: 87.5000 (82.5058)  Acc@5: 100.0000 (97.0039)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:04  Lr: 0.001875  Loss: 0.3712  Acc@1: 87.5000 (82.5181)  Acc@5: 100.0000 (97.0055)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:01  Lr: 0.001875  Loss: 0.0835  Acc@1: 87.5000 (82.5119)  Acc@5: 100.0000 (97.0051)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3060/3750]  eta: 0:03:57  Lr: 0.001875  Loss: 0.6591  Acc@1: 75.0000 (82.4975)  Acc@5: 100.0000 (97.0006)  time: 0.3448  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.5147  Acc@1: 75.0000 (82.4853)  Acc@5: 100.0000 (96.9941)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:50  Lr: 0.001875  Loss: 0.3488  Acc@1: 81.2500 (82.4854)  Acc@5: 100.0000 (96.9957)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:47  Lr: 0.001875  Loss: 0.3756  Acc@1: 81.2500 (82.4854)  Acc@5: 100.0000 (96.9994)  time: 0.3444  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:43  Lr: 0.001875  Loss: 0.4022  Acc@1: 81.2500 (82.4976)  Acc@5: 100.0000 (97.0010)  time: 0.3450  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:40  Lr: 0.001875  Loss: 0.7300  Acc@1: 87.5000 (82.5036)  Acc@5: 100.0000 (97.0066)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:36  Lr: 0.001875  Loss: 0.9796  Acc@1: 81.2500 (82.4976)  Acc@5: 100.0000 (97.0082)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.3838  Acc@1: 81.2500 (82.4956)  Acc@5: 100.0000 (97.0038)  time: 0.3441  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.6023  Acc@1: 81.2500 (82.4837)  Acc@5: 100.0000 (97.0093)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:26  Lr: 0.001875  Loss: 0.3334  Acc@1: 81.2500 (82.4798)  Acc@5: 100.0000 (97.0089)  time: 0.3445  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.7246  Acc@1: 81.2500 (82.4719)  Acc@5: 93.7500 (97.0045)  time: 0.3458  data: 0.0023  max mem: 2500
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:19  Lr: 0.001875  Loss: 0.9029  Acc@1: 87.5000 (82.4878)  Acc@5: 100.0000 (97.0061)  time: 0.3448  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:16  Lr: 0.001875  Loss: 0.6449  Acc@1: 87.5000 (82.5035)  Acc@5: 100.0000 (97.0057)  time: 0.3444  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:12  Lr: 0.001875  Loss: 1.2623  Acc@1: 81.2500 (82.4918)  Acc@5: 100.0000 (97.0052)  time: 0.3438  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:09  Lr: 0.001875  Loss: 0.5828  Acc@1: 81.2500 (82.4996)  Acc@5: 100.0000 (97.0107)  time: 0.3440  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:05  Lr: 0.001875  Loss: 0.2322  Acc@1: 87.5000 (82.5074)  Acc@5: 100.0000 (97.0161)  time: 0.3444  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:02  Lr: 0.001875  Loss: 0.6396  Acc@1: 81.2500 (82.5074)  Acc@5: 100.0000 (97.0137)  time: 0.3443  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 0.1157  Acc@1: 81.2500 (82.5151)  Acc@5: 100.0000 (97.0172)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:55  Lr: 0.001875  Loss: 0.3345  Acc@1: 81.2500 (82.5170)  Acc@5: 100.0000 (97.0129)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.1242  Acc@1: 81.2500 (82.5208)  Acc@5: 100.0000 (97.0144)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:48  Lr: 0.001875  Loss: 0.2847  Acc@1: 81.2500 (82.5226)  Acc@5: 100.0000 (97.0140)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 0.8762  Acc@1: 87.5000 (82.5225)  Acc@5: 100.0000 (97.0116)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:41  Lr: 0.001875  Loss: 0.3527  Acc@1: 87.5000 (82.5320)  Acc@5: 100.0000 (97.0131)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 0.2268  Acc@1: 87.5000 (82.5338)  Acc@5: 100.0000 (97.0108)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:34  Lr: 0.001875  Loss: 0.5602  Acc@1: 81.2500 (82.5356)  Acc@5: 100.0000 (97.0161)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:31  Lr: 0.001875  Loss: 0.1760  Acc@1: 81.2500 (82.5317)  Acc@5: 100.0000 (97.0194)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.3612  Acc@1: 81.2500 (82.5203)  Acc@5: 100.0000 (97.0096)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:24  Lr: 0.001875  Loss: 0.9811  Acc@1: 81.2500 (82.5128)  Acc@5: 100.0000 (97.0110)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.1252  Acc@1: 81.2500 (82.5127)  Acc@5: 100.0000 (97.0144)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:17  Lr: 0.001875  Loss: 0.4408  Acc@1: 81.2500 (82.5164)  Acc@5: 100.0000 (97.0158)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.3317  Acc@1: 81.2500 (82.5145)  Acc@5: 100.0000 (97.0154)  time: 0.3442  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:10  Lr: 0.001875  Loss: 0.6950  Acc@1: 81.2500 (82.5108)  Acc@5: 100.0000 (97.0168)  time: 0.3438  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.5890  Acc@1: 81.2500 (82.5070)  Acc@5: 100.0000 (97.0109)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:03  Lr: 0.001875  Loss: 0.5369  Acc@1: 81.2500 (82.5033)  Acc@5: 100.0000 (97.0123)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 0.6152  Acc@1: 81.2500 (82.5217)  Acc@5: 100.0000 (97.0174)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.6474  Acc@1: 87.5000 (82.5125)  Acc@5: 100.0000 (97.0188)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 0.2572  Acc@1: 87.5000 (82.5252)  Acc@5: 100.0000 (97.0129)  time: 0.3435  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.9884  Acc@1: 81.2500 (82.5051)  Acc@5: 93.7500 (97.0107)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:46  Lr: 0.001875  Loss: 0.3942  Acc@1: 81.2500 (82.5069)  Acc@5: 93.7500 (97.0103)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.8408  Acc@1: 81.2500 (82.5033)  Acc@5: 93.7500 (97.0027)  time: 0.3454  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:39  Lr: 0.001875  Loss: 0.4410  Acc@1: 81.2500 (82.5014)  Acc@5: 93.7500 (97.0005)  time: 0.3447  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.4281  Acc@1: 87.5000 (82.5158)  Acc@5: 100.0000 (97.0019)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:32  Lr: 0.001875  Loss: 1.1498  Acc@1: 87.5000 (82.5104)  Acc@5: 100.0000 (96.9962)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.4618  Acc@1: 81.2500 (82.5158)  Acc@5: 100.0000 (97.0012)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.5177  Acc@1: 87.5000 (82.5371)  Acc@5: 100.0000 (97.0062)  time: 0.3442  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.2053  Acc@1: 87.5000 (82.5370)  Acc@5: 100.0000 (97.0076)  time: 0.3446  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.6874  Acc@1: 81.2500 (82.5493)  Acc@5: 100.0000 (97.0090)  time: 0.3451  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 0.5164  Acc@1: 81.2500 (82.5474)  Acc@5: 100.0000 (97.0051)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.3788  Acc@1: 81.2500 (82.5367)  Acc@5: 93.7500 (97.0030)  time: 0.3459  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:08  Lr: 0.001875  Loss: 0.5047  Acc@1: 81.2500 (82.5313)  Acc@5: 100.0000 (97.0026)  time: 0.3453  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.5779  Acc@1: 81.2500 (82.5435)  Acc@5: 100.0000 (97.0058)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:01  Lr: 0.001875  Loss: 0.4248  Acc@1: 81.2500 (82.5399)  Acc@5: 100.0000 (97.0054)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4714  Acc@1: 81.2500 (82.5380)  Acc@5: 93.7500 (97.0033)  time: 0.3445  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2099  Acc@1: 81.2500 (82.5327)  Acc@5: 100.0000 (97.0064)  time: 0.3446  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1051  Acc@1: 87.5000 (82.5465)  Acc@5: 100.0000 (97.0095)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1840  Acc@1: 87.5000 (82.5533)  Acc@5: 100.0000 (97.0074)  time: 0.3451  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.4551  Acc@1: 87.5000 (82.5704)  Acc@5: 100.0000 (97.0122)  time: 0.3451  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.4050  Acc@1: 87.5000 (82.5823)  Acc@5: 100.0000 (97.0136)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 0.4200  Acc@1: 81.2500 (82.5683)  Acc@5: 100.0000 (97.0063)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0831  Acc@1: 81.2500 (82.5767)  Acc@5: 100.0000 (97.0094)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:30  Lr: 0.001875  Loss: 0.5040  Acc@1: 81.2500 (82.5765)  Acc@5: 100.0000 (97.0073)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.5521  Acc@1: 81.2500 (82.5763)  Acc@5: 100.0000 (97.0086)  time: 0.3439  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2371  Acc@1: 87.5000 (82.5964)  Acc@5: 100.0000 (97.0100)  time: 0.3441  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 0.9080  Acc@1: 87.5000 (82.5928)  Acc@5: 100.0000 (97.0096)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.8702  Acc@1: 81.2500 (82.5942)  Acc@5: 100.0000 (97.0109)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.4735  Acc@1: 75.0000 (82.5805)  Acc@5: 100.0000 (97.0106)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.1687  Acc@1: 75.0000 (82.5836)  Acc@5: 100.0000 (97.0153)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2833  Acc@1: 87.5000 (82.5717)  Acc@5: 100.0000 (97.0115)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.8380  Acc@1: 81.2500 (82.5682)  Acc@5: 93.7500 (97.0045)  time: 0.3460  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2898  Acc@1: 87.5000 (82.5800)  Acc@5: 100.0000 (97.0067)  time: 0.3459  data: 0.0025  max mem: 2500
Train: Epoch[5/5] Total time: 0:21:31 (0.3445 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2898  Acc@1: 87.5000 (82.5800)  Acc@5: 100.0000 (97.0067)
Test: [Task 1]  [   0/1627]  eta: 0:15:22  Loss: 1.5179 (1.5179)  Acc@1: 56.2500 (56.2500)  Acc@5: 87.5000 (87.5000)  time: 0.5673  data: 0.3507  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:38  Loss: 1.0658 (1.0767)  Acc@1: 68.7500 (72.7273)  Acc@5: 100.0000 (96.5909)  time: 0.2464  data: 0.0322  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:11  Loss: 1.0658 (1.0547)  Acc@1: 75.0000 (73.2143)  Acc@5: 93.7500 (94.6429)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:00  Loss: 1.1054 (1.0639)  Acc@1: 75.0000 (73.1855)  Acc@5: 93.7500 (94.3548)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:54  Loss: 1.1449 (1.0932)  Acc@1: 75.0000 (72.2561)  Acc@5: 93.7500 (94.0549)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:49  Loss: 1.1012 (1.0925)  Acc@1: 75.0000 (72.4265)  Acc@5: 93.7500 (94.1176)  time: 0.2149  data: 0.0006  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:45  Loss: 1.0896 (1.0924)  Acc@1: 68.7500 (72.3361)  Acc@5: 93.7500 (94.3648)  time: 0.2143  data: 0.0006  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:41  Loss: 0.9636 (1.0809)  Acc@1: 68.7500 (72.7113)  Acc@5: 93.7500 (94.5423)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:38  Loss: 0.8511 (1.0638)  Acc@1: 81.2500 (73.3025)  Acc@5: 100.0000 (94.9074)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:35  Loss: 1.0044 (1.0723)  Acc@1: 75.0000 (72.9396)  Acc@5: 93.7500 (94.7802)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:32  Loss: 1.1694 (1.0971)  Acc@1: 68.7500 (72.2153)  Acc@5: 93.7500 (94.3688)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:30  Loss: 1.1536 (1.0931)  Acc@1: 68.7500 (72.1847)  Acc@5: 93.7500 (94.6509)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:27  Loss: 1.0896 (1.0962)  Acc@1: 75.0000 (72.2624)  Acc@5: 93.7500 (94.5248)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:25  Loss: 1.1007 (1.1002)  Acc@1: 75.0000 (72.1374)  Acc@5: 93.7500 (94.5134)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:22  Loss: 1.0462 (1.0937)  Acc@1: 75.0000 (72.0301)  Acc@5: 93.7500 (94.6809)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:20  Loss: 0.7716 (1.0767)  Acc@1: 81.2500 (72.5993)  Acc@5: 100.0000 (94.7848)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:17  Loss: 0.7859 (1.0675)  Acc@1: 75.0000 (72.8261)  Acc@5: 100.0000 (94.7981)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:15  Loss: 0.8964 (1.0592)  Acc@1: 75.0000 (73.1725)  Acc@5: 100.0000 (94.9927)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:12  Loss: 0.8964 (1.0657)  Acc@1: 75.0000 (73.0663)  Acc@5: 93.7500 (94.8550)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:10  Loss: 0.9859 (1.0628)  Acc@1: 75.0000 (73.1348)  Acc@5: 93.7500 (94.8298)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:08  Loss: 0.9546 (1.0596)  Acc@1: 75.0000 (73.3209)  Acc@5: 93.7500 (94.8383)  time: 0.2146  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:06  Loss: 0.9185 (1.0571)  Acc@1: 75.0000 (73.4893)  Acc@5: 93.7500 (94.8460)  time: 0.2147  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:03  Loss: 0.8984 (1.0621)  Acc@1: 75.0000 (73.3880)  Acc@5: 93.7500 (94.8247)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:01  Loss: 0.9028 (1.0577)  Acc@1: 75.0000 (73.3766)  Acc@5: 93.7500 (94.8052)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:04:59  Loss: 1.0219 (1.0566)  Acc@1: 68.7500 (73.3921)  Acc@5: 93.7500 (94.7614)  time: 0.2144  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:04:57  Loss: 1.0613 (1.0634)  Acc@1: 68.7500 (73.2819)  Acc@5: 93.7500 (94.6713)  time: 0.2149  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:54  Loss: 1.0604 (1.0614)  Acc@1: 75.0000 (73.3477)  Acc@5: 93.7500 (94.6600)  time: 0.2143  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:52  Loss: 0.9152 (1.0536)  Acc@1: 75.0000 (73.5240)  Acc@5: 93.7500 (94.7186)  time: 0.2142  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:50  Loss: 0.9751 (1.0573)  Acc@1: 75.0000 (73.4875)  Acc@5: 93.7500 (94.6397)  time: 0.2147  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:48  Loss: 1.0099 (1.0542)  Acc@1: 75.0000 (73.6254)  Acc@5: 93.7500 (94.6950)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:45  Loss: 0.9287 (1.0539)  Acc@1: 75.0000 (73.6088)  Acc@5: 93.7500 (94.6221)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:43  Loss: 1.0039 (1.0540)  Acc@1: 75.0000 (73.5932)  Acc@5: 93.7500 (94.7146)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:41  Loss: 1.0039 (1.0511)  Acc@1: 75.0000 (73.6565)  Acc@5: 100.0000 (94.8014)  time: 0.2151  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:39  Loss: 0.8567 (1.0492)  Acc@1: 75.0000 (73.6594)  Acc@5: 100.0000 (94.8263)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:37  Loss: 0.8761 (1.0498)  Acc@1: 75.0000 (73.7170)  Acc@5: 100.0000 (94.8314)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:35  Loss: 0.9887 (1.0510)  Acc@1: 75.0000 (73.7179)  Acc@5: 93.7500 (94.7115)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:32  Loss: 0.9227 (1.0491)  Acc@1: 75.0000 (73.7015)  Acc@5: 93.7500 (94.7368)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:30  Loss: 0.9264 (1.0492)  Acc@1: 75.0000 (73.6860)  Acc@5: 100.0000 (94.7608)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:28  Loss: 0.9912 (1.0485)  Acc@1: 75.0000 (73.6713)  Acc@5: 100.0000 (94.8163)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:26  Loss: 0.9912 (1.0488)  Acc@1: 75.0000 (73.5934)  Acc@5: 100.0000 (94.8370)  time: 0.2154  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:24  Loss: 1.0478 (1.0487)  Acc@1: 68.7500 (73.6128)  Acc@5: 93.7500 (94.8410)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:22  Loss: 0.9172 (1.0473)  Acc@1: 75.0000 (73.7378)  Acc@5: 93.7500 (94.7993)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:19  Loss: 0.9573 (1.0467)  Acc@1: 75.0000 (73.7827)  Acc@5: 93.7500 (94.8486)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:17  Loss: 0.9255 (1.0438)  Acc@1: 75.0000 (73.8544)  Acc@5: 100.0000 (94.8666)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:15  Loss: 0.9284 (1.0438)  Acc@1: 75.0000 (73.8095)  Acc@5: 100.0000 (94.9263)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:13  Loss: 1.1257 (1.0472)  Acc@1: 68.7500 (73.7251)  Acc@5: 100.0000 (94.9002)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:11  Loss: 1.0982 (1.0481)  Acc@1: 68.7500 (73.6849)  Acc@5: 93.7500 (94.9295)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:08  Loss: 0.9511 (1.0455)  Acc@1: 75.0000 (73.7128)  Acc@5: 93.7500 (94.9575)  time: 0.2141  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:06  Loss: 1.0606 (1.0495)  Acc@1: 68.7500 (73.6097)  Acc@5: 93.7500 (94.9324)  time: 0.2141  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:04  Loss: 1.0606 (1.0492)  Acc@1: 75.0000 (73.5616)  Acc@5: 93.7500 (94.9593)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:02  Loss: 0.9869 (1.0507)  Acc@1: 75.0000 (73.5030)  Acc@5: 93.7500 (94.9351)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:00  Loss: 1.1158 (1.0569)  Acc@1: 68.7500 (73.4344)  Acc@5: 93.7500 (94.8875)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:03:58  Loss: 1.2326 (1.0641)  Acc@1: 68.7500 (73.3565)  Acc@5: 93.7500 (94.8417)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:55  Loss: 1.0172 (1.0594)  Acc@1: 75.0000 (73.5169)  Acc@5: 100.0000 (94.8917)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:53  Loss: 0.9589 (1.0586)  Acc@1: 81.2500 (73.5444)  Acc@5: 93.7500 (94.8822)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:51  Loss: 1.1249 (1.0606)  Acc@1: 68.7500 (73.5254)  Acc@5: 93.7500 (94.8503)  time: 0.2151  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:49  Loss: 1.1640 (1.0621)  Acc@1: 68.7500 (73.4514)  Acc@5: 93.7500 (94.8418)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:47  Loss: 1.0491 (1.0594)  Acc@1: 75.0000 (73.5223)  Acc@5: 93.7500 (94.8555)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:45  Loss: 0.9663 (1.0607)  Acc@1: 75.0000 (73.4617)  Acc@5: 93.7500 (94.8903)  time: 0.2151  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:42  Loss: 0.9704 (1.0585)  Acc@1: 75.0000 (73.5195)  Acc@5: 100.0000 (94.9556)  time: 0.2144  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:40  Loss: 0.9833 (1.0617)  Acc@1: 75.0000 (73.4297)  Acc@5: 100.0000 (94.9355)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:38  Loss: 1.1538 (1.0603)  Acc@1: 75.0000 (73.5168)  Acc@5: 93.7500 (94.9264)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:36  Loss: 0.9239 (1.0609)  Acc@1: 75.0000 (73.5407)  Acc@5: 93.7500 (94.8973)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:34  Loss: 0.9622 (1.0625)  Acc@1: 75.0000 (73.4945)  Acc@5: 93.7500 (94.8494)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:32  Loss: 0.9597 (1.0643)  Acc@1: 68.7500 (73.4497)  Acc@5: 93.7500 (94.7543)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:29  Loss: 0.9589 (1.0629)  Acc@1: 68.7500 (73.4735)  Acc@5: 100.0000 (94.7965)  time: 0.2141  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:27  Loss: 0.8446 (1.0602)  Acc@1: 75.0000 (73.5628)  Acc@5: 100.0000 (94.8090)  time: 0.2145  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:25  Loss: 0.9878 (1.0603)  Acc@1: 75.0000 (73.5283)  Acc@5: 93.7500 (94.7839)  time: 0.2148  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:23  Loss: 0.9904 (1.0596)  Acc@1: 75.0000 (73.5775)  Acc@5: 93.7500 (94.7595)  time: 0.2157  data: 0.0019  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:21  Loss: 0.9904 (1.0578)  Acc@1: 81.2500 (73.6342)  Acc@5: 100.0000 (94.7992)  time: 0.2154  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:19  Loss: 1.0164 (1.0572)  Acc@1: 81.2500 (73.7340)  Acc@5: 100.0000 (94.8110)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:17  Loss: 0.9293 (1.0553)  Acc@1: 75.0000 (73.7781)  Acc@5: 100.0000 (94.8576)  time: 0.2141  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:14  Loss: 0.9100 (1.0534)  Acc@1: 75.0000 (73.8211)  Acc@5: 100.0000 (94.8682)  time: 0.2144  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:12  Loss: 0.9372 (1.0540)  Acc@1: 75.0000 (73.7859)  Acc@5: 93.7500 (94.8529)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:10  Loss: 1.0651 (1.0545)  Acc@1: 75.0000 (73.8276)  Acc@5: 93.7500 (94.8549)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:08  Loss: 1.0570 (1.0537)  Acc@1: 75.0000 (73.8931)  Acc@5: 93.7500 (94.8818)  time: 0.2145  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:06  Loss: 1.0590 (1.0563)  Acc@1: 75.0000 (73.8338)  Acc@5: 93.7500 (94.8341)  time: 0.2146  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:04  Loss: 0.8837 (1.0526)  Acc@1: 81.2500 (73.9462)  Acc@5: 93.7500 (94.8606)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:01  Loss: 0.8258 (1.0517)  Acc@1: 81.2500 (73.9437)  Acc@5: 100.0000 (94.8464)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:02:59  Loss: 0.8665 (1.0527)  Acc@1: 75.0000 (73.9412)  Acc@5: 93.7500 (94.8325)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:57  Loss: 0.9971 (1.0525)  Acc@1: 75.0000 (73.9154)  Acc@5: 93.7500 (94.8580)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:55  Loss: 0.8960 (1.0514)  Acc@1: 75.0000 (73.9827)  Acc@5: 100.0000 (94.8674)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:53  Loss: 0.8485 (1.0507)  Acc@1: 81.2500 (73.9951)  Acc@5: 100.0000 (94.8843)  time: 0.2152  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:51  Loss: 0.8567 (1.0501)  Acc@1: 81.2500 (74.0298)  Acc@5: 100.0000 (94.8857)  time: 0.2151  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 0.7398 (1.0473)  Acc@1: 81.2500 (74.1082)  Acc@5: 100.0000 (94.9316)  time: 0.2157  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:46  Loss: 0.8035 (1.0473)  Acc@1: 81.2500 (74.1113)  Acc@5: 100.0000 (94.9398)  time: 0.2165  data: 0.0017  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:44  Loss: 0.8035 (1.0455)  Acc@1: 75.0000 (74.1652)  Acc@5: 100.0000 (94.9695)  time: 0.2162  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:42  Loss: 0.7762 (1.0443)  Acc@1: 81.2500 (74.1963)  Acc@5: 100.0000 (94.9842)  time: 0.2141  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:40  Loss: 1.0975 (1.0469)  Acc@1: 75.0000 (74.1132)  Acc@5: 93.7500 (94.9560)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:38  Loss: 1.2511 (1.0493)  Acc@1: 68.7500 (74.0530)  Acc@5: 93.7500 (94.9425)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:36  Loss: 1.0577 (1.0496)  Acc@1: 68.7500 (74.0635)  Acc@5: 93.7500 (94.9362)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 1.0295 (1.0502)  Acc@1: 75.0000 (74.0944)  Acc@5: 93.7500 (94.9026)  time: 0.2153  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:31  Loss: 0.9585 (1.0499)  Acc@1: 75.0000 (74.1110)  Acc@5: 93.7500 (94.8969)  time: 0.2150  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:29  Loss: 1.0721 (1.0506)  Acc@1: 68.7500 (74.0602)  Acc@5: 93.7500 (94.9047)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:27  Loss: 1.0721 (1.0496)  Acc@1: 68.7500 (74.0768)  Acc@5: 93.7500 (94.9190)  time: 0.2146  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:25  Loss: 1.1343 (1.0503)  Acc@1: 68.7500 (74.0405)  Acc@5: 93.7500 (94.9067)  time: 0.2143  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:23  Loss: 1.0748 (1.0488)  Acc@1: 75.0000 (74.0700)  Acc@5: 100.0000 (94.9272)  time: 0.2147  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 0.8508 (1.0484)  Acc@1: 75.0000 (74.0924)  Acc@5: 100.0000 (94.9343)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 1.0708 (1.0489)  Acc@1: 68.7500 (74.0635)  Acc@5: 93.7500 (94.9159)  time: 0.2163  data: 0.0019  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:16  Loss: 1.1975 (1.0514)  Acc@1: 68.7500 (74.0225)  Acc@5: 93.7500 (94.9041)  time: 0.2165  data: 0.0019  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:14  Loss: 1.1756 (1.0516)  Acc@1: 68.7500 (74.0385)  Acc@5: 93.7500 (94.8989)  time: 0.2152  data: 0.0010  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:12  Loss: 1.0611 (1.0518)  Acc@1: 75.0000 (74.0542)  Acc@5: 93.7500 (94.8937)  time: 0.2153  data: 0.0010  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 1.1001 (1.0515)  Acc@1: 75.0000 (74.0695)  Acc@5: 93.7500 (94.9008)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 0.8757 (1.0489)  Acc@1: 75.0000 (74.1210)  Acc@5: 100.0000 (94.9260)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.7622 (1.0479)  Acc@1: 81.2500 (74.1655)  Acc@5: 100.0000 (94.9328)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:03  Loss: 0.9041 (1.0463)  Acc@1: 75.0000 (74.1912)  Acc@5: 93.7500 (94.9453)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:01  Loss: 0.9845 (1.0468)  Acc@1: 75.0000 (74.1576)  Acc@5: 93.7500 (94.9281)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:01:59  Loss: 1.0426 (1.0474)  Acc@1: 68.7500 (74.1655)  Acc@5: 93.7500 (94.9171)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:57  Loss: 1.0426 (1.0481)  Acc@1: 75.0000 (74.1559)  Acc@5: 100.0000 (94.9295)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 1.1122 (1.0486)  Acc@1: 75.0000 (74.1693)  Acc@5: 93.7500 (94.9129)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 0.9693 (1.0465)  Acc@1: 75.0000 (74.2280)  Acc@5: 100.0000 (94.9421)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 0.9613 (1.0472)  Acc@1: 75.0000 (74.2180)  Acc@5: 100.0000 (94.9426)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:48  Loss: 1.0428 (1.0484)  Acc@1: 75.0000 (74.1971)  Acc@5: 93.7500 (94.9264)  time: 0.2161  data: 0.0003  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:46  Loss: 1.0502 (1.0482)  Acc@1: 75.0000 (74.2098)  Acc@5: 93.7500 (94.9381)  time: 0.2172  data: 0.0006  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:44  Loss: 1.1309 (1.0494)  Acc@1: 75.0000 (74.1893)  Acc@5: 93.7500 (94.9277)  time: 0.2165  data: 0.0006  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 1.2159 (1.0501)  Acc@1: 75.0000 (74.1692)  Acc@5: 93.7500 (94.9283)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 0.9914 (1.0486)  Acc@1: 75.0000 (74.2194)  Acc@5: 93.7500 (94.9397)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 0.9770 (1.0481)  Acc@1: 75.0000 (74.2314)  Acc@5: 100.0000 (94.9562)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 0.9772 (1.0486)  Acc@1: 75.0000 (74.2273)  Acc@5: 100.0000 (94.9672)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:33  Loss: 1.1205 (1.0490)  Acc@1: 75.0000 (74.2233)  Acc@5: 100.0000 (94.9780)  time: 0.2146  data: 0.0002  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:31  Loss: 1.0652 (1.0489)  Acc@1: 75.0000 (74.2298)  Acc@5: 100.0000 (94.9729)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 0.9129 (1.0493)  Acc@1: 75.0000 (74.1897)  Acc@5: 100.0000 (94.9525)  time: 0.2157  data: 0.0008  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 0.9129 (1.0484)  Acc@1: 75.0000 (74.1912)  Acc@5: 93.7500 (94.9478)  time: 0.2169  data: 0.0016  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 1.0988 (1.0490)  Acc@1: 68.7500 (74.1267)  Acc@5: 100.0000 (94.9533)  time: 0.2159  data: 0.0010  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 1.0506 (1.0486)  Acc@1: 68.7500 (74.1287)  Acc@5: 100.0000 (94.9537)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.1066 (1.0491)  Acc@1: 68.7500 (74.0807)  Acc@5: 93.7500 (94.9640)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:18  Loss: 1.1066 (1.0492)  Acc@1: 75.0000 (74.1029)  Acc@5: 93.7500 (94.9643)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:16  Loss: 0.9301 (1.0493)  Acc@1: 75.0000 (74.1149)  Acc@5: 93.7500 (94.9695)  time: 0.2156  data: 0.0007  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 0.8497 (1.0475)  Acc@1: 81.2500 (74.1559)  Acc@5: 100.0000 (94.9893)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 0.9956 (1.0478)  Acc@1: 75.0000 (74.1383)  Acc@5: 93.7500 (94.9845)  time: 0.2160  data: 0.0009  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.0086 (1.0463)  Acc@1: 75.0000 (74.2025)  Acc@5: 93.7500 (94.9990)  time: 0.2158  data: 0.0011  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.7363 (1.0449)  Acc@1: 81.2500 (74.2325)  Acc@5: 100.0000 (95.0086)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.7165 (1.0434)  Acc@1: 81.2500 (74.2808)  Acc@5: 100.0000 (95.0227)  time: 0.2158  data: 0.0006  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:03  Loss: 0.9619 (1.0438)  Acc@1: 75.0000 (74.2628)  Acc@5: 100.0000 (95.0131)  time: 0.2163  data: 0.0006  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 1.0622 (1.0453)  Acc@1: 75.0000 (74.2356)  Acc@5: 93.7500 (94.9991)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 0.9785 (1.0447)  Acc@1: 75.0000 (74.2459)  Acc@5: 93.7500 (95.0037)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.9385 (1.0442)  Acc@1: 75.0000 (74.2469)  Acc@5: 93.7500 (95.0083)  time: 0.2184  data: 0.0008  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.9432 (1.0440)  Acc@1: 75.0000 (74.2524)  Acc@5: 93.7500 (95.0128)  time: 0.2163  data: 0.0006  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 0.9991 (1.0443)  Acc@1: 75.0000 (74.2352)  Acc@5: 93.7500 (94.9991)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:50  Loss: 1.1043 (1.0438)  Acc@1: 75.0000 (74.2407)  Acc@5: 93.7500 (95.0081)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 1.0270 (1.0439)  Acc@1: 75.0000 (74.2282)  Acc@5: 93.7500 (94.9991)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 0.9023 (1.0434)  Acc@1: 75.0000 (74.2470)  Acc@5: 93.7500 (95.0124)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.9334 (1.0429)  Acc@1: 75.0000 (74.2479)  Acc@5: 100.0000 (95.0211)  time: 0.2154  data: 0.0006  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.1115 (1.0448)  Acc@1: 68.7500 (74.2182)  Acc@5: 93.7500 (94.9773)  time: 0.2150  data: 0.0006  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1136 (1.0444)  Acc@1: 68.7500 (74.2280)  Acc@5: 93.7500 (94.9818)  time: 0.2144  data: 0.0008  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.1423 (1.0459)  Acc@1: 68.7500 (74.1601)  Acc@5: 93.7500 (94.9819)  time: 0.2149  data: 0.0010  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:35  Loss: 1.1705 (1.0460)  Acc@1: 68.7500 (74.1359)  Acc@5: 93.7500 (94.9778)  time: 0.2153  data: 0.0006  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 0.9822 (1.0463)  Acc@1: 68.7500 (74.1162)  Acc@5: 100.0000 (94.9864)  time: 0.2152  data: 0.0006  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.0663 (1.0471)  Acc@1: 75.0000 (74.1053)  Acc@5: 93.7500 (94.9654)  time: 0.2148  data: 0.0005  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.0591 (1.0471)  Acc@1: 75.0000 (74.0988)  Acc@5: 93.7500 (94.9698)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.9265 (1.0473)  Acc@1: 75.0000 (74.0798)  Acc@5: 100.0000 (94.9700)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.8794 (1.0475)  Acc@1: 75.0000 (74.0900)  Acc@5: 93.7500 (94.9661)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.8794 (1.0460)  Acc@1: 75.0000 (74.1248)  Acc@5: 100.0000 (94.9786)  time: 0.2158  data: 0.0012  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.8587 (1.0457)  Acc@1: 75.0000 (74.1223)  Acc@5: 100.0000 (94.9788)  time: 0.2161  data: 0.0012  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.8864 (1.0450)  Acc@1: 75.0000 (74.1402)  Acc@5: 93.7500 (94.9789)  time: 0.2151  data: 0.0005  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.9245 (1.0449)  Acc@1: 75.0000 (74.1497)  Acc@5: 93.7500 (94.9831)  time: 0.2150  data: 0.0005  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.9245 (1.0442)  Acc@1: 75.0000 (74.1752)  Acc@5: 93.7500 (94.9912)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.8945 (1.0441)  Acc@1: 81.2500 (74.2043)  Acc@5: 93.7500 (94.9793)  time: 0.2141  data: 0.0005  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.9772 (1.0438)  Acc@1: 75.0000 (74.2291)  Acc@5: 93.7500 (94.9755)  time: 0.2147  data: 0.0007  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 0.8936 (1.0434)  Acc@1: 75.0000 (74.2418)  Acc@5: 93.7500 (94.9796)  time: 0.2143  data: 0.0005  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 0.9818 (1.0446)  Acc@1: 75.0000 (74.2114)  Acc@5: 93.7500 (94.9602)  time: 0.2145  data: 0.0007  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.0247 (1.0439)  Acc@1: 68.7500 (74.2396)  Acc@5: 93.7500 (94.9643)  time: 0.2150  data: 0.0011  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.0247 (1.0434)  Acc@1: 68.7500 (74.2366)  Acc@5: 93.7500 (94.9645)  time: 0.2141  data: 0.0007  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.0173 (1.0427)  Acc@1: 68.7500 (74.2663)  Acc@5: 93.7500 (94.9600)  time: 0.2146  data: 0.0002  max mem: 2500
Test: [Task 1] Total time: 0:05:50 (0.2152 s / it)
* Acc@1 74.266 Acc@5 94.960 loss 1.043
Test: [Task 2]  [  0/625]  eta: 0:04:50  Loss: 0.1485 (0.1485)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4650  data: 0.2508  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:26  Loss: 0.1839 (0.2287)  Acc@1: 93.7500 (94.3182)  Acc@5: 100.0000 (99.4318)  time: 0.2379  data: 0.0244  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:17  Loss: 0.2099 (0.2467)  Acc@1: 93.7500 (94.0476)  Acc@5: 100.0000 (99.7024)  time: 0.2148  data: 0.0010  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:13  Loss: 0.2214 (0.2812)  Acc@1: 93.7500 (92.5403)  Acc@5: 100.0000 (99.7984)  time: 0.2158  data: 0.0015  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:09  Loss: 0.3002 (0.2858)  Acc@1: 87.5000 (92.2256)  Acc@5: 100.0000 (99.8476)  time: 0.2162  data: 0.0016  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:06  Loss: 0.3261 (0.3001)  Acc@1: 87.5000 (91.7892)  Acc@5: 100.0000 (99.7549)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:03  Loss: 0.2893 (0.3019)  Acc@1: 93.7500 (91.7008)  Acc@5: 100.0000 (99.6926)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:01  Loss: 0.2623 (0.2994)  Acc@1: 93.7500 (91.7254)  Acc@5: 100.0000 (99.6479)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:01:58  Loss: 0.2668 (0.3012)  Acc@1: 87.5000 (91.5895)  Acc@5: 100.0000 (99.5370)  time: 0.2142  data: 0.0006  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:01:56  Loss: 0.2694 (0.2973)  Acc@1: 93.7500 (91.8956)  Acc@5: 100.0000 (99.5879)  time: 0.2152  data: 0.0006  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:54  Loss: 0.2694 (0.2938)  Acc@1: 93.7500 (92.2030)  Acc@5: 100.0000 (99.5668)  time: 0.2154  data: 0.0005  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:51  Loss: 0.2209 (0.2935)  Acc@1: 93.7500 (92.2860)  Acc@5: 100.0000 (99.5495)  time: 0.2150  data: 0.0006  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:49  Loss: 0.2427 (0.2924)  Acc@1: 93.7500 (92.3037)  Acc@5: 100.0000 (99.5351)  time: 0.2161  data: 0.0013  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:47  Loss: 0.2427 (0.2883)  Acc@1: 93.7500 (92.4618)  Acc@5: 100.0000 (99.5706)  time: 0.2162  data: 0.0017  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:45  Loss: 0.2007 (0.2909)  Acc@1: 93.7500 (92.3759)  Acc@5: 100.0000 (99.5567)  time: 0.2145  data: 0.0009  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:42  Loss: 0.2936 (0.2959)  Acc@1: 87.5000 (92.1358)  Acc@5: 100.0000 (99.5861)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:40  Loss: 0.3088 (0.2985)  Acc@1: 87.5000 (92.0419)  Acc@5: 100.0000 (99.5730)  time: 0.2145  data: 0.0005  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:38  Loss: 0.2355 (0.2980)  Acc@1: 93.7500 (92.0322)  Acc@5: 100.0000 (99.5249)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:36  Loss: 0.2712 (0.2987)  Acc@1: 93.7500 (92.0235)  Acc@5: 100.0000 (99.5511)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.3082 (0.3018)  Acc@1: 93.7500 (91.9830)  Acc@5: 100.0000 (99.5092)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:31  Loss: 0.2798 (0.3006)  Acc@1: 93.7500 (92.0087)  Acc@5: 100.0000 (99.5336)  time: 0.2150  data: 0.0005  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:29  Loss: 0.2472 (0.3012)  Acc@1: 93.7500 (91.8839)  Acc@5: 100.0000 (99.5557)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:27  Loss: 0.1901 (0.2987)  Acc@1: 93.7500 (92.0814)  Acc@5: 100.0000 (99.5758)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 0.2123 (0.2965)  Acc@1: 93.7500 (92.2078)  Acc@5: 100.0000 (99.5942)  time: 0.2156  data: 0.0008  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.2700 (0.2965)  Acc@1: 93.7500 (92.2199)  Acc@5: 100.0000 (99.6110)  time: 0.2163  data: 0.0015  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:20  Loss: 0.3116 (0.2987)  Acc@1: 93.7500 (92.1315)  Acc@5: 100.0000 (99.5767)  time: 0.2150  data: 0.0010  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:18  Loss: 0.3302 (0.2999)  Acc@1: 87.5000 (92.0498)  Acc@5: 100.0000 (99.5690)  time: 0.2153  data: 0.0011  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:16  Loss: 0.3069 (0.2996)  Acc@1: 87.5000 (92.0895)  Acc@5: 100.0000 (99.5618)  time: 0.2155  data: 0.0010  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 0.2823 (0.3022)  Acc@1: 87.5000 (91.9929)  Acc@5: 100.0000 (99.5107)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.2761 (0.3033)  Acc@1: 87.5000 (91.9244)  Acc@5: 100.0000 (99.5275)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.2761 (0.3039)  Acc@1: 93.7500 (91.9020)  Acc@5: 100.0000 (99.5224)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:07  Loss: 0.3761 (0.3046)  Acc@1: 87.5000 (91.8408)  Acc@5: 100.0000 (99.5177)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:05  Loss: 0.1481 (0.2982)  Acc@1: 93.7500 (92.0171)  Acc@5: 100.0000 (99.5327)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 0.1093 (0.2940)  Acc@1: 100.0000 (92.1828)  Acc@5: 100.0000 (99.5468)  time: 0.2148  data: 0.0005  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.0921 (0.2874)  Acc@1: 100.0000 (92.3937)  Acc@5: 100.0000 (99.5601)  time: 0.2155  data: 0.0006  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.0849 (0.2846)  Acc@1: 100.0000 (92.4145)  Acc@5: 100.0000 (99.5726)  time: 0.2159  data: 0.0009  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.2356 (0.2855)  Acc@1: 87.5000 (92.3650)  Acc@5: 100.0000 (99.5845)  time: 0.2160  data: 0.0010  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:54  Loss: 0.2336 (0.2821)  Acc@1: 93.7500 (92.4865)  Acc@5: 100.0000 (99.5957)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:52  Loss: 0.2877 (0.2879)  Acc@1: 87.5000 (92.2408)  Acc@5: 100.0000 (99.5407)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 0.3361 (0.2879)  Acc@1: 87.5000 (92.2634)  Acc@5: 100.0000 (99.4885)  time: 0.2155  data: 0.0007  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.1125 (0.2838)  Acc@1: 93.7500 (92.3940)  Acc@5: 100.0000 (99.5012)  time: 0.2151  data: 0.0007  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0931 (0.2828)  Acc@1: 100.0000 (92.4878)  Acc@5: 100.0000 (99.4830)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.1253 (0.2822)  Acc@1: 100.0000 (92.4881)  Acc@5: 100.0000 (99.4952)  time: 0.2161  data: 0.0010  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.2016 (0.2802)  Acc@1: 93.7500 (92.5464)  Acc@5: 100.0000 (99.5070)  time: 0.2159  data: 0.0009  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:39  Loss: 0.1188 (0.2766)  Acc@1: 93.7500 (92.6020)  Acc@5: 100.0000 (99.5181)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.0941 (0.2729)  Acc@1: 93.7500 (92.6968)  Acc@5: 100.0000 (99.5288)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.1121 (0.2697)  Acc@1: 100.0000 (92.8281)  Acc@5: 100.0000 (99.5390)  time: 0.2162  data: 0.0006  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1155 (0.2671)  Acc@1: 100.0000 (92.9140)  Acc@5: 100.0000 (99.5488)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1402 (0.2657)  Acc@1: 100.0000 (92.9834)  Acc@5: 100.0000 (99.5582)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1422 (0.2636)  Acc@1: 100.0000 (93.0754)  Acc@5: 100.0000 (99.5672)  time: 0.2163  data: 0.0007  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:26  Loss: 0.1439 (0.2619)  Acc@1: 100.0000 (93.1262)  Acc@5: 100.0000 (99.5758)  time: 0.2158  data: 0.0011  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.1615 (0.2647)  Acc@1: 93.7500 (92.9795)  Acc@5: 100.0000 (99.5841)  time: 0.2155  data: 0.0008  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.2422 (0.2643)  Acc@1: 93.7500 (92.9942)  Acc@5: 100.0000 (99.5921)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1815 (0.2622)  Acc@1: 93.7500 (93.0556)  Acc@5: 100.0000 (99.5998)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1038 (0.2606)  Acc@1: 100.0000 (93.1030)  Acc@5: 100.0000 (99.6072)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0842 (0.2572)  Acc@1: 100.0000 (93.2055)  Acc@5: 100.0000 (99.6143)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0542 (0.2535)  Acc@1: 100.0000 (93.3266)  Acc@5: 100.0000 (99.6212)  time: 0.2164  data: 0.0008  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0568 (0.2523)  Acc@1: 100.0000 (93.3669)  Acc@5: 100.0000 (99.6278)  time: 0.2157  data: 0.0008  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.0864 (0.2496)  Acc@1: 100.0000 (93.4488)  Acc@5: 100.0000 (99.6343)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1128 (0.2486)  Acc@1: 93.7500 (93.4327)  Acc@5: 100.0000 (99.6299)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1881 (0.2484)  Acc@1: 93.7500 (93.4276)  Acc@5: 100.0000 (99.6360)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2574 (0.2505)  Acc@1: 93.7500 (93.4124)  Acc@5: 100.0000 (99.6215)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.2911 (0.2508)  Acc@1: 93.7500 (93.4179)  Acc@5: 100.0000 (99.6276)  time: 0.2148  data: 0.0002  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2291 (0.2504)  Acc@1: 93.7500 (93.4200)  Acc@5: 100.0000 (99.6300)  time: 0.2148  data: 0.0002  max mem: 2500
Test: [Task 2] Total time: 0:02:15 (0.2160 s / it)
* Acc@1 93.420 Acc@5 99.630 loss 0.250
{0: {0: 25002, 1: 25002, 2: 25002, 3: 25002, 4: 25, 5: 25, 6: 25, 7: 25, 8: 146, 9: 146, 10: 146, 11: 146, 12: 67, 13: 67, 14: 67, 15: 67, 16: 792, 17: 792, 18: 792, 19: 792}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 9896, 5: 9896, 6: 9896, 7: 9896, 8: 0, 9: 0, 10: 0, 11: 0, 12: 104, 13: 104, 14: 104, 15: 104, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task2]	Acc@1: 83.8431	Acc@5: 97.2950	Loss: 0.6465	Forgetting: 11.9007	Backward: -11.9007
Train: Epoch[1/5]  [   0/3125]  eta: 0:36:01  Lr: 0.001875  Loss: 2.2964  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  time: 0.6918  data: 0.3306  max mem: 2500
Train: Epoch[1/5]  [  10/3125]  eta: 0:19:31  Lr: 0.001875  Loss: 2.1806  Acc@1: 18.7500 (23.8636)  Acc@5: 68.7500 (67.6136)  time: 0.3761  data: 0.0307  max mem: 2501
Train: Epoch[1/5]  [  20/3125]  eta: 0:18:39  Lr: 0.001875  Loss: 1.9853  Acc@1: 37.5000 (35.4167)  Acc@5: 81.2500 (77.0833)  time: 0.3441  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [  30/3125]  eta: 0:18:19  Lr: 0.001875  Loss: 1.7617  Acc@1: 56.2500 (44.3548)  Acc@5: 87.5000 (80.8468)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [  40/3125]  eta: 0:18:07  Lr: 0.001875  Loss: 1.5195  Acc@1: 68.7500 (50.1524)  Acc@5: 93.7500 (83.8415)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [  50/3125]  eta: 0:17:58  Lr: 0.001875  Loss: 1.1965  Acc@1: 68.7500 (54.1667)  Acc@5: 100.0000 (86.5196)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [  60/3125]  eta: 0:17:51  Lr: 0.001875  Loss: 1.5651  Acc@1: 68.7500 (56.2500)  Acc@5: 93.7500 (87.2951)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [  70/3125]  eta: 0:17:45  Lr: 0.001875  Loss: 1.4166  Acc@1: 68.7500 (58.2746)  Acc@5: 93.7500 (88.3803)  time: 0.3436  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [  80/3125]  eta: 0:17:41  Lr: 0.001875  Loss: 0.9777  Acc@1: 68.7500 (59.4136)  Acc@5: 93.7500 (89.1975)  time: 0.3455  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [  90/3125]  eta: 0:17:37  Lr: 0.001875  Loss: 0.9377  Acc@1: 68.7500 (60.4396)  Acc@5: 93.7500 (89.6291)  time: 0.3472  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 100/3125]  eta: 0:17:32  Lr: 0.001875  Loss: 0.9517  Acc@1: 75.0000 (62.3762)  Acc@5: 93.7500 (90.2228)  time: 0.3465  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 110/3125]  eta: 0:17:28  Lr: 0.001875  Loss: 1.1864  Acc@1: 75.0000 (63.1757)  Acc@5: 93.7500 (90.7658)  time: 0.3447  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 120/3125]  eta: 0:17:24  Lr: 0.001875  Loss: 0.8601  Acc@1: 75.0000 (63.9463)  Acc@5: 93.7500 (91.1157)  time: 0.3441  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 130/3125]  eta: 0:17:19  Lr: 0.001875  Loss: 1.1645  Acc@1: 68.7500 (64.2176)  Acc@5: 93.7500 (91.4599)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 140/3125]  eta: 0:17:15  Lr: 0.001875  Loss: 0.9279  Acc@1: 68.7500 (64.9379)  Acc@5: 100.0000 (91.7996)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 150/3125]  eta: 0:17:11  Lr: 0.001875  Loss: 0.4227  Acc@1: 75.0000 (65.6457)  Acc@5: 100.0000 (92.0944)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 160/3125]  eta: 0:17:07  Lr: 0.001875  Loss: 0.5643  Acc@1: 75.0000 (66.3043)  Acc@5: 93.7500 (92.1584)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 170/3125]  eta: 0:17:03  Lr: 0.001875  Loss: 0.6917  Acc@1: 75.0000 (67.0687)  Acc@5: 93.7500 (92.4342)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 180/3125]  eta: 0:16:59  Lr: 0.001875  Loss: 1.0027  Acc@1: 75.0000 (67.7486)  Acc@5: 93.7500 (92.6450)  time: 0.3436  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 190/3125]  eta: 0:16:55  Lr: 0.001875  Loss: 0.6434  Acc@1: 75.0000 (67.8338)  Acc@5: 93.7500 (92.7683)  time: 0.3434  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 200/3125]  eta: 0:16:52  Lr: 0.001875  Loss: 0.7706  Acc@1: 75.0000 (68.5634)  Acc@5: 100.0000 (93.0348)  time: 0.3445  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [ 210/3125]  eta: 0:16:48  Lr: 0.001875  Loss: 0.4517  Acc@1: 81.2500 (69.1647)  Acc@5: 100.0000 (93.3353)  time: 0.3446  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 220/3125]  eta: 0:16:44  Lr: 0.001875  Loss: 0.7973  Acc@1: 81.2500 (69.5701)  Acc@5: 100.0000 (93.4955)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 230/3125]  eta: 0:16:41  Lr: 0.001875  Loss: 0.5210  Acc@1: 75.0000 (69.8323)  Acc@5: 100.0000 (93.6418)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 240/3125]  eta: 0:16:37  Lr: 0.001875  Loss: 0.5693  Acc@1: 81.2500 (70.3060)  Acc@5: 100.0000 (93.8537)  time: 0.3454  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 250/3125]  eta: 0:16:35  Lr: 0.001875  Loss: 0.8031  Acc@1: 81.2500 (70.4183)  Acc@5: 100.0000 (93.9990)  time: 0.3488  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 260/3125]  eta: 0:16:31  Lr: 0.001875  Loss: 0.5419  Acc@1: 75.0000 (70.6418)  Acc@5: 100.0000 (94.0374)  time: 0.3477  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 270/3125]  eta: 0:16:28  Lr: 0.001875  Loss: 0.9128  Acc@1: 68.7500 (70.7103)  Acc@5: 93.7500 (94.0959)  time: 0.3459  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 280/3125]  eta: 0:16:24  Lr: 0.001875  Loss: 0.8626  Acc@1: 68.7500 (70.7073)  Acc@5: 93.7500 (94.1726)  time: 0.3460  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 290/3125]  eta: 0:16:20  Lr: 0.001875  Loss: 0.5768  Acc@1: 75.0000 (70.8333)  Acc@5: 100.0000 (94.2869)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 300/3125]  eta: 0:16:17  Lr: 0.001875  Loss: 0.6519  Acc@1: 68.7500 (70.8472)  Acc@5: 100.0000 (94.3106)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 310/3125]  eta: 0:16:13  Lr: 0.001875  Loss: 1.0293  Acc@1: 75.0000 (71.1013)  Acc@5: 100.0000 (94.4132)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 320/3125]  eta: 0:16:10  Lr: 0.001875  Loss: 0.5556  Acc@1: 75.0000 (71.2812)  Acc@5: 100.0000 (94.4704)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 330/3125]  eta: 0:16:06  Lr: 0.001875  Loss: 1.2988  Acc@1: 81.2500 (71.6012)  Acc@5: 100.0000 (94.5808)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 340/3125]  eta: 0:16:02  Lr: 0.001875  Loss: 0.4439  Acc@1: 81.2500 (71.6826)  Acc@5: 100.0000 (94.6114)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 350/3125]  eta: 0:15:59  Lr: 0.001875  Loss: 0.7959  Acc@1: 75.0000 (71.8839)  Acc@5: 100.0000 (94.6759)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 360/3125]  eta: 0:15:55  Lr: 0.001875  Loss: 0.7682  Acc@1: 81.2500 (72.1607)  Acc@5: 100.0000 (94.7022)  time: 0.3448  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 370/3125]  eta: 0:15:52  Lr: 0.001875  Loss: 1.0404  Acc@1: 81.2500 (72.2877)  Acc@5: 93.7500 (94.6765)  time: 0.3443  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 380/3125]  eta: 0:15:48  Lr: 0.001875  Loss: 0.2702  Acc@1: 81.2500 (72.5886)  Acc@5: 93.7500 (94.7343)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 390/3125]  eta: 0:15:45  Lr: 0.001875  Loss: 0.9732  Acc@1: 81.2500 (72.6982)  Acc@5: 93.7500 (94.7251)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 400/3125]  eta: 0:15:41  Lr: 0.001875  Loss: 0.7744  Acc@1: 81.2500 (72.8803)  Acc@5: 93.7500 (94.7475)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 410/3125]  eta: 0:15:38  Lr: 0.001875  Loss: 0.7313  Acc@1: 81.2500 (73.0991)  Acc@5: 100.0000 (94.8145)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 420/3125]  eta: 0:15:34  Lr: 0.001875  Loss: 0.8948  Acc@1: 81.2500 (73.1888)  Acc@5: 100.0000 (94.8931)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 430/3125]  eta: 0:15:30  Lr: 0.001875  Loss: 0.5087  Acc@1: 81.2500 (73.4049)  Acc@5: 100.0000 (94.9681)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 440/3125]  eta: 0:15:27  Lr: 0.001875  Loss: 0.7895  Acc@1: 81.2500 (73.3560)  Acc@5: 100.0000 (94.9688)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 450/3125]  eta: 0:15:23  Lr: 0.001875  Loss: 0.6100  Acc@1: 75.0000 (73.5449)  Acc@5: 100.0000 (95.0527)  time: 0.3444  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 460/3125]  eta: 0:15:20  Lr: 0.001875  Loss: 0.6600  Acc@1: 81.2500 (73.6714)  Acc@5: 100.0000 (95.1057)  time: 0.3442  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 470/3125]  eta: 0:15:16  Lr: 0.001875  Loss: 0.9488  Acc@1: 81.2500 (73.7261)  Acc@5: 100.0000 (95.1831)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 480/3125]  eta: 0:15:13  Lr: 0.001875  Loss: 0.8250  Acc@1: 81.2500 (73.8565)  Acc@5: 100.0000 (95.2183)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 490/3125]  eta: 0:15:09  Lr: 0.001875  Loss: 0.3721  Acc@1: 81.2500 (74.0453)  Acc@5: 100.0000 (95.2775)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 500/3125]  eta: 0:15:06  Lr: 0.001875  Loss: 0.6776  Acc@1: 75.0000 (74.1267)  Acc@5: 100.0000 (95.3468)  time: 0.3434  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 510/3125]  eta: 0:15:02  Lr: 0.001875  Loss: 0.3415  Acc@1: 81.2500 (74.2172)  Acc@5: 100.0000 (95.4134)  time: 0.3440  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 520/3125]  eta: 0:14:59  Lr: 0.001875  Loss: 0.3411  Acc@1: 81.2500 (74.3522)  Acc@5: 100.0000 (95.4774)  time: 0.3444  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 530/3125]  eta: 0:14:55  Lr: 0.001875  Loss: 0.7909  Acc@1: 75.0000 (74.4233)  Acc@5: 100.0000 (95.5038)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 540/3125]  eta: 0:14:52  Lr: 0.001875  Loss: 0.7317  Acc@1: 81.2500 (74.5263)  Acc@5: 100.0000 (95.5522)  time: 0.3440  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 550/3125]  eta: 0:14:48  Lr: 0.001875  Loss: 0.5898  Acc@1: 81.2500 (74.6257)  Acc@5: 100.0000 (95.5649)  time: 0.3453  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 560/3125]  eta: 0:14:45  Lr: 0.001875  Loss: 0.5760  Acc@1: 81.2500 (74.6992)  Acc@5: 100.0000 (95.6105)  time: 0.3455  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 570/3125]  eta: 0:14:41  Lr: 0.001875  Loss: 0.5249  Acc@1: 81.2500 (74.7482)  Acc@5: 100.0000 (95.6655)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 580/3125]  eta: 0:14:38  Lr: 0.001875  Loss: 0.5934  Acc@1: 75.0000 (74.8386)  Acc@5: 100.0000 (95.6863)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 590/3125]  eta: 0:14:34  Lr: 0.001875  Loss: 0.5894  Acc@1: 75.0000 (74.8308)  Acc@5: 100.0000 (95.7064)  time: 0.3439  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 600/3125]  eta: 0:14:31  Lr: 0.001875  Loss: 0.6746  Acc@1: 75.0000 (74.9480)  Acc@5: 93.7500 (95.7155)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 610/3125]  eta: 0:14:27  Lr: 0.001875  Loss: 0.4410  Acc@1: 81.2500 (75.0511)  Acc@5: 100.0000 (95.7447)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 620/3125]  eta: 0:14:24  Lr: 0.001875  Loss: 0.4820  Acc@1: 75.0000 (75.0201)  Acc@5: 100.0000 (95.7830)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 630/3125]  eta: 0:14:20  Lr: 0.001875  Loss: 0.5647  Acc@1: 75.0000 (75.0693)  Acc@5: 100.0000 (95.8399)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 640/3125]  eta: 0:14:17  Lr: 0.001875  Loss: 0.6746  Acc@1: 81.2500 (75.1268)  Acc@5: 100.0000 (95.8658)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 650/3125]  eta: 0:14:13  Lr: 0.001875  Loss: 0.3178  Acc@1: 75.0000 (75.1152)  Acc@5: 100.0000 (95.9005)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 660/3125]  eta: 0:14:10  Lr: 0.001875  Loss: 0.7936  Acc@1: 75.0000 (75.1797)  Acc@5: 100.0000 (95.9247)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 670/3125]  eta: 0:14:06  Lr: 0.001875  Loss: 0.5564  Acc@1: 81.2500 (75.2422)  Acc@5: 100.0000 (95.9389)  time: 0.3435  data: 0.0002  max mem: 2501
Train: Epoch[1/5]  [ 680/3125]  eta: 0:14:03  Lr: 0.001875  Loss: 0.4276  Acc@1: 81.2500 (75.3120)  Acc@5: 93.7500 (95.9526)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 690/3125]  eta: 0:13:59  Lr: 0.001875  Loss: 0.6780  Acc@1: 75.0000 (75.3075)  Acc@5: 93.7500 (95.9569)  time: 0.3438  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 700/3125]  eta: 0:13:56  Lr: 0.001875  Loss: 0.6826  Acc@1: 81.2500 (75.4458)  Acc@5: 93.7500 (95.9700)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 710/3125]  eta: 0:13:52  Lr: 0.001875  Loss: 0.6872  Acc@1: 81.2500 (75.4835)  Acc@5: 100.0000 (96.0091)  time: 0.3433  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 720/3125]  eta: 0:13:49  Lr: 0.001875  Loss: 0.5517  Acc@1: 81.2500 (75.6068)  Acc@5: 100.0000 (96.0385)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 730/3125]  eta: 0:13:45  Lr: 0.001875  Loss: 0.4918  Acc@1: 87.5000 (75.7353)  Acc@5: 100.0000 (96.0585)  time: 0.3420  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 740/3125]  eta: 0:13:42  Lr: 0.001875  Loss: 0.2671  Acc@1: 81.2500 (75.7760)  Acc@5: 100.0000 (96.0948)  time: 0.3423  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 750/3125]  eta: 0:13:38  Lr: 0.001875  Loss: 0.5590  Acc@1: 81.2500 (75.8489)  Acc@5: 100.0000 (96.1135)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 760/3125]  eta: 0:13:35  Lr: 0.001875  Loss: 0.8820  Acc@1: 81.2500 (75.9034)  Acc@5: 100.0000 (96.1153)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 770/3125]  eta: 0:13:31  Lr: 0.001875  Loss: 0.6969  Acc@1: 81.2500 (75.9728)  Acc@5: 100.0000 (96.1414)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 780/3125]  eta: 0:13:28  Lr: 0.001875  Loss: 0.5100  Acc@1: 81.2500 (76.0163)  Acc@5: 100.0000 (96.1668)  time: 0.3434  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 790/3125]  eta: 0:13:24  Lr: 0.001875  Loss: 0.8764  Acc@1: 81.2500 (76.0983)  Acc@5: 100.0000 (96.1994)  time: 0.3446  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 800/3125]  eta: 0:13:21  Lr: 0.001875  Loss: 0.3790  Acc@1: 81.2500 (76.1782)  Acc@5: 100.0000 (96.2157)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 810/3125]  eta: 0:13:18  Lr: 0.001875  Loss: 0.7098  Acc@1: 81.2500 (76.2253)  Acc@5: 100.0000 (96.2315)  time: 0.3451  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 820/3125]  eta: 0:13:14  Lr: 0.001875  Loss: 0.7134  Acc@1: 81.2500 (76.2409)  Acc@5: 100.0000 (96.2622)  time: 0.3459  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 830/3125]  eta: 0:13:11  Lr: 0.001875  Loss: 0.5568  Acc@1: 81.2500 (76.2936)  Acc@5: 100.0000 (96.2846)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 840/3125]  eta: 0:13:07  Lr: 0.001875  Loss: 0.3399  Acc@1: 81.2500 (76.3674)  Acc@5: 100.0000 (96.2842)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 850/3125]  eta: 0:13:04  Lr: 0.001875  Loss: 0.3246  Acc@1: 81.2500 (76.3587)  Acc@5: 93.7500 (96.2544)  time: 0.3440  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 860/3125]  eta: 0:13:00  Lr: 0.001875  Loss: 0.5081  Acc@1: 75.0000 (76.3429)  Acc@5: 93.7500 (96.2544)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 870/3125]  eta: 0:12:57  Lr: 0.001875  Loss: 0.4947  Acc@1: 81.2500 (76.3993)  Acc@5: 93.7500 (96.2471)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 880/3125]  eta: 0:12:53  Lr: 0.001875  Loss: 0.4787  Acc@1: 81.2500 (76.4401)  Acc@5: 100.0000 (96.2684)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 890/3125]  eta: 0:12:50  Lr: 0.001875  Loss: 0.7604  Acc@1: 81.2500 (76.4731)  Acc@5: 100.0000 (96.2823)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 900/3125]  eta: 0:12:46  Lr: 0.001875  Loss: 0.5554  Acc@1: 81.2500 (76.4983)  Acc@5: 93.7500 (96.2611)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 910/3125]  eta: 0:12:43  Lr: 0.001875  Loss: 0.3850  Acc@1: 75.0000 (76.5025)  Acc@5: 93.7500 (96.2747)  time: 0.3461  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 920/3125]  eta: 0:12:40  Lr: 0.001875  Loss: 0.5177  Acc@1: 81.2500 (76.5812)  Acc@5: 100.0000 (96.2948)  time: 0.3457  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 930/3125]  eta: 0:12:36  Lr: 0.001875  Loss: 0.7262  Acc@1: 81.2500 (76.6313)  Acc@5: 100.0000 (96.3077)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 940/3125]  eta: 0:12:33  Lr: 0.001875  Loss: 0.3996  Acc@1: 81.2500 (76.6937)  Acc@5: 100.0000 (96.3204)  time: 0.3434  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 950/3125]  eta: 0:12:29  Lr: 0.001875  Loss: 0.5900  Acc@1: 81.2500 (76.7284)  Acc@5: 100.0000 (96.3262)  time: 0.3446  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 960/3125]  eta: 0:12:26  Lr: 0.001875  Loss: 0.3837  Acc@1: 81.2500 (76.7950)  Acc@5: 100.0000 (96.3580)  time: 0.3448  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 970/3125]  eta: 0:12:22  Lr: 0.001875  Loss: 0.3999  Acc@1: 87.5000 (76.9117)  Acc@5: 100.0000 (96.3890)  time: 0.3438  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 980/3125]  eta: 0:12:19  Lr: 0.001875  Loss: 0.5031  Acc@1: 87.5000 (76.9687)  Acc@5: 100.0000 (96.4131)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 990/3125]  eta: 0:12:15  Lr: 0.001875  Loss: 0.4983  Acc@1: 81.2500 (76.9992)  Acc@5: 100.0000 (96.4051)  time: 0.3457  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1000/3125]  eta: 0:12:12  Lr: 0.001875  Loss: 0.4579  Acc@1: 81.2500 (77.0417)  Acc@5: 93.7500 (96.3974)  time: 0.3467  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1010/3125]  eta: 0:12:09  Lr: 0.001875  Loss: 0.5060  Acc@1: 75.0000 (77.0586)  Acc@5: 100.0000 (96.4083)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1020/3125]  eta: 0:12:05  Lr: 0.001875  Loss: 0.0720  Acc@1: 81.2500 (77.1180)  Acc@5: 100.0000 (96.4128)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1030/3125]  eta: 0:12:02  Lr: 0.001875  Loss: 0.7449  Acc@1: 81.2500 (77.1884)  Acc@5: 100.0000 (96.4173)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1040/3125]  eta: 0:11:58  Lr: 0.001875  Loss: 0.4686  Acc@1: 81.2500 (77.2154)  Acc@5: 100.0000 (96.4337)  time: 0.3444  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1050/3125]  eta: 0:11:55  Lr: 0.001875  Loss: 0.4887  Acc@1: 81.2500 (77.2419)  Acc@5: 100.0000 (96.4379)  time: 0.3439  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1060/3125]  eta: 0:11:51  Lr: 0.001875  Loss: 0.9427  Acc@1: 81.2500 (77.3091)  Acc@5: 100.0000 (96.4538)  time: 0.3441  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [1070/3125]  eta: 0:11:48  Lr: 0.001875  Loss: 0.4851  Acc@1: 87.5000 (77.3576)  Acc@5: 100.0000 (96.4694)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1080/3125]  eta: 0:11:44  Lr: 0.001875  Loss: 0.5436  Acc@1: 81.2500 (77.3936)  Acc@5: 100.0000 (96.4905)  time: 0.3446  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1090/3125]  eta: 0:11:41  Lr: 0.001875  Loss: 0.4734  Acc@1: 87.5000 (77.4519)  Acc@5: 100.0000 (96.5170)  time: 0.3447  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1100/3125]  eta: 0:11:38  Lr: 0.001875  Loss: 0.6796  Acc@1: 87.5000 (77.4921)  Acc@5: 100.0000 (96.5372)  time: 0.3456  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1110/3125]  eta: 0:11:34  Lr: 0.001875  Loss: 0.8387  Acc@1: 81.2500 (77.5259)  Acc@5: 100.0000 (96.5403)  time: 0.3467  data: 0.0023  max mem: 2501
Train: Epoch[1/5]  [1120/3125]  eta: 0:11:31  Lr: 0.001875  Loss: 0.7485  Acc@1: 81.2500 (77.5312)  Acc@5: 100.0000 (96.5544)  time: 0.3455  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [1130/3125]  eta: 0:11:27  Lr: 0.001875  Loss: 0.3614  Acc@1: 81.2500 (77.5807)  Acc@5: 100.0000 (96.5517)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1140/3125]  eta: 0:11:24  Lr: 0.001875  Loss: 0.6582  Acc@1: 81.2500 (77.6019)  Acc@5: 100.0000 (96.5546)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1150/3125]  eta: 0:11:20  Lr: 0.001875  Loss: 0.9064  Acc@1: 75.0000 (77.6064)  Acc@5: 100.0000 (96.5628)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1160/3125]  eta: 0:11:17  Lr: 0.001875  Loss: 0.6659  Acc@1: 75.0000 (77.6109)  Acc@5: 100.0000 (96.5708)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1170/3125]  eta: 0:11:13  Lr: 0.001875  Loss: 0.4594  Acc@1: 81.2500 (77.6526)  Acc@5: 100.0000 (96.5841)  time: 0.3438  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1180/3125]  eta: 0:11:10  Lr: 0.001875  Loss: 0.3045  Acc@1: 87.5000 (77.6725)  Acc@5: 100.0000 (96.5919)  time: 0.3438  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1190/3125]  eta: 0:11:07  Lr: 0.001875  Loss: 0.2762  Acc@1: 87.5000 (77.7550)  Acc@5: 100.0000 (96.6152)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1200/3125]  eta: 0:11:03  Lr: 0.001875  Loss: 0.2619  Acc@1: 81.2500 (77.7685)  Acc@5: 100.0000 (96.6174)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1210/3125]  eta: 0:11:00  Lr: 0.001875  Loss: 0.5503  Acc@1: 81.2500 (77.7921)  Acc@5: 100.0000 (96.6299)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1220/3125]  eta: 0:10:56  Lr: 0.001875  Loss: 0.0369  Acc@1: 81.2500 (77.8460)  Acc@5: 100.0000 (96.6472)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1230/3125]  eta: 0:10:53  Lr: 0.001875  Loss: 0.6177  Acc@1: 81.2500 (77.9092)  Acc@5: 100.0000 (96.6694)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1240/3125]  eta: 0:10:49  Lr: 0.001875  Loss: 0.8421  Acc@1: 81.2500 (77.9059)  Acc@5: 100.0000 (96.6761)  time: 0.3439  data: 0.0002  max mem: 2501
Train: Epoch[1/5]  [1250/3125]  eta: 0:10:46  Lr: 0.001875  Loss: 0.2814  Acc@1: 81.2500 (77.9526)  Acc@5: 100.0000 (96.6827)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1260/3125]  eta: 0:10:42  Lr: 0.001875  Loss: 0.4518  Acc@1: 87.5000 (78.0184)  Acc@5: 100.0000 (96.6891)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1270/3125]  eta: 0:10:39  Lr: 0.001875  Loss: 0.4034  Acc@1: 87.5000 (78.0537)  Acc@5: 100.0000 (96.6955)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1280/3125]  eta: 0:10:35  Lr: 0.001875  Loss: 0.6193  Acc@1: 81.2500 (78.0933)  Acc@5: 100.0000 (96.6920)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1290/3125]  eta: 0:10:32  Lr: 0.001875  Loss: 0.6260  Acc@1: 81.2500 (78.1177)  Acc@5: 100.0000 (96.6983)  time: 0.3435  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1300/3125]  eta: 0:10:28  Lr: 0.001875  Loss: 0.5301  Acc@1: 81.2500 (78.1610)  Acc@5: 100.0000 (96.7141)  time: 0.3447  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1310/3125]  eta: 0:10:25  Lr: 0.001875  Loss: 0.8663  Acc@1: 81.2500 (78.2037)  Acc@5: 100.0000 (96.7344)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1320/3125]  eta: 0:10:22  Lr: 0.001875  Loss: 0.3241  Acc@1: 81.2500 (78.2315)  Acc@5: 100.0000 (96.7449)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1330/3125]  eta: 0:10:18  Lr: 0.001875  Loss: 0.2071  Acc@1: 87.5000 (78.3152)  Acc@5: 100.0000 (96.7553)  time: 0.3426  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1340/3125]  eta: 0:10:15  Lr: 0.001875  Loss: 0.2671  Acc@1: 87.5000 (78.3417)  Acc@5: 100.0000 (96.7655)  time: 0.3431  data: 0.0002  max mem: 2501
Train: Epoch[1/5]  [1350/3125]  eta: 0:10:11  Lr: 0.001875  Loss: 0.6855  Acc@1: 81.2500 (78.3679)  Acc@5: 100.0000 (96.7617)  time: 0.3438  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [1360/3125]  eta: 0:10:08  Lr: 0.001875  Loss: 0.3097  Acc@1: 81.2500 (78.3707)  Acc@5: 100.0000 (96.7671)  time: 0.3433  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [1370/3125]  eta: 0:10:04  Lr: 0.001875  Loss: 0.2857  Acc@1: 81.2500 (78.4327)  Acc@5: 100.0000 (96.7679)  time: 0.3436  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [1380/3125]  eta: 0:10:01  Lr: 0.001875  Loss: 0.3824  Acc@1: 87.5000 (78.4893)  Acc@5: 100.0000 (96.7913)  time: 0.3451  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [1390/3125]  eta: 0:09:57  Lr: 0.001875  Loss: 0.9561  Acc@1: 81.2500 (78.4597)  Acc@5: 100.0000 (96.8098)  time: 0.3456  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1400/3125]  eta: 0:09:54  Lr: 0.001875  Loss: 0.7700  Acc@1: 81.2500 (78.4930)  Acc@5: 100.0000 (96.8148)  time: 0.3450  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1410/3125]  eta: 0:09:50  Lr: 0.001875  Loss: 0.4855  Acc@1: 87.5000 (78.5303)  Acc@5: 100.0000 (96.8241)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1420/3125]  eta: 0:09:47  Lr: 0.001875  Loss: 0.1596  Acc@1: 81.2500 (78.5626)  Acc@5: 100.0000 (96.8200)  time: 0.3441  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1430/3125]  eta: 0:09:44  Lr: 0.001875  Loss: 1.0769  Acc@1: 81.2500 (78.5552)  Acc@5: 93.7500 (96.8029)  time: 0.3444  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [1440/3125]  eta: 0:09:40  Lr: 0.001875  Loss: 0.9074  Acc@1: 75.0000 (78.5522)  Acc@5: 100.0000 (96.8078)  time: 0.3445  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [1450/3125]  eta: 0:09:37  Lr: 0.001875  Loss: 0.5314  Acc@1: 75.0000 (78.5794)  Acc@5: 100.0000 (96.8169)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1460/3125]  eta: 0:09:33  Lr: 0.001875  Loss: 0.2823  Acc@1: 81.2500 (78.5934)  Acc@5: 100.0000 (96.8258)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1470/3125]  eta: 0:09:30  Lr: 0.001875  Loss: 0.6328  Acc@1: 81.2500 (78.6242)  Acc@5: 100.0000 (96.8346)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1480/3125]  eta: 0:09:26  Lr: 0.001875  Loss: 0.2291  Acc@1: 81.2500 (78.6166)  Acc@5: 100.0000 (96.8222)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1490/3125]  eta: 0:09:23  Lr: 0.001875  Loss: 0.7336  Acc@1: 81.2500 (78.6133)  Acc@5: 93.7500 (96.8184)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1500/3125]  eta: 0:09:19  Lr: 0.001875  Loss: 0.4664  Acc@1: 81.2500 (78.6101)  Acc@5: 100.0000 (96.8146)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1510/3125]  eta: 0:09:16  Lr: 0.001875  Loss: 0.3785  Acc@1: 81.2500 (78.6276)  Acc@5: 100.0000 (96.8068)  time: 0.3439  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1520/3125]  eta: 0:09:13  Lr: 0.001875  Loss: 0.4217  Acc@1: 81.2500 (78.6489)  Acc@5: 100.0000 (96.8154)  time: 0.3435  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1530/3125]  eta: 0:09:09  Lr: 0.001875  Loss: 0.7384  Acc@1: 87.5000 (78.6741)  Acc@5: 100.0000 (96.8199)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1540/3125]  eta: 0:09:06  Lr: 0.001875  Loss: 0.7776  Acc@1: 81.2500 (78.6948)  Acc@5: 100.0000 (96.8284)  time: 0.3439  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1550/3125]  eta: 0:09:02  Lr: 0.001875  Loss: 0.4708  Acc@1: 81.2500 (78.7153)  Acc@5: 100.0000 (96.8367)  time: 0.3437  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1560/3125]  eta: 0:08:59  Lr: 0.001875  Loss: 0.3837  Acc@1: 81.2500 (78.7356)  Acc@5: 100.0000 (96.8410)  time: 0.3429  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1570/3125]  eta: 0:08:55  Lr: 0.001875  Loss: 0.8033  Acc@1: 81.2500 (78.7516)  Acc@5: 100.0000 (96.8531)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1580/3125]  eta: 0:08:52  Lr: 0.001875  Loss: 0.3943  Acc@1: 81.2500 (78.7634)  Acc@5: 100.0000 (96.8493)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1590/3125]  eta: 0:08:48  Lr: 0.001875  Loss: 0.7176  Acc@1: 81.2500 (78.7987)  Acc@5: 100.0000 (96.8534)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1600/3125]  eta: 0:08:45  Lr: 0.001875  Loss: 0.4495  Acc@1: 81.2500 (78.8218)  Acc@5: 100.0000 (96.8457)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1610/3125]  eta: 0:08:41  Lr: 0.001875  Loss: 0.4007  Acc@1: 81.2500 (78.8214)  Acc@5: 93.7500 (96.8459)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1620/3125]  eta: 0:08:38  Lr: 0.001875  Loss: 0.4316  Acc@1: 81.2500 (78.8518)  Acc@5: 100.0000 (96.8576)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1630/3125]  eta: 0:08:34  Lr: 0.001875  Loss: 0.3798  Acc@1: 87.5000 (78.8742)  Acc@5: 100.0000 (96.8616)  time: 0.3438  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1640/3125]  eta: 0:08:31  Lr: 0.001875  Loss: 0.4024  Acc@1: 81.2500 (78.8924)  Acc@5: 100.0000 (96.8617)  time: 0.3435  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1650/3125]  eta: 0:08:28  Lr: 0.001875  Loss: 0.1552  Acc@1: 81.2500 (78.9332)  Acc@5: 100.0000 (96.8731)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1660/3125]  eta: 0:08:24  Lr: 0.001875  Loss: 0.5555  Acc@1: 87.5000 (78.9697)  Acc@5: 100.0000 (96.8769)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1670/3125]  eta: 0:08:21  Lr: 0.001875  Loss: 0.3199  Acc@1: 81.2500 (78.9946)  Acc@5: 100.0000 (96.8918)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1680/3125]  eta: 0:08:17  Lr: 0.001875  Loss: 0.5825  Acc@1: 81.2500 (79.0155)  Acc@5: 100.0000 (96.8992)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1690/3125]  eta: 0:08:14  Lr: 0.001875  Loss: 0.4907  Acc@1: 81.2500 (79.0287)  Acc@5: 100.0000 (96.9138)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1700/3125]  eta: 0:08:10  Lr: 0.001875  Loss: 0.4570  Acc@1: 81.2500 (79.0491)  Acc@5: 100.0000 (96.9136)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [1710/3125]  eta: 0:08:07  Lr: 0.001875  Loss: 0.7487  Acc@1: 81.2500 (79.0729)  Acc@5: 100.0000 (96.9060)  time: 0.3446  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1720/3125]  eta: 0:08:03  Lr: 0.001875  Loss: 0.3273  Acc@1: 81.2500 (79.1037)  Acc@5: 100.0000 (96.9059)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1730/3125]  eta: 0:08:00  Lr: 0.001875  Loss: 0.4989  Acc@1: 87.5000 (79.1414)  Acc@5: 100.0000 (96.9129)  time: 0.3440  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1740/3125]  eta: 0:07:57  Lr: 0.001875  Loss: 0.3083  Acc@1: 87.5000 (79.1715)  Acc@5: 100.0000 (96.9163)  time: 0.3448  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1750/3125]  eta: 0:07:53  Lr: 0.001875  Loss: 0.1610  Acc@1: 87.5000 (79.2119)  Acc@5: 100.0000 (96.9268)  time: 0.3468  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [1760/3125]  eta: 0:07:50  Lr: 0.001875  Loss: 0.8971  Acc@1: 87.5000 (79.2306)  Acc@5: 100.0000 (96.9194)  time: 0.3476  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [1770/3125]  eta: 0:07:46  Lr: 0.001875  Loss: 0.2483  Acc@1: 75.0000 (79.2349)  Acc@5: 93.7500 (96.9085)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1780/3125]  eta: 0:07:43  Lr: 0.001875  Loss: 0.2055  Acc@1: 75.0000 (79.2532)  Acc@5: 100.0000 (96.9154)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1790/3125]  eta: 0:07:39  Lr: 0.001875  Loss: 0.4817  Acc@1: 87.5000 (79.2818)  Acc@5: 100.0000 (96.9256)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1800/3125]  eta: 0:07:36  Lr: 0.001875  Loss: 1.1063  Acc@1: 87.5000 (79.2928)  Acc@5: 100.0000 (96.9253)  time: 0.3449  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1810/3125]  eta: 0:07:33  Lr: 0.001875  Loss: 0.7484  Acc@1: 87.5000 (79.3208)  Acc@5: 100.0000 (96.9388)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1820/3125]  eta: 0:07:29  Lr: 0.001875  Loss: 0.6140  Acc@1: 87.5000 (79.3245)  Acc@5: 100.0000 (96.9454)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1830/3125]  eta: 0:07:26  Lr: 0.001875  Loss: 0.5483  Acc@1: 81.2500 (79.3453)  Acc@5: 100.0000 (96.9484)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1840/3125]  eta: 0:07:22  Lr: 0.001875  Loss: 0.3904  Acc@1: 81.2500 (79.3794)  Acc@5: 100.0000 (96.9514)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1850/3125]  eta: 0:07:19  Lr: 0.001875  Loss: 0.4638  Acc@1: 87.5000 (79.3996)  Acc@5: 100.0000 (96.9611)  time: 0.3438  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1860/3125]  eta: 0:07:15  Lr: 0.001875  Loss: 0.5027  Acc@1: 87.5000 (79.4398)  Acc@5: 100.0000 (96.9674)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1870/3125]  eta: 0:07:12  Lr: 0.001875  Loss: 0.5391  Acc@1: 81.2500 (79.4562)  Acc@5: 100.0000 (96.9602)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1880/3125]  eta: 0:07:08  Lr: 0.001875  Loss: 0.5095  Acc@1: 81.2500 (79.4591)  Acc@5: 100.0000 (96.9730)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1890/3125]  eta: 0:07:05  Lr: 0.001875  Loss: 0.7505  Acc@1: 81.2500 (79.4851)  Acc@5: 100.0000 (96.9791)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:01  Lr: 0.001875  Loss: 0.5350  Acc@1: 87.5000 (79.5108)  Acc@5: 100.0000 (96.9851)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1910/3125]  eta: 0:06:58  Lr: 0.001875  Loss: 0.5729  Acc@1: 81.2500 (79.5297)  Acc@5: 100.0000 (96.9976)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1920/3125]  eta: 0:06:55  Lr: 0.001875  Loss: 0.7960  Acc@1: 81.2500 (79.5354)  Acc@5: 100.0000 (96.9905)  time: 0.3438  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1930/3125]  eta: 0:06:51  Lr: 0.001875  Loss: 0.2671  Acc@1: 81.2500 (79.5410)  Acc@5: 93.7500 (96.9899)  time: 0.3443  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1940/3125]  eta: 0:06:48  Lr: 0.001875  Loss: 0.7740  Acc@1: 81.2500 (79.5466)  Acc@5: 100.0000 (96.9861)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1950/3125]  eta: 0:06:44  Lr: 0.001875  Loss: 0.7050  Acc@1: 75.0000 (79.5361)  Acc@5: 100.0000 (96.9855)  time: 0.3434  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [1960/3125]  eta: 0:06:41  Lr: 0.001875  Loss: 1.1272  Acc@1: 81.2500 (79.5608)  Acc@5: 100.0000 (96.9977)  time: 0.3436  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1970/3125]  eta: 0:06:37  Lr: 0.001875  Loss: 0.4950  Acc@1: 81.2500 (79.5440)  Acc@5: 100.0000 (97.0066)  time: 0.3428  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1980/3125]  eta: 0:06:34  Lr: 0.001875  Loss: 0.3926  Acc@1: 75.0000 (79.5652)  Acc@5: 100.0000 (97.0122)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1990/3125]  eta: 0:06:30  Lr: 0.001875  Loss: 0.4142  Acc@1: 81.2500 (79.5549)  Acc@5: 100.0000 (97.0147)  time: 0.3438  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2000/3125]  eta: 0:06:27  Lr: 0.001875  Loss: 0.3419  Acc@1: 87.5000 (79.5915)  Acc@5: 100.0000 (97.0234)  time: 0.3443  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2010/3125]  eta: 0:06:24  Lr: 0.001875  Loss: 0.2457  Acc@1: 81.2500 (79.5873)  Acc@5: 100.0000 (97.0195)  time: 0.3447  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2020/3125]  eta: 0:06:20  Lr: 0.001875  Loss: 0.7445  Acc@1: 75.0000 (79.5584)  Acc@5: 100.0000 (97.0250)  time: 0.3442  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [2030/3125]  eta: 0:06:17  Lr: 0.001875  Loss: 0.3676  Acc@1: 75.0000 (79.5636)  Acc@5: 100.0000 (97.0273)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2040/3125]  eta: 0:06:13  Lr: 0.001875  Loss: 0.3537  Acc@1: 81.2500 (79.5811)  Acc@5: 100.0000 (97.0388)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2050/3125]  eta: 0:06:10  Lr: 0.001875  Loss: 0.8625  Acc@1: 81.2500 (79.6075)  Acc@5: 100.0000 (97.0472)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:06  Lr: 0.001875  Loss: 0.5107  Acc@1: 81.2500 (79.6185)  Acc@5: 100.0000 (97.0554)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:03  Lr: 0.001875  Loss: 0.2016  Acc@1: 81.2500 (79.6354)  Acc@5: 100.0000 (97.0546)  time: 0.3443  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2080/3125]  eta: 0:05:59  Lr: 0.001875  Loss: 0.4814  Acc@1: 87.5000 (79.6582)  Acc@5: 100.0000 (97.0657)  time: 0.3437  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2090/3125]  eta: 0:05:56  Lr: 0.001875  Loss: 0.8627  Acc@1: 81.2500 (79.6569)  Acc@5: 100.0000 (97.0738)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2100/3125]  eta: 0:05:53  Lr: 0.001875  Loss: 0.0770  Acc@1: 81.2500 (79.6615)  Acc@5: 100.0000 (97.0847)  time: 0.3439  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2110/3125]  eta: 0:05:49  Lr: 0.001875  Loss: 0.4211  Acc@1: 81.2500 (79.6749)  Acc@5: 100.0000 (97.0837)  time: 0.3445  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [2120/3125]  eta: 0:05:46  Lr: 0.001875  Loss: 0.3236  Acc@1: 87.5000 (79.7000)  Acc@5: 100.0000 (97.0857)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2130/3125]  eta: 0:05:42  Lr: 0.001875  Loss: 0.3192  Acc@1: 81.2500 (79.7337)  Acc@5: 100.0000 (97.0964)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2140/3125]  eta: 0:05:39  Lr: 0.001875  Loss: 0.1840  Acc@1: 87.5000 (79.7700)  Acc@5: 100.0000 (97.1042)  time: 0.3442  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [2150/3125]  eta: 0:05:35  Lr: 0.001875  Loss: 0.2623  Acc@1: 87.5000 (79.7798)  Acc@5: 100.0000 (97.1118)  time: 0.3441  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [2160/3125]  eta: 0:05:32  Lr: 0.001875  Loss: 0.6916  Acc@1: 81.2500 (79.7894)  Acc@5: 100.0000 (97.1049)  time: 0.3436  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2170/3125]  eta: 0:05:28  Lr: 0.001875  Loss: 0.4930  Acc@1: 81.2500 (79.8106)  Acc@5: 100.0000 (97.1067)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2180/3125]  eta: 0:05:25  Lr: 0.001875  Loss: 0.4229  Acc@1: 81.2500 (79.8344)  Acc@5: 100.0000 (97.1086)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2190/3125]  eta: 0:05:22  Lr: 0.001875  Loss: 0.7542  Acc@1: 87.5000 (79.8694)  Acc@5: 100.0000 (97.1103)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2200/3125]  eta: 0:05:18  Lr: 0.001875  Loss: 0.2666  Acc@1: 87.5000 (79.8983)  Acc@5: 100.0000 (97.1121)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:15  Lr: 0.001875  Loss: 0.2537  Acc@1: 87.5000 (79.9271)  Acc@5: 100.0000 (97.1054)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:11  Lr: 0.001875  Loss: 0.7501  Acc@1: 87.5000 (79.9443)  Acc@5: 100.0000 (97.1072)  time: 0.3452  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:08  Lr: 0.001875  Loss: 0.8587  Acc@1: 81.2500 (79.9417)  Acc@5: 100.0000 (97.1117)  time: 0.3458  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:04  Lr: 0.001875  Loss: 0.6083  Acc@1: 81.2500 (79.9336)  Acc@5: 100.0000 (97.1107)  time: 0.3466  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:01  Lr: 0.001875  Loss: 0.7181  Acc@1: 81.2500 (79.9617)  Acc@5: 100.0000 (97.1235)  time: 0.3451  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [2260/3125]  eta: 0:04:57  Lr: 0.001875  Loss: 0.4048  Acc@1: 81.2500 (79.9646)  Acc@5: 100.0000 (97.1224)  time: 0.3443  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [2270/3125]  eta: 0:04:54  Lr: 0.001875  Loss: 0.2031  Acc@1: 81.2500 (79.9675)  Acc@5: 100.0000 (97.1323)  time: 0.3445  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2280/3125]  eta: 0:04:51  Lr: 0.001875  Loss: 0.1697  Acc@1: 81.2500 (79.9759)  Acc@5: 100.0000 (97.1285)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2290/3125]  eta: 0:04:47  Lr: 0.001875  Loss: 0.4582  Acc@1: 81.2500 (80.0087)  Acc@5: 100.0000 (97.1328)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2300/3125]  eta: 0:04:44  Lr: 0.001875  Loss: 0.1872  Acc@1: 87.5000 (80.0331)  Acc@5: 100.0000 (97.1371)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2310/3125]  eta: 0:04:40  Lr: 0.001875  Loss: 0.7575  Acc@1: 81.2500 (80.0222)  Acc@5: 100.0000 (97.1387)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2320/3125]  eta: 0:04:37  Lr: 0.001875  Loss: 0.2857  Acc@1: 81.2500 (80.0382)  Acc@5: 100.0000 (97.1375)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2330/3125]  eta: 0:04:33  Lr: 0.001875  Loss: 0.5256  Acc@1: 87.5000 (80.0595)  Acc@5: 93.7500 (97.1364)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2340/3125]  eta: 0:04:30  Lr: 0.001875  Loss: 0.2537  Acc@1: 81.2500 (80.0726)  Acc@5: 93.7500 (97.1326)  time: 0.3437  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2350/3125]  eta: 0:04:26  Lr: 0.001875  Loss: 0.2663  Acc@1: 81.2500 (80.0883)  Acc@5: 100.0000 (97.1315)  time: 0.3438  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:23  Lr: 0.001875  Loss: 1.1615  Acc@1: 81.2500 (80.0773)  Acc@5: 100.0000 (97.1384)  time: 0.3445  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:20  Lr: 0.001875  Loss: 0.4181  Acc@1: 81.2500 (80.0796)  Acc@5: 100.0000 (97.1373)  time: 0.3450  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:16  Lr: 0.001875  Loss: 0.8295  Acc@1: 81.2500 (80.0898)  Acc@5: 100.0000 (97.1362)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:13  Lr: 0.001875  Loss: 0.4111  Acc@1: 87.5000 (80.1129)  Acc@5: 93.7500 (97.1325)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:09  Lr: 0.001875  Loss: 0.3322  Acc@1: 87.5000 (80.1333)  Acc@5: 100.0000 (97.1418)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:06  Lr: 0.001875  Loss: 0.4398  Acc@1: 87.5000 (80.1612)  Acc@5: 100.0000 (97.1459)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:02  Lr: 0.001875  Loss: 0.3969  Acc@1: 87.5000 (80.1761)  Acc@5: 100.0000 (97.1448)  time: 0.3438  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2430/3125]  eta: 0:03:59  Lr: 0.001875  Loss: 0.9834  Acc@1: 81.2500 (80.1625)  Acc@5: 100.0000 (97.1488)  time: 0.3430  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2440/3125]  eta: 0:03:55  Lr: 0.001875  Loss: 0.3828  Acc@1: 87.5000 (80.1874)  Acc@5: 100.0000 (97.1554)  time: 0.3444  data: 0.0017  max mem: 2501
Train: Epoch[1/5]  [2450/3125]  eta: 0:03:52  Lr: 0.001875  Loss: 0.5564  Acc@1: 87.5000 (80.1892)  Acc@5: 100.0000 (97.1517)  time: 0.3454  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [2460/3125]  eta: 0:03:49  Lr: 0.001875  Loss: 0.8487  Acc@1: 81.2500 (80.1986)  Acc@5: 100.0000 (97.1531)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2470/3125]  eta: 0:03:45  Lr: 0.001875  Loss: 0.5303  Acc@1: 87.5000 (80.2281)  Acc@5: 100.0000 (97.1621)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2480/3125]  eta: 0:03:42  Lr: 0.001875  Loss: 0.3428  Acc@1: 87.5000 (80.2600)  Acc@5: 100.0000 (97.1685)  time: 0.3437  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2490/3125]  eta: 0:03:38  Lr: 0.001875  Loss: 0.3891  Acc@1: 81.2500 (80.2539)  Acc@5: 100.0000 (97.1648)  time: 0.3437  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [2500/3125]  eta: 0:03:35  Lr: 0.001875  Loss: 0.7422  Acc@1: 81.2500 (80.2704)  Acc@5: 100.0000 (97.1711)  time: 0.3432  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2510/3125]  eta: 0:03:31  Lr: 0.001875  Loss: 0.1725  Acc@1: 87.5000 (80.3141)  Acc@5: 100.0000 (97.1799)  time: 0.3437  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:28  Lr: 0.001875  Loss: 0.1086  Acc@1: 87.5000 (80.3154)  Acc@5: 100.0000 (97.1688)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:24  Lr: 0.001875  Loss: 0.5511  Acc@1: 81.2500 (80.3314)  Acc@5: 100.0000 (97.1800)  time: 0.3433  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:21  Lr: 0.001875  Loss: 0.4677  Acc@1: 81.2500 (80.3375)  Acc@5: 100.0000 (97.1812)  time: 0.3433  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:18  Lr: 0.001875  Loss: 0.2839  Acc@1: 87.5000 (80.3655)  Acc@5: 100.0000 (97.1800)  time: 0.3434  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:14  Lr: 0.001875  Loss: 0.2691  Acc@1: 87.5000 (80.3910)  Acc@5: 100.0000 (97.1837)  time: 0.3443  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:11  Lr: 0.001875  Loss: 0.3216  Acc@1: 87.5000 (80.4162)  Acc@5: 100.0000 (97.1898)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0270  Acc@1: 87.5000 (80.4315)  Acc@5: 100.0000 (97.1910)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:04  Lr: 0.001875  Loss: 0.5509  Acc@1: 87.5000 (80.4467)  Acc@5: 100.0000 (97.1970)  time: 0.3449  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:00  Lr: 0.001875  Loss: 0.3225  Acc@1: 87.5000 (80.4691)  Acc@5: 100.0000 (97.2030)  time: 0.3448  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [2610/3125]  eta: 0:02:57  Lr: 0.001875  Loss: 0.7768  Acc@1: 81.2500 (80.4768)  Acc@5: 100.0000 (97.2017)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2620/3125]  eta: 0:02:53  Lr: 0.001875  Loss: 0.2665  Acc@1: 81.2500 (80.4869)  Acc@5: 100.0000 (97.2053)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2630/3125]  eta: 0:02:50  Lr: 0.001875  Loss: 0.4303  Acc@1: 81.2500 (80.4898)  Acc@5: 100.0000 (97.2040)  time: 0.3427  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2640/3125]  eta: 0:02:47  Lr: 0.001875  Loss: 0.3658  Acc@1: 81.2500 (80.5093)  Acc@5: 100.0000 (97.2004)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2650/3125]  eta: 0:02:43  Lr: 0.001875  Loss: 0.1966  Acc@1: 81.2500 (80.4979)  Acc@5: 93.7500 (97.1945)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2660/3125]  eta: 0:02:40  Lr: 0.001875  Loss: 0.0420  Acc@1: 81.2500 (80.5125)  Acc@5: 93.7500 (97.1933)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:36  Lr: 0.001875  Loss: 0.5207  Acc@1: 87.5000 (80.5293)  Acc@5: 100.0000 (97.2038)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:33  Lr: 0.001875  Loss: 0.6659  Acc@1: 81.2500 (80.5297)  Acc@5: 100.0000 (97.2142)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:29  Lr: 0.001875  Loss: 0.4007  Acc@1: 81.2500 (80.5463)  Acc@5: 100.0000 (97.2129)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:26  Lr: 0.001875  Loss: 0.1098  Acc@1: 87.5000 (80.5651)  Acc@5: 100.0000 (97.2209)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:22  Lr: 0.001875  Loss: 0.2109  Acc@1: 87.5000 (80.5676)  Acc@5: 100.0000 (97.2243)  time: 0.3460  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1496  Acc@1: 81.2500 (80.5678)  Acc@5: 100.0000 (97.2276)  time: 0.3458  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:16  Lr: 0.001875  Loss: 0.6975  Acc@1: 81.2500 (80.5840)  Acc@5: 100.0000 (97.2263)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:12  Lr: 0.001875  Loss: 0.3036  Acc@1: 87.5000 (80.6138)  Acc@5: 100.0000 (97.2318)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:09  Lr: 0.001875  Loss: 0.2498  Acc@1: 87.5000 (80.6275)  Acc@5: 100.0000 (97.2374)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:05  Lr: 0.001875  Loss: 0.1787  Acc@1: 87.5000 (80.6411)  Acc@5: 100.0000 (97.2406)  time: 0.3459  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:02  Lr: 0.001875  Loss: 0.4205  Acc@1: 81.2500 (80.6636)  Acc@5: 100.0000 (97.2438)  time: 0.3464  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [2780/3125]  eta: 0:01:58  Lr: 0.001875  Loss: 0.2803  Acc@1: 87.5000 (80.6769)  Acc@5: 100.0000 (97.2537)  time: 0.3447  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2790/3125]  eta: 0:01:55  Lr: 0.001875  Loss: 0.6276  Acc@1: 87.5000 (80.6879)  Acc@5: 100.0000 (97.2523)  time: 0.3450  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2800/3125]  eta: 0:01:51  Lr: 0.001875  Loss: 0.8444  Acc@1: 81.2500 (80.6743)  Acc@5: 100.0000 (97.2577)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2810/3125]  eta: 0:01:48  Lr: 0.001875  Loss: 0.1078  Acc@1: 81.2500 (80.6808)  Acc@5: 100.0000 (97.2608)  time: 0.3459  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:45  Lr: 0.001875  Loss: 0.2186  Acc@1: 87.5000 (80.6939)  Acc@5: 100.0000 (97.2683)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:41  Lr: 0.001875  Loss: 0.5162  Acc@1: 87.5000 (80.7069)  Acc@5: 100.0000 (97.2691)  time: 0.3443  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:38  Lr: 0.001875  Loss: 1.3924  Acc@1: 87.5000 (80.7110)  Acc@5: 100.0000 (97.2677)  time: 0.3455  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:34  Lr: 0.001875  Loss: 1.0100  Acc@1: 87.5000 (80.7129)  Acc@5: 100.0000 (97.2729)  time: 0.3445  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:31  Lr: 0.001875  Loss: 0.3671  Acc@1: 87.5000 (80.7301)  Acc@5: 100.0000 (97.2715)  time: 0.3439  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0456  Acc@1: 87.5000 (80.7580)  Acc@5: 100.0000 (97.2745)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:24  Lr: 0.001875  Loss: 0.6269  Acc@1: 87.5000 (80.7792)  Acc@5: 100.0000 (97.2818)  time: 0.3462  data: 0.0016  max mem: 2501
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:20  Lr: 0.001875  Loss: 0.5668  Acc@1: 81.2500 (80.7874)  Acc@5: 100.0000 (97.2868)  time: 0.3467  data: 0.0019  max mem: 2501
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:17  Lr: 0.001875  Loss: 0.0736  Acc@1: 81.2500 (80.8040)  Acc@5: 100.0000 (97.2897)  time: 0.3449  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:14  Lr: 0.001875  Loss: 0.8423  Acc@1: 87.5000 (80.8120)  Acc@5: 100.0000 (97.2905)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:10  Lr: 0.001875  Loss: 0.4824  Acc@1: 87.5000 (80.8285)  Acc@5: 100.0000 (97.2912)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1513  Acc@1: 87.5000 (80.8321)  Acc@5: 100.0000 (97.2983)  time: 0.3445  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:03  Lr: 0.001875  Loss: 0.6339  Acc@1: 81.2500 (80.8420)  Acc@5: 100.0000 (97.3053)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:00  Lr: 0.001875  Loss: 0.5798  Acc@1: 81.2500 (80.8539)  Acc@5: 100.0000 (97.3124)  time: 0.3438  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [2960/3125]  eta: 0:00:56  Lr: 0.001875  Loss: 0.5589  Acc@1: 81.2500 (80.8616)  Acc@5: 100.0000 (97.3151)  time: 0.3444  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2970/3125]  eta: 0:00:53  Lr: 0.001875  Loss: 0.3560  Acc@1: 87.5000 (80.9008)  Acc@5: 100.0000 (97.3178)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:49  Lr: 0.001875  Loss: 0.4791  Acc@1: 87.5000 (80.9208)  Acc@5: 100.0000 (97.3247)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:46  Lr: 0.001875  Loss: 0.6328  Acc@1: 87.5000 (80.9303)  Acc@5: 100.0000 (97.3316)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: 0.3625  Acc@1: 81.2500 (80.9439)  Acc@5: 100.0000 (97.3384)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:39  Lr: 0.001875  Loss: 0.4847  Acc@1: 81.2500 (80.9449)  Acc@5: 100.0000 (97.3431)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: 0.6042  Acc@1: 81.2500 (80.9479)  Acc@5: 100.0000 (97.3457)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:32  Lr: 0.001875  Loss: 0.0931  Acc@1: 81.2500 (80.9634)  Acc@5: 100.0000 (97.3503)  time: 0.3476  data: 0.0020  max mem: 2501
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: 0.3966  Acc@1: 87.5000 (80.9787)  Acc@5: 100.0000 (97.3487)  time: 0.3471  data: 0.0020  max mem: 2501
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:25  Lr: 0.001875  Loss: 0.2256  Acc@1: 87.5000 (81.0021)  Acc@5: 100.0000 (97.3554)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: 0.6352  Acc@1: 87.5000 (81.0029)  Acc@5: 100.0000 (97.3599)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:18  Lr: 0.001875  Loss: 0.1817  Acc@1: 87.5000 (81.0261)  Acc@5: 100.0000 (97.3604)  time: 0.3455  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1777  Acc@1: 81.2500 (81.0269)  Acc@5: 100.0000 (97.3629)  time: 0.3466  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: 0.1151  Acc@1: 81.2500 (81.0377)  Acc@5: 100.0000 (97.3653)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: 0.5868  Acc@1: 87.5000 (81.0464)  Acc@5: 100.0000 (97.3678)  time: 0.3443  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: 0.5653  Acc@1: 81.2500 (81.0431)  Acc@5: 100.0000 (97.3682)  time: 0.3446  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: 0.5055  Acc@1: 81.2500 (81.0497)  Acc@5: 100.0000 (97.3726)  time: 0.3453  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7654  Acc@1: 81.2500 (81.0400)  Acc@5: 100.0000 (97.3720)  time: 0.3450  data: 0.0006  max mem: 2501
Train: Epoch[1/5] Total time: 0:17:56 (0.3446 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.7654  Acc@1: 81.2500 (81.0400)  Acc@5: 100.0000 (97.3720)
Train: Epoch[2/5]  [   0/3125]  eta: 0:33:59  Lr: 0.001875  Loss: 0.3578  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6527  data: 0.3070  max mem: 2501
Train: Epoch[2/5]  [  10/3125]  eta: 0:19:17  Lr: 0.001875  Loss: 0.5673  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (97.1591)  time: 0.3716  data: 0.0281  max mem: 2501
Train: Epoch[2/5]  [  20/3125]  eta: 0:18:30  Lr: 0.001875  Loss: 0.6406  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (97.9167)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  30/3125]  eta: 0:18:12  Lr: 0.001875  Loss: 0.3503  Acc@1: 87.5000 (83.2661)  Acc@5: 100.0000 (97.5806)  time: 0.3426  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  40/3125]  eta: 0:18:00  Lr: 0.001875  Loss: 0.0863  Acc@1: 87.5000 (83.5366)  Acc@5: 100.0000 (97.7134)  time: 0.3424  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  50/3125]  eta: 0:17:52  Lr: 0.001875  Loss: 0.7667  Acc@1: 81.2500 (83.5784)  Acc@5: 100.0000 (97.9167)  time: 0.3423  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  60/3125]  eta: 0:17:45  Lr: 0.001875  Loss: 0.1930  Acc@1: 81.2500 (84.2213)  Acc@5: 100.0000 (98.1557)  time: 0.3423  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  70/3125]  eta: 0:17:39  Lr: 0.001875  Loss: 0.5508  Acc@1: 81.2500 (84.1549)  Acc@5: 100.0000 (98.0634)  time: 0.3420  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  80/3125]  eta: 0:17:34  Lr: 0.001875  Loss: 0.7016  Acc@1: 81.2500 (83.2562)  Acc@5: 93.7500 (97.6080)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  90/3125]  eta: 0:17:30  Lr: 0.001875  Loss: 0.2676  Acc@1: 81.2500 (83.3791)  Acc@5: 93.7500 (97.6648)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 100/3125]  eta: 0:17:25  Lr: 0.001875  Loss: 0.6903  Acc@1: 87.5000 (83.1064)  Acc@5: 100.0000 (97.5866)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 110/3125]  eta: 0:17:22  Lr: 0.001875  Loss: 0.4069  Acc@1: 87.5000 (83.3896)  Acc@5: 100.0000 (97.6351)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 120/3125]  eta: 0:17:18  Lr: 0.001875  Loss: 0.3311  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (97.6756)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 130/3125]  eta: 0:17:14  Lr: 0.001875  Loss: 0.3379  Acc@1: 87.5000 (83.7309)  Acc@5: 100.0000 (97.7576)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 140/3125]  eta: 0:17:10  Lr: 0.001875  Loss: 0.4725  Acc@1: 87.5000 (83.9539)  Acc@5: 100.0000 (97.8723)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 150/3125]  eta: 0:17:06  Lr: 0.001875  Loss: 0.5328  Acc@1: 87.5000 (84.2301)  Acc@5: 100.0000 (97.9305)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 160/3125]  eta: 0:17:03  Lr: 0.001875  Loss: 0.7047  Acc@1: 87.5000 (84.2780)  Acc@5: 100.0000 (97.9425)  time: 0.3435  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 170/3125]  eta: 0:16:59  Lr: 0.001875  Loss: 0.2426  Acc@1: 81.2500 (84.4298)  Acc@5: 100.0000 (97.9898)  time: 0.3452  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [ 180/3125]  eta: 0:16:56  Lr: 0.001875  Loss: 0.3223  Acc@1: 87.5000 (84.5649)  Acc@5: 100.0000 (97.9972)  time: 0.3455  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [ 190/3125]  eta: 0:16:52  Lr: 0.001875  Loss: 0.0509  Acc@1: 87.5000 (84.5550)  Acc@5: 100.0000 (98.0694)  time: 0.3444  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 200/3125]  eta: 0:16:49  Lr: 0.001875  Loss: 0.5377  Acc@1: 81.2500 (84.4527)  Acc@5: 100.0000 (98.0721)  time: 0.3452  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 210/3125]  eta: 0:16:46  Lr: 0.001875  Loss: 0.5042  Acc@1: 87.5000 (84.5675)  Acc@5: 100.0000 (98.1339)  time: 0.3457  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 220/3125]  eta: 0:16:42  Lr: 0.001875  Loss: 0.7800  Acc@1: 87.5000 (84.5305)  Acc@5: 100.0000 (98.1900)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 230/3125]  eta: 0:16:38  Lr: 0.001875  Loss: 0.2011  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (98.2143)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 240/3125]  eta: 0:16:35  Lr: 0.001875  Loss: 0.8061  Acc@1: 81.2500 (84.5176)  Acc@5: 100.0000 (98.1587)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 250/3125]  eta: 0:16:31  Lr: 0.001875  Loss: 0.9763  Acc@1: 81.2500 (84.3875)  Acc@5: 100.0000 (98.1076)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 260/3125]  eta: 0:16:28  Lr: 0.001875  Loss: 0.4792  Acc@1: 81.2500 (84.3630)  Acc@5: 100.0000 (98.1561)  time: 0.3437  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 270/3125]  eta: 0:16:24  Lr: 0.001875  Loss: 0.4806  Acc@1: 81.2500 (84.4327)  Acc@5: 100.0000 (98.2011)  time: 0.3441  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [ 280/3125]  eta: 0:16:21  Lr: 0.001875  Loss: 0.3811  Acc@1: 81.2500 (84.4306)  Acc@5: 100.0000 (98.1539)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 290/3125]  eta: 0:16:17  Lr: 0.001875  Loss: 0.2622  Acc@1: 87.5000 (84.4072)  Acc@5: 100.0000 (98.0885)  time: 0.3450  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [ 300/3125]  eta: 0:16:13  Lr: 0.001875  Loss: 0.8749  Acc@1: 87.5000 (84.2608)  Acc@5: 93.7500 (97.9651)  time: 0.3437  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [ 310/3125]  eta: 0:16:10  Lr: 0.001875  Loss: 0.4305  Acc@1: 81.2500 (84.2846)  Acc@5: 93.7500 (97.9301)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 320/3125]  eta: 0:16:06  Lr: 0.001875  Loss: 0.2579  Acc@1: 81.2500 (84.4431)  Acc@5: 100.0000 (97.9167)  time: 0.3435  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 330/3125]  eta: 0:16:03  Lr: 0.001875  Loss: 0.5162  Acc@1: 87.5000 (84.4600)  Acc@5: 100.0000 (97.8852)  time: 0.3451  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [ 340/3125]  eta: 0:16:00  Lr: 0.001875  Loss: 0.2075  Acc@1: 87.5000 (84.5858)  Acc@5: 100.0000 (97.8739)  time: 0.3453  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [ 350/3125]  eta: 0:15:56  Lr: 0.001875  Loss: 0.6728  Acc@1: 87.5000 (84.6510)  Acc@5: 100.0000 (97.8454)  time: 0.3449  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [ 360/3125]  eta: 0:15:53  Lr: 0.001875  Loss: 0.2714  Acc@1: 87.5000 (84.6780)  Acc@5: 100.0000 (97.8532)  time: 0.3448  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 370/3125]  eta: 0:15:49  Lr: 0.001875  Loss: 0.7119  Acc@1: 87.5000 (84.8046)  Acc@5: 100.0000 (97.8942)  time: 0.3435  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 380/3125]  eta: 0:15:46  Lr: 0.001875  Loss: 0.7780  Acc@1: 87.5000 (84.7933)  Acc@5: 100.0000 (97.8839)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 390/3125]  eta: 0:15:42  Lr: 0.001875  Loss: 0.6225  Acc@1: 87.5000 (84.8785)  Acc@5: 100.0000 (97.9380)  time: 0.3450  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [ 400/3125]  eta: 0:15:39  Lr: 0.001875  Loss: 0.6368  Acc@1: 87.5000 (84.8192)  Acc@5: 100.0000 (97.9582)  time: 0.3449  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [ 410/3125]  eta: 0:15:35  Lr: 0.001875  Loss: 0.5642  Acc@1: 87.5000 (84.8236)  Acc@5: 100.0000 (97.9471)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 420/3125]  eta: 0:15:32  Lr: 0.001875  Loss: 0.5956  Acc@1: 87.5000 (84.7387)  Acc@5: 100.0000 (97.9662)  time: 0.3444  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 430/3125]  eta: 0:15:29  Lr: 0.001875  Loss: 0.8810  Acc@1: 81.2500 (84.6723)  Acc@5: 100.0000 (97.9408)  time: 0.3451  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [ 440/3125]  eta: 0:15:25  Lr: 0.001875  Loss: 0.5161  Acc@1: 81.2500 (84.6230)  Acc@5: 100.0000 (97.9450)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 450/3125]  eta: 0:15:22  Lr: 0.001875  Loss: 0.4197  Acc@1: 87.5000 (84.6175)  Acc@5: 100.0000 (97.9490)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 460/3125]  eta: 0:15:18  Lr: 0.001875  Loss: 0.3672  Acc@1: 87.5000 (84.6394)  Acc@5: 100.0000 (97.9393)  time: 0.3451  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 470/3125]  eta: 0:15:15  Lr: 0.001875  Loss: 0.2487  Acc@1: 87.5000 (84.6603)  Acc@5: 100.0000 (97.9565)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 480/3125]  eta: 0:15:11  Lr: 0.001875  Loss: 0.3505  Acc@1: 81.2500 (84.6284)  Acc@5: 100.0000 (97.9600)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 490/3125]  eta: 0:15:08  Lr: 0.001875  Loss: 0.1903  Acc@1: 81.2500 (84.6869)  Acc@5: 100.0000 (97.9506)  time: 0.3441  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 500/3125]  eta: 0:15:04  Lr: 0.001875  Loss: 0.4483  Acc@1: 87.5000 (84.7056)  Acc@5: 100.0000 (97.9666)  time: 0.3435  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 510/3125]  eta: 0:15:01  Lr: 0.001875  Loss: 0.3864  Acc@1: 81.2500 (84.6257)  Acc@5: 100.0000 (97.9819)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 520/3125]  eta: 0:14:57  Lr: 0.001875  Loss: 0.1318  Acc@1: 87.5000 (84.7769)  Acc@5: 100.0000 (98.0086)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 530/3125]  eta: 0:14:54  Lr: 0.001875  Loss: 0.1824  Acc@1: 93.7500 (84.8046)  Acc@5: 100.0000 (98.0461)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 540/3125]  eta: 0:14:50  Lr: 0.001875  Loss: 0.2424  Acc@1: 87.5000 (84.8660)  Acc@5: 100.0000 (98.0360)  time: 0.3436  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 550/3125]  eta: 0:14:47  Lr: 0.001875  Loss: 0.3018  Acc@1: 87.5000 (84.8911)  Acc@5: 100.0000 (98.0263)  time: 0.3435  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 560/3125]  eta: 0:14:43  Lr: 0.001875  Loss: 0.9009  Acc@1: 87.5000 (84.8708)  Acc@5: 100.0000 (98.0281)  time: 0.3430  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 570/3125]  eta: 0:14:40  Lr: 0.001875  Loss: 0.6098  Acc@1: 87.5000 (84.9168)  Acc@5: 100.0000 (98.0407)  time: 0.3430  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 580/3125]  eta: 0:14:36  Lr: 0.001875  Loss: 0.1565  Acc@1: 87.5000 (84.8752)  Acc@5: 100.0000 (98.0422)  time: 0.3435  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 590/3125]  eta: 0:14:33  Lr: 0.001875  Loss: 0.9671  Acc@1: 81.2500 (84.8668)  Acc@5: 100.0000 (98.0118)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 600/3125]  eta: 0:14:29  Lr: 0.001875  Loss: 0.4044  Acc@1: 81.2500 (84.8690)  Acc@5: 100.0000 (98.0241)  time: 0.3432  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 610/3125]  eta: 0:14:26  Lr: 0.001875  Loss: 0.5223  Acc@1: 81.2500 (84.8404)  Acc@5: 100.0000 (98.0258)  time: 0.3438  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 620/3125]  eta: 0:14:23  Lr: 0.001875  Loss: 0.6898  Acc@1: 81.2500 (84.8531)  Acc@5: 100.0000 (98.0475)  time: 0.3453  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 630/3125]  eta: 0:14:19  Lr: 0.001875  Loss: 0.2017  Acc@1: 81.2500 (84.8455)  Acc@5: 100.0000 (98.0586)  time: 0.3462  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [ 640/3125]  eta: 0:14:16  Lr: 0.001875  Loss: 0.3680  Acc@1: 87.5000 (84.8381)  Acc@5: 100.0000 (98.0304)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 650/3125]  eta: 0:14:12  Lr: 0.001875  Loss: 0.7065  Acc@1: 87.5000 (84.8886)  Acc@5: 100.0000 (98.0607)  time: 0.3434  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 660/3125]  eta: 0:14:09  Lr: 0.001875  Loss: 0.5964  Acc@1: 87.5000 (84.9281)  Acc@5: 100.0000 (98.0711)  time: 0.3435  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 670/3125]  eta: 0:14:05  Lr: 0.001875  Loss: 0.0562  Acc@1: 87.5000 (84.9944)  Acc@5: 100.0000 (98.0905)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 680/3125]  eta: 0:14:02  Lr: 0.001875  Loss: 0.5429  Acc@1: 81.2500 (84.9486)  Acc@5: 100.0000 (98.0910)  time: 0.3455  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 690/3125]  eta: 0:13:58  Lr: 0.001875  Loss: 0.7719  Acc@1: 81.2500 (84.9584)  Acc@5: 100.0000 (98.0825)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 700/3125]  eta: 0:13:55  Lr: 0.001875  Loss: 0.5295  Acc@1: 81.2500 (84.9412)  Acc@5: 100.0000 (98.0742)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 710/3125]  eta: 0:13:51  Lr: 0.001875  Loss: 0.6570  Acc@1: 81.2500 (84.8892)  Acc@5: 100.0000 (98.0573)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 720/3125]  eta: 0:13:48  Lr: 0.001875  Loss: 0.5570  Acc@1: 81.2500 (84.8561)  Acc@5: 100.0000 (98.0496)  time: 0.3424  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 730/3125]  eta: 0:13:44  Lr: 0.001875  Loss: 0.6834  Acc@1: 81.2500 (84.8495)  Acc@5: 100.0000 (98.0506)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 740/3125]  eta: 0:13:41  Lr: 0.001875  Loss: 0.2600  Acc@1: 81.2500 (84.7672)  Acc@5: 100.0000 (98.0516)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 750/3125]  eta: 0:13:38  Lr: 0.001875  Loss: 0.1618  Acc@1: 81.2500 (84.7870)  Acc@5: 100.0000 (98.0609)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 760/3125]  eta: 0:13:34  Lr: 0.001875  Loss: 0.4458  Acc@1: 87.5000 (84.8062)  Acc@5: 100.0000 (98.0618)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 770/3125]  eta: 0:13:31  Lr: 0.001875  Loss: 0.3093  Acc@1: 87.5000 (84.8168)  Acc@5: 100.0000 (98.0707)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 780/3125]  eta: 0:13:27  Lr: 0.001875  Loss: 0.6101  Acc@1: 87.5000 (84.8191)  Acc@5: 100.0000 (98.0874)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 790/3125]  eta: 0:13:24  Lr: 0.001875  Loss: 0.8850  Acc@1: 81.2500 (84.7661)  Acc@5: 100.0000 (98.0800)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 800/3125]  eta: 0:13:20  Lr: 0.001875  Loss: 0.5141  Acc@1: 87.5000 (84.7690)  Acc@5: 100.0000 (98.0883)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 810/3125]  eta: 0:13:17  Lr: 0.001875  Loss: 1.0740  Acc@1: 87.5000 (84.7179)  Acc@5: 100.0000 (98.0965)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 820/3125]  eta: 0:13:13  Lr: 0.001875  Loss: 0.7344  Acc@1: 81.2500 (84.6757)  Acc@5: 100.0000 (98.0816)  time: 0.3439  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [ 830/3125]  eta: 0:13:10  Lr: 0.001875  Loss: 0.6060  Acc@1: 87.5000 (84.6946)  Acc@5: 100.0000 (98.0821)  time: 0.3437  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [ 840/3125]  eta: 0:13:06  Lr: 0.001875  Loss: 0.4014  Acc@1: 87.5000 (84.6908)  Acc@5: 100.0000 (98.0752)  time: 0.3430  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 850/3125]  eta: 0:13:03  Lr: 0.001875  Loss: 0.2330  Acc@1: 81.2500 (84.6945)  Acc@5: 100.0000 (98.0758)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 860/3125]  eta: 0:12:59  Lr: 0.001875  Loss: 1.0538  Acc@1: 81.2500 (84.6472)  Acc@5: 100.0000 (98.0401)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 870/3125]  eta: 0:12:56  Lr: 0.001875  Loss: 0.0996  Acc@1: 87.5000 (84.6728)  Acc@5: 100.0000 (98.0554)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 880/3125]  eta: 0:12:53  Lr: 0.001875  Loss: 0.3994  Acc@1: 87.5000 (84.6978)  Acc@5: 100.0000 (98.0562)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 890/3125]  eta: 0:12:49  Lr: 0.001875  Loss: 0.4616  Acc@1: 87.5000 (84.7643)  Acc@5: 100.0000 (98.0710)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 900/3125]  eta: 0:12:46  Lr: 0.001875  Loss: 1.0227  Acc@1: 87.5000 (84.7253)  Acc@5: 100.0000 (98.0647)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 910/3125]  eta: 0:12:42  Lr: 0.001875  Loss: 0.4605  Acc@1: 87.5000 (84.7626)  Acc@5: 100.0000 (98.0722)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 920/3125]  eta: 0:12:39  Lr: 0.001875  Loss: 0.0793  Acc@1: 87.5000 (84.8127)  Acc@5: 100.0000 (98.0931)  time: 0.3450  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 930/3125]  eta: 0:12:35  Lr: 0.001875  Loss: 0.3844  Acc@1: 87.5000 (84.8147)  Acc@5: 100.0000 (98.0800)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 940/3125]  eta: 0:12:32  Lr: 0.001875  Loss: 0.4771  Acc@1: 81.2500 (84.7901)  Acc@5: 100.0000 (98.0606)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 950/3125]  eta: 0:12:28  Lr: 0.001875  Loss: 0.3616  Acc@1: 81.2500 (84.7792)  Acc@5: 100.0000 (98.0547)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 960/3125]  eta: 0:12:25  Lr: 0.001875  Loss: 0.5821  Acc@1: 87.5000 (84.8205)  Acc@5: 100.0000 (98.0554)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 970/3125]  eta: 0:12:21  Lr: 0.001875  Loss: 0.1454  Acc@1: 87.5000 (84.8674)  Acc@5: 100.0000 (98.0433)  time: 0.3445  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [ 980/3125]  eta: 0:12:18  Lr: 0.001875  Loss: 0.5114  Acc@1: 87.5000 (84.8942)  Acc@5: 100.0000 (98.0632)  time: 0.3448  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [ 990/3125]  eta: 0:12:15  Lr: 0.001875  Loss: 0.3175  Acc@1: 87.5000 (84.9142)  Acc@5: 100.0000 (98.0638)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1000/3125]  eta: 0:12:11  Lr: 0.001875  Loss: 0.3361  Acc@1: 87.5000 (84.9401)  Acc@5: 100.0000 (98.0707)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1010/3125]  eta: 0:12:08  Lr: 0.001875  Loss: 0.8719  Acc@1: 87.5000 (84.9345)  Acc@5: 100.0000 (98.0650)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1020/3125]  eta: 0:12:04  Lr: 0.001875  Loss: 0.4382  Acc@1: 81.2500 (84.9535)  Acc@5: 100.0000 (98.0534)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1030/3125]  eta: 0:12:01  Lr: 0.001875  Loss: 0.3833  Acc@1: 81.2500 (84.9236)  Acc@5: 100.0000 (98.0601)  time: 0.3456  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1040/3125]  eta: 0:11:57  Lr: 0.001875  Loss: 0.2823  Acc@1: 81.2500 (84.8883)  Acc@5: 100.0000 (98.0608)  time: 0.3446  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [1050/3125]  eta: 0:11:54  Lr: 0.001875  Loss: 0.3548  Acc@1: 87.5000 (84.9132)  Acc@5: 100.0000 (98.0614)  time: 0.3442  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1060/3125]  eta: 0:11:51  Lr: 0.001875  Loss: 0.5833  Acc@1: 87.5000 (84.8963)  Acc@5: 100.0000 (98.0502)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1070/3125]  eta: 0:11:47  Lr: 0.001875  Loss: 0.7271  Acc@1: 87.5000 (84.8973)  Acc@5: 100.0000 (98.0567)  time: 0.3455  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1080/3125]  eta: 0:11:44  Lr: 0.001875  Loss: 0.2386  Acc@1: 87.5000 (84.8809)  Acc@5: 100.0000 (98.0458)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1090/3125]  eta: 0:11:40  Lr: 0.001875  Loss: 0.5414  Acc@1: 87.5000 (84.9164)  Acc@5: 100.0000 (98.0580)  time: 0.3450  data: 0.0020  max mem: 2501
Train: Epoch[2/5]  [1100/3125]  eta: 0:11:37  Lr: 0.001875  Loss: 0.7919  Acc@1: 87.5000 (84.9001)  Acc@5: 100.0000 (98.0643)  time: 0.3458  data: 0.0019  max mem: 2501
Train: Epoch[2/5]  [1110/3125]  eta: 0:11:33  Lr: 0.001875  Loss: 0.2312  Acc@1: 81.2500 (84.8672)  Acc@5: 100.0000 (98.0704)  time: 0.3446  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1120/3125]  eta: 0:11:30  Lr: 0.001875  Loss: 0.6142  Acc@1: 81.2500 (84.8628)  Acc@5: 100.0000 (98.0542)  time: 0.3446  data: 0.0015  max mem: 2501
Train: Epoch[2/5]  [1130/3125]  eta: 0:11:27  Lr: 0.001875  Loss: 0.6078  Acc@1: 81.2500 (84.8530)  Acc@5: 100.0000 (98.0548)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1140/3125]  eta: 0:11:23  Lr: 0.001875  Loss: 0.1771  Acc@1: 87.5000 (84.8598)  Acc@5: 100.0000 (98.0609)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1150/3125]  eta: 0:11:20  Lr: 0.001875  Loss: 0.1700  Acc@1: 81.2500 (84.8284)  Acc@5: 100.0000 (98.0506)  time: 0.3424  data: 0.0002  max mem: 2501
Train: Epoch[2/5]  [1160/3125]  eta: 0:11:16  Lr: 0.001875  Loss: 0.5528  Acc@1: 81.2500 (84.8514)  Acc@5: 100.0000 (98.0512)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1170/3125]  eta: 0:11:13  Lr: 0.001875  Loss: 0.8569  Acc@1: 81.2500 (84.8100)  Acc@5: 100.0000 (98.0465)  time: 0.3443  data: 0.0002  max mem: 2501
Train: Epoch[2/5]  [1180/3125]  eta: 0:11:09  Lr: 0.001875  Loss: 1.0231  Acc@1: 81.2500 (84.7957)  Acc@5: 100.0000 (98.0472)  time: 0.3433  data: 0.0002  max mem: 2501
Train: Epoch[2/5]  [1190/3125]  eta: 0:11:06  Lr: 0.001875  Loss: 0.4499  Acc@1: 81.2500 (84.8079)  Acc@5: 100.0000 (98.0584)  time: 0.3433  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1200/3125]  eta: 0:11:02  Lr: 0.001875  Loss: 0.1033  Acc@1: 87.5000 (84.8460)  Acc@5: 100.0000 (98.0693)  time: 0.3439  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1210/3125]  eta: 0:10:59  Lr: 0.001875  Loss: 0.9293  Acc@1: 87.5000 (84.8421)  Acc@5: 100.0000 (98.0698)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1220/3125]  eta: 0:10:55  Lr: 0.001875  Loss: 0.3235  Acc@1: 87.5000 (84.8434)  Acc@5: 100.0000 (98.0651)  time: 0.3429  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1230/3125]  eta: 0:10:52  Lr: 0.001875  Loss: 0.4523  Acc@1: 81.2500 (84.8040)  Acc@5: 100.0000 (98.0605)  time: 0.3434  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1240/3125]  eta: 0:10:48  Lr: 0.001875  Loss: 0.2794  Acc@1: 81.2500 (84.8106)  Acc@5: 100.0000 (98.0610)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1250/3125]  eta: 0:10:45  Lr: 0.001875  Loss: 0.2377  Acc@1: 87.5000 (84.8371)  Acc@5: 100.0000 (98.0665)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1260/3125]  eta: 0:10:42  Lr: 0.001875  Loss: 0.3735  Acc@1: 87.5000 (84.8483)  Acc@5: 100.0000 (98.0819)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1270/3125]  eta: 0:10:38  Lr: 0.001875  Loss: 0.2030  Acc@1: 87.5000 (84.8495)  Acc@5: 100.0000 (98.0822)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1280/3125]  eta: 0:10:35  Lr: 0.001875  Loss: 0.3107  Acc@1: 87.5000 (84.8556)  Acc@5: 100.0000 (98.0777)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1290/3125]  eta: 0:10:31  Lr: 0.001875  Loss: 0.4442  Acc@1: 87.5000 (84.8470)  Acc@5: 100.0000 (98.0780)  time: 0.3431  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [1300/3125]  eta: 0:10:28  Lr: 0.001875  Loss: 0.1381  Acc@1: 87.5000 (84.8626)  Acc@5: 100.0000 (98.0880)  time: 0.3431  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1310/3125]  eta: 0:10:24  Lr: 0.001875  Loss: 0.3940  Acc@1: 87.5000 (84.8589)  Acc@5: 100.0000 (98.0883)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1320/3125]  eta: 0:10:21  Lr: 0.001875  Loss: 0.2945  Acc@1: 87.5000 (84.8789)  Acc@5: 100.0000 (98.0980)  time: 0.3445  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1330/3125]  eta: 0:10:17  Lr: 0.001875  Loss: 0.7684  Acc@1: 87.5000 (84.8939)  Acc@5: 100.0000 (98.0888)  time: 0.3449  data: 0.0017  max mem: 2501
Train: Epoch[2/5]  [1340/3125]  eta: 0:10:14  Lr: 0.001875  Loss: 0.3389  Acc@1: 87.5000 (84.8853)  Acc@5: 100.0000 (98.0938)  time: 0.3434  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1350/3125]  eta: 0:10:10  Lr: 0.001875  Loss: 0.6572  Acc@1: 81.2500 (84.8816)  Acc@5: 100.0000 (98.0986)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1360/3125]  eta: 0:10:07  Lr: 0.001875  Loss: 1.0870  Acc@1: 81.2500 (84.8733)  Acc@5: 100.0000 (98.0988)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1370/3125]  eta: 0:10:04  Lr: 0.001875  Loss: 1.0620  Acc@1: 81.2500 (84.8332)  Acc@5: 100.0000 (98.0899)  time: 0.3433  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1380/3125]  eta: 0:10:00  Lr: 0.001875  Loss: 0.3216  Acc@1: 81.2500 (84.8344)  Acc@5: 100.0000 (98.0992)  time: 0.3440  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1390/3125]  eta: 0:09:57  Lr: 0.001875  Loss: 0.2151  Acc@1: 87.5000 (84.8535)  Acc@5: 100.0000 (98.0949)  time: 0.3451  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1400/3125]  eta: 0:09:53  Lr: 0.001875  Loss: 0.7839  Acc@1: 87.5000 (84.8189)  Acc@5: 100.0000 (98.0728)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1410/3125]  eta: 0:09:50  Lr: 0.001875  Loss: 0.2889  Acc@1: 87.5000 (84.8290)  Acc@5: 100.0000 (98.0599)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1420/3125]  eta: 0:09:46  Lr: 0.001875  Loss: 0.4537  Acc@1: 87.5000 (84.7818)  Acc@5: 100.0000 (98.0515)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1430/3125]  eta: 0:09:43  Lr: 0.001875  Loss: 0.7087  Acc@1: 81.2500 (84.7877)  Acc@5: 100.0000 (98.0652)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1440/3125]  eta: 0:09:39  Lr: 0.001875  Loss: 0.3457  Acc@1: 87.5000 (84.7719)  Acc@5: 100.0000 (98.0656)  time: 0.3439  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1450/3125]  eta: 0:09:36  Lr: 0.001875  Loss: 0.3022  Acc@1: 81.2500 (84.7476)  Acc@5: 100.0000 (98.0660)  time: 0.3433  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1460/3125]  eta: 0:09:33  Lr: 0.001875  Loss: 0.3067  Acc@1: 87.5000 (84.7664)  Acc@5: 100.0000 (98.0664)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1470/3125]  eta: 0:09:29  Lr: 0.001875  Loss: 0.1640  Acc@1: 87.5000 (84.7978)  Acc@5: 100.0000 (98.0753)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1480/3125]  eta: 0:09:26  Lr: 0.001875  Loss: 0.3782  Acc@1: 87.5000 (84.8118)  Acc@5: 100.0000 (98.0841)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1490/3125]  eta: 0:09:22  Lr: 0.001875  Loss: 0.2916  Acc@1: 81.2500 (84.8089)  Acc@5: 100.0000 (98.0801)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1500/3125]  eta: 0:09:19  Lr: 0.001875  Loss: 1.1992  Acc@1: 87.5000 (84.8143)  Acc@5: 100.0000 (98.0888)  time: 0.3434  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1510/3125]  eta: 0:09:15  Lr: 0.001875  Loss: 0.0844  Acc@1: 87.5000 (84.8279)  Acc@5: 100.0000 (98.0973)  time: 0.3427  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1520/3125]  eta: 0:09:12  Lr: 0.001875  Loss: 0.4244  Acc@1: 87.5000 (84.8250)  Acc@5: 100.0000 (98.0893)  time: 0.3437  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1530/3125]  eta: 0:09:08  Lr: 0.001875  Loss: 0.4795  Acc@1: 87.5000 (84.8179)  Acc@5: 100.0000 (98.0936)  time: 0.3460  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [1540/3125]  eta: 0:09:05  Lr: 0.001875  Loss: 0.6302  Acc@1: 87.5000 (84.8272)  Acc@5: 100.0000 (98.0938)  time: 0.3459  data: 0.0021  max mem: 2501
Train: Epoch[2/5]  [1550/3125]  eta: 0:09:01  Lr: 0.001875  Loss: 0.4947  Acc@1: 87.5000 (84.8082)  Acc@5: 100.0000 (98.0899)  time: 0.3437  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [1560/3125]  eta: 0:08:58  Lr: 0.001875  Loss: 0.4518  Acc@1: 81.2500 (84.7934)  Acc@5: 100.0000 (98.0862)  time: 0.3442  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1570/3125]  eta: 0:08:55  Lr: 0.001875  Loss: 0.2811  Acc@1: 81.2500 (84.7748)  Acc@5: 100.0000 (98.0864)  time: 0.3452  data: 0.0018  max mem: 2501
Train: Epoch[2/5]  [1580/3125]  eta: 0:08:51  Lr: 0.001875  Loss: 0.0696  Acc@1: 81.2500 (84.7842)  Acc@5: 100.0000 (98.0867)  time: 0.3442  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1590/3125]  eta: 0:08:48  Lr: 0.001875  Loss: 0.5164  Acc@1: 81.2500 (84.7541)  Acc@5: 100.0000 (98.0948)  time: 0.3436  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1600/3125]  eta: 0:08:44  Lr: 0.001875  Loss: 0.3187  Acc@1: 81.2500 (84.7478)  Acc@5: 100.0000 (98.0949)  time: 0.3438  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1610/3125]  eta: 0:08:41  Lr: 0.001875  Loss: 0.3577  Acc@1: 81.2500 (84.7339)  Acc@5: 100.0000 (98.0912)  time: 0.3443  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1620/3125]  eta: 0:08:37  Lr: 0.001875  Loss: 0.3921  Acc@1: 81.2500 (84.7239)  Acc@5: 100.0000 (98.0722)  time: 0.3447  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1630/3125]  eta: 0:08:34  Lr: 0.001875  Loss: 0.2970  Acc@1: 87.5000 (84.7486)  Acc@5: 100.0000 (98.0840)  time: 0.3439  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1640/3125]  eta: 0:08:31  Lr: 0.001875  Loss: 0.3057  Acc@1: 87.5000 (84.7425)  Acc@5: 100.0000 (98.0766)  time: 0.3428  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1650/3125]  eta: 0:08:27  Lr: 0.001875  Loss: 0.3519  Acc@1: 87.5000 (84.7592)  Acc@5: 100.0000 (98.0845)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1660/3125]  eta: 0:08:24  Lr: 0.001875  Loss: 0.7150  Acc@1: 87.5000 (84.7757)  Acc@5: 100.0000 (98.0772)  time: 0.3426  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1670/3125]  eta: 0:08:20  Lr: 0.001875  Loss: 0.4750  Acc@1: 81.2500 (84.7621)  Acc@5: 100.0000 (98.0700)  time: 0.3452  data: 0.0017  max mem: 2501
Train: Epoch[2/5]  [1680/3125]  eta: 0:08:17  Lr: 0.001875  Loss: 0.4533  Acc@1: 81.2500 (84.7784)  Acc@5: 100.0000 (98.0741)  time: 0.3462  data: 0.0018  max mem: 2501
Train: Epoch[2/5]  [1690/3125]  eta: 0:08:13  Lr: 0.001875  Loss: 0.6156  Acc@1: 87.5000 (84.7945)  Acc@5: 100.0000 (98.0670)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1700/3125]  eta: 0:08:10  Lr: 0.001875  Loss: 0.3950  Acc@1: 87.5000 (84.8067)  Acc@5: 100.0000 (98.0673)  time: 0.3441  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1710/3125]  eta: 0:08:06  Lr: 0.001875  Loss: 0.2793  Acc@1: 87.5000 (84.8152)  Acc@5: 100.0000 (98.0786)  time: 0.3449  data: 0.0021  max mem: 2501
Train: Epoch[2/5]  [1720/3125]  eta: 0:08:03  Lr: 0.001875  Loss: 0.4185  Acc@1: 87.5000 (84.8090)  Acc@5: 100.0000 (98.0898)  time: 0.3444  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [1730/3125]  eta: 0:08:00  Lr: 0.001875  Loss: 0.0984  Acc@1: 87.5000 (84.8390)  Acc@5: 100.0000 (98.0900)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1740/3125]  eta: 0:07:56  Lr: 0.001875  Loss: 0.4018  Acc@1: 87.5000 (84.8578)  Acc@5: 100.0000 (98.0974)  time: 0.3452  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1750/3125]  eta: 0:07:53  Lr: 0.001875  Loss: 0.5455  Acc@1: 87.5000 (84.8479)  Acc@5: 100.0000 (98.1011)  time: 0.3453  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1760/3125]  eta: 0:07:49  Lr: 0.001875  Loss: 0.2946  Acc@1: 81.2500 (84.8488)  Acc@5: 100.0000 (98.1083)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1770/3125]  eta: 0:07:46  Lr: 0.001875  Loss: 0.4270  Acc@1: 87.5000 (84.8779)  Acc@5: 100.0000 (98.1119)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1780/3125]  eta: 0:07:42  Lr: 0.001875  Loss: 0.0972  Acc@1: 87.5000 (84.9031)  Acc@5: 100.0000 (98.1085)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1790/3125]  eta: 0:07:39  Lr: 0.001875  Loss: 0.2871  Acc@1: 87.5000 (84.8897)  Acc@5: 100.0000 (98.1121)  time: 0.3438  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1800/3125]  eta: 0:07:35  Lr: 0.001875  Loss: 0.4026  Acc@1: 81.2500 (84.8938)  Acc@5: 100.0000 (98.1052)  time: 0.3441  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1810/3125]  eta: 0:07:32  Lr: 0.001875  Loss: 0.2094  Acc@1: 87.5000 (84.9047)  Acc@5: 100.0000 (98.1122)  time: 0.3460  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1820/3125]  eta: 0:07:29  Lr: 0.001875  Loss: 0.3359  Acc@1: 87.5000 (84.9053)  Acc@5: 100.0000 (98.1089)  time: 0.3467  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1830/3125]  eta: 0:07:25  Lr: 0.001875  Loss: 0.5102  Acc@1: 87.5000 (84.9229)  Acc@5: 100.0000 (98.1124)  time: 0.3455  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1840/3125]  eta: 0:07:22  Lr: 0.001875  Loss: 0.3233  Acc@1: 87.5000 (84.9233)  Acc@5: 100.0000 (98.1158)  time: 0.3454  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1850/3125]  eta: 0:07:18  Lr: 0.001875  Loss: 0.2292  Acc@1: 87.5000 (84.9203)  Acc@5: 100.0000 (98.1226)  time: 0.3460  data: 0.0023  max mem: 2501
Train: Epoch[2/5]  [1860/3125]  eta: 0:07:15  Lr: 0.001875  Loss: 0.3972  Acc@1: 81.2500 (84.8972)  Acc@5: 100.0000 (98.1226)  time: 0.3453  data: 0.0015  max mem: 2501
Train: Epoch[2/5]  [1870/3125]  eta: 0:07:11  Lr: 0.001875  Loss: 0.1112  Acc@1: 81.2500 (84.8944)  Acc@5: 100.0000 (98.1193)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1880/3125]  eta: 0:07:08  Lr: 0.001875  Loss: 0.4824  Acc@1: 81.2500 (84.8784)  Acc@5: 100.0000 (98.1293)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1890/3125]  eta: 0:07:05  Lr: 0.001875  Loss: 0.2299  Acc@1: 81.2500 (84.8956)  Acc@5: 100.0000 (98.1392)  time: 0.3461  data: 0.0017  max mem: 2501
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:01  Lr: 0.001875  Loss: 0.9318  Acc@1: 87.5000 (84.8797)  Acc@5: 100.0000 (98.1391)  time: 0.3451  data: 0.0017  max mem: 2501
Train: Epoch[2/5]  [1910/3125]  eta: 0:06:58  Lr: 0.001875  Loss: 0.5714  Acc@1: 87.5000 (84.9065)  Acc@5: 100.0000 (98.1391)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1920/3125]  eta: 0:06:54  Lr: 0.001875  Loss: 0.1920  Acc@1: 87.5000 (84.9135)  Acc@5: 100.0000 (98.1357)  time: 0.3448  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1930/3125]  eta: 0:06:51  Lr: 0.001875  Loss: 0.8583  Acc@1: 81.2500 (84.9010)  Acc@5: 100.0000 (98.1422)  time: 0.3457  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1940/3125]  eta: 0:06:47  Lr: 0.001875  Loss: 0.3660  Acc@1: 87.5000 (84.9079)  Acc@5: 100.0000 (98.1453)  time: 0.3454  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1950/3125]  eta: 0:06:44  Lr: 0.001875  Loss: 0.5400  Acc@1: 87.5000 (84.9148)  Acc@5: 93.7500 (98.1260)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1960/3125]  eta: 0:06:41  Lr: 0.001875  Loss: 0.4372  Acc@1: 87.5000 (84.9184)  Acc@5: 93.7500 (98.1291)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1970/3125]  eta: 0:06:37  Lr: 0.001875  Loss: 0.6191  Acc@1: 87.5000 (84.9283)  Acc@5: 100.0000 (98.1355)  time: 0.3450  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1980/3125]  eta: 0:06:34  Lr: 0.001875  Loss: 0.4057  Acc@1: 87.5000 (84.9129)  Acc@5: 100.0000 (98.1354)  time: 0.3447  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1990/3125]  eta: 0:06:30  Lr: 0.001875  Loss: 0.6639  Acc@1: 87.5000 (84.9196)  Acc@5: 100.0000 (98.1354)  time: 0.3456  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2000/3125]  eta: 0:06:27  Lr: 0.001875  Loss: 0.4439  Acc@1: 87.5000 (84.9294)  Acc@5: 100.0000 (98.1353)  time: 0.3459  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2010/3125]  eta: 0:06:23  Lr: 0.001875  Loss: 0.2198  Acc@1: 87.5000 (84.9267)  Acc@5: 100.0000 (98.1353)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2020/3125]  eta: 0:06:20  Lr: 0.001875  Loss: 0.5311  Acc@1: 81.2500 (84.9023)  Acc@5: 100.0000 (98.1414)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2030/3125]  eta: 0:06:16  Lr: 0.001875  Loss: 0.5319  Acc@1: 81.2500 (84.8966)  Acc@5: 100.0000 (98.1321)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2040/3125]  eta: 0:06:13  Lr: 0.001875  Loss: 0.8534  Acc@1: 87.5000 (84.8910)  Acc@5: 100.0000 (98.1290)  time: 0.3440  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2050/3125]  eta: 0:06:10  Lr: 0.001875  Loss: 0.0850  Acc@1: 87.5000 (84.8946)  Acc@5: 100.0000 (98.1351)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:06  Lr: 0.001875  Loss: 0.1954  Acc@1: 87.5000 (84.9133)  Acc@5: 100.0000 (98.1380)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:03  Lr: 0.001875  Loss: 0.7530  Acc@1: 81.2500 (84.8926)  Acc@5: 100.0000 (98.1410)  time: 0.3439  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2080/3125]  eta: 0:05:59  Lr: 0.001875  Loss: 0.0942  Acc@1: 81.2500 (84.8901)  Acc@5: 100.0000 (98.1409)  time: 0.3442  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2090/3125]  eta: 0:05:56  Lr: 0.001875  Loss: 0.5753  Acc@1: 87.5000 (84.8966)  Acc@5: 100.0000 (98.1319)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2100/3125]  eta: 0:05:52  Lr: 0.001875  Loss: 0.5398  Acc@1: 87.5000 (84.9238)  Acc@5: 100.0000 (98.1318)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2110/3125]  eta: 0:05:49  Lr: 0.001875  Loss: 0.7218  Acc@1: 87.5000 (84.9331)  Acc@5: 100.0000 (98.1377)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2120/3125]  eta: 0:05:45  Lr: 0.001875  Loss: 0.5425  Acc@1: 87.5000 (84.9511)  Acc@5: 100.0000 (98.1465)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2130/3125]  eta: 0:05:42  Lr: 0.001875  Loss: 0.2921  Acc@1: 87.5000 (84.9396)  Acc@5: 100.0000 (98.1464)  time: 0.3423  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2140/3125]  eta: 0:05:39  Lr: 0.001875  Loss: 0.2012  Acc@1: 81.2500 (84.9399)  Acc@5: 100.0000 (98.1463)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2150/3125]  eta: 0:05:35  Lr: 0.001875  Loss: 0.2452  Acc@1: 87.5000 (84.9489)  Acc@5: 100.0000 (98.1433)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2160/3125]  eta: 0:05:32  Lr: 0.001875  Loss: 0.6526  Acc@1: 87.5000 (84.9346)  Acc@5: 100.0000 (98.1432)  time: 0.3426  data: 0.0002  max mem: 2501
Train: Epoch[2/5]  [2170/3125]  eta: 0:05:28  Lr: 0.001875  Loss: 0.2463  Acc@1: 81.2500 (84.9349)  Acc@5: 100.0000 (98.1489)  time: 0.3427  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2180/3125]  eta: 0:05:25  Lr: 0.001875  Loss: 0.5137  Acc@1: 81.2500 (84.9266)  Acc@5: 100.0000 (98.1488)  time: 0.3441  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [2190/3125]  eta: 0:05:21  Lr: 0.001875  Loss: 0.0641  Acc@1: 87.5000 (84.9469)  Acc@5: 100.0000 (98.1515)  time: 0.3444  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2200/3125]  eta: 0:05:18  Lr: 0.001875  Loss: 0.3195  Acc@1: 87.5000 (84.9358)  Acc@5: 100.0000 (98.1486)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:14  Lr: 0.001875  Loss: 0.2682  Acc@1: 87.5000 (84.9474)  Acc@5: 100.0000 (98.1541)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:11  Lr: 0.001875  Loss: 0.4198  Acc@1: 87.5000 (84.9589)  Acc@5: 100.0000 (98.1596)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:08  Lr: 0.001875  Loss: 0.7758  Acc@1: 87.5000 (84.9675)  Acc@5: 100.0000 (98.1651)  time: 0.3451  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:04  Lr: 0.001875  Loss: 0.3667  Acc@1: 87.5000 (84.9816)  Acc@5: 100.0000 (98.1649)  time: 0.3450  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:01  Lr: 0.001875  Loss: 0.5351  Acc@1: 87.5000 (84.9817)  Acc@5: 100.0000 (98.1592)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2260/3125]  eta: 0:04:57  Lr: 0.001875  Loss: 0.5069  Acc@1: 87.5000 (85.0066)  Acc@5: 100.0000 (98.1645)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2270/3125]  eta: 0:04:54  Lr: 0.001875  Loss: 0.6228  Acc@1: 87.5000 (85.0094)  Acc@5: 100.0000 (98.1644)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2280/3125]  eta: 0:04:50  Lr: 0.001875  Loss: 0.4728  Acc@1: 87.5000 (85.0285)  Acc@5: 100.0000 (98.1669)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2290/3125]  eta: 0:04:47  Lr: 0.001875  Loss: 0.2202  Acc@1: 87.5000 (85.0311)  Acc@5: 100.0000 (98.1695)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2300/3125]  eta: 0:04:43  Lr: 0.001875  Loss: 0.4143  Acc@1: 81.2500 (85.0201)  Acc@5: 100.0000 (98.1666)  time: 0.3437  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2310/3125]  eta: 0:04:40  Lr: 0.001875  Loss: 0.5979  Acc@1: 87.5000 (85.0281)  Acc@5: 100.0000 (98.1664)  time: 0.3439  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2320/3125]  eta: 0:04:37  Lr: 0.001875  Loss: 0.1699  Acc@1: 81.2500 (84.9903)  Acc@5: 100.0000 (98.1662)  time: 0.3438  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2330/3125]  eta: 0:04:33  Lr: 0.001875  Loss: 0.1064  Acc@1: 81.2500 (84.9984)  Acc@5: 100.0000 (98.1741)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2340/3125]  eta: 0:04:30  Lr: 0.001875  Loss: 0.0771  Acc@1: 87.5000 (85.0198)  Acc@5: 100.0000 (98.1792)  time: 0.3447  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2350/3125]  eta: 0:04:26  Lr: 0.001875  Loss: 0.3072  Acc@1: 93.7500 (85.0356)  Acc@5: 100.0000 (98.1816)  time: 0.3449  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:23  Lr: 0.001875  Loss: 0.2320  Acc@1: 81.2500 (85.0222)  Acc@5: 100.0000 (98.1734)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:19  Lr: 0.001875  Loss: 0.5909  Acc@1: 81.2500 (85.0116)  Acc@5: 100.0000 (98.1759)  time: 0.3451  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:16  Lr: 0.001875  Loss: 0.2469  Acc@1: 81.2500 (85.0115)  Acc@5: 100.0000 (98.1730)  time: 0.3453  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:13  Lr: 0.001875  Loss: 0.2388  Acc@1: 87.5000 (85.0167)  Acc@5: 100.0000 (98.1728)  time: 0.3453  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:09  Lr: 0.001875  Loss: 0.1054  Acc@1: 87.5000 (85.0141)  Acc@5: 100.0000 (98.1778)  time: 0.3457  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:06  Lr: 0.001875  Loss: 0.2169  Acc@1: 87.5000 (85.0140)  Acc@5: 100.0000 (98.1750)  time: 0.3452  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:02  Lr: 0.001875  Loss: 0.4699  Acc@1: 87.5000 (85.0243)  Acc@5: 100.0000 (98.1800)  time: 0.3454  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2430/3125]  eta: 0:03:59  Lr: 0.001875  Loss: 0.9096  Acc@1: 87.5000 (85.0036)  Acc@5: 100.0000 (98.1849)  time: 0.3455  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2440/3125]  eta: 0:03:55  Lr: 0.001875  Loss: 0.7293  Acc@1: 81.2500 (84.9754)  Acc@5: 100.0000 (98.1872)  time: 0.3459  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2450/3125]  eta: 0:03:52  Lr: 0.001875  Loss: 0.3491  Acc@1: 81.2500 (84.9755)  Acc@5: 100.0000 (98.1921)  time: 0.3462  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2460/3125]  eta: 0:03:48  Lr: 0.001875  Loss: 0.1747  Acc@1: 81.2500 (84.9502)  Acc@5: 100.0000 (98.1893)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2470/3125]  eta: 0:03:45  Lr: 0.001875  Loss: 0.6635  Acc@1: 81.2500 (84.9580)  Acc@5: 100.0000 (98.1865)  time: 0.3459  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2480/3125]  eta: 0:03:42  Lr: 0.001875  Loss: 0.9861  Acc@1: 87.5000 (84.9632)  Acc@5: 100.0000 (98.1812)  time: 0.3459  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2490/3125]  eta: 0:03:38  Lr: 0.001875  Loss: 0.4969  Acc@1: 87.5000 (84.9558)  Acc@5: 100.0000 (98.1810)  time: 0.3450  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2500/3125]  eta: 0:03:35  Lr: 0.001875  Loss: 0.6099  Acc@1: 87.5000 (84.9685)  Acc@5: 100.0000 (98.1807)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2510/3125]  eta: 0:03:31  Lr: 0.001875  Loss: 0.3892  Acc@1: 87.5000 (84.9587)  Acc@5: 100.0000 (98.1755)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:28  Lr: 0.001875  Loss: 0.3115  Acc@1: 81.2500 (84.9539)  Acc@5: 100.0000 (98.1828)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:24  Lr: 0.001875  Loss: 0.5965  Acc@1: 81.2500 (84.9615)  Acc@5: 100.0000 (98.1801)  time: 0.3446  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:21  Lr: 0.001875  Loss: 0.3028  Acc@1: 87.5000 (84.9690)  Acc@5: 93.7500 (98.1700)  time: 0.3457  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:17  Lr: 0.001875  Loss: 0.6212  Acc@1: 87.5000 (84.9716)  Acc@5: 93.7500 (98.1674)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:14  Lr: 0.001875  Loss: 0.0440  Acc@1: 87.5000 (84.9961)  Acc@5: 100.0000 (98.1697)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:11  Lr: 0.001875  Loss: 0.3611  Acc@1: 87.5000 (85.0107)  Acc@5: 100.0000 (98.1695)  time: 0.3450  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:07  Lr: 0.001875  Loss: 0.3358  Acc@1: 93.7500 (85.0373)  Acc@5: 100.0000 (98.1742)  time: 0.3451  data: 0.0020  max mem: 2501
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:04  Lr: 0.001875  Loss: 0.6445  Acc@1: 87.5000 (85.0396)  Acc@5: 100.0000 (98.1716)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:00  Lr: 0.001875  Loss: 0.1478  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (98.1738)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2610/3125]  eta: 0:02:57  Lr: 0.001875  Loss: 0.3887  Acc@1: 87.5000 (85.0680)  Acc@5: 100.0000 (98.1784)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2620/3125]  eta: 0:02:53  Lr: 0.001875  Loss: 0.1044  Acc@1: 87.5000 (85.0534)  Acc@5: 100.0000 (98.1734)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2630/3125]  eta: 0:02:50  Lr: 0.001875  Loss: 0.3957  Acc@1: 81.2500 (85.0508)  Acc@5: 100.0000 (98.1756)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2640/3125]  eta: 0:02:46  Lr: 0.001875  Loss: 0.1092  Acc@1: 81.2500 (85.0506)  Acc@5: 100.0000 (98.1707)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2650/3125]  eta: 0:02:43  Lr: 0.001875  Loss: 0.8397  Acc@1: 81.2500 (85.0363)  Acc@5: 100.0000 (98.1658)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2660/3125]  eta: 0:02:40  Lr: 0.001875  Loss: 0.1070  Acc@1: 87.5000 (85.0503)  Acc@5: 100.0000 (98.1633)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:36  Lr: 0.001875  Loss: 0.7845  Acc@1: 87.5000 (85.0431)  Acc@5: 100.0000 (98.1631)  time: 0.3435  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1949  Acc@1: 87.5000 (85.0592)  Acc@5: 100.0000 (98.1560)  time: 0.3449  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:29  Lr: 0.001875  Loss: 0.7167  Acc@1: 87.5000 (85.0427)  Acc@5: 93.7500 (98.1512)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:26  Lr: 0.001875  Loss: 0.5765  Acc@1: 81.2500 (85.0403)  Acc@5: 100.0000 (98.1488)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:22  Lr: 0.001875  Loss: 0.5113  Acc@1: 81.2500 (85.0309)  Acc@5: 100.0000 (98.1487)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1732  Acc@1: 81.2500 (85.0354)  Acc@5: 100.0000 (98.1533)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:15  Lr: 0.001875  Loss: 0.2064  Acc@1: 87.5000 (85.0444)  Acc@5: 100.0000 (98.1554)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:12  Lr: 0.001875  Loss: 0.4962  Acc@1: 81.2500 (85.0328)  Acc@5: 100.0000 (98.1576)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:09  Lr: 0.001875  Loss: 0.8494  Acc@1: 81.2500 (85.0259)  Acc@5: 100.0000 (98.1620)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:05  Lr: 0.001875  Loss: 0.7051  Acc@1: 81.2500 (85.0190)  Acc@5: 100.0000 (98.1551)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:02  Lr: 0.001875  Loss: 0.0248  Acc@1: 87.5000 (85.0302)  Acc@5: 100.0000 (98.1595)  time: 0.3444  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2780/3125]  eta: 0:01:58  Lr: 0.001875  Loss: 0.4458  Acc@1: 87.5000 (85.0503)  Acc@5: 100.0000 (98.1639)  time: 0.3449  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2790/3125]  eta: 0:01:55  Lr: 0.001875  Loss: 0.4123  Acc@1: 87.5000 (85.0457)  Acc@5: 100.0000 (98.1615)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2800/3125]  eta: 0:01:51  Lr: 0.001875  Loss: 0.7274  Acc@1: 87.5000 (85.0500)  Acc@5: 100.0000 (98.1591)  time: 0.3448  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2810/3125]  eta: 0:01:48  Lr: 0.001875  Loss: 0.1803  Acc@1: 81.2500 (85.0476)  Acc@5: 100.0000 (98.1635)  time: 0.3440  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:45  Lr: 0.001875  Loss: 0.0487  Acc@1: 81.2500 (85.0563)  Acc@5: 100.0000 (98.1655)  time: 0.3449  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:41  Lr: 0.001875  Loss: 0.1272  Acc@1: 87.5000 (85.0583)  Acc@5: 100.0000 (98.1632)  time: 0.3450  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:38  Lr: 0.001875  Loss: 0.2847  Acc@1: 87.5000 (85.0625)  Acc@5: 100.0000 (98.1675)  time: 0.3448  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:34  Lr: 0.001875  Loss: 0.7137  Acc@1: 81.2500 (85.0579)  Acc@5: 100.0000 (98.1695)  time: 0.3448  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:31  Lr: 0.001875  Loss: 0.7434  Acc@1: 81.2500 (85.0577)  Acc@5: 100.0000 (98.1715)  time: 0.3434  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:27  Lr: 0.001875  Loss: 0.5888  Acc@1: 81.2500 (85.0401)  Acc@5: 100.0000 (98.1692)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:24  Lr: 0.001875  Loss: 0.8567  Acc@1: 87.5000 (85.0486)  Acc@5: 100.0000 (98.1712)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:20  Lr: 0.001875  Loss: 0.6361  Acc@1: 87.5000 (85.0441)  Acc@5: 100.0000 (98.1710)  time: 0.3426  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:17  Lr: 0.001875  Loss: 0.5146  Acc@1: 81.2500 (85.0375)  Acc@5: 100.0000 (98.1709)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:14  Lr: 0.001875  Loss: 0.0777  Acc@1: 87.5000 (85.0417)  Acc@5: 100.0000 (98.1729)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:10  Lr: 0.001875  Loss: 0.2673  Acc@1: 87.5000 (85.0479)  Acc@5: 100.0000 (98.1727)  time: 0.3439  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:07  Lr: 0.001875  Loss: 0.6326  Acc@1: 87.5000 (85.0414)  Acc@5: 100.0000 (98.1704)  time: 0.3435  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:03  Lr: 0.001875  Loss: 0.8690  Acc@1: 87.5000 (85.0476)  Acc@5: 100.0000 (98.1703)  time: 0.3430  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:00  Lr: 0.001875  Loss: 0.4536  Acc@1: 87.5000 (85.0538)  Acc@5: 100.0000 (98.1701)  time: 0.3436  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2960/3125]  eta: 0:00:56  Lr: 0.001875  Loss: 0.5805  Acc@1: 87.5000 (85.0452)  Acc@5: 100.0000 (98.1678)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [2970/3125]  eta: 0:00:53  Lr: 0.001875  Loss: 0.4393  Acc@1: 81.2500 (85.0429)  Acc@5: 100.0000 (98.1635)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:49  Lr: 0.001875  Loss: 1.0943  Acc@1: 87.5000 (85.0428)  Acc@5: 100.0000 (98.1613)  time: 0.3439  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:46  Lr: 0.001875  Loss: 0.2958  Acc@1: 87.5000 (85.0384)  Acc@5: 100.0000 (98.1632)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: 0.3978  Acc@1: 87.5000 (85.0425)  Acc@5: 100.0000 (98.1694)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:39  Lr: 0.001875  Loss: 0.5488  Acc@1: 81.2500 (85.0195)  Acc@5: 100.0000 (98.1630)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: 0.6541  Acc@1: 81.2500 (85.0339)  Acc@5: 100.0000 (98.1629)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1889  Acc@1: 87.5000 (85.0338)  Acc@5: 100.0000 (98.1586)  time: 0.3444  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: 0.9489  Acc@1: 87.5000 (85.0419)  Acc@5: 100.0000 (98.1585)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:25  Lr: 0.001875  Loss: 0.2801  Acc@1: 87.5000 (85.0418)  Acc@5: 100.0000 (98.1563)  time: 0.3424  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: 0.3306  Acc@1: 81.2500 (85.0396)  Acc@5: 100.0000 (98.1562)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:18  Lr: 0.001875  Loss: 0.5068  Acc@1: 87.5000 (85.0374)  Acc@5: 100.0000 (98.1582)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: 0.5173  Acc@1: 87.5000 (85.0394)  Acc@5: 100.0000 (98.1540)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: 0.7390  Acc@1: 87.5000 (85.0291)  Acc@5: 100.0000 (98.1499)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4352  Acc@1: 81.2500 (85.0210)  Acc@5: 100.0000 (98.1498)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: 0.3369  Acc@1: 81.2500 (85.0209)  Acc@5: 100.0000 (98.1537)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: 0.7260  Acc@1: 81.2500 (85.0168)  Acc@5: 100.0000 (98.1536)  time: 0.3430  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6259  Acc@1: 81.2500 (85.0060)  Acc@5: 100.0000 (98.1520)  time: 0.3430  data: 0.0005  max mem: 2501
Train: Epoch[2/5] Total time: 0:17:56 (0.3444 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.6259  Acc@1: 81.2500 (85.0060)  Acc@5: 100.0000 (98.1520)
Train: Epoch[3/5]  [   0/3125]  eta: 0:31:32  Lr: 0.001875  Loss: 0.3390  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6056  data: 0.2363  max mem: 2501
Train: Epoch[3/5]  [  10/3125]  eta: 0:19:05  Lr: 0.001875  Loss: 0.3001  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.8636)  time: 0.3678  data: 0.0220  max mem: 2501
Train: Epoch[3/5]  [  20/3125]  eta: 0:18:24  Lr: 0.001875  Loss: 0.1910  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (99.1071)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [  30/3125]  eta: 0:18:09  Lr: 0.001875  Loss: 0.4674  Acc@1: 87.5000 (84.8790)  Acc@5: 100.0000 (98.3871)  time: 0.3433  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [  40/3125]  eta: 0:17:59  Lr: 0.001875  Loss: 0.1897  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (98.6280)  time: 0.3440  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [  50/3125]  eta: 0:17:51  Lr: 0.001875  Loss: 0.5871  Acc@1: 87.5000 (85.2941)  Acc@5: 100.0000 (98.6520)  time: 0.3428  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [  60/3125]  eta: 0:17:45  Lr: 0.001875  Loss: 0.3785  Acc@1: 87.5000 (85.6557)  Acc@5: 100.0000 (98.6680)  time: 0.3428  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [  70/3125]  eta: 0:17:40  Lr: 0.001875  Loss: 0.2346  Acc@1: 81.2500 (85.1232)  Acc@5: 100.0000 (98.5035)  time: 0.3433  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [  80/3125]  eta: 0:17:35  Lr: 0.001875  Loss: 0.9563  Acc@1: 81.2500 (85.1852)  Acc@5: 100.0000 (98.2253)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [  90/3125]  eta: 0:17:30  Lr: 0.001875  Loss: 0.4897  Acc@1: 81.2500 (85.0275)  Acc@5: 100.0000 (98.4203)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 100/3125]  eta: 0:17:26  Lr: 0.001875  Loss: 0.2963  Acc@1: 87.5000 (85.3960)  Acc@5: 100.0000 (98.4530)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 110/3125]  eta: 0:17:22  Lr: 0.001875  Loss: 0.4672  Acc@1: 87.5000 (85.5856)  Acc@5: 100.0000 (98.5360)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 120/3125]  eta: 0:17:18  Lr: 0.001875  Loss: 0.2645  Acc@1: 81.2500 (85.4339)  Acc@5: 100.0000 (98.5021)  time: 0.3428  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 130/3125]  eta: 0:17:14  Lr: 0.001875  Loss: 0.3578  Acc@1: 81.2500 (85.4962)  Acc@5: 100.0000 (98.4733)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 140/3125]  eta: 0:17:10  Lr: 0.001875  Loss: 0.1705  Acc@1: 87.5000 (85.5496)  Acc@5: 100.0000 (98.4929)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 150/3125]  eta: 0:17:07  Lr: 0.001875  Loss: 0.4229  Acc@1: 87.5000 (85.3063)  Acc@5: 100.0000 (98.5513)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 160/3125]  eta: 0:17:03  Lr: 0.001875  Loss: 0.2321  Acc@1: 87.5000 (85.4814)  Acc@5: 100.0000 (98.5248)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 170/3125]  eta: 0:16:59  Lr: 0.001875  Loss: 0.1660  Acc@1: 87.5000 (85.5263)  Acc@5: 100.0000 (98.4649)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 180/3125]  eta: 0:16:55  Lr: 0.001875  Loss: 0.4852  Acc@1: 87.5000 (85.6008)  Acc@5: 100.0000 (98.5152)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 190/3125]  eta: 0:16:52  Lr: 0.001875  Loss: 0.1206  Acc@1: 87.5000 (85.8312)  Acc@5: 100.0000 (98.5275)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 200/3125]  eta: 0:16:49  Lr: 0.001875  Loss: 0.3191  Acc@1: 87.5000 (86.0697)  Acc@5: 100.0000 (98.5386)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 210/3125]  eta: 0:16:45  Lr: 0.001875  Loss: 0.4129  Acc@1: 87.5000 (86.0782)  Acc@5: 100.0000 (98.5782)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 220/3125]  eta: 0:16:42  Lr: 0.001875  Loss: 0.4113  Acc@1: 87.5000 (86.1991)  Acc@5: 100.0000 (98.6143)  time: 0.3450  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 230/3125]  eta: 0:16:38  Lr: 0.001875  Loss: 0.5186  Acc@1: 87.5000 (86.0390)  Acc@5: 100.0000 (98.6201)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 240/3125]  eta: 0:16:35  Lr: 0.001875  Loss: 0.0989  Acc@1: 87.5000 (86.0737)  Acc@5: 100.0000 (98.5218)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 250/3125]  eta: 0:16:31  Lr: 0.001875  Loss: 0.6357  Acc@1: 87.5000 (86.1803)  Acc@5: 100.0000 (98.5060)  time: 0.3438  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 260/3125]  eta: 0:16:28  Lr: 0.001875  Loss: 0.6109  Acc@1: 87.5000 (86.1830)  Acc@5: 100.0000 (98.4674)  time: 0.3451  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 270/3125]  eta: 0:16:24  Lr: 0.001875  Loss: 0.5523  Acc@1: 81.2500 (86.0701)  Acc@5: 100.0000 (98.3856)  time: 0.3456  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 280/3125]  eta: 0:16:21  Lr: 0.001875  Loss: 0.5066  Acc@1: 87.5000 (86.0543)  Acc@5: 100.0000 (98.3763)  time: 0.3450  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 290/3125]  eta: 0:16:17  Lr: 0.001875  Loss: 0.5450  Acc@1: 87.5000 (85.9966)  Acc@5: 100.0000 (98.3892)  time: 0.3445  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 300/3125]  eta: 0:16:14  Lr: 0.001875  Loss: 0.6627  Acc@1: 87.5000 (85.8804)  Acc@5: 100.0000 (98.3389)  time: 0.3432  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 310/3125]  eta: 0:16:10  Lr: 0.001875  Loss: 0.8414  Acc@1: 87.5000 (85.8521)  Acc@5: 100.0000 (98.3722)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 320/3125]  eta: 0:16:07  Lr: 0.001875  Loss: 0.4286  Acc@1: 87.5000 (85.8450)  Acc@5: 100.0000 (98.3840)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 330/3125]  eta: 0:16:03  Lr: 0.001875  Loss: 0.4302  Acc@1: 87.5000 (85.8384)  Acc@5: 100.0000 (98.3950)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 340/3125]  eta: 0:16:00  Lr: 0.001875  Loss: 0.3642  Acc@1: 87.5000 (85.7405)  Acc@5: 100.0000 (98.4238)  time: 0.3451  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 350/3125]  eta: 0:15:56  Lr: 0.001875  Loss: 0.8612  Acc@1: 81.2500 (85.5413)  Acc@5: 100.0000 (98.4330)  time: 0.3442  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 360/3125]  eta: 0:15:53  Lr: 0.001875  Loss: 0.3217  Acc@1: 81.2500 (85.4571)  Acc@5: 100.0000 (98.4245)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 370/3125]  eta: 0:15:49  Lr: 0.001875  Loss: 0.7250  Acc@1: 87.5000 (85.5795)  Acc@5: 100.0000 (98.3996)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 380/3125]  eta: 0:15:46  Lr: 0.001875  Loss: 0.1107  Acc@1: 87.5000 (85.6627)  Acc@5: 100.0000 (98.3924)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 390/3125]  eta: 0:15:42  Lr: 0.001875  Loss: 0.4847  Acc@1: 87.5000 (85.6298)  Acc@5: 100.0000 (98.4175)  time: 0.3444  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 400/3125]  eta: 0:15:39  Lr: 0.001875  Loss: 0.3912  Acc@1: 81.2500 (85.4894)  Acc@5: 100.0000 (98.4258)  time: 0.3439  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 410/3125]  eta: 0:15:35  Lr: 0.001875  Loss: 0.2229  Acc@1: 87.5000 (85.4927)  Acc@5: 100.0000 (98.4337)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 420/3125]  eta: 0:15:32  Lr: 0.001875  Loss: 0.5867  Acc@1: 87.5000 (85.5404)  Acc@5: 100.0000 (98.4709)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 430/3125]  eta: 0:15:28  Lr: 0.001875  Loss: 0.5384  Acc@1: 87.5000 (85.4553)  Acc@5: 100.0000 (98.4484)  time: 0.3437  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 440/3125]  eta: 0:15:25  Lr: 0.001875  Loss: 0.4633  Acc@1: 81.2500 (85.5017)  Acc@5: 100.0000 (98.4410)  time: 0.3439  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 450/3125]  eta: 0:15:21  Lr: 0.001875  Loss: 0.5470  Acc@1: 81.2500 (85.5044)  Acc@5: 100.0000 (98.4618)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 460/3125]  eta: 0:15:18  Lr: 0.001875  Loss: 0.1177  Acc@1: 87.5000 (85.5884)  Acc@5: 100.0000 (98.4680)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 470/3125]  eta: 0:15:14  Lr: 0.001875  Loss: 0.3180  Acc@1: 87.5000 (85.6290)  Acc@5: 100.0000 (98.5005)  time: 0.3441  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 480/3125]  eta: 0:15:11  Lr: 0.001875  Loss: 0.6517  Acc@1: 87.5000 (85.6939)  Acc@5: 100.0000 (98.5057)  time: 0.3446  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [ 490/3125]  eta: 0:15:08  Lr: 0.001875  Loss: 0.2965  Acc@1: 87.5000 (85.7561)  Acc@5: 100.0000 (98.5234)  time: 0.3460  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [ 500/3125]  eta: 0:15:04  Lr: 0.001875  Loss: 0.3867  Acc@1: 87.5000 (85.8283)  Acc@5: 100.0000 (98.5404)  time: 0.3469  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [ 510/3125]  eta: 0:15:01  Lr: 0.001875  Loss: 0.2740  Acc@1: 87.5000 (85.8488)  Acc@5: 100.0000 (98.5445)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 520/3125]  eta: 0:14:57  Lr: 0.001875  Loss: 0.5206  Acc@1: 87.5000 (85.8445)  Acc@5: 100.0000 (98.5605)  time: 0.3431  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 530/3125]  eta: 0:14:54  Lr: 0.001875  Loss: 0.8751  Acc@1: 81.2500 (85.7815)  Acc@5: 100.0000 (98.5523)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 540/3125]  eta: 0:14:50  Lr: 0.001875  Loss: 0.4062  Acc@1: 81.2500 (85.7440)  Acc@5: 100.0000 (98.5328)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 550/3125]  eta: 0:14:47  Lr: 0.001875  Loss: 0.5212  Acc@1: 81.2500 (85.7305)  Acc@5: 100.0000 (98.5481)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 560/3125]  eta: 0:14:43  Lr: 0.001875  Loss: 0.7156  Acc@1: 81.2500 (85.6506)  Acc@5: 100.0000 (98.5294)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 570/3125]  eta: 0:14:40  Lr: 0.001875  Loss: 0.4234  Acc@1: 87.5000 (85.7377)  Acc@5: 100.0000 (98.5442)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 580/3125]  eta: 0:14:36  Lr: 0.001875  Loss: 0.1767  Acc@1: 87.5000 (85.7573)  Acc@5: 100.0000 (98.5585)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 590/3125]  eta: 0:14:33  Lr: 0.001875  Loss: 0.1542  Acc@1: 87.5000 (85.7657)  Acc@5: 100.0000 (98.5512)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 600/3125]  eta: 0:14:29  Lr: 0.001875  Loss: 0.2574  Acc@1: 87.5000 (85.7841)  Acc@5: 100.0000 (98.5545)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 610/3125]  eta: 0:14:26  Lr: 0.001875  Loss: 0.0685  Acc@1: 87.5000 (85.7917)  Acc@5: 100.0000 (98.5679)  time: 0.3453  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [ 620/3125]  eta: 0:14:23  Lr: 0.001875  Loss: 0.1975  Acc@1: 87.5000 (85.7689)  Acc@5: 100.0000 (98.5709)  time: 0.3448  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [ 630/3125]  eta: 0:14:19  Lr: 0.001875  Loss: 0.5206  Acc@1: 81.2500 (85.7270)  Acc@5: 100.0000 (98.5440)  time: 0.3435  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 640/3125]  eta: 0:14:15  Lr: 0.001875  Loss: 1.5330  Acc@1: 81.2500 (85.6864)  Acc@5: 100.0000 (98.5374)  time: 0.3428  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 650/3125]  eta: 0:14:12  Lr: 0.001875  Loss: 0.1565  Acc@1: 87.5000 (85.6759)  Acc@5: 100.0000 (98.5503)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 660/3125]  eta: 0:14:09  Lr: 0.001875  Loss: 0.7292  Acc@1: 87.5000 (85.7413)  Acc@5: 100.0000 (98.5344)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 670/3125]  eta: 0:14:05  Lr: 0.001875  Loss: 0.1158  Acc@1: 81.2500 (85.7489)  Acc@5: 100.0000 (98.5283)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 680/3125]  eta: 0:14:02  Lr: 0.001875  Loss: 0.6869  Acc@1: 81.2500 (85.7379)  Acc@5: 100.0000 (98.5407)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 690/3125]  eta: 0:13:58  Lr: 0.001875  Loss: 0.1804  Acc@1: 87.5000 (85.7543)  Acc@5: 100.0000 (98.5347)  time: 0.3421  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 700/3125]  eta: 0:13:55  Lr: 0.001875  Loss: 0.1744  Acc@1: 87.5000 (85.7257)  Acc@5: 100.0000 (98.5467)  time: 0.3435  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 710/3125]  eta: 0:13:51  Lr: 0.001875  Loss: 0.4244  Acc@1: 87.5000 (85.7683)  Acc@5: 100.0000 (98.5408)  time: 0.3441  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 720/3125]  eta: 0:13:48  Lr: 0.001875  Loss: 0.7119  Acc@1: 87.5000 (85.8010)  Acc@5: 100.0000 (98.5610)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 730/3125]  eta: 0:13:44  Lr: 0.001875  Loss: 0.1338  Acc@1: 87.5000 (85.8841)  Acc@5: 100.0000 (98.5636)  time: 0.3428  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 740/3125]  eta: 0:13:41  Lr: 0.001875  Loss: 0.4201  Acc@1: 87.5000 (85.8974)  Acc@5: 100.0000 (98.5661)  time: 0.3431  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 750/3125]  eta: 0:13:37  Lr: 0.001875  Loss: 0.2826  Acc@1: 87.5000 (85.9354)  Acc@5: 100.0000 (98.5603)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 760/3125]  eta: 0:13:34  Lr: 0.001875  Loss: 0.2318  Acc@1: 87.5000 (85.8903)  Acc@5: 100.0000 (98.5545)  time: 0.3437  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 770/3125]  eta: 0:13:30  Lr: 0.001875  Loss: 0.4480  Acc@1: 87.5000 (85.8868)  Acc@5: 100.0000 (98.5652)  time: 0.3437  data: 0.0016  max mem: 2501
Train: Epoch[3/5]  [ 780/3125]  eta: 0:13:27  Lr: 0.001875  Loss: 0.3588  Acc@1: 87.5000 (85.8915)  Acc@5: 100.0000 (98.5755)  time: 0.3437  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [ 790/3125]  eta: 0:13:24  Lr: 0.001875  Loss: 0.3381  Acc@1: 87.5000 (85.9197)  Acc@5: 100.0000 (98.5777)  time: 0.3447  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 800/3125]  eta: 0:13:20  Lr: 0.001875  Loss: 0.1454  Acc@1: 87.5000 (85.9238)  Acc@5: 100.0000 (98.5331)  time: 0.3446  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 810/3125]  eta: 0:13:17  Lr: 0.001875  Loss: 0.0902  Acc@1: 87.5000 (85.9279)  Acc@5: 100.0000 (98.5281)  time: 0.3438  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 820/3125]  eta: 0:13:13  Lr: 0.001875  Loss: 0.4720  Acc@1: 87.5000 (85.9394)  Acc@5: 100.0000 (98.5308)  time: 0.3442  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 830/3125]  eta: 0:13:10  Lr: 0.001875  Loss: 0.9473  Acc@1: 87.5000 (85.9807)  Acc@5: 100.0000 (98.5334)  time: 0.3449  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 840/3125]  eta: 0:13:06  Lr: 0.001875  Loss: 0.4970  Acc@1: 87.5000 (86.0211)  Acc@5: 100.0000 (98.5285)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 850/3125]  eta: 0:13:03  Lr: 0.001875  Loss: 0.6013  Acc@1: 87.5000 (86.0311)  Acc@5: 100.0000 (98.5311)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 860/3125]  eta: 0:12:59  Lr: 0.001875  Loss: 0.4047  Acc@1: 81.2500 (85.9974)  Acc@5: 100.0000 (98.5337)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 870/3125]  eta: 0:12:56  Lr: 0.001875  Loss: 0.3319  Acc@1: 87.5000 (86.0146)  Acc@5: 100.0000 (98.5290)  time: 0.3440  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 880/3125]  eta: 0:12:53  Lr: 0.001875  Loss: 0.1574  Acc@1: 87.5000 (86.0670)  Acc@5: 100.0000 (98.5244)  time: 0.3448  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 890/3125]  eta: 0:12:49  Lr: 0.001875  Loss: 0.3561  Acc@1: 87.5000 (86.0971)  Acc@5: 100.0000 (98.5340)  time: 0.3456  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 900/3125]  eta: 0:12:46  Lr: 0.001875  Loss: 0.5052  Acc@1: 87.5000 (86.1335)  Acc@5: 100.0000 (98.5433)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 910/3125]  eta: 0:12:42  Lr: 0.001875  Loss: 0.3420  Acc@1: 87.5000 (86.1553)  Acc@5: 100.0000 (98.5387)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 920/3125]  eta: 0:12:39  Lr: 0.001875  Loss: 0.8502  Acc@1: 87.5000 (86.1631)  Acc@5: 100.0000 (98.5342)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 930/3125]  eta: 0:12:35  Lr: 0.001875  Loss: 0.0204  Acc@1: 87.5000 (86.1976)  Acc@5: 100.0000 (98.5231)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 940/3125]  eta: 0:12:32  Lr: 0.001875  Loss: 0.7282  Acc@1: 87.5000 (86.1583)  Acc@5: 100.0000 (98.5056)  time: 0.3449  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 950/3125]  eta: 0:12:29  Lr: 0.001875  Loss: 0.2191  Acc@1: 81.2500 (86.1593)  Acc@5: 100.0000 (98.4950)  time: 0.3458  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [ 960/3125]  eta: 0:12:25  Lr: 0.001875  Loss: 0.5943  Acc@1: 81.2500 (86.1472)  Acc@5: 100.0000 (98.4847)  time: 0.3457  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 970/3125]  eta: 0:12:22  Lr: 0.001875  Loss: 0.2288  Acc@1: 87.5000 (86.1740)  Acc@5: 100.0000 (98.4874)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 980/3125]  eta: 0:12:18  Lr: 0.001875  Loss: 0.6296  Acc@1: 87.5000 (86.1430)  Acc@5: 100.0000 (98.4901)  time: 0.3450  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 990/3125]  eta: 0:12:15  Lr: 0.001875  Loss: 0.1542  Acc@1: 81.2500 (86.1251)  Acc@5: 100.0000 (98.4864)  time: 0.3459  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1000/3125]  eta: 0:12:11  Lr: 0.001875  Loss: 0.5118  Acc@1: 87.5000 (86.1451)  Acc@5: 100.0000 (98.4953)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1010/3125]  eta: 0:12:08  Lr: 0.001875  Loss: 1.1585  Acc@1: 87.5000 (86.0720)  Acc@5: 100.0000 (98.4792)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1020/3125]  eta: 0:12:04  Lr: 0.001875  Loss: 0.5926  Acc@1: 81.2500 (86.0186)  Acc@5: 100.0000 (98.4696)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1030/3125]  eta: 0:12:01  Lr: 0.001875  Loss: 0.6016  Acc@1: 81.2500 (86.0330)  Acc@5: 100.0000 (98.4784)  time: 0.3445  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1040/3125]  eta: 0:11:58  Lr: 0.001875  Loss: 0.3408  Acc@1: 87.5000 (86.0711)  Acc@5: 100.0000 (98.4870)  time: 0.3442  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1050/3125]  eta: 0:11:54  Lr: 0.001875  Loss: 0.4053  Acc@1: 87.5000 (86.1085)  Acc@5: 100.0000 (98.4836)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1060/3125]  eta: 0:11:51  Lr: 0.001875  Loss: 0.4456  Acc@1: 87.5000 (86.1275)  Acc@5: 100.0000 (98.4920)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1070/3125]  eta: 0:11:47  Lr: 0.001875  Loss: 0.3739  Acc@1: 87.5000 (86.1461)  Acc@5: 100.0000 (98.4944)  time: 0.3450  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1080/3125]  eta: 0:11:44  Lr: 0.001875  Loss: 0.3258  Acc@1: 87.5000 (86.1760)  Acc@5: 100.0000 (98.4968)  time: 0.3448  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1090/3125]  eta: 0:11:40  Lr: 0.001875  Loss: 0.5425  Acc@1: 87.5000 (86.1824)  Acc@5: 100.0000 (98.4934)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1100/3125]  eta: 0:11:37  Lr: 0.001875  Loss: 0.2540  Acc@1: 87.5000 (86.1887)  Acc@5: 100.0000 (98.4957)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1110/3125]  eta: 0:11:33  Lr: 0.001875  Loss: 0.0908  Acc@1: 87.5000 (86.1780)  Acc@5: 100.0000 (98.4980)  time: 0.3451  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1120/3125]  eta: 0:11:30  Lr: 0.001875  Loss: 0.4362  Acc@1: 87.5000 (86.2065)  Acc@5: 100.0000 (98.5002)  time: 0.3455  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1130/3125]  eta: 0:11:27  Lr: 0.001875  Loss: 0.4718  Acc@1: 87.5000 (86.2124)  Acc@5: 100.0000 (98.5080)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1140/3125]  eta: 0:11:23  Lr: 0.001875  Loss: 0.8719  Acc@1: 87.5000 (86.2018)  Acc@5: 100.0000 (98.4936)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1150/3125]  eta: 0:11:20  Lr: 0.001875  Loss: 0.2872  Acc@1: 87.5000 (86.1805)  Acc@5: 100.0000 (98.4959)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1160/3125]  eta: 0:11:16  Lr: 0.001875  Loss: 0.7403  Acc@1: 87.5000 (86.1649)  Acc@5: 100.0000 (98.4873)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1170/3125]  eta: 0:11:13  Lr: 0.001875  Loss: 0.3681  Acc@1: 81.2500 (86.1497)  Acc@5: 100.0000 (98.4895)  time: 0.3428  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1180/3125]  eta: 0:11:09  Lr: 0.001875  Loss: 0.2160  Acc@1: 87.5000 (86.1770)  Acc@5: 100.0000 (98.4917)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1190/3125]  eta: 0:11:06  Lr: 0.001875  Loss: 0.4130  Acc@1: 87.5000 (86.1776)  Acc@5: 100.0000 (98.4992)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1200/3125]  eta: 0:11:02  Lr: 0.001875  Loss: 0.1871  Acc@1: 87.5000 (86.1678)  Acc@5: 100.0000 (98.5012)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1210/3125]  eta: 0:10:59  Lr: 0.001875  Loss: 0.2876  Acc@1: 81.2500 (86.1117)  Acc@5: 100.0000 (98.4981)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1220/3125]  eta: 0:10:55  Lr: 0.001875  Loss: 0.6057  Acc@1: 81.2500 (86.0872)  Acc@5: 100.0000 (98.5002)  time: 0.3431  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1230/3125]  eta: 0:10:52  Lr: 0.001875  Loss: 0.1789  Acc@1: 87.5000 (86.1444)  Acc@5: 100.0000 (98.5124)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1240/3125]  eta: 0:10:49  Lr: 0.001875  Loss: 0.3357  Acc@1: 87.5000 (86.1201)  Acc@5: 100.0000 (98.5143)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1250/3125]  eta: 0:10:45  Lr: 0.001875  Loss: 0.3236  Acc@1: 87.5000 (86.1311)  Acc@5: 100.0000 (98.5162)  time: 0.3436  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1260/3125]  eta: 0:10:42  Lr: 0.001875  Loss: 0.6931  Acc@1: 87.5000 (86.1469)  Acc@5: 100.0000 (98.5230)  time: 0.3440  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1270/3125]  eta: 0:10:38  Lr: 0.001875  Loss: 0.3397  Acc@1: 87.5000 (86.1920)  Acc@5: 100.0000 (98.5248)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1280/3125]  eta: 0:10:35  Lr: 0.001875  Loss: 0.7803  Acc@1: 87.5000 (86.1632)  Acc@5: 100.0000 (98.5217)  time: 0.3429  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1290/3125]  eta: 0:10:31  Lr: 0.001875  Loss: 0.4118  Acc@1: 87.5000 (86.1832)  Acc@5: 100.0000 (98.5234)  time: 0.3440  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1300/3125]  eta: 0:10:28  Lr: 0.001875  Loss: 0.5300  Acc@1: 87.5000 (86.1837)  Acc@5: 100.0000 (98.5252)  time: 0.3447  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1310/3125]  eta: 0:10:24  Lr: 0.001875  Loss: 0.2992  Acc@1: 81.2500 (86.1747)  Acc@5: 100.0000 (98.5317)  time: 0.3434  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1320/3125]  eta: 0:10:21  Lr: 0.001875  Loss: 0.8080  Acc@1: 87.5000 (86.1611)  Acc@5: 100.0000 (98.5286)  time: 0.3441  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1330/3125]  eta: 0:10:18  Lr: 0.001875  Loss: 0.2306  Acc@1: 81.2500 (86.0772)  Acc@5: 100.0000 (98.5302)  time: 0.3441  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1340/3125]  eta: 0:10:14  Lr: 0.001875  Loss: 0.6494  Acc@1: 81.2500 (86.0925)  Acc@5: 100.0000 (98.5226)  time: 0.3439  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1350/3125]  eta: 0:10:11  Lr: 0.001875  Loss: 0.8129  Acc@1: 87.5000 (86.0798)  Acc@5: 100.0000 (98.5104)  time: 0.3442  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1360/3125]  eta: 0:10:07  Lr: 0.001875  Loss: 0.3655  Acc@1: 87.5000 (86.1086)  Acc@5: 100.0000 (98.5121)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1370/3125]  eta: 0:10:04  Lr: 0.001875  Loss: 1.0568  Acc@1: 87.5000 (86.0914)  Acc@5: 100.0000 (98.5047)  time: 0.3443  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1380/3125]  eta: 0:10:00  Lr: 0.001875  Loss: 0.8388  Acc@1: 87.5000 (86.0925)  Acc@5: 100.0000 (98.5020)  time: 0.3440  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1390/3125]  eta: 0:09:57  Lr: 0.001875  Loss: 0.9089  Acc@1: 87.5000 (86.0981)  Acc@5: 100.0000 (98.4948)  time: 0.3437  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1400/3125]  eta: 0:09:53  Lr: 0.001875  Loss: 0.7659  Acc@1: 81.2500 (86.0948)  Acc@5: 100.0000 (98.4832)  time: 0.3447  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1410/3125]  eta: 0:09:50  Lr: 0.001875  Loss: 0.3662  Acc@1: 87.5000 (86.0870)  Acc@5: 100.0000 (98.4851)  time: 0.3451  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1420/3125]  eta: 0:09:47  Lr: 0.001875  Loss: 0.5840  Acc@1: 87.5000 (86.1013)  Acc@5: 100.0000 (98.4826)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1430/3125]  eta: 0:09:43  Lr: 0.001875  Loss: 0.7181  Acc@1: 87.5000 (86.0631)  Acc@5: 100.0000 (98.4801)  time: 0.3433  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1440/3125]  eta: 0:09:40  Lr: 0.001875  Loss: 0.3244  Acc@1: 81.2500 (86.0514)  Acc@5: 100.0000 (98.4820)  time: 0.3440  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1450/3125]  eta: 0:09:36  Lr: 0.001875  Loss: 0.5655  Acc@1: 81.2500 (86.0398)  Acc@5: 100.0000 (98.4795)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1460/3125]  eta: 0:09:33  Lr: 0.001875  Loss: 0.3370  Acc@1: 87.5000 (86.0412)  Acc@5: 100.0000 (98.4813)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1470/3125]  eta: 0:09:29  Lr: 0.001875  Loss: 0.3561  Acc@1: 87.5000 (86.0512)  Acc@5: 100.0000 (98.4789)  time: 0.3456  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1480/3125]  eta: 0:09:26  Lr: 0.001875  Loss: 0.5887  Acc@1: 87.5000 (86.0441)  Acc@5: 100.0000 (98.4850)  time: 0.3458  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1490/3125]  eta: 0:09:22  Lr: 0.001875  Loss: 0.3153  Acc@1: 81.2500 (86.0287)  Acc@5: 100.0000 (98.4868)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1500/3125]  eta: 0:09:19  Lr: 0.001875  Loss: 0.5563  Acc@1: 87.5000 (86.0301)  Acc@5: 100.0000 (98.4843)  time: 0.3441  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1510/3125]  eta: 0:09:16  Lr: 0.001875  Loss: 0.8105  Acc@1: 81.2500 (85.9985)  Acc@5: 100.0000 (98.4861)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1520/3125]  eta: 0:09:12  Lr: 0.001875  Loss: 0.2221  Acc@1: 87.5000 (86.0330)  Acc@5: 100.0000 (98.4837)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1530/3125]  eta: 0:09:09  Lr: 0.001875  Loss: 0.5512  Acc@1: 87.5000 (86.0467)  Acc@5: 100.0000 (98.4855)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1540/3125]  eta: 0:09:05  Lr: 0.001875  Loss: 0.4189  Acc@1: 87.5000 (86.0440)  Acc@5: 100.0000 (98.4912)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1550/3125]  eta: 0:09:02  Lr: 0.001875  Loss: 0.2088  Acc@1: 87.5000 (86.0534)  Acc@5: 100.0000 (98.5010)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1560/3125]  eta: 0:08:58  Lr: 0.001875  Loss: 0.8826  Acc@1: 87.5000 (86.0186)  Acc@5: 100.0000 (98.4986)  time: 0.3455  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1570/3125]  eta: 0:08:55  Lr: 0.001875  Loss: 0.2538  Acc@1: 81.2500 (86.0081)  Acc@5: 100.0000 (98.4962)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1580/3125]  eta: 0:08:51  Lr: 0.001875  Loss: 0.1804  Acc@1: 87.5000 (86.0096)  Acc@5: 100.0000 (98.4978)  time: 0.3446  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1590/3125]  eta: 0:08:48  Lr: 0.001875  Loss: 0.3922  Acc@1: 87.5000 (86.0072)  Acc@5: 100.0000 (98.4954)  time: 0.3442  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1600/3125]  eta: 0:08:45  Lr: 0.001875  Loss: 0.4138  Acc@1: 87.5000 (86.0283)  Acc@5: 100.0000 (98.4970)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1610/3125]  eta: 0:08:41  Lr: 0.001875  Loss: 0.2829  Acc@1: 87.5000 (86.0413)  Acc@5: 100.0000 (98.5025)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1620/3125]  eta: 0:08:38  Lr: 0.001875  Loss: 0.0675  Acc@1: 87.5000 (86.0618)  Acc@5: 100.0000 (98.5040)  time: 0.3446  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1630/3125]  eta: 0:08:34  Lr: 0.001875  Loss: 0.6451  Acc@1: 81.2500 (86.0592)  Acc@5: 100.0000 (98.4940)  time: 0.3458  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [1640/3125]  eta: 0:08:31  Lr: 0.001875  Loss: 0.5563  Acc@1: 81.2500 (86.0603)  Acc@5: 100.0000 (98.4918)  time: 0.3449  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1650/3125]  eta: 0:08:27  Lr: 0.001875  Loss: 0.8917  Acc@1: 81.2500 (86.0274)  Acc@5: 100.0000 (98.4744)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1660/3125]  eta: 0:08:24  Lr: 0.001875  Loss: 0.6221  Acc@1: 81.2500 (86.0438)  Acc@5: 100.0000 (98.4798)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1670/3125]  eta: 0:08:21  Lr: 0.001875  Loss: 1.3916  Acc@1: 87.5000 (86.0226)  Acc@5: 100.0000 (98.4665)  time: 0.3448  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1680/3125]  eta: 0:08:17  Lr: 0.001875  Loss: 0.2115  Acc@1: 87.5000 (86.0239)  Acc@5: 100.0000 (98.4570)  time: 0.3438  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1690/3125]  eta: 0:08:14  Lr: 0.001875  Loss: 0.5514  Acc@1: 87.5000 (86.0290)  Acc@5: 100.0000 (98.4588)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1700/3125]  eta: 0:08:10  Lr: 0.001875  Loss: 0.6493  Acc@1: 87.5000 (86.0266)  Acc@5: 100.0000 (98.4678)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1710/3125]  eta: 0:08:07  Lr: 0.001875  Loss: 0.6674  Acc@1: 81.2500 (86.0279)  Acc@5: 100.0000 (98.4695)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1720/3125]  eta: 0:08:03  Lr: 0.001875  Loss: 0.3820  Acc@1: 87.5000 (86.0583)  Acc@5: 100.0000 (98.4784)  time: 0.3458  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1730/3125]  eta: 0:08:00  Lr: 0.001875  Loss: 0.2938  Acc@1: 87.5000 (86.0666)  Acc@5: 100.0000 (98.4799)  time: 0.3472  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [1740/3125]  eta: 0:07:56  Lr: 0.001875  Loss: 1.1151  Acc@1: 87.5000 (86.0569)  Acc@5: 100.0000 (98.4815)  time: 0.3450  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1750/3125]  eta: 0:07:53  Lr: 0.001875  Loss: 0.9527  Acc@1: 87.5000 (86.0544)  Acc@5: 100.0000 (98.4759)  time: 0.3444  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1760/3125]  eta: 0:07:50  Lr: 0.001875  Loss: 0.2908  Acc@1: 87.5000 (86.0449)  Acc@5: 100.0000 (98.4668)  time: 0.3449  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1770/3125]  eta: 0:07:46  Lr: 0.001875  Loss: 0.5450  Acc@1: 87.5000 (86.0425)  Acc@5: 100.0000 (98.4684)  time: 0.3451  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1780/3125]  eta: 0:07:43  Lr: 0.001875  Loss: 0.5929  Acc@1: 81.2500 (86.0401)  Acc@5: 100.0000 (98.4700)  time: 0.3453  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1790/3125]  eta: 0:07:39  Lr: 0.001875  Loss: 0.4051  Acc@1: 87.5000 (86.0553)  Acc@5: 100.0000 (98.4715)  time: 0.3443  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1800/3125]  eta: 0:07:36  Lr: 0.001875  Loss: 0.1314  Acc@1: 87.5000 (86.0598)  Acc@5: 100.0000 (98.4696)  time: 0.3436  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1810/3125]  eta: 0:07:32  Lr: 0.001875  Loss: 0.7832  Acc@1: 87.5000 (86.0678)  Acc@5: 100.0000 (98.4677)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1820/3125]  eta: 0:07:29  Lr: 0.001875  Loss: 0.4522  Acc@1: 87.5000 (86.0551)  Acc@5: 100.0000 (98.4590)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1830/3125]  eta: 0:07:25  Lr: 0.001875  Loss: 0.6018  Acc@1: 87.5000 (86.0459)  Acc@5: 100.0000 (98.4674)  time: 0.3461  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1840/3125]  eta: 0:07:22  Lr: 0.001875  Loss: 0.0630  Acc@1: 87.5000 (86.0741)  Acc@5: 100.0000 (98.4723)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1850/3125]  eta: 0:07:19  Lr: 0.001875  Loss: 0.3772  Acc@1: 87.5000 (86.0650)  Acc@5: 100.0000 (98.4738)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1860/3125]  eta: 0:07:15  Lr: 0.001875  Loss: 0.6012  Acc@1: 81.2500 (86.0626)  Acc@5: 100.0000 (98.4618)  time: 0.3429  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1870/3125]  eta: 0:07:12  Lr: 0.001875  Loss: 0.4571  Acc@1: 87.5000 (86.0770)  Acc@5: 100.0000 (98.4667)  time: 0.3445  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1880/3125]  eta: 0:07:08  Lr: 0.001875  Loss: 0.0746  Acc@1: 93.7500 (86.1011)  Acc@5: 100.0000 (98.4716)  time: 0.3445  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1890/3125]  eta: 0:07:05  Lr: 0.001875  Loss: 1.0109  Acc@1: 93.7500 (86.0920)  Acc@5: 100.0000 (98.4631)  time: 0.3427  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:01  Lr: 0.001875  Loss: 0.1625  Acc@1: 87.5000 (86.0961)  Acc@5: 100.0000 (98.4580)  time: 0.3426  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1910/3125]  eta: 0:06:58  Lr: 0.001875  Loss: 0.3159  Acc@1: 87.5000 (86.0806)  Acc@5: 100.0000 (98.4628)  time: 0.3429  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1920/3125]  eta: 0:06:54  Lr: 0.001875  Loss: 0.2114  Acc@1: 87.5000 (86.0977)  Acc@5: 100.0000 (98.4676)  time: 0.3428  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1930/3125]  eta: 0:06:51  Lr: 0.001875  Loss: 0.5634  Acc@1: 87.5000 (86.1050)  Acc@5: 100.0000 (98.4626)  time: 0.3430  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1940/3125]  eta: 0:06:47  Lr: 0.001875  Loss: 0.3232  Acc@1: 81.2500 (86.0896)  Acc@5: 100.0000 (98.4705)  time: 0.3432  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1950/3125]  eta: 0:06:44  Lr: 0.001875  Loss: 0.3918  Acc@1: 87.5000 (86.0969)  Acc@5: 100.0000 (98.4687)  time: 0.3426  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1960/3125]  eta: 0:06:41  Lr: 0.001875  Loss: 0.5640  Acc@1: 87.5000 (86.0817)  Acc@5: 100.0000 (98.4638)  time: 0.3439  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1970/3125]  eta: 0:06:37  Lr: 0.001875  Loss: 0.3337  Acc@1: 87.5000 (86.0984)  Acc@5: 100.0000 (98.4684)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1980/3125]  eta: 0:06:34  Lr: 0.001875  Loss: 0.1474  Acc@1: 87.5000 (86.0992)  Acc@5: 100.0000 (98.4730)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1990/3125]  eta: 0:06:30  Lr: 0.001875  Loss: 0.4367  Acc@1: 87.5000 (86.0811)  Acc@5: 100.0000 (98.4807)  time: 0.3431  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2000/3125]  eta: 0:06:27  Lr: 0.001875  Loss: 0.2225  Acc@1: 87.5000 (86.0820)  Acc@5: 100.0000 (98.4851)  time: 0.3433  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2010/3125]  eta: 0:06:23  Lr: 0.001875  Loss: 0.1400  Acc@1: 81.2500 (86.0673)  Acc@5: 100.0000 (98.4802)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2020/3125]  eta: 0:06:20  Lr: 0.001875  Loss: 0.0664  Acc@1: 87.5000 (86.0867)  Acc@5: 100.0000 (98.4754)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2030/3125]  eta: 0:06:16  Lr: 0.001875  Loss: 0.5310  Acc@1: 87.5000 (86.0937)  Acc@5: 100.0000 (98.4737)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2040/3125]  eta: 0:06:13  Lr: 0.001875  Loss: 0.7142  Acc@1: 87.5000 (86.0914)  Acc@5: 100.0000 (98.4750)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:10  Lr: 0.001875  Loss: 0.3099  Acc@1: 81.2500 (86.0922)  Acc@5: 100.0000 (98.4794)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:06  Lr: 0.001875  Loss: 0.2368  Acc@1: 87.5000 (86.0959)  Acc@5: 100.0000 (98.4746)  time: 0.3447  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:03  Lr: 0.001875  Loss: 0.5953  Acc@1: 87.5000 (86.0967)  Acc@5: 100.0000 (98.4730)  time: 0.3445  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2080/3125]  eta: 0:05:59  Lr: 0.001875  Loss: 0.4419  Acc@1: 81.2500 (86.0824)  Acc@5: 100.0000 (98.4653)  time: 0.3451  data: 0.0018  max mem: 2501
Train: Epoch[3/5]  [2090/3125]  eta: 0:05:56  Lr: 0.001875  Loss: 0.1790  Acc@1: 87.5000 (86.0982)  Acc@5: 100.0000 (98.4726)  time: 0.3450  data: 0.0018  max mem: 2501
Train: Epoch[3/5]  [2100/3125]  eta: 0:05:52  Lr: 0.001875  Loss: 0.4562  Acc@1: 87.5000 (86.0989)  Acc@5: 100.0000 (98.4710)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2110/3125]  eta: 0:05:49  Lr: 0.001875  Loss: 0.5609  Acc@1: 87.5000 (86.0907)  Acc@5: 100.0000 (98.4752)  time: 0.3433  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2120/3125]  eta: 0:05:46  Lr: 0.001875  Loss: 0.7397  Acc@1: 81.2500 (86.0797)  Acc@5: 100.0000 (98.4765)  time: 0.3453  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2130/3125]  eta: 0:05:42  Lr: 0.001875  Loss: 0.4348  Acc@1: 81.2500 (86.0717)  Acc@5: 100.0000 (98.4778)  time: 0.3455  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2140/3125]  eta: 0:05:39  Lr: 0.001875  Loss: 0.7574  Acc@1: 87.5000 (86.0696)  Acc@5: 100.0000 (98.4849)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2150/3125]  eta: 0:05:35  Lr: 0.001875  Loss: 0.4074  Acc@1: 87.5000 (86.0501)  Acc@5: 100.0000 (98.4833)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2160/3125]  eta: 0:05:32  Lr: 0.001875  Loss: 0.3586  Acc@1: 87.5000 (86.0655)  Acc@5: 100.0000 (98.4816)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2170/3125]  eta: 0:05:28  Lr: 0.001875  Loss: 0.3180  Acc@1: 87.5000 (86.0836)  Acc@5: 100.0000 (98.4857)  time: 0.3452  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2180/3125]  eta: 0:05:25  Lr: 0.001875  Loss: 0.3803  Acc@1: 87.5000 (86.0930)  Acc@5: 100.0000 (98.4869)  time: 0.3451  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2190/3125]  eta: 0:05:21  Lr: 0.001875  Loss: 0.6015  Acc@1: 87.5000 (86.1022)  Acc@5: 100.0000 (98.4853)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2200/3125]  eta: 0:05:18  Lr: 0.001875  Loss: 0.4050  Acc@1: 87.5000 (86.1057)  Acc@5: 100.0000 (98.4836)  time: 0.3451  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:15  Lr: 0.001875  Loss: 1.0167  Acc@1: 87.5000 (86.1121)  Acc@5: 100.0000 (98.4848)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:11  Lr: 0.001875  Loss: 0.4183  Acc@1: 87.5000 (86.0958)  Acc@5: 100.0000 (98.4860)  time: 0.3447  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:08  Lr: 0.001875  Loss: 0.6332  Acc@1: 81.2500 (86.0993)  Acc@5: 100.0000 (98.4844)  time: 0.3443  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:04  Lr: 0.001875  Loss: 0.6882  Acc@1: 87.5000 (86.1027)  Acc@5: 100.0000 (98.4828)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:01  Lr: 0.001875  Loss: 0.3460  Acc@1: 87.5000 (86.0978)  Acc@5: 100.0000 (98.4785)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2260/3125]  eta: 0:04:57  Lr: 0.001875  Loss: 0.4543  Acc@1: 81.2500 (86.0819)  Acc@5: 100.0000 (98.4741)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2270/3125]  eta: 0:04:54  Lr: 0.001875  Loss: 1.1760  Acc@1: 81.2500 (86.0799)  Acc@5: 100.0000 (98.4753)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2280/3125]  eta: 0:04:50  Lr: 0.001875  Loss: 0.2760  Acc@1: 87.5000 (86.0889)  Acc@5: 100.0000 (98.4793)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2290/3125]  eta: 0:04:47  Lr: 0.001875  Loss: 0.2523  Acc@1: 87.5000 (86.1114)  Acc@5: 100.0000 (98.4832)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2300/3125]  eta: 0:04:44  Lr: 0.001875  Loss: 0.5240  Acc@1: 87.5000 (86.1093)  Acc@5: 100.0000 (98.4762)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2310/3125]  eta: 0:04:40  Lr: 0.001875  Loss: 0.3505  Acc@1: 87.5000 (86.1099)  Acc@5: 100.0000 (98.4801)  time: 0.3445  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [2320/3125]  eta: 0:04:37  Lr: 0.001875  Loss: 0.1150  Acc@1: 87.5000 (86.0970)  Acc@5: 100.0000 (98.4813)  time: 0.3457  data: 0.0018  max mem: 2501
Train: Epoch[3/5]  [2330/3125]  eta: 0:04:33  Lr: 0.001875  Loss: 0.4364  Acc@1: 87.5000 (86.0789)  Acc@5: 100.0000 (98.4797)  time: 0.3457  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2340/3125]  eta: 0:04:30  Lr: 0.001875  Loss: 0.2255  Acc@1: 87.5000 (86.0797)  Acc@5: 100.0000 (98.4809)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2350/3125]  eta: 0:04:26  Lr: 0.001875  Loss: 0.5835  Acc@1: 87.5000 (86.0724)  Acc@5: 100.0000 (98.4847)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:23  Lr: 0.001875  Loss: 0.3620  Acc@1: 87.5000 (86.0891)  Acc@5: 100.0000 (98.4858)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:19  Lr: 0.001875  Loss: 0.7335  Acc@1: 87.5000 (86.0845)  Acc@5: 100.0000 (98.4869)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:16  Lr: 0.001875  Loss: 0.1616  Acc@1: 87.5000 (86.0983)  Acc@5: 100.0000 (98.4933)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:13  Lr: 0.001875  Loss: 0.3198  Acc@1: 87.5000 (86.0937)  Acc@5: 100.0000 (98.4865)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:09  Lr: 0.001875  Loss: 0.5982  Acc@1: 87.5000 (86.0709)  Acc@5: 100.0000 (98.4850)  time: 0.3445  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:06  Lr: 0.001875  Loss: 0.6345  Acc@1: 81.2500 (86.0457)  Acc@5: 100.0000 (98.4783)  time: 0.3449  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:02  Lr: 0.001875  Loss: 0.7386  Acc@1: 87.5000 (86.0672)  Acc@5: 100.0000 (98.4846)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2430/3125]  eta: 0:03:59  Lr: 0.001875  Loss: 0.4405  Acc@1: 87.5000 (86.0680)  Acc@5: 100.0000 (98.4806)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2440/3125]  eta: 0:03:55  Lr: 0.001875  Loss: 0.4503  Acc@1: 87.5000 (86.0790)  Acc@5: 100.0000 (98.4842)  time: 0.3424  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2450/3125]  eta: 0:03:52  Lr: 0.001875  Loss: 0.0971  Acc@1: 87.5000 (86.0695)  Acc@5: 100.0000 (98.4802)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2460/3125]  eta: 0:03:48  Lr: 0.001875  Loss: 0.6517  Acc@1: 81.2500 (86.0753)  Acc@5: 100.0000 (98.4813)  time: 0.3424  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2470/3125]  eta: 0:03:45  Lr: 0.001875  Loss: 0.3968  Acc@1: 87.5000 (86.0659)  Acc@5: 100.0000 (98.4849)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2480/3125]  eta: 0:03:42  Lr: 0.001875  Loss: 0.3417  Acc@1: 87.5000 (86.0767)  Acc@5: 100.0000 (98.4860)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2490/3125]  eta: 0:03:38  Lr: 0.001875  Loss: 0.3035  Acc@1: 87.5000 (86.0774)  Acc@5: 100.0000 (98.4820)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2500/3125]  eta: 0:03:35  Lr: 0.001875  Loss: 0.3174  Acc@1: 87.5000 (86.0756)  Acc@5: 100.0000 (98.4856)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2510/3125]  eta: 0:03:31  Lr: 0.001875  Loss: 0.1299  Acc@1: 87.5000 (86.0887)  Acc@5: 100.0000 (98.4867)  time: 0.3434  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:28  Lr: 0.001875  Loss: 0.2728  Acc@1: 93.7500 (86.1092)  Acc@5: 100.0000 (98.4927)  time: 0.3437  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:24  Lr: 0.001875  Loss: 0.4977  Acc@1: 93.7500 (86.1171)  Acc@5: 100.0000 (98.4937)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:21  Lr: 0.001875  Loss: 0.3640  Acc@1: 87.5000 (86.1103)  Acc@5: 100.0000 (98.4971)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:17  Lr: 0.001875  Loss: 0.2736  Acc@1: 81.2500 (86.0863)  Acc@5: 100.0000 (98.4957)  time: 0.3443  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:14  Lr: 0.001875  Loss: 0.6364  Acc@1: 81.2500 (86.0870)  Acc@5: 100.0000 (98.4991)  time: 0.3454  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:11  Lr: 0.001875  Loss: 0.2322  Acc@1: 87.5000 (86.0755)  Acc@5: 100.0000 (98.4904)  time: 0.3451  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:07  Lr: 0.001875  Loss: 0.2546  Acc@1: 87.5000 (86.0858)  Acc@5: 100.0000 (98.4914)  time: 0.3432  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:04  Lr: 0.001875  Loss: 0.2593  Acc@1: 87.5000 (86.0865)  Acc@5: 100.0000 (98.4948)  time: 0.3433  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:00  Lr: 0.001875  Loss: 0.9897  Acc@1: 81.2500 (86.0679)  Acc@5: 100.0000 (98.4934)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2610/3125]  eta: 0:02:57  Lr: 0.001875  Loss: 0.1300  Acc@1: 87.5000 (86.0781)  Acc@5: 100.0000 (98.4967)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2620/3125]  eta: 0:02:53  Lr: 0.001875  Loss: 0.4073  Acc@1: 87.5000 (86.0740)  Acc@5: 100.0000 (98.4953)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2630/3125]  eta: 0:02:50  Lr: 0.001875  Loss: 0.5831  Acc@1: 87.5000 (86.0937)  Acc@5: 100.0000 (98.4963)  time: 0.3426  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2640/3125]  eta: 0:02:46  Lr: 0.001875  Loss: 0.3700  Acc@1: 87.5000 (86.0872)  Acc@5: 100.0000 (98.4973)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2650/3125]  eta: 0:02:43  Lr: 0.001875  Loss: 0.3368  Acc@1: 81.2500 (86.0713)  Acc@5: 100.0000 (98.5006)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2660/3125]  eta: 0:02:40  Lr: 0.001875  Loss: 0.5427  Acc@1: 87.5000 (86.0861)  Acc@5: 100.0000 (98.5015)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:36  Lr: 0.001875  Loss: 0.2717  Acc@1: 87.5000 (86.0960)  Acc@5: 100.0000 (98.5071)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:33  Lr: 0.001875  Loss: 0.6936  Acc@1: 87.5000 (86.0989)  Acc@5: 100.0000 (98.5034)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:29  Lr: 0.001875  Loss: 0.2921  Acc@1: 87.5000 (86.0995)  Acc@5: 100.0000 (98.5020)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:26  Lr: 0.001875  Loss: 0.3106  Acc@1: 87.5000 (86.0954)  Acc@5: 100.0000 (98.5029)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:22  Lr: 0.001875  Loss: 0.3553  Acc@1: 87.5000 (86.1098)  Acc@5: 100.0000 (98.5015)  time: 0.3423  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1863  Acc@1: 87.5000 (86.1035)  Acc@5: 100.0000 (98.5024)  time: 0.3422  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:15  Lr: 0.001875  Loss: 0.1332  Acc@1: 87.5000 (86.1063)  Acc@5: 100.0000 (98.5033)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:12  Lr: 0.001875  Loss: 0.0885  Acc@1: 87.5000 (86.1250)  Acc@5: 100.0000 (98.5019)  time: 0.3471  data: 0.0016  max mem: 2501
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:09  Lr: 0.001875  Loss: 0.0803  Acc@1: 87.5000 (86.1300)  Acc@5: 100.0000 (98.5028)  time: 0.3454  data: 0.0016  max mem: 2501
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:05  Lr: 0.001875  Loss: 0.1645  Acc@1: 87.5000 (86.1373)  Acc@5: 100.0000 (98.5082)  time: 0.3426  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:02  Lr: 0.001875  Loss: 0.4055  Acc@1: 87.5000 (86.1422)  Acc@5: 100.0000 (98.5114)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2780/3125]  eta: 0:01:58  Lr: 0.001875  Loss: 0.2919  Acc@1: 87.5000 (86.1358)  Acc@5: 100.0000 (98.5145)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2790/3125]  eta: 0:01:55  Lr: 0.001875  Loss: 0.2703  Acc@1: 87.5000 (86.1497)  Acc@5: 100.0000 (98.5176)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2800/3125]  eta: 0:01:51  Lr: 0.001875  Loss: 0.2748  Acc@1: 93.7500 (86.1657)  Acc@5: 100.0000 (98.5162)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2810/3125]  eta: 0:01:48  Lr: 0.001875  Loss: 0.4239  Acc@1: 81.2500 (86.1437)  Acc@5: 100.0000 (98.5125)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:44  Lr: 0.001875  Loss: 0.1836  Acc@1: 81.2500 (86.1419)  Acc@5: 100.0000 (98.5112)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:41  Lr: 0.001875  Loss: 0.2333  Acc@1: 81.2500 (86.1312)  Acc@5: 100.0000 (98.5120)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:38  Lr: 0.001875  Loss: 0.5760  Acc@1: 81.2500 (86.1316)  Acc@5: 100.0000 (98.5128)  time: 0.3444  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:34  Lr: 0.001875  Loss: 0.2429  Acc@1: 87.5000 (86.1386)  Acc@5: 100.0000 (98.5137)  time: 0.3439  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:31  Lr: 0.001875  Loss: 0.9026  Acc@1: 87.5000 (86.1303)  Acc@5: 100.0000 (98.5123)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2157  Acc@1: 87.5000 (86.1329)  Acc@5: 100.0000 (98.5088)  time: 0.3456  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:24  Lr: 0.001875  Loss: 0.6689  Acc@1: 87.5000 (86.1289)  Acc@5: 100.0000 (98.5096)  time: 0.3455  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1724  Acc@1: 87.5000 (86.1359)  Acc@5: 100.0000 (98.5083)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:17  Lr: 0.001875  Loss: 0.4006  Acc@1: 87.5000 (86.1470)  Acc@5: 100.0000 (98.5113)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2253  Acc@1: 81.2500 (86.1302)  Acc@5: 100.0000 (98.5100)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:10  Lr: 0.001875  Loss: 0.9680  Acc@1: 81.2500 (86.1178)  Acc@5: 100.0000 (98.5065)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1887  Acc@1: 87.5000 (86.1204)  Acc@5: 100.0000 (98.5073)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:03  Lr: 0.001875  Loss: 0.4793  Acc@1: 87.5000 (86.1229)  Acc@5: 100.0000 (98.5103)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:00  Lr: 0.001875  Loss: 0.4549  Acc@1: 87.5000 (86.1128)  Acc@5: 100.0000 (98.5069)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [2960/3125]  eta: 0:00:56  Lr: 0.001875  Loss: 0.4749  Acc@1: 87.5000 (86.1069)  Acc@5: 100.0000 (98.5056)  time: 0.3451  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2970/3125]  eta: 0:00:53  Lr: 0.001875  Loss: 0.2671  Acc@1: 87.5000 (86.0990)  Acc@5: 100.0000 (98.5064)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:49  Lr: 0.001875  Loss: 0.5142  Acc@1: 87.5000 (86.1162)  Acc@5: 100.0000 (98.5114)  time: 0.3441  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:46  Lr: 0.001875  Loss: 0.4338  Acc@1: 87.5000 (86.1271)  Acc@5: 100.0000 (98.5122)  time: 0.3434  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: 0.4140  Acc@1: 87.5000 (86.1046)  Acc@5: 100.0000 (98.5109)  time: 0.3442  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:39  Lr: 0.001875  Loss: 0.6046  Acc@1: 81.2500 (86.0989)  Acc@5: 100.0000 (98.5138)  time: 0.3448  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2188  Acc@1: 87.5000 (86.0994)  Acc@5: 100.0000 (98.5166)  time: 0.3443  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:32  Lr: 0.001875  Loss: 0.5242  Acc@1: 81.2500 (86.0937)  Acc@5: 100.0000 (98.5133)  time: 0.3444  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: 0.3973  Acc@1: 81.2500 (86.0901)  Acc@5: 100.0000 (98.5120)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:25  Lr: 0.001875  Loss: 0.5579  Acc@1: 87.5000 (86.0804)  Acc@5: 100.0000 (98.5128)  time: 0.3451  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: 0.4631  Acc@1: 87.5000 (86.0891)  Acc@5: 100.0000 (98.5136)  time: 0.3456  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:18  Lr: 0.001875  Loss: 0.2397  Acc@1: 87.5000 (86.0978)  Acc@5: 100.0000 (98.5164)  time: 0.3443  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2955  Acc@1: 87.5000 (86.1003)  Acc@5: 100.0000 (98.5191)  time: 0.3440  data: 0.0002  max mem: 2501
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: 0.1590  Acc@1: 87.5000 (86.1129)  Acc@5: 100.0000 (98.5199)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4238  Acc@1: 93.7500 (86.1254)  Acc@5: 100.0000 (98.5166)  time: 0.3459  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: 0.4886  Acc@1: 87.5000 (86.1299)  Acc@5: 100.0000 (98.5194)  time: 0.3451  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4790  Acc@1: 87.5000 (86.1222)  Acc@5: 100.0000 (98.5141)  time: 0.3452  data: 0.0017  max mem: 2501
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3552  Acc@1: 87.5000 (86.1240)  Acc@5: 100.0000 (98.5120)  time: 0.3450  data: 0.0016  max mem: 2501
Train: Epoch[3/5] Total time: 0:17:56 (0.3444 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.3552  Acc@1: 87.5000 (86.1240)  Acc@5: 100.0000 (98.5120)
Train: Epoch[4/5]  [   0/3125]  eta: 0:35:31  Lr: 0.001875  Loss: 0.5841  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6821  data: 0.3349  max mem: 2501
Train: Epoch[4/5]  [  10/3125]  eta: 0:19:24  Lr: 0.001875  Loss: 0.3420  Acc@1: 81.2500 (85.7955)  Acc@5: 100.0000 (98.8636)  time: 0.3740  data: 0.0307  max mem: 2501
Train: Epoch[4/5]  [  20/3125]  eta: 0:18:37  Lr: 0.001875  Loss: 0.4466  Acc@1: 81.2500 (86.3095)  Acc@5: 100.0000 (98.5119)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [  30/3125]  eta: 0:18:17  Lr: 0.001875  Loss: 0.7478  Acc@1: 81.2500 (85.0806)  Acc@5: 100.0000 (98.5887)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [  40/3125]  eta: 0:18:05  Lr: 0.001875  Loss: 0.4889  Acc@1: 81.2500 (85.2134)  Acc@5: 100.0000 (98.4756)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [  50/3125]  eta: 0:17:57  Lr: 0.001875  Loss: 0.2600  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (98.4069)  time: 0.3441  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [  60/3125]  eta: 0:17:51  Lr: 0.001875  Loss: 0.1392  Acc@1: 87.5000 (85.4508)  Acc@5: 100.0000 (98.3607)  time: 0.3451  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [  70/3125]  eta: 0:17:45  Lr: 0.001875  Loss: 0.1689  Acc@1: 87.5000 (86.0035)  Acc@5: 100.0000 (98.3275)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [  80/3125]  eta: 0:17:39  Lr: 0.001875  Loss: 0.2811  Acc@1: 87.5000 (85.9568)  Acc@5: 100.0000 (98.4568)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [  90/3125]  eta: 0:17:35  Lr: 0.001875  Loss: 0.2575  Acc@1: 81.2500 (85.5082)  Acc@5: 100.0000 (98.2143)  time: 0.3441  data: 0.0019  max mem: 2501
Train: Epoch[4/5]  [ 100/3125]  eta: 0:17:31  Lr: 0.001875  Loss: 0.4326  Acc@1: 81.2500 (85.5817)  Acc@5: 100.0000 (98.2673)  time: 0.3452  data: 0.0019  max mem: 2501
Train: Epoch[4/5]  [ 110/3125]  eta: 0:17:26  Lr: 0.001875  Loss: 0.3731  Acc@1: 87.5000 (85.8108)  Acc@5: 100.0000 (98.3108)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 120/3125]  eta: 0:17:21  Lr: 0.001875  Loss: 0.7783  Acc@1: 87.5000 (85.7438)  Acc@5: 100.0000 (98.3471)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 130/3125]  eta: 0:17:17  Lr: 0.001875  Loss: 0.0984  Acc@1: 81.2500 (85.7347)  Acc@5: 100.0000 (98.4256)  time: 0.3428  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 140/3125]  eta: 0:17:13  Lr: 0.001875  Loss: 0.1999  Acc@1: 87.5000 (85.8156)  Acc@5: 100.0000 (98.4043)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 150/3125]  eta: 0:17:09  Lr: 0.001875  Loss: 0.7270  Acc@1: 81.2500 (85.7616)  Acc@5: 100.0000 (98.3444)  time: 0.3448  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [ 160/3125]  eta: 0:17:06  Lr: 0.001875  Loss: 0.3809  Acc@1: 81.2500 (85.4425)  Acc@5: 100.0000 (98.2531)  time: 0.3460  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [ 170/3125]  eta: 0:17:02  Lr: 0.001875  Loss: 0.0930  Acc@1: 87.5000 (85.6725)  Acc@5: 100.0000 (98.3553)  time: 0.3448  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 180/3125]  eta: 0:16:58  Lr: 0.001875  Loss: 0.3791  Acc@1: 87.5000 (85.7735)  Acc@5: 100.0000 (98.3771)  time: 0.3436  data: 0.0002  max mem: 2501
Train: Epoch[4/5]  [ 190/3125]  eta: 0:16:54  Lr: 0.001875  Loss: 0.1436  Acc@1: 93.7500 (86.1911)  Acc@5: 100.0000 (98.4293)  time: 0.3434  data: 0.0002  max mem: 2501
Train: Epoch[4/5]  [ 200/3125]  eta: 0:16:51  Lr: 0.001875  Loss: 0.4967  Acc@1: 93.7500 (86.3184)  Acc@5: 100.0000 (98.4764)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 210/3125]  eta: 0:16:47  Lr: 0.001875  Loss: 0.1637  Acc@1: 87.5000 (86.4633)  Acc@5: 100.0000 (98.5190)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 220/3125]  eta: 0:16:44  Lr: 0.001875  Loss: 0.1621  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (98.5294)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 230/3125]  eta: 0:16:40  Lr: 0.001875  Loss: 0.5145  Acc@1: 81.2500 (86.2013)  Acc@5: 100.0000 (98.5119)  time: 0.3445  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 240/3125]  eta: 0:16:37  Lr: 0.001875  Loss: 0.8831  Acc@1: 81.2500 (86.1255)  Acc@5: 100.0000 (98.4699)  time: 0.3453  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 250/3125]  eta: 0:16:33  Lr: 0.001875  Loss: 0.2940  Acc@1: 87.5000 (86.1803)  Acc@5: 100.0000 (98.4811)  time: 0.3458  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 260/3125]  eta: 0:16:29  Lr: 0.001875  Loss: 0.2287  Acc@1: 87.5000 (86.0632)  Acc@5: 100.0000 (98.4674)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 270/3125]  eta: 0:16:26  Lr: 0.001875  Loss: 0.4063  Acc@1: 81.2500 (86.0009)  Acc@5: 100.0000 (98.4087)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 280/3125]  eta: 0:16:22  Lr: 0.001875  Loss: 0.5658  Acc@1: 81.2500 (86.0320)  Acc@5: 100.0000 (98.4208)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 290/3125]  eta: 0:16:18  Lr: 0.001875  Loss: 0.1831  Acc@1: 81.2500 (86.0395)  Acc@5: 100.0000 (98.3892)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 300/3125]  eta: 0:16:15  Lr: 0.001875  Loss: 0.3549  Acc@1: 81.2500 (86.0257)  Acc@5: 100.0000 (98.4012)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 310/3125]  eta: 0:16:11  Lr: 0.001875  Loss: 0.6364  Acc@1: 87.5000 (86.0330)  Acc@5: 100.0000 (98.3923)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 320/3125]  eta: 0:16:08  Lr: 0.001875  Loss: 0.0260  Acc@1: 87.5000 (86.1176)  Acc@5: 100.0000 (98.3645)  time: 0.3457  data: 0.0018  max mem: 2501
Train: Epoch[4/5]  [ 330/3125]  eta: 0:16:04  Lr: 0.001875  Loss: 0.7217  Acc@1: 87.5000 (86.2349)  Acc@5: 100.0000 (98.3573)  time: 0.3448  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [ 340/3125]  eta: 0:16:01  Lr: 0.001875  Loss: 0.1742  Acc@1: 87.5000 (86.2170)  Acc@5: 100.0000 (98.3688)  time: 0.3439  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 350/3125]  eta: 0:15:57  Lr: 0.001875  Loss: 0.8152  Acc@1: 87.5000 (86.0933)  Acc@5: 100.0000 (98.3796)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 360/3125]  eta: 0:15:54  Lr: 0.001875  Loss: 0.2419  Acc@1: 87.5000 (86.2015)  Acc@5: 100.0000 (98.4245)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 370/3125]  eta: 0:15:50  Lr: 0.001875  Loss: 0.3773  Acc@1: 87.5000 (86.1860)  Acc@5: 100.0000 (98.4501)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 380/3125]  eta: 0:15:47  Lr: 0.001875  Loss: 0.4228  Acc@1: 87.5000 (86.2861)  Acc@5: 100.0000 (98.4580)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 390/3125]  eta: 0:15:43  Lr: 0.001875  Loss: 0.3657  Acc@1: 87.5000 (86.3651)  Acc@5: 100.0000 (98.4815)  time: 0.3450  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 400/3125]  eta: 0:15:40  Lr: 0.001875  Loss: 0.5004  Acc@1: 87.5000 (86.3778)  Acc@5: 100.0000 (98.4882)  time: 0.3461  data: 0.0019  max mem: 2501
Train: Epoch[4/5]  [ 410/3125]  eta: 0:15:37  Lr: 0.001875  Loss: 0.1509  Acc@1: 81.2500 (86.2987)  Acc@5: 100.0000 (98.4793)  time: 0.3459  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [ 420/3125]  eta: 0:15:33  Lr: 0.001875  Loss: 0.4714  Acc@1: 81.2500 (86.1936)  Acc@5: 100.0000 (98.4857)  time: 0.3443  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 430/3125]  eta: 0:15:30  Lr: 0.001875  Loss: 0.4956  Acc@1: 87.5000 (86.2094)  Acc@5: 100.0000 (98.5064)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 440/3125]  eta: 0:15:26  Lr: 0.001875  Loss: 0.4921  Acc@1: 87.5000 (86.1253)  Acc@5: 100.0000 (98.5119)  time: 0.3448  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 450/3125]  eta: 0:15:23  Lr: 0.001875  Loss: 0.0295  Acc@1: 81.2500 (86.1142)  Acc@5: 100.0000 (98.5172)  time: 0.3446  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 460/3125]  eta: 0:15:19  Lr: 0.001875  Loss: 0.3835  Acc@1: 87.5000 (86.1036)  Acc@5: 100.0000 (98.5222)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 470/3125]  eta: 0:15:16  Lr: 0.001875  Loss: 0.7932  Acc@1: 81.2500 (86.1067)  Acc@5: 100.0000 (98.5271)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 480/3125]  eta: 0:15:12  Lr: 0.001875  Loss: 0.6065  Acc@1: 87.5000 (86.1486)  Acc@5: 100.0000 (98.5447)  time: 0.3441  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 490/3125]  eta: 0:15:09  Lr: 0.001875  Loss: 0.4461  Acc@1: 87.5000 (86.1507)  Acc@5: 100.0000 (98.5489)  time: 0.3434  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 500/3125]  eta: 0:15:05  Lr: 0.001875  Loss: 0.7245  Acc@1: 87.5000 (86.2275)  Acc@5: 100.0000 (98.5654)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 510/3125]  eta: 0:15:02  Lr: 0.001875  Loss: 0.3527  Acc@1: 87.5000 (86.2402)  Acc@5: 100.0000 (98.5445)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 520/3125]  eta: 0:14:58  Lr: 0.001875  Loss: 0.1400  Acc@1: 87.5000 (86.2524)  Acc@5: 100.0000 (98.5725)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 530/3125]  eta: 0:14:55  Lr: 0.001875  Loss: 0.2997  Acc@1: 87.5000 (86.2288)  Acc@5: 100.0000 (98.5758)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 540/3125]  eta: 0:14:51  Lr: 0.001875  Loss: 0.2509  Acc@1: 87.5000 (86.2061)  Acc@5: 100.0000 (98.5559)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 550/3125]  eta: 0:14:48  Lr: 0.001875  Loss: 0.2861  Acc@1: 87.5000 (86.2523)  Acc@5: 100.0000 (98.5821)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 560/3125]  eta: 0:14:44  Lr: 0.001875  Loss: 0.6738  Acc@1: 87.5000 (86.2077)  Acc@5: 100.0000 (98.5740)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 570/3125]  eta: 0:14:41  Lr: 0.001875  Loss: 0.3170  Acc@1: 87.5000 (86.2850)  Acc@5: 100.0000 (98.5989)  time: 0.3448  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 580/3125]  eta: 0:14:37  Lr: 0.001875  Loss: 0.4824  Acc@1: 87.5000 (86.2952)  Acc@5: 100.0000 (98.5908)  time: 0.3443  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 590/3125]  eta: 0:14:34  Lr: 0.001875  Loss: 0.3138  Acc@1: 87.5000 (86.2733)  Acc@5: 100.0000 (98.5829)  time: 0.3445  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 600/3125]  eta: 0:14:30  Lr: 0.001875  Loss: 0.2187  Acc@1: 87.5000 (86.2313)  Acc@5: 100.0000 (98.5545)  time: 0.3443  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [ 610/3125]  eta: 0:14:27  Lr: 0.001875  Loss: 0.4231  Acc@1: 87.5000 (86.1804)  Acc@5: 93.7500 (98.5065)  time: 0.3434  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [ 620/3125]  eta: 0:14:23  Lr: 0.001875  Loss: 0.2491  Acc@1: 87.5000 (86.2520)  Acc@5: 100.0000 (98.5105)  time: 0.3437  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 630/3125]  eta: 0:14:20  Lr: 0.001875  Loss: 0.8542  Acc@1: 87.5000 (86.2322)  Acc@5: 100.0000 (98.4845)  time: 0.3434  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 640/3125]  eta: 0:14:16  Lr: 0.001875  Loss: 0.3611  Acc@1: 87.5000 (86.2617)  Acc@5: 100.0000 (98.4789)  time: 0.3431  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 650/3125]  eta: 0:14:13  Lr: 0.001875  Loss: 0.4670  Acc@1: 87.5000 (86.2807)  Acc@5: 100.0000 (98.4831)  time: 0.3433  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 660/3125]  eta: 0:14:09  Lr: 0.001875  Loss: 0.2180  Acc@1: 87.5000 (86.2803)  Acc@5: 100.0000 (98.4871)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 670/3125]  eta: 0:14:06  Lr: 0.001875  Loss: 0.3788  Acc@1: 87.5000 (86.3357)  Acc@5: 100.0000 (98.5097)  time: 0.3426  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 680/3125]  eta: 0:14:02  Lr: 0.001875  Loss: 0.3464  Acc@1: 87.5000 (86.3069)  Acc@5: 100.0000 (98.5132)  time: 0.3428  data: 0.0002  max mem: 2501
Train: Epoch[4/5]  [ 690/3125]  eta: 0:13:59  Lr: 0.001875  Loss: 0.4721  Acc@1: 87.5000 (86.2699)  Acc@5: 100.0000 (98.5076)  time: 0.3438  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [ 700/3125]  eta: 0:13:55  Lr: 0.001875  Loss: 0.3354  Acc@1: 87.5000 (86.2964)  Acc@5: 100.0000 (98.5200)  time: 0.3435  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [ 710/3125]  eta: 0:13:52  Lr: 0.001875  Loss: 0.3460  Acc@1: 87.5000 (86.3221)  Acc@5: 100.0000 (98.5232)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 720/3125]  eta: 0:13:48  Lr: 0.001875  Loss: 0.5222  Acc@1: 87.5000 (86.3211)  Acc@5: 100.0000 (98.5177)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 730/3125]  eta: 0:13:45  Lr: 0.001875  Loss: 0.2984  Acc@1: 87.5000 (86.3885)  Acc@5: 100.0000 (98.5209)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 740/3125]  eta: 0:13:41  Lr: 0.001875  Loss: 0.1027  Acc@1: 87.5000 (86.3276)  Acc@5: 100.0000 (98.4987)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 750/3125]  eta: 0:13:38  Lr: 0.001875  Loss: 0.8183  Acc@1: 87.5000 (86.3848)  Acc@5: 100.0000 (98.5020)  time: 0.3424  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 760/3125]  eta: 0:13:34  Lr: 0.001875  Loss: 0.2405  Acc@1: 87.5000 (86.3338)  Acc@5: 100.0000 (98.4970)  time: 0.3430  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 770/3125]  eta: 0:13:31  Lr: 0.001875  Loss: 1.2874  Acc@1: 81.2500 (86.3165)  Acc@5: 100.0000 (98.4841)  time: 0.3436  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 780/3125]  eta: 0:13:27  Lr: 0.001875  Loss: 0.2234  Acc@1: 87.5000 (86.3716)  Acc@5: 100.0000 (98.4875)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 790/3125]  eta: 0:13:24  Lr: 0.001875  Loss: 0.2545  Acc@1: 87.5000 (86.4017)  Acc@5: 100.0000 (98.4908)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 800/3125]  eta: 0:13:20  Lr: 0.001875  Loss: 0.4999  Acc@1: 87.5000 (86.3530)  Acc@5: 100.0000 (98.5097)  time: 0.3442  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 810/3125]  eta: 0:13:17  Lr: 0.001875  Loss: 0.2653  Acc@1: 87.5000 (86.3826)  Acc@5: 100.0000 (98.5126)  time: 0.3442  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 820/3125]  eta: 0:13:14  Lr: 0.001875  Loss: 0.4034  Acc@1: 81.2500 (86.2972)  Acc@5: 100.0000 (98.5308)  time: 0.3442  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 830/3125]  eta: 0:13:10  Lr: 0.001875  Loss: 0.3086  Acc@1: 81.2500 (86.3192)  Acc@5: 100.0000 (98.5409)  time: 0.3439  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 840/3125]  eta: 0:13:07  Lr: 0.001875  Loss: 0.6401  Acc@1: 87.5000 (86.2738)  Acc@5: 100.0000 (98.5360)  time: 0.3429  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 850/3125]  eta: 0:13:03  Lr: 0.001875  Loss: 0.5371  Acc@1: 87.5000 (86.2955)  Acc@5: 100.0000 (98.5532)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 860/3125]  eta: 0:13:00  Lr: 0.001875  Loss: 0.1805  Acc@1: 87.5000 (86.2805)  Acc@5: 100.0000 (98.5482)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 870/3125]  eta: 0:12:56  Lr: 0.001875  Loss: 0.3522  Acc@1: 87.5000 (86.2873)  Acc@5: 100.0000 (98.5505)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 880/3125]  eta: 0:12:53  Lr: 0.001875  Loss: 0.2881  Acc@1: 87.5000 (86.3295)  Acc@5: 100.0000 (98.5457)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 890/3125]  eta: 0:12:49  Lr: 0.001875  Loss: 0.1681  Acc@1: 87.5000 (86.3566)  Acc@5: 100.0000 (98.5340)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 900/3125]  eta: 0:12:46  Lr: 0.001875  Loss: 0.7072  Acc@1: 87.5000 (86.3693)  Acc@5: 100.0000 (98.5294)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 910/3125]  eta: 0:12:42  Lr: 0.001875  Loss: 0.6965  Acc@1: 87.5000 (86.3611)  Acc@5: 100.0000 (98.5387)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 920/3125]  eta: 0:12:39  Lr: 0.001875  Loss: 0.3418  Acc@1: 87.5000 (86.3667)  Acc@5: 100.0000 (98.5206)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 930/3125]  eta: 0:12:35  Lr: 0.001875  Loss: 0.6990  Acc@1: 87.5000 (86.3722)  Acc@5: 100.0000 (98.5030)  time: 0.3442  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 940/3125]  eta: 0:12:32  Lr: 0.001875  Loss: 0.6886  Acc@1: 87.5000 (86.3111)  Acc@5: 100.0000 (98.4989)  time: 0.3443  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [ 950/3125]  eta: 0:12:29  Lr: 0.001875  Loss: 0.7769  Acc@1: 87.5000 (86.3368)  Acc@5: 100.0000 (98.4884)  time: 0.3444  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [ 960/3125]  eta: 0:12:25  Lr: 0.001875  Loss: 0.8548  Acc@1: 87.5000 (86.3293)  Acc@5: 100.0000 (98.4912)  time: 0.3446  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 970/3125]  eta: 0:12:22  Lr: 0.001875  Loss: 0.2888  Acc@1: 81.2500 (86.3028)  Acc@5: 100.0000 (98.4809)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 980/3125]  eta: 0:12:18  Lr: 0.001875  Loss: 0.1749  Acc@1: 87.5000 (86.3532)  Acc@5: 100.0000 (98.4964)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 990/3125]  eta: 0:12:15  Lr: 0.001875  Loss: 0.3625  Acc@1: 87.5000 (86.3585)  Acc@5: 100.0000 (98.4990)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1000/3125]  eta: 0:12:11  Lr: 0.001875  Loss: 0.0562  Acc@1: 87.5000 (86.4136)  Acc@5: 100.0000 (98.4953)  time: 0.3444  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1010/3125]  eta: 0:12:08  Lr: 0.001875  Loss: 0.5877  Acc@1: 93.7500 (86.4182)  Acc@5: 100.0000 (98.5040)  time: 0.3446  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1020/3125]  eta: 0:12:04  Lr: 0.001875  Loss: 0.3036  Acc@1: 81.2500 (86.4104)  Acc@5: 100.0000 (98.5064)  time: 0.3447  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1030/3125]  eta: 0:12:01  Lr: 0.001875  Loss: 0.6012  Acc@1: 87.5000 (86.4270)  Acc@5: 100.0000 (98.5087)  time: 0.3441  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1040/3125]  eta: 0:11:58  Lr: 0.001875  Loss: 0.5831  Acc@1: 87.5000 (86.4313)  Acc@5: 100.0000 (98.5110)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1050/3125]  eta: 0:11:54  Lr: 0.001875  Loss: 0.3750  Acc@1: 87.5000 (86.4236)  Acc@5: 100.0000 (98.5014)  time: 0.3440  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1060/3125]  eta: 0:11:51  Lr: 0.001875  Loss: 0.6802  Acc@1: 87.5000 (86.4102)  Acc@5: 100.0000 (98.5038)  time: 0.3442  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1070/3125]  eta: 0:11:47  Lr: 0.001875  Loss: 0.4021  Acc@1: 87.5000 (86.4087)  Acc@5: 100.0000 (98.5061)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1080/3125]  eta: 0:11:44  Lr: 0.001875  Loss: 0.3282  Acc@1: 87.5000 (86.4535)  Acc@5: 100.0000 (98.5141)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1090/3125]  eta: 0:11:40  Lr: 0.001875  Loss: 0.6175  Acc@1: 87.5000 (86.4345)  Acc@5: 100.0000 (98.5163)  time: 0.3440  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1100/3125]  eta: 0:11:37  Lr: 0.001875  Loss: 0.8344  Acc@1: 81.2500 (86.3874)  Acc@5: 100.0000 (98.5070)  time: 0.3442  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1110/3125]  eta: 0:11:33  Lr: 0.001875  Loss: 0.6191  Acc@1: 81.2500 (86.3130)  Acc@5: 100.0000 (98.5036)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1120/3125]  eta: 0:11:30  Lr: 0.001875  Loss: 0.1497  Acc@1: 81.2500 (86.3069)  Acc@5: 100.0000 (98.5114)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1130/3125]  eta: 0:11:27  Lr: 0.001875  Loss: 0.7031  Acc@1: 81.2500 (86.2898)  Acc@5: 100.0000 (98.5135)  time: 0.3481  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1140/3125]  eta: 0:11:23  Lr: 0.001875  Loss: 0.1921  Acc@1: 87.5000 (86.3168)  Acc@5: 100.0000 (98.5210)  time: 0.3489  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1150/3125]  eta: 0:11:20  Lr: 0.001875  Loss: 0.3616  Acc@1: 87.5000 (86.2945)  Acc@5: 100.0000 (98.5067)  time: 0.3461  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1160/3125]  eta: 0:11:16  Lr: 0.001875  Loss: 0.5870  Acc@1: 87.5000 (86.3049)  Acc@5: 100.0000 (98.5088)  time: 0.3451  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1170/3125]  eta: 0:11:13  Lr: 0.001875  Loss: 0.0297  Acc@1: 87.5000 (86.3525)  Acc@5: 100.0000 (98.5162)  time: 0.3472  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1180/3125]  eta: 0:11:10  Lr: 0.001875  Loss: 0.7121  Acc@1: 93.7500 (86.3781)  Acc@5: 100.0000 (98.5182)  time: 0.3473  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1190/3125]  eta: 0:11:06  Lr: 0.001875  Loss: 0.5875  Acc@1: 87.5000 (86.3560)  Acc@5: 100.0000 (98.5149)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1200/3125]  eta: 0:11:03  Lr: 0.001875  Loss: 0.2689  Acc@1: 87.5000 (86.3499)  Acc@5: 100.0000 (98.5221)  time: 0.3446  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1210/3125]  eta: 0:10:59  Lr: 0.001875  Loss: 0.4240  Acc@1: 87.5000 (86.3646)  Acc@5: 100.0000 (98.5291)  time: 0.3461  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1220/3125]  eta: 0:10:56  Lr: 0.001875  Loss: 0.2054  Acc@1: 87.5000 (86.3380)  Acc@5: 100.0000 (98.5309)  time: 0.3455  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1230/3125]  eta: 0:10:52  Lr: 0.001875  Loss: 0.3913  Acc@1: 81.2500 (86.3323)  Acc@5: 100.0000 (98.5327)  time: 0.3445  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1240/3125]  eta: 0:10:49  Lr: 0.001875  Loss: 0.5381  Acc@1: 87.5000 (86.3467)  Acc@5: 100.0000 (98.5344)  time: 0.3470  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1250/3125]  eta: 0:10:46  Lr: 0.001875  Loss: 0.1425  Acc@1: 87.5000 (86.3809)  Acc@5: 100.0000 (98.5362)  time: 0.3472  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1260/3125]  eta: 0:10:42  Lr: 0.001875  Loss: 0.0934  Acc@1: 87.5000 (86.3997)  Acc@5: 100.0000 (98.5428)  time: 0.3462  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [1270/3125]  eta: 0:10:39  Lr: 0.001875  Loss: 0.4677  Acc@1: 87.5000 (86.4231)  Acc@5: 100.0000 (98.5543)  time: 0.3476  data: 0.0019  max mem: 2501
Train: Epoch[4/5]  [1280/3125]  eta: 0:10:35  Lr: 0.001875  Loss: 0.3216  Acc@1: 87.5000 (86.4217)  Acc@5: 100.0000 (98.5558)  time: 0.3465  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1290/3125]  eta: 0:10:32  Lr: 0.001875  Loss: 0.3510  Acc@1: 81.2500 (86.4156)  Acc@5: 100.0000 (98.5622)  time: 0.3456  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [1300/3125]  eta: 0:10:28  Lr: 0.001875  Loss: 0.8388  Acc@1: 81.2500 (86.4239)  Acc@5: 100.0000 (98.5636)  time: 0.3457  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1310/3125]  eta: 0:10:25  Lr: 0.001875  Loss: 0.3588  Acc@1: 87.5000 (86.4273)  Acc@5: 100.0000 (98.5746)  time: 0.3459  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [1320/3125]  eta: 0:10:22  Lr: 0.001875  Loss: 0.5091  Acc@1: 87.5000 (86.4023)  Acc@5: 100.0000 (98.5759)  time: 0.3461  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [1330/3125]  eta: 0:10:18  Lr: 0.001875  Loss: 0.3707  Acc@1: 87.5000 (86.4106)  Acc@5: 100.0000 (98.5678)  time: 0.3465  data: 0.0019  max mem: 2501
Train: Epoch[4/5]  [1340/3125]  eta: 0:10:15  Lr: 0.001875  Loss: 0.3448  Acc@1: 87.5000 (86.3954)  Acc@5: 100.0000 (98.5598)  time: 0.3463  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [1350/3125]  eta: 0:10:11  Lr: 0.001875  Loss: 0.2039  Acc@1: 87.5000 (86.4036)  Acc@5: 100.0000 (98.5613)  time: 0.3461  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1360/3125]  eta: 0:10:08  Lr: 0.001875  Loss: 0.6859  Acc@1: 87.5000 (86.4025)  Acc@5: 100.0000 (98.5580)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1370/3125]  eta: 0:10:04  Lr: 0.001875  Loss: 0.3365  Acc@1: 87.5000 (86.4241)  Acc@5: 100.0000 (98.5594)  time: 0.3455  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [1380/3125]  eta: 0:10:01  Lr: 0.001875  Loss: 0.1676  Acc@1: 87.5000 (86.4455)  Acc@5: 100.0000 (98.5563)  time: 0.3456  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [1390/3125]  eta: 0:09:58  Lr: 0.001875  Loss: 0.3669  Acc@1: 87.5000 (86.4351)  Acc@5: 100.0000 (98.5532)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1400/3125]  eta: 0:09:54  Lr: 0.001875  Loss: 0.7185  Acc@1: 87.5000 (86.4338)  Acc@5: 100.0000 (98.5412)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1410/3125]  eta: 0:09:51  Lr: 0.001875  Loss: 0.4429  Acc@1: 81.2500 (86.4458)  Acc@5: 100.0000 (98.5471)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1420/3125]  eta: 0:09:47  Lr: 0.001875  Loss: 0.4833  Acc@1: 87.5000 (86.4224)  Acc@5: 100.0000 (98.5486)  time: 0.3442  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1430/3125]  eta: 0:09:44  Lr: 0.001875  Loss: 0.4307  Acc@1: 87.5000 (86.4430)  Acc@5: 100.0000 (98.5587)  time: 0.3444  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1440/3125]  eta: 0:09:40  Lr: 0.001875  Loss: 0.2906  Acc@1: 87.5000 (86.4244)  Acc@5: 100.0000 (98.5470)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1450/3125]  eta: 0:09:37  Lr: 0.001875  Loss: 0.1760  Acc@1: 87.5000 (86.4232)  Acc@5: 100.0000 (98.5312)  time: 0.3428  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1460/3125]  eta: 0:09:33  Lr: 0.001875  Loss: 0.5978  Acc@1: 87.5000 (86.4091)  Acc@5: 100.0000 (98.5327)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1470/3125]  eta: 0:09:30  Lr: 0.001875  Loss: 0.6328  Acc@1: 81.2500 (86.3826)  Acc@5: 100.0000 (98.5257)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1480/3125]  eta: 0:09:27  Lr: 0.001875  Loss: 0.5354  Acc@1: 81.2500 (86.3901)  Acc@5: 100.0000 (98.5187)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1490/3125]  eta: 0:09:23  Lr: 0.001875  Loss: 0.4094  Acc@1: 87.5000 (86.3892)  Acc@5: 100.0000 (98.5287)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1500/3125]  eta: 0:09:20  Lr: 0.001875  Loss: 0.3259  Acc@1: 93.7500 (86.4007)  Acc@5: 100.0000 (98.5301)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1510/3125]  eta: 0:09:16  Lr: 0.001875  Loss: 0.3855  Acc@1: 93.7500 (86.3997)  Acc@5: 100.0000 (98.5357)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1520/3125]  eta: 0:09:13  Lr: 0.001875  Loss: 0.3796  Acc@1: 87.5000 (86.3905)  Acc@5: 100.0000 (98.5371)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1530/3125]  eta: 0:09:09  Lr: 0.001875  Loss: 0.2989  Acc@1: 87.5000 (86.3978)  Acc@5: 100.0000 (98.5426)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1540/3125]  eta: 0:09:06  Lr: 0.001875  Loss: 0.3652  Acc@1: 87.5000 (86.4212)  Acc@5: 100.0000 (98.5440)  time: 0.3448  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [1550/3125]  eta: 0:09:02  Lr: 0.001875  Loss: 0.3423  Acc@1: 87.5000 (86.4321)  Acc@5: 100.0000 (98.5453)  time: 0.3461  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [1560/3125]  eta: 0:08:59  Lr: 0.001875  Loss: 0.3404  Acc@1: 87.5000 (86.4070)  Acc@5: 100.0000 (98.5466)  time: 0.3461  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1570/3125]  eta: 0:08:56  Lr: 0.001875  Loss: 0.5446  Acc@1: 81.2500 (86.3861)  Acc@5: 100.0000 (98.5439)  time: 0.3444  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1580/3125]  eta: 0:08:52  Lr: 0.001875  Loss: 0.6064  Acc@1: 81.2500 (86.3812)  Acc@5: 100.0000 (98.5492)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1590/3125]  eta: 0:08:49  Lr: 0.001875  Loss: 0.6181  Acc@1: 81.2500 (86.3804)  Acc@5: 100.0000 (98.5504)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1600/3125]  eta: 0:08:45  Lr: 0.001875  Loss: 0.3581  Acc@1: 81.2500 (86.3874)  Acc@5: 100.0000 (98.5517)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1610/3125]  eta: 0:08:42  Lr: 0.001875  Loss: 0.3737  Acc@1: 81.2500 (86.3866)  Acc@5: 100.0000 (98.5607)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1620/3125]  eta: 0:08:38  Lr: 0.001875  Loss: 0.5152  Acc@1: 87.5000 (86.3819)  Acc@5: 100.0000 (98.5541)  time: 0.3449  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1630/3125]  eta: 0:08:35  Lr: 0.001875  Loss: 0.4919  Acc@1: 81.2500 (86.3427)  Acc@5: 100.0000 (98.5553)  time: 0.3441  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1640/3125]  eta: 0:08:31  Lr: 0.001875  Loss: 0.5858  Acc@1: 81.2500 (86.3346)  Acc@5: 100.0000 (98.5641)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1650/3125]  eta: 0:08:28  Lr: 0.001875  Loss: 0.0177  Acc@1: 87.5000 (86.3340)  Acc@5: 100.0000 (98.5690)  time: 0.3442  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1660/3125]  eta: 0:08:24  Lr: 0.001875  Loss: 0.1868  Acc@1: 81.2500 (86.3448)  Acc@5: 100.0000 (98.5701)  time: 0.3435  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1670/3125]  eta: 0:08:21  Lr: 0.001875  Loss: 0.2376  Acc@1: 81.2500 (86.3256)  Acc@5: 100.0000 (98.5675)  time: 0.3441  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1680/3125]  eta: 0:08:18  Lr: 0.001875  Loss: 0.4725  Acc@1: 81.2500 (86.3251)  Acc@5: 100.0000 (98.5611)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1690/3125]  eta: 0:08:14  Lr: 0.001875  Loss: 0.7118  Acc@1: 87.5000 (86.3173)  Acc@5: 100.0000 (98.5585)  time: 0.3452  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [1700/3125]  eta: 0:08:11  Lr: 0.001875  Loss: 1.0580  Acc@1: 87.5000 (86.3169)  Acc@5: 100.0000 (98.5486)  time: 0.3449  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [1710/3125]  eta: 0:08:07  Lr: 0.001875  Loss: 0.5261  Acc@1: 87.5000 (86.3274)  Acc@5: 100.0000 (98.5425)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1720/3125]  eta: 0:08:04  Lr: 0.001875  Loss: 0.5363  Acc@1: 87.5000 (86.3234)  Acc@5: 100.0000 (98.5401)  time: 0.3446  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [1730/3125]  eta: 0:08:00  Lr: 0.001875  Loss: 0.6369  Acc@1: 81.2500 (86.3157)  Acc@5: 100.0000 (98.5413)  time: 0.3450  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [1740/3125]  eta: 0:07:57  Lr: 0.001875  Loss: 0.4883  Acc@1: 81.2500 (86.3046)  Acc@5: 100.0000 (98.5389)  time: 0.3442  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1750/3125]  eta: 0:07:53  Lr: 0.001875  Loss: 0.3749  Acc@1: 87.5000 (86.3364)  Acc@5: 100.0000 (98.5366)  time: 0.3438  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1760/3125]  eta: 0:07:50  Lr: 0.001875  Loss: 0.9017  Acc@1: 87.5000 (86.3430)  Acc@5: 100.0000 (98.5236)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1770/3125]  eta: 0:07:47  Lr: 0.001875  Loss: 0.2437  Acc@1: 87.5000 (86.3425)  Acc@5: 100.0000 (98.5107)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1780/3125]  eta: 0:07:43  Lr: 0.001875  Loss: 0.4764  Acc@1: 87.5000 (86.3490)  Acc@5: 100.0000 (98.5121)  time: 0.3430  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1790/3125]  eta: 0:07:40  Lr: 0.001875  Loss: 0.5664  Acc@1: 81.2500 (86.3275)  Acc@5: 100.0000 (98.5134)  time: 0.3447  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1800/3125]  eta: 0:07:36  Lr: 0.001875  Loss: 0.1792  Acc@1: 81.2500 (86.3375)  Acc@5: 100.0000 (98.5182)  time: 0.3445  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1810/3125]  eta: 0:07:33  Lr: 0.001875  Loss: 0.7228  Acc@1: 87.5000 (86.3370)  Acc@5: 100.0000 (98.5160)  time: 0.3447  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [1820/3125]  eta: 0:07:29  Lr: 0.001875  Loss: 0.3970  Acc@1: 87.5000 (86.3331)  Acc@5: 100.0000 (98.5242)  time: 0.3453  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [1830/3125]  eta: 0:07:26  Lr: 0.001875  Loss: 0.3176  Acc@1: 87.5000 (86.3428)  Acc@5: 100.0000 (98.5322)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1840/3125]  eta: 0:07:22  Lr: 0.001875  Loss: 0.4669  Acc@1: 81.2500 (86.3152)  Acc@5: 100.0000 (98.5334)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1850/3125]  eta: 0:07:19  Lr: 0.001875  Loss: 0.2936  Acc@1: 81.2500 (86.3047)  Acc@5: 100.0000 (98.5278)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1860/3125]  eta: 0:07:16  Lr: 0.001875  Loss: 0.1701  Acc@1: 81.2500 (86.3010)  Acc@5: 100.0000 (98.5290)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1870/3125]  eta: 0:07:12  Lr: 0.001875  Loss: 0.3114  Acc@1: 87.5000 (86.2908)  Acc@5: 100.0000 (98.5302)  time: 0.3448  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1880/3125]  eta: 0:07:09  Lr: 0.001875  Loss: 0.3827  Acc@1: 87.5000 (86.2939)  Acc@5: 100.0000 (98.5314)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1890/3125]  eta: 0:07:05  Lr: 0.001875  Loss: 0.3403  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.5358)  time: 0.3444  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:02  Lr: 0.001875  Loss: 0.0730  Acc@1: 87.5000 (86.2901)  Acc@5: 100.0000 (98.5435)  time: 0.3442  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1910/3125]  eta: 0:06:58  Lr: 0.001875  Loss: 0.1011  Acc@1: 87.5000 (86.2932)  Acc@5: 100.0000 (98.5413)  time: 0.3431  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1920/3125]  eta: 0:06:55  Lr: 0.001875  Loss: 0.2880  Acc@1: 87.5000 (86.2962)  Acc@5: 100.0000 (98.5457)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1930/3125]  eta: 0:06:51  Lr: 0.001875  Loss: 0.3102  Acc@1: 87.5000 (86.2798)  Acc@5: 100.0000 (98.5467)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1940/3125]  eta: 0:06:48  Lr: 0.001875  Loss: 0.2406  Acc@1: 87.5000 (86.2764)  Acc@5: 100.0000 (98.5478)  time: 0.3424  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1950/3125]  eta: 0:06:44  Lr: 0.001875  Loss: 0.3971  Acc@1: 87.5000 (86.2603)  Acc@5: 100.0000 (98.5456)  time: 0.3425  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1960/3125]  eta: 0:06:41  Lr: 0.001875  Loss: 0.3734  Acc@1: 87.5000 (86.2761)  Acc@5: 100.0000 (98.5498)  time: 0.3427  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1970/3125]  eta: 0:06:38  Lr: 0.001875  Loss: 0.6845  Acc@1: 87.5000 (86.2506)  Acc@5: 100.0000 (98.5509)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1980/3125]  eta: 0:06:34  Lr: 0.001875  Loss: 0.5681  Acc@1: 81.2500 (86.2538)  Acc@5: 100.0000 (98.5550)  time: 0.3447  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1990/3125]  eta: 0:06:31  Lr: 0.001875  Loss: 0.4846  Acc@1: 87.5000 (86.2412)  Acc@5: 100.0000 (98.5497)  time: 0.3452  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2000/3125]  eta: 0:06:27  Lr: 0.001875  Loss: 0.1550  Acc@1: 87.5000 (86.2537)  Acc@5: 100.0000 (98.5507)  time: 0.3451  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2010/3125]  eta: 0:06:24  Lr: 0.001875  Loss: 0.1755  Acc@1: 87.5000 (86.2693)  Acc@5: 100.0000 (98.5548)  time: 0.3442  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2020/3125]  eta: 0:06:20  Lr: 0.001875  Loss: 0.2606  Acc@1: 87.5000 (86.2568)  Acc@5: 100.0000 (98.5558)  time: 0.3445  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2030/3125]  eta: 0:06:17  Lr: 0.001875  Loss: 0.4344  Acc@1: 87.5000 (86.2814)  Acc@5: 100.0000 (98.5598)  time: 0.3455  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2040/3125]  eta: 0:06:13  Lr: 0.001875  Loss: 0.3731  Acc@1: 87.5000 (86.2874)  Acc@5: 100.0000 (98.5546)  time: 0.3469  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:10  Lr: 0.001875  Loss: 0.6078  Acc@1: 87.5000 (86.2902)  Acc@5: 100.0000 (98.5556)  time: 0.3463  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:07  Lr: 0.001875  Loss: 0.1779  Acc@1: 87.5000 (86.3143)  Acc@5: 100.0000 (98.5565)  time: 0.3441  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:03  Lr: 0.001875  Loss: 0.1965  Acc@1: 87.5000 (86.3019)  Acc@5: 100.0000 (98.5514)  time: 0.3435  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:00  Lr: 0.001875  Loss: 0.5149  Acc@1: 87.5000 (86.3017)  Acc@5: 100.0000 (98.5494)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2090/3125]  eta: 0:05:56  Lr: 0.001875  Loss: 0.8547  Acc@1: 87.5000 (86.2984)  Acc@5: 100.0000 (98.5473)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2100/3125]  eta: 0:05:53  Lr: 0.001875  Loss: 0.3341  Acc@1: 87.5000 (86.3160)  Acc@5: 100.0000 (98.5483)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2110/3125]  eta: 0:05:49  Lr: 0.001875  Loss: 0.5912  Acc@1: 87.5000 (86.3009)  Acc@5: 100.0000 (98.5522)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2120/3125]  eta: 0:05:46  Lr: 0.001875  Loss: 0.6115  Acc@1: 87.5000 (86.2948)  Acc@5: 100.0000 (98.5502)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2130/3125]  eta: 0:05:42  Lr: 0.001875  Loss: 0.3698  Acc@1: 87.5000 (86.2770)  Acc@5: 100.0000 (98.5482)  time: 0.3443  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2140/3125]  eta: 0:05:39  Lr: 0.001875  Loss: 0.4102  Acc@1: 87.5000 (86.2827)  Acc@5: 100.0000 (98.5462)  time: 0.3437  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2150/3125]  eta: 0:05:35  Lr: 0.001875  Loss: 0.6322  Acc@1: 87.5000 (86.2913)  Acc@5: 100.0000 (98.5530)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2160/3125]  eta: 0:05:32  Lr: 0.001875  Loss: 0.3573  Acc@1: 87.5000 (86.3113)  Acc@5: 100.0000 (98.5568)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2170/3125]  eta: 0:05:29  Lr: 0.001875  Loss: 0.3341  Acc@1: 87.5000 (86.3197)  Acc@5: 100.0000 (98.5606)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2180/3125]  eta: 0:05:25  Lr: 0.001875  Loss: 0.5681  Acc@1: 87.5000 (86.3279)  Acc@5: 100.0000 (98.5614)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2190/3125]  eta: 0:05:22  Lr: 0.001875  Loss: 0.1970  Acc@1: 87.5000 (86.3419)  Acc@5: 100.0000 (98.5623)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2200/3125]  eta: 0:05:18  Lr: 0.001875  Loss: 0.5458  Acc@1: 87.5000 (86.3471)  Acc@5: 100.0000 (98.5632)  time: 0.3442  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:15  Lr: 0.001875  Loss: 0.0912  Acc@1: 87.5000 (86.3608)  Acc@5: 100.0000 (98.5697)  time: 0.3444  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:11  Lr: 0.001875  Loss: 0.5354  Acc@1: 87.5000 (86.3575)  Acc@5: 100.0000 (98.5648)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:08  Lr: 0.001875  Loss: 0.2159  Acc@1: 87.5000 (86.3626)  Acc@5: 100.0000 (98.5629)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:04  Lr: 0.001875  Loss: 0.3662  Acc@1: 87.5000 (86.3593)  Acc@5: 100.0000 (98.5693)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:01  Lr: 0.001875  Loss: 0.2869  Acc@1: 87.5000 (86.3616)  Acc@5: 100.0000 (98.5645)  time: 0.3449  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [2260/3125]  eta: 0:04:58  Lr: 0.001875  Loss: 0.6879  Acc@1: 87.5000 (86.3445)  Acc@5: 100.0000 (98.5515)  time: 0.3450  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2270/3125]  eta: 0:04:54  Lr: 0.001875  Loss: 0.2916  Acc@1: 87.5000 (86.3579)  Acc@5: 100.0000 (98.5552)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2280/3125]  eta: 0:04:51  Lr: 0.001875  Loss: 0.8015  Acc@1: 93.7500 (86.3738)  Acc@5: 100.0000 (98.5560)  time: 0.3445  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2290/3125]  eta: 0:04:47  Lr: 0.001875  Loss: 0.2514  Acc@1: 93.7500 (86.3842)  Acc@5: 100.0000 (98.5569)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2300/3125]  eta: 0:04:44  Lr: 0.001875  Loss: 0.3475  Acc@1: 87.5000 (86.3918)  Acc@5: 100.0000 (98.5523)  time: 0.3451  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2310/3125]  eta: 0:04:40  Lr: 0.001875  Loss: 0.2580  Acc@1: 87.5000 (86.4020)  Acc@5: 100.0000 (98.5504)  time: 0.3444  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2320/3125]  eta: 0:04:37  Lr: 0.001875  Loss: 1.0590  Acc@1: 87.5000 (86.3933)  Acc@5: 100.0000 (98.5486)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2330/3125]  eta: 0:04:33  Lr: 0.001875  Loss: 0.1844  Acc@1: 87.5000 (86.3953)  Acc@5: 100.0000 (98.5468)  time: 0.3452  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [2340/3125]  eta: 0:04:30  Lr: 0.001875  Loss: 1.0053  Acc@1: 87.5000 (86.3733)  Acc@5: 100.0000 (98.5370)  time: 0.3450  data: 0.0019  max mem: 2501
Train: Epoch[4/5]  [2350/3125]  eta: 0:04:27  Lr: 0.001875  Loss: 0.6503  Acc@1: 87.5000 (86.3755)  Acc@5: 100.0000 (98.5405)  time: 0.3436  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:23  Lr: 0.001875  Loss: 0.5077  Acc@1: 87.5000 (86.3829)  Acc@5: 100.0000 (98.5414)  time: 0.3442  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:20  Lr: 0.001875  Loss: 0.6946  Acc@1: 87.5000 (86.3691)  Acc@5: 100.0000 (98.5423)  time: 0.3437  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:16  Lr: 0.001875  Loss: 0.2859  Acc@1: 81.2500 (86.3634)  Acc@5: 100.0000 (98.5484)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:13  Lr: 0.001875  Loss: 0.6989  Acc@1: 87.5000 (86.3603)  Acc@5: 100.0000 (98.5466)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:09  Lr: 0.001875  Loss: 0.2558  Acc@1: 87.5000 (86.3599)  Acc@5: 100.0000 (98.5423)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:06  Lr: 0.001875  Loss: 0.5980  Acc@1: 87.5000 (86.3672)  Acc@5: 100.0000 (98.5405)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:02  Lr: 0.001875  Loss: 0.6090  Acc@1: 87.5000 (86.3589)  Acc@5: 100.0000 (98.5440)  time: 0.3455  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2430/3125]  eta: 0:03:59  Lr: 0.001875  Loss: 0.5244  Acc@1: 87.5000 (86.3713)  Acc@5: 100.0000 (98.5474)  time: 0.3462  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2440/3125]  eta: 0:03:56  Lr: 0.001875  Loss: 0.2145  Acc@1: 93.7500 (86.3837)  Acc@5: 100.0000 (98.5482)  time: 0.3452  data: 0.0017  max mem: 2501
Train: Epoch[4/5]  [2450/3125]  eta: 0:03:52  Lr: 0.001875  Loss: 0.2540  Acc@1: 87.5000 (86.3959)  Acc@5: 100.0000 (98.5542)  time: 0.3441  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [2460/3125]  eta: 0:03:49  Lr: 0.001875  Loss: 0.4015  Acc@1: 87.5000 (86.3800)  Acc@5: 100.0000 (98.5524)  time: 0.3435  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2470/3125]  eta: 0:03:45  Lr: 0.001875  Loss: 0.1027  Acc@1: 81.2500 (86.3770)  Acc@5: 100.0000 (98.5532)  time: 0.3442  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2480/3125]  eta: 0:03:42  Lr: 0.001875  Loss: 0.4556  Acc@1: 81.2500 (86.3488)  Acc@5: 100.0000 (98.5414)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2490/3125]  eta: 0:03:38  Lr: 0.001875  Loss: 0.3309  Acc@1: 87.5000 (86.3609)  Acc@5: 100.0000 (98.5423)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2500/3125]  eta: 0:03:35  Lr: 0.001875  Loss: 0.5904  Acc@1: 87.5000 (86.3580)  Acc@5: 100.0000 (98.5431)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2510/3125]  eta: 0:03:31  Lr: 0.001875  Loss: 0.1632  Acc@1: 87.5000 (86.3675)  Acc@5: 100.0000 (98.5464)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:28  Lr: 0.001875  Loss: 0.5755  Acc@1: 87.5000 (86.3794)  Acc@5: 100.0000 (98.5472)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:25  Lr: 0.001875  Loss: 0.2862  Acc@1: 87.5000 (86.3888)  Acc@5: 100.0000 (98.5505)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:21  Lr: 0.001875  Loss: 0.0151  Acc@1: 87.5000 (86.4005)  Acc@5: 100.0000 (98.5463)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:18  Lr: 0.001875  Loss: 0.8714  Acc@1: 87.5000 (86.4024)  Acc@5: 100.0000 (98.5471)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:14  Lr: 0.001875  Loss: 0.1945  Acc@1: 87.5000 (86.4067)  Acc@5: 100.0000 (98.5504)  time: 0.3444  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:11  Lr: 0.001875  Loss: 0.2630  Acc@1: 87.5000 (86.4158)  Acc@5: 100.0000 (98.5487)  time: 0.3437  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:07  Lr: 0.001875  Loss: 0.4840  Acc@1: 87.5000 (86.4006)  Acc@5: 100.0000 (98.5447)  time: 0.3434  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:04  Lr: 0.001875  Loss: 0.4450  Acc@1: 87.5000 (86.3976)  Acc@5: 100.0000 (98.5454)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:00  Lr: 0.001875  Loss: 0.6581  Acc@1: 87.5000 (86.3947)  Acc@5: 100.0000 (98.5462)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2610/3125]  eta: 0:02:57  Lr: 0.001875  Loss: 0.2054  Acc@1: 87.5000 (86.4037)  Acc@5: 100.0000 (98.5470)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2620/3125]  eta: 0:02:54  Lr: 0.001875  Loss: 0.7861  Acc@1: 87.5000 (86.4055)  Acc@5: 100.0000 (98.5454)  time: 0.3445  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2630/3125]  eta: 0:02:50  Lr: 0.001875  Loss: 0.5472  Acc@1: 87.5000 (86.3978)  Acc@5: 100.0000 (98.5414)  time: 0.3452  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2640/3125]  eta: 0:02:47  Lr: 0.001875  Loss: 0.1925  Acc@1: 87.5000 (86.4067)  Acc@5: 100.0000 (98.5422)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2650/3125]  eta: 0:02:43  Lr: 0.001875  Loss: 0.1228  Acc@1: 87.5000 (86.4084)  Acc@5: 100.0000 (98.5406)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2660/3125]  eta: 0:02:40  Lr: 0.001875  Loss: 0.1966  Acc@1: 87.5000 (86.4196)  Acc@5: 100.0000 (98.5414)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:36  Lr: 0.001875  Loss: 0.2926  Acc@1: 87.5000 (86.4049)  Acc@5: 100.0000 (98.5375)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:33  Lr: 0.001875  Loss: 1.2381  Acc@1: 87.5000 (86.3950)  Acc@5: 100.0000 (98.5383)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:29  Lr: 0.001875  Loss: 0.7832  Acc@1: 87.5000 (86.4084)  Acc@5: 100.0000 (98.5391)  time: 0.3440  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:26  Lr: 0.001875  Loss: 0.1127  Acc@1: 93.7500 (86.4101)  Acc@5: 100.0000 (98.5376)  time: 0.3443  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:22  Lr: 0.001875  Loss: 0.2997  Acc@1: 87.5000 (86.4141)  Acc@5: 100.0000 (98.5407)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:19  Lr: 0.001875  Loss: 0.7038  Acc@1: 87.5000 (86.4089)  Acc@5: 100.0000 (98.5345)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:16  Lr: 0.001875  Loss: 0.3036  Acc@1: 87.5000 (86.4244)  Acc@5: 100.0000 (98.5399)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:12  Lr: 0.001875  Loss: 0.3678  Acc@1: 87.5000 (86.4260)  Acc@5: 100.0000 (98.5430)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:09  Lr: 0.001875  Loss: 0.3131  Acc@1: 87.5000 (86.4254)  Acc@5: 100.0000 (98.5437)  time: 0.3443  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:05  Lr: 0.001875  Loss: 0.7477  Acc@1: 87.5000 (86.4202)  Acc@5: 100.0000 (98.5399)  time: 0.3449  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:02  Lr: 0.001875  Loss: 0.4156  Acc@1: 87.5000 (86.4128)  Acc@5: 100.0000 (98.5429)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2780/3125]  eta: 0:01:58  Lr: 0.001875  Loss: 0.4102  Acc@1: 81.2500 (86.4055)  Acc@5: 100.0000 (98.5392)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2790/3125]  eta: 0:01:55  Lr: 0.001875  Loss: 0.5774  Acc@1: 81.2500 (86.3960)  Acc@5: 100.0000 (98.5332)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2800/3125]  eta: 0:01:51  Lr: 0.001875  Loss: 0.5330  Acc@1: 87.5000 (86.4022)  Acc@5: 100.0000 (98.5318)  time: 0.3461  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2810/3125]  eta: 0:01:48  Lr: 0.001875  Loss: 0.1782  Acc@1: 87.5000 (86.4172)  Acc@5: 100.0000 (98.5303)  time: 0.3457  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:45  Lr: 0.001875  Loss: 0.4834  Acc@1: 87.5000 (86.4233)  Acc@5: 100.0000 (98.5289)  time: 0.3450  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:41  Lr: 0.001875  Loss: 0.3838  Acc@1: 87.5000 (86.4248)  Acc@5: 100.0000 (98.5297)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:38  Lr: 0.001875  Loss: 0.4360  Acc@1: 87.5000 (86.4352)  Acc@5: 100.0000 (98.5326)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:34  Lr: 0.001875  Loss: 0.2454  Acc@1: 87.5000 (86.4390)  Acc@5: 100.0000 (98.5334)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:31  Lr: 0.001875  Loss: 0.1395  Acc@1: 87.5000 (86.4427)  Acc@5: 100.0000 (98.5385)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0806  Acc@1: 87.5000 (86.4507)  Acc@5: 100.0000 (98.5414)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:24  Lr: 0.001875  Loss: 0.7596  Acc@1: 87.5000 (86.4544)  Acc@5: 100.0000 (98.5400)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:20  Lr: 0.001875  Loss: 0.3948  Acc@1: 87.5000 (86.4645)  Acc@5: 100.0000 (98.5386)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:17  Lr: 0.001875  Loss: 1.0695  Acc@1: 93.7500 (86.4702)  Acc@5: 100.0000 (98.5393)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:14  Lr: 0.001875  Loss: 0.0884  Acc@1: 87.5000 (86.4673)  Acc@5: 100.0000 (98.5357)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:10  Lr: 0.001875  Loss: 0.0605  Acc@1: 87.5000 (86.4601)  Acc@5: 100.0000 (98.5365)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2961  Acc@1: 87.5000 (86.4573)  Acc@5: 100.0000 (98.5372)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:03  Lr: 0.001875  Loss: 0.4466  Acc@1: 87.5000 (86.4544)  Acc@5: 100.0000 (98.5400)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:00  Lr: 0.001875  Loss: 0.6898  Acc@1: 87.5000 (86.4516)  Acc@5: 100.0000 (98.5302)  time: 0.3446  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [2960/3125]  eta: 0:00:56  Lr: 0.001875  Loss: 0.1852  Acc@1: 87.5000 (86.4678)  Acc@5: 100.0000 (98.5309)  time: 0.3452  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [2970/3125]  eta: 0:00:53  Lr: 0.001875  Loss: 0.4238  Acc@1: 93.7500 (86.4818)  Acc@5: 100.0000 (98.5316)  time: 0.3442  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:49  Lr: 0.001875  Loss: 0.6749  Acc@1: 87.5000 (86.4664)  Acc@5: 100.0000 (98.5261)  time: 0.3447  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:46  Lr: 0.001875  Loss: 0.2401  Acc@1: 81.2500 (86.4636)  Acc@5: 100.0000 (98.5247)  time: 0.3464  data: 0.0018  max mem: 2501
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: 0.3975  Acc@1: 87.5000 (86.4753)  Acc@5: 100.0000 (98.5234)  time: 0.3457  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:39  Lr: 0.001875  Loss: 0.5336  Acc@1: 87.5000 (86.4746)  Acc@5: 100.0000 (98.5242)  time: 0.3443  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1390  Acc@1: 87.5000 (86.4780)  Acc@5: 100.0000 (98.5249)  time: 0.3442  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1673  Acc@1: 87.5000 (86.4752)  Acc@5: 100.0000 (98.5257)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: 0.5667  Acc@1: 81.2500 (86.4642)  Acc@5: 100.0000 (98.5182)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:25  Lr: 0.001875  Loss: 0.4894  Acc@1: 81.2500 (86.4655)  Acc@5: 100.0000 (98.5148)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: 0.5255  Acc@1: 81.2500 (86.4587)  Acc@5: 100.0000 (98.5156)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:18  Lr: 0.001875  Loss: 0.4675  Acc@1: 87.5000 (86.4682)  Acc@5: 100.0000 (98.5123)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2029  Acc@1: 87.5000 (86.4675)  Acc@5: 100.0000 (98.5131)  time: 0.3443  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: 0.3882  Acc@1: 87.5000 (86.4748)  Acc@5: 100.0000 (98.5138)  time: 0.3435  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2729  Acc@1: 87.5000 (86.4640)  Acc@5: 100.0000 (98.5166)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: 0.4357  Acc@1: 87.5000 (86.4694)  Acc@5: 100.0000 (98.5174)  time: 0.3451  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4827  Acc@1: 87.5000 (86.4747)  Acc@5: 100.0000 (98.5141)  time: 0.3442  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2510  Acc@1: 87.5000 (86.4760)  Acc@5: 100.0000 (98.5140)  time: 0.3441  data: 0.0012  max mem: 2501
Train: Epoch[4/5] Total time: 0:17:57 (0.3447 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2510  Acc@1: 87.5000 (86.4760)  Acc@5: 100.0000 (98.5140)
Train: Epoch[5/5]  [   0/3125]  eta: 0:32:56  Lr: 0.001875  Loss: 0.5865  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6326  data: 0.2899  max mem: 2501
Train: Epoch[5/5]  [  10/3125]  eta: 0:19:14  Lr: 0.001875  Loss: 1.0579  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (97.7273)  time: 0.3705  data: 0.0274  max mem: 2501
Train: Epoch[5/5]  [  20/3125]  eta: 0:18:29  Lr: 0.001875  Loss: 0.5813  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.6190)  time: 0.3437  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [  30/3125]  eta: 0:18:12  Lr: 0.001875  Loss: 0.2125  Acc@1: 93.7500 (88.1048)  Acc@5: 100.0000 (98.3871)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [  40/3125]  eta: 0:18:01  Lr: 0.001875  Loss: 0.3121  Acc@1: 93.7500 (88.1098)  Acc@5: 100.0000 (98.1707)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [  50/3125]  eta: 0:17:54  Lr: 0.001875  Loss: 0.4141  Acc@1: 93.7500 (88.1127)  Acc@5: 100.0000 (98.1618)  time: 0.3433  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [  60/3125]  eta: 0:17:47  Lr: 0.001875  Loss: 0.0858  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (97.9508)  time: 0.3434  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [  70/3125]  eta: 0:17:41  Lr: 0.001875  Loss: 0.4701  Acc@1: 87.5000 (88.4683)  Acc@5: 100.0000 (98.2394)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [  80/3125]  eta: 0:17:36  Lr: 0.001875  Loss: 0.1798  Acc@1: 87.5000 (87.8858)  Acc@5: 100.0000 (98.1481)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [  90/3125]  eta: 0:17:32  Lr: 0.001875  Loss: 0.2941  Acc@1: 87.5000 (87.9121)  Acc@5: 100.0000 (98.2830)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 100/3125]  eta: 0:17:27  Lr: 0.001875  Loss: 0.1864  Acc@1: 87.5000 (88.3045)  Acc@5: 100.0000 (98.4530)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 110/3125]  eta: 0:17:23  Lr: 0.001875  Loss: 0.0222  Acc@1: 93.7500 (88.5698)  Acc@5: 100.0000 (98.4797)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 120/3125]  eta: 0:17:19  Lr: 0.001875  Loss: 0.5724  Acc@1: 87.5000 (88.3781)  Acc@5: 100.0000 (98.3988)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 130/3125]  eta: 0:17:14  Lr: 0.001875  Loss: 0.0645  Acc@1: 87.5000 (88.4065)  Acc@5: 100.0000 (98.4733)  time: 0.3426  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 140/3125]  eta: 0:17:11  Lr: 0.001875  Loss: 0.9001  Acc@1: 87.5000 (88.3422)  Acc@5: 100.0000 (98.4486)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 150/3125]  eta: 0:17:07  Lr: 0.001875  Loss: 0.4681  Acc@1: 87.5000 (88.3278)  Acc@5: 100.0000 (98.5099)  time: 0.3454  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [ 160/3125]  eta: 0:17:04  Lr: 0.001875  Loss: 0.1011  Acc@1: 87.5000 (88.3152)  Acc@5: 100.0000 (98.4860)  time: 0.3444  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [ 170/3125]  eta: 0:17:00  Lr: 0.001875  Loss: 0.5799  Acc@1: 87.5000 (88.2675)  Acc@5: 100.0000 (98.5380)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 180/3125]  eta: 0:16:56  Lr: 0.001875  Loss: 0.2636  Acc@1: 81.2500 (87.7762)  Acc@5: 100.0000 (98.4461)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 190/3125]  eta: 0:16:53  Lr: 0.001875  Loss: 0.4147  Acc@1: 81.2500 (87.8599)  Acc@5: 100.0000 (98.4620)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 200/3125]  eta: 0:16:49  Lr: 0.001875  Loss: 0.1584  Acc@1: 87.5000 (88.0286)  Acc@5: 100.0000 (98.4764)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 210/3125]  eta: 0:16:45  Lr: 0.001875  Loss: 0.1719  Acc@1: 93.7500 (88.0332)  Acc@5: 100.0000 (98.4893)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 220/3125]  eta: 0:16:42  Lr: 0.001875  Loss: 0.2156  Acc@1: 93.7500 (88.0373)  Acc@5: 100.0000 (98.5294)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 230/3125]  eta: 0:16:38  Lr: 0.001875  Loss: 0.6076  Acc@1: 87.5000 (87.8788)  Acc@5: 100.0000 (98.5931)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 240/3125]  eta: 0:16:35  Lr: 0.001875  Loss: 0.4487  Acc@1: 87.5000 (87.8631)  Acc@5: 100.0000 (98.6515)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 250/3125]  eta: 0:16:31  Lr: 0.001875  Loss: 0.4058  Acc@1: 93.7500 (87.9731)  Acc@5: 100.0000 (98.6803)  time: 0.3458  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 260/3125]  eta: 0:16:28  Lr: 0.001875  Loss: 0.3614  Acc@1: 93.7500 (88.0029)  Acc@5: 100.0000 (98.7308)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 270/3125]  eta: 0:16:24  Lr: 0.001875  Loss: 1.0468  Acc@1: 87.5000 (88.0304)  Acc@5: 100.0000 (98.6854)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 280/3125]  eta: 0:16:21  Lr: 0.001875  Loss: 0.4819  Acc@1: 87.5000 (88.0116)  Acc@5: 100.0000 (98.7322)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 290/3125]  eta: 0:16:17  Lr: 0.001875  Loss: 0.4016  Acc@1: 87.5000 (87.9510)  Acc@5: 100.0000 (98.7328)  time: 0.3445  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 300/3125]  eta: 0:16:14  Lr: 0.001875  Loss: 0.2769  Acc@1: 87.5000 (87.9568)  Acc@5: 100.0000 (98.6919)  time: 0.3439  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 310/3125]  eta: 0:16:10  Lr: 0.001875  Loss: 0.7015  Acc@1: 87.5000 (88.0024)  Acc@5: 100.0000 (98.6736)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 320/3125]  eta: 0:16:06  Lr: 0.001875  Loss: 0.1402  Acc@1: 87.5000 (87.8699)  Acc@5: 100.0000 (98.6176)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 330/3125]  eta: 0:16:03  Lr: 0.001875  Loss: 1.0163  Acc@1: 81.2500 (87.7266)  Acc@5: 100.0000 (98.5838)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 340/3125]  eta: 0:16:00  Lr: 0.001875  Loss: 0.0382  Acc@1: 87.5000 (87.7749)  Acc@5: 100.0000 (98.5887)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 350/3125]  eta: 0:15:56  Lr: 0.001875  Loss: 0.2669  Acc@1: 87.5000 (87.6781)  Acc@5: 100.0000 (98.5933)  time: 0.3458  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 360/3125]  eta: 0:15:53  Lr: 0.001875  Loss: 0.5176  Acc@1: 81.2500 (87.5346)  Acc@5: 100.0000 (98.5976)  time: 0.3449  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 370/3125]  eta: 0:15:49  Lr: 0.001875  Loss: 0.3619  Acc@1: 81.2500 (87.4832)  Acc@5: 100.0000 (98.5849)  time: 0.3449  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 380/3125]  eta: 0:15:46  Lr: 0.001875  Loss: 0.8035  Acc@1: 81.2500 (87.3688)  Acc@5: 100.0000 (98.5564)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 390/3125]  eta: 0:15:43  Lr: 0.001875  Loss: 0.1493  Acc@1: 81.2500 (87.3561)  Acc@5: 100.0000 (98.5454)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 400/3125]  eta: 0:15:39  Lr: 0.001875  Loss: 0.6675  Acc@1: 87.5000 (87.4221)  Acc@5: 100.0000 (98.5661)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 410/3125]  eta: 0:15:36  Lr: 0.001875  Loss: 0.0664  Acc@1: 87.5000 (87.4088)  Acc@5: 100.0000 (98.6010)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 420/3125]  eta: 0:15:32  Lr: 0.001875  Loss: 0.4943  Acc@1: 87.5000 (87.3812)  Acc@5: 100.0000 (98.5748)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 430/3125]  eta: 0:15:29  Lr: 0.001875  Loss: 0.4041  Acc@1: 87.5000 (87.4130)  Acc@5: 100.0000 (98.5644)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 440/3125]  eta: 0:15:25  Lr: 0.001875  Loss: 0.2613  Acc@1: 87.5000 (87.4433)  Acc@5: 100.0000 (98.5686)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 450/3125]  eta: 0:15:22  Lr: 0.001875  Loss: 0.5336  Acc@1: 87.5000 (87.4169)  Acc@5: 100.0000 (98.5865)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 460/3125]  eta: 0:15:19  Lr: 0.001875  Loss: 0.2237  Acc@1: 87.5000 (87.4729)  Acc@5: 100.0000 (98.6171)  time: 0.3454  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 470/3125]  eta: 0:15:15  Lr: 0.001875  Loss: 0.3487  Acc@1: 87.5000 (87.4735)  Acc@5: 100.0000 (98.6067)  time: 0.3465  data: 0.0017  max mem: 2501
Train: Epoch[5/5]  [ 480/3125]  eta: 0:15:12  Lr: 0.001875  Loss: 0.1932  Acc@1: 81.2500 (87.3571)  Acc@5: 100.0000 (98.5967)  time: 0.3447  data: 0.0015  max mem: 2501
Train: Epoch[5/5]  [ 490/3125]  eta: 0:15:08  Lr: 0.001875  Loss: 0.5969  Acc@1: 87.5000 (87.4109)  Acc@5: 100.0000 (98.5871)  time: 0.3445  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 500/3125]  eta: 0:15:05  Lr: 0.001875  Loss: 0.3217  Acc@1: 87.5000 (87.3877)  Acc@5: 100.0000 (98.5778)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 510/3125]  eta: 0:15:01  Lr: 0.001875  Loss: 0.4779  Acc@1: 81.2500 (87.2676)  Acc@5: 100.0000 (98.5812)  time: 0.3465  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 520/3125]  eta: 0:14:58  Lr: 0.001875  Loss: 0.1550  Acc@1: 81.2500 (87.2481)  Acc@5: 100.0000 (98.5365)  time: 0.3474  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [ 530/3125]  eta: 0:14:55  Lr: 0.001875  Loss: 0.3827  Acc@1: 87.5000 (87.2293)  Acc@5: 100.0000 (98.5169)  time: 0.3455  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 540/3125]  eta: 0:14:51  Lr: 0.001875  Loss: 0.1744  Acc@1: 93.7500 (87.3383)  Acc@5: 100.0000 (98.5213)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 550/3125]  eta: 0:14:48  Lr: 0.001875  Loss: 0.5248  Acc@1: 87.5000 (87.3072)  Acc@5: 100.0000 (98.5368)  time: 0.3454  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 560/3125]  eta: 0:14:44  Lr: 0.001875  Loss: 0.5375  Acc@1: 81.2500 (87.2549)  Acc@5: 100.0000 (98.5294)  time: 0.3463  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [ 570/3125]  eta: 0:14:41  Lr: 0.001875  Loss: 0.3421  Acc@1: 87.5000 (87.2920)  Acc@5: 100.0000 (98.5333)  time: 0.3453  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 580/3125]  eta: 0:14:37  Lr: 0.001875  Loss: 0.3546  Acc@1: 87.5000 (87.3279)  Acc@5: 100.0000 (98.5262)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 590/3125]  eta: 0:14:34  Lr: 0.001875  Loss: 0.5550  Acc@1: 87.5000 (87.2568)  Acc@5: 100.0000 (98.4983)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 600/3125]  eta: 0:14:30  Lr: 0.001875  Loss: 0.2071  Acc@1: 81.2500 (87.2816)  Acc@5: 100.0000 (98.5129)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 610/3125]  eta: 0:14:27  Lr: 0.001875  Loss: 0.0434  Acc@1: 87.5000 (87.2238)  Acc@5: 100.0000 (98.5270)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 620/3125]  eta: 0:14:23  Lr: 0.001875  Loss: 0.5872  Acc@1: 81.2500 (87.1679)  Acc@5: 100.0000 (98.5306)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 630/3125]  eta: 0:14:20  Lr: 0.001875  Loss: 0.4753  Acc@1: 81.2500 (87.1137)  Acc@5: 100.0000 (98.5242)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 640/3125]  eta: 0:14:17  Lr: 0.001875  Loss: 0.4577  Acc@1: 87.5000 (87.1197)  Acc@5: 100.0000 (98.5472)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 650/3125]  eta: 0:14:13  Lr: 0.001875  Loss: 0.4309  Acc@1: 87.5000 (87.0872)  Acc@5: 100.0000 (98.5503)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 660/3125]  eta: 0:14:10  Lr: 0.001875  Loss: 0.2677  Acc@1: 87.5000 (87.1029)  Acc@5: 100.0000 (98.5628)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 670/3125]  eta: 0:14:06  Lr: 0.001875  Loss: 0.4172  Acc@1: 87.5000 (87.0715)  Acc@5: 100.0000 (98.5469)  time: 0.3435  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 680/3125]  eta: 0:14:03  Lr: 0.001875  Loss: 0.7075  Acc@1: 87.5000 (87.0503)  Acc@5: 100.0000 (98.5499)  time: 0.3440  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 690/3125]  eta: 0:13:59  Lr: 0.001875  Loss: 0.1639  Acc@1: 87.5000 (87.0387)  Acc@5: 100.0000 (98.5528)  time: 0.3438  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 700/3125]  eta: 0:13:56  Lr: 0.001875  Loss: 0.3825  Acc@1: 87.5000 (87.0275)  Acc@5: 100.0000 (98.5467)  time: 0.3439  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 710/3125]  eta: 0:13:52  Lr: 0.001875  Loss: 0.1527  Acc@1: 87.5000 (87.0429)  Acc@5: 100.0000 (98.5408)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 720/3125]  eta: 0:13:49  Lr: 0.001875  Loss: 0.5784  Acc@1: 87.5000 (87.0406)  Acc@5: 100.0000 (98.5350)  time: 0.3427  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 730/3125]  eta: 0:13:45  Lr: 0.001875  Loss: 0.3593  Acc@1: 87.5000 (87.0554)  Acc@5: 100.0000 (98.5294)  time: 0.3439  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [ 740/3125]  eta: 0:13:42  Lr: 0.001875  Loss: 0.4226  Acc@1: 87.5000 (87.0445)  Acc@5: 100.0000 (98.5155)  time: 0.3434  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [ 750/3125]  eta: 0:13:38  Lr: 0.001875  Loss: 0.4421  Acc@1: 87.5000 (87.0340)  Acc@5: 100.0000 (98.5186)  time: 0.3431  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 760/3125]  eta: 0:13:35  Lr: 0.001875  Loss: 0.3643  Acc@1: 87.5000 (87.0565)  Acc@5: 100.0000 (98.5135)  time: 0.3429  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [ 770/3125]  eta: 0:13:31  Lr: 0.001875  Loss: 0.4217  Acc@1: 87.5000 (87.0136)  Acc@5: 100.0000 (98.5165)  time: 0.3419  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 780/3125]  eta: 0:13:28  Lr: 0.001875  Loss: 0.4629  Acc@1: 87.5000 (87.0359)  Acc@5: 100.0000 (98.5275)  time: 0.3429  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 790/3125]  eta: 0:13:24  Lr: 0.001875  Loss: 0.6897  Acc@1: 87.5000 (87.0733)  Acc@5: 100.0000 (98.5303)  time: 0.3452  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [ 800/3125]  eta: 0:13:21  Lr: 0.001875  Loss: 0.4524  Acc@1: 87.5000 (87.0630)  Acc@5: 100.0000 (98.5487)  time: 0.3444  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 810/3125]  eta: 0:13:17  Lr: 0.001875  Loss: 0.5775  Acc@1: 87.5000 (87.0761)  Acc@5: 100.0000 (98.5589)  time: 0.3433  data: 0.0002  max mem: 2501
Train: Epoch[5/5]  [ 820/3125]  eta: 0:13:14  Lr: 0.001875  Loss: 0.2848  Acc@1: 87.5000 (87.0965)  Acc@5: 100.0000 (98.5460)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 830/3125]  eta: 0:13:10  Lr: 0.001875  Loss: 0.2168  Acc@1: 87.5000 (87.0563)  Acc@5: 100.0000 (98.5184)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 840/3125]  eta: 0:13:07  Lr: 0.001875  Loss: 0.3309  Acc@1: 87.5000 (87.0690)  Acc@5: 100.0000 (98.5211)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 850/3125]  eta: 0:13:03  Lr: 0.001875  Loss: 0.5606  Acc@1: 93.7500 (87.0887)  Acc@5: 100.0000 (98.5311)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 860/3125]  eta: 0:13:00  Lr: 0.001875  Loss: 0.5972  Acc@1: 87.5000 (87.0935)  Acc@5: 100.0000 (98.5264)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 870/3125]  eta: 0:12:56  Lr: 0.001875  Loss: 0.4322  Acc@1: 87.5000 (87.1197)  Acc@5: 100.0000 (98.5362)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 880/3125]  eta: 0:12:53  Lr: 0.001875  Loss: 0.0376  Acc@1: 87.5000 (87.0743)  Acc@5: 100.0000 (98.5102)  time: 0.3423  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 890/3125]  eta: 0:12:50  Lr: 0.001875  Loss: 0.4432  Acc@1: 87.5000 (87.1002)  Acc@5: 100.0000 (98.5129)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 900/3125]  eta: 0:12:46  Lr: 0.001875  Loss: 0.3324  Acc@1: 87.5000 (87.0422)  Acc@5: 100.0000 (98.4878)  time: 0.3453  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 910/3125]  eta: 0:12:43  Lr: 0.001875  Loss: 0.1694  Acc@1: 81.2500 (87.0198)  Acc@5: 100.0000 (98.4769)  time: 0.3438  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 920/3125]  eta: 0:12:39  Lr: 0.001875  Loss: 0.2185  Acc@1: 87.5000 (87.0250)  Acc@5: 100.0000 (98.4663)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 930/3125]  eta: 0:12:36  Lr: 0.001875  Loss: 0.2506  Acc@1: 87.5000 (87.0234)  Acc@5: 100.0000 (98.4761)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 940/3125]  eta: 0:12:32  Lr: 0.001875  Loss: 0.2711  Acc@1: 87.5000 (87.0151)  Acc@5: 100.0000 (98.4524)  time: 0.3445  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [ 950/3125]  eta: 0:12:29  Lr: 0.001875  Loss: 0.2192  Acc@1: 87.5000 (86.9808)  Acc@5: 100.0000 (98.4556)  time: 0.3453  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [ 960/3125]  eta: 0:12:25  Lr: 0.001875  Loss: 0.4859  Acc@1: 87.5000 (86.9927)  Acc@5: 100.0000 (98.4651)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 970/3125]  eta: 0:12:22  Lr: 0.001875  Loss: 0.3933  Acc@1: 87.5000 (87.0237)  Acc@5: 100.0000 (98.4745)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 980/3125]  eta: 0:12:19  Lr: 0.001875  Loss: 0.5916  Acc@1: 87.5000 (87.0349)  Acc@5: 100.0000 (98.4646)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 990/3125]  eta: 0:12:15  Lr: 0.001875  Loss: 0.5273  Acc@1: 87.5000 (87.0270)  Acc@5: 100.0000 (98.4612)  time: 0.3441  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1000/3125]  eta: 0:12:12  Lr: 0.001875  Loss: 0.3589  Acc@1: 87.5000 (87.0317)  Acc@5: 100.0000 (98.4703)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1010/3125]  eta: 0:12:08  Lr: 0.001875  Loss: 0.1239  Acc@1: 87.5000 (87.0054)  Acc@5: 100.0000 (98.4730)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1020/3125]  eta: 0:12:05  Lr: 0.001875  Loss: 0.4005  Acc@1: 81.2500 (86.9797)  Acc@5: 100.0000 (98.4758)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1030/3125]  eta: 0:12:01  Lr: 0.001875  Loss: 0.2661  Acc@1: 87.5000 (87.0150)  Acc@5: 100.0000 (98.4784)  time: 0.3460  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [1040/3125]  eta: 0:11:58  Lr: 0.001875  Loss: 0.3943  Acc@1: 87.5000 (86.9837)  Acc@5: 100.0000 (98.4690)  time: 0.3454  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [1050/3125]  eta: 0:11:54  Lr: 0.001875  Loss: 0.3901  Acc@1: 87.5000 (87.0243)  Acc@5: 100.0000 (98.4657)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1060/3125]  eta: 0:11:51  Lr: 0.001875  Loss: 0.3121  Acc@1: 87.5000 (87.0287)  Acc@5: 100.0000 (98.4684)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1070/3125]  eta: 0:11:48  Lr: 0.001875  Loss: 0.4445  Acc@1: 87.5000 (87.0040)  Acc@5: 100.0000 (98.4827)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1080/3125]  eta: 0:11:44  Lr: 0.001875  Loss: 0.3067  Acc@1: 87.5000 (87.0086)  Acc@5: 100.0000 (98.4968)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1090/3125]  eta: 0:11:41  Lr: 0.001875  Loss: 0.6018  Acc@1: 87.5000 (87.0016)  Acc@5: 100.0000 (98.5105)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1100/3125]  eta: 0:11:37  Lr: 0.001875  Loss: 0.2545  Acc@1: 87.5000 (87.0232)  Acc@5: 100.0000 (98.5127)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1110/3125]  eta: 0:11:34  Lr: 0.001875  Loss: 0.6883  Acc@1: 87.5000 (87.0162)  Acc@5: 100.0000 (98.4923)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1120/3125]  eta: 0:11:30  Lr: 0.001875  Loss: 0.3046  Acc@1: 87.5000 (87.0205)  Acc@5: 100.0000 (98.5002)  time: 0.3452  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1130/3125]  eta: 0:11:27  Lr: 0.001875  Loss: 0.0881  Acc@1: 87.5000 (86.9916)  Acc@5: 100.0000 (98.4914)  time: 0.3441  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1140/3125]  eta: 0:11:23  Lr: 0.001875  Loss: 0.8055  Acc@1: 81.2500 (86.9522)  Acc@5: 100.0000 (98.4772)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1150/3125]  eta: 0:11:20  Lr: 0.001875  Loss: 0.6278  Acc@1: 81.2500 (86.9570)  Acc@5: 100.0000 (98.4904)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1160/3125]  eta: 0:11:16  Lr: 0.001875  Loss: 0.2165  Acc@1: 87.5000 (86.9401)  Acc@5: 100.0000 (98.4873)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1170/3125]  eta: 0:11:13  Lr: 0.001875  Loss: 0.3534  Acc@1: 87.5000 (86.9769)  Acc@5: 100.0000 (98.4949)  time: 0.3428  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1180/3125]  eta: 0:11:10  Lr: 0.001875  Loss: 0.4041  Acc@1: 87.5000 (86.9496)  Acc@5: 100.0000 (98.4865)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1190/3125]  eta: 0:11:06  Lr: 0.001875  Loss: 0.4604  Acc@1: 87.5000 (86.9700)  Acc@5: 100.0000 (98.4939)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1200/3125]  eta: 0:11:03  Lr: 0.001875  Loss: 0.3035  Acc@1: 87.5000 (86.9640)  Acc@5: 100.0000 (98.4908)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1210/3125]  eta: 0:10:59  Lr: 0.001875  Loss: 0.4786  Acc@1: 87.5000 (86.9684)  Acc@5: 100.0000 (98.5033)  time: 0.3443  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [1220/3125]  eta: 0:10:56  Lr: 0.001875  Loss: 0.3869  Acc@1: 87.5000 (86.9676)  Acc@5: 100.0000 (98.5053)  time: 0.3445  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [1230/3125]  eta: 0:10:52  Lr: 0.001875  Loss: 0.0823  Acc@1: 87.5000 (86.9821)  Acc@5: 100.0000 (98.5022)  time: 0.3445  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1240/3125]  eta: 0:10:49  Lr: 0.001875  Loss: 0.4414  Acc@1: 81.2500 (86.9309)  Acc@5: 100.0000 (98.4992)  time: 0.3443  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1250/3125]  eta: 0:10:45  Lr: 0.001875  Loss: 0.4442  Acc@1: 81.2500 (86.8505)  Acc@5: 100.0000 (98.4862)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1260/3125]  eta: 0:10:42  Lr: 0.001875  Loss: 0.4169  Acc@1: 81.2500 (86.8656)  Acc@5: 100.0000 (98.4982)  time: 0.3424  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1270/3125]  eta: 0:10:38  Lr: 0.001875  Loss: 0.5187  Acc@1: 87.5000 (86.8558)  Acc@5: 100.0000 (98.4953)  time: 0.3428  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1280/3125]  eta: 0:10:35  Lr: 0.001875  Loss: 0.5485  Acc@1: 87.5000 (86.8755)  Acc@5: 100.0000 (98.4924)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1290/3125]  eta: 0:10:32  Lr: 0.001875  Loss: 0.2978  Acc@1: 87.5000 (86.8658)  Acc@5: 100.0000 (98.5041)  time: 0.3458  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1300/3125]  eta: 0:10:28  Lr: 0.001875  Loss: 0.5801  Acc@1: 87.5000 (86.8659)  Acc@5: 100.0000 (98.5108)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1310/3125]  eta: 0:10:25  Lr: 0.001875  Loss: 0.3781  Acc@1: 87.5000 (86.8755)  Acc@5: 100.0000 (98.5174)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1320/3125]  eta: 0:10:21  Lr: 0.001875  Loss: 0.3314  Acc@1: 87.5000 (86.8707)  Acc@5: 100.0000 (98.5144)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1330/3125]  eta: 0:10:18  Lr: 0.001875  Loss: 0.6473  Acc@1: 87.5000 (86.8802)  Acc@5: 100.0000 (98.5255)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1340/3125]  eta: 0:10:14  Lr: 0.001875  Loss: 0.1529  Acc@1: 93.7500 (86.8941)  Acc@5: 100.0000 (98.5272)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1350/3125]  eta: 0:10:11  Lr: 0.001875  Loss: 0.5506  Acc@1: 93.7500 (86.8755)  Acc@5: 100.0000 (98.5242)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1360/3125]  eta: 0:10:07  Lr: 0.001875  Loss: 0.4615  Acc@1: 87.5000 (86.8617)  Acc@5: 100.0000 (98.5259)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1370/3125]  eta: 0:10:04  Lr: 0.001875  Loss: 0.5074  Acc@1: 87.5000 (86.8755)  Acc@5: 100.0000 (98.5275)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1380/3125]  eta: 0:10:01  Lr: 0.001875  Loss: 0.2502  Acc@1: 87.5000 (86.8709)  Acc@5: 100.0000 (98.5337)  time: 0.3449  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1390/3125]  eta: 0:09:57  Lr: 0.001875  Loss: 0.2651  Acc@1: 87.5000 (86.8934)  Acc@5: 100.0000 (98.5442)  time: 0.3431  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1400/3125]  eta: 0:09:54  Lr: 0.001875  Loss: 0.4208  Acc@1: 87.5000 (86.8665)  Acc@5: 100.0000 (98.5412)  time: 0.3432  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1410/3125]  eta: 0:09:50  Lr: 0.001875  Loss: 0.3212  Acc@1: 87.5000 (86.8577)  Acc@5: 100.0000 (98.5516)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1420/3125]  eta: 0:09:47  Lr: 0.001875  Loss: 0.2149  Acc@1: 87.5000 (86.8578)  Acc@5: 100.0000 (98.5530)  time: 0.3434  data: 0.0002  max mem: 2501
Train: Epoch[5/5]  [1430/3125]  eta: 0:09:43  Lr: 0.001875  Loss: 0.7128  Acc@1: 87.5000 (86.8580)  Acc@5: 100.0000 (98.5369)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1440/3125]  eta: 0:09:40  Lr: 0.001875  Loss: 0.1449  Acc@1: 87.5000 (86.8668)  Acc@5: 100.0000 (98.5340)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1450/3125]  eta: 0:09:36  Lr: 0.001875  Loss: 0.3051  Acc@1: 87.5000 (86.8625)  Acc@5: 100.0000 (98.5355)  time: 0.3445  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1460/3125]  eta: 0:09:33  Lr: 0.001875  Loss: 0.1278  Acc@1: 87.5000 (86.8540)  Acc@5: 100.0000 (98.5370)  time: 0.3433  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [1470/3125]  eta: 0:09:29  Lr: 0.001875  Loss: 0.2924  Acc@1: 81.2500 (86.8372)  Acc@5: 100.0000 (98.5257)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1480/3125]  eta: 0:09:26  Lr: 0.001875  Loss: 0.1635  Acc@1: 81.2500 (86.8290)  Acc@5: 100.0000 (98.5230)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1490/3125]  eta: 0:09:23  Lr: 0.001875  Loss: 0.3281  Acc@1: 81.2500 (86.8084)  Acc@5: 100.0000 (98.5287)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1500/3125]  eta: 0:09:19  Lr: 0.001875  Loss: 0.2879  Acc@1: 87.5000 (86.8088)  Acc@5: 100.0000 (98.5343)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1510/3125]  eta: 0:09:16  Lr: 0.001875  Loss: 0.3960  Acc@1: 87.5000 (86.7968)  Acc@5: 100.0000 (98.5399)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1520/3125]  eta: 0:09:12  Lr: 0.001875  Loss: 0.7025  Acc@1: 87.5000 (86.7932)  Acc@5: 100.0000 (98.5371)  time: 0.3451  data: 0.0015  max mem: 2501
Train: Epoch[5/5]  [1530/3125]  eta: 0:09:09  Lr: 0.001875  Loss: 0.3742  Acc@1: 81.2500 (86.7734)  Acc@5: 100.0000 (98.5467)  time: 0.3449  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [1540/3125]  eta: 0:09:05  Lr: 0.001875  Loss: 0.1917  Acc@1: 81.2500 (86.7700)  Acc@5: 100.0000 (98.5359)  time: 0.3443  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1550/3125]  eta: 0:09:02  Lr: 0.001875  Loss: 0.5905  Acc@1: 87.5000 (86.7747)  Acc@5: 100.0000 (98.5372)  time: 0.3452  data: 0.0020  max mem: 2501
Train: Epoch[5/5]  [1560/3125]  eta: 0:08:58  Lr: 0.001875  Loss: 0.3206  Acc@1: 87.5000 (86.7433)  Acc@5: 100.0000 (98.5386)  time: 0.3447  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [1570/3125]  eta: 0:08:55  Lr: 0.001875  Loss: 0.4466  Acc@1: 81.2500 (86.7242)  Acc@5: 100.0000 (98.5360)  time: 0.3441  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [1580/3125]  eta: 0:08:52  Lr: 0.001875  Loss: 0.5002  Acc@1: 87.5000 (86.7410)  Acc@5: 100.0000 (98.5373)  time: 0.3441  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [1590/3125]  eta: 0:08:48  Lr: 0.001875  Loss: 0.6121  Acc@1: 93.7500 (86.7693)  Acc@5: 100.0000 (98.5426)  time: 0.3434  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1600/3125]  eta: 0:08:45  Lr: 0.001875  Loss: 0.1406  Acc@1: 87.5000 (86.7583)  Acc@5: 100.0000 (98.5439)  time: 0.3439  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1610/3125]  eta: 0:08:41  Lr: 0.001875  Loss: 0.2439  Acc@1: 87.5000 (86.7862)  Acc@5: 100.0000 (98.5529)  time: 0.3443  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1620/3125]  eta: 0:08:38  Lr: 0.001875  Loss: 0.3753  Acc@1: 87.5000 (86.7713)  Acc@5: 100.0000 (98.5541)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1630/3125]  eta: 0:08:34  Lr: 0.001875  Loss: 0.1901  Acc@1: 87.5000 (86.8064)  Acc@5: 100.0000 (98.5630)  time: 0.3476  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1640/3125]  eta: 0:08:31  Lr: 0.001875  Loss: 0.7247  Acc@1: 93.7500 (86.8373)  Acc@5: 100.0000 (98.5565)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1650/3125]  eta: 0:08:27  Lr: 0.001875  Loss: 0.2739  Acc@1: 93.7500 (86.8413)  Acc@5: 100.0000 (98.5615)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1660/3125]  eta: 0:08:24  Lr: 0.001875  Loss: 0.3772  Acc@1: 87.5000 (86.8377)  Acc@5: 100.0000 (98.5551)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1670/3125]  eta: 0:08:21  Lr: 0.001875  Loss: 0.3266  Acc@1: 87.5000 (86.8455)  Acc@5: 100.0000 (98.5488)  time: 0.3436  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1680/3125]  eta: 0:08:17  Lr: 0.001875  Loss: 0.6959  Acc@1: 81.2500 (86.8196)  Acc@5: 100.0000 (98.5425)  time: 0.3440  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1690/3125]  eta: 0:08:14  Lr: 0.001875  Loss: 0.5508  Acc@1: 87.5000 (86.8273)  Acc@5: 100.0000 (98.5364)  time: 0.3457  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1700/3125]  eta: 0:08:10  Lr: 0.001875  Loss: 0.3695  Acc@1: 87.5000 (86.8313)  Acc@5: 100.0000 (98.5376)  time: 0.3462  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1710/3125]  eta: 0:08:07  Lr: 0.001875  Loss: 0.4165  Acc@1: 93.7500 (86.8534)  Acc@5: 100.0000 (98.5425)  time: 0.3460  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [1720/3125]  eta: 0:08:03  Lr: 0.001875  Loss: 0.9724  Acc@1: 93.7500 (86.8826)  Acc@5: 100.0000 (98.5401)  time: 0.3464  data: 0.0019  max mem: 2501
Train: Epoch[5/5]  [1730/3125]  eta: 0:08:00  Lr: 0.001875  Loss: 0.1528  Acc@1: 87.5000 (86.8718)  Acc@5: 100.0000 (98.5341)  time: 0.3452  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [1740/3125]  eta: 0:07:57  Lr: 0.001875  Loss: 0.4053  Acc@1: 87.5000 (86.8789)  Acc@5: 100.0000 (98.5353)  time: 0.3446  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1750/3125]  eta: 0:07:53  Lr: 0.001875  Loss: 0.1285  Acc@1: 87.5000 (86.8646)  Acc@5: 100.0000 (98.5294)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1760/3125]  eta: 0:07:50  Lr: 0.001875  Loss: 0.3474  Acc@1: 87.5000 (86.8754)  Acc@5: 100.0000 (98.5378)  time: 0.3457  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1770/3125]  eta: 0:07:46  Lr: 0.001875  Loss: 0.1687  Acc@1: 87.5000 (86.8648)  Acc@5: 100.0000 (98.5284)  time: 0.3457  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1780/3125]  eta: 0:07:43  Lr: 0.001875  Loss: 0.1955  Acc@1: 93.7500 (86.8824)  Acc@5: 100.0000 (98.5331)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1790/3125]  eta: 0:07:39  Lr: 0.001875  Loss: 0.6311  Acc@1: 87.5000 (86.8823)  Acc@5: 100.0000 (98.5343)  time: 0.3430  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1800/3125]  eta: 0:07:36  Lr: 0.001875  Loss: 0.4480  Acc@1: 87.5000 (86.8719)  Acc@5: 100.0000 (98.5355)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1810/3125]  eta: 0:07:32  Lr: 0.001875  Loss: 0.1613  Acc@1: 87.5000 (86.8719)  Acc@5: 100.0000 (98.5367)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1820/3125]  eta: 0:07:29  Lr: 0.001875  Loss: 0.3918  Acc@1: 87.5000 (86.8719)  Acc@5: 100.0000 (98.5379)  time: 0.3451  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1830/3125]  eta: 0:07:26  Lr: 0.001875  Loss: 0.8652  Acc@1: 87.5000 (86.8788)  Acc@5: 100.0000 (98.5356)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1840/3125]  eta: 0:07:22  Lr: 0.001875  Loss: 0.3388  Acc@1: 93.7500 (86.8889)  Acc@5: 100.0000 (98.5334)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1850/3125]  eta: 0:07:19  Lr: 0.001875  Loss: 0.1986  Acc@1: 87.5000 (86.8990)  Acc@5: 100.0000 (98.5312)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1860/3125]  eta: 0:07:15  Lr: 0.001875  Loss: 0.2976  Acc@1: 87.5000 (86.8921)  Acc@5: 100.0000 (98.5290)  time: 0.3447  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1870/3125]  eta: 0:07:12  Lr: 0.001875  Loss: 0.6006  Acc@1: 87.5000 (86.8854)  Acc@5: 100.0000 (98.5302)  time: 0.3454  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1880/3125]  eta: 0:07:08  Lr: 0.001875  Loss: 0.3313  Acc@1: 87.5000 (86.9052)  Acc@5: 100.0000 (98.5280)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1890/3125]  eta: 0:07:05  Lr: 0.001875  Loss: 0.2473  Acc@1: 87.5000 (86.9084)  Acc@5: 100.0000 (98.5193)  time: 0.3431  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:01  Lr: 0.001875  Loss: 0.0959  Acc@1: 87.5000 (86.9345)  Acc@5: 100.0000 (98.5238)  time: 0.3438  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1910/3125]  eta: 0:06:58  Lr: 0.001875  Loss: 0.4417  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (98.5184)  time: 0.3451  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1920/3125]  eta: 0:06:55  Lr: 0.001875  Loss: 0.5909  Acc@1: 87.5000 (86.9014)  Acc@5: 100.0000 (98.5197)  time: 0.3461  data: 0.0018  max mem: 2501
Train: Epoch[5/5]  [1930/3125]  eta: 0:06:51  Lr: 0.001875  Loss: 0.6214  Acc@1: 87.5000 (86.8850)  Acc@5: 100.0000 (98.5241)  time: 0.3448  data: 0.0015  max mem: 2501
Train: Epoch[5/5]  [1940/3125]  eta: 0:06:48  Lr: 0.001875  Loss: 0.3459  Acc@1: 87.5000 (86.9172)  Acc@5: 100.0000 (98.5285)  time: 0.3439  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [1950/3125]  eta: 0:06:44  Lr: 0.001875  Loss: 0.6322  Acc@1: 87.5000 (86.8977)  Acc@5: 100.0000 (98.5232)  time: 0.3435  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1960/3125]  eta: 0:06:41  Lr: 0.001875  Loss: 0.0568  Acc@1: 81.2500 (86.8913)  Acc@5: 100.0000 (98.5212)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1970/3125]  eta: 0:06:37  Lr: 0.001875  Loss: 0.5659  Acc@1: 81.2500 (86.8785)  Acc@5: 100.0000 (98.5255)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1980/3125]  eta: 0:06:34  Lr: 0.001875  Loss: 0.3279  Acc@1: 87.5000 (86.8722)  Acc@5: 100.0000 (98.5298)  time: 0.3457  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1990/3125]  eta: 0:06:30  Lr: 0.001875  Loss: 0.1234  Acc@1: 87.5000 (86.8785)  Acc@5: 100.0000 (98.5309)  time: 0.3457  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [2000/3125]  eta: 0:06:27  Lr: 0.001875  Loss: 0.4526  Acc@1: 87.5000 (86.8691)  Acc@5: 100.0000 (98.5289)  time: 0.3439  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [2010/3125]  eta: 0:06:24  Lr: 0.001875  Loss: 0.4822  Acc@1: 87.5000 (86.8784)  Acc@5: 100.0000 (98.5269)  time: 0.3445  data: 0.0017  max mem: 2501
Train: Epoch[5/5]  [2020/3125]  eta: 0:06:20  Lr: 0.001875  Loss: 0.0688  Acc@1: 87.5000 (86.8568)  Acc@5: 100.0000 (98.5280)  time: 0.3441  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2030/3125]  eta: 0:06:17  Lr: 0.001875  Loss: 1.7743  Acc@1: 87.5000 (86.8568)  Acc@5: 100.0000 (98.5167)  time: 0.3438  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2040/3125]  eta: 0:06:13  Lr: 0.001875  Loss: 0.0764  Acc@1: 87.5000 (86.8202)  Acc@5: 100.0000 (98.5148)  time: 0.3438  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2050/3125]  eta: 0:06:10  Lr: 0.001875  Loss: 0.8229  Acc@1: 87.5000 (86.8205)  Acc@5: 100.0000 (98.5190)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:06  Lr: 0.001875  Loss: 0.6411  Acc@1: 87.5000 (86.8207)  Acc@5: 100.0000 (98.5201)  time: 0.3440  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:03  Lr: 0.001875  Loss: 0.3445  Acc@1: 87.5000 (86.8180)  Acc@5: 100.0000 (98.5212)  time: 0.3457  data: 0.0019  max mem: 2501
Train: Epoch[5/5]  [2080/3125]  eta: 0:05:59  Lr: 0.001875  Loss: 0.5095  Acc@1: 87.5000 (86.8182)  Acc@5: 100.0000 (98.5193)  time: 0.3467  data: 0.0017  max mem: 2501
Train: Epoch[5/5]  [2090/3125]  eta: 0:05:56  Lr: 0.001875  Loss: 0.1720  Acc@1: 87.5000 (86.8335)  Acc@5: 100.0000 (98.5204)  time: 0.3444  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2100/3125]  eta: 0:05:53  Lr: 0.001875  Loss: 0.2276  Acc@1: 87.5000 (86.8218)  Acc@5: 100.0000 (98.5186)  time: 0.3431  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2110/3125]  eta: 0:05:49  Lr: 0.001875  Loss: 0.6535  Acc@1: 87.5000 (86.8190)  Acc@5: 100.0000 (98.5256)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2120/3125]  eta: 0:05:46  Lr: 0.001875  Loss: 0.3887  Acc@1: 87.5000 (86.8134)  Acc@5: 100.0000 (98.5325)  time: 0.3432  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2130/3125]  eta: 0:05:42  Lr: 0.001875  Loss: 0.3942  Acc@1: 87.5000 (86.8049)  Acc@5: 100.0000 (98.5277)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2140/3125]  eta: 0:05:39  Lr: 0.001875  Loss: 0.6374  Acc@1: 87.5000 (86.8111)  Acc@5: 100.0000 (98.5346)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2150/3125]  eta: 0:05:35  Lr: 0.001875  Loss: 0.4297  Acc@1: 87.5000 (86.8172)  Acc@5: 100.0000 (98.5356)  time: 0.3438  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2160/3125]  eta: 0:05:32  Lr: 0.001875  Loss: 0.4455  Acc@1: 87.5000 (86.8030)  Acc@5: 100.0000 (98.5279)  time: 0.3437  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2170/3125]  eta: 0:05:28  Lr: 0.001875  Loss: 0.0762  Acc@1: 81.2500 (86.7947)  Acc@5: 100.0000 (98.5289)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2180/3125]  eta: 0:05:25  Lr: 0.001875  Loss: 0.3678  Acc@1: 87.5000 (86.7893)  Acc@5: 100.0000 (98.5271)  time: 0.3439  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2190/3125]  eta: 0:05:22  Lr: 0.001875  Loss: 0.5707  Acc@1: 87.5000 (86.7954)  Acc@5: 100.0000 (98.5252)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2200/3125]  eta: 0:05:18  Lr: 0.001875  Loss: 0.0272  Acc@1: 87.5000 (86.8071)  Acc@5: 100.0000 (98.5177)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:15  Lr: 0.001875  Loss: 0.2854  Acc@1: 87.5000 (86.8074)  Acc@5: 100.0000 (98.5188)  time: 0.3439  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:11  Lr: 0.001875  Loss: 0.3210  Acc@1: 87.5000 (86.8077)  Acc@5: 100.0000 (98.5198)  time: 0.3444  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:08  Lr: 0.001875  Loss: 0.0203  Acc@1: 87.5000 (86.8165)  Acc@5: 100.0000 (98.5180)  time: 0.3442  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:04  Lr: 0.001875  Loss: 0.0310  Acc@1: 93.7500 (86.8334)  Acc@5: 100.0000 (98.5219)  time: 0.3449  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:01  Lr: 0.001875  Loss: 0.0878  Acc@1: 93.7500 (86.8503)  Acc@5: 100.0000 (98.5257)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2260/3125]  eta: 0:04:57  Lr: 0.001875  Loss: 0.4778  Acc@1: 93.7500 (86.8725)  Acc@5: 100.0000 (98.5294)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2270/3125]  eta: 0:04:54  Lr: 0.001875  Loss: 0.5700  Acc@1: 93.7500 (86.8780)  Acc@5: 100.0000 (98.5304)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2280/3125]  eta: 0:04:51  Lr: 0.001875  Loss: 1.0071  Acc@1: 87.5000 (86.8588)  Acc@5: 100.0000 (98.5286)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2290/3125]  eta: 0:04:47  Lr: 0.001875  Loss: 0.2933  Acc@1: 87.5000 (86.8753)  Acc@5: 100.0000 (98.5350)  time: 0.3434  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2300/3125]  eta: 0:04:44  Lr: 0.001875  Loss: 0.4161  Acc@1: 87.5000 (86.8780)  Acc@5: 100.0000 (98.5305)  time: 0.3441  data: 0.0016  max mem: 2501
Train: Epoch[5/5]  [2310/3125]  eta: 0:04:40  Lr: 0.001875  Loss: 0.1521  Acc@1: 87.5000 (86.8834)  Acc@5: 100.0000 (98.5369)  time: 0.3453  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [2320/3125]  eta: 0:04:37  Lr: 0.001875  Loss: 0.2759  Acc@1: 87.5000 (86.8753)  Acc@5: 100.0000 (98.5351)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2330/3125]  eta: 0:04:33  Lr: 0.001875  Loss: 0.1106  Acc@1: 81.2500 (86.8458)  Acc@5: 100.0000 (98.5280)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2340/3125]  eta: 0:04:30  Lr: 0.001875  Loss: 0.3838  Acc@1: 81.2500 (86.8459)  Acc@5: 100.0000 (98.5316)  time: 0.3438  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2350/3125]  eta: 0:04:26  Lr: 0.001875  Loss: 0.1938  Acc@1: 87.5000 (86.8407)  Acc@5: 100.0000 (98.5325)  time: 0.3436  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:23  Lr: 0.001875  Loss: 0.4533  Acc@1: 87.5000 (86.8461)  Acc@5: 100.0000 (98.5361)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:20  Lr: 0.001875  Loss: 0.8921  Acc@1: 87.5000 (86.8436)  Acc@5: 100.0000 (98.5370)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:16  Lr: 0.001875  Loss: 0.1898  Acc@1: 87.5000 (86.8543)  Acc@5: 100.0000 (98.5353)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:13  Lr: 0.001875  Loss: 0.4855  Acc@1: 87.5000 (86.8465)  Acc@5: 100.0000 (98.5414)  time: 0.3426  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:09  Lr: 0.001875  Loss: 0.2674  Acc@1: 87.5000 (86.8570)  Acc@5: 100.0000 (98.5449)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:06  Lr: 0.001875  Loss: 0.3169  Acc@1: 87.5000 (86.8597)  Acc@5: 100.0000 (98.5380)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:02  Lr: 0.001875  Loss: 0.3401  Acc@1: 87.5000 (86.8572)  Acc@5: 100.0000 (98.5388)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2430/3125]  eta: 0:03:59  Lr: 0.001875  Loss: 0.2156  Acc@1: 87.5000 (86.8470)  Acc@5: 100.0000 (98.5371)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2440/3125]  eta: 0:03:55  Lr: 0.001875  Loss: 0.3522  Acc@1: 87.5000 (86.8625)  Acc@5: 100.0000 (98.5431)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2450/3125]  eta: 0:03:52  Lr: 0.001875  Loss: 0.2356  Acc@1: 87.5000 (86.8702)  Acc@5: 100.0000 (98.5465)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2460/3125]  eta: 0:03:49  Lr: 0.001875  Loss: 0.3448  Acc@1: 87.5000 (86.8549)  Acc@5: 100.0000 (98.5499)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2470/3125]  eta: 0:03:45  Lr: 0.001875  Loss: 0.7385  Acc@1: 87.5000 (86.8500)  Acc@5: 100.0000 (98.5532)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2480/3125]  eta: 0:03:42  Lr: 0.001875  Loss: 0.6375  Acc@1: 81.2500 (86.8349)  Acc@5: 100.0000 (98.5465)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2490/3125]  eta: 0:03:38  Lr: 0.001875  Loss: 0.3525  Acc@1: 87.5000 (86.8376)  Acc@5: 100.0000 (98.5397)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2500/3125]  eta: 0:03:35  Lr: 0.001875  Loss: 0.0601  Acc@1: 87.5000 (86.8453)  Acc@5: 100.0000 (98.5431)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2510/3125]  eta: 0:03:31  Lr: 0.001875  Loss: 0.5059  Acc@1: 87.5000 (86.8329)  Acc@5: 100.0000 (98.5464)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:28  Lr: 0.001875  Loss: 0.0841  Acc@1: 87.5000 (86.8381)  Acc@5: 100.0000 (98.5447)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:24  Lr: 0.001875  Loss: 0.4731  Acc@1: 87.5000 (86.8555)  Acc@5: 100.0000 (98.5505)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:21  Lr: 0.001875  Loss: 0.3388  Acc@1: 87.5000 (86.8556)  Acc@5: 100.0000 (98.5562)  time: 0.3439  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:18  Lr: 0.001875  Loss: 0.1591  Acc@1: 87.5000 (86.8752)  Acc@5: 100.0000 (98.5545)  time: 0.3448  data: 0.0018  max mem: 2501
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:14  Lr: 0.001875  Loss: 0.1938  Acc@1: 87.5000 (86.8728)  Acc@5: 100.0000 (98.5504)  time: 0.3440  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:11  Lr: 0.001875  Loss: 0.4430  Acc@1: 87.5000 (86.8874)  Acc@5: 100.0000 (98.5511)  time: 0.3423  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:07  Lr: 0.001875  Loss: 0.3526  Acc@1: 93.7500 (86.9067)  Acc@5: 100.0000 (98.5543)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:04  Lr: 0.001875  Loss: 0.0264  Acc@1: 87.5000 (86.9042)  Acc@5: 100.0000 (98.5527)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:00  Lr: 0.001875  Loss: 0.4170  Acc@1: 87.5000 (86.8993)  Acc@5: 100.0000 (98.5534)  time: 0.3429  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2610/3125]  eta: 0:02:57  Lr: 0.001875  Loss: 0.7113  Acc@1: 87.5000 (86.8968)  Acc@5: 100.0000 (98.5590)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2620/3125]  eta: 0:02:53  Lr: 0.001875  Loss: 0.3531  Acc@1: 87.5000 (86.9086)  Acc@5: 100.0000 (98.5645)  time: 0.3442  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2630/3125]  eta: 0:02:50  Lr: 0.001875  Loss: 0.8387  Acc@1: 81.2500 (86.8824)  Acc@5: 100.0000 (98.5604)  time: 0.3440  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2640/3125]  eta: 0:02:47  Lr: 0.001875  Loss: 0.5324  Acc@1: 81.2500 (86.8847)  Acc@5: 100.0000 (98.5564)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2650/3125]  eta: 0:02:43  Lr: 0.001875  Loss: 0.4616  Acc@1: 87.5000 (86.8776)  Acc@5: 100.0000 (98.5571)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2660/3125]  eta: 0:02:40  Lr: 0.001875  Loss: 0.3799  Acc@1: 87.5000 (86.8870)  Acc@5: 100.0000 (98.5579)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:36  Lr: 0.001875  Loss: 0.1769  Acc@1: 87.5000 (86.8823)  Acc@5: 100.0000 (98.5516)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:33  Lr: 0.001875  Loss: 0.5368  Acc@1: 81.2500 (86.8776)  Acc@5: 100.0000 (98.5523)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:29  Lr: 0.001875  Loss: 0.3376  Acc@1: 87.5000 (86.8752)  Acc@5: 100.0000 (98.5530)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:26  Lr: 0.001875  Loss: 0.3164  Acc@1: 87.5000 (86.8752)  Acc@5: 100.0000 (98.5491)  time: 0.3433  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:22  Lr: 0.001875  Loss: 0.5189  Acc@1: 87.5000 (86.8821)  Acc@5: 100.0000 (98.5522)  time: 0.3436  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:19  Lr: 0.001875  Loss: 0.3657  Acc@1: 87.5000 (86.8890)  Acc@5: 100.0000 (98.5575)  time: 0.3441  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:16  Lr: 0.001875  Loss: 0.3883  Acc@1: 87.5000 (86.8890)  Acc@5: 100.0000 (98.5628)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:12  Lr: 0.001875  Loss: 0.5898  Acc@1: 87.5000 (86.8843)  Acc@5: 100.0000 (98.5658)  time: 0.3440  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:09  Lr: 0.001875  Loss: 0.3765  Acc@1: 87.5000 (86.8798)  Acc@5: 100.0000 (98.5664)  time: 0.3441  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:05  Lr: 0.001875  Loss: 0.2218  Acc@1: 87.5000 (86.8865)  Acc@5: 100.0000 (98.5694)  time: 0.3431  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:02  Lr: 0.001875  Loss: 0.2534  Acc@1: 87.5000 (86.9023)  Acc@5: 100.0000 (98.5700)  time: 0.3427  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2780/3125]  eta: 0:01:58  Lr: 0.001875  Loss: 0.2664  Acc@1: 87.5000 (86.8999)  Acc@5: 100.0000 (98.5617)  time: 0.3455  data: 0.0021  max mem: 2501
Train: Epoch[5/5]  [2790/3125]  eta: 0:01:55  Lr: 0.001875  Loss: 0.3524  Acc@1: 87.5000 (86.9066)  Acc@5: 100.0000 (98.5579)  time: 0.3466  data: 0.0030  max mem: 2501
Train: Epoch[5/5]  [2800/3125]  eta: 0:01:51  Lr: 0.001875  Loss: 0.0302  Acc@1: 87.5000 (86.9221)  Acc@5: 100.0000 (98.5608)  time: 0.3454  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [2810/3125]  eta: 0:01:48  Lr: 0.001875  Loss: 0.2454  Acc@1: 93.7500 (86.9241)  Acc@5: 100.0000 (98.5570)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:45  Lr: 0.001875  Loss: 0.3981  Acc@1: 93.7500 (86.9439)  Acc@5: 100.0000 (98.5577)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:41  Lr: 0.001875  Loss: 0.1495  Acc@1: 93.7500 (86.9547)  Acc@5: 100.0000 (98.5562)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:38  Lr: 0.001875  Loss: 0.2403  Acc@1: 87.5000 (86.9544)  Acc@5: 100.0000 (98.5590)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1706  Acc@1: 87.5000 (86.9541)  Acc@5: 100.0000 (98.5641)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:31  Lr: 0.001875  Loss: 0.4204  Acc@1: 87.5000 (86.9539)  Acc@5: 100.0000 (98.5648)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:27  Lr: 0.001875  Loss: 0.3567  Acc@1: 87.5000 (86.9601)  Acc@5: 100.0000 (98.5654)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:24  Lr: 0.001875  Loss: 0.3120  Acc@1: 87.5000 (86.9511)  Acc@5: 100.0000 (98.5617)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:20  Lr: 0.001875  Loss: 0.7706  Acc@1: 87.5000 (86.9487)  Acc@5: 100.0000 (98.5559)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:17  Lr: 0.001875  Loss: 0.2088  Acc@1: 87.5000 (86.9528)  Acc@5: 100.0000 (98.5587)  time: 0.3450  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:14  Lr: 0.001875  Loss: 0.1314  Acc@1: 87.5000 (86.9525)  Acc@5: 100.0000 (98.5550)  time: 0.3458  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:10  Lr: 0.001875  Loss: 0.0118  Acc@1: 87.5000 (86.9415)  Acc@5: 100.0000 (98.5579)  time: 0.3459  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1985  Acc@1: 87.5000 (86.9307)  Acc@5: 100.0000 (98.5606)  time: 0.3455  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:03  Lr: 0.001875  Loss: 0.6274  Acc@1: 81.2500 (86.9092)  Acc@5: 100.0000 (98.5613)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:00  Lr: 0.001875  Loss: 0.8387  Acc@1: 87.5000 (86.9070)  Acc@5: 100.0000 (98.5577)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2960/3125]  eta: 0:00:56  Lr: 0.001875  Loss: 0.4579  Acc@1: 87.5000 (86.8963)  Acc@5: 100.0000 (98.5583)  time: 0.3448  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2970/3125]  eta: 0:00:53  Lr: 0.001875  Loss: 0.4063  Acc@1: 87.5000 (86.9068)  Acc@5: 100.0000 (98.5590)  time: 0.3446  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:49  Lr: 0.001875  Loss: 0.2131  Acc@1: 87.5000 (86.9046)  Acc@5: 100.0000 (98.5638)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:46  Lr: 0.001875  Loss: 0.6474  Acc@1: 87.5000 (86.9003)  Acc@5: 100.0000 (98.5665)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: 0.2570  Acc@1: 87.5000 (86.9044)  Acc@5: 100.0000 (98.5609)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:39  Lr: 0.001875  Loss: 0.6548  Acc@1: 87.5000 (86.9126)  Acc@5: 100.0000 (98.5636)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2883  Acc@1: 87.5000 (86.9228)  Acc@5: 100.0000 (98.5642)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:32  Lr: 0.001875  Loss: 0.2205  Acc@1: 87.5000 (86.9103)  Acc@5: 100.0000 (98.5628)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: 0.3893  Acc@1: 87.5000 (86.9122)  Acc@5: 100.0000 (98.5572)  time: 0.3449  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:25  Lr: 0.001875  Loss: 0.5341  Acc@1: 87.5000 (86.9182)  Acc@5: 100.0000 (98.5558)  time: 0.3455  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: 0.0398  Acc@1: 87.5000 (86.9262)  Acc@5: 100.0000 (98.5564)  time: 0.3451  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:18  Lr: 0.001875  Loss: 0.3883  Acc@1: 87.5000 (86.9281)  Acc@5: 100.0000 (98.5591)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1340  Acc@1: 87.5000 (86.9300)  Acc@5: 100.0000 (98.5577)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: 0.2287  Acc@1: 87.5000 (86.9237)  Acc@5: 100.0000 (98.5603)  time: 0.3440  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4229  Acc@1: 87.5000 (86.9155)  Acc@5: 100.0000 (98.5650)  time: 0.3449  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: 0.4466  Acc@1: 87.5000 (86.9134)  Acc@5: 100.0000 (98.5656)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2753  Acc@1: 87.5000 (86.9173)  Acc@5: 100.0000 (98.5662)  time: 0.3448  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2779  Acc@1: 87.5000 (86.9200)  Acc@5: 100.0000 (98.5680)  time: 0.3441  data: 0.0005  max mem: 2501
Train: Epoch[5/5] Total time: 0:17:56 (0.3445 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2779  Acc@1: 87.5000 (86.9200)  Acc@5: 100.0000 (98.5680)
Test: [Task 1]  [   0/1627]  eta: 0:14:52  Loss: 3.0690 (3.0690)  Acc@1: 31.2500 (31.2500)  Acc@5: 62.5000 (62.5000)  time: 0.5484  data: 0.3323  max mem: 2501
Test: [Task 1]  [  10/1627]  eta: 0:06:35  Loss: 2.7740 (2.6302)  Acc@1: 31.2500 (33.5227)  Acc@5: 68.7500 (71.0227)  time: 0.2446  data: 0.0305  max mem: 2501
Test: [Task 1]  [  20/1627]  eta: 0:06:10  Loss: 2.6728 (2.5906)  Acc@1: 37.5000 (36.9048)  Acc@5: 68.7500 (72.0238)  time: 0.2145  data: 0.0003  max mem: 2501
Test: [Task 1]  [  30/1627]  eta: 0:06:00  Loss: 2.6820 (2.6752)  Acc@1: 31.2500 (32.6613)  Acc@5: 68.7500 (69.5565)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [  40/1627]  eta: 0:05:53  Loss: 2.7297 (2.6888)  Acc@1: 25.0000 (32.3171)  Acc@5: 68.7500 (69.8171)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [  50/1627]  eta: 0:05:48  Loss: 2.7008 (2.6737)  Acc@1: 31.2500 (32.5980)  Acc@5: 68.7500 (69.6078)  time: 0.2145  data: 0.0003  max mem: 2501
Test: [Task 1]  [  60/1627]  eta: 0:05:45  Loss: 2.6397 (2.6862)  Acc@1: 31.2500 (32.5820)  Acc@5: 68.7500 (69.2623)  time: 0.2151  data: 0.0005  max mem: 2501
Test: [Task 1]  [  70/1627]  eta: 0:05:41  Loss: 2.7037 (2.6972)  Acc@1: 31.2500 (32.5704)  Acc@5: 68.7500 (68.4859)  time: 0.2152  data: 0.0005  max mem: 2501
Test: [Task 1]  [  80/1627]  eta: 0:05:38  Loss: 2.5789 (2.6873)  Acc@1: 31.2500 (32.9475)  Acc@5: 68.7500 (69.2901)  time: 0.2147  data: 0.0004  max mem: 2501
Test: [Task 1]  [  90/1627]  eta: 0:05:35  Loss: 2.6276 (2.6788)  Acc@1: 31.2500 (33.3104)  Acc@5: 75.0000 (69.7115)  time: 0.2149  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 100/1627]  eta: 0:05:33  Loss: 2.7177 (2.6894)  Acc@1: 25.0000 (32.4876)  Acc@5: 68.7500 (69.0594)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 110/1627]  eta: 0:05:30  Loss: 2.7316 (2.6816)  Acc@1: 25.0000 (32.7703)  Acc@5: 68.7500 (69.3131)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 120/1627]  eta: 0:05:27  Loss: 2.5299 (2.6664)  Acc@1: 31.2500 (33.2128)  Acc@5: 68.7500 (69.3182)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 130/1627]  eta: 0:05:25  Loss: 2.5583 (2.6676)  Acc@1: 37.5000 (33.4924)  Acc@5: 68.7500 (69.4179)  time: 0.2158  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 140/1627]  eta: 0:05:23  Loss: 2.6332 (2.6678)  Acc@1: 31.2500 (33.3777)  Acc@5: 68.7500 (69.2376)  time: 0.2161  data: 0.0011  max mem: 2501
Test: [Task 1]  [ 150/1627]  eta: 0:05:20  Loss: 2.5075 (2.6576)  Acc@1: 31.2500 (33.4851)  Acc@5: 75.0000 (69.6606)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 160/1627]  eta: 0:05:18  Loss: 2.6638 (2.6593)  Acc@1: 31.2500 (33.5404)  Acc@5: 68.7500 (69.7593)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 170/1627]  eta: 0:05:16  Loss: 2.6638 (2.6462)  Acc@1: 31.2500 (33.8085)  Acc@5: 68.7500 (70.0292)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 180/1627]  eta: 0:05:13  Loss: 2.5907 (2.6539)  Acc@1: 31.2500 (33.5981)  Acc@5: 68.7500 (69.8550)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 190/1627]  eta: 0:05:11  Loss: 2.6335 (2.6491)  Acc@1: 31.2500 (33.9005)  Acc@5: 68.7500 (69.8298)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 200/1627]  eta: 0:05:09  Loss: 2.6793 (2.6604)  Acc@1: 37.5000 (33.7376)  Acc@5: 68.7500 (69.4652)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 210/1627]  eta: 0:05:07  Loss: 2.8156 (2.6635)  Acc@1: 37.5000 (33.8566)  Acc@5: 62.5000 (69.1351)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 220/1627]  eta: 0:05:04  Loss: 2.7202 (2.6689)  Acc@1: 31.2500 (33.6256)  Acc@5: 68.7500 (69.2025)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 230/1627]  eta: 0:05:02  Loss: 2.7438 (2.6761)  Acc@1: 25.0000 (33.3063)  Acc@5: 68.7500 (68.9665)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 240/1627]  eta: 0:05:00  Loss: 2.6747 (2.6726)  Acc@1: 31.2500 (33.4284)  Acc@5: 68.7500 (69.0093)  time: 0.2156  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 250/1627]  eta: 0:04:58  Loss: 2.6061 (2.6713)  Acc@1: 37.5000 (33.4910)  Acc@5: 68.7500 (68.8994)  time: 0.2160  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 260/1627]  eta: 0:04:55  Loss: 2.6610 (2.6707)  Acc@1: 31.2500 (33.6925)  Acc@5: 68.7500 (68.9176)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 270/1627]  eta: 0:04:53  Loss: 2.4782 (2.6622)  Acc@1: 37.5000 (33.8330)  Acc@5: 68.7500 (69.1190)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 280/1627]  eta: 0:04:51  Loss: 2.5149 (2.6628)  Acc@1: 31.2500 (33.6966)  Acc@5: 68.7500 (69.1059)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 290/1627]  eta: 0:04:49  Loss: 2.5149 (2.6573)  Acc@1: 31.2500 (33.8273)  Acc@5: 68.7500 (69.2010)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 300/1627]  eta: 0:04:47  Loss: 2.4249 (2.6549)  Acc@1: 31.2500 (33.9286)  Acc@5: 75.0000 (69.3729)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 310/1627]  eta: 0:04:44  Loss: 2.4249 (2.6527)  Acc@1: 37.5000 (34.2042)  Acc@5: 75.0000 (69.4333)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 320/1627]  eta: 0:04:42  Loss: 2.5509 (2.6539)  Acc@1: 37.5000 (34.1121)  Acc@5: 75.0000 (69.3731)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 330/1627]  eta: 0:04:40  Loss: 2.7135 (2.6569)  Acc@1: 25.0000 (34.0257)  Acc@5: 68.7500 (69.2409)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 340/1627]  eta: 0:04:38  Loss: 2.6934 (2.6602)  Acc@1: 25.0000 (34.0543)  Acc@5: 68.7500 (69.3182)  time: 0.2157  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 350/1627]  eta: 0:04:36  Loss: 2.7859 (2.6637)  Acc@1: 31.2500 (34.0278)  Acc@5: 68.7500 (69.1774)  time: 0.2157  data: 0.0011  max mem: 2501
Test: [Task 1]  [ 360/1627]  eta: 0:04:33  Loss: 2.7152 (2.6635)  Acc@1: 31.2500 (34.0201)  Acc@5: 68.7500 (69.2175)  time: 0.2158  data: 0.0009  max mem: 2501
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 2.5553 (2.6617)  Acc@1: 31.2500 (33.9623)  Acc@5: 68.7500 (69.3228)  time: 0.2155  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 380/1627]  eta: 0:04:29  Loss: 2.7128 (2.6659)  Acc@1: 25.0000 (33.7106)  Acc@5: 68.7500 (69.2585)  time: 0.2158  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 390/1627]  eta: 0:04:27  Loss: 2.6907 (2.6681)  Acc@1: 25.0000 (33.7916)  Acc@5: 62.5000 (69.1976)  time: 0.2168  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 400/1627]  eta: 0:04:25  Loss: 2.6215 (2.6699)  Acc@1: 31.2500 (33.6191)  Acc@5: 62.5000 (69.2643)  time: 0.2164  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 410/1627]  eta: 0:04:23  Loss: 2.5995 (2.6703)  Acc@1: 31.2500 (33.5918)  Acc@5: 68.7500 (69.2974)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 420/1627]  eta: 0:04:20  Loss: 2.5611 (2.6710)  Acc@1: 31.2500 (33.5362)  Acc@5: 68.7500 (69.2102)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 430/1627]  eta: 0:04:18  Loss: 2.4678 (2.6652)  Acc@1: 31.2500 (33.6862)  Acc@5: 68.7500 (69.4026)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 440/1627]  eta: 0:04:16  Loss: 2.5153 (2.6643)  Acc@1: 31.2500 (33.7160)  Acc@5: 75.0000 (69.4444)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 450/1627]  eta: 0:04:14  Loss: 2.7564 (2.6683)  Acc@1: 31.2500 (33.7445)  Acc@5: 68.7500 (69.3182)  time: 0.2165  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 2.7071 (2.6682)  Acc@1: 31.2500 (33.7310)  Acc@5: 62.5000 (69.3736)  time: 0.2161  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 470/1627]  eta: 0:04:10  Loss: 2.6061 (2.6681)  Acc@1: 31.2500 (33.7182)  Acc@5: 68.7500 (69.3471)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 480/1627]  eta: 0:04:07  Loss: 2.6774 (2.6696)  Acc@1: 31.2500 (33.6538)  Acc@5: 68.7500 (69.2568)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 2.6559 (2.6689)  Acc@1: 31.2500 (33.6685)  Acc@5: 68.7500 (69.2210)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 2.5356 (2.6696)  Acc@1: 31.2500 (33.6702)  Acc@5: 68.7500 (69.2241)  time: 0.2162  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 510/1627]  eta: 0:04:01  Loss: 2.6244 (2.6717)  Acc@1: 31.2500 (33.6106)  Acc@5: 68.7500 (69.1414)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 2.9048 (2.6755)  Acc@1: 31.2500 (33.5413)  Acc@5: 68.7500 (69.0619)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 530/1627]  eta: 0:03:57  Loss: 2.4119 (2.6680)  Acc@1: 37.5000 (33.7924)  Acc@5: 68.7500 (69.2797)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 2.3686 (2.6677)  Acc@1: 37.5000 (33.7569)  Acc@5: 75.0000 (69.2930)  time: 0.2159  data: 0.0011  max mem: 2501
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 2.8241 (2.6727)  Acc@1: 25.0000 (33.6320)  Acc@5: 62.5000 (69.1697)  time: 0.2164  data: 0.0012  max mem: 2501
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 2.7850 (2.6730)  Acc@1: 25.0000 (33.5227)  Acc@5: 68.7500 (69.1734)  time: 0.2170  data: 0.0011  max mem: 2501
Test: [Task 1]  [ 570/1627]  eta: 0:03:48  Loss: 2.5463 (2.6711)  Acc@1: 31.2500 (33.5158)  Acc@5: 75.0000 (69.2207)  time: 0.2160  data: 0.0009  max mem: 2501
Test: [Task 1]  [ 580/1627]  eta: 0:03:46  Loss: 2.6378 (2.6735)  Acc@1: 31.2500 (33.3692)  Acc@5: 68.7500 (69.2018)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 590/1627]  eta: 0:03:44  Loss: 2.6527 (2.6735)  Acc@1: 25.0000 (33.4285)  Acc@5: 68.7500 (69.1730)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 2.6482 (2.6755)  Acc@1: 25.0000 (33.3299)  Acc@5: 68.7500 (69.0516)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 2.5487 (2.6730)  Acc@1: 31.2500 (33.3981)  Acc@5: 68.7500 (69.1387)  time: 0.2161  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 2.4694 (2.6725)  Acc@1: 37.5000 (33.4138)  Acc@5: 75.0000 (69.1526)  time: 0.2166  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 2.4512 (2.6698)  Acc@1: 37.5000 (33.4984)  Acc@5: 75.0000 (69.2552)  time: 0.2165  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 2.4029 (2.6670)  Acc@1: 37.5000 (33.5608)  Acc@5: 75.0000 (69.3643)  time: 0.2163  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 650/1627]  eta: 0:03:31  Loss: 2.5400 (2.6639)  Acc@1: 37.5000 (33.6694)  Acc@5: 75.0000 (69.4700)  time: 0.2158  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 2.5466 (2.6616)  Acc@1: 37.5000 (33.6895)  Acc@5: 75.0000 (69.5443)  time: 0.2158  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 2.5997 (2.6620)  Acc@1: 37.5000 (33.7370)  Acc@5: 68.7500 (69.5231)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 2.5773 (2.6596)  Acc@1: 37.5000 (33.8656)  Acc@5: 68.7500 (69.6127)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 2.5773 (2.6595)  Acc@1: 37.5000 (33.8368)  Acc@5: 68.7500 (69.5912)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 2.5793 (2.6592)  Acc@1: 31.2500 (33.8088)  Acc@5: 75.0000 (69.6416)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 2.4699 (2.6571)  Acc@1: 31.2500 (33.8344)  Acc@5: 75.0000 (69.6642)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 2.4600 (2.6562)  Acc@1: 37.5000 (33.8506)  Acc@5: 68.7500 (69.7035)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 2.7070 (2.6567)  Acc@1: 31.2500 (33.8577)  Acc@5: 68.7500 (69.7076)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 2.7070 (2.6565)  Acc@1: 31.2500 (33.8563)  Acc@5: 68.7500 (69.7453)  time: 0.2157  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 2.6907 (2.6582)  Acc@1: 31.2500 (33.7716)  Acc@5: 68.7500 (69.7487)  time: 0.2156  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 2.7382 (2.6586)  Acc@1: 31.2500 (33.8042)  Acc@5: 68.7500 (69.7684)  time: 0.2151  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 2.5232 (2.6559)  Acc@1: 37.5000 (33.9008)  Acc@5: 75.0000 (69.8687)  time: 0.2153  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 780/1627]  eta: 0:03:02  Loss: 2.4055 (2.6555)  Acc@1: 37.5000 (33.8908)  Acc@5: 75.0000 (69.9024)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 2.8249 (2.6571)  Acc@1: 31.2500 (33.8417)  Acc@5: 68.7500 (69.9352)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 2.8361 (2.6570)  Acc@1: 31.2500 (33.8015)  Acc@5: 68.7500 (69.9594)  time: 0.2153  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 2.6917 (2.6565)  Acc@1: 31.2500 (33.7777)  Acc@5: 75.0000 (70.0139)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 2.6917 (2.6573)  Acc@1: 31.2500 (33.7470)  Acc@5: 75.0000 (69.9833)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 2.6321 (2.6569)  Acc@1: 31.2500 (33.7846)  Acc@5: 68.7500 (70.0286)  time: 0.2152  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 2.4407 (2.6546)  Acc@1: 37.5000 (33.8288)  Acc@5: 75.0000 (70.1026)  time: 0.2166  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 2.5957 (2.6572)  Acc@1: 31.2500 (33.7177)  Acc@5: 68.7500 (70.0059)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 2.6689 (2.6571)  Acc@1: 25.0000 (33.7108)  Acc@5: 62.5000 (70.0348)  time: 0.2152  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 2.5473 (2.6561)  Acc@1: 31.2500 (33.7113)  Acc@5: 68.7500 (70.0631)  time: 0.2168  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 2.6310 (2.6589)  Acc@1: 31.2500 (33.6691)  Acc@5: 68.7500 (69.9915)  time: 0.2170  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 2.8586 (2.6612)  Acc@1: 25.0000 (33.5859)  Acc@5: 62.5000 (69.9355)  time: 0.2165  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 900/1627]  eta: 0:02:36  Loss: 2.7350 (2.6605)  Acc@1: 31.2500 (33.6293)  Acc@5: 68.7500 (69.9709)  time: 0.2170  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 2.5592 (2.6599)  Acc@1: 31.2500 (33.6306)  Acc@5: 75.0000 (69.9780)  time: 0.2162  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 2.7477 (2.6599)  Acc@1: 31.2500 (33.6048)  Acc@5: 62.5000 (69.9511)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 2.6530 (2.6592)  Acc@1: 31.2500 (33.6399)  Acc@5: 68.7500 (69.9852)  time: 0.2173  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 2.6264 (2.6597)  Acc@1: 37.5000 (33.6145)  Acc@5: 68.7500 (69.9787)  time: 0.2169  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 2.6219 (2.6591)  Acc@1: 31.2500 (33.6225)  Acc@5: 68.7500 (69.9527)  time: 0.2151  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 2.5235 (2.6581)  Acc@1: 31.2500 (33.6433)  Acc@5: 68.7500 (69.9922)  time: 0.2158  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 2.4603 (2.6565)  Acc@1: 37.5000 (33.6766)  Acc@5: 75.0000 (70.0438)  time: 0.2158  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 2.5125 (2.6553)  Acc@1: 37.5000 (33.7156)  Acc@5: 75.0000 (70.0624)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 2.7003 (2.6580)  Acc@1: 31.2500 (33.6592)  Acc@5: 68.7500 (70.0050)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 2.8153 (2.6587)  Acc@1: 25.0000 (33.6663)  Acc@5: 62.5000 (70.0050)  time: 0.2158  data: 0.0013  max mem: 2501
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 2.6528 (2.6579)  Acc@1: 31.2500 (33.7166)  Acc@5: 68.7500 (69.9988)  time: 0.2165  data: 0.0019  max mem: 2501
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 2.6479 (2.6581)  Acc@1: 31.2500 (33.7047)  Acc@5: 68.7500 (70.0049)  time: 0.2151  data: 0.0009  max mem: 2501
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 2.4445 (2.6562)  Acc@1: 31.2500 (33.7536)  Acc@5: 68.7500 (70.0291)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 2.3895 (2.6546)  Acc@1: 37.5000 (33.8136)  Acc@5: 75.0000 (70.1009)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 2.4779 (2.6532)  Acc@1: 37.5000 (33.8249)  Acc@5: 75.0000 (70.1713)  time: 0.2160  data: 0.0006  max mem: 2501
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 2.5884 (2.6527)  Acc@1: 31.2500 (33.8419)  Acc@5: 75.0000 (70.1873)  time: 0.2152  data: 0.0006  max mem: 2501
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 2.5137 (2.6528)  Acc@1: 31.2500 (33.8527)  Acc@5: 75.0000 (70.1972)  time: 0.2143  data: 0.0003  max mem: 2501
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 2.5651 (2.6537)  Acc@1: 31.2500 (33.8575)  Acc@5: 75.0000 (70.1781)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 2.7669 (2.6549)  Acc@1: 31.2500 (33.8451)  Acc@5: 68.7500 (70.1306)  time: 0.2145  data: 0.0003  max mem: 2501
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 2.5396 (2.6543)  Acc@1: 31.2500 (33.8442)  Acc@5: 75.0000 (70.1975)  time: 0.2151  data: 0.0009  max mem: 2501
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 2.7139 (2.6560)  Acc@1: 31.2500 (33.7759)  Acc@5: 75.0000 (70.1058)  time: 0.2156  data: 0.0009  max mem: 2501
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 2.7964 (2.6557)  Acc@1: 25.0000 (33.7979)  Acc@5: 56.2500 (70.0602)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 2.6764 (2.6557)  Acc@1: 31.2500 (33.8031)  Acc@5: 68.7500 (70.0597)  time: 0.2148  data: 0.0003  max mem: 2501
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 2.6973 (2.6580)  Acc@1: 31.2500 (33.7478)  Acc@5: 62.5000 (69.9934)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 2.8772 (2.6581)  Acc@1: 31.2500 (33.7533)  Acc@5: 62.5000 (69.9989)  time: 0.2139  data: 0.0003  max mem: 2501
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 2.4000 (2.6579)  Acc@1: 31.2500 (33.7801)  Acc@5: 68.7500 (70.0043)  time: 0.2161  data: 0.0012  max mem: 2501
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 2.6447 (2.6583)  Acc@1: 31.2500 (33.7692)  Acc@5: 68.7500 (69.9829)  time: 0.2170  data: 0.0020  max mem: 2501
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 2.6906 (2.6590)  Acc@1: 31.2500 (33.7902)  Acc@5: 62.5000 (69.9619)  time: 0.2150  data: 0.0011  max mem: 2501
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 2.7231 (2.6588)  Acc@1: 31.2500 (33.8109)  Acc@5: 62.5000 (69.9360)  time: 0.2155  data: 0.0005  max mem: 2501
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 2.7231 (2.6591)  Acc@1: 31.2500 (33.7427)  Acc@5: 62.5000 (69.9001)  time: 0.2159  data: 0.0005  max mem: 2501
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 2.6020 (2.6593)  Acc@1: 31.2500 (33.7325)  Acc@5: 68.7500 (69.8803)  time: 0.2178  data: 0.0011  max mem: 2501
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 2.5945 (2.6588)  Acc@1: 31.2500 (33.7224)  Acc@5: 75.0000 (69.9171)  time: 0.2180  data: 0.0011  max mem: 2501
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 2.6257 (2.6590)  Acc@1: 31.2500 (33.7175)  Acc@5: 68.7500 (69.9076)  time: 0.2155  data: 0.0004  max mem: 2501
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 2.5497 (2.6582)  Acc@1: 31.2500 (33.7379)  Acc@5: 68.7500 (69.9335)  time: 0.2151  data: 0.0004  max mem: 2501
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 2.5806 (2.6591)  Acc@1: 31.2500 (33.7230)  Acc@5: 68.7500 (69.8941)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 2.6435 (2.6582)  Acc@1: 37.5000 (33.7877)  Acc@5: 68.7500 (69.9247)  time: 0.2142  data: 0.0003  max mem: 2501
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 2.5940 (2.6591)  Acc@1: 37.5000 (33.7628)  Acc@5: 75.0000 (69.9007)  time: 0.2141  data: 0.0003  max mem: 2501
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 2.5269 (2.6578)  Acc@1: 31.2500 (33.8017)  Acc@5: 68.7500 (69.9258)  time: 0.2141  data: 0.0003  max mem: 2501
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 2.5127 (2.6579)  Acc@1: 31.2500 (33.7965)  Acc@5: 68.7500 (69.8974)  time: 0.2144  data: 0.0003  max mem: 2501
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 2.5215 (2.6570)  Acc@1: 31.2500 (33.8153)  Acc@5: 68.7500 (69.9318)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 2.4940 (2.6566)  Acc@1: 37.5000 (33.8530)  Acc@5: 75.0000 (69.9418)  time: 0.2157  data: 0.0006  max mem: 2501
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 2.4452 (2.6546)  Acc@1: 37.5000 (33.8900)  Acc@5: 75.0000 (69.9849)  time: 0.2151  data: 0.0006  max mem: 2501
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 2.5860 (2.6561)  Acc@1: 31.2500 (33.8655)  Acc@5: 68.7500 (69.9145)  time: 0.2150  data: 0.0005  max mem: 2501
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 2.8761 (2.6569)  Acc@1: 25.0000 (33.8460)  Acc@5: 56.2500 (69.8639)  time: 0.2147  data: 0.0005  max mem: 2501
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 2.7272 (2.6569)  Acc@1: 31.2500 (33.8499)  Acc@5: 62.5000 (69.8649)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 2.6672 (2.6574)  Acc@1: 31.2500 (33.8262)  Acc@5: 62.5000 (69.8200)  time: 0.2144  data: 0.0003  max mem: 2501
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 2.6314 (2.6571)  Acc@1: 31.2500 (33.8394)  Acc@5: 68.7500 (69.8441)  time: 0.2142  data: 0.0003  max mem: 2501
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 2.6114 (2.6565)  Acc@1: 37.5000 (33.8749)  Acc@5: 75.0000 (69.8814)  time: 0.2142  data: 0.0003  max mem: 2501
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 2.4731 (2.6549)  Acc@1: 43.7500 (33.9414)  Acc@5: 75.0000 (69.8733)  time: 0.2145  data: 0.0003  max mem: 2501
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 2.7135 (2.6555)  Acc@1: 37.5000 (33.9356)  Acc@5: 68.7500 (69.8564)  time: 0.2162  data: 0.0006  max mem: 2501
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 2.7155 (2.6549)  Acc@1: 31.2500 (33.9387)  Acc@5: 68.7500 (69.8618)  time: 0.2161  data: 0.0006  max mem: 2501
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 2.4814 (2.6542)  Acc@1: 37.5000 (33.9682)  Acc@5: 62.5000 (69.8540)  time: 0.2156  data: 0.0008  max mem: 2501
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 2.6306 (2.6552)  Acc@1: 37.5000 (33.9448)  Acc@5: 62.5000 (69.8288)  time: 0.2157  data: 0.0008  max mem: 2501
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 2.7507 (2.6543)  Acc@1: 37.5000 (33.9651)  Acc@5: 68.7500 (69.8473)  time: 0.2155  data: 0.0010  max mem: 2501
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 2.5790 (2.6545)  Acc@1: 31.2500 (33.9593)  Acc@5: 68.7500 (69.8484)  time: 0.2161  data: 0.0013  max mem: 2501
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 2.5790 (2.6545)  Acc@1: 31.2500 (33.9322)  Acc@5: 75.0000 (69.8665)  time: 0.2161  data: 0.0011  max mem: 2501
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 2.7369 (2.6554)  Acc@1: 31.2500 (33.9225)  Acc@5: 75.0000 (69.8377)  time: 0.2155  data: 0.0008  max mem: 2501
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 2.7123 (2.6555)  Acc@1: 37.5000 (33.9213)  Acc@5: 62.5000 (69.8430)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 2.6342 (2.6559)  Acc@1: 37.5000 (33.9034)  Acc@5: 68.7500 (69.8189)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.7244 (2.6560)  Acc@1: 31.2500 (33.8899)  Acc@5: 68.7500 (69.8284)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 2.7458 (2.6563)  Acc@1: 31.2500 (33.9055)  Acc@5: 68.7500 (69.8254)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 2.5364 (2.6550)  Acc@1: 37.5000 (33.9127)  Acc@5: 75.0000 (69.8882)  time: 0.2162  data: 0.0011  max mem: 2501
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 2.5352 (2.6550)  Acc@1: 37.5000 (33.9443)  Acc@5: 81.2500 (69.9053)  time: 0.2161  data: 0.0011  max mem: 2501
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 2.5401 (2.6544)  Acc@1: 37.5000 (33.9633)  Acc@5: 75.0000 (69.9018)  time: 0.2155  data: 0.0008  max mem: 2501
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.5398 (2.6543)  Acc@1: 37.5000 (33.9740)  Acc@5: 68.7500 (69.9105)  time: 0.2156  data: 0.0008  max mem: 2501
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.4350 (2.6524)  Acc@1: 43.7500 (34.0207)  Acc@5: 75.0000 (69.9431)  time: 0.2161  data: 0.0003  max mem: 2501
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.5493 (2.6528)  Acc@1: 37.5000 (34.0110)  Acc@5: 75.0000 (69.9395)  time: 0.2165  data: 0.0004  max mem: 2501
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.6633 (2.6525)  Acc@1: 31.2500 (34.0172)  Acc@5: 68.7500 (69.9439)  time: 0.2164  data: 0.0008  max mem: 2501
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 2.6633 (2.6534)  Acc@1: 31.2500 (33.9841)  Acc@5: 68.7500 (69.9010)  time: 0.2169  data: 0.0007  max mem: 2501
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 2.7875 (2.6544)  Acc@1: 25.0000 (33.9553)  Acc@5: 68.7500 (69.8665)  time: 0.2168  data: 0.0005  max mem: 2501
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.5313 (2.6540)  Acc@1: 31.2500 (33.9967)  Acc@5: 75.0000 (69.8673)  time: 0.2178  data: 0.0007  max mem: 2501
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 2.4563 (2.6537)  Acc@1: 37.5000 (34.0184)  Acc@5: 75.0000 (69.8681)  time: 0.2175  data: 0.0006  max mem: 2501
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.5189 (2.6531)  Acc@1: 37.5000 (34.0120)  Acc@5: 75.0000 (69.8871)  time: 0.2168  data: 0.0005  max mem: 2501
Test: [Task 1] Total time: 0:05:51 (0.2159 s / it)
* Acc@1 34.012 Acc@5 69.887 loss 2.653
Test: [Task 2]  [  0/625]  eta: 0:04:50  Loss: 0.5046 (0.5046)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4645  data: 0.2478  max mem: 2501
Test: [Task 2]  [ 10/625]  eta: 0:02:26  Loss: 0.7726 (0.7564)  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (97.1591)  time: 0.2387  data: 0.0231  max mem: 2501
Test: [Task 2]  [ 20/625]  eta: 0:02:17  Loss: 0.6952 (0.7091)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (97.9167)  time: 0.2155  data: 0.0004  max mem: 2501
Test: [Task 2]  [ 30/625]  eta: 0:02:13  Loss: 0.6179 (0.7299)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (96.9758)  time: 0.2161  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 40/625]  eta: 0:02:09  Loss: 0.7104 (0.7361)  Acc@1: 81.2500 (82.0122)  Acc@5: 100.0000 (97.1037)  time: 0.2162  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 50/625]  eta: 0:02:07  Loss: 0.7997 (0.7600)  Acc@1: 81.2500 (81.1275)  Acc@5: 93.7500 (96.8137)  time: 0.2165  data: 0.0010  max mem: 2501
Test: [Task 2]  [ 60/625]  eta: 0:02:04  Loss: 0.8145 (0.7596)  Acc@1: 81.2500 (81.5574)  Acc@5: 93.7500 (96.9262)  time: 0.2175  data: 0.0010  max mem: 2501
Test: [Task 2]  [ 70/625]  eta: 0:02:02  Loss: 0.7599 (0.7606)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.1831)  time: 0.2168  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 80/625]  eta: 0:01:59  Loss: 0.8000 (0.7716)  Acc@1: 75.0000 (80.9414)  Acc@5: 100.0000 (97.0679)  time: 0.2178  data: 0.0011  max mem: 2501
Test: [Task 2]  [ 90/625]  eta: 0:01:57  Loss: 0.7644 (0.7674)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.1841)  time: 0.2187  data: 0.0019  max mem: 2501
Test: [Task 2]  [100/625]  eta: 0:01:55  Loss: 0.6957 (0.7675)  Acc@1: 81.2500 (81.1881)  Acc@5: 100.0000 (97.1535)  time: 0.2169  data: 0.0010  max mem: 2501
Test: [Task 2]  [110/625]  eta: 0:01:52  Loss: 0.6427 (0.7592)  Acc@1: 75.0000 (81.3063)  Acc@5: 100.0000 (97.2410)  time: 0.2163  data: 0.0003  max mem: 2501
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.6367 (0.7527)  Acc@1: 81.2500 (81.6632)  Acc@5: 100.0000 (97.2107)  time: 0.2163  data: 0.0003  max mem: 2501
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.6432 (0.7549)  Acc@1: 81.2500 (81.6794)  Acc@5: 100.0000 (97.3282)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 2]  [140/625]  eta: 0:01:45  Loss: 0.7214 (0.7618)  Acc@1: 81.2500 (81.4273)  Acc@5: 100.0000 (97.2074)  time: 0.2165  data: 0.0007  max mem: 2501
Test: [Task 2]  [150/625]  eta: 0:01:43  Loss: 0.7891 (0.7644)  Acc@1: 75.0000 (81.2500)  Acc@5: 100.0000 (97.2682)  time: 0.2169  data: 0.0008  max mem: 2501
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.7664 (0.7663)  Acc@1: 81.2500 (81.0947)  Acc@5: 100.0000 (97.2826)  time: 0.2163  data: 0.0004  max mem: 2501
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.7543 (0.7670)  Acc@1: 81.2500 (81.1769)  Acc@5: 100.0000 (97.2588)  time: 0.2161  data: 0.0004  max mem: 2501
Test: [Task 2]  [180/625]  eta: 0:01:36  Loss: 0.8090 (0.7731)  Acc@1: 75.0000 (80.8702)  Acc@5: 100.0000 (97.3066)  time: 0.2165  data: 0.0009  max mem: 2501
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.8041 (0.7741)  Acc@1: 75.0000 (80.8246)  Acc@5: 100.0000 (97.3168)  time: 0.2163  data: 0.0011  max mem: 2501
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.7952 (0.7786)  Acc@1: 75.0000 (80.5970)  Acc@5: 100.0000 (97.3570)  time: 0.2161  data: 0.0007  max mem: 2501
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.8729 (0.7784)  Acc@1: 81.2500 (80.7168)  Acc@5: 100.0000 (97.2749)  time: 0.2157  data: 0.0004  max mem: 2501
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.7543 (0.7760)  Acc@1: 87.5000 (80.8541)  Acc@5: 100.0000 (97.3416)  time: 0.2157  data: 0.0003  max mem: 2501
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 0.6608 (0.7766)  Acc@1: 81.2500 (80.8171)  Acc@5: 100.0000 (97.2132)  time: 0.2160  data: 0.0004  max mem: 2501
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.8300 (0.7788)  Acc@1: 81.2500 (80.8091)  Acc@5: 93.7500 (97.1214)  time: 0.2161  data: 0.0004  max mem: 2501
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.7556 (0.7764)  Acc@1: 81.2500 (80.9512)  Acc@5: 93.7500 (97.0369)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.7011 (0.7745)  Acc@1: 81.2500 (80.9866)  Acc@5: 93.7500 (97.0307)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.7655 (0.7724)  Acc@1: 81.2500 (81.0424)  Acc@5: 100.0000 (97.0480)  time: 0.2167  data: 0.0003  max mem: 2501
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 0.7316 (0.7727)  Acc@1: 81.2500 (81.1388)  Acc@5: 100.0000 (97.0641)  time: 0.2161  data: 0.0003  max mem: 2501
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.7564 (0.7760)  Acc@1: 81.2500 (80.9923)  Acc@5: 100.0000 (96.9931)  time: 0.2164  data: 0.0009  max mem: 2501
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.8502 (0.7781)  Acc@1: 75.0000 (80.8140)  Acc@5: 100.0000 (96.9892)  time: 0.2166  data: 0.0010  max mem: 2501
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.8502 (0.7803)  Acc@1: 75.0000 (80.5667)  Acc@5: 100.0000 (97.0056)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.6771 (0.7714)  Acc@1: 81.2500 (80.8217)  Acc@5: 100.0000 (97.0989)  time: 0.2166  data: 0.0006  max mem: 2501
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.5522 (0.7668)  Acc@1: 87.5000 (80.9290)  Acc@5: 100.0000 (97.1866)  time: 0.2162  data: 0.0007  max mem: 2501
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.4848 (0.7564)  Acc@1: 87.5000 (81.2683)  Acc@5: 100.0000 (97.2507)  time: 0.2169  data: 0.0006  max mem: 2501
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.4169 (0.7510)  Acc@1: 87.5000 (81.3390)  Acc@5: 100.0000 (97.2934)  time: 0.2185  data: 0.0009  max mem: 2501
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.7940 (0.7525)  Acc@1: 81.2500 (81.3366)  Acc@5: 100.0000 (97.3338)  time: 0.2168  data: 0.0006  max mem: 2501
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.6072 (0.7461)  Acc@1: 87.5000 (81.4858)  Acc@5: 100.0000 (97.4057)  time: 0.2157  data: 0.0003  max mem: 2501
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.6083 (0.7468)  Acc@1: 81.2500 (81.3812)  Acc@5: 100.0000 (97.3589)  time: 0.2162  data: 0.0005  max mem: 2501
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.6506 (0.7448)  Acc@1: 75.0000 (81.3779)  Acc@5: 100.0000 (97.3306)  time: 0.2165  data: 0.0008  max mem: 2501
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.5201 (0.7372)  Acc@1: 87.5000 (81.7020)  Acc@5: 100.0000 (97.3971)  time: 0.2180  data: 0.0010  max mem: 2501
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.4660 (0.7357)  Acc@1: 93.7500 (81.7670)  Acc@5: 100.0000 (97.3996)  time: 0.2178  data: 0.0013  max mem: 2501
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.6047 (0.7392)  Acc@1: 81.2500 (81.6657)  Acc@5: 100.0000 (97.3723)  time: 0.2169  data: 0.0018  max mem: 2501
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.7236 (0.7366)  Acc@1: 81.2500 (81.7575)  Acc@5: 100.0000 (97.4043)  time: 0.2170  data: 0.0017  max mem: 2501
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.3742 (0.7288)  Acc@1: 93.7500 (82.0437)  Acc@5: 100.0000 (97.4490)  time: 0.2160  data: 0.0009  max mem: 2501
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.4432 (0.7246)  Acc@1: 93.7500 (82.1646)  Acc@5: 100.0000 (97.5055)  time: 0.2158  data: 0.0009  max mem: 2501
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.4454 (0.7194)  Acc@1: 87.5000 (82.3075)  Acc@5: 100.0000 (97.5597)  time: 0.2157  data: 0.0009  max mem: 2501
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.5980 (0.7189)  Acc@1: 87.5000 (82.3116)  Acc@5: 100.0000 (97.5849)  time: 0.2155  data: 0.0007  max mem: 2501
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.6745 (0.7184)  Acc@1: 81.2500 (82.3285)  Acc@5: 100.0000 (97.6091)  time: 0.2168  data: 0.0014  max mem: 2501
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.5951 (0.7151)  Acc@1: 81.2500 (82.4593)  Acc@5: 100.0000 (97.6578)  time: 0.2177  data: 0.0011  max mem: 2501
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.6620 (0.7156)  Acc@1: 81.2500 (82.4227)  Acc@5: 100.0000 (97.6796)  time: 0.2178  data: 0.0005  max mem: 2501
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.6986 (0.7161)  Acc@1: 81.2500 (82.4119)  Acc@5: 100.0000 (97.6761)  time: 0.2169  data: 0.0003  max mem: 2501
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.8361 (0.7207)  Acc@1: 81.2500 (82.2577)  Acc@5: 100.0000 (97.6607)  time: 0.2163  data: 0.0006  max mem: 2501
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.8361 (0.7204)  Acc@1: 75.0000 (82.2387)  Acc@5: 100.0000 (97.6813)  time: 0.2162  data: 0.0007  max mem: 2501
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.5636 (0.7173)  Acc@1: 81.2500 (82.2897)  Acc@5: 100.0000 (97.6895)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.4137 (0.7119)  Acc@1: 87.5000 (82.4637)  Acc@5: 100.0000 (97.7201)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.3921 (0.7069)  Acc@1: 93.7500 (82.6537)  Acc@5: 100.0000 (97.7607)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.4604 (0.7089)  Acc@1: 87.5000 (82.6839)  Acc@5: 100.0000 (97.7561)  time: 0.2158  data: 0.0007  max mem: 2501
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.6159 (0.7056)  Acc@1: 87.5000 (82.8313)  Acc@5: 100.0000 (97.7840)  time: 0.2162  data: 0.0007  max mem: 2501
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.5132 (0.7011)  Acc@1: 93.7500 (82.9526)  Acc@5: 100.0000 (97.8109)  time: 0.2161  data: 0.0004  max mem: 2501
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.6262 (0.7026)  Acc@1: 87.5000 (82.9347)  Acc@5: 100.0000 (97.8057)  time: 0.2160  data: 0.0005  max mem: 2501
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.7831 (0.7095)  Acc@1: 75.0000 (82.7844)  Acc@5: 93.7500 (97.7496)  time: 0.2158  data: 0.0004  max mem: 2501
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.7831 (0.7091)  Acc@1: 81.2500 (82.8100)  Acc@5: 100.0000 (97.7858)  time: 0.2164  data: 0.0004  max mem: 2501
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.7157 (0.7084)  Acc@1: 87.5000 (82.8000)  Acc@5: 100.0000 (97.8000)  time: 0.2167  data: 0.0003  max mem: 2501
Test: [Task 2] Total time: 0:02:15 (0.2170 s / it)
* Acc@1 82.800 Acc@5 97.800 loss 0.708
Test: [Task 3]  [  0/625]  eta: 0:05:39  Loss: 0.3099 (0.3099)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5438  data: 0.3289  max mem: 2501
Test: [Task 3]  [ 10/625]  eta: 0:02:30  Loss: 0.2476 (0.2301)  Acc@1: 93.7500 (96.0227)  Acc@5: 100.0000 (98.8636)  time: 0.2453  data: 0.0302  max mem: 2501
Test: [Task 3]  [ 20/625]  eta: 0:02:20  Loss: 0.2476 (0.2532)  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (98.5119)  time: 0.2160  data: 0.0013  max mem: 2501
Test: [Task 3]  [ 30/625]  eta: 0:02:14  Loss: 0.2485 (0.2542)  Acc@1: 93.7500 (95.3629)  Acc@5: 100.0000 (98.7903)  time: 0.2153  data: 0.0013  max mem: 2501
Test: [Task 3]  [ 40/625]  eta: 0:02:10  Loss: 0.1712 (0.2346)  Acc@1: 93.7500 (95.7317)  Acc@5: 100.0000 (99.0854)  time: 0.2142  data: 0.0002  max mem: 2501
Test: [Task 3]  [ 50/625]  eta: 0:02:07  Loss: 0.1465 (0.2302)  Acc@1: 100.0000 (95.7108)  Acc@5: 100.0000 (99.1422)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 3]  [ 60/625]  eta: 0:02:04  Loss: 0.1629 (0.2222)  Acc@1: 100.0000 (96.2090)  Acc@5: 100.0000 (99.2828)  time: 0.2158  data: 0.0004  max mem: 2501
Test: [Task 3]  [ 70/625]  eta: 0:02:02  Loss: 0.1241 (0.2091)  Acc@1: 100.0000 (96.5669)  Acc@5: 100.0000 (99.2958)  time: 0.2161  data: 0.0007  max mem: 2501
Test: [Task 3]  [ 80/625]  eta: 0:01:59  Loss: 0.1241 (0.2132)  Acc@1: 100.0000 (96.5278)  Acc@5: 100.0000 (99.3827)  time: 0.2150  data: 0.0005  max mem: 2501
Test: [Task 3]  [ 90/625]  eta: 0:01:57  Loss: 0.1959 (0.2126)  Acc@1: 100.0000 (96.5659)  Acc@5: 100.0000 (99.3819)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 3]  [100/625]  eta: 0:01:54  Loss: 0.1729 (0.2099)  Acc@1: 100.0000 (96.7822)  Acc@5: 100.0000 (99.4431)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 0.1729 (0.2054)  Acc@1: 100.0000 (97.0158)  Acc@5: 100.0000 (99.4932)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 3]  [120/625]  eta: 0:01:49  Loss: 0.1758 (0.2073)  Acc@1: 100.0000 (97.0558)  Acc@5: 100.0000 (99.5351)  time: 0.2145  data: 0.0003  max mem: 2501
Test: [Task 3]  [130/625]  eta: 0:01:47  Loss: 0.1779 (0.2079)  Acc@1: 100.0000 (97.0897)  Acc@5: 100.0000 (99.5229)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 3]  [140/625]  eta: 0:01:45  Loss: 0.2207 (0.2134)  Acc@1: 100.0000 (96.9415)  Acc@5: 100.0000 (99.4681)  time: 0.2155  data: 0.0004  max mem: 2501
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 0.2436 (0.2185)  Acc@1: 93.7500 (96.6887)  Acc@5: 100.0000 (99.4205)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 3]  [160/625]  eta: 0:01:40  Loss: 0.1722 (0.2196)  Acc@1: 93.7500 (96.7391)  Acc@5: 100.0000 (99.3789)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 3]  [170/625]  eta: 0:01:38  Loss: 0.1891 (0.2198)  Acc@1: 100.0000 (96.7836)  Acc@5: 100.0000 (99.3787)  time: 0.2158  data: 0.0006  max mem: 2501
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.2296 (0.2220)  Acc@1: 93.7500 (96.7196)  Acc@5: 100.0000 (99.3785)  time: 0.2173  data: 0.0013  max mem: 2501
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.2248 (0.2211)  Acc@1: 93.7500 (96.6950)  Acc@5: 100.0000 (99.3783)  time: 0.2162  data: 0.0010  max mem: 2501
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 0.2248 (0.2235)  Acc@1: 93.7500 (96.6729)  Acc@5: 100.0000 (99.3781)  time: 0.2148  data: 0.0003  max mem: 2501
Test: [Task 3]  [210/625]  eta: 0:01:29  Loss: 0.1630 (0.2252)  Acc@1: 100.0000 (96.6825)  Acc@5: 100.0000 (99.3780)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 3]  [220/625]  eta: 0:01:27  Loss: 0.1510 (0.2254)  Acc@1: 100.0000 (96.6063)  Acc@5: 100.0000 (99.3213)  time: 0.2143  data: 0.0002  max mem: 2501
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.1578 (0.2256)  Acc@1: 93.7500 (96.6180)  Acc@5: 100.0000 (99.2965)  time: 0.2144  data: 0.0003  max mem: 2501
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.1578 (0.2276)  Acc@1: 100.0000 (96.5768)  Acc@5: 100.0000 (99.2739)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1593 (0.2261)  Acc@1: 100.0000 (96.6135)  Acc@5: 100.0000 (99.3028)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1589 (0.2264)  Acc@1: 100.0000 (96.5757)  Acc@5: 100.0000 (99.2816)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 3]  [270/625]  eta: 0:01:16  Loss: 0.1889 (0.2280)  Acc@1: 93.7500 (96.4483)  Acc@5: 100.0000 (99.2389)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 0.1889 (0.2279)  Acc@1: 93.7500 (96.4413)  Acc@5: 100.0000 (99.2438)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.2260 (0.2291)  Acc@1: 93.7500 (96.3918)  Acc@5: 100.0000 (99.2483)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.2260 (0.2294)  Acc@1: 93.7500 (96.3248)  Acc@5: 100.0000 (99.2733)  time: 0.2152  data: 0.0006  max mem: 2501
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1864 (0.2322)  Acc@1: 100.0000 (96.2822)  Acc@5: 100.0000 (99.2363)  time: 0.2147  data: 0.0005  max mem: 2501
Test: [Task 3]  [320/625]  eta: 0:01:05  Loss: 0.1937 (0.2313)  Acc@1: 100.0000 (96.3006)  Acc@5: 100.0000 (99.2407)  time: 0.2158  data: 0.0009  max mem: 2501
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 0.2181 (0.2336)  Acc@1: 93.7500 (96.2236)  Acc@5: 100.0000 (99.2447)  time: 0.2166  data: 0.0013  max mem: 2501
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.1791 (0.2311)  Acc@1: 93.7500 (96.2793)  Acc@5: 100.0000 (99.2669)  time: 0.2151  data: 0.0006  max mem: 2501
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1513 (0.2312)  Acc@1: 100.0000 (96.2785)  Acc@5: 100.0000 (99.2699)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.1947 (0.2325)  Acc@1: 93.7500 (96.2084)  Acc@5: 100.0000 (99.2729)  time: 0.2153  data: 0.0004  max mem: 2501
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.2587 (0.2338)  Acc@1: 93.7500 (96.1253)  Acc@5: 100.0000 (99.2925)  time: 0.2151  data: 0.0004  max mem: 2501
Test: [Task 3]  [380/625]  eta: 0:00:52  Loss: 0.1989 (0.2317)  Acc@1: 93.7500 (96.1942)  Acc@5: 100.0000 (99.3110)  time: 0.2146  data: 0.0005  max mem: 2501
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.1713 (0.2333)  Acc@1: 100.0000 (96.1317)  Acc@5: 100.0000 (99.3286)  time: 0.2146  data: 0.0005  max mem: 2501
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1713 (0.2320)  Acc@1: 93.7500 (96.1502)  Acc@5: 100.0000 (99.3142)  time: 0.2145  data: 0.0003  max mem: 2501
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.1675 (0.2332)  Acc@1: 100.0000 (96.1679)  Acc@5: 100.0000 (99.3157)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.1955 (0.2335)  Acc@1: 93.7500 (96.1550)  Acc@5: 100.0000 (99.3171)  time: 0.2152  data: 0.0005  max mem: 2501
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1870 (0.2333)  Acc@1: 93.7500 (96.1427)  Acc@5: 100.0000 (99.3184)  time: 0.2149  data: 0.0008  max mem: 2501
Test: [Task 3]  [440/625]  eta: 0:00:39  Loss: 0.1870 (0.2348)  Acc@1: 93.7500 (96.1026)  Acc@5: 100.0000 (99.2914)  time: 0.2156  data: 0.0008  max mem: 2501
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.1849 (0.2349)  Acc@1: 100.0000 (96.1475)  Acc@5: 100.0000 (99.2932)  time: 0.2156  data: 0.0007  max mem: 2501
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.1825 (0.2339)  Acc@1: 100.0000 (96.1632)  Acc@5: 100.0000 (99.3086)  time: 0.2152  data: 0.0007  max mem: 2501
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1825 (0.2334)  Acc@1: 100.0000 (96.1783)  Acc@5: 100.0000 (99.3100)  time: 0.2149  data: 0.0005  max mem: 2501
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1982 (0.2344)  Acc@1: 100.0000 (96.1538)  Acc@5: 100.0000 (99.2853)  time: 0.2141  data: 0.0003  max mem: 2501
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2564 (0.2349)  Acc@1: 93.7500 (96.1431)  Acc@5: 100.0000 (99.2872)  time: 0.2143  data: 0.0003  max mem: 2501
Test: [Task 3]  [500/625]  eta: 0:00:26  Loss: 0.2093 (0.2339)  Acc@1: 93.7500 (96.1452)  Acc@5: 100.0000 (99.3014)  time: 0.2148  data: 0.0003  max mem: 2501
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.1348 (0.2334)  Acc@1: 100.0000 (96.1473)  Acc@5: 100.0000 (99.3151)  time: 0.2164  data: 0.0004  max mem: 2501
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.2067 (0.2346)  Acc@1: 93.7500 (96.1132)  Acc@5: 100.0000 (99.3042)  time: 0.2171  data: 0.0004  max mem: 2501
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.2655 (0.2356)  Acc@1: 93.7500 (96.1040)  Acc@5: 100.0000 (99.2938)  time: 0.2160  data: 0.0003  max mem: 2501
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2312 (0.2369)  Acc@1: 100.0000 (96.0952)  Acc@5: 100.0000 (99.2606)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2312 (0.2376)  Acc@1: 93.7500 (96.0753)  Acc@5: 100.0000 (99.2514)  time: 0.2162  data: 0.0007  max mem: 2501
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1850 (0.2370)  Acc@1: 100.0000 (96.1119)  Acc@5: 100.0000 (99.2647)  time: 0.2158  data: 0.0007  max mem: 2501
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.1850 (0.2362)  Acc@1: 100.0000 (96.1252)  Acc@5: 100.0000 (99.2776)  time: 0.2152  data: 0.0007  max mem: 2501
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2318 (0.2384)  Acc@1: 93.7500 (96.0628)  Acc@5: 100.0000 (99.2577)  time: 0.2179  data: 0.0012  max mem: 2501
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1995 (0.2376)  Acc@1: 93.7500 (96.0871)  Acc@5: 100.0000 (99.2703)  time: 0.2173  data: 0.0008  max mem: 2501
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1995 (0.2375)  Acc@1: 93.7500 (96.0379)  Acc@5: 100.0000 (99.2720)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.2168 (0.2374)  Acc@1: 93.7500 (96.0413)  Acc@5: 100.0000 (99.2635)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2480 (0.2385)  Acc@1: 93.7500 (96.0044)  Acc@5: 100.0000 (99.2552)  time: 0.2146  data: 0.0002  max mem: 2501
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1955 (0.2378)  Acc@1: 93.7500 (96.0200)  Acc@5: 100.0000 (99.2600)  time: 0.2145  data: 0.0002  max mem: 2501
Test: [Task 3] Total time: 0:02:15 (0.2160 s / it)
* Acc@1 96.020 Acc@5 99.260 loss 0.238
{0: {0: 25002, 1: 25002, 2: 25002, 3: 25002, 4: 25, 5: 25, 6: 25, 7: 25, 8: 146, 9: 146, 10: 146, 11: 146, 12: 67, 13: 67, 14: 67, 15: 67, 16: 792, 17: 792, 18: 792, 19: 792}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 9896, 5: 9896, 6: 9896, 7: 9896, 8: 0, 9: 0, 10: 0, 11: 0, 12: 104, 13: 104, 14: 104, 15: 104, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 151, 1: 151, 2: 151, 3: 151, 4: 14, 5: 14, 6: 14, 7: 14, 8: 9679, 9: 9679, 10: 9679, 11: 9679, 12: 46, 13: 46, 14: 46, 15: 46, 16: 110, 17: 110, 18: 110, 19: 110}}
[Average accuracy till task3]	Acc@1: 70.9440	Acc@5: 88.9824	Loss: 1.1998	Forgetting: 31.3875	Backward: -31.3875
Train: Epoch[1/5]  [   0/1142]  eta: 0:13:30  Lr: 0.001875  Loss: 2.2739  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  time: 0.7096  data: 0.3567  max mem: 2501
Train: Epoch[1/5]  [  10/1142]  eta: 0:07:08  Lr: 0.001875  Loss: 2.1392  Acc@1: 25.0000 (27.8409)  Acc@5: 68.7500 (66.4773)  time: 0.3782  data: 0.0327  max mem: 2501
Train: Epoch[1/5]  [  20/1142]  eta: 0:06:46  Lr: 0.001875  Loss: 1.9410  Acc@1: 31.2500 (30.6548)  Acc@5: 68.7500 (70.2381)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [  30/1142]  eta: 0:06:37  Lr: 0.001875  Loss: 1.7873  Acc@1: 31.2500 (33.2661)  Acc@5: 81.2500 (73.9919)  time: 0.3460  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [  40/1142]  eta: 0:06:30  Lr: 0.001875  Loss: 1.9358  Acc@1: 37.5000 (35.2134)  Acc@5: 87.5000 (77.5915)  time: 0.3468  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [  50/1142]  eta: 0:06:25  Lr: 0.001875  Loss: 1.6833  Acc@1: 50.0000 (38.8480)  Acc@5: 93.7500 (80.7598)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [  60/1142]  eta: 0:06:19  Lr: 0.001875  Loss: 1.8216  Acc@1: 50.0000 (39.8566)  Acc@5: 93.7500 (81.6598)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [  70/1142]  eta: 0:06:15  Lr: 0.001875  Loss: 1.7808  Acc@1: 43.7500 (40.6690)  Acc@5: 87.5000 (82.6585)  time: 0.3440  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [  80/1142]  eta: 0:06:11  Lr: 0.001875  Loss: 1.4021  Acc@1: 50.0000 (42.0525)  Acc@5: 87.5000 (83.1790)  time: 0.3440  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [  90/1142]  eta: 0:06:07  Lr: 0.001875  Loss: 1.3503  Acc@1: 50.0000 (42.5824)  Acc@5: 87.5000 (83.6538)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 100/1142]  eta: 0:06:03  Lr: 0.001875  Loss: 1.2759  Acc@1: 50.0000 (44.6163)  Acc@5: 87.5000 (84.0965)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 110/1142]  eta: 0:05:59  Lr: 0.001875  Loss: 1.3688  Acc@1: 56.2500 (45.3266)  Acc@5: 87.5000 (84.2905)  time: 0.3447  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 120/1142]  eta: 0:05:55  Lr: 0.001875  Loss: 1.7719  Acc@1: 56.2500 (46.2810)  Acc@5: 87.5000 (84.9690)  time: 0.3451  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [ 130/1142]  eta: 0:05:51  Lr: 0.001875  Loss: 0.9850  Acc@1: 56.2500 (46.5649)  Acc@5: 93.7500 (85.2576)  time: 0.3455  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [ 140/1142]  eta: 0:05:48  Lr: 0.001875  Loss: 1.3314  Acc@1: 43.7500 (46.7642)  Acc@5: 87.5000 (85.4610)  time: 0.3456  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [ 150/1142]  eta: 0:05:44  Lr: 0.001875  Loss: 1.5266  Acc@1: 50.0000 (47.3510)  Acc@5: 87.5000 (85.7616)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 160/1142]  eta: 0:05:40  Lr: 0.001875  Loss: 1.4504  Acc@1: 50.0000 (47.5932)  Acc@5: 87.5000 (85.9084)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 170/1142]  eta: 0:05:37  Lr: 0.001875  Loss: 1.3767  Acc@1: 50.0000 (48.0263)  Acc@5: 87.5000 (86.1842)  time: 0.3446  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 180/1142]  eta: 0:05:33  Lr: 0.001875  Loss: 1.6587  Acc@1: 50.0000 (48.3080)  Acc@5: 87.5000 (86.3260)  time: 0.3465  data: 0.0019  max mem: 2501
Train: Epoch[1/5]  [ 190/1142]  eta: 0:05:30  Lr: 0.001875  Loss: 1.7019  Acc@1: 50.0000 (48.2003)  Acc@5: 87.5000 (86.5510)  time: 0.3460  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 200/1142]  eta: 0:05:26  Lr: 0.001875  Loss: 1.3196  Acc@1: 56.2500 (48.9428)  Acc@5: 93.7500 (86.8781)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 210/1142]  eta: 0:05:23  Lr: 0.001875  Loss: 1.4870  Acc@1: 62.5000 (49.2891)  Acc@5: 93.7500 (87.2334)  time: 0.3470  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 220/1142]  eta: 0:05:19  Lr: 0.001875  Loss: 1.1964  Acc@1: 56.2500 (49.6324)  Acc@5: 93.7500 (87.4152)  time: 0.3460  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 230/1142]  eta: 0:05:16  Lr: 0.001875  Loss: 1.5960  Acc@1: 56.2500 (49.9188)  Acc@5: 93.7500 (87.6623)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 240/1142]  eta: 0:05:12  Lr: 0.001875  Loss: 1.5677  Acc@1: 56.2500 (50.2075)  Acc@5: 87.5000 (87.7593)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 250/1142]  eta: 0:05:09  Lr: 0.001875  Loss: 1.4160  Acc@1: 56.2500 (50.5478)  Acc@5: 93.7500 (87.9482)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 260/1142]  eta: 0:05:05  Lr: 0.001875  Loss: 1.3744  Acc@1: 56.2500 (50.8860)  Acc@5: 93.7500 (88.0268)  time: 0.3452  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 270/1142]  eta: 0:05:02  Lr: 0.001875  Loss: 0.9392  Acc@1: 56.2500 (51.1301)  Acc@5: 87.5000 (88.1227)  time: 0.3454  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 280/1142]  eta: 0:04:58  Lr: 0.001875  Loss: 1.1268  Acc@1: 56.2500 (51.3568)  Acc@5: 93.7500 (88.3007)  time: 0.3464  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 290/1142]  eta: 0:04:55  Lr: 0.001875  Loss: 1.2393  Acc@1: 56.2500 (51.4820)  Acc@5: 93.7500 (88.4021)  time: 0.3458  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 300/1142]  eta: 0:04:51  Lr: 0.001875  Loss: 1.0679  Acc@1: 56.2500 (51.7027)  Acc@5: 93.7500 (88.4967)  time: 0.3452  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 310/1142]  eta: 0:04:48  Lr: 0.001875  Loss: 1.1443  Acc@1: 62.5000 (52.0297)  Acc@5: 93.7500 (88.6053)  time: 0.3462  data: 0.0021  max mem: 2501
Train: Epoch[1/5]  [ 320/1142]  eta: 0:04:44  Lr: 0.001875  Loss: 0.9968  Acc@1: 62.5000 (52.2002)  Acc@5: 93.7500 (88.6488)  time: 0.3469  data: 0.0021  max mem: 2501
Train: Epoch[1/5]  [ 330/1142]  eta: 0:04:41  Lr: 0.001875  Loss: 1.2858  Acc@1: 62.5000 (52.4547)  Acc@5: 87.5000 (88.6518)  time: 0.3465  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 340/1142]  eta: 0:04:37  Lr: 0.001875  Loss: 1.5712  Acc@1: 62.5000 (52.7859)  Acc@5: 87.5000 (88.6730)  time: 0.3457  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 350/1142]  eta: 0:04:34  Lr: 0.001875  Loss: 1.0550  Acc@1: 62.5000 (53.0271)  Acc@5: 93.7500 (88.7108)  time: 0.3458  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 360/1142]  eta: 0:04:30  Lr: 0.001875  Loss: 1.0987  Acc@1: 62.5000 (53.3241)  Acc@5: 93.7500 (88.7985)  time: 0.3460  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 370/1142]  eta: 0:04:27  Lr: 0.001875  Loss: 1.1273  Acc@1: 62.5000 (53.5377)  Acc@5: 93.7500 (88.9993)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.001875  Loss: 1.5516  Acc@1: 56.2500 (53.6417)  Acc@5: 93.7500 (89.0420)  time: 0.3443  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 390/1142]  eta: 0:04:20  Lr: 0.001875  Loss: 1.1178  Acc@1: 56.2500 (53.7404)  Acc@5: 93.7500 (89.2104)  time: 0.3456  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [ 400/1142]  eta: 0:04:16  Lr: 0.001875  Loss: 1.2837  Acc@1: 56.2500 (53.9589)  Acc@5: 93.7500 (89.2924)  time: 0.3453  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 410/1142]  eta: 0:04:13  Lr: 0.001875  Loss: 1.4442  Acc@1: 62.5000 (54.2883)  Acc@5: 93.7500 (89.3400)  time: 0.3445  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.001875  Loss: 1.0818  Acc@1: 62.5000 (54.2755)  Acc@5: 87.5000 (89.2815)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 430/1142]  eta: 0:04:06  Lr: 0.001875  Loss: 1.0785  Acc@1: 56.2500 (54.4519)  Acc@5: 93.7500 (89.3561)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.001875  Loss: 0.9778  Acc@1: 56.2500 (54.4926)  Acc@5: 93.7500 (89.4416)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 450/1142]  eta: 0:03:59  Lr: 0.001875  Loss: 1.0435  Acc@1: 62.5000 (54.6979)  Acc@5: 93.7500 (89.5233)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.001875  Loss: 1.3032  Acc@1: 62.5000 (54.7316)  Acc@5: 93.7500 (89.5607)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 470/1142]  eta: 0:03:52  Lr: 0.001875  Loss: 0.8113  Acc@1: 62.5000 (54.8832)  Acc@5: 93.7500 (89.6762)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 480/1142]  eta: 0:03:49  Lr: 0.001875  Loss: 1.6966  Acc@1: 62.5000 (54.8207)  Acc@5: 93.7500 (89.6830)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.001875  Loss: 1.3086  Acc@1: 50.0000 (54.8753)  Acc@5: 93.7500 (89.7403)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 500/1142]  eta: 0:03:42  Lr: 0.001875  Loss: 1.4061  Acc@1: 56.2500 (55.1397)  Acc@5: 93.7500 (89.7705)  time: 0.3452  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.001875  Loss: 0.8221  Acc@1: 62.5000 (55.2226)  Acc@5: 87.5000 (89.8116)  time: 0.3454  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 520/1142]  eta: 0:03:35  Lr: 0.001875  Loss: 1.1278  Acc@1: 56.2500 (55.2903)  Acc@5: 93.7500 (89.8512)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.001875  Loss: 1.4382  Acc@1: 56.2500 (55.4143)  Acc@5: 93.7500 (89.9364)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 540/1142]  eta: 0:03:28  Lr: 0.001875  Loss: 1.2856  Acc@1: 62.5000 (55.5106)  Acc@5: 93.7500 (89.9838)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.001875  Loss: 0.9179  Acc@1: 62.5000 (55.5808)  Acc@5: 93.7500 (90.0295)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.001875  Loss: 1.1118  Acc@1: 62.5000 (55.6707)  Acc@5: 93.7500 (90.0512)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.001875  Loss: 1.3598  Acc@1: 62.5000 (55.7684)  Acc@5: 93.7500 (90.0941)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 580/1142]  eta: 0:03:14  Lr: 0.001875  Loss: 1.2831  Acc@1: 62.5000 (55.9165)  Acc@5: 93.7500 (90.1463)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.001875  Loss: 1.5286  Acc@1: 62.5000 (56.0279)  Acc@5: 93.7500 (90.1861)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.001875  Loss: 0.7141  Acc@1: 62.5000 (56.2188)  Acc@5: 93.7500 (90.2454)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.001875  Loss: 1.1217  Acc@1: 68.7500 (56.4239)  Acc@5: 93.7500 (90.2926)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.001875  Loss: 0.9222  Acc@1: 68.7500 (56.5318)  Acc@5: 93.7500 (90.3482)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.001875  Loss: 0.7086  Acc@1: 62.5000 (56.6462)  Acc@5: 93.7500 (90.4021)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.001875  Loss: 1.3213  Acc@1: 62.5000 (56.7278)  Acc@5: 93.7500 (90.4446)  time: 0.3449  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 650/1142]  eta: 0:02:50  Lr: 0.001875  Loss: 1.1861  Acc@1: 62.5000 (56.8548)  Acc@5: 93.7500 (90.4858)  time: 0.3461  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.001875  Loss: 0.6004  Acc@1: 56.2500 (56.9024)  Acc@5: 93.7500 (90.4784)  time: 0.3472  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.001875  Loss: 1.1972  Acc@1: 62.5000 (57.0138)  Acc@5: 87.5000 (90.4899)  time: 0.3467  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.001875  Loss: 1.0988  Acc@1: 62.5000 (57.0943)  Acc@5: 87.5000 (90.4919)  time: 0.3460  data: 0.0016  max mem: 2501
Train: Epoch[1/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.001875  Loss: 1.0307  Acc@1: 62.5000 (57.1274)  Acc@5: 93.7500 (90.5391)  time: 0.3447  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.001875  Loss: 1.0033  Acc@1: 62.5000 (57.3110)  Acc@5: 93.7500 (90.5670)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.001875  Loss: 0.8134  Acc@1: 62.5000 (57.4367)  Acc@5: 93.7500 (90.6118)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.001875  Loss: 0.8173  Acc@1: 62.5000 (57.4549)  Acc@5: 93.7500 (90.6293)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.001875  Loss: 1.3279  Acc@1: 56.2500 (57.5154)  Acc@5: 93.7500 (90.6464)  time: 0.3449  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.001875  Loss: 0.9987  Acc@1: 62.5000 (57.5658)  Acc@5: 87.5000 (90.6208)  time: 0.3449  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.001875  Loss: 1.2358  Acc@1: 62.5000 (57.6648)  Acc@5: 87.5000 (90.6375)  time: 0.3443  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.001875  Loss: 1.1987  Acc@1: 62.5000 (57.7858)  Acc@5: 93.7500 (90.6866)  time: 0.3463  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.001875  Loss: 0.9181  Acc@1: 62.5000 (57.8713)  Acc@5: 93.7500 (90.7020)  time: 0.3463  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: 0.9539  Acc@1: 62.5000 (57.9545)  Acc@5: 93.7500 (90.6850)  time: 0.3453  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.001875  Loss: 0.8834  Acc@1: 68.7500 (58.0831)  Acc@5: 93.7500 (90.7317)  time: 0.3472  data: 0.0023  max mem: 2501
Train: Epoch[1/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: 0.7241  Acc@1: 68.7500 (58.1773)  Acc@5: 93.7500 (90.7850)  time: 0.3459  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.001875  Loss: 0.9259  Acc@1: 68.7500 (58.2229)  Acc@5: 93.7500 (90.8215)  time: 0.3456  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: 1.0535  Acc@1: 68.7500 (58.3739)  Acc@5: 93.7500 (90.8724)  time: 0.3460  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.001875  Loss: 1.1769  Acc@1: 62.5000 (58.3709)  Acc@5: 93.7500 (90.8770)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: 0.8356  Acc@1: 62.5000 (58.4423)  Acc@5: 93.7500 (90.9111)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.001875  Loss: 0.7161  Acc@1: 62.5000 (58.5488)  Acc@5: 93.7500 (90.9298)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: 1.1846  Acc@1: 62.5000 (58.6237)  Acc@5: 93.7500 (90.9625)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.001875  Loss: 1.0144  Acc@1: 62.5000 (58.6754)  Acc@5: 93.7500 (91.0232)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.001875  Loss: 1.0034  Acc@1: 62.5000 (58.7117)  Acc@5: 93.7500 (91.0329)  time: 0.3453  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: 0.9949  Acc@1: 62.5000 (58.7682)  Acc@5: 93.7500 (91.0704)  time: 0.3453  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.001875  Loss: 1.0889  Acc@1: 62.5000 (58.8582)  Acc@5: 93.7500 (91.1071)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: 1.1729  Acc@1: 62.5000 (58.8707)  Acc@5: 93.7500 (91.1087)  time: 0.3465  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.001875  Loss: 0.9331  Acc@1: 62.5000 (58.8762)  Acc@5: 93.7500 (91.1441)  time: 0.3465  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: 0.8820  Acc@1: 62.5000 (58.9017)  Acc@5: 93.7500 (91.1654)  time: 0.3458  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.001875  Loss: 0.9569  Acc@1: 56.2500 (58.9134)  Acc@5: 93.7500 (91.2062)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: 1.0977  Acc@1: 56.2500 (58.9380)  Acc@5: 93.7500 (91.2329)  time: 0.3436  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.001875  Loss: 1.3599  Acc@1: 62.5000 (59.0206)  Acc@5: 93.7500 (91.2721)  time: 0.3442  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: 1.2984  Acc@1: 68.7500 (59.1594)  Acc@5: 93.7500 (91.3041)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.001875  Loss: 1.0223  Acc@1: 68.7500 (59.2253)  Acc@5: 87.5000 (91.2908)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: 0.8455  Acc@1: 62.5000 (59.2772)  Acc@5: 93.7500 (91.3030)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: 1.3693  Acc@1: 62.5000 (59.3407)  Acc@5: 93.7500 (91.3212)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: 0.6324  Acc@1: 62.5000 (59.3657)  Acc@5: 93.7500 (91.3019)  time: 0.3451  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: 0.9128  Acc@1: 62.5000 (59.3536)  Acc@5: 87.5000 (91.3014)  time: 0.3443  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: 0.8139  Acc@1: 62.5000 (59.4205)  Acc@5: 93.7500 (91.2827)  time: 0.3432  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 1.3663  Acc@1: 62.5000 (59.4621)  Acc@5: 93.7500 (91.2884)  time: 0.3434  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: 1.0794  Acc@1: 62.5000 (59.5266)  Acc@5: 93.7500 (91.3059)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: 0.8970  Acc@1: 62.5000 (59.5488)  Acc@5: 93.7500 (91.2936)  time: 0.3448  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:24  Lr: 0.001875  Loss: 0.5908  Acc@1: 62.5000 (59.5880)  Acc@5: 93.7500 (91.3107)  time: 0.3448  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: 1.0390  Acc@1: 62.5000 (59.6323)  Acc@5: 93.7500 (91.3217)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:17  Lr: 0.001875  Loss: 1.0261  Acc@1: 62.5000 (59.6242)  Acc@5: 93.7500 (91.3497)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: 0.7914  Acc@1: 56.2500 (59.6503)  Acc@5: 93.7500 (91.3772)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5792  Acc@1: 62.5000 (59.7266)  Acc@5: 93.7500 (91.3985)  time: 0.3452  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: 0.9304  Acc@1: 68.7500 (59.7681)  Acc@5: 93.7500 (91.3972)  time: 0.3464  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: 0.8928  Acc@1: 68.7500 (59.8143)  Acc@5: 93.7500 (91.4180)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6764  Acc@1: 68.7500 (59.8488)  Acc@5: 93.7500 (91.4549)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 1.4629  Acc@1: 62.5000 (59.8467)  Acc@5: 93.7500 (91.4481)  time: 0.3372  data: 0.0003  max mem: 2501
Train: Epoch[1/5] Total time: 0:06:34 (0.3454 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.4629  Acc@1: 62.5000 (59.8467)  Acc@5: 93.7500 (91.4481)
Train: Epoch[2/5]  [   0/1142]  eta: 0:11:01  Lr: 0.001875  Loss: 0.3455  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5797  data: 0.2310  max mem: 2501
Train: Epoch[2/5]  [  10/1142]  eta: 0:06:53  Lr: 0.001875  Loss: 0.8042  Acc@1: 75.0000 (72.7273)  Acc@5: 93.7500 (93.7500)  time: 0.3653  data: 0.0222  max mem: 2501
Train: Epoch[2/5]  [  20/1142]  eta: 0:06:39  Lr: 0.001875  Loss: 1.6120  Acc@1: 68.7500 (69.0476)  Acc@5: 93.7500 (91.0714)  time: 0.3447  data: 0.0015  max mem: 2501
Train: Epoch[2/5]  [  30/1142]  eta: 0:06:31  Lr: 0.001875  Loss: 1.1222  Acc@1: 68.7500 (68.3468)  Acc@5: 87.5000 (90.7258)  time: 0.3449  data: 0.0014  max mem: 2501
Train: Epoch[2/5]  [  40/1142]  eta: 0:06:26  Lr: 0.001875  Loss: 1.6107  Acc@1: 68.7500 (67.6829)  Acc@5: 93.7500 (91.0061)  time: 0.3444  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [  50/1142]  eta: 0:06:20  Lr: 0.001875  Loss: 1.0883  Acc@1: 68.7500 (68.3824)  Acc@5: 93.7500 (91.7892)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  60/1142]  eta: 0:06:16  Lr: 0.001875  Loss: 0.7248  Acc@1: 68.7500 (68.0328)  Acc@5: 93.7500 (91.8033)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  70/1142]  eta: 0:06:13  Lr: 0.001875  Loss: 0.7273  Acc@1: 68.7500 (68.2218)  Acc@5: 93.7500 (92.4296)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [  80/1142]  eta: 0:06:09  Lr: 0.001875  Loss: 1.1112  Acc@1: 68.7500 (67.5926)  Acc@5: 93.7500 (92.5154)  time: 0.3466  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:05  Lr: 0.001875  Loss: 1.4012  Acc@1: 62.5000 (66.9643)  Acc@5: 93.7500 (92.6511)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:01  Lr: 0.001875  Loss: 0.9819  Acc@1: 62.5000 (66.6460)  Acc@5: 93.7500 (92.5124)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 110/1142]  eta: 0:05:57  Lr: 0.001875  Loss: 1.0176  Acc@1: 62.5000 (66.0473)  Acc@5: 93.7500 (92.3423)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 120/1142]  eta: 0:05:54  Lr: 0.001875  Loss: 1.4831  Acc@1: 62.5000 (66.0640)  Acc@5: 93.7500 (92.2004)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 130/1142]  eta: 0:05:50  Lr: 0.001875  Loss: 0.8486  Acc@1: 68.7500 (66.0305)  Acc@5: 93.7500 (92.4618)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 140/1142]  eta: 0:05:46  Lr: 0.001875  Loss: 1.0006  Acc@1: 68.7500 (65.9574)  Acc@5: 93.7500 (92.4202)  time: 0.3446  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 150/1142]  eta: 0:05:43  Lr: 0.001875  Loss: 2.0727  Acc@1: 62.5000 (65.8940)  Acc@5: 93.7500 (92.4255)  time: 0.3441  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 160/1142]  eta: 0:05:39  Lr: 0.001875  Loss: 0.5036  Acc@1: 68.7500 (66.2267)  Acc@5: 100.0000 (92.8183)  time: 0.3432  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 170/1142]  eta: 0:05:35  Lr: 0.001875  Loss: 1.3856  Acc@1: 68.7500 (65.9357)  Acc@5: 100.0000 (92.8363)  time: 0.3438  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 180/1142]  eta: 0:05:32  Lr: 0.001875  Loss: 1.0466  Acc@1: 62.5000 (65.7804)  Acc@5: 93.7500 (92.7141)  time: 0.3437  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 190/1142]  eta: 0:05:28  Lr: 0.001875  Loss: 0.7116  Acc@1: 62.5000 (65.9031)  Acc@5: 93.7500 (92.8338)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 200/1142]  eta: 0:05:25  Lr: 0.001875  Loss: 0.7650  Acc@1: 68.7500 (66.0137)  Acc@5: 93.7500 (92.9415)  time: 0.3440  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 210/1142]  eta: 0:05:21  Lr: 0.001875  Loss: 1.7221  Acc@1: 68.7500 (65.7583)  Acc@5: 93.7500 (92.9206)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 220/1142]  eta: 0:05:18  Lr: 0.001875  Loss: 1.0978  Acc@1: 62.5000 (65.8088)  Acc@5: 93.7500 (92.8733)  time: 0.3439  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:14  Lr: 0.001875  Loss: 0.9705  Acc@1: 62.5000 (65.8279)  Acc@5: 93.7500 (92.9924)  time: 0.3447  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:11  Lr: 0.001875  Loss: 0.7566  Acc@1: 62.5000 (65.7936)  Acc@5: 100.0000 (93.1017)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:07  Lr: 0.001875  Loss: 0.7527  Acc@1: 62.5000 (65.7371)  Acc@5: 100.0000 (93.1773)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:04  Lr: 0.001875  Loss: 1.0481  Acc@1: 62.5000 (65.7088)  Acc@5: 93.7500 (93.1753)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:00  Lr: 0.001875  Loss: 1.1060  Acc@1: 62.5000 (65.6365)  Acc@5: 93.7500 (93.2657)  time: 0.3446  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 280/1142]  eta: 0:04:57  Lr: 0.001875  Loss: 1.3123  Acc@1: 62.5000 (65.4582)  Acc@5: 93.7500 (93.3274)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 290/1142]  eta: 0:04:53  Lr: 0.001875  Loss: 0.4486  Acc@1: 62.5000 (65.4854)  Acc@5: 93.7500 (93.4064)  time: 0.3441  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 300/1142]  eta: 0:04:50  Lr: 0.001875  Loss: 0.6956  Acc@1: 62.5000 (65.3654)  Acc@5: 93.7500 (93.4178)  time: 0.3447  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 310/1142]  eta: 0:04:47  Lr: 0.001875  Loss: 0.9713  Acc@1: 62.5000 (65.2733)  Acc@5: 93.7500 (93.2878)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 320/1142]  eta: 0:04:43  Lr: 0.001875  Loss: 0.9870  Acc@1: 62.5000 (65.3232)  Acc@5: 93.7500 (93.2632)  time: 0.3450  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 330/1142]  eta: 0:04:40  Lr: 0.001875  Loss: 1.0740  Acc@1: 62.5000 (65.2190)  Acc@5: 93.7500 (93.2591)  time: 0.3442  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 340/1142]  eta: 0:04:36  Lr: 0.001875  Loss: 1.2630  Acc@1: 62.5000 (65.1760)  Acc@5: 93.7500 (93.2918)  time: 0.3463  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 350/1142]  eta: 0:04:33  Lr: 0.001875  Loss: 1.3689  Acc@1: 62.5000 (65.0107)  Acc@5: 93.7500 (93.3048)  time: 0.3466  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 360/1142]  eta: 0:04:29  Lr: 0.001875  Loss: 1.1122  Acc@1: 62.5000 (64.9584)  Acc@5: 93.7500 (93.3345)  time: 0.3462  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [ 370/1142]  eta: 0:04:26  Lr: 0.001875  Loss: 1.2592  Acc@1: 62.5000 (64.9596)  Acc@5: 93.7500 (93.3288)  time: 0.3458  data: 0.0015  max mem: 2501
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.001875  Loss: 0.9012  Acc@1: 62.5000 (64.7638)  Acc@5: 93.7500 (93.3563)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:19  Lr: 0.001875  Loss: 1.1950  Acc@1: 62.5000 (64.8977)  Acc@5: 93.7500 (93.4303)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:16  Lr: 0.001875  Loss: 0.7357  Acc@1: 68.7500 (64.9002)  Acc@5: 93.7500 (93.3136)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:12  Lr: 0.001875  Loss: 1.4124  Acc@1: 62.5000 (64.7354)  Acc@5: 93.7500 (93.3242)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.001875  Loss: 0.9724  Acc@1: 62.5000 (64.6378)  Acc@5: 93.7500 (93.3640)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:05  Lr: 0.001875  Loss: 1.0521  Acc@1: 62.5000 (64.7187)  Acc@5: 93.7500 (93.3875)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.001875  Loss: 0.8502  Acc@1: 62.5000 (64.6684)  Acc@5: 93.7500 (93.4099)  time: 0.3452  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 450/1142]  eta: 0:03:58  Lr: 0.001875  Loss: 1.0335  Acc@1: 62.5000 (64.5926)  Acc@5: 93.7500 (93.3758)  time: 0.3449  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.001875  Loss: 1.1950  Acc@1: 62.5000 (64.5607)  Acc@5: 93.7500 (93.3975)  time: 0.3456  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 470/1142]  eta: 0:03:51  Lr: 0.001875  Loss: 0.5766  Acc@1: 62.5000 (64.4639)  Acc@5: 93.7500 (93.3785)  time: 0.3465  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 480/1142]  eta: 0:03:48  Lr: 0.001875  Loss: 0.9677  Acc@1: 62.5000 (64.6180)  Acc@5: 93.7500 (93.4252)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.001875  Loss: 0.6994  Acc@1: 68.7500 (64.8167)  Acc@5: 93.7500 (93.4700)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 500/1142]  eta: 0:03:41  Lr: 0.001875  Loss: 0.6655  Acc@1: 68.7500 (64.8328)  Acc@5: 93.7500 (93.5130)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.001875  Loss: 0.9491  Acc@1: 68.7500 (64.8116)  Acc@5: 93.7500 (93.5298)  time: 0.3453  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 520/1142]  eta: 0:03:34  Lr: 0.001875  Loss: 0.9197  Acc@1: 68.7500 (64.8872)  Acc@5: 93.7500 (93.5341)  time: 0.3452  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.001875  Loss: 1.4362  Acc@1: 68.7500 (64.8423)  Acc@5: 93.7500 (93.5617)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:27  Lr: 0.001875  Loss: 1.1800  Acc@1: 68.7500 (64.8336)  Acc@5: 93.7500 (93.5305)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.001875  Loss: 0.6847  Acc@1: 68.7500 (64.8593)  Acc@5: 93.7500 (93.5345)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:20  Lr: 0.001875  Loss: 1.3021  Acc@1: 68.7500 (64.8953)  Acc@5: 93.7500 (93.4715)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.001875  Loss: 0.9588  Acc@1: 68.7500 (64.9737)  Acc@5: 93.7500 (93.5092)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:13  Lr: 0.001875  Loss: 0.8827  Acc@1: 62.5000 (64.9419)  Acc@5: 93.7500 (93.5133)  time: 0.3457  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.001875  Loss: 0.8672  Acc@1: 62.5000 (64.9323)  Acc@5: 93.7500 (93.5491)  time: 0.3452  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.001875  Loss: 0.9619  Acc@1: 62.5000 (64.8918)  Acc@5: 93.7500 (93.5524)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.001875  Loss: 1.1288  Acc@1: 62.5000 (64.9038)  Acc@5: 93.7500 (93.5250)  time: 0.3443  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.001875  Loss: 0.8918  Acc@1: 68.7500 (64.8551)  Acc@5: 93.7500 (93.5286)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.001875  Loss: 0.6765  Acc@1: 68.7500 (64.8673)  Acc@5: 93.7500 (93.5024)  time: 0.3469  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.001875  Loss: 0.9033  Acc@1: 68.7500 (64.9181)  Acc@5: 93.7500 (93.5452)  time: 0.3462  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 650/1142]  eta: 0:02:49  Lr: 0.001875  Loss: 1.4027  Acc@1: 62.5000 (64.8137)  Acc@5: 93.7500 (93.5388)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.001875  Loss: 1.3069  Acc@1: 62.5000 (64.7787)  Acc@5: 93.7500 (93.4947)  time: 0.3443  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 670/1142]  eta: 0:02:42  Lr: 0.001875  Loss: 1.1756  Acc@1: 62.5000 (64.7820)  Acc@5: 93.7500 (93.4799)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.001875  Loss: 0.9370  Acc@1: 62.5000 (64.8128)  Acc@5: 93.7500 (93.5114)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:35  Lr: 0.001875  Loss: 0.8863  Acc@1: 62.5000 (64.7884)  Acc@5: 93.7500 (93.5239)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.001875  Loss: 0.7444  Acc@1: 68.7500 (64.8359)  Acc@5: 93.7500 (93.5271)  time: 0.3458  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.001875  Loss: 1.0758  Acc@1: 68.7500 (64.8383)  Acc@5: 93.7500 (93.4951)  time: 0.3465  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.001875  Loss: 0.8920  Acc@1: 62.5000 (64.7972)  Acc@5: 93.7500 (93.4899)  time: 0.3461  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.001875  Loss: 0.8285  Acc@1: 68.7500 (64.8598)  Acc@5: 93.7500 (93.5021)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.001875  Loss: 1.2919  Acc@1: 68.7500 (64.8785)  Acc@5: 93.7500 (93.5223)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.001875  Loss: 0.9364  Acc@1: 62.5000 (64.8635)  Acc@5: 93.7500 (93.5419)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:11  Lr: 0.001875  Loss: 0.9449  Acc@1: 68.7500 (64.9064)  Acc@5: 93.7500 (93.5447)  time: 0.3455  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.001875  Loss: 1.0755  Acc@1: 68.7500 (64.9481)  Acc@5: 93.7500 (93.5473)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:04  Lr: 0.001875  Loss: 1.1902  Acc@1: 68.7500 (64.9328)  Acc@5: 87.5000 (93.4859)  time: 0.3456  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.001875  Loss: 1.5506  Acc@1: 62.5000 (64.8467)  Acc@5: 87.5000 (93.4497)  time: 0.3455  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: 0.7113  Acc@1: 68.7500 (64.8486)  Acc@5: 87.5000 (93.4067)  time: 0.3462  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.001875  Loss: 1.2129  Acc@1: 62.5000 (64.8043)  Acc@5: 93.7500 (93.4186)  time: 0.3467  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: 1.5196  Acc@1: 62.5000 (64.8523)  Acc@5: 93.7500 (93.4455)  time: 0.3458  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.001875  Loss: 1.3321  Acc@1: 68.7500 (64.8767)  Acc@5: 93.7500 (93.4191)  time: 0.3446  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: 1.0593  Acc@1: 68.7500 (64.8558)  Acc@5: 93.7500 (93.4156)  time: 0.3455  data: 0.0014  max mem: 2501
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.001875  Loss: 0.8627  Acc@1: 62.5000 (64.9163)  Acc@5: 93.7500 (93.4269)  time: 0.3467  data: 0.0018  max mem: 2501
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: 0.8436  Acc@1: 62.5000 (64.8955)  Acc@5: 93.7500 (93.4088)  time: 0.3466  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.001875  Loss: 0.7253  Acc@1: 62.5000 (64.8895)  Acc@5: 93.7500 (93.4127)  time: 0.3456  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.001875  Loss: 0.8738  Acc@1: 62.5000 (64.8624)  Acc@5: 93.7500 (93.4237)  time: 0.3460  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: 1.3857  Acc@1: 56.2500 (64.8359)  Acc@5: 93.7500 (93.3993)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.001875  Loss: 1.2177  Acc@1: 62.5000 (64.8585)  Acc@5: 87.5000 (93.3546)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: 0.9593  Acc@1: 68.7500 (64.8943)  Acc@5: 87.5000 (93.3315)  time: 0.3457  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.001875  Loss: 1.1131  Acc@1: 68.7500 (64.9091)  Acc@5: 93.7500 (93.3496)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: 0.7871  Acc@1: 68.7500 (64.9100)  Acc@5: 93.7500 (93.3271)  time: 0.3470  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.001875  Loss: 0.8443  Acc@1: 62.5000 (64.8844)  Acc@5: 93.7500 (93.3249)  time: 0.3486  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: 0.9147  Acc@1: 68.7500 (64.9251)  Acc@5: 93.7500 (93.3491)  time: 0.3472  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.001875  Loss: 0.8094  Acc@1: 62.5000 (64.9063)  Acc@5: 93.7500 (93.3598)  time: 0.3452  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: 0.9353  Acc@1: 68.7500 (64.9395)  Acc@5: 93.7500 (93.3831)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.001875  Loss: 0.9749  Acc@1: 68.7500 (64.9783)  Acc@5: 93.7500 (93.4123)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: 1.5224  Acc@1: 62.5000 (64.9470)  Acc@5: 93.7500 (93.4094)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: 1.1235  Acc@1: 62.5000 (64.9351)  Acc@5: 93.7500 (93.4253)  time: 0.3441  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: 1.0886  Acc@1: 62.5000 (64.8677)  Acc@5: 93.7500 (93.4471)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: 0.7783  Acc@1: 68.7500 (64.9241)  Acc@5: 93.7500 (93.4684)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: 1.0550  Acc@1: 68.7500 (64.9430)  Acc@5: 93.7500 (93.4711)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 1.7691  Acc@1: 62.5000 (64.9856)  Acc@5: 93.7500 (93.4798)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: 1.0180  Acc@1: 68.7500 (65.0392)  Acc@5: 93.7500 (93.4943)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: 1.4156  Acc@1: 68.7500 (65.0448)  Acc@5: 93.7500 (93.5144)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:24  Lr: 0.001875  Loss: 1.3049  Acc@1: 62.5000 (64.9860)  Acc@5: 93.7500 (93.5166)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: 0.5875  Acc@1: 56.2500 (64.9746)  Acc@5: 93.7500 (93.5245)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:17  Lr: 0.001875  Loss: 1.1607  Acc@1: 62.5000 (64.9920)  Acc@5: 93.7500 (93.4979)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: 0.9659  Acc@1: 68.7500 (65.0261)  Acc@5: 93.7500 (93.5116)  time: 0.3460  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 1.2243  Acc@1: 68.7500 (64.9865)  Acc@5: 93.7500 (93.4912)  time: 0.3462  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: 0.9441  Acc@1: 68.7500 (64.9922)  Acc@5: 93.7500 (93.4824)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: 0.6320  Acc@1: 68.7500 (65.0144)  Acc@5: 93.7500 (93.4847)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4241  Acc@1: 68.7500 (65.0416)  Acc@5: 93.7500 (93.4652)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4607  Acc@1: 68.7500 (65.0534)  Acc@5: 93.7500 (93.4684)  time: 0.3360  data: 0.0003  max mem: 2501
Train: Epoch[2/5] Total time: 0:06:34 (0.3452 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.4607  Acc@1: 68.7500 (65.0534)  Acc@5: 93.7500 (93.4684)
Train: Epoch[3/5]  [   0/1142]  eta: 0:13:20  Lr: 0.001875  Loss: 0.9507  Acc@1: 68.7500 (68.7500)  Acc@5: 87.5000 (87.5000)  time: 0.7007  data: 0.3430  max mem: 2501
Train: Epoch[3/5]  [  10/1142]  eta: 0:07:06  Lr: 0.001875  Loss: 0.6925  Acc@1: 68.7500 (68.1818)  Acc@5: 93.7500 (94.3182)  time: 0.3766  data: 0.0315  max mem: 2501
Train: Epoch[3/5]  [  20/1142]  eta: 0:06:45  Lr: 0.001875  Loss: 0.6131  Acc@1: 62.5000 (69.0476)  Acc@5: 100.0000 (94.3452)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [  30/1142]  eta: 0:06:35  Lr: 0.001875  Loss: 0.8212  Acc@1: 62.5000 (67.7419)  Acc@5: 93.7500 (94.3548)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [  40/1142]  eta: 0:06:29  Lr: 0.001875  Loss: 0.9434  Acc@1: 68.7500 (67.3780)  Acc@5: 93.7500 (94.5122)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [  50/1142]  eta: 0:06:24  Lr: 0.001875  Loss: 0.8251  Acc@1: 68.7500 (68.0147)  Acc@5: 93.7500 (94.7304)  time: 0.3463  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [  60/1142]  eta: 0:06:19  Lr: 0.001875  Loss: 1.0304  Acc@1: 68.7500 (66.9057)  Acc@5: 93.7500 (94.5697)  time: 0.3462  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [  70/1142]  eta: 0:06:15  Lr: 0.001875  Loss: 1.1674  Acc@1: 62.5000 (66.8134)  Acc@5: 87.5000 (93.7500)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [  80/1142]  eta: 0:06:10  Lr: 0.001875  Loss: 1.1026  Acc@1: 62.5000 (66.6667)  Acc@5: 87.5000 (93.5185)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:06  Lr: 0.001875  Loss: 0.7679  Acc@1: 62.5000 (66.6209)  Acc@5: 93.7500 (93.3379)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:02  Lr: 0.001875  Loss: 1.5311  Acc@1: 68.7500 (66.4604)  Acc@5: 93.7500 (93.2550)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 110/1142]  eta: 0:05:58  Lr: 0.001875  Loss: 1.5513  Acc@1: 62.5000 (66.2725)  Acc@5: 93.7500 (93.2432)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 120/1142]  eta: 0:05:54  Lr: 0.001875  Loss: 0.8129  Acc@1: 62.5000 (66.4256)  Acc@5: 93.7500 (93.3368)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 130/1142]  eta: 0:05:51  Lr: 0.001875  Loss: 0.8330  Acc@1: 68.7500 (66.6508)  Acc@5: 93.7500 (93.3206)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 140/1142]  eta: 0:05:47  Lr: 0.001875  Loss: 1.0337  Acc@1: 68.7500 (66.7110)  Acc@5: 93.7500 (93.5284)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 150/1142]  eta: 0:05:43  Lr: 0.001875  Loss: 0.7894  Acc@1: 68.7500 (66.3493)  Acc@5: 93.7500 (93.5844)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 160/1142]  eta: 0:05:40  Lr: 0.001875  Loss: 0.6466  Acc@1: 68.7500 (66.4208)  Acc@5: 93.7500 (93.5559)  time: 0.3437  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 170/1142]  eta: 0:05:36  Lr: 0.001875  Loss: 1.1182  Acc@1: 68.7500 (66.8129)  Acc@5: 93.7500 (93.6404)  time: 0.3464  data: 0.0018  max mem: 2501
Train: Epoch[3/5]  [ 180/1142]  eta: 0:05:33  Lr: 0.001875  Loss: 0.9957  Acc@1: 68.7500 (66.6436)  Acc@5: 93.7500 (93.7155)  time: 0.3472  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [ 190/1142]  eta: 0:05:29  Lr: 0.001875  Loss: 1.2847  Acc@1: 62.5000 (66.5249)  Acc@5: 93.7500 (93.8154)  time: 0.3452  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 200/1142]  eta: 0:05:26  Lr: 0.001875  Loss: 0.9563  Acc@1: 62.5000 (66.4179)  Acc@5: 93.7500 (93.9055)  time: 0.3471  data: 0.0018  max mem: 2501
Train: Epoch[3/5]  [ 210/1142]  eta: 0:05:23  Lr: 0.001875  Loss: 1.2261  Acc@1: 62.5000 (66.4988)  Acc@5: 93.7500 (93.8981)  time: 0.3473  data: 0.0025  max mem: 2501
Train: Epoch[3/5]  [ 220/1142]  eta: 0:05:19  Lr: 0.001875  Loss: 0.7240  Acc@1: 68.7500 (66.4593)  Acc@5: 93.7500 (93.7217)  time: 0.3449  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:15  Lr: 0.001875  Loss: 0.9600  Acc@1: 68.7500 (66.4502)  Acc@5: 93.7500 (93.7500)  time: 0.3445  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:12  Lr: 0.001875  Loss: 1.9524  Acc@1: 68.7500 (66.5716)  Acc@5: 93.7500 (93.7241)  time: 0.3450  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:08  Lr: 0.001875  Loss: 0.8371  Acc@1: 62.5000 (66.4592)  Acc@5: 93.7500 (93.7002)  time: 0.3447  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:05  Lr: 0.001875  Loss: 0.8757  Acc@1: 62.5000 (66.4033)  Acc@5: 93.7500 (93.7021)  time: 0.3445  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:01  Lr: 0.001875  Loss: 1.1282  Acc@1: 62.5000 (66.1208)  Acc@5: 93.7500 (93.6808)  time: 0.3453  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [ 280/1142]  eta: 0:04:58  Lr: 0.001875  Loss: 1.2361  Acc@1: 68.7500 (66.2367)  Acc@5: 93.7500 (93.5943)  time: 0.3459  data: 0.0014  max mem: 2501
Train: Epoch[3/5]  [ 290/1142]  eta: 0:04:54  Lr: 0.001875  Loss: 0.9111  Acc@1: 68.7500 (66.1942)  Acc@5: 93.7500 (93.5567)  time: 0.3454  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 300/1142]  eta: 0:04:51  Lr: 0.001875  Loss: 1.0120  Acc@1: 62.5000 (66.0091)  Acc@5: 93.7500 (93.6254)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 310/1142]  eta: 0:04:47  Lr: 0.001875  Loss: 1.9806  Acc@1: 62.5000 (65.9164)  Acc@5: 93.7500 (93.6093)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 320/1142]  eta: 0:04:44  Lr: 0.001875  Loss: 0.5921  Acc@1: 62.5000 (65.9657)  Acc@5: 93.7500 (93.6526)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 330/1142]  eta: 0:04:40  Lr: 0.001875  Loss: 0.7719  Acc@1: 68.7500 (66.0498)  Acc@5: 93.7500 (93.6556)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 340/1142]  eta: 0:04:37  Lr: 0.001875  Loss: 1.0543  Acc@1: 68.7500 (66.1474)  Acc@5: 93.7500 (93.6767)  time: 0.3441  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 350/1142]  eta: 0:04:33  Lr: 0.001875  Loss: 1.4753  Acc@1: 68.7500 (66.2037)  Acc@5: 93.7500 (93.6610)  time: 0.3447  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 360/1142]  eta: 0:04:30  Lr: 0.001875  Loss: 0.9229  Acc@1: 68.7500 (66.2916)  Acc@5: 93.7500 (93.6634)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 370/1142]  eta: 0:04:26  Lr: 0.001875  Loss: 0.7268  Acc@1: 68.7500 (66.5094)  Acc@5: 93.7500 (93.7837)  time: 0.3452  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.001875  Loss: 1.1562  Acc@1: 68.7500 (66.6010)  Acc@5: 100.0000 (93.7992)  time: 0.3466  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 390/1142]  eta: 0:04:20  Lr: 0.001875  Loss: 0.9265  Acc@1: 68.7500 (66.6880)  Acc@5: 93.7500 (93.8139)  time: 0.3474  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 400/1142]  eta: 0:04:16  Lr: 0.001875  Loss: 1.6680  Acc@1: 62.5000 (66.5680)  Acc@5: 93.7500 (93.8435)  time: 0.3468  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 410/1142]  eta: 0:04:13  Lr: 0.001875  Loss: 1.3974  Acc@1: 62.5000 (66.5146)  Acc@5: 93.7500 (93.7956)  time: 0.3458  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.001875  Loss: 1.0874  Acc@1: 62.5000 (66.6122)  Acc@5: 93.7500 (93.8094)  time: 0.3464  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [ 430/1142]  eta: 0:04:06  Lr: 0.001875  Loss: 1.1130  Acc@1: 62.5000 (66.5748)  Acc@5: 93.7500 (93.8370)  time: 0.3472  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.001875  Loss: 1.4927  Acc@1: 62.5000 (66.5533)  Acc@5: 93.7500 (93.8492)  time: 0.3457  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 450/1142]  eta: 0:03:59  Lr: 0.001875  Loss: 0.9242  Acc@1: 68.7500 (66.6990)  Acc@5: 93.7500 (93.8609)  time: 0.3447  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.001875  Loss: 0.9811  Acc@1: 75.0000 (66.7977)  Acc@5: 100.0000 (93.9262)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 470/1142]  eta: 0:03:52  Lr: 0.001875  Loss: 0.4296  Acc@1: 68.7500 (66.8790)  Acc@5: 93.7500 (93.9490)  time: 0.3447  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 480/1142]  eta: 0:03:48  Lr: 0.001875  Loss: 0.8041  Acc@1: 68.7500 (66.9569)  Acc@5: 93.7500 (93.9969)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.001875  Loss: 1.4618  Acc@1: 62.5000 (66.8152)  Acc@5: 93.7500 (93.9919)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 500/1142]  eta: 0:03:41  Lr: 0.001875  Loss: 1.4912  Acc@1: 56.2500 (66.7166)  Acc@5: 93.7500 (93.9122)  time: 0.3448  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.001875  Loss: 0.5858  Acc@1: 62.5000 (66.6952)  Acc@5: 93.7500 (93.8845)  time: 0.3457  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 520/1142]  eta: 0:03:35  Lr: 0.001875  Loss: 1.0882  Acc@1: 62.5000 (66.6627)  Acc@5: 93.7500 (93.8820)  time: 0.3462  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.001875  Loss: 1.3229  Acc@1: 68.7500 (66.7491)  Acc@5: 93.7500 (93.9266)  time: 0.3453  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 540/1142]  eta: 0:03:28  Lr: 0.001875  Loss: 1.5242  Acc@1: 68.7500 (66.7629)  Acc@5: 100.0000 (93.9695)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.001875  Loss: 0.7716  Acc@1: 68.7500 (66.7423)  Acc@5: 100.0000 (94.0109)  time: 0.3464  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.001875  Loss: 1.0865  Acc@1: 68.7500 (66.7335)  Acc@5: 93.7500 (93.9840)  time: 0.3462  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.001875  Loss: 1.2550  Acc@1: 68.7500 (66.6922)  Acc@5: 93.7500 (93.9908)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:14  Lr: 0.001875  Loss: 0.8851  Acc@1: 62.5000 (66.5232)  Acc@5: 93.7500 (93.9974)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.001875  Loss: 0.7368  Acc@1: 62.5000 (66.5398)  Acc@5: 93.7500 (93.9404)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.001875  Loss: 0.9915  Acc@1: 68.7500 (66.4829)  Acc@5: 93.7500 (93.9476)  time: 0.3452  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.001875  Loss: 0.5096  Acc@1: 68.7500 (66.7144)  Acc@5: 93.7500 (93.9341)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.001875  Loss: 1.2109  Acc@1: 68.7500 (66.6667)  Acc@5: 93.7500 (93.9412)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.001875  Loss: 1.3484  Acc@1: 68.7500 (66.7492)  Acc@5: 93.7500 (93.9382)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.001875  Loss: 1.6703  Acc@1: 68.7500 (66.7219)  Acc@5: 93.7500 (93.8865)  time: 0.3468  data: 0.0019  max mem: 2501
Train: Epoch[3/5]  [ 650/1142]  eta: 0:02:50  Lr: 0.001875  Loss: 0.7608  Acc@1: 62.5000 (66.6091)  Acc@5: 93.7500 (93.8652)  time: 0.3459  data: 0.0023  max mem: 2501
Train: Epoch[3/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.001875  Loss: 0.8585  Acc@1: 62.5000 (66.6509)  Acc@5: 93.7500 (93.9013)  time: 0.3442  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.001875  Loss: 1.2675  Acc@1: 68.7500 (66.6822)  Acc@5: 93.7500 (93.8897)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.001875  Loss: 0.5855  Acc@1: 62.5000 (66.6483)  Acc@5: 93.7500 (93.8234)  time: 0.3443  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.001875  Loss: 0.8432  Acc@1: 68.7500 (66.7149)  Acc@5: 93.7500 (93.8404)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.001875  Loss: 1.0255  Acc@1: 68.7500 (66.6459)  Acc@5: 93.7500 (93.8570)  time: 0.3452  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.001875  Loss: 0.6790  Acc@1: 62.5000 (66.6403)  Acc@5: 93.7500 (93.8467)  time: 0.3450  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.001875  Loss: 1.2393  Acc@1: 68.7500 (66.7042)  Acc@5: 93.7500 (93.8454)  time: 0.3442  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.001875  Loss: 0.9873  Acc@1: 68.7500 (66.6724)  Acc@5: 93.7500 (93.7927)  time: 0.3446  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.001875  Loss: 0.8970  Acc@1: 68.7500 (66.6582)  Acc@5: 93.7500 (93.7922)  time: 0.3447  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.001875  Loss: 1.2109  Acc@1: 62.5000 (66.5779)  Acc@5: 93.7500 (93.7833)  time: 0.3451  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.001875  Loss: 1.5967  Acc@1: 62.5000 (66.5243)  Acc@5: 93.7500 (93.7664)  time: 0.3455  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.001875  Loss: 0.6707  Acc@1: 62.5000 (66.5045)  Acc@5: 93.7500 (93.7014)  time: 0.3462  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: 0.9505  Acc@1: 62.5000 (66.4213)  Acc@5: 93.7500 (93.6780)  time: 0.3451  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.001875  Loss: 1.3282  Acc@1: 62.5000 (66.3717)  Acc@5: 93.7500 (93.6473)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: 0.5127  Acc@1: 68.7500 (66.4950)  Acc@5: 93.7500 (93.6720)  time: 0.3440  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.001875  Loss: 0.9062  Acc@1: 68.7500 (66.4997)  Acc@5: 100.0000 (93.7192)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: 0.7411  Acc@1: 68.7500 (66.5499)  Acc@5: 93.7500 (93.6815)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.001875  Loss: 0.9762  Acc@1: 68.7500 (66.5313)  Acc@5: 93.7500 (93.6974)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: 0.6010  Acc@1: 68.7500 (66.4982)  Acc@5: 93.7500 (93.6905)  time: 0.3435  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.001875  Loss: 0.9786  Acc@1: 68.7500 (66.5100)  Acc@5: 93.7500 (93.6912)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: 0.9092  Acc@1: 68.7500 (66.4997)  Acc@5: 93.7500 (93.6629)  time: 0.3435  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.001875  Loss: 0.9153  Acc@1: 68.7500 (66.5614)  Acc@5: 93.7500 (93.6782)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.001875  Loss: 1.0250  Acc@1: 75.0000 (66.6359)  Acc@5: 93.7500 (93.7003)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: 0.6450  Acc@1: 75.0000 (66.6176)  Acc@5: 93.7500 (93.7219)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.001875  Loss: 0.6350  Acc@1: 68.7500 (66.6065)  Acc@5: 93.7500 (93.7361)  time: 0.3455  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: 1.1684  Acc@1: 68.7500 (66.6507)  Acc@5: 93.7500 (93.7569)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.001875  Loss: 1.1358  Acc@1: 62.5000 (66.6192)  Acc@5: 93.7500 (93.7636)  time: 0.3445  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: 1.2187  Acc@1: 68.7500 (66.6756)  Acc@5: 93.7500 (93.7634)  time: 0.3451  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.001875  Loss: 0.7612  Acc@1: 68.7500 (66.6711)  Acc@5: 93.7500 (93.7965)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: 1.2113  Acc@1: 68.7500 (66.6864)  Acc@5: 100.0000 (93.8026)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.001875  Loss: 0.9109  Acc@1: 68.7500 (66.6558)  Acc@5: 93.7500 (93.7890)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: 1.2933  Acc@1: 62.5000 (66.6388)  Acc@5: 93.7500 (93.7951)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.001875  Loss: 1.1427  Acc@1: 68.7500 (66.6858)  Acc@5: 93.7500 (93.8265)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: 0.6110  Acc@1: 68.7500 (66.6688)  Acc@5: 93.7500 (93.8320)  time: 0.3469  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: 0.8362  Acc@1: 62.5000 (66.6896)  Acc@5: 93.7500 (93.8249)  time: 0.3479  data: 0.0026  max mem: 2501
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: 1.5002  Acc@1: 68.7500 (66.7223)  Acc@5: 93.7500 (93.8242)  time: 0.3482  data: 0.0018  max mem: 2501
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: 0.7608  Acc@1: 68.7500 (66.7054)  Acc@5: 93.7500 (93.8357)  time: 0.3465  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: 0.9978  Acc@1: 62.5000 (66.6525)  Acc@5: 93.7500 (93.8349)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.4809  Acc@1: 62.5000 (66.7087)  Acc@5: 93.7500 (93.8641)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: 1.1633  Acc@1: 68.7500 (66.7578)  Acc@5: 100.0000 (93.8689)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: 0.5352  Acc@1: 68.7500 (66.7884)  Acc@5: 93.7500 (93.8737)  time: 0.3441  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:24  Lr: 0.001875  Loss: 1.4035  Acc@1: 68.7500 (66.8009)  Acc@5: 93.7500 (93.8609)  time: 0.3450  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: 1.0107  Acc@1: 68.7500 (66.8363)  Acc@5: 93.7500 (93.8541)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4027  Acc@1: 68.7500 (66.8882)  Acc@5: 93.7500 (93.8588)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: 1.1445  Acc@1: 68.7500 (66.9164)  Acc@5: 93.7500 (93.8522)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 1.2292  Acc@1: 68.7500 (66.9779)  Acc@5: 93.7500 (93.8456)  time: 0.3459  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: 0.7795  Acc@1: 68.7500 (66.9770)  Acc@5: 93.7500 (93.8448)  time: 0.3452  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: 1.4057  Acc@1: 62.5000 (66.9706)  Acc@5: 93.7500 (93.8329)  time: 0.3450  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.9621  Acc@1: 68.7500 (66.9533)  Acc@5: 93.7500 (93.8650)  time: 0.3455  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1023  Acc@1: 68.7500 (66.9696)  Acc@5: 100.0000 (93.8681)  time: 0.3381  data: 0.0006  max mem: 2501
Train: Epoch[3/5] Total time: 0:06:34 (0.3454 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.1023  Acc@1: 68.7500 (66.9696)  Acc@5: 100.0000 (93.8681)
Train: Epoch[4/5]  [   0/1142]  eta: 0:13:05  Lr: 0.001875  Loss: 0.6173  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6875  data: 0.3426  max mem: 2501
Train: Epoch[4/5]  [  10/1142]  eta: 0:07:05  Lr: 0.001875  Loss: 1.1193  Acc@1: 68.7500 (67.0455)  Acc@5: 93.7500 (92.6136)  time: 0.3759  data: 0.0315  max mem: 2501
Train: Epoch[4/5]  [  20/1142]  eta: 0:06:46  Lr: 0.001875  Loss: 0.8910  Acc@1: 68.7500 (70.5357)  Acc@5: 93.7500 (94.0476)  time: 0.3457  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [  30/1142]  eta: 0:06:36  Lr: 0.001875  Loss: 0.5288  Acc@1: 68.7500 (68.5484)  Acc@5: 93.7500 (94.1532)  time: 0.3460  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [  40/1142]  eta: 0:06:30  Lr: 0.001875  Loss: 1.0818  Acc@1: 68.7500 (68.2927)  Acc@5: 93.7500 (93.5976)  time: 0.3455  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [  50/1142]  eta: 0:06:24  Lr: 0.001875  Loss: 0.7812  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.3824)  time: 0.3454  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [  60/1142]  eta: 0:06:19  Lr: 0.001875  Loss: 0.6807  Acc@1: 62.5000 (67.8279)  Acc@5: 93.7500 (93.4426)  time: 0.3454  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [  70/1142]  eta: 0:06:15  Lr: 0.001875  Loss: 1.2035  Acc@1: 68.7500 (68.2218)  Acc@5: 93.7500 (93.7500)  time: 0.3462  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [  80/1142]  eta: 0:06:11  Lr: 0.001875  Loss: 1.1478  Acc@1: 68.7500 (68.2870)  Acc@5: 93.7500 (93.9815)  time: 0.3457  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:07  Lr: 0.001875  Loss: 0.7170  Acc@1: 68.7500 (68.2005)  Acc@5: 93.7500 (93.9560)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:03  Lr: 0.001875  Loss: 0.8546  Acc@1: 62.5000 (67.6980)  Acc@5: 93.7500 (93.6262)  time: 0.3454  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 110/1142]  eta: 0:05:59  Lr: 0.001875  Loss: 0.6590  Acc@1: 75.0000 (68.4685)  Acc@5: 93.7500 (93.9189)  time: 0.3445  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 120/1142]  eta: 0:05:55  Lr: 0.001875  Loss: 0.4095  Acc@1: 75.0000 (68.8017)  Acc@5: 100.0000 (94.1632)  time: 0.3451  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 130/1142]  eta: 0:05:52  Lr: 0.001875  Loss: 1.0571  Acc@1: 62.5000 (67.9866)  Acc@5: 93.7500 (94.0363)  time: 0.3447  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 140/1142]  eta: 0:05:48  Lr: 0.001875  Loss: 0.5498  Acc@1: 62.5000 (68.5284)  Acc@5: 93.7500 (94.1489)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 150/1142]  eta: 0:05:44  Lr: 0.001875  Loss: 1.1951  Acc@1: 75.0000 (68.4603)  Acc@5: 93.7500 (93.9983)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 160/1142]  eta: 0:05:41  Lr: 0.001875  Loss: 0.2484  Acc@1: 68.7500 (68.5947)  Acc@5: 93.7500 (94.0217)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 170/1142]  eta: 0:05:37  Lr: 0.001875  Loss: 0.8989  Acc@1: 68.7500 (68.8231)  Acc@5: 93.7500 (94.2251)  time: 0.3457  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 180/1142]  eta: 0:05:33  Lr: 0.001875  Loss: 1.0417  Acc@1: 68.7500 (68.9917)  Acc@5: 93.7500 (94.0953)  time: 0.3455  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 190/1142]  eta: 0:05:30  Lr: 0.001875  Loss: 0.9744  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.0772)  time: 0.3449  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 200/1142]  eta: 0:05:26  Lr: 0.001875  Loss: 1.0463  Acc@1: 62.5000 (68.5012)  Acc@5: 93.7500 (94.1853)  time: 0.3444  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 210/1142]  eta: 0:05:23  Lr: 0.001875  Loss: 0.7479  Acc@1: 62.5000 (68.3057)  Acc@5: 93.7500 (94.1943)  time: 0.3448  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 220/1142]  eta: 0:05:19  Lr: 0.001875  Loss: 0.4887  Acc@1: 68.7500 (68.4389)  Acc@5: 93.7500 (94.2308)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 230/1142]  eta: 0:05:16  Lr: 0.001875  Loss: 1.2582  Acc@1: 68.7500 (68.2630)  Acc@5: 93.7500 (94.1829)  time: 0.3444  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:12  Lr: 0.001875  Loss: 0.4061  Acc@1: 68.7500 (68.3091)  Acc@5: 93.7500 (94.2168)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:08  Lr: 0.001875  Loss: 1.1116  Acc@1: 68.7500 (68.3018)  Acc@5: 93.7500 (94.1982)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:05  Lr: 0.001875  Loss: 0.7447  Acc@1: 68.7500 (68.2471)  Acc@5: 93.7500 (94.2768)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:02  Lr: 0.001875  Loss: 0.5989  Acc@1: 68.7500 (68.2196)  Acc@5: 93.7500 (94.2343)  time: 0.3463  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 280/1142]  eta: 0:04:58  Lr: 0.001875  Loss: 0.6700  Acc@1: 68.7500 (68.3496)  Acc@5: 93.7500 (94.1726)  time: 0.3462  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 290/1142]  eta: 0:04:55  Lr: 0.001875  Loss: 1.0282  Acc@1: 68.7500 (68.3849)  Acc@5: 93.7500 (94.2440)  time: 0.3459  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 300/1142]  eta: 0:04:51  Lr: 0.001875  Loss: 1.2840  Acc@1: 68.7500 (68.2932)  Acc@5: 93.7500 (94.1653)  time: 0.3465  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 310/1142]  eta: 0:04:48  Lr: 0.001875  Loss: 1.1591  Acc@1: 62.5000 (67.9662)  Acc@5: 93.7500 (94.0916)  time: 0.3467  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 320/1142]  eta: 0:04:44  Lr: 0.001875  Loss: 1.2632  Acc@1: 62.5000 (67.8933)  Acc@5: 93.7500 (94.0615)  time: 0.3458  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 330/1142]  eta: 0:04:41  Lr: 0.001875  Loss: 0.8479  Acc@1: 68.7500 (67.9569)  Acc@5: 93.7500 (93.9955)  time: 0.3452  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 340/1142]  eta: 0:04:37  Lr: 0.001875  Loss: 0.4335  Acc@1: 68.7500 (68.1085)  Acc@5: 93.7500 (93.9516)  time: 0.3458  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 350/1142]  eta: 0:04:34  Lr: 0.001875  Loss: 1.2528  Acc@1: 75.0000 (68.3405)  Acc@5: 93.7500 (94.0527)  time: 0.3475  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 360/1142]  eta: 0:04:30  Lr: 0.001875  Loss: 1.3423  Acc@1: 75.0000 (68.3864)  Acc@5: 100.0000 (94.0963)  time: 0.3486  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 370/1142]  eta: 0:04:27  Lr: 0.001875  Loss: 0.8235  Acc@1: 62.5000 (68.2615)  Acc@5: 93.7500 (94.1206)  time: 0.3479  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.001875  Loss: 0.9278  Acc@1: 62.5000 (68.1923)  Acc@5: 93.7500 (94.1109)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:20  Lr: 0.001875  Loss: 1.3678  Acc@1: 62.5000 (68.1106)  Acc@5: 93.7500 (94.0058)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:16  Lr: 0.001875  Loss: 1.2916  Acc@1: 62.5000 (68.0019)  Acc@5: 93.7500 (93.9682)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:13  Lr: 0.001875  Loss: 1.0157  Acc@1: 68.7500 (68.1113)  Acc@5: 93.7500 (93.9629)  time: 0.3440  data: 0.0002  max mem: 2501
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.001875  Loss: 0.6626  Acc@1: 68.7500 (68.0226)  Acc@5: 93.7500 (93.9875)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:06  Lr: 0.001875  Loss: 1.1745  Acc@1: 68.7500 (67.9814)  Acc@5: 93.7500 (93.9385)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.001875  Loss: 1.0111  Acc@1: 68.7500 (68.1406)  Acc@5: 93.7500 (93.9342)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 450/1142]  eta: 0:03:59  Lr: 0.001875  Loss: 0.9973  Acc@1: 62.5000 (68.0017)  Acc@5: 93.7500 (93.9302)  time: 0.3437  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.001875  Loss: 0.8059  Acc@1: 62.5000 (68.0721)  Acc@5: 93.7500 (93.9127)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 470/1142]  eta: 0:03:52  Lr: 0.001875  Loss: 1.2533  Acc@1: 68.7500 (67.9936)  Acc@5: 93.7500 (93.8960)  time: 0.3456  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 480/1142]  eta: 0:03:49  Lr: 0.001875  Loss: 0.9261  Acc@1: 68.7500 (67.9964)  Acc@5: 93.7500 (93.9319)  time: 0.3448  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.001875  Loss: 0.6796  Acc@1: 68.7500 (67.8462)  Acc@5: 93.7500 (93.9282)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 500/1142]  eta: 0:03:42  Lr: 0.001875  Loss: 0.6399  Acc@1: 68.7500 (67.9017)  Acc@5: 93.7500 (93.9621)  time: 0.3452  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.001875  Loss: 0.8103  Acc@1: 68.7500 (68.0039)  Acc@5: 93.7500 (93.9824)  time: 0.3453  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 520/1142]  eta: 0:03:35  Lr: 0.001875  Loss: 1.9881  Acc@1: 68.7500 (68.0302)  Acc@5: 93.7500 (93.9899)  time: 0.3450  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.001875  Loss: 0.8753  Acc@1: 68.7500 (67.9967)  Acc@5: 93.7500 (94.0443)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:28  Lr: 0.001875  Loss: 1.0971  Acc@1: 68.7500 (68.0799)  Acc@5: 93.7500 (94.0619)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.001875  Loss: 1.1702  Acc@1: 68.7500 (68.0808)  Acc@5: 93.7500 (94.0336)  time: 0.3433  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.001875  Loss: 0.9475  Acc@1: 68.7500 (68.0593)  Acc@5: 87.5000 (93.9283)  time: 0.3442  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.001875  Loss: 1.0779  Acc@1: 68.7500 (68.1151)  Acc@5: 93.7500 (93.9361)  time: 0.3458  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:14  Lr: 0.001875  Loss: 1.4094  Acc@1: 68.7500 (68.0615)  Acc@5: 93.7500 (93.9651)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.001875  Loss: 0.8915  Acc@1: 68.7500 (68.1155)  Acc@5: 93.7500 (93.9827)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.001875  Loss: 1.2975  Acc@1: 68.7500 (68.0844)  Acc@5: 93.7500 (93.9164)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.001875  Loss: 1.3073  Acc@1: 62.5000 (68.0033)  Acc@5: 93.7500 (93.8830)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.001875  Loss: 1.1826  Acc@1: 62.5000 (67.9348)  Acc@5: 93.7500 (93.9513)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.001875  Loss: 1.2743  Acc@1: 62.5000 (67.9378)  Acc@5: 93.7500 (93.9184)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.001875  Loss: 0.9352  Acc@1: 62.5000 (67.9310)  Acc@5: 93.7500 (93.8963)  time: 0.3448  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 650/1142]  eta: 0:02:50  Lr: 0.001875  Loss: 1.1343  Acc@1: 62.5000 (67.9531)  Acc@5: 93.7500 (93.9228)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.001875  Loss: 1.1753  Acc@1: 62.5000 (67.7666)  Acc@5: 93.7500 (93.8918)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.001875  Loss: 0.9514  Acc@1: 56.2500 (67.7440)  Acc@5: 93.7500 (93.9363)  time: 0.3434  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.001875  Loss: 0.8370  Acc@1: 68.7500 (67.7955)  Acc@5: 100.0000 (93.9794)  time: 0.3452  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.001875  Loss: 1.0008  Acc@1: 68.7500 (67.8093)  Acc@5: 93.7500 (93.9399)  time: 0.3459  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.001875  Loss: 0.8844  Acc@1: 75.0000 (67.9387)  Acc@5: 93.7500 (93.9818)  time: 0.3455  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.001875  Loss: 0.7562  Acc@1: 75.0000 (67.9852)  Acc@5: 93.7500 (93.9873)  time: 0.3455  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.001875  Loss: 1.2930  Acc@1: 68.7500 (67.9785)  Acc@5: 93.7500 (94.0014)  time: 0.3452  data: 0.0018  max mem: 2501
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.001875  Loss: 0.7362  Acc@1: 68.7500 (67.9549)  Acc@5: 93.7500 (93.9894)  time: 0.3445  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.001875  Loss: 0.4288  Acc@1: 68.7500 (67.9740)  Acc@5: 93.7500 (93.9946)  time: 0.3438  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.001875  Loss: 1.3729  Acc@1: 68.7500 (67.9677)  Acc@5: 93.7500 (93.9997)  time: 0.3437  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:11  Lr: 0.001875  Loss: 0.9136  Acc@1: 62.5000 (67.9041)  Acc@5: 93.7500 (93.9800)  time: 0.3438  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.001875  Loss: 0.7403  Acc@1: 68.7500 (67.9232)  Acc@5: 93.7500 (93.9851)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: 0.6319  Acc@1: 68.7500 (67.9017)  Acc@5: 93.7500 (93.9741)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.001875  Loss: 1.1396  Acc@1: 62.5000 (67.8571)  Acc@5: 93.7500 (93.9554)  time: 0.3444  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: 1.1171  Acc@1: 62.5000 (67.7591)  Acc@5: 93.7500 (93.9451)  time: 0.3438  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.001875  Loss: 0.7086  Acc@1: 62.5000 (67.7404)  Acc@5: 93.7500 (93.9504)  time: 0.3445  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: 1.0307  Acc@1: 62.5000 (67.7299)  Acc@5: 93.7500 (93.9175)  time: 0.3462  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.001875  Loss: 0.9355  Acc@1: 68.7500 (67.7647)  Acc@5: 93.7500 (93.9531)  time: 0.3460  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: 0.8881  Acc@1: 68.7500 (67.7690)  Acc@5: 93.7500 (93.9581)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.001875  Loss: 0.5948  Acc@1: 75.0000 (67.8026)  Acc@5: 93.7500 (93.9483)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: 0.8753  Acc@1: 62.5000 (67.7991)  Acc@5: 93.7500 (93.9533)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.001875  Loss: 0.5753  Acc@1: 68.7500 (67.8746)  Acc@5: 93.7500 (93.9796)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.001875  Loss: 1.2635  Acc@1: 68.7500 (67.8136)  Acc@5: 93.7500 (93.9557)  time: 0.3454  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: 0.6202  Acc@1: 68.7500 (67.8521)  Acc@5: 93.7500 (93.9745)  time: 0.3456  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.001875  Loss: 1.2545  Acc@1: 68.7500 (67.8274)  Acc@5: 93.7500 (93.9789)  time: 0.3446  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: 1.2302  Acc@1: 62.5000 (67.8032)  Acc@5: 93.7500 (93.9833)  time: 0.3437  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.001875  Loss: 0.6732  Acc@1: 62.5000 (67.7321)  Acc@5: 93.7500 (93.9468)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: 0.8798  Acc@1: 62.5000 (67.7296)  Acc@5: 93.7500 (93.9715)  time: 0.3464  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.001875  Loss: 1.3458  Acc@1: 68.7500 (67.7537)  Acc@5: 93.7500 (93.9559)  time: 0.3449  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: 0.8723  Acc@1: 68.7500 (67.8102)  Acc@5: 93.7500 (93.9537)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.001875  Loss: 0.7842  Acc@1: 68.7500 (67.8005)  Acc@5: 93.7500 (93.9711)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: 0.7943  Acc@1: 68.7500 (67.8617)  Acc@5: 93.7500 (93.9946)  time: 0.3431  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.001875  Loss: 0.7818  Acc@1: 75.0000 (67.9345)  Acc@5: 93.7500 (94.0112)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: 1.0662  Acc@1: 75.0000 (67.9427)  Acc@5: 93.7500 (94.0338)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: 0.6804  Acc@1: 75.0000 (68.0132)  Acc@5: 93.7500 (94.0497)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: 0.7547  Acc@1: 68.7500 (67.9958)  Acc@5: 93.7500 (94.0529)  time: 0.3436  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: 0.9737  Acc@1: 68.7500 (67.9848)  Acc@5: 93.7500 (94.0377)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: 0.9772  Acc@1: 68.7500 (67.9741)  Acc@5: 93.7500 (94.0410)  time: 0.3436  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.6912  Acc@1: 68.7500 (68.0055)  Acc@5: 93.7500 (94.0562)  time: 0.3440  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: 1.4154  Acc@1: 68.7500 (68.0423)  Acc@5: 93.7500 (94.0652)  time: 0.3444  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: 1.1251  Acc@1: 68.7500 (68.0372)  Acc@5: 93.7500 (94.0151)  time: 0.3440  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:24  Lr: 0.001875  Loss: 1.1816  Acc@1: 62.5000 (67.9739)  Acc@5: 93.7500 (94.0243)  time: 0.3456  data: 0.0002  max mem: 2501
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: 0.5049  Acc@1: 62.5000 (68.0273)  Acc@5: 93.7500 (94.0449)  time: 0.3463  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4235  Acc@1: 75.0000 (68.0454)  Acc@5: 93.7500 (94.0250)  time: 0.3458  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: 0.8820  Acc@1: 68.7500 (68.0120)  Acc@5: 93.7500 (94.0282)  time: 0.3461  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 1.6034  Acc@1: 62.5000 (68.0074)  Acc@5: 93.7500 (93.9975)  time: 0.3449  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: 1.2992  Acc@1: 68.7500 (68.0085)  Acc@5: 93.7500 (94.0343)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: 0.6445  Acc@1: 68.7500 (68.0150)  Acc@5: 93.7500 (94.0153)  time: 0.3459  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7813  Acc@1: 68.7500 (68.0379)  Acc@5: 93.7500 (94.0348)  time: 0.3460  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7564  Acc@1: 68.7500 (68.0372)  Acc@5: 93.7500 (94.0323)  time: 0.3384  data: 0.0012  max mem: 2501
Train: Epoch[4/5] Total time: 0:06:34 (0.3453 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.7564  Acc@1: 68.7500 (68.0372)  Acc@5: 93.7500 (94.0323)
Train: Epoch[5/5]  [   0/1142]  eta: 0:12:55  Lr: 0.001875  Loss: 0.9856  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6795  data: 0.3364  max mem: 2501
Train: Epoch[5/5]  [  10/1142]  eta: 0:07:04  Lr: 0.001875  Loss: 0.8309  Acc@1: 68.7500 (68.1818)  Acc@5: 93.7500 (93.1818)  time: 0.3753  data: 0.0308  max mem: 2501
Train: Epoch[5/5]  [  20/1142]  eta: 0:06:44  Lr: 0.001875  Loss: 0.9342  Acc@1: 68.7500 (69.9405)  Acc@5: 93.7500 (93.4524)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [  30/1142]  eta: 0:06:34  Lr: 0.001875  Loss: 1.3936  Acc@1: 68.7500 (69.3548)  Acc@5: 93.7500 (93.7500)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [  40/1142]  eta: 0:06:28  Lr: 0.001875  Loss: 1.0217  Acc@1: 68.7500 (67.9878)  Acc@5: 93.7500 (94.0549)  time: 0.3450  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [  50/1142]  eta: 0:06:23  Lr: 0.001875  Loss: 0.6713  Acc@1: 68.7500 (69.1176)  Acc@5: 100.0000 (94.7304)  time: 0.3455  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [  60/1142]  eta: 0:06:18  Lr: 0.001875  Loss: 0.4960  Acc@1: 68.7500 (68.8525)  Acc@5: 100.0000 (95.0820)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [  70/1142]  eta: 0:06:15  Lr: 0.001875  Loss: 0.4663  Acc@1: 68.7500 (69.3662)  Acc@5: 100.0000 (95.2465)  time: 0.3460  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [  80/1142]  eta: 0:06:11  Lr: 0.001875  Loss: 0.9120  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (95.1389)  time: 0.3469  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:06  Lr: 0.001875  Loss: 0.4928  Acc@1: 68.7500 (69.2995)  Acc@5: 93.7500 (95.1236)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:03  Lr: 0.001875  Loss: 0.9935  Acc@1: 68.7500 (69.0594)  Acc@5: 93.7500 (95.0495)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 110/1142]  eta: 0:05:59  Lr: 0.001875  Loss: 0.8053  Acc@1: 62.5000 (68.6374)  Acc@5: 93.7500 (95.1014)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 120/1142]  eta: 0:05:55  Lr: 0.001875  Loss: 1.0611  Acc@1: 62.5000 (67.9236)  Acc@5: 93.7500 (95.0930)  time: 0.3455  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 130/1142]  eta: 0:05:51  Lr: 0.001875  Loss: 1.0806  Acc@1: 62.5000 (67.7481)  Acc@5: 93.7500 (95.0859)  time: 0.3462  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 140/1142]  eta: 0:05:48  Lr: 0.001875  Loss: 0.9973  Acc@1: 68.7500 (67.8635)  Acc@5: 93.7500 (95.0355)  time: 0.3460  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [ 150/1142]  eta: 0:05:44  Lr: 0.001875  Loss: 0.8140  Acc@1: 68.7500 (67.7566)  Acc@5: 93.7500 (94.9503)  time: 0.3451  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 160/1142]  eta: 0:05:41  Lr: 0.001875  Loss: 0.9596  Acc@1: 62.5000 (67.2360)  Acc@5: 93.7500 (94.9146)  time: 0.3449  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [ 170/1142]  eta: 0:05:37  Lr: 0.001875  Loss: 0.5866  Acc@1: 56.2500 (66.9956)  Acc@5: 93.7500 (94.8465)  time: 0.3450  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [ 180/1142]  eta: 0:05:33  Lr: 0.001875  Loss: 0.7217  Acc@1: 68.7500 (67.0235)  Acc@5: 93.7500 (94.7169)  time: 0.3447  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 190/1142]  eta: 0:05:30  Lr: 0.001875  Loss: 0.4463  Acc@1: 68.7500 (67.0484)  Acc@5: 93.7500 (94.8298)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 200/1142]  eta: 0:05:26  Lr: 0.001875  Loss: 1.2266  Acc@1: 62.5000 (66.9776)  Acc@5: 93.7500 (94.6828)  time: 0.3441  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 210/1142]  eta: 0:05:23  Lr: 0.001875  Loss: 0.5069  Acc@1: 68.7500 (67.5355)  Acc@5: 93.7500 (94.7275)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 220/1142]  eta: 0:05:19  Lr: 0.001875  Loss: 0.9373  Acc@1: 68.7500 (67.5905)  Acc@5: 93.7500 (94.7681)  time: 0.3442  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:15  Lr: 0.001875  Loss: 0.9437  Acc@1: 68.7500 (67.7760)  Acc@5: 93.7500 (94.7511)  time: 0.3440  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:12  Lr: 0.001875  Loss: 0.8597  Acc@1: 68.7500 (67.9201)  Acc@5: 93.7500 (94.7873)  time: 0.3456  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:08  Lr: 0.001875  Loss: 1.0561  Acc@1: 68.7500 (67.7291)  Acc@5: 93.7500 (94.6962)  time: 0.3457  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:05  Lr: 0.001875  Loss: 1.2061  Acc@1: 62.5000 (67.7203)  Acc@5: 93.7500 (94.7079)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:01  Lr: 0.001875  Loss: 0.6884  Acc@1: 62.5000 (67.8506)  Acc@5: 93.7500 (94.7878)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 280/1142]  eta: 0:04:58  Lr: 0.001875  Loss: 0.8402  Acc@1: 75.0000 (68.1272)  Acc@5: 100.0000 (94.8621)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 290/1142]  eta: 0:04:54  Lr: 0.001875  Loss: 0.9693  Acc@1: 68.7500 (68.0627)  Acc@5: 93.7500 (94.7809)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 300/1142]  eta: 0:04:51  Lr: 0.001875  Loss: 0.8261  Acc@1: 68.7500 (68.2101)  Acc@5: 93.7500 (94.7467)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 310/1142]  eta: 0:04:47  Lr: 0.001875  Loss: 0.7445  Acc@1: 68.7500 (68.1471)  Acc@5: 93.7500 (94.7950)  time: 0.3445  data: 0.0002  max mem: 2501
Train: Epoch[5/5]  [ 320/1142]  eta: 0:04:44  Lr: 0.001875  Loss: 0.9576  Acc@1: 68.7500 (68.1464)  Acc@5: 93.7500 (94.7819)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 330/1142]  eta: 0:04:40  Lr: 0.001875  Loss: 1.0341  Acc@1: 68.7500 (68.0514)  Acc@5: 93.7500 (94.7885)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 340/1142]  eta: 0:04:37  Lr: 0.001875  Loss: 0.9560  Acc@1: 68.7500 (68.1268)  Acc@5: 100.0000 (94.8314)  time: 0.3447  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 350/1142]  eta: 0:04:33  Lr: 0.001875  Loss: 1.1077  Acc@1: 68.7500 (68.0912)  Acc@5: 93.7500 (94.7472)  time: 0.3453  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 360/1142]  eta: 0:04:30  Lr: 0.001875  Loss: 1.3032  Acc@1: 68.7500 (68.1960)  Acc@5: 93.7500 (94.7368)  time: 0.3447  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 370/1142]  eta: 0:04:26  Lr: 0.001875  Loss: 0.7080  Acc@1: 68.7500 (68.2446)  Acc@5: 93.7500 (94.7608)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.001875  Loss: 0.7414  Acc@1: 68.7500 (68.2579)  Acc@5: 93.7500 (94.7014)  time: 0.3452  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:20  Lr: 0.001875  Loss: 0.5258  Acc@1: 75.0000 (68.3344)  Acc@5: 93.7500 (94.7410)  time: 0.3451  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:16  Lr: 0.001875  Loss: 0.7961  Acc@1: 68.7500 (68.4383)  Acc@5: 100.0000 (94.7163)  time: 0.3449  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:13  Lr: 0.001875  Loss: 1.0638  Acc@1: 68.7500 (68.3394)  Acc@5: 93.7500 (94.7232)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.001875  Loss: 0.7148  Acc@1: 62.5000 (68.3343)  Acc@5: 100.0000 (94.7892)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:06  Lr: 0.001875  Loss: 0.8281  Acc@1: 68.7500 (68.4310)  Acc@5: 100.0000 (94.8376)  time: 0.3455  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.001875  Loss: 0.9211  Acc@1: 75.0000 (68.4949)  Acc@5: 100.0000 (94.8129)  time: 0.3453  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 450/1142]  eta: 0:03:59  Lr: 0.001875  Loss: 1.0421  Acc@1: 75.0000 (68.4728)  Acc@5: 93.7500 (94.8032)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.001875  Loss: 0.6453  Acc@1: 75.0000 (68.4789)  Acc@5: 93.7500 (94.8210)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 470/1142]  eta: 0:03:52  Lr: 0.001875  Loss: 1.1439  Acc@1: 68.7500 (68.4183)  Acc@5: 93.7500 (94.7850)  time: 0.3457  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 480/1142]  eta: 0:03:48  Lr: 0.001875  Loss: 1.1345  Acc@1: 68.7500 (68.5031)  Acc@5: 93.7500 (94.7505)  time: 0.3452  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.001875  Loss: 0.6950  Acc@1: 75.0000 (68.6227)  Acc@5: 93.7500 (94.7556)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 500/1142]  eta: 0:03:41  Lr: 0.001875  Loss: 0.9867  Acc@1: 68.7500 (68.4631)  Acc@5: 93.7500 (94.6856)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.001875  Loss: 0.7274  Acc@1: 68.7500 (68.4932)  Acc@5: 93.7500 (94.6673)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 520/1142]  eta: 0:03:35  Lr: 0.001875  Loss: 0.4404  Acc@1: 75.0000 (68.5341)  Acc@5: 93.7500 (94.6737)  time: 0.3455  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.001875  Loss: 1.0536  Acc@1: 75.0000 (68.6323)  Acc@5: 93.7500 (94.6916)  time: 0.3467  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:28  Lr: 0.001875  Loss: 0.5420  Acc@1: 68.7500 (68.6576)  Acc@5: 100.0000 (94.7089)  time: 0.3472  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.001875  Loss: 0.7666  Acc@1: 62.5000 (68.5685)  Acc@5: 93.7500 (94.6801)  time: 0.3457  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.001875  Loss: 0.8486  Acc@1: 68.7500 (68.6275)  Acc@5: 93.7500 (94.6970)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.001875  Loss: 0.8514  Acc@1: 68.7500 (68.6296)  Acc@5: 100.0000 (94.7023)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:14  Lr: 0.001875  Loss: 0.9175  Acc@1: 68.7500 (68.6102)  Acc@5: 93.7500 (94.6751)  time: 0.3443  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.001875  Loss: 1.0425  Acc@1: 68.7500 (68.5702)  Acc@5: 93.7500 (94.7124)  time: 0.3445  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.001875  Loss: 1.0716  Acc@1: 68.7500 (68.5420)  Acc@5: 93.7500 (94.6755)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.001875  Loss: 1.4418  Acc@1: 68.7500 (68.4943)  Acc@5: 93.7500 (94.6399)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.001875  Loss: 1.0380  Acc@1: 68.7500 (68.5386)  Acc@5: 93.7500 (94.6357)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.001875  Loss: 1.3575  Acc@1: 75.0000 (68.6311)  Acc@5: 93.7500 (94.6613)  time: 0.3470  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.001875  Loss: 0.5760  Acc@1: 75.0000 (68.6817)  Acc@5: 93.7500 (94.5983)  time: 0.3464  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 650/1142]  eta: 0:02:50  Lr: 0.001875  Loss: 0.3617  Acc@1: 75.0000 (68.7500)  Acc@5: 93.7500 (94.5853)  time: 0.3453  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.001875  Loss: 0.9860  Acc@1: 75.0000 (68.8162)  Acc@5: 93.7500 (94.5537)  time: 0.3456  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.001875  Loss: 1.1045  Acc@1: 75.0000 (68.8525)  Acc@5: 93.7500 (94.5790)  time: 0.3460  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.001875  Loss: 0.8170  Acc@1: 68.7500 (68.8785)  Acc@5: 93.7500 (94.5668)  time: 0.3451  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.001875  Loss: 0.6214  Acc@1: 68.7500 (68.8947)  Acc@5: 93.7500 (94.5821)  time: 0.3448  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.001875  Loss: 0.9168  Acc@1: 68.7500 (68.9372)  Acc@5: 100.0000 (94.6416)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.001875  Loss: 0.7900  Acc@1: 68.7500 (68.9522)  Acc@5: 93.7500 (94.6027)  time: 0.3445  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.001875  Loss: 0.7065  Acc@1: 68.7500 (68.9407)  Acc@5: 93.7500 (94.6082)  time: 0.3448  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.001875  Loss: 1.3473  Acc@1: 68.7500 (68.8355)  Acc@5: 93.7500 (94.5964)  time: 0.3454  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.001875  Loss: 0.8498  Acc@1: 62.5000 (68.7669)  Acc@5: 93.7500 (94.5597)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.001875  Loss: 1.4263  Acc@1: 68.7500 (68.8249)  Acc@5: 93.7500 (94.5406)  time: 0.3463  data: 0.0016  max mem: 2501
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.001875  Loss: 0.7981  Acc@1: 75.0000 (68.8568)  Acc@5: 93.7500 (94.5466)  time: 0.3454  data: 0.0016  max mem: 2501
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.001875  Loss: 0.6194  Acc@1: 75.0000 (68.9040)  Acc@5: 93.7500 (94.5850)  time: 0.3452  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: 0.6652  Acc@1: 68.7500 (68.9421)  Acc@5: 100.0000 (94.6063)  time: 0.3453  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.001875  Loss: 0.7770  Acc@1: 68.7500 (68.9791)  Acc@5: 93.7500 (94.6192)  time: 0.3439  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: 0.9005  Acc@1: 75.0000 (68.9841)  Acc@5: 93.7500 (94.6317)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.001875  Loss: 0.8400  Acc@1: 75.0000 (69.0274)  Acc@5: 93.7500 (94.6440)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: 1.0875  Acc@1: 68.7500 (68.9860)  Acc@5: 93.7500 (94.6559)  time: 0.3449  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.001875  Loss: 1.4247  Acc@1: 62.5000 (68.9681)  Acc@5: 93.7500 (94.6300)  time: 0.3442  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: 0.8558  Acc@1: 68.7500 (69.0027)  Acc@5: 93.7500 (94.6344)  time: 0.3449  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.001875  Loss: 0.8792  Acc@1: 75.0000 (69.0731)  Acc@5: 93.7500 (94.6387)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: 0.8191  Acc@1: 68.7500 (69.0331)  Acc@5: 100.0000 (94.6646)  time: 0.3451  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.001875  Loss: 0.6867  Acc@1: 68.7500 (69.0155)  Acc@5: 100.0000 (94.6900)  time: 0.3444  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.001875  Loss: 0.5086  Acc@1: 68.7500 (69.0409)  Acc@5: 93.7500 (94.6935)  time: 0.3438  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: 1.0271  Acc@1: 68.7500 (69.0586)  Acc@5: 93.7500 (94.6900)  time: 0.3446  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.001875  Loss: 1.4183  Acc@1: 68.7500 (69.0413)  Acc@5: 93.7500 (94.7003)  time: 0.3454  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: 1.0461  Acc@1: 68.7500 (69.0587)  Acc@5: 93.7500 (94.6693)  time: 0.3450  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.001875  Loss: 0.8819  Acc@1: 75.0000 (69.0825)  Acc@5: 93.7500 (94.6865)  time: 0.3443  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: 0.6146  Acc@1: 75.0000 (69.0521)  Acc@5: 93.7500 (94.6831)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.001875  Loss: 1.0014  Acc@1: 68.7500 (69.0489)  Acc@5: 93.7500 (94.7064)  time: 0.3448  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: 0.5278  Acc@1: 68.7500 (69.0786)  Acc@5: 100.0000 (94.7292)  time: 0.3457  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.001875  Loss: 1.3644  Acc@1: 68.7500 (69.0687)  Acc@5: 93.7500 (94.7190)  time: 0.3451  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: 1.2873  Acc@1: 68.7500 (69.0783)  Acc@5: 93.7500 (94.7219)  time: 0.3448  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.001875  Loss: 0.7073  Acc@1: 68.7500 (69.0877)  Acc@5: 93.7500 (94.7120)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: 1.4328  Acc@1: 68.7500 (69.0149)  Acc@5: 93.7500 (94.6897)  time: 0.3449  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: 1.0455  Acc@1: 62.5000 (69.0185)  Acc@5: 93.7500 (94.6928)  time: 0.3459  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: 1.2810  Acc@1: 62.5000 (69.0035)  Acc@5: 93.7500 (94.6526)  time: 0.3476  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: 0.8721  Acc@1: 68.7500 (69.0255)  Acc@5: 93.7500 (94.6621)  time: 0.3476  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: 1.2015  Acc@1: 68.7500 (69.0349)  Acc@5: 93.7500 (94.6351)  time: 0.3465  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 1.2754  Acc@1: 68.7500 (69.0802)  Acc@5: 93.7500 (94.6266)  time: 0.3453  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: 0.8407  Acc@1: 75.0000 (69.0771)  Acc@5: 93.7500 (94.5766)  time: 0.3442  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: 0.8794  Acc@1: 75.0000 (69.0917)  Acc@5: 93.7500 (94.5747)  time: 0.3444  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:24  Lr: 0.001875  Loss: 1.1078  Acc@1: 75.0000 (69.1118)  Acc@5: 93.7500 (94.5787)  time: 0.3452  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: 1.4957  Acc@1: 68.7500 (69.0911)  Acc@5: 93.7500 (94.5710)  time: 0.3478  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:17  Lr: 0.001875  Loss: 0.8906  Acc@1: 62.5000 (69.0708)  Acc@5: 93.7500 (94.5577)  time: 0.3473  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: 0.6020  Acc@1: 68.7500 (69.0849)  Acc@5: 100.0000 (94.5958)  time: 0.3440  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.7198  Acc@1: 68.7500 (69.1213)  Acc@5: 100.0000 (94.6220)  time: 0.3456  data: 0.0019  max mem: 2501
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: 0.7986  Acc@1: 68.7500 (69.1291)  Acc@5: 100.0000 (94.6421)  time: 0.3468  data: 0.0025  max mem: 2501
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: 1.0306  Acc@1: 68.7500 (69.0926)  Acc@5: 93.7500 (94.6508)  time: 0.3456  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 1.3052  Acc@1: 68.7500 (69.0732)  Acc@5: 93.7500 (94.6538)  time: 0.3445  data: 0.0003  max mem: 2501
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5947  Acc@1: 68.7500 (69.0829)  Acc@5: 93.7500 (94.6564)  time: 0.3372  data: 0.0003  max mem: 2501
Train: Epoch[5/5] Total time: 0:06:34 (0.3455 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.5947  Acc@1: 68.7500 (69.0829)  Acc@5: 93.7500 (94.6564)
Test: [Task 1]  [   0/1627]  eta: 0:13:55  Loss: 3.1979 (3.1979)  Acc@1: 31.2500 (31.2500)  Acc@5: 56.2500 (56.2500)  time: 0.5138  data: 0.2928  max mem: 2501
Test: [Task 1]  [  10/1627]  eta: 0:06:31  Loss: 2.8766 (2.7074)  Acc@1: 25.0000 (30.6818)  Acc@5: 56.2500 (60.2273)  time: 0.2424  data: 0.0269  max mem: 2501
Test: [Task 1]  [  20/1627]  eta: 0:06:08  Loss: 2.6826 (2.6535)  Acc@1: 25.0000 (34.2262)  Acc@5: 62.5000 (63.6905)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [  30/1627]  eta: 0:05:58  Loss: 2.7372 (2.7337)  Acc@1: 25.0000 (30.4435)  Acc@5: 62.5000 (61.4919)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 1]  [  40/1627]  eta: 0:05:52  Loss: 2.7824 (2.7464)  Acc@1: 25.0000 (30.3354)  Acc@5: 62.5000 (62.6524)  time: 0.2144  data: 0.0003  max mem: 2501
Test: [Task 1]  [  50/1627]  eta: 0:05:48  Loss: 2.7613 (2.7363)  Acc@1: 31.2500 (30.3922)  Acc@5: 62.5000 (62.7451)  time: 0.2161  data: 0.0017  max mem: 2501
Test: [Task 1]  [  60/1627]  eta: 0:05:45  Loss: 2.7613 (2.7502)  Acc@1: 31.2500 (30.2254)  Acc@5: 62.5000 (62.2951)  time: 0.2161  data: 0.0017  max mem: 2501
Test: [Task 1]  [  70/1627]  eta: 0:05:41  Loss: 2.7954 (2.7576)  Acc@1: 25.0000 (30.3697)  Acc@5: 62.5000 (61.9718)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 1]  [  80/1627]  eta: 0:05:38  Loss: 2.6360 (2.7460)  Acc@1: 31.2500 (30.6327)  Acc@5: 62.5000 (62.5772)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 1]  [  90/1627]  eta: 0:05:35  Loss: 2.6956 (2.7381)  Acc@1: 31.2500 (31.1126)  Acc@5: 68.7500 (63.0495)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 100/1627]  eta: 0:05:32  Loss: 2.7881 (2.7480)  Acc@1: 25.0000 (30.3837)  Acc@5: 62.5000 (62.6238)  time: 0.2148  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 110/1627]  eta: 0:05:30  Loss: 2.7881 (2.7390)  Acc@1: 25.0000 (30.5180)  Acc@5: 62.5000 (62.6126)  time: 0.2153  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 120/1627]  eta: 0:05:27  Loss: 2.5349 (2.7226)  Acc@1: 31.2500 (31.0434)  Acc@5: 62.5000 (62.9132)  time: 0.2150  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 130/1627]  eta: 0:05:25  Loss: 2.6389 (2.7251)  Acc@1: 31.2500 (30.9637)  Acc@5: 62.5000 (63.1679)  time: 0.2146  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 140/1627]  eta: 0:05:23  Loss: 2.7066 (2.7260)  Acc@1: 25.0000 (30.8954)  Acc@5: 62.5000 (62.9876)  time: 0.2156  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 150/1627]  eta: 0:05:20  Loss: 2.5786 (2.7165)  Acc@1: 25.0000 (31.0430)  Acc@5: 62.5000 (63.1623)  time: 0.2154  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 160/1627]  eta: 0:05:18  Loss: 2.6211 (2.7171)  Acc@1: 31.2500 (31.0947)  Acc@5: 68.7500 (63.3540)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 170/1627]  eta: 0:05:15  Loss: 2.6985 (2.7038)  Acc@1: 31.2500 (31.2865)  Acc@5: 62.5000 (63.5599)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 180/1627]  eta: 0:05:13  Loss: 2.6046 (2.7110)  Acc@1: 31.2500 (31.1464)  Acc@5: 62.5000 (63.3633)  time: 0.2160  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 190/1627]  eta: 0:05:11  Loss: 2.6977 (2.7072)  Acc@1: 31.2500 (31.4463)  Acc@5: 62.5000 (63.4817)  time: 0.2161  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 200/1627]  eta: 0:05:09  Loss: 2.7243 (2.7188)  Acc@1: 31.2500 (31.2500)  Acc@5: 62.5000 (63.0286)  time: 0.2165  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 210/1627]  eta: 0:05:07  Loss: 2.8578 (2.7217)  Acc@1: 31.2500 (31.3389)  Acc@5: 56.2500 (62.9147)  time: 0.2159  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 220/1627]  eta: 0:05:04  Loss: 2.8059 (2.7267)  Acc@1: 31.2500 (31.1086)  Acc@5: 62.5000 (62.8676)  time: 0.2153  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 230/1627]  eta: 0:05:02  Loss: 2.8059 (2.7333)  Acc@1: 25.0000 (30.8171)  Acc@5: 56.2500 (62.5000)  time: 0.2171  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 240/1627]  eta: 0:05:00  Loss: 2.7410 (2.7297)  Acc@1: 25.0000 (30.9907)  Acc@5: 56.2500 (62.3963)  time: 0.2163  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 250/1627]  eta: 0:04:58  Loss: 2.6304 (2.7280)  Acc@1: 31.2500 (31.0259)  Acc@5: 62.5000 (62.3506)  time: 0.2153  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 260/1627]  eta: 0:04:56  Loss: 2.7031 (2.7271)  Acc@1: 31.2500 (31.2979)  Acc@5: 62.5000 (62.3324)  time: 0.2157  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 270/1627]  eta: 0:04:53  Loss: 2.5158 (2.7187)  Acc@1: 37.5000 (31.4576)  Acc@5: 62.5000 (62.4308)  time: 0.2158  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 280/1627]  eta: 0:04:51  Loss: 2.5770 (2.7189)  Acc@1: 31.2500 (31.3612)  Acc@5: 62.5000 (62.3665)  time: 0.2153  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 290/1627]  eta: 0:04:49  Loss: 2.5770 (2.7129)  Acc@1: 25.0000 (31.5077)  Acc@5: 62.5000 (62.4570)  time: 0.2149  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 300/1627]  eta: 0:04:47  Loss: 2.4813 (2.7107)  Acc@1: 31.2500 (31.5822)  Acc@5: 68.7500 (62.7284)  time: 0.2165  data: 0.0021  max mem: 2501
Test: [Task 1]  [ 310/1627]  eta: 0:04:45  Loss: 2.4672 (2.7089)  Acc@1: 31.2500 (31.7524)  Acc@5: 68.7500 (62.8416)  time: 0.2162  data: 0.0019  max mem: 2501
Test: [Task 1]  [ 320/1627]  eta: 0:04:42  Loss: 2.6255 (2.7103)  Acc@1: 31.2500 (31.6783)  Acc@5: 62.5000 (62.8115)  time: 0.2153  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 330/1627]  eta: 0:04:40  Loss: 2.7877 (2.7135)  Acc@1: 25.0000 (31.5521)  Acc@5: 62.5000 (62.7077)  time: 0.2153  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 340/1627]  eta: 0:04:38  Loss: 2.6457 (2.7162)  Acc@1: 25.0000 (31.5249)  Acc@5: 62.5000 (62.8482)  time: 0.2149  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 350/1627]  eta: 0:04:36  Loss: 2.7745 (2.7192)  Acc@1: 25.0000 (31.4637)  Acc@5: 62.5000 (62.7671)  time: 0.2148  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 360/1627]  eta: 0:04:33  Loss: 2.7745 (2.7188)  Acc@1: 25.0000 (31.4924)  Acc@5: 62.5000 (62.7770)  time: 0.2152  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 2.6133 (2.7165)  Acc@1: 25.0000 (31.4016)  Acc@5: 68.7500 (62.9380)  time: 0.2155  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 380/1627]  eta: 0:04:29  Loss: 2.7062 (2.7211)  Acc@1: 25.0000 (31.2008)  Acc@5: 62.5000 (62.8281)  time: 0.2150  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 390/1627]  eta: 0:04:27  Loss: 2.7703 (2.7237)  Acc@1: 25.0000 (31.2500)  Acc@5: 56.2500 (62.8037)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 400/1627]  eta: 0:04:25  Loss: 2.7270 (2.7255)  Acc@1: 25.0000 (31.0786)  Acc@5: 56.2500 (62.7961)  time: 0.2162  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 410/1627]  eta: 0:04:23  Loss: 2.6536 (2.7256)  Acc@1: 25.0000 (31.0523)  Acc@5: 62.5000 (62.8193)  time: 0.2158  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 420/1627]  eta: 0:04:20  Loss: 2.5867 (2.7261)  Acc@1: 31.2500 (30.9976)  Acc@5: 62.5000 (62.7227)  time: 0.2148  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 430/1627]  eta: 0:04:18  Loss: 2.5443 (2.7201)  Acc@1: 31.2500 (31.1630)  Acc@5: 62.5000 (62.9785)  time: 0.2148  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 440/1627]  eta: 0:04:16  Loss: 2.5433 (2.7192)  Acc@1: 25.0000 (31.2217)  Acc@5: 68.7500 (62.9819)  time: 0.2149  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 450/1627]  eta: 0:04:14  Loss: 2.7604 (2.7231)  Acc@1: 25.0000 (31.2639)  Acc@5: 62.5000 (62.9435)  time: 0.2154  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 2.7604 (2.7234)  Acc@1: 31.2500 (31.2364)  Acc@5: 62.5000 (63.0287)  time: 0.2161  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 470/1627]  eta: 0:04:09  Loss: 2.7116 (2.7232)  Acc@1: 31.2500 (31.2633)  Acc@5: 62.5000 (62.9910)  time: 0.2158  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 480/1627]  eta: 0:04:07  Loss: 2.7116 (2.7251)  Acc@1: 31.2500 (31.1590)  Acc@5: 62.5000 (62.9158)  time: 0.2149  data: 0.0002  max mem: 2501
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 2.7064 (2.7242)  Acc@1: 25.0000 (31.1864)  Acc@5: 62.5000 (62.9073)  time: 0.2141  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 2.5947 (2.7254)  Acc@1: 31.2500 (31.1627)  Acc@5: 62.5000 (62.9491)  time: 0.2152  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 510/1627]  eta: 0:04:01  Loss: 2.6847 (2.7278)  Acc@1: 31.2500 (31.1032)  Acc@5: 56.2500 (62.8302)  time: 0.2158  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 2.9784 (2.7319)  Acc@1: 25.0000 (31.0461)  Acc@5: 56.2500 (62.7279)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 530/1627]  eta: 0:03:56  Loss: 2.4390 (2.7245)  Acc@1: 37.5000 (31.2971)  Acc@5: 68.7500 (62.9708)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 2.3838 (2.7241)  Acc@1: 37.5000 (31.2731)  Acc@5: 68.7500 (63.0199)  time: 0.2160  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 2.8934 (2.7292)  Acc@1: 25.0000 (31.1366)  Acc@5: 56.2500 (62.8743)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 2.7822 (2.7293)  Acc@1: 18.7500 (31.0272)  Acc@5: 56.2500 (62.9234)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 570/1627]  eta: 0:03:48  Loss: 2.6289 (2.7274)  Acc@1: 25.0000 (31.0530)  Acc@5: 62.5000 (62.9159)  time: 0.2161  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 580/1627]  eta: 0:03:46  Loss: 2.6880 (2.7298)  Acc@1: 25.0000 (30.9488)  Acc@5: 62.5000 (62.8765)  time: 0.2157  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 590/1627]  eta: 0:03:43  Loss: 2.6880 (2.7298)  Acc@1: 25.0000 (30.9645)  Acc@5: 62.5000 (62.8173)  time: 0.2150  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 2.6802 (2.7318)  Acc@1: 25.0000 (30.8860)  Acc@5: 62.5000 (62.7392)  time: 0.2149  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 2.5979 (2.7294)  Acc@1: 31.2500 (30.9431)  Acc@5: 62.5000 (62.7864)  time: 0.2149  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 2.5252 (2.7286)  Acc@1: 31.2500 (30.9581)  Acc@5: 62.5000 (62.8221)  time: 0.2144  data: 0.0002  max mem: 2501
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 2.5187 (2.7262)  Acc@1: 31.2500 (30.9925)  Acc@5: 62.5000 (62.9655)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 2.4682 (2.7240)  Acc@1: 37.5000 (31.0452)  Acc@5: 68.7500 (63.0558)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 650/1627]  eta: 0:03:30  Loss: 2.5911 (2.7207)  Acc@1: 37.5000 (31.1444)  Acc@5: 68.7500 (63.1816)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 2.6101 (2.7184)  Acc@1: 31.2500 (31.1365)  Acc@5: 68.7500 (63.2943)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 2.6759 (2.7186)  Acc@1: 31.2500 (31.1941)  Acc@5: 68.7500 (63.3104)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 2.6037 (2.7160)  Acc@1: 37.5000 (31.2959)  Acc@5: 68.7500 (63.4086)  time: 0.2163  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 2.6037 (2.7161)  Acc@1: 37.5000 (31.2862)  Acc@5: 62.5000 (63.3412)  time: 0.2166  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 2.6639 (2.7157)  Acc@1: 25.0000 (31.2589)  Acc@5: 62.5000 (63.4362)  time: 0.2157  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 710/1627]  eta: 0:03:17  Loss: 2.5382 (2.7135)  Acc@1: 31.2500 (31.2852)  Acc@5: 68.7500 (63.4406)  time: 0.2157  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 2.5299 (2.7127)  Acc@1: 31.2500 (31.3020)  Acc@5: 62.5000 (63.4882)  time: 0.2170  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 2.7064 (2.7127)  Acc@1: 31.2500 (31.3013)  Acc@5: 62.5000 (63.5174)  time: 0.2166  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 2.7276 (2.7123)  Acc@1: 31.2500 (31.2922)  Acc@5: 62.5000 (63.5712)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 2.6967 (2.7142)  Acc@1: 31.2500 (31.2084)  Acc@5: 68.7500 (63.5153)  time: 0.2161  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 2.6658 (2.7145)  Acc@1: 25.0000 (31.2500)  Acc@5: 62.5000 (63.5020)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 770/1627]  eta: 0:03:04  Loss: 2.5735 (2.7119)  Acc@1: 37.5000 (31.3473)  Acc@5: 68.7500 (63.5944)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 780/1627]  eta: 0:03:02  Loss: 2.4807 (2.7117)  Acc@1: 31.2500 (31.3460)  Acc@5: 62.5000 (63.5883)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 2.8341 (2.7132)  Acc@1: 25.0000 (31.3053)  Acc@5: 62.5000 (63.5904)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 2.8958 (2.7135)  Acc@1: 25.0000 (31.2734)  Acc@5: 62.5000 (63.6236)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 2.8305 (2.7131)  Acc@1: 25.0000 (31.2423)  Acc@5: 62.5000 (63.6406)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 2.7526 (2.7137)  Acc@1: 31.2500 (31.2348)  Acc@5: 62.5000 (63.6343)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 830/1627]  eta: 0:02:51  Loss: 2.6763 (2.7134)  Acc@1: 31.2500 (31.2425)  Acc@5: 62.5000 (63.6432)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 2.5104 (2.7114)  Acc@1: 31.2500 (31.3095)  Acc@5: 68.7500 (63.7039)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 2.6873 (2.7140)  Acc@1: 25.0000 (31.2059)  Acc@5: 62.5000 (63.5870)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 2.7323 (2.7138)  Acc@1: 25.0000 (31.2137)  Acc@5: 56.2500 (63.5816)  time: 0.2148  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 2.5896 (2.7127)  Acc@1: 31.2500 (31.2141)  Acc@5: 68.7500 (63.6553)  time: 0.2164  data: 0.0009  max mem: 2501
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 2.6319 (2.7153)  Acc@1: 25.0000 (31.1649)  Acc@5: 62.5000 (63.5570)  time: 0.2165  data: 0.0009  max mem: 2501
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 2.9132 (2.7177)  Acc@1: 25.0000 (31.0957)  Acc@5: 56.2500 (63.4680)  time: 0.2157  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 900/1627]  eta: 0:02:36  Loss: 2.7750 (2.7169)  Acc@1: 25.0000 (31.1390)  Acc@5: 62.5000 (63.4920)  time: 0.2163  data: 0.0012  max mem: 2501
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 2.6152 (2.7162)  Acc@1: 31.2500 (31.1540)  Acc@5: 68.7500 (63.5085)  time: 0.2165  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 2.8332 (2.7163)  Acc@1: 25.0000 (31.1346)  Acc@5: 56.2500 (63.4772)  time: 0.2161  data: 0.0002  max mem: 2501
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 2.7002 (2.7156)  Acc@1: 25.0000 (31.1762)  Acc@5: 62.5000 (63.5338)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 2.6817 (2.7162)  Acc@1: 31.2500 (31.1637)  Acc@5: 62.5000 (63.4896)  time: 0.2159  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 2.6817 (2.7155)  Acc@1: 31.2500 (31.1711)  Acc@5: 56.2500 (63.4464)  time: 0.2159  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 960/1627]  eta: 0:02:23  Loss: 2.5795 (2.7143)  Acc@1: 31.2500 (31.1850)  Acc@5: 62.5000 (63.4886)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 2.5135 (2.7129)  Acc@1: 37.5000 (31.2178)  Acc@5: 68.7500 (63.5363)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 2.5724 (2.7117)  Acc@1: 31.2500 (31.2373)  Acc@5: 68.7500 (63.5640)  time: 0.2150  data: 0.0002  max mem: 2501
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 2.7565 (2.7143)  Acc@1: 25.0000 (31.1932)  Acc@5: 62.5000 (63.5091)  time: 0.2155  data: 0.0002  max mem: 2501
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 2.8614 (2.7148)  Acc@1: 25.0000 (31.1751)  Acc@5: 56.2500 (63.5115)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 2.6819 (2.7140)  Acc@1: 31.2500 (31.2253)  Acc@5: 62.5000 (63.5077)  time: 0.2160  data: 0.0007  max mem: 2501
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 2.7067 (2.7142)  Acc@1: 31.2500 (31.2316)  Acc@5: 56.2500 (63.4917)  time: 0.2159  data: 0.0008  max mem: 2501
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 2.5079 (2.7123)  Acc@1: 31.2500 (31.2742)  Acc@5: 56.2500 (63.4821)  time: 0.2167  data: 0.0005  max mem: 2501
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 2.4986 (2.7108)  Acc@1: 37.5000 (31.3401)  Acc@5: 68.7500 (63.5687)  time: 0.2166  data: 0.0004  max mem: 2501
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 2.5423 (2.7094)  Acc@1: 31.2500 (31.3451)  Acc@5: 75.0000 (63.6715)  time: 0.2158  data: 0.0002  max mem: 2501
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 2.6413 (2.7089)  Acc@1: 31.2500 (31.3560)  Acc@5: 68.7500 (63.6722)  time: 0.2165  data: 0.0005  max mem: 2501
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 2.5923 (2.7090)  Acc@1: 37.5000 (31.3842)  Acc@5: 62.5000 (63.6846)  time: 0.2161  data: 0.0005  max mem: 2501
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 2.6359 (2.7099)  Acc@1: 31.2500 (31.3945)  Acc@5: 62.5000 (63.6621)  time: 0.2151  data: 0.0002  max mem: 2501
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 2.7530 (2.7112)  Acc@1: 31.2500 (31.3932)  Acc@5: 62.5000 (63.6286)  time: 0.2156  data: 0.0002  max mem: 2501
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 2.6323 (2.7105)  Acc@1: 31.2500 (31.4033)  Acc@5: 62.5000 (63.6751)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 2.9009 (2.7125)  Acc@1: 25.0000 (31.3400)  Acc@5: 62.5000 (63.5576)  time: 0.2151  data: 0.0003  max mem: 2501
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 2.9009 (2.7121)  Acc@1: 25.0000 (31.3671)  Acc@5: 50.0000 (63.5426)  time: 0.2157  data: 0.0005  max mem: 2501
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 2.7004 (2.7121)  Acc@1: 31.2500 (31.3605)  Acc@5: 62.5000 (63.5389)  time: 0.2160  data: 0.0004  max mem: 2501
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 2.7601 (2.7144)  Acc@1: 25.0000 (31.2993)  Acc@5: 62.5000 (63.4805)  time: 0.2160  data: 0.0005  max mem: 2501
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 2.9555 (2.7145)  Acc@1: 25.0000 (31.3097)  Acc@5: 62.5000 (63.4883)  time: 0.2161  data: 0.0007  max mem: 2501
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 2.4767 (2.7144)  Acc@1: 31.2500 (31.3254)  Acc@5: 68.7500 (63.5067)  time: 0.2168  data: 0.0016  max mem: 2501
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 2.7017 (2.7148)  Acc@1: 31.2500 (31.3247)  Acc@5: 62.5000 (63.5034)  time: 0.2166  data: 0.0015  max mem: 2501
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 2.7561 (2.7156)  Acc@1: 31.2500 (31.3241)  Acc@5: 62.5000 (63.4632)  time: 0.2157  data: 0.0004  max mem: 2501
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 2.8065 (2.7155)  Acc@1: 31.2500 (31.3235)  Acc@5: 56.2500 (63.4393)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 2.7975 (2.7156)  Acc@1: 25.0000 (31.2448)  Acc@5: 62.5000 (63.4159)  time: 0.2159  data: 0.0007  max mem: 2501
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 2.6569 (2.7158)  Acc@1: 25.0000 (31.2448)  Acc@5: 62.5000 (63.3722)  time: 0.2170  data: 0.0014  max mem: 2501
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 2.6481 (2.7153)  Acc@1: 25.0000 (31.2346)  Acc@5: 62.5000 (63.4316)  time: 0.2173  data: 0.0013  max mem: 2501
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 2.6853 (2.7157)  Acc@1: 31.2500 (31.2297)  Acc@5: 68.7500 (63.4139)  time: 0.2166  data: 0.0006  max mem: 2501
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 2.6191 (2.7150)  Acc@1: 31.2500 (31.2450)  Acc@5: 62.5000 (63.4166)  time: 0.2162  data: 0.0005  max mem: 2501
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 2.6373 (2.7159)  Acc@1: 31.2500 (31.2400)  Acc@5: 62.5000 (63.3843)  time: 0.2171  data: 0.0005  max mem: 2501
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 2.7157 (2.7150)  Acc@1: 37.5000 (31.3045)  Acc@5: 62.5000 (63.3971)  time: 0.2175  data: 0.0004  max mem: 2501
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 2.6273 (2.7159)  Acc@1: 37.5000 (31.2795)  Acc@5: 62.5000 (63.3851)  time: 0.2168  data: 0.0004  max mem: 2501
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 2.5758 (2.7145)  Acc@1: 31.2500 (31.3232)  Acc@5: 62.5000 (63.3929)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 2.5820 (2.7147)  Acc@1: 31.2500 (31.3226)  Acc@5: 62.5000 (63.3569)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 2.5820 (2.7137)  Acc@1: 31.2500 (31.3461)  Acc@5: 62.5000 (63.4176)  time: 0.2184  data: 0.0015  max mem: 2501
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 2.5519 (2.7133)  Acc@1: 31.2500 (31.3692)  Acc@5: 68.7500 (63.4439)  time: 0.2180  data: 0.0015  max mem: 2501
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 2.5215 (2.7113)  Acc@1: 31.2500 (31.3967)  Acc@5: 68.7500 (63.4983)  time: 0.2159  data: 0.0004  max mem: 2501
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 2.6357 (2.7128)  Acc@1: 31.2500 (31.3909)  Acc@5: 62.5000 (63.4532)  time: 0.2167  data: 0.0007  max mem: 2501
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 2.9307 (2.7137)  Acc@1: 25.0000 (31.3712)  Acc@5: 56.2500 (63.3949)  time: 0.2159  data: 0.0005  max mem: 2501
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 2.7761 (2.7136)  Acc@1: 25.0000 (31.3610)  Acc@5: 62.5000 (63.3975)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 2.7098 (2.7141)  Acc@1: 31.2500 (31.3373)  Acc@5: 62.5000 (63.3679)  time: 0.2163  data: 0.0003  max mem: 2501
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 2.6889 (2.7135)  Acc@1: 31.2500 (31.3640)  Acc@5: 62.5000 (63.4026)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 2.6889 (2.7130)  Acc@1: 31.2500 (31.3948)  Acc@5: 62.5000 (63.4006)  time: 0.2167  data: 0.0003  max mem: 2501
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 2.5154 (2.7115)  Acc@1: 37.5000 (31.4522)  Acc@5: 62.5000 (63.4166)  time: 0.2170  data: 0.0003  max mem: 2501
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 2.7693 (2.7121)  Acc@1: 31.2500 (31.4418)  Acc@5: 62.5000 (63.4056)  time: 0.2163  data: 0.0005  max mem: 2501
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 2.7899 (2.7116)  Acc@1: 25.0000 (31.4582)  Acc@5: 62.5000 (63.3903)  time: 0.2170  data: 0.0015  max mem: 2501
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 2.5398 (2.7109)  Acc@1: 37.5000 (31.4875)  Acc@5: 62.5000 (63.3929)  time: 0.2168  data: 0.0013  max mem: 2501
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 2.6853 (2.7118)  Acc@1: 31.2500 (31.4727)  Acc@5: 56.2500 (63.3517)  time: 0.2166  data: 0.0002  max mem: 2501
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 2.7189 (2.7109)  Acc@1: 37.5000 (31.4799)  Acc@5: 56.2500 (63.3718)  time: 0.2167  data: 0.0003  max mem: 2501
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 2.6097 (2.7112)  Acc@1: 31.2500 (31.4783)  Acc@5: 62.5000 (63.3701)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 2.6273 (2.7112)  Acc@1: 31.2500 (31.4468)  Acc@5: 68.7500 (63.3984)  time: 0.2161  data: 0.0003  max mem: 2501
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 2.8009 (2.7120)  Acc@1: 31.2500 (31.4369)  Acc@5: 68.7500 (63.3795)  time: 0.2161  data: 0.0003  max mem: 2501
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 2.7603 (2.7120)  Acc@1: 31.2500 (31.4483)  Acc@5: 62.5000 (63.3989)  time: 0.2166  data: 0.0003  max mem: 2501
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 2.6829 (2.7124)  Acc@1: 31.2500 (31.4344)  Acc@5: 56.2500 (63.3719)  time: 0.2165  data: 0.0003  max mem: 2501
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.7737 (2.7125)  Acc@1: 25.0000 (31.4124)  Acc@5: 56.2500 (63.3911)  time: 0.2159  data: 0.0002  max mem: 2501
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 2.7951 (2.7127)  Acc@1: 25.0000 (31.4237)  Acc@5: 62.5000 (63.3852)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 2.6509 (2.7113)  Acc@1: 31.2500 (31.4226)  Acc@5: 62.5000 (63.4451)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 2.5692 (2.7113)  Acc@1: 31.2500 (31.4378)  Acc@5: 75.0000 (63.4553)  time: 0.2160  data: 0.0003  max mem: 2501
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 2.5972 (2.7106)  Acc@1: 37.5000 (31.4528)  Acc@5: 68.7500 (63.4734)  time: 0.2168  data: 0.0003  max mem: 2501
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.6301 (2.7105)  Acc@1: 37.5000 (31.4636)  Acc@5: 62.5000 (63.4631)  time: 0.2163  data: 0.0003  max mem: 2501
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.4847 (2.7087)  Acc@1: 37.5000 (31.5102)  Acc@5: 68.7500 (63.4930)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.5598 (2.7093)  Acc@1: 37.5000 (31.5126)  Acc@5: 68.7500 (63.4906)  time: 0.2168  data: 0.0008  max mem: 2501
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.7307 (2.7089)  Acc@1: 31.2500 (31.5030)  Acc@5: 62.5000 (63.5041)  time: 0.2168  data: 0.0007  max mem: 2501
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 2.6251 (2.7097)  Acc@1: 31.2500 (31.4778)  Acc@5: 62.5000 (63.4860)  time: 0.2160  data: 0.0002  max mem: 2501
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 2.8470 (2.7106)  Acc@1: 18.7500 (31.4374)  Acc@5: 56.2500 (63.4564)  time: 0.2165  data: 0.0003  max mem: 2501
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.5855 (2.7103)  Acc@1: 25.0000 (31.4789)  Acc@5: 62.5000 (63.4583)  time: 0.2174  data: 0.0005  max mem: 2501
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 2.5322 (2.7101)  Acc@1: 31.2500 (31.4929)  Acc@5: 62.5000 (63.4755)  time: 0.2168  data: 0.0005  max mem: 2501
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.5377 (2.7094)  Acc@1: 31.2500 (31.4959)  Acc@5: 62.5000 (63.4988)  time: 0.2168  data: 0.0005  max mem: 2501
Test: [Task 1] Total time: 0:05:51 (0.2162 s / it)
* Acc@1 31.496 Acc@5 63.499 loss 2.709
Test: [Task 2]  [  0/625]  eta: 0:05:27  Loss: 0.3837 (0.3837)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5246  data: 0.3079  max mem: 2501
Test: [Task 2]  [ 10/625]  eta: 0:02:29  Loss: 0.5931 (0.5976)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.2955)  time: 0.2435  data: 0.0282  max mem: 2501
Test: [Task 2]  [ 20/625]  eta: 0:02:19  Loss: 0.5704 (0.5920)  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (98.2143)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 30/625]  eta: 0:02:14  Loss: 0.5704 (0.6297)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (97.5806)  time: 0.2157  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 40/625]  eta: 0:02:10  Loss: 0.6236 (0.6559)  Acc@1: 81.2500 (83.3841)  Acc@5: 100.0000 (97.7134)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 50/625]  eta: 0:02:07  Loss: 0.7026 (0.6763)  Acc@1: 81.2500 (82.7206)  Acc@5: 100.0000 (97.5490)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 60/625]  eta: 0:02:04  Loss: 0.6964 (0.6837)  Acc@1: 81.2500 (82.5820)  Acc@5: 93.7500 (97.2336)  time: 0.2160  data: 0.0005  max mem: 2501
Test: [Task 2]  [ 70/625]  eta: 0:02:02  Loss: 0.6740 (0.6820)  Acc@1: 81.2500 (82.6585)  Acc@5: 93.7500 (97.2711)  time: 0.2165  data: 0.0009  max mem: 2501
Test: [Task 2]  [ 80/625]  eta: 0:01:59  Loss: 0.7040 (0.6865)  Acc@1: 81.2500 (82.7160)  Acc@5: 100.0000 (97.2222)  time: 0.2164  data: 0.0006  max mem: 2501
Test: [Task 2]  [ 90/625]  eta: 0:01:57  Loss: 0.7114 (0.6886)  Acc@1: 81.2500 (82.5549)  Acc@5: 100.0000 (97.3214)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 2]  [100/625]  eta: 0:01:54  Loss: 0.7304 (0.6961)  Acc@1: 81.2500 (81.9307)  Acc@5: 100.0000 (97.1535)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 2]  [110/625]  eta: 0:01:52  Loss: 0.6341 (0.6892)  Acc@1: 81.2500 (82.0946)  Acc@5: 93.7500 (97.1284)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.5741 (0.6838)  Acc@1: 87.5000 (82.3347)  Acc@5: 100.0000 (97.1591)  time: 0.2160  data: 0.0005  max mem: 2501
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.6308 (0.6837)  Acc@1: 81.2500 (82.3950)  Acc@5: 100.0000 (97.2805)  time: 0.2162  data: 0.0005  max mem: 2501
Test: [Task 2]  [140/625]  eta: 0:01:45  Loss: 0.6639 (0.6918)  Acc@1: 81.2500 (82.1809)  Acc@5: 100.0000 (97.1188)  time: 0.2167  data: 0.0009  max mem: 2501
Test: [Task 2]  [150/625]  eta: 0:01:43  Loss: 0.7672 (0.6942)  Acc@1: 81.2500 (82.1192)  Acc@5: 100.0000 (97.2682)  time: 0.2169  data: 0.0010  max mem: 2501
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.6564 (0.6979)  Acc@1: 81.2500 (81.5994)  Acc@5: 100.0000 (97.1661)  time: 0.2169  data: 0.0009  max mem: 2501
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.6564 (0.6966)  Acc@1: 81.2500 (81.8348)  Acc@5: 100.0000 (97.1491)  time: 0.2165  data: 0.0008  max mem: 2501
Test: [Task 2]  [180/625]  eta: 0:01:36  Loss: 0.7487 (0.7023)  Acc@1: 81.2500 (81.6989)  Acc@5: 100.0000 (97.2376)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.7629 (0.7052)  Acc@1: 81.2500 (81.6099)  Acc@5: 100.0000 (97.2186)  time: 0.2161  data: 0.0005  max mem: 2501
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.6976 (0.7081)  Acc@1: 81.2500 (81.3744)  Acc@5: 100.0000 (97.2015)  time: 0.2162  data: 0.0005  max mem: 2501
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.6490 (0.7074)  Acc@1: 81.2500 (81.4277)  Acc@5: 100.0000 (97.2156)  time: 0.2153  data: 0.0002  max mem: 2501
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.6183 (0.7055)  Acc@1: 87.5000 (81.6459)  Acc@5: 100.0000 (97.2851)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 0.6183 (0.7060)  Acc@1: 87.5000 (81.6829)  Acc@5: 100.0000 (97.2944)  time: 0.2160  data: 0.0004  max mem: 2501
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.6738 (0.7047)  Acc@1: 81.2500 (81.6909)  Acc@5: 100.0000 (97.3288)  time: 0.2174  data: 0.0008  max mem: 2501
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.6282 (0.7014)  Acc@1: 81.2500 (81.9223)  Acc@5: 100.0000 (97.3108)  time: 0.2171  data: 0.0007  max mem: 2501
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.6219 (0.6999)  Acc@1: 81.2500 (81.8487)  Acc@5: 100.0000 (97.3420)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.6943 (0.6996)  Acc@1: 81.2500 (81.7804)  Acc@5: 100.0000 (97.3478)  time: 0.2170  data: 0.0003  max mem: 2501
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 0.7150 (0.7021)  Acc@1: 81.2500 (81.6948)  Acc@5: 100.0000 (97.3310)  time: 0.2177  data: 0.0009  max mem: 2501
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.6852 (0.7044)  Acc@1: 81.2500 (81.6796)  Acc@5: 100.0000 (97.2509)  time: 0.2165  data: 0.0014  max mem: 2501
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.6852 (0.7045)  Acc@1: 81.2500 (81.6030)  Acc@5: 100.0000 (97.2384)  time: 0.2157  data: 0.0007  max mem: 2501
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.7752 (0.7070)  Acc@1: 81.2500 (81.4912)  Acc@5: 100.0000 (97.2066)  time: 0.2151  data: 0.0002  max mem: 2501
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.4553 (0.6967)  Acc@1: 81.2500 (81.7952)  Acc@5: 100.0000 (97.2741)  time: 0.2151  data: 0.0002  max mem: 2501
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.3994 (0.6939)  Acc@1: 87.5000 (81.8731)  Acc@5: 100.0000 (97.3376)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.4540 (0.6841)  Acc@1: 87.5000 (82.2031)  Acc@5: 100.0000 (97.3974)  time: 0.2161  data: 0.0003  max mem: 2501
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.3843 (0.6778)  Acc@1: 93.7500 (82.3362)  Acc@5: 100.0000 (97.4359)  time: 0.2159  data: 0.0002  max mem: 2501
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.5177 (0.6797)  Acc@1: 81.2500 (82.2195)  Acc@5: 100.0000 (97.4896)  time: 0.2159  data: 0.0004  max mem: 2501
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.5896 (0.6741)  Acc@1: 81.2500 (82.3787)  Acc@5: 100.0000 (97.5573)  time: 0.2171  data: 0.0008  max mem: 2501
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.6087 (0.6762)  Acc@1: 81.2500 (82.2507)  Acc@5: 100.0000 (97.5066)  time: 0.2161  data: 0.0005  max mem: 2501
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 0.6653 (0.6726)  Acc@1: 81.2500 (82.3050)  Acc@5: 93.7500 (97.4904)  time: 0.2149  data: 0.0002  max mem: 2501
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.4050 (0.6651)  Acc@1: 87.5000 (82.5748)  Acc@5: 100.0000 (97.5530)  time: 0.2157  data: 0.0005  max mem: 2501
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.3580 (0.6617)  Acc@1: 93.7500 (82.7707)  Acc@5: 100.0000 (97.5821)  time: 0.2167  data: 0.0005  max mem: 2501
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.4107 (0.6630)  Acc@1: 93.7500 (82.7939)  Acc@5: 100.0000 (97.5505)  time: 0.2161  data: 0.0004  max mem: 2501
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.5217 (0.6605)  Acc@1: 87.5000 (82.9031)  Acc@5: 100.0000 (97.5928)  time: 0.2161  data: 0.0008  max mem: 2501
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.4145 (0.6536)  Acc@1: 87.5000 (83.1633)  Acc@5: 100.0000 (97.6332)  time: 0.2164  data: 0.0008  max mem: 2501
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.3494 (0.6473)  Acc@1: 93.7500 (83.3287)  Acc@5: 100.0000 (97.6857)  time: 0.2154  data: 0.0004  max mem: 2501
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.3860 (0.6419)  Acc@1: 93.7500 (83.5277)  Acc@5: 100.0000 (97.7359)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.5231 (0.6415)  Acc@1: 87.5000 (83.6253)  Acc@5: 100.0000 (97.7574)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.6270 (0.6406)  Acc@1: 87.5000 (83.7058)  Acc@5: 100.0000 (97.7781)  time: 0.2151  data: 0.0002  max mem: 2501
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.5300 (0.6371)  Acc@1: 87.5000 (83.8977)  Acc@5: 100.0000 (97.8106)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.4816 (0.6357)  Acc@1: 93.7500 (83.9820)  Acc@5: 100.0000 (97.8418)  time: 0.2157  data: 0.0003  max mem: 2501
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.5528 (0.6356)  Acc@1: 87.5000 (84.0020)  Acc@5: 100.0000 (97.8596)  time: 0.2156  data: 0.0003  max mem: 2501
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.6095 (0.6382)  Acc@1: 81.2500 (83.9611)  Acc@5: 100.0000 (97.8527)  time: 0.2155  data: 0.0003  max mem: 2501
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.6047 (0.6373)  Acc@1: 81.2500 (83.9807)  Acc@5: 100.0000 (97.8696)  time: 0.2156  data: 0.0005  max mem: 2501
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.4821 (0.6340)  Acc@1: 87.5000 (84.0689)  Acc@5: 100.0000 (97.8974)  time: 0.2162  data: 0.0010  max mem: 2501
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.3021 (0.6280)  Acc@1: 93.7500 (84.2672)  Acc@5: 100.0000 (97.9242)  time: 0.2159  data: 0.0007  max mem: 2501
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.3018 (0.6228)  Acc@1: 93.7500 (84.4474)  Acc@5: 100.0000 (97.9612)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.3496 (0.6226)  Acc@1: 93.7500 (84.4790)  Acc@5: 100.0000 (97.9641)  time: 0.2166  data: 0.0003  max mem: 2501
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.4478 (0.6184)  Acc@1: 93.7500 (84.6386)  Acc@5: 100.0000 (97.9991)  time: 0.2166  data: 0.0004  max mem: 2501
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.3961 (0.6151)  Acc@1: 93.7500 (84.6870)  Acc@5: 100.0000 (98.0224)  time: 0.2167  data: 0.0006  max mem: 2501
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.5072 (0.6155)  Acc@1: 87.5000 (84.7026)  Acc@5: 100.0000 (98.0241)  time: 0.2167  data: 0.0005  max mem: 2501
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.6604 (0.6200)  Acc@1: 81.2500 (84.6358)  Acc@5: 100.0000 (97.9644)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.6738 (0.6202)  Acc@1: 81.2500 (84.6417)  Acc@5: 100.0000 (97.9871)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.6033 (0.6194)  Acc@1: 81.2500 (84.6700)  Acc@5: 100.0000 (97.9900)  time: 0.2149  data: 0.0002  max mem: 2501
Test: [Task 2] Total time: 0:02:15 (0.2167 s / it)
* Acc@1 84.670 Acc@5 97.990 loss 0.619
Test: [Task 3]  [  0/625]  eta: 0:05:53  Loss: 0.3232 (0.3232)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5654  data: 0.3492  max mem: 2501
Test: [Task 3]  [ 10/625]  eta: 0:02:31  Loss: 0.2690 (0.2863)  Acc@1: 93.7500 (96.5909)  Acc@5: 100.0000 (98.2955)  time: 0.2469  data: 0.0320  max mem: 2501
Test: [Task 3]  [ 20/625]  eta: 0:02:20  Loss: 0.2690 (0.3163)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (97.6190)  time: 0.2161  data: 0.0006  max mem: 2501
Test: [Task 3]  [ 30/625]  eta: 0:02:15  Loss: 0.2553 (0.3011)  Acc@1: 93.7500 (95.7661)  Acc@5: 100.0000 (98.1855)  time: 0.2167  data: 0.0007  max mem: 2501
Test: [Task 3]  [ 40/625]  eta: 0:02:11  Loss: 0.2094 (0.2835)  Acc@1: 93.7500 (95.7317)  Acc@5: 100.0000 (98.6280)  time: 0.2158  data: 0.0004  max mem: 2501
Test: [Task 3]  [ 50/625]  eta: 0:02:08  Loss: 0.1670 (0.2720)  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (98.7745)  time: 0.2173  data: 0.0022  max mem: 2501
Test: [Task 3]  [ 60/625]  eta: 0:02:05  Loss: 0.1962 (0.2646)  Acc@1: 100.0000 (96.1066)  Acc@5: 100.0000 (98.9754)  time: 0.2170  data: 0.0022  max mem: 2501
Test: [Task 3]  [ 70/625]  eta: 0:02:02  Loss: 0.1602 (0.2520)  Acc@1: 100.0000 (96.3028)  Acc@5: 100.0000 (98.9437)  time: 0.2148  data: 0.0002  max mem: 2501
Test: [Task 3]  [ 80/625]  eta: 0:02:00  Loss: 0.1602 (0.2529)  Acc@1: 100.0000 (96.2191)  Acc@5: 100.0000 (98.9198)  time: 0.2157  data: 0.0004  max mem: 2501
Test: [Task 3]  [ 90/625]  eta: 0:01:57  Loss: 0.2206 (0.2483)  Acc@1: 93.7500 (96.2912)  Acc@5: 100.0000 (98.9698)  time: 0.2161  data: 0.0004  max mem: 2501
Test: [Task 3]  [100/625]  eta: 0:01:55  Loss: 0.1664 (0.2426)  Acc@1: 100.0000 (96.5965)  Acc@5: 100.0000 (99.0718)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 0.1664 (0.2365)  Acc@1: 100.0000 (96.7905)  Acc@5: 100.0000 (99.1554)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 3]  [120/625]  eta: 0:01:50  Loss: 0.1760 (0.2381)  Acc@1: 100.0000 (96.8492)  Acc@5: 100.0000 (99.2252)  time: 0.2146  data: 0.0002  max mem: 2501
Test: [Task 3]  [130/625]  eta: 0:01:48  Loss: 0.2101 (0.2387)  Acc@1: 100.0000 (96.7557)  Acc@5: 100.0000 (99.1889)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 3]  [140/625]  eta: 0:01:45  Loss: 0.2622 (0.2427)  Acc@1: 93.7500 (96.6755)  Acc@5: 100.0000 (99.1578)  time: 0.2148  data: 0.0003  max mem: 2501
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 0.2650 (0.2479)  Acc@1: 93.7500 (96.4404)  Acc@5: 100.0000 (99.0894)  time: 0.2165  data: 0.0007  max mem: 2501
Test: [Task 3]  [160/625]  eta: 0:01:41  Loss: 0.1816 (0.2488)  Acc@1: 93.7500 (96.3509)  Acc@5: 100.0000 (99.0683)  time: 0.2171  data: 0.0009  max mem: 2501
Test: [Task 3]  [170/625]  eta: 0:01:39  Loss: 0.2228 (0.2504)  Acc@1: 100.0000 (96.3085)  Acc@5: 100.0000 (99.0497)  time: 0.2157  data: 0.0005  max mem: 2501
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.2831 (0.2534)  Acc@1: 93.7500 (96.2017)  Acc@5: 100.0000 (99.0331)  time: 0.2154  data: 0.0007  max mem: 2501
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.2655 (0.2528)  Acc@1: 93.7500 (96.2369)  Acc@5: 100.0000 (99.0183)  time: 0.2153  data: 0.0007  max mem: 2501
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 0.2655 (0.2560)  Acc@1: 93.7500 (96.1754)  Acc@5: 100.0000 (98.9739)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 3]  [210/625]  eta: 0:01:30  Loss: 0.1863 (0.2577)  Acc@1: 93.7500 (96.1493)  Acc@5: 100.0000 (98.9633)  time: 0.2160  data: 0.0002  max mem: 2501
Test: [Task 3]  [220/625]  eta: 0:01:28  Loss: 0.1705 (0.2572)  Acc@1: 100.0000 (96.0690)  Acc@5: 100.0000 (98.9253)  time: 0.2157  data: 0.0006  max mem: 2501
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.2066 (0.2586)  Acc@1: 93.7500 (96.0768)  Acc@5: 100.0000 (98.8907)  time: 0.2153  data: 0.0008  max mem: 2501
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.2066 (0.2603)  Acc@1: 93.7500 (96.0581)  Acc@5: 100.0000 (98.8589)  time: 0.2164  data: 0.0004  max mem: 2501
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1633 (0.2577)  Acc@1: 100.0000 (96.0906)  Acc@5: 100.0000 (98.8795)  time: 0.2158  data: 0.0003  max mem: 2501
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1483 (0.2573)  Acc@1: 100.0000 (96.0728)  Acc@5: 100.0000 (98.8745)  time: 0.2153  data: 0.0009  max mem: 2501
Test: [Task 3]  [270/625]  eta: 0:01:17  Loss: 0.1897 (0.2580)  Acc@1: 93.7500 (95.9871)  Acc@5: 100.0000 (98.8469)  time: 0.2153  data: 0.0008  max mem: 2501
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 0.1976 (0.2578)  Acc@1: 93.7500 (95.9964)  Acc@5: 100.0000 (98.8434)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.2170 (0.2587)  Acc@1: 93.7500 (95.9622)  Acc@5: 100.0000 (98.8402)  time: 0.2156  data: 0.0007  max mem: 2501
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.2444 (0.2588)  Acc@1: 93.7500 (95.9510)  Acc@5: 100.0000 (98.8787)  time: 0.2155  data: 0.0007  max mem: 2501
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1944 (0.2615)  Acc@1: 100.0000 (95.8601)  Acc@5: 100.0000 (98.8545)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 3]  [320/625]  eta: 0:01:06  Loss: 0.2094 (0.2605)  Acc@1: 93.7500 (95.8723)  Acc@5: 100.0000 (98.8512)  time: 0.2162  data: 0.0007  max mem: 2501
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 0.2673 (0.2638)  Acc@1: 93.7500 (95.8082)  Acc@5: 100.0000 (98.8482)  time: 0.2169  data: 0.0006  max mem: 2501
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.2484 (0.2620)  Acc@1: 100.0000 (95.8761)  Acc@5: 100.0000 (98.8636)  time: 0.2159  data: 0.0003  max mem: 2501
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1875 (0.2622)  Acc@1: 100.0000 (95.8333)  Acc@5: 100.0000 (98.8426)  time: 0.2165  data: 0.0013  max mem: 2501
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.2088 (0.2636)  Acc@1: 93.7500 (95.7756)  Acc@5: 100.0000 (98.8400)  time: 0.2170  data: 0.0022  max mem: 2501
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.3141 (0.2644)  Acc@1: 93.7500 (95.7379)  Acc@5: 100.0000 (98.8544)  time: 0.2161  data: 0.0013  max mem: 2501
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.2267 (0.2629)  Acc@1: 93.7500 (95.7841)  Acc@5: 100.0000 (98.8845)  time: 0.2155  data: 0.0004  max mem: 2501
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.2241 (0.2641)  Acc@1: 93.7500 (95.7321)  Acc@5: 100.0000 (98.8971)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1966 (0.2622)  Acc@1: 93.7500 (95.7762)  Acc@5: 100.0000 (98.9090)  time: 0.2154  data: 0.0005  max mem: 2501
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.1934 (0.2637)  Acc@1: 93.7500 (95.7117)  Acc@5: 100.0000 (98.9051)  time: 0.2157  data: 0.0005  max mem: 2501
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.2660 (0.2637)  Acc@1: 93.7500 (95.7245)  Acc@5: 100.0000 (98.9163)  time: 0.2177  data: 0.0017  max mem: 2501
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.2063 (0.2636)  Acc@1: 93.7500 (95.7077)  Acc@5: 100.0000 (98.9124)  time: 0.2170  data: 0.0017  max mem: 2501
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.2352 (0.2654)  Acc@1: 93.7500 (95.6491)  Acc@5: 100.0000 (98.8946)  time: 0.2156  data: 0.0005  max mem: 2501
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.2395 (0.2652)  Acc@1: 93.7500 (95.6901)  Acc@5: 100.0000 (98.9052)  time: 0.2155  data: 0.0005  max mem: 2501
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.2115 (0.2637)  Acc@1: 100.0000 (95.7158)  Acc@5: 100.0000 (98.9154)  time: 0.2153  data: 0.0003  max mem: 2501
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.2141 (0.2632)  Acc@1: 93.7500 (95.7006)  Acc@5: 100.0000 (98.9252)  time: 0.2157  data: 0.0003  max mem: 2501
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.2213 (0.2643)  Acc@1: 93.7500 (95.6861)  Acc@5: 100.0000 (98.9085)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2768 (0.2645)  Acc@1: 93.7500 (95.6848)  Acc@5: 100.0000 (98.8926)  time: 0.2145  data: 0.0002  max mem: 2501
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2272 (0.2639)  Acc@1: 93.7500 (95.6587)  Acc@5: 100.0000 (98.9022)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.1777 (0.2633)  Acc@1: 93.7500 (95.6703)  Acc@5: 100.0000 (98.9237)  time: 0.2152  data: 0.0003  max mem: 2501
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.2242 (0.2639)  Acc@1: 93.7500 (95.6574)  Acc@5: 100.0000 (98.9203)  time: 0.2155  data: 0.0006  max mem: 2501
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.2506 (0.2649)  Acc@1: 100.0000 (95.6568)  Acc@5: 100.0000 (98.9171)  time: 0.2161  data: 0.0009  max mem: 2501
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2843 (0.2665)  Acc@1: 100.0000 (95.6331)  Acc@5: 100.0000 (98.8794)  time: 0.2156  data: 0.0006  max mem: 2501
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2865 (0.2673)  Acc@1: 93.7500 (95.6103)  Acc@5: 100.0000 (98.8657)  time: 0.2150  data: 0.0003  max mem: 2501
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2037 (0.2667)  Acc@1: 100.0000 (95.6439)  Acc@5: 100.0000 (98.8636)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.2028 (0.2658)  Acc@1: 100.0000 (95.6546)  Acc@5: 100.0000 (98.8835)  time: 0.2154  data: 0.0003  max mem: 2501
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2742 (0.2679)  Acc@1: 93.7500 (95.6003)  Acc@5: 100.0000 (98.8920)  time: 0.2147  data: 0.0003  max mem: 2501
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.2118 (0.2668)  Acc@1: 93.7500 (95.6430)  Acc@5: 100.0000 (98.9107)  time: 0.2145  data: 0.0003  max mem: 2501
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.2118 (0.2665)  Acc@1: 100.0000 (95.6323)  Acc@5: 100.0000 (98.9081)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.2411 (0.2659)  Acc@1: 93.7500 (95.6322)  Acc@5: 100.0000 (98.9055)  time: 0.2155  data: 0.0010  max mem: 2501
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2281 (0.2667)  Acc@1: 93.7500 (95.6220)  Acc@5: 100.0000 (98.9030)  time: 0.2154  data: 0.0010  max mem: 2501
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.2272 (0.2662)  Acc@1: 93.7500 (95.6200)  Acc@5: 100.0000 (98.9100)  time: 0.2144  data: 0.0002  max mem: 2501
Test: [Task 3] Total time: 0:02:15 (0.2164 s / it)
* Acc@1 95.620 Acc@5 98.910 loss 0.266
Test: [Task 4]  [ 0/29]  eta: 0:00:15  Loss: 1.7361 (1.7361)  Acc@1: 43.7500 (43.7500)  Acc@5: 87.5000 (87.5000)  time: 0.5217  data: 0.3035  max mem: 2501
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 1.6649 (1.5805)  Acc@1: 50.0000 (51.7045)  Acc@5: 87.5000 (86.9318)  time: 0.2426  data: 0.0278  max mem: 2501
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.4589 (1.4952)  Acc@1: 56.2500 (59.2262)  Acc@5: 87.5000 (86.9048)  time: 0.2146  data: 0.0003  max mem: 2501
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.4589 (1.4581)  Acc@1: 62.5000 (61.2200)  Acc@5: 87.5000 (87.3638)  time: 0.2167  data: 0.0002  max mem: 2501
Test: [Task 4] Total time: 0:00:06 (0.2316 s / it)
* Acc@1 61.220 Acc@5 87.364 loss 1.458
{0: {0: 25002, 1: 25002, 2: 25002, 3: 25002, 4: 25, 5: 25, 6: 25, 7: 25, 8: 146, 9: 146, 10: 146, 11: 146, 12: 67, 13: 67, 14: 67, 15: 67, 16: 792, 17: 792, 18: 792, 19: 792}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 9896, 5: 9896, 6: 9896, 7: 9896, 8: 0, 9: 0, 10: 0, 11: 0, 12: 104, 13: 104, 14: 104, 15: 104, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 151, 1: 151, 2: 151, 3: 151, 4: 14, 5: 14, 6: 14, 7: 14, 8: 9679, 9: 9679, 10: 9679, 11: 9679, 12: 46, 13: 46, 14: 46, 15: 46, 16: 110, 17: 110, 18: 110, 19: 110}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 30, 5: 30, 6: 30, 7: 30, 8: 0, 9: 0, 10: 0, 11: 0, 12: 428, 13: 428, 14: 428, 15: 428, 16: 1, 17: 1, 18: 1, 19: 1}}
[Average accuracy till task4]	Acc@1: 68.2515	Acc@5: 86.9407	Loss: 1.2633	Forgetting: 21.2737	Backward: -21.2737
Train: Epoch[1/5]  [   0/3750]  eta: 0:40:08  Lr: 0.001875  Loss: 2.2975  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  time: 0.6423  data: 0.2647  max mem: 2501
Train: Epoch[1/5]  [  10/3750]  eta: 0:23:06  Lr: 0.001875  Loss: 2.1116  Acc@1: 25.0000 (23.8636)  Acc@5: 75.0000 (69.3182)  time: 0.3706  data: 0.0243  max mem: 2503
Train: Epoch[1/5]  [  20/3750]  eta: 0:22:14  Lr: 0.001875  Loss: 2.0132  Acc@1: 31.2500 (31.2500)  Acc@5: 87.5000 (79.7619)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [  30/3750]  eta: 0:21:55  Lr: 0.001875  Loss: 1.8922  Acc@1: 37.5000 (35.2823)  Acc@5: 93.7500 (84.6774)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [  40/3750]  eta: 0:21:43  Lr: 0.001875  Loss: 1.5934  Acc@1: 43.7500 (40.2439)  Acc@5: 93.7500 (86.7378)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [  50/3750]  eta: 0:21:34  Lr: 0.001875  Loss: 1.2116  Acc@1: 62.5000 (45.5882)  Acc@5: 93.7500 (88.7255)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:28  Lr: 0.001875  Loss: 1.2313  Acc@1: 68.7500 (49.8975)  Acc@5: 100.0000 (90.2664)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:22  Lr: 0.001875  Loss: 1.3786  Acc@1: 68.7500 (52.2887)  Acc@5: 100.0000 (91.1092)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:17  Lr: 0.001875  Loss: 1.0595  Acc@1: 68.7500 (53.9352)  Acc@5: 93.7500 (91.6667)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:12  Lr: 0.001875  Loss: 1.2128  Acc@1: 62.5000 (54.8764)  Acc@5: 93.7500 (92.1703)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:08  Lr: 0.001875  Loss: 1.1853  Acc@1: 62.5000 (55.8787)  Acc@5: 93.7500 (92.6361)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:03  Lr: 0.001875  Loss: 0.9033  Acc@1: 68.7500 (56.9257)  Acc@5: 100.0000 (93.1306)  time: 0.3449  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 120/3750]  eta: 0:20:59  Lr: 0.001875  Loss: 0.8740  Acc@1: 68.7500 (57.8512)  Acc@5: 100.0000 (93.3368)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 130/3750]  eta: 0:20:56  Lr: 0.001875  Loss: 1.0469  Acc@1: 68.7500 (58.5401)  Acc@5: 100.0000 (93.6546)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 140/3750]  eta: 0:20:51  Lr: 0.001875  Loss: 0.8964  Acc@1: 68.7500 (59.5301)  Acc@5: 100.0000 (94.0160)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 150/3750]  eta: 0:20:47  Lr: 0.001875  Loss: 0.5809  Acc@1: 75.0000 (60.3477)  Acc@5: 100.0000 (94.2053)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 160/3750]  eta: 0:20:44  Lr: 0.001875  Loss: 0.9441  Acc@1: 68.7500 (60.8696)  Acc@5: 93.7500 (94.3323)  time: 0.3452  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 170/3750]  eta: 0:20:40  Lr: 0.001875  Loss: 1.2383  Acc@1: 68.7500 (61.5863)  Acc@5: 100.0000 (94.5175)  time: 0.3454  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:36  Lr: 0.001875  Loss: 0.9281  Acc@1: 75.0000 (62.3273)  Acc@5: 100.0000 (94.7514)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:32  Lr: 0.001875  Loss: 0.7408  Acc@1: 75.0000 (62.7945)  Acc@5: 100.0000 (94.8953)  time: 0.3452  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:29  Lr: 0.001875  Loss: 0.8790  Acc@1: 75.0000 (63.2774)  Acc@5: 100.0000 (95.1182)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:25  Lr: 0.001875  Loss: 0.8175  Acc@1: 75.0000 (63.5960)  Acc@5: 100.0000 (95.2607)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:21  Lr: 0.001875  Loss: 0.9521  Acc@1: 68.7500 (63.8009)  Acc@5: 100.0000 (95.3903)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:18  Lr: 0.001875  Loss: 1.0878  Acc@1: 68.7500 (63.9610)  Acc@5: 100.0000 (95.4545)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:14  Lr: 0.001875  Loss: 0.7976  Acc@1: 68.7500 (64.2376)  Acc@5: 100.0000 (95.5913)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:10  Lr: 0.001875  Loss: 0.6219  Acc@1: 68.7500 (64.6414)  Acc@5: 100.0000 (95.6424)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:07  Lr: 0.001875  Loss: 0.7732  Acc@1: 75.0000 (65.0383)  Acc@5: 93.7500 (95.6418)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:03  Lr: 0.001875  Loss: 0.9504  Acc@1: 68.7500 (65.1983)  Acc@5: 93.7500 (95.6873)  time: 0.3461  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:00  Lr: 0.001875  Loss: 1.1752  Acc@1: 68.7500 (65.5472)  Acc@5: 100.0000 (95.7740)  time: 0.3456  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 290/3750]  eta: 0:19:57  Lr: 0.001875  Loss: 0.6648  Acc@1: 75.0000 (65.7431)  Acc@5: 100.0000 (95.8333)  time: 0.3467  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 300/3750]  eta: 0:19:53  Lr: 0.001875  Loss: 1.0357  Acc@1: 75.0000 (65.9884)  Acc@5: 100.0000 (95.9302)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 310/3750]  eta: 0:19:50  Lr: 0.001875  Loss: 1.3888  Acc@1: 75.0000 (66.2982)  Acc@5: 100.0000 (95.9606)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 320/3750]  eta: 0:19:46  Lr: 0.001875  Loss: 0.7265  Acc@1: 75.0000 (66.5498)  Acc@5: 100.0000 (96.0086)  time: 0.3452  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 330/3750]  eta: 0:19:42  Lr: 0.001875  Loss: 1.2525  Acc@1: 68.7500 (66.5974)  Acc@5: 100.0000 (96.0725)  time: 0.3446  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:39  Lr: 0.001875  Loss: 0.7927  Acc@1: 68.7500 (66.6056)  Acc@5: 100.0000 (96.1327)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:35  Lr: 0.001875  Loss: 0.7204  Acc@1: 68.7500 (66.6311)  Acc@5: 100.0000 (96.2251)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:32  Lr: 0.001875  Loss: 0.7384  Acc@1: 68.7500 (66.7763)  Acc@5: 100.0000 (96.2084)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:28  Lr: 0.001875  Loss: 0.5703  Acc@1: 75.0000 (67.0148)  Acc@5: 93.7500 (96.2433)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:25  Lr: 0.001875  Loss: 0.6208  Acc@1: 68.7500 (67.0276)  Acc@5: 100.0000 (96.3091)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:21  Lr: 0.001875  Loss: 1.1201  Acc@1: 68.7500 (67.1835)  Acc@5: 100.0000 (96.3555)  time: 0.3456  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:18  Lr: 0.001875  Loss: 1.2360  Acc@1: 75.0000 (67.3317)  Acc@5: 100.0000 (96.4308)  time: 0.3449  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:14  Lr: 0.001875  Loss: 0.7166  Acc@1: 75.0000 (67.5182)  Acc@5: 100.0000 (96.5176)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:10  Lr: 0.001875  Loss: 0.9316  Acc@1: 75.0000 (67.5772)  Acc@5: 100.0000 (96.5113)  time: 0.3447  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:07  Lr: 0.001875  Loss: 1.0125  Acc@1: 68.7500 (67.5754)  Acc@5: 93.7500 (96.5052)  time: 0.3451  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:04  Lr: 0.001875  Loss: 0.9260  Acc@1: 68.7500 (67.6446)  Acc@5: 100.0000 (96.5420)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:00  Lr: 0.001875  Loss: 0.4575  Acc@1: 75.0000 (67.8769)  Acc@5: 100.0000 (96.5909)  time: 0.3463  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 460/3750]  eta: 0:18:57  Lr: 0.001875  Loss: 0.6558  Acc@1: 75.0000 (67.9908)  Acc@5: 100.0000 (96.6106)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 470/3750]  eta: 0:18:53  Lr: 0.001875  Loss: 0.9487  Acc@1: 75.0000 (68.0865)  Acc@5: 100.0000 (96.6561)  time: 0.3441  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [ 480/3750]  eta: 0:18:49  Lr: 0.001875  Loss: 0.9044  Acc@1: 75.0000 (68.1783)  Acc@5: 100.0000 (96.6996)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 490/3750]  eta: 0:18:46  Lr: 0.001875  Loss: 0.9065  Acc@1: 68.7500 (68.2663)  Acc@5: 100.0000 (96.7286)  time: 0.3449  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:43  Lr: 0.001875  Loss: 0.5093  Acc@1: 75.0000 (68.4381)  Acc@5: 100.0000 (96.7440)  time: 0.3457  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:39  Lr: 0.001875  Loss: 0.2646  Acc@1: 75.0000 (68.4687)  Acc@5: 100.0000 (96.7710)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:36  Lr: 0.001875  Loss: 0.5380  Acc@1: 75.0000 (68.6180)  Acc@5: 100.0000 (96.7850)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:32  Lr: 0.001875  Loss: 0.6370  Acc@1: 75.0000 (68.6558)  Acc@5: 100.0000 (96.8220)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:29  Lr: 0.001875  Loss: 0.8681  Acc@1: 68.7500 (68.7616)  Acc@5: 100.0000 (96.8577)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:25  Lr: 0.001875  Loss: 0.6607  Acc@1: 75.0000 (68.8634)  Acc@5: 100.0000 (96.8807)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:22  Lr: 0.001875  Loss: 0.9051  Acc@1: 68.7500 (68.8614)  Acc@5: 100.0000 (96.8917)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:18  Lr: 0.001875  Loss: 0.6568  Acc@1: 68.7500 (68.8704)  Acc@5: 100.0000 (96.9352)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:15  Lr: 0.001875  Loss: 0.8431  Acc@1: 75.0000 (69.0189)  Acc@5: 100.0000 (96.9342)  time: 0.3447  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:11  Lr: 0.001875  Loss: 0.6004  Acc@1: 75.0000 (69.1519)  Acc@5: 100.0000 (96.9332)  time: 0.3441  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:08  Lr: 0.001875  Loss: 0.9658  Acc@1: 75.0000 (69.3116)  Acc@5: 100.0000 (96.9738)  time: 0.3445  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:04  Lr: 0.001875  Loss: 1.0159  Acc@1: 75.0000 (69.4149)  Acc@5: 100.0000 (97.0029)  time: 0.3448  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:01  Lr: 0.001875  Loss: 0.7604  Acc@1: 75.0000 (69.4746)  Acc@5: 100.0000 (97.0109)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 630/3750]  eta: 0:17:57  Lr: 0.001875  Loss: 0.6226  Acc@1: 75.0000 (69.4929)  Acc@5: 100.0000 (97.0285)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 640/3750]  eta: 0:17:53  Lr: 0.001875  Loss: 0.7256  Acc@1: 68.7500 (69.5008)  Acc@5: 100.0000 (97.0066)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 650/3750]  eta: 0:17:50  Lr: 0.001875  Loss: 1.0866  Acc@1: 68.7500 (69.4988)  Acc@5: 100.0000 (97.0334)  time: 0.3454  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 660/3750]  eta: 0:17:46  Lr: 0.001875  Loss: 1.0237  Acc@1: 75.0000 (69.5348)  Acc@5: 100.0000 (97.0216)  time: 0.3445  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:43  Lr: 0.001875  Loss: 0.8823  Acc@1: 68.7500 (69.5604)  Acc@5: 100.0000 (97.0380)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:40  Lr: 0.001875  Loss: 0.6161  Acc@1: 68.7500 (69.5943)  Acc@5: 100.0000 (97.0631)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:36  Lr: 0.001875  Loss: 0.7569  Acc@1: 68.7500 (69.6274)  Acc@5: 100.0000 (97.0785)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:33  Lr: 0.001875  Loss: 1.0087  Acc@1: 68.7500 (69.6951)  Acc@5: 93.7500 (97.0399)  time: 0.3448  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:29  Lr: 0.001875  Loss: 1.0513  Acc@1: 75.0000 (69.8136)  Acc@5: 100.0000 (97.0640)  time: 0.3451  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:26  Lr: 0.001875  Loss: 0.4281  Acc@1: 75.0000 (69.8509)  Acc@5: 100.0000 (97.0960)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:22  Lr: 0.001875  Loss: 0.8163  Acc@1: 68.7500 (69.8786)  Acc@5: 100.0000 (97.1272)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:19  Lr: 0.001875  Loss: 0.5002  Acc@1: 75.0000 (69.9393)  Acc@5: 100.0000 (97.1491)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:15  Lr: 0.001875  Loss: 1.1973  Acc@1: 75.0000 (69.9318)  Acc@5: 100.0000 (97.1455)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:12  Lr: 0.001875  Loss: 0.7389  Acc@1: 75.0000 (70.0476)  Acc@5: 100.0000 (97.1666)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:08  Lr: 0.001875  Loss: 0.3597  Acc@1: 81.2500 (70.1362)  Acc@5: 100.0000 (97.1871)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:05  Lr: 0.001875  Loss: 0.4940  Acc@1: 68.7500 (70.1424)  Acc@5: 100.0000 (97.1991)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.001875  Loss: 1.1120  Acc@1: 68.7500 (70.1406)  Acc@5: 100.0000 (97.2187)  time: 0.3450  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 800/3750]  eta: 0:16:58  Lr: 0.001875  Loss: 0.5323  Acc@1: 75.0000 (70.2325)  Acc@5: 100.0000 (97.2222)  time: 0.3454  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.001875  Loss: 1.1008  Acc@1: 68.7500 (70.2374)  Acc@5: 100.0000 (97.2334)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 820/3750]  eta: 0:16:51  Lr: 0.001875  Loss: 0.4062  Acc@1: 75.0000 (70.3410)  Acc@5: 100.0000 (97.2518)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 830/3750]  eta: 0:16:48  Lr: 0.001875  Loss: 0.6807  Acc@1: 75.0000 (70.3896)  Acc@5: 100.0000 (97.2548)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:44  Lr: 0.001875  Loss: 0.6979  Acc@1: 75.0000 (70.4295)  Acc@5: 100.0000 (97.2503)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:41  Lr: 0.001875  Loss: 0.4181  Acc@1: 75.0000 (70.5053)  Acc@5: 100.0000 (97.2532)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:37  Lr: 0.001875  Loss: 0.8027  Acc@1: 75.0000 (70.5502)  Acc@5: 100.0000 (97.2634)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:34  Lr: 0.001875  Loss: 0.6678  Acc@1: 75.0000 (70.6013)  Acc@5: 100.0000 (97.2732)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.001875  Loss: 0.8208  Acc@1: 75.0000 (70.5803)  Acc@5: 100.0000 (97.2687)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:27  Lr: 0.001875  Loss: 0.8844  Acc@1: 75.0000 (70.6650)  Acc@5: 100.0000 (97.2783)  time: 0.3468  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:24  Lr: 0.001875  Loss: 0.5377  Acc@1: 81.2500 (70.7200)  Acc@5: 100.0000 (97.2739)  time: 0.3463  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:20  Lr: 0.001875  Loss: 0.4463  Acc@1: 75.0000 (70.7602)  Acc@5: 100.0000 (97.2832)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:17  Lr: 0.001875  Loss: 0.8697  Acc@1: 75.0000 (70.7858)  Acc@5: 100.0000 (97.2991)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:13  Lr: 0.001875  Loss: 0.8851  Acc@1: 75.0000 (70.8445)  Acc@5: 100.0000 (97.3147)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:10  Lr: 0.001875  Loss: 0.2577  Acc@1: 75.0000 (70.9152)  Acc@5: 100.0000 (97.3366)  time: 0.3430  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:06  Lr: 0.001875  Loss: 1.1406  Acc@1: 75.0000 (70.9451)  Acc@5: 100.0000 (97.3449)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:03  Lr: 0.001875  Loss: 1.2880  Acc@1: 75.0000 (71.0263)  Acc@5: 100.0000 (97.3725)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 970/3750]  eta: 0:15:59  Lr: 0.001875  Loss: 0.2971  Acc@1: 75.0000 (71.1058)  Acc@5: 100.0000 (97.3867)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 980/3750]  eta: 0:15:56  Lr: 0.001875  Loss: 0.4642  Acc@1: 75.0000 (71.1710)  Acc@5: 100.0000 (97.4070)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 990/3750]  eta: 0:15:52  Lr: 0.001875  Loss: 0.5410  Acc@1: 81.2500 (71.2538)  Acc@5: 100.0000 (97.4268)  time: 0.3444  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1000/3750]  eta: 0:15:49  Lr: 0.001875  Loss: 0.3936  Acc@1: 81.2500 (71.3474)  Acc@5: 100.0000 (97.4463)  time: 0.3441  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:45  Lr: 0.001875  Loss: 0.4720  Acc@1: 75.0000 (71.3773)  Acc@5: 100.0000 (97.4716)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:42  Lr: 0.001875  Loss: 0.3641  Acc@1: 75.0000 (71.4006)  Acc@5: 100.0000 (97.4841)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:38  Lr: 0.001875  Loss: 0.3566  Acc@1: 68.7500 (71.3991)  Acc@5: 100.0000 (97.4964)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:35  Lr: 0.001875  Loss: 0.6783  Acc@1: 68.7500 (71.3857)  Acc@5: 100.0000 (97.5024)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:31  Lr: 0.001875  Loss: 0.6641  Acc@1: 75.0000 (71.4498)  Acc@5: 100.0000 (97.5202)  time: 0.3448  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:28  Lr: 0.001875  Loss: 0.4203  Acc@1: 81.2500 (71.5245)  Acc@5: 100.0000 (97.5318)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:25  Lr: 0.001875  Loss: 0.5715  Acc@1: 81.2500 (71.6270)  Acc@5: 100.0000 (97.5490)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:21  Lr: 0.001875  Loss: 0.8468  Acc@1: 75.0000 (71.6813)  Acc@5: 100.0000 (97.5486)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:18  Lr: 0.001875  Loss: 1.1051  Acc@1: 75.0000 (71.7518)  Acc@5: 100.0000 (97.5596)  time: 0.3445  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:14  Lr: 0.001875  Loss: 0.5104  Acc@1: 75.0000 (71.7870)  Acc@5: 100.0000 (97.5647)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:11  Lr: 0.001875  Loss: 0.3002  Acc@1: 81.2500 (71.8666)  Acc@5: 100.0000 (97.5754)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:07  Lr: 0.001875  Loss: 0.6407  Acc@1: 81.2500 (71.9391)  Acc@5: 100.0000 (97.5691)  time: 0.3441  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:04  Lr: 0.001875  Loss: 0.6653  Acc@1: 75.0000 (71.9607)  Acc@5: 100.0000 (97.5851)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:00  Lr: 0.001875  Loss: 0.4945  Acc@1: 75.0000 (71.9654)  Acc@5: 100.0000 (97.5898)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1150/3750]  eta: 0:14:57  Lr: 0.001875  Loss: 0.3344  Acc@1: 75.0000 (72.0243)  Acc@5: 100.0000 (97.5891)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1160/3750]  eta: 0:14:53  Lr: 0.001875  Loss: 0.3688  Acc@1: 75.0000 (72.0984)  Acc@5: 100.0000 (97.6044)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1170/3750]  eta: 0:14:50  Lr: 0.001875  Loss: 0.6865  Acc@1: 81.2500 (72.1392)  Acc@5: 100.0000 (97.6196)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:47  Lr: 0.001875  Loss: 0.4689  Acc@1: 75.0000 (72.1105)  Acc@5: 100.0000 (97.6291)  time: 0.3457  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:43  Lr: 0.001875  Loss: 0.2371  Acc@1: 75.0000 (72.1820)  Acc@5: 100.0000 (97.6280)  time: 0.3470  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:40  Lr: 0.001875  Loss: 0.4425  Acc@1: 75.0000 (72.2055)  Acc@5: 100.0000 (97.6426)  time: 0.3477  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:36  Lr: 0.001875  Loss: 0.7085  Acc@1: 75.0000 (72.1976)  Acc@5: 100.0000 (97.6156)  time: 0.3461  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:33  Lr: 0.001875  Loss: 0.7387  Acc@1: 75.0000 (72.2000)  Acc@5: 100.0000 (97.6147)  time: 0.3454  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:29  Lr: 0.001875  Loss: 1.1707  Acc@1: 75.0000 (72.1974)  Acc@5: 100.0000 (97.6036)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:26  Lr: 0.001875  Loss: 0.3139  Acc@1: 75.0000 (72.2603)  Acc@5: 100.0000 (97.6229)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:23  Lr: 0.001875  Loss: 0.9707  Acc@1: 81.2500 (72.2872)  Acc@5: 100.0000 (97.6269)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:19  Lr: 0.001875  Loss: 0.9825  Acc@1: 75.0000 (72.3186)  Acc@5: 100.0000 (97.6259)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:16  Lr: 0.001875  Loss: 0.6446  Acc@1: 81.2500 (72.3987)  Acc@5: 100.0000 (97.6347)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:12  Lr: 0.001875  Loss: 0.5015  Acc@1: 81.2500 (72.4483)  Acc@5: 100.0000 (97.6386)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:09  Lr: 0.001875  Loss: 0.3241  Acc@1: 81.2500 (72.5213)  Acc@5: 100.0000 (97.6520)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:05  Lr: 0.001875  Loss: 0.2126  Acc@1: 81.2500 (72.5884)  Acc@5: 100.0000 (97.6653)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:02  Lr: 0.001875  Loss: 0.3257  Acc@1: 81.2500 (72.6068)  Acc@5: 100.0000 (97.6735)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1320/3750]  eta: 0:13:58  Lr: 0.001875  Loss: 0.8778  Acc@1: 75.0000 (72.6012)  Acc@5: 100.0000 (97.6769)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1330/3750]  eta: 0:13:55  Lr: 0.001875  Loss: 0.5730  Acc@1: 68.7500 (72.5911)  Acc@5: 100.0000 (97.6615)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1340/3750]  eta: 0:13:51  Lr: 0.001875  Loss: 0.4066  Acc@1: 75.0000 (72.6277)  Acc@5: 100.0000 (97.6650)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:48  Lr: 0.001875  Loss: 0.7006  Acc@1: 75.0000 (72.6638)  Acc@5: 100.0000 (97.6591)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:44  Lr: 0.001875  Loss: 0.5629  Acc@1: 75.0000 (72.7039)  Acc@5: 100.0000 (97.6763)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:41  Lr: 0.001875  Loss: 0.9901  Acc@1: 75.0000 (72.7161)  Acc@5: 100.0000 (97.6751)  time: 0.3451  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:38  Lr: 0.001875  Loss: 0.8937  Acc@1: 75.0000 (72.7371)  Acc@5: 100.0000 (97.6919)  time: 0.3456  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:34  Lr: 0.001875  Loss: 0.8879  Acc@1: 75.0000 (72.7220)  Acc@5: 100.0000 (97.6950)  time: 0.3465  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:31  Lr: 0.001875  Loss: 0.7740  Acc@1: 68.7500 (72.7293)  Acc@5: 100.0000 (97.7070)  time: 0.3456  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:27  Lr: 0.001875  Loss: 0.9800  Acc@1: 75.0000 (72.7720)  Acc@5: 100.0000 (97.7232)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:24  Lr: 0.001875  Loss: 0.3336  Acc@1: 75.0000 (72.7833)  Acc@5: 100.0000 (97.7261)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:20  Lr: 0.001875  Loss: 0.5331  Acc@1: 75.0000 (72.8162)  Acc@5: 100.0000 (97.7332)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:17  Lr: 0.001875  Loss: 1.5771  Acc@1: 75.0000 (72.7880)  Acc@5: 100.0000 (97.7359)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:13  Lr: 0.001875  Loss: 0.6224  Acc@1: 75.0000 (72.8463)  Acc@5: 100.0000 (97.7343)  time: 0.3455  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:10  Lr: 0.001875  Loss: 0.5913  Acc@1: 75.0000 (72.8653)  Acc@5: 100.0000 (97.7327)  time: 0.3462  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:07  Lr: 0.001875  Loss: 0.5602  Acc@1: 75.0000 (72.8841)  Acc@5: 100.0000 (97.7396)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:03  Lr: 0.001875  Loss: 1.1334  Acc@1: 75.0000 (72.9026)  Acc@5: 100.0000 (97.7380)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:00  Lr: 0.001875  Loss: 0.8397  Acc@1: 75.0000 (72.9376)  Acc@5: 100.0000 (97.7532)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1500/3750]  eta: 0:12:56  Lr: 0.001875  Loss: 0.6210  Acc@1: 75.0000 (72.9514)  Acc@5: 100.0000 (97.7598)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1510/3750]  eta: 0:12:53  Lr: 0.001875  Loss: 0.7802  Acc@1: 75.0000 (72.9442)  Acc@5: 100.0000 (97.7664)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1520/3750]  eta: 0:12:49  Lr: 0.001875  Loss: 0.7698  Acc@1: 75.0000 (72.9783)  Acc@5: 100.0000 (97.7687)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:46  Lr: 0.001875  Loss: 0.8113  Acc@1: 81.2500 (73.0446)  Acc@5: 100.0000 (97.7711)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:42  Lr: 0.001875  Loss: 0.9280  Acc@1: 81.2500 (73.0654)  Acc@5: 100.0000 (97.7693)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:39  Lr: 0.001875  Loss: 0.5693  Acc@1: 81.2500 (73.1061)  Acc@5: 100.0000 (97.7756)  time: 0.3461  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:36  Lr: 0.001875  Loss: 0.6996  Acc@1: 81.2500 (73.1382)  Acc@5: 100.0000 (97.7819)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:32  Lr: 0.001875  Loss: 0.7616  Acc@1: 81.2500 (73.1739)  Acc@5: 100.0000 (97.7960)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:29  Lr: 0.001875  Loss: 0.7286  Acc@1: 81.2500 (73.2013)  Acc@5: 100.0000 (97.7981)  time: 0.3452  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:25  Lr: 0.001875  Loss: 0.3943  Acc@1: 75.0000 (73.2087)  Acc@5: 100.0000 (97.8041)  time: 0.3443  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:22  Lr: 0.001875  Loss: 0.3497  Acc@1: 75.0000 (73.2472)  Acc@5: 100.0000 (97.8178)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:18  Lr: 0.001875  Loss: 0.7805  Acc@1: 75.0000 (73.2619)  Acc@5: 100.0000 (97.8119)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:15  Lr: 0.001875  Loss: 1.0402  Acc@1: 75.0000 (73.2534)  Acc@5: 100.0000 (97.8177)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:11  Lr: 0.001875  Loss: 0.3728  Acc@1: 75.0000 (73.2833)  Acc@5: 100.0000 (97.8196)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:08  Lr: 0.001875  Loss: 1.2251  Acc@1: 75.0000 (73.3166)  Acc@5: 100.0000 (97.8215)  time: 0.3453  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:04  Lr: 0.001875  Loss: 0.3524  Acc@1: 81.2500 (73.3646)  Acc@5: 100.0000 (97.8271)  time: 0.3451  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:01  Lr: 0.001875  Loss: 0.5499  Acc@1: 81.2500 (73.4008)  Acc@5: 100.0000 (97.8289)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1670/3750]  eta: 0:11:58  Lr: 0.001875  Loss: 0.3935  Acc@1: 81.2500 (73.4141)  Acc@5: 100.0000 (97.8344)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1680/3750]  eta: 0:11:54  Lr: 0.001875  Loss: 0.6026  Acc@1: 75.0000 (73.4533)  Acc@5: 100.0000 (97.8435)  time: 0.3448  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1690/3750]  eta: 0:11:51  Lr: 0.001875  Loss: 0.5200  Acc@1: 75.0000 (73.4846)  Acc@5: 100.0000 (97.8489)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:47  Lr: 0.001875  Loss: 0.4573  Acc@1: 81.2500 (73.5560)  Acc@5: 100.0000 (97.8616)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:44  Lr: 0.001875  Loss: 0.5160  Acc@1: 81.2500 (73.5827)  Acc@5: 100.0000 (97.8704)  time: 0.3454  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:40  Lr: 0.001875  Loss: 1.0016  Acc@1: 81.2500 (73.6273)  Acc@5: 100.0000 (97.8755)  time: 0.3456  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:37  Lr: 0.001875  Loss: 0.7745  Acc@1: 81.2500 (73.6532)  Acc@5: 100.0000 (97.8697)  time: 0.3445  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:33  Lr: 0.001875  Loss: 0.6523  Acc@1: 75.0000 (73.6897)  Acc@5: 100.0000 (97.8784)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:30  Lr: 0.001875  Loss: 0.9521  Acc@1: 81.2500 (73.7329)  Acc@5: 100.0000 (97.8798)  time: 0.3441  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:26  Lr: 0.001875  Loss: 1.0297  Acc@1: 81.2500 (73.7649)  Acc@5: 100.0000 (97.8847)  time: 0.3447  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:23  Lr: 0.001875  Loss: 0.5774  Acc@1: 81.2500 (73.7789)  Acc@5: 100.0000 (97.8826)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:19  Lr: 0.001875  Loss: 0.6291  Acc@1: 75.0000 (73.7612)  Acc@5: 100.0000 (97.8804)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:16  Lr: 0.001875  Loss: 0.6307  Acc@1: 68.7500 (73.7332)  Acc@5: 100.0000 (97.8818)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:13  Lr: 0.001875  Loss: 0.8135  Acc@1: 68.7500 (73.7333)  Acc@5: 100.0000 (97.8901)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:09  Lr: 0.001875  Loss: 0.7818  Acc@1: 68.7500 (73.7369)  Acc@5: 100.0000 (97.9017)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:06  Lr: 0.001875  Loss: 0.4534  Acc@1: 75.0000 (73.7438)  Acc@5: 100.0000 (97.9098)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:02  Lr: 0.001875  Loss: 0.7670  Acc@1: 75.0000 (73.7643)  Acc@5: 100.0000 (97.9178)  time: 0.3451  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1840/3750]  eta: 0:10:59  Lr: 0.001875  Loss: 0.2622  Acc@1: 75.0000 (73.7982)  Acc@5: 100.0000 (97.9155)  time: 0.3463  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1850/3750]  eta: 0:10:55  Lr: 0.001875  Loss: 0.5292  Acc@1: 75.0000 (73.7811)  Acc@5: 100.0000 (97.8998)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1860/3750]  eta: 0:10:52  Lr: 0.001875  Loss: 0.6916  Acc@1: 75.0000 (73.8178)  Acc@5: 100.0000 (97.9010)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:48  Lr: 0.001875  Loss: 0.2299  Acc@1: 81.2500 (73.8475)  Acc@5: 100.0000 (97.9055)  time: 0.3430  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:45  Lr: 0.001875  Loss: 0.8223  Acc@1: 75.0000 (73.8470)  Acc@5: 100.0000 (97.9034)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:42  Lr: 0.001875  Loss: 0.5786  Acc@1: 75.0000 (73.8730)  Acc@5: 100.0000 (97.9079)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:38  Lr: 0.001875  Loss: 0.4210  Acc@1: 81.2500 (73.9019)  Acc@5: 100.0000 (97.9156)  time: 0.3449  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:35  Lr: 0.001875  Loss: 0.2828  Acc@1: 75.0000 (73.9044)  Acc@5: 100.0000 (97.9199)  time: 0.3442  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:31  Lr: 0.001875  Loss: 0.8753  Acc@1: 75.0000 (73.9328)  Acc@5: 100.0000 (97.9243)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:28  Lr: 0.001875  Loss: 0.3959  Acc@1: 81.2500 (73.9675)  Acc@5: 100.0000 (97.9285)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:24  Lr: 0.001875  Loss: 0.6442  Acc@1: 81.2500 (73.9760)  Acc@5: 100.0000 (97.9263)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:21  Lr: 0.001875  Loss: 0.5627  Acc@1: 75.0000 (73.9685)  Acc@5: 100.0000 (97.9241)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:17  Lr: 0.001875  Loss: 0.2318  Acc@1: 75.0000 (73.9897)  Acc@5: 100.0000 (97.9315)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:14  Lr: 0.001875  Loss: 0.6022  Acc@1: 81.2500 (74.0138)  Acc@5: 100.0000 (97.9325)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:10  Lr: 0.001875  Loss: 0.5424  Acc@1: 81.2500 (74.0440)  Acc@5: 100.0000 (97.9303)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:07  Lr: 0.001875  Loss: 0.8836  Acc@1: 81.2500 (74.0614)  Acc@5: 100.0000 (97.9313)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:03  Lr: 0.001875  Loss: 0.3006  Acc@1: 75.0000 (74.0630)  Acc@5: 100.0000 (97.9354)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:00  Lr: 0.001875  Loss: 0.4999  Acc@1: 75.0000 (74.1049)  Acc@5: 100.0000 (97.9457)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2020/3750]  eta: 0:09:57  Lr: 0.001875  Loss: 0.5866  Acc@1: 81.2500 (74.1279)  Acc@5: 100.0000 (97.9497)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2030/3750]  eta: 0:09:53  Lr: 0.001875  Loss: 0.9385  Acc@1: 75.0000 (74.1476)  Acc@5: 100.0000 (97.9567)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:50  Lr: 0.001875  Loss: 0.7338  Acc@1: 75.0000 (74.1548)  Acc@5: 100.0000 (97.9606)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:46  Lr: 0.001875  Loss: 0.6524  Acc@1: 75.0000 (74.1742)  Acc@5: 100.0000 (97.9644)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:43  Lr: 0.001875  Loss: 0.9321  Acc@1: 75.0000 (74.1600)  Acc@5: 100.0000 (97.9591)  time: 0.3445  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:39  Lr: 0.001875  Loss: 0.6348  Acc@1: 75.0000 (74.2003)  Acc@5: 100.0000 (97.9629)  time: 0.3450  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:36  Lr: 0.001875  Loss: 0.6963  Acc@1: 81.2500 (74.2221)  Acc@5: 100.0000 (97.9697)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:32  Lr: 0.001875  Loss: 0.9623  Acc@1: 81.2500 (74.2378)  Acc@5: 100.0000 (97.9705)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:29  Lr: 0.001875  Loss: 0.3667  Acc@1: 81.2500 (74.2801)  Acc@5: 100.0000 (97.9712)  time: 0.3455  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:25  Lr: 0.001875  Loss: 0.9609  Acc@1: 81.2500 (74.3102)  Acc@5: 100.0000 (97.9779)  time: 0.3449  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:22  Lr: 0.001875  Loss: 0.5596  Acc@1: 81.2500 (74.3340)  Acc@5: 100.0000 (97.9815)  time: 0.3450  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:19  Lr: 0.001875  Loss: 0.4026  Acc@1: 81.2500 (74.3577)  Acc@5: 100.0000 (97.9880)  time: 0.3456  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:15  Lr: 0.001875  Loss: 1.1520  Acc@1: 75.0000 (74.3461)  Acc@5: 100.0000 (97.9887)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:12  Lr: 0.001875  Loss: 0.5105  Acc@1: 75.0000 (74.3869)  Acc@5: 100.0000 (97.9980)  time: 0.3452  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:08  Lr: 0.001875  Loss: 0.5747  Acc@1: 75.0000 (74.3984)  Acc@5: 100.0000 (97.9986)  time: 0.3459  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:05  Lr: 0.001875  Loss: 0.2645  Acc@1: 75.0000 (74.4213)  Acc@5: 100.0000 (97.9963)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:01  Lr: 0.001875  Loss: 0.5221  Acc@1: 75.0000 (74.4068)  Acc@5: 100.0000 (98.0055)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2190/3750]  eta: 0:08:58  Lr: 0.001875  Loss: 0.5792  Acc@1: 81.2500 (74.4409)  Acc@5: 100.0000 (98.0146)  time: 0.3438  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2200/3750]  eta: 0:08:54  Lr: 0.001875  Loss: 0.2880  Acc@1: 81.2500 (74.4605)  Acc@5: 100.0000 (98.0179)  time: 0.3439  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:51  Lr: 0.001875  Loss: 0.6059  Acc@1: 75.0000 (74.4799)  Acc@5: 100.0000 (98.0184)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:47  Lr: 0.001875  Loss: 0.6042  Acc@1: 81.2500 (74.5047)  Acc@5: 100.0000 (98.0274)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:44  Lr: 0.001875  Loss: 0.5920  Acc@1: 81.2500 (74.5406)  Acc@5: 100.0000 (98.0306)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:41  Lr: 0.001875  Loss: 0.4293  Acc@1: 81.2500 (74.5621)  Acc@5: 100.0000 (98.0310)  time: 0.3461  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:37  Lr: 0.001875  Loss: 0.7909  Acc@1: 75.0000 (74.5752)  Acc@5: 100.0000 (98.0398)  time: 0.3461  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:34  Lr: 0.001875  Loss: 0.6602  Acc@1: 81.2500 (74.6047)  Acc@5: 100.0000 (98.0457)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:30  Lr: 0.001875  Loss: 0.8325  Acc@1: 81.2500 (74.6120)  Acc@5: 100.0000 (98.0515)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:27  Lr: 0.001875  Loss: 0.7301  Acc@1: 75.0000 (74.6164)  Acc@5: 100.0000 (98.0464)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:23  Lr: 0.001875  Loss: 0.6244  Acc@1: 75.0000 (74.6263)  Acc@5: 100.0000 (98.0522)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:20  Lr: 0.001875  Loss: 0.3315  Acc@1: 81.2500 (74.6605)  Acc@5: 100.0000 (98.0552)  time: 0.3443  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:16  Lr: 0.001875  Loss: 0.4266  Acc@1: 81.2500 (74.6728)  Acc@5: 100.0000 (98.0636)  time: 0.3446  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:13  Lr: 0.001875  Loss: 0.5303  Acc@1: 81.2500 (74.7146)  Acc@5: 100.0000 (98.0693)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:10  Lr: 0.001875  Loss: 0.2049  Acc@1: 81.2500 (74.7426)  Acc@5: 100.0000 (98.0722)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:06  Lr: 0.001875  Loss: 0.6862  Acc@1: 75.0000 (74.7384)  Acc@5: 100.0000 (98.0751)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:03  Lr: 0.001875  Loss: 0.6128  Acc@1: 75.0000 (74.7554)  Acc@5: 100.0000 (98.0806)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2360/3750]  eta: 0:07:59  Lr: 0.001875  Loss: 0.8113  Acc@1: 81.2500 (74.7750)  Acc@5: 100.0000 (98.0808)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2370/3750]  eta: 0:07:56  Lr: 0.001875  Loss: 0.7584  Acc@1: 81.2500 (74.7865)  Acc@5: 100.0000 (98.0810)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:52  Lr: 0.001875  Loss: 0.4591  Acc@1: 81.2500 (74.8084)  Acc@5: 100.0000 (98.0812)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:49  Lr: 0.001875  Loss: 0.3670  Acc@1: 81.2500 (74.8196)  Acc@5: 100.0000 (98.0840)  time: 0.3452  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:45  Lr: 0.001875  Loss: 0.6319  Acc@1: 75.0000 (74.8308)  Acc@5: 100.0000 (98.0893)  time: 0.3454  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:42  Lr: 0.001875  Loss: 0.4546  Acc@1: 81.2500 (74.8574)  Acc@5: 100.0000 (98.0947)  time: 0.3464  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:38  Lr: 0.001875  Loss: 0.7389  Acc@1: 81.2500 (74.8864)  Acc@5: 100.0000 (98.1000)  time: 0.3463  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:35  Lr: 0.001875  Loss: 0.8489  Acc@1: 81.2500 (74.9126)  Acc@5: 100.0000 (98.1001)  time: 0.3449  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:32  Lr: 0.001875  Loss: 0.6240  Acc@1: 81.2500 (74.9283)  Acc@5: 100.0000 (98.1027)  time: 0.3448  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:28  Lr: 0.001875  Loss: 0.3353  Acc@1: 81.2500 (74.9618)  Acc@5: 100.0000 (98.1105)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:25  Lr: 0.001875  Loss: 0.3622  Acc@1: 81.2500 (74.9619)  Acc@5: 100.0000 (98.1105)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:21  Lr: 0.001875  Loss: 0.2244  Acc@1: 81.2500 (74.9899)  Acc@5: 100.0000 (98.1106)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:18  Lr: 0.001875  Loss: 0.3724  Acc@1: 81.2500 (75.0151)  Acc@5: 100.0000 (98.1182)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:14  Lr: 0.001875  Loss: 1.2051  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (98.1232)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:11  Lr: 0.001875  Loss: 1.0195  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (98.1233)  time: 0.3446  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:07  Lr: 0.001875  Loss: 0.6838  Acc@1: 81.2500 (75.0174)  Acc@5: 100.0000 (98.1282)  time: 0.3443  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:04  Lr: 0.001875  Loss: 0.5159  Acc@1: 81.2500 (75.0471)  Acc@5: 100.0000 (98.1307)  time: 0.3444  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:00  Lr: 0.001875  Loss: 0.4880  Acc@1: 81.2500 (75.0568)  Acc@5: 100.0000 (98.1307)  time: 0.3447  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2540/3750]  eta: 0:06:57  Lr: 0.001875  Loss: 0.9448  Acc@1: 81.2500 (75.0787)  Acc@5: 100.0000 (98.1307)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:54  Lr: 0.001875  Loss: 0.8692  Acc@1: 81.2500 (75.0882)  Acc@5: 100.0000 (98.1306)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:50  Lr: 0.001875  Loss: 0.4834  Acc@1: 81.2500 (75.1147)  Acc@5: 100.0000 (98.1331)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:47  Lr: 0.001875  Loss: 0.7176  Acc@1: 81.2500 (75.1483)  Acc@5: 100.0000 (98.1330)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:43  Lr: 0.001875  Loss: 0.5850  Acc@1: 75.0000 (75.1404)  Acc@5: 100.0000 (98.1378)  time: 0.3431  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:40  Lr: 0.001875  Loss: 0.3653  Acc@1: 75.0000 (75.1544)  Acc@5: 100.0000 (98.1305)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:36  Lr: 0.001875  Loss: 0.5792  Acc@1: 75.0000 (75.1538)  Acc@5: 100.0000 (98.1329)  time: 0.3470  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:33  Lr: 0.001875  Loss: 0.7235  Acc@1: 75.0000 (75.1556)  Acc@5: 100.0000 (98.1353)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:29  Lr: 0.001875  Loss: 1.0502  Acc@1: 75.0000 (75.1693)  Acc@5: 100.0000 (98.1400)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:26  Lr: 0.001875  Loss: 0.5562  Acc@1: 75.0000 (75.1710)  Acc@5: 100.0000 (98.1400)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:22  Lr: 0.001875  Loss: 0.5618  Acc@1: 75.0000 (75.1799)  Acc@5: 100.0000 (98.1352)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:19  Lr: 0.001875  Loss: 0.4580  Acc@1: 81.2500 (75.2216)  Acc@5: 100.0000 (98.1422)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:16  Lr: 0.001875  Loss: 0.6641  Acc@1: 75.0000 (75.1949)  Acc@5: 100.0000 (98.1468)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:12  Lr: 0.001875  Loss: 0.5285  Acc@1: 75.0000 (75.1895)  Acc@5: 100.0000 (98.1491)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:09  Lr: 0.001875  Loss: 0.8136  Acc@1: 75.0000 (75.1818)  Acc@5: 100.0000 (98.1537)  time: 0.3443  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:05  Lr: 0.001875  Loss: 0.9263  Acc@1: 75.0000 (75.1858)  Acc@5: 100.0000 (98.1582)  time: 0.3435  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:02  Lr: 0.001875  Loss: 0.8332  Acc@1: 75.0000 (75.2036)  Acc@5: 100.0000 (98.1604)  time: 0.3451  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2710/3750]  eta: 0:05:58  Lr: 0.001875  Loss: 0.7711  Acc@1: 81.2500 (75.2098)  Acc@5: 100.0000 (98.1626)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2720/3750]  eta: 0:05:55  Lr: 0.001875  Loss: 0.4812  Acc@1: 75.0000 (75.1929)  Acc@5: 100.0000 (98.1647)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:51  Lr: 0.001875  Loss: 0.4965  Acc@1: 81.2500 (75.2266)  Acc@5: 100.0000 (98.1669)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:48  Lr: 0.001875  Loss: 1.1554  Acc@1: 81.2500 (75.2371)  Acc@5: 100.0000 (98.1690)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:45  Lr: 0.001875  Loss: 0.3145  Acc@1: 81.2500 (75.2499)  Acc@5: 100.0000 (98.1688)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:41  Lr: 0.001875  Loss: 0.5043  Acc@1: 81.2500 (75.2648)  Acc@5: 100.0000 (98.1710)  time: 0.3441  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:38  Lr: 0.001875  Loss: 0.4129  Acc@1: 81.2500 (75.2752)  Acc@5: 100.0000 (98.1708)  time: 0.3445  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:34  Lr: 0.001875  Loss: 0.5902  Acc@1: 81.2500 (75.2899)  Acc@5: 100.0000 (98.1751)  time: 0.3446  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:31  Lr: 0.001875  Loss: 1.3245  Acc@1: 75.0000 (75.2934)  Acc@5: 100.0000 (98.1705)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:27  Lr: 0.001875  Loss: 0.4001  Acc@1: 81.2500 (75.3146)  Acc@5: 100.0000 (98.1725)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:24  Lr: 0.001875  Loss: 0.5661  Acc@1: 81.2500 (75.3469)  Acc@5: 100.0000 (98.1768)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:20  Lr: 0.001875  Loss: 0.7859  Acc@1: 81.2500 (75.3700)  Acc@5: 100.0000 (98.1788)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:17  Lr: 0.001875  Loss: 0.4028  Acc@1: 81.2500 (75.3731)  Acc@5: 100.0000 (98.1831)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:13  Lr: 0.001875  Loss: 0.3441  Acc@1: 81.2500 (75.4158)  Acc@5: 100.0000 (98.1851)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:10  Lr: 0.001875  Loss: 0.2121  Acc@1: 87.5000 (75.4450)  Acc@5: 100.0000 (98.1892)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:07  Lr: 0.001875  Loss: 0.2481  Acc@1: 81.2500 (75.4500)  Acc@5: 100.0000 (98.1934)  time: 0.3449  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:03  Lr: 0.001875  Loss: 0.7836  Acc@1: 81.2500 (75.4724)  Acc@5: 100.0000 (98.1931)  time: 0.3454  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:00  Lr: 0.001875  Loss: 0.5406  Acc@1: 81.2500 (75.4642)  Acc@5: 100.0000 (98.1929)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2890/3750]  eta: 0:04:56  Lr: 0.001875  Loss: 0.2784  Acc@1: 81.2500 (75.4799)  Acc@5: 100.0000 (98.1948)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:53  Lr: 0.001875  Loss: 0.8381  Acc@1: 75.0000 (75.4675)  Acc@5: 100.0000 (98.2011)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:49  Lr: 0.001875  Loss: 0.1096  Acc@1: 75.0000 (75.4766)  Acc@5: 100.0000 (98.1965)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:46  Lr: 0.001875  Loss: 0.7167  Acc@1: 81.2500 (75.4943)  Acc@5: 100.0000 (98.1984)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:42  Lr: 0.001875  Loss: 0.4608  Acc@1: 81.2500 (75.5075)  Acc@5: 100.0000 (98.1981)  time: 0.3443  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:39  Lr: 0.001875  Loss: 0.7547  Acc@1: 81.2500 (75.5228)  Acc@5: 100.0000 (98.2000)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:35  Lr: 0.001875  Loss: 0.6642  Acc@1: 75.0000 (75.5147)  Acc@5: 100.0000 (98.1998)  time: 0.3445  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:32  Lr: 0.001875  Loss: 0.2790  Acc@1: 68.7500 (75.4939)  Acc@5: 100.0000 (98.1995)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:29  Lr: 0.001875  Loss: 0.9170  Acc@1: 75.0000 (75.5070)  Acc@5: 100.0000 (98.2035)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:25  Lr: 0.001875  Loss: 0.5399  Acc@1: 81.2500 (75.5095)  Acc@5: 100.0000 (98.2074)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:22  Lr: 0.001875  Loss: 0.7567  Acc@1: 75.0000 (75.5120)  Acc@5: 100.0000 (98.1925)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:18  Lr: 0.001875  Loss: 0.5417  Acc@1: 75.0000 (75.5165)  Acc@5: 100.0000 (98.1985)  time: 0.3450  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:15  Lr: 0.001875  Loss: 0.5346  Acc@1: 75.0000 (75.5397)  Acc@5: 100.0000 (98.2024)  time: 0.3453  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:11  Lr: 0.001875  Loss: 0.8035  Acc@1: 81.2500 (75.5607)  Acc@5: 100.0000 (98.2022)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:08  Lr: 0.001875  Loss: 0.7898  Acc@1: 81.2500 (75.5712)  Acc@5: 100.0000 (98.2040)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:04  Lr: 0.001875  Loss: 0.5744  Acc@1: 81.2500 (75.5816)  Acc@5: 100.0000 (98.2078)  time: 0.3445  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:01  Lr: 0.001875  Loss: 1.1852  Acc@1: 81.2500 (75.6023)  Acc@5: 100.0000 (98.2035)  time: 0.3440  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3060/3750]  eta: 0:03:58  Lr: 0.001875  Loss: 0.6186  Acc@1: 81.2500 (75.6166)  Acc@5: 100.0000 (98.2073)  time: 0.3434  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.5133  Acc@1: 75.0000 (75.6228)  Acc@5: 100.0000 (98.2029)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:51  Lr: 0.001875  Loss: 0.7416  Acc@1: 75.0000 (75.6370)  Acc@5: 100.0000 (98.2027)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:47  Lr: 0.001875  Loss: 0.8276  Acc@1: 75.0000 (75.6288)  Acc@5: 100.0000 (98.2065)  time: 0.3448  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:44  Lr: 0.001875  Loss: 0.6499  Acc@1: 68.7500 (75.6329)  Acc@5: 100.0000 (98.2123)  time: 0.3446  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:40  Lr: 0.001875  Loss: 0.4395  Acc@1: 75.0000 (75.6288)  Acc@5: 100.0000 (98.2080)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:37  Lr: 0.001875  Loss: 0.4183  Acc@1: 75.0000 (75.6428)  Acc@5: 100.0000 (98.2077)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.6648  Acc@1: 81.2500 (75.6468)  Acc@5: 100.0000 (98.2074)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.3253  Acc@1: 75.0000 (75.6527)  Acc@5: 100.0000 (98.2092)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:26  Lr: 0.001875  Loss: 0.8358  Acc@1: 75.0000 (75.6625)  Acc@5: 100.0000 (98.2129)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.4378  Acc@1: 75.0000 (75.6802)  Acc@5: 100.0000 (98.2146)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:20  Lr: 0.001875  Loss: 0.2397  Acc@1: 81.2500 (75.6958)  Acc@5: 100.0000 (98.2182)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:16  Lr: 0.001875  Loss: 0.6853  Acc@1: 75.0000 (75.7034)  Acc@5: 100.0000 (98.2238)  time: 0.3451  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:13  Lr: 0.001875  Loss: 0.5149  Acc@1: 81.2500 (75.7208)  Acc@5: 100.0000 (98.2255)  time: 0.3464  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:09  Lr: 0.001875  Loss: 0.7660  Acc@1: 81.2500 (75.7263)  Acc@5: 100.0000 (98.2252)  time: 0.3466  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:06  Lr: 0.001875  Loss: 0.4577  Acc@1: 81.2500 (75.7435)  Acc@5: 100.0000 (98.2249)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:02  Lr: 0.001875  Loss: 0.9524  Acc@1: 81.2500 (75.7471)  Acc@5: 100.0000 (98.2265)  time: 0.3446  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 0.2215  Acc@1: 75.0000 (75.7660)  Acc@5: 100.0000 (98.2300)  time: 0.3436  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:55  Lr: 0.001875  Loss: 0.8830  Acc@1: 81.2500 (75.7637)  Acc@5: 100.0000 (98.2336)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.4554  Acc@1: 81.2500 (75.7805)  Acc@5: 100.0000 (98.2371)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:49  Lr: 0.001875  Loss: 0.6954  Acc@1: 81.2500 (75.7858)  Acc@5: 100.0000 (98.2367)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 0.5108  Acc@1: 81.2500 (75.7910)  Acc@5: 100.0000 (98.2383)  time: 0.3435  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:42  Lr: 0.001875  Loss: 0.4625  Acc@1: 81.2500 (75.8020)  Acc@5: 100.0000 (98.2342)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 0.8075  Acc@1: 81.2500 (75.8166)  Acc@5: 100.0000 (98.2357)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:35  Lr: 0.001875  Loss: 0.3462  Acc@1: 75.0000 (75.8160)  Acc@5: 100.0000 (98.2392)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:31  Lr: 0.001875  Loss: 0.7627  Acc@1: 75.0000 (75.8211)  Acc@5: 100.0000 (98.2388)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.8812  Acc@1: 75.0000 (75.8262)  Acc@5: 100.0000 (98.2366)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:24  Lr: 0.001875  Loss: 0.5231  Acc@1: 75.0000 (75.8218)  Acc@5: 100.0000 (98.2325)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.9123  Acc@1: 75.0000 (75.8325)  Acc@5: 100.0000 (98.2378)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:17  Lr: 0.001875  Loss: 0.5320  Acc@1: 75.0000 (75.8374)  Acc@5: 100.0000 (98.2375)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.3858  Acc@1: 75.0000 (75.8480)  Acc@5: 100.0000 (98.2427)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:11  Lr: 0.001875  Loss: 0.5079  Acc@1: 81.2500 (75.8733)  Acc@5: 100.0000 (98.2479)  time: 0.3452  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.5570  Acc@1: 81.2500 (75.8966)  Acc@5: 100.0000 (98.2531)  time: 0.3460  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:04  Lr: 0.001875  Loss: 0.6203  Acc@1: 81.2500 (75.9123)  Acc@5: 100.0000 (98.2527)  time: 0.3458  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 0.3588  Acc@1: 81.2500 (75.9133)  Acc@5: 100.0000 (98.2579)  time: 0.3448  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.5879  Acc@1: 75.0000 (75.9180)  Acc@5: 100.0000 (98.2556)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 0.6647  Acc@1: 81.2500 (75.9299)  Acc@5: 100.0000 (98.2571)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.6023  Acc@1: 75.0000 (75.9327)  Acc@5: 100.0000 (98.2567)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:46  Lr: 0.001875  Loss: 0.4581  Acc@1: 81.2500 (75.9554)  Acc@5: 100.0000 (98.2600)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.4964  Acc@1: 81.2500 (75.9562)  Acc@5: 100.0000 (98.2596)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: 0.6617  Acc@1: 75.0000 (75.9589)  Acc@5: 100.0000 (98.2574)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 1.1211  Acc@1: 75.0000 (75.9579)  Acc@5: 100.0000 (98.2588)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: 0.5798  Acc@1: 81.2500 (75.9839)  Acc@5: 100.0000 (98.2638)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.8704  Acc@1: 81.2500 (75.9847)  Acc@5: 100.0000 (98.2634)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.7818  Acc@1: 75.0000 (75.9890)  Acc@5: 100.0000 (98.2630)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.6004  Acc@1: 81.2500 (75.9969)  Acc@5: 100.0000 (98.2555)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.3286  Acc@1: 75.0000 (75.9994)  Acc@5: 100.0000 (98.2587)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 0.2731  Acc@1: 75.0000 (76.0036)  Acc@5: 100.0000 (98.2636)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.2537  Acc@1: 81.2500 (76.0220)  Acc@5: 100.0000 (98.2685)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:08  Lr: 0.001875  Loss: 0.4397  Acc@1: 81.2500 (76.0384)  Acc@5: 100.0000 (98.2681)  time: 0.3448  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.6820  Acc@1: 81.2500 (76.0496)  Acc@5: 100.0000 (98.2677)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: 0.9637  Acc@1: 81.2500 (76.0571)  Acc@5: 100.0000 (98.2673)  time: 0.3461  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.8254  Acc@1: 81.2500 (76.0612)  Acc@5: 100.0000 (98.2721)  time: 0.3463  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2314  Acc@1: 81.2500 (76.0791)  Acc@5: 100.0000 (98.2752)  time: 0.3455  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1866  Acc@1: 81.2500 (76.0952)  Acc@5: 100.0000 (98.2783)  time: 0.3446  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3766  Acc@1: 81.2500 (76.1181)  Acc@5: 100.0000 (98.2778)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.6167  Acc@1: 81.2500 (76.1254)  Acc@5: 100.0000 (98.2826)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.5523  Acc@1: 81.2500 (76.1447)  Acc@5: 100.0000 (98.2873)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 1.0029  Acc@1: 81.2500 (76.1467)  Acc@5: 100.0000 (98.2903)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.7262  Acc@1: 81.2500 (76.1658)  Acc@5: 100.0000 (98.2916)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: 0.5959  Acc@1: 81.2500 (76.1660)  Acc@5: 100.0000 (98.2928)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.7860  Acc@1: 81.2500 (76.1747)  Acc@5: 100.0000 (98.2907)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.5135  Acc@1: 75.0000 (76.1868)  Acc@5: 100.0000 (98.2953)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 1.0453  Acc@1: 81.2500 (76.1870)  Acc@5: 100.0000 (98.2915)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4670  Acc@1: 81.2500 (76.1906)  Acc@5: 100.0000 (98.2944)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.8899  Acc@1: 81.2500 (76.2076)  Acc@5: 100.0000 (98.2973)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.5330  Acc@1: 81.2500 (76.2178)  Acc@5: 100.0000 (98.2968)  time: 0.3439  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.9026  Acc@1: 81.2500 (76.2346)  Acc@5: 100.0000 (98.2980)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.6394  Acc@1: 81.2500 (76.2396)  Acc@5: 100.0000 (98.3009)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 1.8475  Acc@1: 81.2500 (76.2433)  Acc@5: 100.0000 (98.3033)  time: 0.3446  data: 0.0006  max mem: 2503
Train: Epoch[1/5] Total time: 0:21:34 (0.3451 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.8475  Acc@1: 81.2500 (76.2433)  Acc@5: 100.0000 (98.3033)
Train: Epoch[2/5]  [   0/3750]  eta: 0:40:49  Lr: 0.001875  Loss: 0.4391  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6532  data: 0.3074  max mem: 2503
Train: Epoch[2/5]  [  10/3750]  eta: 0:23:15  Lr: 0.001875  Loss: 0.4997  Acc@1: 81.2500 (80.1136)  Acc@5: 100.0000 (98.8636)  time: 0.3731  data: 0.0282  max mem: 2503
Train: Epoch[2/5]  [  20/3750]  eta: 0:22:19  Lr: 0.001875  Loss: 0.6013  Acc@1: 75.0000 (79.4643)  Acc@5: 100.0000 (98.8095)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [  30/3750]  eta: 0:21:59  Lr: 0.001875  Loss: 0.4161  Acc@1: 75.0000 (79.6371)  Acc@5: 100.0000 (98.9919)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [  40/3750]  eta: 0:21:45  Lr: 0.001875  Loss: 0.4256  Acc@1: 75.0000 (79.2683)  Acc@5: 100.0000 (98.7805)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  50/3750]  eta: 0:21:36  Lr: 0.001875  Loss: 0.5440  Acc@1: 75.0000 (78.6765)  Acc@5: 100.0000 (99.0196)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:29  Lr: 0.001875  Loss: 0.7234  Acc@1: 81.2500 (78.5861)  Acc@5: 100.0000 (98.9754)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:23  Lr: 0.001875  Loss: 0.2430  Acc@1: 75.0000 (78.4331)  Acc@5: 100.0000 (98.9437)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:17  Lr: 0.001875  Loss: 0.3430  Acc@1: 81.2500 (78.8580)  Acc@5: 100.0000 (99.0741)  time: 0.3440  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:12  Lr: 0.001875  Loss: 0.2008  Acc@1: 81.2500 (78.7088)  Acc@5: 100.0000 (99.1071)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:07  Lr: 0.001875  Loss: 0.2664  Acc@1: 75.0000 (78.8985)  Acc@5: 100.0000 (99.1337)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:02  Lr: 0.001875  Loss: 0.7450  Acc@1: 75.0000 (78.9414)  Acc@5: 100.0000 (99.1554)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 120/3750]  eta: 0:20:58  Lr: 0.001875  Loss: 0.6866  Acc@1: 75.0000 (78.5640)  Acc@5: 100.0000 (99.1219)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 130/3750]  eta: 0:20:54  Lr: 0.001875  Loss: 0.5007  Acc@1: 81.2500 (78.7691)  Acc@5: 100.0000 (98.9981)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 140/3750]  eta: 0:20:50  Lr: 0.001875  Loss: 0.7722  Acc@1: 81.2500 (78.9450)  Acc@5: 100.0000 (99.0248)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 150/3750]  eta: 0:20:46  Lr: 0.001875  Loss: 0.4565  Acc@1: 81.2500 (78.8493)  Acc@5: 100.0000 (99.0480)  time: 0.3442  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [ 160/3750]  eta: 0:20:43  Lr: 0.001875  Loss: 0.3166  Acc@1: 81.2500 (78.9596)  Acc@5: 100.0000 (98.9130)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:39  Lr: 0.001875  Loss: 1.1197  Acc@1: 81.2500 (79.0205)  Acc@5: 100.0000 (98.9035)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:35  Lr: 0.001875  Loss: 0.7134  Acc@1: 81.2500 (78.9365)  Acc@5: 100.0000 (98.9296)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:32  Lr: 0.001875  Loss: 0.5281  Acc@1: 75.0000 (78.8940)  Acc@5: 100.0000 (98.8874)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:28  Lr: 0.001875  Loss: 0.4037  Acc@1: 75.0000 (79.0734)  Acc@5: 100.0000 (98.9117)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:24  Lr: 0.001875  Loss: 0.5932  Acc@1: 81.2500 (79.1469)  Acc@5: 100.0000 (98.9040)  time: 0.3449  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:21  Lr: 0.001875  Loss: 0.2490  Acc@1: 81.2500 (79.2704)  Acc@5: 100.0000 (98.8688)  time: 0.3450  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:17  Lr: 0.001875  Loss: 0.3085  Acc@1: 75.0000 (79.0855)  Acc@5: 100.0000 (98.8366)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:14  Lr: 0.001875  Loss: 0.2920  Acc@1: 75.0000 (79.1494)  Acc@5: 100.0000 (98.8330)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:10  Lr: 0.001875  Loss: 0.4790  Acc@1: 81.2500 (79.2580)  Acc@5: 100.0000 (98.7799)  time: 0.3448  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:06  Lr: 0.001875  Loss: 0.4705  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (98.7787)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:03  Lr: 0.001875  Loss: 0.2373  Acc@1: 81.2500 (79.3819)  Acc@5: 100.0000 (98.8007)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 280/3750]  eta: 0:19:59  Lr: 0.001875  Loss: 0.9055  Acc@1: 81.2500 (79.2260)  Acc@5: 100.0000 (98.7767)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 290/3750]  eta: 0:19:55  Lr: 0.001875  Loss: 0.7282  Acc@1: 75.0000 (79.2955)  Acc@5: 100.0000 (98.7543)  time: 0.3439  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [ 300/3750]  eta: 0:19:52  Lr: 0.001875  Loss: 0.9040  Acc@1: 75.0000 (79.0075)  Acc@5: 100.0000 (98.7334)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 310/3750]  eta: 0:19:48  Lr: 0.001875  Loss: 0.5026  Acc@1: 75.0000 (78.9992)  Acc@5: 100.0000 (98.6937)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 320/3750]  eta: 0:19:45  Lr: 0.001875  Loss: 0.2939  Acc@1: 81.2500 (79.0498)  Acc@5: 100.0000 (98.7150)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:41  Lr: 0.001875  Loss: 0.2765  Acc@1: 81.2500 (79.0408)  Acc@5: 100.0000 (98.7538)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:38  Lr: 0.001875  Loss: 0.2699  Acc@1: 81.2500 (79.1239)  Acc@5: 100.0000 (98.7720)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:34  Lr: 0.001875  Loss: 1.0057  Acc@1: 81.2500 (79.1132)  Acc@5: 100.0000 (98.7536)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:30  Lr: 0.001875  Loss: 0.7280  Acc@1: 81.2500 (79.1551)  Acc@5: 100.0000 (98.7881)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:27  Lr: 0.001875  Loss: 0.5728  Acc@1: 81.2500 (79.1947)  Acc@5: 100.0000 (98.7871)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:24  Lr: 0.001875  Loss: 0.5067  Acc@1: 81.2500 (79.3635)  Acc@5: 100.0000 (98.7861)  time: 0.3459  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:20  Lr: 0.001875  Loss: 0.1624  Acc@1: 87.5000 (79.4757)  Acc@5: 100.0000 (98.8012)  time: 0.3458  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:17  Lr: 0.001875  Loss: 0.3926  Acc@1: 87.5000 (79.5979)  Acc@5: 100.0000 (98.7999)  time: 0.3447  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:13  Lr: 0.001875  Loss: 0.6837  Acc@1: 87.5000 (79.6381)  Acc@5: 100.0000 (98.7835)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:10  Lr: 0.001875  Loss: 0.8059  Acc@1: 75.0000 (79.5131)  Acc@5: 100.0000 (98.7678)  time: 0.3452  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:06  Lr: 0.001875  Loss: 0.4586  Acc@1: 75.0000 (79.5099)  Acc@5: 100.0000 (98.7384)  time: 0.3454  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:03  Lr: 0.001875  Loss: 0.7393  Acc@1: 81.2500 (79.5351)  Acc@5: 100.0000 (98.7528)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 450/3750]  eta: 0:18:59  Lr: 0.001875  Loss: 0.6769  Acc@1: 81.2500 (79.4762)  Acc@5: 100.0000 (98.7528)  time: 0.3451  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 460/3750]  eta: 0:18:56  Lr: 0.001875  Loss: 0.5593  Acc@1: 81.2500 (79.5146)  Acc@5: 100.0000 (98.7798)  time: 0.3450  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 470/3750]  eta: 0:18:52  Lr: 0.001875  Loss: 0.3926  Acc@1: 81.2500 (79.5117)  Acc@5: 100.0000 (98.8057)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 480/3750]  eta: 0:18:49  Lr: 0.001875  Loss: 1.0664  Acc@1: 75.0000 (79.4439)  Acc@5: 100.0000 (98.8046)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 490/3750]  eta: 0:18:45  Lr: 0.001875  Loss: 0.5400  Acc@1: 75.0000 (79.4679)  Acc@5: 100.0000 (98.8035)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:42  Lr: 0.001875  Loss: 0.7892  Acc@1: 81.2500 (79.5409)  Acc@5: 100.0000 (98.7899)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:38  Lr: 0.001875  Loss: 0.7737  Acc@1: 81.2500 (79.5499)  Acc@5: 100.0000 (98.7769)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:35  Lr: 0.001875  Loss: 0.3609  Acc@1: 81.2500 (79.5585)  Acc@5: 100.0000 (98.8004)  time: 0.3454  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:31  Lr: 0.001875  Loss: 0.2668  Acc@1: 81.2500 (79.5315)  Acc@5: 100.0000 (98.7641)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:28  Lr: 0.001875  Loss: 0.6943  Acc@1: 75.0000 (79.4593)  Acc@5: 100.0000 (98.7754)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:24  Lr: 0.001875  Loss: 0.5185  Acc@1: 75.0000 (79.4351)  Acc@5: 100.0000 (98.7750)  time: 0.3444  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:21  Lr: 0.001875  Loss: 0.4051  Acc@1: 75.0000 (79.4229)  Acc@5: 100.0000 (98.7745)  time: 0.3456  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:17  Lr: 0.001875  Loss: 0.4576  Acc@1: 75.0000 (79.4111)  Acc@5: 100.0000 (98.7850)  time: 0.3452  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:14  Lr: 0.001875  Loss: 0.6678  Acc@1: 81.2500 (79.4750)  Acc@5: 100.0000 (98.7844)  time: 0.3454  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.001875  Loss: 0.8998  Acc@1: 81.2500 (79.4522)  Acc@5: 100.0000 (98.7944)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:07  Lr: 0.001875  Loss: 0.6845  Acc@1: 75.0000 (79.3885)  Acc@5: 100.0000 (98.7937)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:04  Lr: 0.001875  Loss: 0.6105  Acc@1: 75.0000 (79.3985)  Acc@5: 100.0000 (98.8032)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:00  Lr: 0.001875  Loss: 0.6212  Acc@1: 81.2500 (79.3680)  Acc@5: 100.0000 (98.8124)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 630/3750]  eta: 0:17:57  Lr: 0.001875  Loss: 1.0786  Acc@1: 75.0000 (79.3384)  Acc@5: 100.0000 (98.8213)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 640/3750]  eta: 0:17:53  Lr: 0.001875  Loss: 0.7458  Acc@1: 75.0000 (79.2804)  Acc@5: 100.0000 (98.8105)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 650/3750]  eta: 0:17:50  Lr: 0.001875  Loss: 0.7339  Acc@1: 75.0000 (79.2531)  Acc@5: 100.0000 (98.8095)  time: 0.3454  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 660/3750]  eta: 0:17:46  Lr: 0.001875  Loss: 0.6292  Acc@1: 81.2500 (79.2644)  Acc@5: 100.0000 (98.8181)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:43  Lr: 0.001875  Loss: 0.2297  Acc@1: 75.0000 (79.1915)  Acc@5: 100.0000 (98.7984)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:39  Lr: 0.001875  Loss: 0.3922  Acc@1: 75.0000 (79.2401)  Acc@5: 100.0000 (98.7977)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:36  Lr: 0.001875  Loss: 0.5687  Acc@1: 81.2500 (79.2149)  Acc@5: 100.0000 (98.7699)  time: 0.3441  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:32  Lr: 0.001875  Loss: 0.5885  Acc@1: 81.2500 (79.2350)  Acc@5: 100.0000 (98.7785)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:29  Lr: 0.001875  Loss: 0.8576  Acc@1: 75.0000 (79.2282)  Acc@5: 100.0000 (98.7781)  time: 0.3454  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:25  Lr: 0.001875  Loss: 1.2892  Acc@1: 75.0000 (79.1609)  Acc@5: 100.0000 (98.7344)  time: 0.3447  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:22  Lr: 0.001875  Loss: 0.5648  Acc@1: 75.0000 (79.1125)  Acc@5: 100.0000 (98.7346)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:18  Lr: 0.001875  Loss: 0.6100  Acc@1: 75.0000 (79.0992)  Acc@5: 100.0000 (98.7179)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:15  Lr: 0.001875  Loss: 1.1428  Acc@1: 81.2500 (79.1445)  Acc@5: 100.0000 (98.7101)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:11  Lr: 0.001875  Loss: 0.5765  Acc@1: 81.2500 (79.0818)  Acc@5: 100.0000 (98.7106)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:08  Lr: 0.001875  Loss: 0.3583  Acc@1: 75.0000 (79.0856)  Acc@5: 100.0000 (98.7273)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:05  Lr: 0.001875  Loss: 0.4695  Acc@1: 81.2500 (79.0653)  Acc@5: 100.0000 (98.7276)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.001875  Loss: 0.3807  Acc@1: 81.2500 (79.0850)  Acc@5: 100.0000 (98.7279)  time: 0.3449  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 800/3750]  eta: 0:16:58  Lr: 0.001875  Loss: 0.4457  Acc@1: 81.2500 (79.0652)  Acc@5: 100.0000 (98.7360)  time: 0.3444  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.001875  Loss: 0.9622  Acc@1: 75.0000 (79.0305)  Acc@5: 100.0000 (98.7515)  time: 0.3446  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 820/3750]  eta: 0:16:51  Lr: 0.001875  Loss: 0.6782  Acc@1: 81.2500 (79.0880)  Acc@5: 100.0000 (98.7591)  time: 0.3449  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 830/3750]  eta: 0:16:47  Lr: 0.001875  Loss: 0.3928  Acc@1: 81.2500 (79.1441)  Acc@5: 100.0000 (98.7741)  time: 0.3444  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:44  Lr: 0.001875  Loss: 0.4724  Acc@1: 81.2500 (79.1914)  Acc@5: 100.0000 (98.7812)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.001875  Loss: 0.7105  Acc@1: 81.2500 (79.0908)  Acc@5: 100.0000 (98.7735)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:37  Lr: 0.001875  Loss: 0.9101  Acc@1: 75.0000 (79.1231)  Acc@5: 100.0000 (98.7805)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:34  Lr: 0.001875  Loss: 0.5664  Acc@1: 81.2500 (79.1475)  Acc@5: 100.0000 (98.7945)  time: 0.3478  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.001875  Loss: 0.1386  Acc@1: 81.2500 (79.1785)  Acc@5: 100.0000 (98.8011)  time: 0.3465  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:27  Lr: 0.001875  Loss: 0.4864  Acc@1: 81.2500 (79.1807)  Acc@5: 100.0000 (98.7935)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.001875  Loss: 0.4508  Acc@1: 75.0000 (79.1204)  Acc@5: 100.0000 (98.7999)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:20  Lr: 0.001875  Loss: 0.4987  Acc@1: 75.0000 (79.0958)  Acc@5: 100.0000 (98.7925)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.001875  Loss: 0.3394  Acc@1: 75.0000 (79.0852)  Acc@5: 100.0000 (98.7921)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:13  Lr: 0.001875  Loss: 0.5651  Acc@1: 75.0000 (79.0749)  Acc@5: 100.0000 (98.7849)  time: 0.3459  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.001875  Loss: 0.6166  Acc@1: 75.0000 (79.0383)  Acc@5: 100.0000 (98.7513)  time: 0.3454  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:06  Lr: 0.001875  Loss: 0.3167  Acc@1: 75.0000 (79.0418)  Acc@5: 100.0000 (98.7513)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.001875  Loss: 0.9547  Acc@1: 75.0000 (79.0323)  Acc@5: 100.0000 (98.7513)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 970/3750]  eta: 0:15:59  Lr: 0.001875  Loss: 0.4869  Acc@1: 75.0000 (79.0294)  Acc@5: 100.0000 (98.7577)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 980/3750]  eta: 0:15:56  Lr: 0.001875  Loss: 0.5517  Acc@1: 75.0000 (79.0138)  Acc@5: 100.0000 (98.7640)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 990/3750]  eta: 0:15:52  Lr: 0.001875  Loss: 0.7560  Acc@1: 81.2500 (79.0363)  Acc@5: 100.0000 (98.7765)  time: 0.3475  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1000/3750]  eta: 0:15:49  Lr: 0.001875  Loss: 0.7427  Acc@1: 81.2500 (79.0647)  Acc@5: 100.0000 (98.7825)  time: 0.3493  data: 0.0030  max mem: 2503
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:45  Lr: 0.001875  Loss: 0.7921  Acc@1: 81.2500 (79.0492)  Acc@5: 100.0000 (98.7760)  time: 0.3473  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:42  Lr: 0.001875  Loss: 0.4566  Acc@1: 81.2500 (79.0891)  Acc@5: 100.0000 (98.7757)  time: 0.3447  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:38  Lr: 0.001875  Loss: 0.5001  Acc@1: 81.2500 (79.1101)  Acc@5: 100.0000 (98.7755)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:35  Lr: 0.001875  Loss: 0.3030  Acc@1: 81.2500 (79.1006)  Acc@5: 100.0000 (98.7872)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:32  Lr: 0.001875  Loss: 0.5580  Acc@1: 81.2500 (79.1211)  Acc@5: 100.0000 (98.7928)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:28  Lr: 0.001875  Loss: 0.4436  Acc@1: 75.0000 (79.0763)  Acc@5: 100.0000 (98.7983)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:25  Lr: 0.001875  Loss: 0.3656  Acc@1: 75.0000 (79.1083)  Acc@5: 100.0000 (98.7862)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:21  Lr: 0.001875  Loss: 0.3694  Acc@1: 87.5000 (79.1686)  Acc@5: 100.0000 (98.7916)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:18  Lr: 0.001875  Loss: 0.7004  Acc@1: 81.2500 (79.1762)  Acc@5: 100.0000 (98.7912)  time: 0.3460  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:14  Lr: 0.001875  Loss: 0.5808  Acc@1: 81.2500 (79.2178)  Acc@5: 100.0000 (98.7909)  time: 0.3455  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:11  Lr: 0.001875  Loss: 0.4647  Acc@1: 81.2500 (79.1685)  Acc@5: 100.0000 (98.7961)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:07  Lr: 0.001875  Loss: 0.3370  Acc@1: 81.2500 (79.1871)  Acc@5: 100.0000 (98.8013)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:04  Lr: 0.001875  Loss: 0.4627  Acc@1: 75.0000 (79.1390)  Acc@5: 100.0000 (98.8119)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:01  Lr: 0.001875  Loss: 0.6451  Acc@1: 81.2500 (79.2014)  Acc@5: 100.0000 (98.8223)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1150/3750]  eta: 0:14:57  Lr: 0.001875  Loss: 0.6601  Acc@1: 81.2500 (79.2409)  Acc@5: 100.0000 (98.8217)  time: 0.3448  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1160/3750]  eta: 0:14:54  Lr: 0.001875  Loss: 0.6905  Acc@1: 81.2500 (79.2259)  Acc@5: 100.0000 (98.8264)  time: 0.3453  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1170/3750]  eta: 0:14:50  Lr: 0.001875  Loss: 0.9839  Acc@1: 81.2500 (79.2111)  Acc@5: 100.0000 (98.8365)  time: 0.3454  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:47  Lr: 0.001875  Loss: 0.2321  Acc@1: 81.2500 (79.2549)  Acc@5: 100.0000 (98.8304)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:43  Lr: 0.001875  Loss: 0.6426  Acc@1: 81.2500 (79.2769)  Acc@5: 100.0000 (98.8403)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:40  Lr: 0.001875  Loss: 0.3347  Acc@1: 81.2500 (79.2881)  Acc@5: 100.0000 (98.8395)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:36  Lr: 0.001875  Loss: 0.5269  Acc@1: 81.2500 (79.3095)  Acc@5: 100.0000 (98.8284)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:33  Lr: 0.001875  Loss: 0.9415  Acc@1: 81.2500 (79.2946)  Acc@5: 100.0000 (98.8227)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:29  Lr: 0.001875  Loss: 0.8180  Acc@1: 75.0000 (79.2851)  Acc@5: 100.0000 (98.8272)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:26  Lr: 0.001875  Loss: 0.6176  Acc@1: 81.2500 (79.3261)  Acc@5: 100.0000 (98.8266)  time: 0.3432  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:22  Lr: 0.001875  Loss: 0.5479  Acc@1: 87.5000 (79.3365)  Acc@5: 100.0000 (98.8309)  time: 0.3444  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:19  Lr: 0.001875  Loss: 0.3411  Acc@1: 81.2500 (79.3517)  Acc@5: 100.0000 (98.8352)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:16  Lr: 0.001875  Loss: 0.7626  Acc@1: 81.2500 (79.3765)  Acc@5: 100.0000 (98.8346)  time: 0.3445  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:12  Lr: 0.001875  Loss: 0.3741  Acc@1: 87.5000 (79.4009)  Acc@5: 100.0000 (98.8339)  time: 0.3447  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:09  Lr: 0.001875  Loss: 0.8400  Acc@1: 81.2500 (79.3958)  Acc@5: 100.0000 (98.8187)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:05  Lr: 0.001875  Loss: 0.3268  Acc@1: 81.2500 (79.4053)  Acc@5: 100.0000 (98.8182)  time: 0.3458  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:02  Lr: 0.001875  Loss: 0.3086  Acc@1: 81.2500 (79.4289)  Acc@5: 100.0000 (98.8225)  time: 0.3456  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1320/3750]  eta: 0:13:58  Lr: 0.001875  Loss: 0.6295  Acc@1: 81.2500 (79.4285)  Acc@5: 100.0000 (98.8314)  time: 0.3461  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1330/3750]  eta: 0:13:55  Lr: 0.001875  Loss: 0.9168  Acc@1: 81.2500 (79.4375)  Acc@5: 100.0000 (98.8308)  time: 0.3455  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1340/3750]  eta: 0:13:51  Lr: 0.001875  Loss: 0.9624  Acc@1: 75.0000 (79.4137)  Acc@5: 100.0000 (98.8348)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:48  Lr: 0.001875  Loss: 0.6349  Acc@1: 81.2500 (79.4273)  Acc@5: 100.0000 (98.8296)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:44  Lr: 0.001875  Loss: 0.4023  Acc@1: 81.2500 (79.4774)  Acc@5: 100.0000 (98.8336)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:41  Lr: 0.001875  Loss: 0.4828  Acc@1: 87.5000 (79.4767)  Acc@5: 100.0000 (98.8330)  time: 0.3458  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:38  Lr: 0.001875  Loss: 0.6353  Acc@1: 81.2500 (79.4804)  Acc@5: 100.0000 (98.8324)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:34  Lr: 0.001875  Loss: 0.5674  Acc@1: 81.2500 (79.5066)  Acc@5: 100.0000 (98.8363)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:31  Lr: 0.001875  Loss: 0.5407  Acc@1: 81.2500 (79.5191)  Acc@5: 100.0000 (98.8357)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:27  Lr: 0.001875  Loss: 0.3995  Acc@1: 81.2500 (79.5402)  Acc@5: 100.0000 (98.8262)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:24  Lr: 0.001875  Loss: 0.2355  Acc@1: 81.2500 (79.5742)  Acc@5: 100.0000 (98.8344)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:20  Lr: 0.001875  Loss: 1.0536  Acc@1: 81.2500 (79.5860)  Acc@5: 100.0000 (98.8339)  time: 0.3448  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:17  Lr: 0.001875  Loss: 0.7023  Acc@1: 75.0000 (79.5845)  Acc@5: 100.0000 (98.8246)  time: 0.3441  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:13  Lr: 0.001875  Loss: 0.6543  Acc@1: 75.0000 (79.5486)  Acc@5: 100.0000 (98.8241)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:10  Lr: 0.001875  Loss: 0.3402  Acc@1: 75.0000 (79.5517)  Acc@5: 100.0000 (98.8193)  time: 0.3458  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:06  Lr: 0.001875  Loss: 0.6628  Acc@1: 75.0000 (79.5122)  Acc@5: 100.0000 (98.8188)  time: 0.3451  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:03  Lr: 0.001875  Loss: 0.3867  Acc@1: 81.2500 (79.5324)  Acc@5: 100.0000 (98.8099)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:00  Lr: 0.001875  Loss: 0.7118  Acc@1: 81.2500 (79.5062)  Acc@5: 100.0000 (98.8137)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1500/3750]  eta: 0:12:56  Lr: 0.001875  Loss: 0.4636  Acc@1: 75.0000 (79.5053)  Acc@5: 100.0000 (98.8050)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1510/3750]  eta: 0:12:53  Lr: 0.001875  Loss: 0.4100  Acc@1: 81.2500 (79.4838)  Acc@5: 100.0000 (98.8005)  time: 0.3440  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:49  Lr: 0.001875  Loss: 0.6200  Acc@1: 75.0000 (79.4502)  Acc@5: 100.0000 (98.8042)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:46  Lr: 0.001875  Loss: 0.8996  Acc@1: 75.0000 (79.4211)  Acc@5: 100.0000 (98.7998)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:42  Lr: 0.001875  Loss: 0.3933  Acc@1: 81.2500 (79.4614)  Acc@5: 100.0000 (98.8076)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:39  Lr: 0.001875  Loss: 0.6573  Acc@1: 81.2500 (79.4649)  Acc@5: 100.0000 (98.8113)  time: 0.3444  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:35  Lr: 0.001875  Loss: 0.1581  Acc@1: 81.2500 (79.4883)  Acc@5: 100.0000 (98.8189)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:32  Lr: 0.001875  Loss: 0.6667  Acc@1: 81.2500 (79.4876)  Acc@5: 100.0000 (98.8224)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:28  Lr: 0.001875  Loss: 0.4341  Acc@1: 75.0000 (79.5027)  Acc@5: 100.0000 (98.8219)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:25  Lr: 0.001875  Loss: 0.6364  Acc@1: 81.2500 (79.5255)  Acc@5: 100.0000 (98.8254)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:21  Lr: 0.001875  Loss: 0.7013  Acc@1: 75.0000 (79.5167)  Acc@5: 100.0000 (98.8289)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:18  Lr: 0.001875  Loss: 0.3492  Acc@1: 75.0000 (79.5042)  Acc@5: 100.0000 (98.8284)  time: 0.3454  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:15  Lr: 0.001875  Loss: 0.5984  Acc@1: 81.2500 (79.5342)  Acc@5: 100.0000 (98.8317)  time: 0.3457  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:11  Lr: 0.001875  Loss: 0.6555  Acc@1: 81.2500 (79.5371)  Acc@5: 100.0000 (98.8236)  time: 0.3447  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:08  Lr: 0.001875  Loss: 0.5387  Acc@1: 81.2500 (79.5704)  Acc@5: 100.0000 (98.8231)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:04  Lr: 0.001875  Loss: 0.8432  Acc@1: 81.2500 (79.5427)  Acc@5: 100.0000 (98.8227)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:01  Lr: 0.001875  Loss: 0.6110  Acc@1: 75.0000 (79.5417)  Acc@5: 100.0000 (98.8260)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1670/3750]  eta: 0:11:57  Lr: 0.001875  Loss: 0.3609  Acc@1: 81.2500 (79.5557)  Acc@5: 100.0000 (98.8293)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1680/3750]  eta: 0:11:54  Lr: 0.001875  Loss: 0.5920  Acc@1: 81.2500 (79.5248)  Acc@5: 100.0000 (98.8325)  time: 0.3451  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:50  Lr: 0.001875  Loss: 0.4458  Acc@1: 81.2500 (79.5424)  Acc@5: 100.0000 (98.8321)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:47  Lr: 0.001875  Loss: 0.3863  Acc@1: 81.2500 (79.5561)  Acc@5: 100.0000 (98.8389)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:43  Lr: 0.001875  Loss: 0.8097  Acc@1: 81.2500 (79.5332)  Acc@5: 100.0000 (98.8384)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:40  Lr: 0.001875  Loss: 0.4597  Acc@1: 81.2500 (79.5250)  Acc@5: 100.0000 (98.8415)  time: 0.3441  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:37  Lr: 0.001875  Loss: 0.7326  Acc@1: 81.2500 (79.4988)  Acc@5: 100.0000 (98.8410)  time: 0.3440  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:33  Lr: 0.001875  Loss: 0.6106  Acc@1: 75.0000 (79.4874)  Acc@5: 100.0000 (98.8369)  time: 0.3439  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:30  Lr: 0.001875  Loss: 0.9745  Acc@1: 68.7500 (79.4475)  Acc@5: 100.0000 (98.8328)  time: 0.3446  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:26  Lr: 0.001875  Loss: 1.0064  Acc@1: 68.7500 (79.4329)  Acc@5: 100.0000 (98.8323)  time: 0.3459  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:23  Lr: 0.001875  Loss: 0.5828  Acc@1: 81.2500 (79.4325)  Acc@5: 100.0000 (98.8389)  time: 0.3453  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:19  Lr: 0.001875  Loss: 0.4823  Acc@1: 81.2500 (79.4392)  Acc@5: 100.0000 (98.8419)  time: 0.3433  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:16  Lr: 0.001875  Loss: 0.5616  Acc@1: 81.2500 (79.4179)  Acc@5: 100.0000 (98.8484)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:12  Lr: 0.001875  Loss: 0.6006  Acc@1: 81.2500 (79.4246)  Acc@5: 100.0000 (98.8513)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:09  Lr: 0.001875  Loss: 0.7495  Acc@1: 81.2500 (79.4520)  Acc@5: 100.0000 (98.8577)  time: 0.3443  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:05  Lr: 0.001875  Loss: 0.7052  Acc@1: 81.2500 (79.4275)  Acc@5: 100.0000 (98.8605)  time: 0.3445  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:02  Lr: 0.001875  Loss: 0.9057  Acc@1: 75.0000 (79.4067)  Acc@5: 100.0000 (98.8599)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1840/3750]  eta: 0:10:58  Lr: 0.001875  Loss: 0.5677  Acc@1: 75.0000 (79.3930)  Acc@5: 100.0000 (98.8593)  time: 0.3454  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [1850/3750]  eta: 0:10:55  Lr: 0.001875  Loss: 0.8801  Acc@1: 81.2500 (79.4030)  Acc@5: 100.0000 (98.8621)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1860/3750]  eta: 0:10:52  Lr: 0.001875  Loss: 0.3306  Acc@1: 81.2500 (79.4197)  Acc@5: 100.0000 (98.8581)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:48  Lr: 0.001875  Loss: 0.8018  Acc@1: 81.2500 (79.4428)  Acc@5: 100.0000 (98.8576)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:45  Lr: 0.001875  Loss: 0.8194  Acc@1: 81.2500 (79.4391)  Acc@5: 100.0000 (98.8603)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:41  Lr: 0.001875  Loss: 0.3150  Acc@1: 75.0000 (79.4487)  Acc@5: 100.0000 (98.8630)  time: 0.3441  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:38  Lr: 0.001875  Loss: 0.4210  Acc@1: 81.2500 (79.4516)  Acc@5: 100.0000 (98.8526)  time: 0.3436  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:34  Lr: 0.001875  Loss: 1.0639  Acc@1: 81.2500 (79.4447)  Acc@5: 100.0000 (98.8488)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:31  Lr: 0.001875  Loss: 0.3820  Acc@1: 81.2500 (79.4801)  Acc@5: 100.0000 (98.8548)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:27  Lr: 0.001875  Loss: 0.6442  Acc@1: 81.2500 (79.4601)  Acc@5: 100.0000 (98.8607)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:24  Lr: 0.001875  Loss: 0.3284  Acc@1: 81.2500 (79.4887)  Acc@5: 100.0000 (98.8601)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:20  Lr: 0.001875  Loss: 0.1470  Acc@1: 81.2500 (79.4913)  Acc@5: 100.0000 (98.8660)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:17  Lr: 0.001875  Loss: 0.5122  Acc@1: 81.2500 (79.5003)  Acc@5: 100.0000 (98.8686)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:14  Lr: 0.001875  Loss: 0.3425  Acc@1: 81.2500 (79.4996)  Acc@5: 100.0000 (98.8648)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:10  Lr: 0.001875  Loss: 0.7991  Acc@1: 81.2500 (79.5148)  Acc@5: 100.0000 (98.8705)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:07  Lr: 0.001875  Loss: 0.6932  Acc@1: 81.2500 (79.4952)  Acc@5: 100.0000 (98.8574)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:03  Lr: 0.001875  Loss: 0.6169  Acc@1: 75.0000 (79.4696)  Acc@5: 100.0000 (98.8568)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:00  Lr: 0.001875  Loss: 0.7787  Acc@1: 75.0000 (79.4598)  Acc@5: 100.0000 (98.8501)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2020/3750]  eta: 0:09:56  Lr: 0.001875  Loss: 0.3457  Acc@1: 75.0000 (79.4687)  Acc@5: 100.0000 (98.8527)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2030/3750]  eta: 0:09:53  Lr: 0.001875  Loss: 0.3538  Acc@1: 81.2500 (79.4621)  Acc@5: 100.0000 (98.8552)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:49  Lr: 0.001875  Loss: 0.6329  Acc@1: 81.2500 (79.4739)  Acc@5: 100.0000 (98.8609)  time: 0.3455  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:46  Lr: 0.001875  Loss: 1.2139  Acc@1: 75.0000 (79.4430)  Acc@5: 100.0000 (98.8542)  time: 0.3465  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:43  Lr: 0.001875  Loss: 0.5787  Acc@1: 68.7500 (79.4032)  Acc@5: 100.0000 (98.8507)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:39  Lr: 0.001875  Loss: 0.6558  Acc@1: 75.0000 (79.3880)  Acc@5: 100.0000 (98.8502)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:36  Lr: 0.001875  Loss: 0.7071  Acc@1: 75.0000 (79.3909)  Acc@5: 100.0000 (98.8527)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:32  Lr: 0.001875  Loss: 1.0165  Acc@1: 75.0000 (79.3789)  Acc@5: 100.0000 (98.8462)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:29  Lr: 0.001875  Loss: 0.4798  Acc@1: 81.2500 (79.4027)  Acc@5: 100.0000 (98.8488)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:25  Lr: 0.001875  Loss: 0.6811  Acc@1: 81.2500 (79.4085)  Acc@5: 100.0000 (98.8542)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:22  Lr: 0.001875  Loss: 0.5723  Acc@1: 81.2500 (79.3936)  Acc@5: 100.0000 (98.8567)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:18  Lr: 0.001875  Loss: 0.5017  Acc@1: 81.2500 (79.4111)  Acc@5: 100.0000 (98.8591)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:15  Lr: 0.001875  Loss: 0.8807  Acc@1: 81.2500 (79.4226)  Acc@5: 100.0000 (98.8498)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:11  Lr: 0.001875  Loss: 0.4164  Acc@1: 81.2500 (79.4166)  Acc@5: 100.0000 (98.8523)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:08  Lr: 0.001875  Loss: 0.6008  Acc@1: 75.0000 (79.4135)  Acc@5: 100.0000 (98.8547)  time: 0.3437  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:05  Lr: 0.001875  Loss: 0.4872  Acc@1: 81.2500 (79.4190)  Acc@5: 100.0000 (98.8456)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:01  Lr: 0.001875  Loss: 0.8986  Acc@1: 81.2500 (79.4102)  Acc@5: 100.0000 (98.8423)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2190/3750]  eta: 0:08:58  Lr: 0.001875  Loss: 0.6044  Acc@1: 81.2500 (79.4272)  Acc@5: 100.0000 (98.8447)  time: 0.3448  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2200/3750]  eta: 0:08:54  Lr: 0.001875  Loss: 0.4221  Acc@1: 81.2500 (79.4213)  Acc@5: 100.0000 (98.8414)  time: 0.3458  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:51  Lr: 0.001875  Loss: 0.6438  Acc@1: 81.2500 (79.4211)  Acc@5: 100.0000 (98.8467)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:47  Lr: 0.001875  Loss: 0.5659  Acc@1: 81.2500 (79.4293)  Acc@5: 100.0000 (98.8491)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:44  Lr: 0.001875  Loss: 0.5450  Acc@1: 81.2500 (79.4263)  Acc@5: 100.0000 (98.8486)  time: 0.3461  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:40  Lr: 0.001875  Loss: 0.5559  Acc@1: 81.2500 (79.4205)  Acc@5: 100.0000 (98.8426)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:37  Lr: 0.001875  Loss: 0.5127  Acc@1: 75.0000 (79.4119)  Acc@5: 100.0000 (98.8394)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:34  Lr: 0.001875  Loss: 0.2649  Acc@1: 75.0000 (79.3979)  Acc@5: 100.0000 (98.8362)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:30  Lr: 0.001875  Loss: 0.6628  Acc@1: 75.0000 (79.3951)  Acc@5: 100.0000 (98.8304)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:27  Lr: 0.001875  Loss: 0.4156  Acc@1: 75.0000 (79.3895)  Acc@5: 100.0000 (98.8300)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:23  Lr: 0.001875  Loss: 0.6067  Acc@1: 81.2500 (79.3949)  Acc@5: 100.0000 (98.8351)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:20  Lr: 0.001875  Loss: 0.7131  Acc@1: 81.2500 (79.3921)  Acc@5: 100.0000 (98.8375)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:16  Lr: 0.001875  Loss: 0.8984  Acc@1: 75.0000 (79.3812)  Acc@5: 100.0000 (98.8344)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:13  Lr: 0.001875  Loss: 0.3016  Acc@1: 81.2500 (79.3947)  Acc@5: 100.0000 (98.8367)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:09  Lr: 0.001875  Loss: 0.5770  Acc@1: 81.2500 (79.3999)  Acc@5: 100.0000 (98.8390)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:06  Lr: 0.001875  Loss: 0.4926  Acc@1: 81.2500 (79.3918)  Acc@5: 100.0000 (98.8413)  time: 0.3460  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:03  Lr: 0.001875  Loss: 0.3957  Acc@1: 81.2500 (79.3891)  Acc@5: 100.0000 (98.8409)  time: 0.3456  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2360/3750]  eta: 0:07:59  Lr: 0.001875  Loss: 0.9452  Acc@1: 81.2500 (79.3811)  Acc@5: 100.0000 (98.8458)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2370/3750]  eta: 0:07:56  Lr: 0.001875  Loss: 0.3736  Acc@1: 81.2500 (79.3863)  Acc@5: 100.0000 (98.8428)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:52  Lr: 0.001875  Loss: 0.4891  Acc@1: 87.5000 (79.4099)  Acc@5: 100.0000 (98.8424)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:49  Lr: 0.001875  Loss: 0.5248  Acc@1: 87.5000 (79.4333)  Acc@5: 100.0000 (98.8472)  time: 0.3454  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:45  Lr: 0.001875  Loss: 0.8849  Acc@1: 81.2500 (79.4226)  Acc@5: 100.0000 (98.8494)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:42  Lr: 0.001875  Loss: 0.7823  Acc@1: 81.2500 (79.4328)  Acc@5: 100.0000 (98.8516)  time: 0.3451  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:38  Lr: 0.001875  Loss: 0.5899  Acc@1: 81.2500 (79.4222)  Acc@5: 100.0000 (98.8538)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:35  Lr: 0.001875  Loss: 0.9578  Acc@1: 75.0000 (79.4092)  Acc@5: 100.0000 (98.8456)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:32  Lr: 0.001875  Loss: 0.3924  Acc@1: 75.0000 (79.4167)  Acc@5: 100.0000 (98.8376)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:28  Lr: 0.001875  Loss: 1.0372  Acc@1: 81.2500 (79.4115)  Acc@5: 100.0000 (98.8347)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:25  Lr: 0.001875  Loss: 0.6435  Acc@1: 81.2500 (79.4062)  Acc@5: 100.0000 (98.8369)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:21  Lr: 0.001875  Loss: 0.7325  Acc@1: 75.0000 (79.3960)  Acc@5: 100.0000 (98.8340)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:18  Lr: 0.001875  Loss: 0.4039  Acc@1: 75.0000 (79.3959)  Acc@5: 100.0000 (98.8336)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:14  Lr: 0.001875  Loss: 0.7270  Acc@1: 75.0000 (79.3707)  Acc@5: 100.0000 (98.8358)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:11  Lr: 0.001875  Loss: 0.5115  Acc@1: 75.0000 (79.3733)  Acc@5: 100.0000 (98.8405)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:07  Lr: 0.001875  Loss: 0.6363  Acc@1: 75.0000 (79.3658)  Acc@5: 100.0000 (98.8426)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:04  Lr: 0.001875  Loss: 0.5611  Acc@1: 75.0000 (79.3633)  Acc@5: 100.0000 (98.8373)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:00  Lr: 0.001875  Loss: 0.9827  Acc@1: 75.0000 (79.3362)  Acc@5: 100.0000 (98.8369)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2540/3750]  eta: 0:06:57  Lr: 0.001875  Loss: 0.2315  Acc@1: 81.2500 (79.3610)  Acc@5: 100.0000 (98.8390)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:54  Lr: 0.001875  Loss: 0.4267  Acc@1: 87.5000 (79.3831)  Acc@5: 100.0000 (98.8411)  time: 0.3457  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:50  Lr: 0.001875  Loss: 0.4130  Acc@1: 81.2500 (79.3733)  Acc@5: 100.0000 (98.8383)  time: 0.3462  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:47  Lr: 0.001875  Loss: 0.1370  Acc@1: 81.2500 (79.3927)  Acc@5: 100.0000 (98.8429)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:43  Lr: 0.001875  Loss: 0.5815  Acc@1: 81.2500 (79.3806)  Acc@5: 100.0000 (98.8425)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:40  Lr: 0.001875  Loss: 0.8632  Acc@1: 75.0000 (79.3950)  Acc@5: 100.0000 (98.8446)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:36  Lr: 0.001875  Loss: 1.0168  Acc@1: 75.0000 (79.3853)  Acc@5: 100.0000 (98.8466)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:33  Lr: 0.001875  Loss: 0.5836  Acc@1: 75.0000 (79.3805)  Acc@5: 100.0000 (98.8438)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:29  Lr: 0.001875  Loss: 0.6073  Acc@1: 81.2500 (79.3996)  Acc@5: 100.0000 (98.8482)  time: 0.3433  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:26  Lr: 0.001875  Loss: 0.0698  Acc@1: 81.2500 (79.4090)  Acc@5: 100.0000 (98.8455)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:22  Lr: 0.001875  Loss: 0.4251  Acc@1: 81.2500 (79.4065)  Acc@5: 100.0000 (98.8451)  time: 0.3446  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:19  Lr: 0.001875  Loss: 0.3911  Acc@1: 81.2500 (79.3946)  Acc@5: 100.0000 (98.8495)  time: 0.3442  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:16  Lr: 0.001875  Loss: 0.5558  Acc@1: 81.2500 (79.3945)  Acc@5: 100.0000 (98.8491)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:12  Lr: 0.001875  Loss: 0.4691  Acc@1: 81.2500 (79.3804)  Acc@5: 100.0000 (98.8464)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:09  Lr: 0.001875  Loss: 0.8467  Acc@1: 75.0000 (79.3780)  Acc@5: 100.0000 (98.8460)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:05  Lr: 0.001875  Loss: 0.3987  Acc@1: 75.0000 (79.3571)  Acc@5: 100.0000 (98.8387)  time: 0.3446  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:02  Lr: 0.001875  Loss: 0.9595  Acc@1: 75.0000 (79.3641)  Acc@5: 100.0000 (98.8384)  time: 0.3441  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2710/3750]  eta: 0:05:58  Lr: 0.001875  Loss: 0.5305  Acc@1: 75.0000 (79.3711)  Acc@5: 100.0000 (98.8427)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:55  Lr: 0.001875  Loss: 0.3959  Acc@1: 75.0000 (79.3757)  Acc@5: 100.0000 (98.8469)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:51  Lr: 0.001875  Loss: 0.6432  Acc@1: 75.0000 (79.3711)  Acc@5: 100.0000 (98.8466)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:48  Lr: 0.001875  Loss: 0.1801  Acc@1: 75.0000 (79.3688)  Acc@5: 100.0000 (98.8462)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:45  Lr: 0.001875  Loss: 0.5581  Acc@1: 81.2500 (79.3734)  Acc@5: 100.0000 (98.8436)  time: 0.3442  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:41  Lr: 0.001875  Loss: 0.6742  Acc@1: 81.2500 (79.3779)  Acc@5: 100.0000 (98.8433)  time: 0.3436  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:38  Lr: 0.001875  Loss: 0.6778  Acc@1: 75.0000 (79.3734)  Acc@5: 100.0000 (98.8429)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:34  Lr: 0.001875  Loss: 0.8065  Acc@1: 75.0000 (79.3757)  Acc@5: 100.0000 (98.8403)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:31  Lr: 0.001875  Loss: 0.1506  Acc@1: 75.0000 (79.3779)  Acc@5: 100.0000 (98.8355)  time: 0.3436  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:27  Lr: 0.001875  Loss: 0.8491  Acc@1: 81.2500 (79.3980)  Acc@5: 100.0000 (98.8352)  time: 0.3441  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:24  Lr: 0.001875  Loss: 0.4983  Acc@1: 81.2500 (79.4046)  Acc@5: 100.0000 (98.8327)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:20  Lr: 0.001875  Loss: 0.7001  Acc@1: 81.2500 (79.4067)  Acc@5: 100.0000 (98.8280)  time: 0.3439  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:17  Lr: 0.001875  Loss: 0.4298  Acc@1: 81.2500 (79.4220)  Acc@5: 100.0000 (98.8321)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:13  Lr: 0.001875  Loss: 0.3748  Acc@1: 81.2500 (79.4329)  Acc@5: 100.0000 (98.8340)  time: 0.3437  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:10  Lr: 0.001875  Loss: 0.9549  Acc@1: 75.0000 (79.4042)  Acc@5: 100.0000 (98.8337)  time: 0.3448  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:07  Lr: 0.001875  Loss: 0.3312  Acc@1: 75.0000 (79.4150)  Acc@5: 100.0000 (98.8378)  time: 0.3451  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:03  Lr: 0.001875  Loss: 0.3583  Acc@1: 81.2500 (79.4192)  Acc@5: 100.0000 (98.8375)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:00  Lr: 0.001875  Loss: 0.4701  Acc@1: 81.2500 (79.4212)  Acc@5: 100.0000 (98.8394)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2890/3750]  eta: 0:04:56  Lr: 0.001875  Loss: 0.8780  Acc@1: 81.2500 (79.4319)  Acc@5: 100.0000 (98.8412)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:53  Lr: 0.001875  Loss: 0.2504  Acc@1: 81.2500 (79.4274)  Acc@5: 100.0000 (98.8388)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:49  Lr: 0.001875  Loss: 0.5088  Acc@1: 75.0000 (79.4272)  Acc@5: 100.0000 (98.8406)  time: 0.3440  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:46  Lr: 0.001875  Loss: 0.8506  Acc@1: 75.0000 (79.4184)  Acc@5: 100.0000 (98.8403)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:42  Lr: 0.001875  Loss: 0.3940  Acc@1: 75.0000 (79.3970)  Acc@5: 100.0000 (98.8400)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:39  Lr: 0.001875  Loss: 0.3869  Acc@1: 81.2500 (79.4330)  Acc@5: 100.0000 (98.8418)  time: 0.3449  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:35  Lr: 0.001875  Loss: 0.9403  Acc@1: 87.5000 (79.4265)  Acc@5: 100.0000 (98.8415)  time: 0.3443  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:32  Lr: 0.001875  Loss: 0.7540  Acc@1: 75.0000 (79.4010)  Acc@5: 100.0000 (98.8412)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:29  Lr: 0.001875  Loss: 0.4675  Acc@1: 81.2500 (79.4156)  Acc@5: 100.0000 (98.8451)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:25  Lr: 0.001875  Loss: 0.6096  Acc@1: 81.2500 (79.4176)  Acc@5: 100.0000 (98.8406)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:22  Lr: 0.001875  Loss: 0.5995  Acc@1: 81.2500 (79.4195)  Acc@5: 100.0000 (98.8361)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:18  Lr: 0.001875  Loss: 0.7600  Acc@1: 81.2500 (79.4173)  Acc@5: 100.0000 (98.8400)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:15  Lr: 0.001875  Loss: 0.2982  Acc@1: 81.2500 (79.4337)  Acc@5: 100.0000 (98.8417)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:11  Lr: 0.001875  Loss: 0.6724  Acc@1: 81.2500 (79.4294)  Acc@5: 100.0000 (98.8414)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:08  Lr: 0.001875  Loss: 0.8832  Acc@1: 75.0000 (79.4169)  Acc@5: 100.0000 (98.8411)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:04  Lr: 0.001875  Loss: 0.2823  Acc@1: 75.0000 (79.4064)  Acc@5: 100.0000 (98.8388)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:01  Lr: 0.001875  Loss: 0.1795  Acc@1: 81.2500 (79.4084)  Acc@5: 100.0000 (98.8385)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3060/3750]  eta: 0:03:58  Lr: 0.001875  Loss: 0.4702  Acc@1: 75.0000 (79.3858)  Acc@5: 100.0000 (98.8382)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.4367  Acc@1: 75.0000 (79.3817)  Acc@5: 100.0000 (98.8400)  time: 0.3447  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:51  Lr: 0.001875  Loss: 0.8054  Acc@1: 81.2500 (79.3797)  Acc@5: 100.0000 (98.8417)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:47  Lr: 0.001875  Loss: 0.5275  Acc@1: 81.2500 (79.3877)  Acc@5: 100.0000 (98.8434)  time: 0.3459  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:44  Lr: 0.001875  Loss: 0.2721  Acc@1: 87.5000 (79.4058)  Acc@5: 100.0000 (98.8371)  time: 0.3452  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:40  Lr: 0.001875  Loss: 0.6131  Acc@1: 87.5000 (79.4098)  Acc@5: 100.0000 (98.8328)  time: 0.3453  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:37  Lr: 0.001875  Loss: 0.3410  Acc@1: 81.2500 (79.4197)  Acc@5: 100.0000 (98.8345)  time: 0.3457  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.5558  Acc@1: 81.2500 (79.4175)  Acc@5: 100.0000 (98.8322)  time: 0.3457  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.5557  Acc@1: 81.2500 (79.4194)  Acc@5: 100.0000 (98.8320)  time: 0.3453  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:26  Lr: 0.001875  Loss: 0.2470  Acc@1: 81.2500 (79.4351)  Acc@5: 100.0000 (98.8297)  time: 0.3459  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.5323  Acc@1: 81.2500 (79.4290)  Acc@5: 100.0000 (98.8315)  time: 0.3453  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:20  Lr: 0.001875  Loss: 0.4840  Acc@1: 75.0000 (79.4268)  Acc@5: 100.0000 (98.8332)  time: 0.3447  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:16  Lr: 0.001875  Loss: 0.1541  Acc@1: 81.2500 (79.4227)  Acc@5: 100.0000 (98.8309)  time: 0.3453  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:13  Lr: 0.001875  Loss: 0.9694  Acc@1: 81.2500 (79.4148)  Acc@5: 100.0000 (98.8327)  time: 0.3446  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:09  Lr: 0.001875  Loss: 0.8419  Acc@1: 81.2500 (79.4127)  Acc@5: 100.0000 (98.8304)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:06  Lr: 0.001875  Loss: 0.4083  Acc@1: 81.2500 (79.4242)  Acc@5: 100.0000 (98.8321)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:02  Lr: 0.001875  Loss: 0.5303  Acc@1: 81.2500 (79.4338)  Acc@5: 100.0000 (98.8319)  time: 0.3457  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 0.4335  Acc@1: 81.2500 (79.4297)  Acc@5: 100.0000 (98.8297)  time: 0.3450  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:55  Lr: 0.001875  Loss: 0.2443  Acc@1: 81.2500 (79.4489)  Acc@5: 100.0000 (98.8295)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.5008  Acc@1: 81.2500 (79.4467)  Acc@5: 100.0000 (98.8311)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:49  Lr: 0.001875  Loss: 0.5126  Acc@1: 81.2500 (79.4503)  Acc@5: 100.0000 (98.8347)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 0.3824  Acc@1: 87.5000 (79.4654)  Acc@5: 100.0000 (98.8345)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:42  Lr: 0.001875  Loss: 0.4691  Acc@1: 81.2500 (79.4556)  Acc@5: 100.0000 (98.8323)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 0.3199  Acc@1: 75.0000 (79.4534)  Acc@5: 100.0000 (98.8320)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:35  Lr: 0.001875  Loss: 0.1721  Acc@1: 75.0000 (79.4627)  Acc@5: 100.0000 (98.8299)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:31  Lr: 0.001875  Loss: 0.3371  Acc@1: 81.2500 (79.4643)  Acc@5: 100.0000 (98.8278)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.6829  Acc@1: 81.2500 (79.4603)  Acc@5: 100.0000 (98.8294)  time: 0.3451  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:24  Lr: 0.001875  Loss: 0.2497  Acc@1: 81.2500 (79.4731)  Acc@5: 100.0000 (98.8273)  time: 0.3454  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.8351  Acc@1: 81.2500 (79.4784)  Acc@5: 100.0000 (98.8289)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:17  Lr: 0.001875  Loss: 0.5588  Acc@1: 81.2500 (79.4707)  Acc@5: 100.0000 (98.8306)  time: 0.3439  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.5646  Acc@1: 81.2500 (79.4630)  Acc@5: 100.0000 (98.8266)  time: 0.3443  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:11  Lr: 0.001875  Loss: 0.1085  Acc@1: 81.2500 (79.4775)  Acc@5: 100.0000 (98.8282)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.2797  Acc@1: 87.5000 (79.4883)  Acc@5: 100.0000 (98.8299)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:04  Lr: 0.001875  Loss: 0.4696  Acc@1: 81.2500 (79.4843)  Acc@5: 100.0000 (98.8333)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 0.3225  Acc@1: 81.2500 (79.4840)  Acc@5: 100.0000 (98.8331)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.5096  Acc@1: 81.2500 (79.4763)  Acc@5: 100.0000 (98.8347)  time: 0.3440  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 0.5027  Acc@1: 81.2500 (79.4870)  Acc@5: 100.0000 (98.8362)  time: 0.3450  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.9658  Acc@1: 81.2500 (79.5067)  Acc@5: 100.0000 (98.8396)  time: 0.3454  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:46  Lr: 0.001875  Loss: 0.1291  Acc@1: 81.2500 (79.5209)  Acc@5: 100.0000 (98.8412)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.4843  Acc@1: 75.0000 (79.5096)  Acc@5: 100.0000 (98.8409)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: 0.4885  Acc@1: 81.2500 (79.5146)  Acc@5: 100.0000 (98.8425)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.5232  Acc@1: 81.2500 (79.5052)  Acc@5: 100.0000 (98.8422)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: 0.7073  Acc@1: 81.2500 (79.5192)  Acc@5: 100.0000 (98.8401)  time: 0.3442  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.7623  Acc@1: 81.2500 (79.5134)  Acc@5: 100.0000 (98.8417)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.5197  Acc@1: 81.2500 (79.5166)  Acc@5: 100.0000 (98.8450)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.4264  Acc@1: 81.2500 (79.5233)  Acc@5: 100.0000 (98.8429)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.9796  Acc@1: 75.0000 (79.5264)  Acc@5: 100.0000 (98.8427)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 0.5004  Acc@1: 81.2500 (79.5384)  Acc@5: 100.0000 (98.8442)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.8172  Acc@1: 87.5000 (79.5591)  Acc@5: 100.0000 (98.8439)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:08  Lr: 0.001875  Loss: 0.3269  Acc@1: 81.2500 (79.5603)  Acc@5: 100.0000 (98.8472)  time: 0.3431  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.2728  Acc@1: 81.2500 (79.5668)  Acc@5: 100.0000 (98.8486)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: 0.8989  Acc@1: 81.2500 (79.5715)  Acc@5: 100.0000 (98.8501)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.9628  Acc@1: 81.2500 (79.5710)  Acc@5: 100.0000 (98.8481)  time: 0.3451  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.5042  Acc@1: 81.2500 (79.5826)  Acc@5: 100.0000 (98.8496)  time: 0.3447  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3352  Acc@1: 81.2500 (79.5821)  Acc@5: 100.0000 (98.8493)  time: 0.3438  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.6529  Acc@1: 81.2500 (79.5798)  Acc@5: 100.0000 (98.8490)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3071  Acc@1: 81.2500 (79.5878)  Acc@5: 100.0000 (98.8522)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.8017  Acc@1: 81.2500 (79.5631)  Acc@5: 100.0000 (98.8553)  time: 0.3443  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 0.5262  Acc@1: 75.0000 (79.5609)  Acc@5: 100.0000 (98.8465)  time: 0.3453  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4231  Acc@1: 75.0000 (79.5484)  Acc@5: 100.0000 (98.8428)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: 0.5049  Acc@1: 75.0000 (79.5462)  Acc@5: 100.0000 (98.8442)  time: 0.3452  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3718  Acc@1: 81.2500 (79.5321)  Acc@5: 100.0000 (98.8457)  time: 0.3446  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1574  Acc@1: 81.2500 (79.5368)  Acc@5: 100.0000 (98.8386)  time: 0.3451  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 1.0771  Acc@1: 81.2500 (79.5330)  Acc@5: 100.0000 (98.8401)  time: 0.3457  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.6826  Acc@1: 81.2500 (79.5326)  Acc@5: 100.0000 (98.8365)  time: 0.3446  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.6175  Acc@1: 81.2500 (79.5355)  Acc@5: 100.0000 (98.8379)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.6837  Acc@1: 75.0000 (79.5334)  Acc@5: 100.0000 (98.8360)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.3791  Acc@1: 75.0000 (79.5397)  Acc@5: 100.0000 (98.8324)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.3345  Acc@1: 81.2500 (79.5376)  Acc@5: 100.0000 (98.8339)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3590  Acc@1: 81.2500 (79.5383)  Acc@5: 100.0000 (98.8317)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[2/5] Total time: 0:21:33 (0.3451 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.3590  Acc@1: 81.2500 (79.5383)  Acc@5: 100.0000 (98.8317)
Train: Epoch[3/5]  [   0/3750]  eta: 0:47:47  Lr: 0.001875  Loss: 0.2201  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7645  data: 0.4207  max mem: 2503
Train: Epoch[3/5]  [  10/3750]  eta: 0:23:51  Lr: 0.001875  Loss: 0.9169  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (97.7273)  time: 0.3827  data: 0.0385  max mem: 2503
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:37  Lr: 0.001875  Loss: 0.6688  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (97.3214)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:10  Lr: 0.001875  Loss: 0.6846  Acc@1: 81.2500 (79.8387)  Acc@5: 100.0000 (97.7823)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  40/3750]  eta: 0:21:55  Lr: 0.001875  Loss: 0.7207  Acc@1: 81.2500 (79.7256)  Acc@5: 100.0000 (97.7134)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [  50/3750]  eta: 0:21:44  Lr: 0.001875  Loss: 0.4921  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (98.0392)  time: 0.3446  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:36  Lr: 0.001875  Loss: 0.3595  Acc@1: 75.0000 (78.7910)  Acc@5: 100.0000 (98.2582)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:30  Lr: 0.001875  Loss: 0.2898  Acc@1: 75.0000 (79.1373)  Acc@5: 100.0000 (98.3275)  time: 0.3459  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:23  Lr: 0.001875  Loss: 0.5513  Acc@1: 75.0000 (79.0123)  Acc@5: 100.0000 (98.4568)  time: 0.3454  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:17  Lr: 0.001875  Loss: 0.1965  Acc@1: 87.5000 (79.7390)  Acc@5: 100.0000 (98.4203)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:12  Lr: 0.001875  Loss: 0.3041  Acc@1: 87.5000 (79.9505)  Acc@5: 100.0000 (98.4530)  time: 0.3439  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:08  Lr: 0.001875  Loss: 0.8047  Acc@1: 81.2500 (79.7860)  Acc@5: 100.0000 (98.4234)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:04  Lr: 0.001875  Loss: 0.4058  Acc@1: 81.2500 (79.9587)  Acc@5: 100.0000 (98.5537)  time: 0.3463  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 130/3750]  eta: 0:20:59  Lr: 0.001875  Loss: 0.5517  Acc@1: 81.2500 (79.8187)  Acc@5: 100.0000 (98.6164)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 140/3750]  eta: 0:20:55  Lr: 0.001875  Loss: 0.1363  Acc@1: 81.2500 (80.2748)  Acc@5: 100.0000 (98.7145)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 150/3750]  eta: 0:20:50  Lr: 0.001875  Loss: 0.3294  Acc@1: 81.2500 (80.1738)  Acc@5: 100.0000 (98.7169)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 160/3750]  eta: 0:20:46  Lr: 0.001875  Loss: 0.3760  Acc@1: 81.2500 (80.1630)  Acc@5: 100.0000 (98.7578)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:42  Lr: 0.001875  Loss: 0.5754  Acc@1: 75.0000 (80.0439)  Acc@5: 100.0000 (98.7939)  time: 0.3444  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:38  Lr: 0.001875  Loss: 0.5145  Acc@1: 75.0000 (79.9378)  Acc@5: 100.0000 (98.7914)  time: 0.3443  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:34  Lr: 0.001875  Loss: 0.9189  Acc@1: 81.2500 (79.8757)  Acc@5: 100.0000 (98.7893)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:30  Lr: 0.001875  Loss: 0.3042  Acc@1: 81.2500 (79.7264)  Acc@5: 100.0000 (98.7873)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:26  Lr: 0.001875  Loss: 0.5292  Acc@1: 75.0000 (79.4727)  Acc@5: 100.0000 (98.7559)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:22  Lr: 0.001875  Loss: 0.2615  Acc@1: 75.0000 (79.5532)  Acc@5: 100.0000 (98.6991)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:19  Lr: 0.001875  Loss: 0.8186  Acc@1: 81.2500 (79.6807)  Acc@5: 100.0000 (98.7284)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:15  Lr: 0.001875  Loss: 0.2435  Acc@1: 81.2500 (79.7977)  Acc@5: 100.0000 (98.7552)  time: 0.3444  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:11  Lr: 0.001875  Loss: 0.8956  Acc@1: 81.2500 (79.7560)  Acc@5: 100.0000 (98.7052)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:08  Lr: 0.001875  Loss: 0.4803  Acc@1: 81.2500 (79.7653)  Acc@5: 100.0000 (98.7308)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:04  Lr: 0.001875  Loss: 0.7333  Acc@1: 81.2500 (79.7970)  Acc@5: 100.0000 (98.6624)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:00  Lr: 0.001875  Loss: 0.3774  Acc@1: 81.2500 (79.8265)  Acc@5: 100.0000 (98.6655)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 290/3750]  eta: 0:19:57  Lr: 0.001875  Loss: 0.4102  Acc@1: 81.2500 (79.8110)  Acc@5: 100.0000 (98.6684)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 300/3750]  eta: 0:19:53  Lr: 0.001875  Loss: 0.2526  Acc@1: 81.2500 (79.8173)  Acc@5: 100.0000 (98.6919)  time: 0.3454  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 310/3750]  eta: 0:19:50  Lr: 0.001875  Loss: 0.2901  Acc@1: 81.2500 (79.8031)  Acc@5: 100.0000 (98.6736)  time: 0.3445  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 320/3750]  eta: 0:19:46  Lr: 0.001875  Loss: 0.7771  Acc@1: 81.2500 (79.9065)  Acc@5: 100.0000 (98.6955)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:42  Lr: 0.001875  Loss: 0.3897  Acc@1: 81.2500 (79.9660)  Acc@5: 100.0000 (98.7349)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:39  Lr: 0.001875  Loss: 0.7746  Acc@1: 81.2500 (79.9670)  Acc@5: 100.0000 (98.7720)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:35  Lr: 0.001875  Loss: 0.5609  Acc@1: 81.2500 (80.0036)  Acc@5: 100.0000 (98.7892)  time: 0.3462  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:32  Lr: 0.001875  Loss: 0.4619  Acc@1: 81.2500 (80.0900)  Acc@5: 100.0000 (98.8054)  time: 0.3467  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:28  Lr: 0.001875  Loss: 0.9759  Acc@1: 81.2500 (80.1213)  Acc@5: 100.0000 (98.7871)  time: 0.3459  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:25  Lr: 0.001875  Loss: 0.4918  Acc@1: 75.0000 (79.9049)  Acc@5: 100.0000 (98.7861)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:21  Lr: 0.001875  Loss: 0.5294  Acc@1: 75.0000 (79.9712)  Acc@5: 100.0000 (98.8171)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:18  Lr: 0.001875  Loss: 0.4675  Acc@1: 81.2500 (80.1122)  Acc@5: 100.0000 (98.8466)  time: 0.3455  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:14  Lr: 0.001875  Loss: 0.1740  Acc@1: 87.5000 (80.2464)  Acc@5: 100.0000 (98.8747)  time: 0.3459  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:11  Lr: 0.001875  Loss: 0.6238  Acc@1: 81.2500 (80.1960)  Acc@5: 100.0000 (98.8866)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:07  Lr: 0.001875  Loss: 0.4018  Acc@1: 81.2500 (80.2494)  Acc@5: 100.0000 (98.8834)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:04  Lr: 0.001875  Loss: 0.7013  Acc@1: 81.2500 (80.2863)  Acc@5: 100.0000 (98.8946)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:00  Lr: 0.001875  Loss: 0.3692  Acc@1: 75.0000 (80.2799)  Acc@5: 100.0000 (98.8914)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 460/3750]  eta: 0:18:57  Lr: 0.001875  Loss: 0.3769  Acc@1: 81.2500 (80.3416)  Acc@5: 100.0000 (98.8883)  time: 0.3454  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 470/3750]  eta: 0:18:53  Lr: 0.001875  Loss: 0.3092  Acc@1: 81.2500 (80.3609)  Acc@5: 100.0000 (98.8854)  time: 0.3449  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 480/3750]  eta: 0:18:50  Lr: 0.001875  Loss: 0.7538  Acc@1: 81.2500 (80.3794)  Acc@5: 100.0000 (98.8955)  time: 0.3454  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 490/3750]  eta: 0:18:47  Lr: 0.001875  Loss: 0.7271  Acc@1: 81.2500 (80.4099)  Acc@5: 100.0000 (98.8798)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:43  Lr: 0.001875  Loss: 0.5584  Acc@1: 75.0000 (80.3767)  Acc@5: 100.0000 (98.8772)  time: 0.3465  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:40  Lr: 0.001875  Loss: 0.6000  Acc@1: 75.0000 (80.3694)  Acc@5: 100.0000 (98.8625)  time: 0.3459  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:36  Lr: 0.001875  Loss: 0.6847  Acc@1: 81.2500 (80.4103)  Acc@5: 100.0000 (98.8844)  time: 0.3460  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:33  Lr: 0.001875  Loss: 0.4584  Acc@1: 81.2500 (80.4849)  Acc@5: 100.0000 (98.9054)  time: 0.3455  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:29  Lr: 0.001875  Loss: 0.4245  Acc@1: 81.2500 (80.4182)  Acc@5: 100.0000 (98.9025)  time: 0.3458  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:26  Lr: 0.001875  Loss: 0.4188  Acc@1: 75.0000 (80.4106)  Acc@5: 100.0000 (98.8770)  time: 0.3464  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:22  Lr: 0.001875  Loss: 0.6052  Acc@1: 75.0000 (80.3030)  Acc@5: 100.0000 (98.8636)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:19  Lr: 0.001875  Loss: 0.5632  Acc@1: 75.0000 (80.3743)  Acc@5: 100.0000 (98.8726)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:15  Lr: 0.001875  Loss: 0.5810  Acc@1: 81.2500 (80.4109)  Acc@5: 100.0000 (98.8920)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:12  Lr: 0.001875  Loss: 0.4737  Acc@1: 81.2500 (80.4040)  Acc@5: 100.0000 (98.9002)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:08  Lr: 0.001875  Loss: 0.9002  Acc@1: 81.2500 (80.3245)  Acc@5: 100.0000 (98.8977)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:05  Lr: 0.001875  Loss: 0.7516  Acc@1: 81.2500 (80.3805)  Acc@5: 100.0000 (98.9055)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:01  Lr: 0.001875  Loss: 0.8930  Acc@1: 81.2500 (80.2436)  Acc@5: 100.0000 (98.8829)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 630/3750]  eta: 0:17:58  Lr: 0.001875  Loss: 0.7682  Acc@1: 81.2500 (80.2496)  Acc@5: 100.0000 (98.8906)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 640/3750]  eta: 0:17:54  Lr: 0.001875  Loss: 0.6280  Acc@1: 81.2500 (80.1385)  Acc@5: 100.0000 (98.8690)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 650/3750]  eta: 0:17:51  Lr: 0.001875  Loss: 0.5171  Acc@1: 75.0000 (80.0595)  Acc@5: 100.0000 (98.8863)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 660/3750]  eta: 0:17:47  Lr: 0.001875  Loss: 0.5093  Acc@1: 81.2500 (80.1343)  Acc@5: 100.0000 (98.9032)  time: 0.3453  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:44  Lr: 0.001875  Loss: 0.4069  Acc@1: 81.2500 (80.1043)  Acc@5: 100.0000 (98.9102)  time: 0.3452  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:41  Lr: 0.001875  Loss: 0.8152  Acc@1: 81.2500 (80.1211)  Acc@5: 100.0000 (98.9262)  time: 0.3455  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:37  Lr: 0.001875  Loss: 0.7398  Acc@1: 81.2500 (80.1918)  Acc@5: 100.0000 (98.9327)  time: 0.3466  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:34  Lr: 0.001875  Loss: 0.3287  Acc@1: 81.2500 (80.1979)  Acc@5: 100.0000 (98.9390)  time: 0.3453  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:30  Lr: 0.001875  Loss: 0.3628  Acc@1: 81.2500 (80.2127)  Acc@5: 100.0000 (98.9539)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:27  Lr: 0.001875  Loss: 0.1350  Acc@1: 81.2500 (80.2445)  Acc@5: 100.0000 (98.9598)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:23  Lr: 0.001875  Loss: 0.8160  Acc@1: 81.2500 (80.2240)  Acc@5: 100.0000 (98.9398)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:20  Lr: 0.001875  Loss: 0.4038  Acc@1: 81.2500 (80.2800)  Acc@5: 100.0000 (98.9457)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:16  Lr: 0.001875  Loss: 0.7190  Acc@1: 81.2500 (80.2347)  Acc@5: 100.0000 (98.9348)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:13  Lr: 0.001875  Loss: 0.3853  Acc@1: 75.0000 (80.2152)  Acc@5: 100.0000 (98.9405)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:09  Lr: 0.001875  Loss: 1.1327  Acc@1: 81.2500 (80.2367)  Acc@5: 100.0000 (98.9137)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:06  Lr: 0.001875  Loss: 0.4447  Acc@1: 81.2500 (80.2817)  Acc@5: 100.0000 (98.9277)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:02  Lr: 0.001875  Loss: 0.5583  Acc@1: 81.2500 (80.2544)  Acc@5: 100.0000 (98.9412)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 800/3750]  eta: 0:16:59  Lr: 0.001875  Loss: 0.9092  Acc@1: 81.2500 (80.2434)  Acc@5: 100.0000 (98.8842)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 810/3750]  eta: 0:16:56  Lr: 0.001875  Loss: 0.3276  Acc@1: 81.2500 (80.3021)  Acc@5: 100.0000 (98.8903)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 820/3750]  eta: 0:16:52  Lr: 0.001875  Loss: 0.3824  Acc@1: 81.2500 (80.2908)  Acc@5: 100.0000 (98.8886)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 830/3750]  eta: 0:16:49  Lr: 0.001875  Loss: 0.4880  Acc@1: 81.2500 (80.3400)  Acc@5: 100.0000 (98.8869)  time: 0.3452  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:45  Lr: 0.001875  Loss: 0.5947  Acc@1: 81.2500 (80.3285)  Acc@5: 100.0000 (98.9001)  time: 0.3451  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:42  Lr: 0.001875  Loss: 0.5751  Acc@1: 81.2500 (80.3467)  Acc@5: 100.0000 (98.9130)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:38  Lr: 0.001875  Loss: 0.6910  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (98.9111)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:35  Lr: 0.001875  Loss: 0.7940  Acc@1: 81.2500 (80.3028)  Acc@5: 100.0000 (98.9021)  time: 0.3462  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:31  Lr: 0.001875  Loss: 0.8248  Acc@1: 81.2500 (80.3278)  Acc@5: 100.0000 (98.9146)  time: 0.3457  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:28  Lr: 0.001875  Loss: 0.5154  Acc@1: 81.2500 (80.3100)  Acc@5: 100.0000 (98.9198)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:24  Lr: 0.001875  Loss: 0.6340  Acc@1: 81.2500 (80.2719)  Acc@5: 100.0000 (98.9248)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:21  Lr: 0.001875  Loss: 0.4150  Acc@1: 75.0000 (80.2415)  Acc@5: 100.0000 (98.9297)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:17  Lr: 0.001875  Loss: 0.7143  Acc@1: 81.2500 (80.2660)  Acc@5: 100.0000 (98.9210)  time: 0.3452  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:14  Lr: 0.001875  Loss: 0.2999  Acc@1: 81.2500 (80.2229)  Acc@5: 100.0000 (98.9057)  time: 0.3453  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:10  Lr: 0.001875  Loss: 0.8849  Acc@1: 81.2500 (80.2604)  Acc@5: 100.0000 (98.9107)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:07  Lr: 0.001875  Loss: 0.1649  Acc@1: 87.5000 (80.2773)  Acc@5: 100.0000 (98.9156)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:04  Lr: 0.001875  Loss: 0.3792  Acc@1: 87.5000 (80.3135)  Acc@5: 100.0000 (98.9204)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:00  Lr: 0.001875  Loss: 0.5748  Acc@1: 87.5000 (80.3167)  Acc@5: 100.0000 (98.9186)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 980/3750]  eta: 0:15:57  Lr: 0.001875  Loss: 0.3721  Acc@1: 81.2500 (80.3135)  Acc@5: 100.0000 (98.9169)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 990/3750]  eta: 0:15:53  Lr: 0.001875  Loss: 0.5149  Acc@1: 81.2500 (80.3229)  Acc@5: 100.0000 (98.9152)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1000/3750]  eta: 0:15:50  Lr: 0.001875  Loss: 0.3136  Acc@1: 81.2500 (80.3072)  Acc@5: 100.0000 (98.9136)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:46  Lr: 0.001875  Loss: 0.7406  Acc@1: 81.2500 (80.3165)  Acc@5: 100.0000 (98.9058)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:43  Lr: 0.001875  Loss: 0.7918  Acc@1: 81.2500 (80.3318)  Acc@5: 100.0000 (98.9043)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:39  Lr: 0.001875  Loss: 0.6602  Acc@1: 81.2500 (80.3104)  Acc@5: 100.0000 (98.9088)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:36  Lr: 0.001875  Loss: 0.2376  Acc@1: 81.2500 (80.3614)  Acc@5: 100.0000 (98.9133)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:32  Lr: 0.001875  Loss: 0.5340  Acc@1: 81.2500 (80.3461)  Acc@5: 100.0000 (98.9236)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:29  Lr: 0.001875  Loss: 0.5788  Acc@1: 81.2500 (80.3723)  Acc@5: 100.0000 (98.9279)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:26  Lr: 0.001875  Loss: 0.3702  Acc@1: 87.5000 (80.4272)  Acc@5: 100.0000 (98.9321)  time: 0.3461  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:22  Lr: 0.001875  Loss: 0.5089  Acc@1: 87.5000 (80.4348)  Acc@5: 100.0000 (98.9246)  time: 0.3471  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:19  Lr: 0.001875  Loss: 0.5547  Acc@1: 81.2500 (80.4193)  Acc@5: 100.0000 (98.9115)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:15  Lr: 0.001875  Loss: 0.6102  Acc@1: 81.2500 (80.4496)  Acc@5: 100.0000 (98.9158)  time: 0.3454  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:12  Lr: 0.001875  Loss: 0.7967  Acc@1: 81.2500 (80.4399)  Acc@5: 100.0000 (98.9143)  time: 0.3451  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:08  Lr: 0.001875  Loss: 0.7366  Acc@1: 81.2500 (80.4527)  Acc@5: 100.0000 (98.9128)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:05  Lr: 0.001875  Loss: 0.4365  Acc@1: 81.2500 (80.4819)  Acc@5: 100.0000 (98.9169)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:01  Lr: 0.001875  Loss: 0.5358  Acc@1: 81.2500 (80.5050)  Acc@5: 100.0000 (98.9209)  time: 0.3452  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1150/3750]  eta: 0:14:58  Lr: 0.001875  Loss: 0.5244  Acc@1: 81.2500 (80.5224)  Acc@5: 100.0000 (98.9140)  time: 0.3458  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1160/3750]  eta: 0:14:54  Lr: 0.001875  Loss: 0.3997  Acc@1: 75.0000 (80.4587)  Acc@5: 100.0000 (98.9126)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1170/3750]  eta: 0:14:51  Lr: 0.001875  Loss: 0.2970  Acc@1: 75.0000 (80.4174)  Acc@5: 100.0000 (98.9112)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:47  Lr: 0.001875  Loss: 0.8462  Acc@1: 81.2500 (80.4244)  Acc@5: 100.0000 (98.9098)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:44  Lr: 0.001875  Loss: 0.3567  Acc@1: 81.2500 (80.4104)  Acc@5: 100.0000 (98.9032)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:40  Lr: 0.001875  Loss: 0.4901  Acc@1: 81.2500 (80.4330)  Acc@5: 100.0000 (98.8915)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:37  Lr: 0.001875  Loss: 0.5121  Acc@1: 81.2500 (80.4294)  Acc@5: 100.0000 (98.9007)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:34  Lr: 0.001875  Loss: 0.2971  Acc@1: 81.2500 (80.4668)  Acc@5: 100.0000 (98.9097)  time: 0.3468  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:30  Lr: 0.001875  Loss: 0.4501  Acc@1: 81.2500 (80.4833)  Acc@5: 100.0000 (98.9135)  time: 0.3468  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:27  Lr: 0.001875  Loss: 0.5580  Acc@1: 81.2500 (80.4392)  Acc@5: 100.0000 (98.9071)  time: 0.3449  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:23  Lr: 0.001875  Loss: 0.7226  Acc@1: 75.0000 (80.4456)  Acc@5: 100.0000 (98.9009)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:20  Lr: 0.001875  Loss: 0.7711  Acc@1: 87.5000 (80.4471)  Acc@5: 100.0000 (98.8997)  time: 0.3452  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:16  Lr: 0.001875  Loss: 0.6596  Acc@1: 81.2500 (80.4534)  Acc@5: 100.0000 (98.8985)  time: 0.3454  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:13  Lr: 0.001875  Loss: 0.7032  Acc@1: 81.2500 (80.4352)  Acc@5: 100.0000 (98.8925)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:09  Lr: 0.001875  Loss: 1.0542  Acc@1: 75.0000 (80.4125)  Acc@5: 100.0000 (98.8914)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:06  Lr: 0.001875  Loss: 0.9705  Acc@1: 75.0000 (80.3468)  Acc@5: 100.0000 (98.8951)  time: 0.3466  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:02  Lr: 0.001875  Loss: 0.3056  Acc@1: 75.0000 (80.3394)  Acc@5: 100.0000 (98.8987)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1320/3750]  eta: 0:13:59  Lr: 0.001875  Loss: 0.7676  Acc@1: 81.2500 (80.3700)  Acc@5: 100.0000 (98.8976)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1330/3750]  eta: 0:13:56  Lr: 0.001875  Loss: 0.2956  Acc@1: 87.5000 (80.4236)  Acc@5: 100.0000 (98.9012)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1340/3750]  eta: 0:13:52  Lr: 0.001875  Loss: 0.4150  Acc@1: 81.2500 (80.4204)  Acc@5: 100.0000 (98.9001)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:49  Lr: 0.001875  Loss: 0.6822  Acc@1: 81.2500 (80.3756)  Acc@5: 100.0000 (98.9036)  time: 0.3446  data: 0.0002  max mem: 2503
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:45  Lr: 0.001875  Loss: 0.3690  Acc@1: 75.0000 (80.3729)  Acc@5: 100.0000 (98.9025)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:42  Lr: 0.001875  Loss: 0.1688  Acc@1: 81.2500 (80.4158)  Acc@5: 100.0000 (98.9105)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:38  Lr: 0.001875  Loss: 0.3331  Acc@1: 81.2500 (80.4037)  Acc@5: 100.0000 (98.9003)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:35  Lr: 0.001875  Loss: 0.9785  Acc@1: 81.2500 (80.3873)  Acc@5: 100.0000 (98.8947)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:31  Lr: 0.001875  Loss: 0.6782  Acc@1: 75.0000 (80.3444)  Acc@5: 100.0000 (98.8758)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:28  Lr: 0.001875  Loss: 0.6049  Acc@1: 75.0000 (80.3464)  Acc@5: 100.0000 (98.8838)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:24  Lr: 0.001875  Loss: 0.2690  Acc@1: 81.2500 (80.3439)  Acc@5: 100.0000 (98.8828)  time: 0.3441  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:21  Lr: 0.001875  Loss: 0.4754  Acc@1: 75.0000 (80.3153)  Acc@5: 100.0000 (98.8732)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:17  Lr: 0.001875  Loss: 0.3810  Acc@1: 81.2500 (80.3565)  Acc@5: 100.0000 (98.8766)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:14  Lr: 0.001875  Loss: 0.5461  Acc@1: 87.5000 (80.3799)  Acc@5: 100.0000 (98.8801)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:11  Lr: 0.001875  Loss: 0.6440  Acc@1: 81.2500 (80.3645)  Acc@5: 100.0000 (98.8877)  time: 0.3458  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:07  Lr: 0.001875  Loss: 0.8746  Acc@1: 81.2500 (80.3832)  Acc@5: 100.0000 (98.8868)  time: 0.3465  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:04  Lr: 0.001875  Loss: 1.0596  Acc@1: 81.2500 (80.3891)  Acc@5: 100.0000 (98.8817)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:00  Lr: 0.001875  Loss: 0.6903  Acc@1: 75.0000 (80.3739)  Acc@5: 100.0000 (98.8892)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1500/3750]  eta: 0:12:57  Lr: 0.001875  Loss: 0.4831  Acc@1: 81.2500 (80.3922)  Acc@5: 100.0000 (98.8924)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1510/3750]  eta: 0:12:53  Lr: 0.001875  Loss: 0.6198  Acc@1: 81.2500 (80.3855)  Acc@5: 100.0000 (98.8873)  time: 0.3460  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:50  Lr: 0.001875  Loss: 0.6825  Acc@1: 81.2500 (80.3583)  Acc@5: 100.0000 (98.8741)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:46  Lr: 0.001875  Loss: 0.3956  Acc@1: 81.2500 (80.3519)  Acc@5: 100.0000 (98.8774)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:43  Lr: 0.001875  Loss: 0.5816  Acc@1: 81.2500 (80.3618)  Acc@5: 100.0000 (98.8644)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:39  Lr: 0.001875  Loss: 0.6411  Acc@1: 81.2500 (80.3554)  Acc@5: 100.0000 (98.8636)  time: 0.3467  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:36  Lr: 0.001875  Loss: 0.5522  Acc@1: 75.0000 (80.3331)  Acc@5: 100.0000 (98.8589)  time: 0.3450  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:33  Lr: 0.001875  Loss: 0.8676  Acc@1: 75.0000 (80.2952)  Acc@5: 100.0000 (98.8503)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:29  Lr: 0.001875  Loss: 0.2381  Acc@1: 75.0000 (80.3052)  Acc@5: 100.0000 (98.8457)  time: 0.3451  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:26  Lr: 0.001875  Loss: 0.4484  Acc@1: 81.2500 (80.3072)  Acc@5: 100.0000 (98.8372)  time: 0.3462  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:22  Lr: 0.001875  Loss: 0.2333  Acc@1: 81.2500 (80.3053)  Acc@5: 100.0000 (98.8328)  time: 0.3457  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:19  Lr: 0.001875  Loss: 0.1611  Acc@1: 81.2500 (80.3111)  Acc@5: 100.0000 (98.8322)  time: 0.3457  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:15  Lr: 0.001875  Loss: 0.4278  Acc@1: 81.2500 (80.3169)  Acc@5: 100.0000 (98.8317)  time: 0.3460  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:12  Lr: 0.001875  Loss: 0.4779  Acc@1: 81.2500 (80.3112)  Acc@5: 100.0000 (98.8312)  time: 0.3460  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:08  Lr: 0.001875  Loss: 0.3821  Acc@1: 81.2500 (80.3169)  Acc@5: 100.0000 (98.8307)  time: 0.3456  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:05  Lr: 0.001875  Loss: 0.3851  Acc@1: 81.2500 (80.3263)  Acc@5: 100.0000 (98.8340)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:01  Lr: 0.001875  Loss: 0.4360  Acc@1: 81.2500 (80.3281)  Acc@5: 100.0000 (98.8298)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1670/3750]  eta: 0:11:58  Lr: 0.001875  Loss: 0.3968  Acc@1: 81.2500 (80.3411)  Acc@5: 100.0000 (98.8330)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1680/3750]  eta: 0:11:55  Lr: 0.001875  Loss: 0.2655  Acc@1: 81.2500 (80.3614)  Acc@5: 100.0000 (98.8363)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1690/3750]  eta: 0:11:51  Lr: 0.001875  Loss: 0.4839  Acc@1: 81.2500 (80.3408)  Acc@5: 100.0000 (98.8394)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:48  Lr: 0.001875  Loss: 0.5001  Acc@1: 81.2500 (80.3424)  Acc@5: 100.0000 (98.8463)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:44  Lr: 0.001875  Loss: 0.1457  Acc@1: 81.2500 (80.3404)  Acc@5: 100.0000 (98.8494)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:41  Lr: 0.001875  Loss: 0.8128  Acc@1: 81.2500 (80.3748)  Acc@5: 100.0000 (98.8524)  time: 0.3455  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:37  Lr: 0.001875  Loss: 0.2993  Acc@1: 81.2500 (80.3726)  Acc@5: 100.0000 (98.8518)  time: 0.3455  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:34  Lr: 0.001875  Loss: 0.3949  Acc@1: 81.2500 (80.3777)  Acc@5: 100.0000 (98.8584)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:30  Lr: 0.001875  Loss: 0.5565  Acc@1: 81.2500 (80.3755)  Acc@5: 100.0000 (98.8542)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:27  Lr: 0.001875  Loss: 0.7312  Acc@1: 81.2500 (80.3911)  Acc@5: 100.0000 (98.8572)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:23  Lr: 0.001875  Loss: 0.4412  Acc@1: 81.2500 (80.4171)  Acc@5: 100.0000 (98.8530)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:20  Lr: 0.001875  Loss: 0.3440  Acc@1: 81.2500 (80.4253)  Acc@5: 100.0000 (98.8525)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:16  Lr: 0.001875  Loss: 0.5704  Acc@1: 81.2500 (80.4264)  Acc@5: 100.0000 (98.8589)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:13  Lr: 0.001875  Loss: 0.4998  Acc@1: 81.2500 (80.4414)  Acc@5: 100.0000 (98.8617)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:10  Lr: 0.001875  Loss: 0.4606  Acc@1: 81.2500 (80.4562)  Acc@5: 100.0000 (98.8680)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:06  Lr: 0.001875  Loss: 0.3631  Acc@1: 81.2500 (80.4434)  Acc@5: 100.0000 (98.8708)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:03  Lr: 0.001875  Loss: 0.2469  Acc@1: 81.2500 (80.4513)  Acc@5: 100.0000 (98.8667)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1840/3750]  eta: 0:10:59  Lr: 0.001875  Loss: 0.6766  Acc@1: 81.2500 (80.4250)  Acc@5: 100.0000 (98.8559)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1850/3750]  eta: 0:10:56  Lr: 0.001875  Loss: 0.4678  Acc@1: 75.0000 (80.4092)  Acc@5: 100.0000 (98.8553)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1860/3750]  eta: 0:10:52  Lr: 0.001875  Loss: 0.4013  Acc@1: 75.0000 (80.4003)  Acc@5: 100.0000 (98.8581)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:49  Lr: 0.001875  Loss: 0.9338  Acc@1: 81.2500 (80.4049)  Acc@5: 100.0000 (98.8576)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:45  Lr: 0.001875  Loss: 1.1191  Acc@1: 81.2500 (80.3894)  Acc@5: 100.0000 (98.8470)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:42  Lr: 0.001875  Loss: 0.4703  Acc@1: 81.2500 (80.3841)  Acc@5: 100.0000 (98.8531)  time: 0.3438  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:38  Lr: 0.001875  Loss: 0.3661  Acc@1: 81.2500 (80.3755)  Acc@5: 100.0000 (98.8460)  time: 0.3441  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:35  Lr: 0.001875  Loss: 0.9229  Acc@1: 81.2500 (80.3702)  Acc@5: 100.0000 (98.8422)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:31  Lr: 0.001875  Loss: 0.9506  Acc@1: 81.2500 (80.3878)  Acc@5: 100.0000 (98.8417)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:28  Lr: 0.001875  Loss: 0.4760  Acc@1: 81.2500 (80.3696)  Acc@5: 100.0000 (98.8316)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:25  Lr: 0.001875  Loss: 0.7949  Acc@1: 81.2500 (80.3742)  Acc@5: 100.0000 (98.8344)  time: 0.3453  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:21  Lr: 0.001875  Loss: 0.4769  Acc@1: 81.2500 (80.3658)  Acc@5: 100.0000 (98.8339)  time: 0.3450  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:18  Lr: 0.001875  Loss: 0.4188  Acc@1: 81.2500 (80.3576)  Acc@5: 100.0000 (98.8399)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:14  Lr: 0.001875  Loss: 0.1469  Acc@1: 81.2500 (80.3653)  Acc@5: 100.0000 (98.8426)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:11  Lr: 0.001875  Loss: 0.6884  Acc@1: 81.2500 (80.3887)  Acc@5: 100.0000 (98.8390)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:07  Lr: 0.001875  Loss: 0.5918  Acc@1: 75.0000 (80.3648)  Acc@5: 100.0000 (98.8322)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:04  Lr: 0.001875  Loss: 0.6151  Acc@1: 75.0000 (80.3348)  Acc@5: 100.0000 (98.8381)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:00  Lr: 0.001875  Loss: 0.5794  Acc@1: 81.2500 (80.3518)  Acc@5: 100.0000 (98.8408)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2020/3750]  eta: 0:09:57  Lr: 0.001875  Loss: 1.0047  Acc@1: 81.2500 (80.3377)  Acc@5: 100.0000 (98.8403)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2030/3750]  eta: 0:09:53  Lr: 0.001875  Loss: 0.4248  Acc@1: 81.2500 (80.3237)  Acc@5: 100.0000 (98.8399)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:50  Lr: 0.001875  Loss: 0.3928  Acc@1: 81.2500 (80.3221)  Acc@5: 100.0000 (98.8364)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:46  Lr: 0.001875  Loss: 0.6148  Acc@1: 81.2500 (80.3450)  Acc@5: 100.0000 (98.8329)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:43  Lr: 0.001875  Loss: 0.5142  Acc@1: 81.2500 (80.3372)  Acc@5: 100.0000 (98.8355)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:40  Lr: 0.001875  Loss: 0.6035  Acc@1: 81.2500 (80.3386)  Acc@5: 100.0000 (98.8381)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:36  Lr: 0.001875  Loss: 0.2137  Acc@1: 81.2500 (80.3580)  Acc@5: 100.0000 (98.8407)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:33  Lr: 0.001875  Loss: 0.5995  Acc@1: 87.5000 (80.3682)  Acc@5: 100.0000 (98.8373)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:29  Lr: 0.001875  Loss: 0.2662  Acc@1: 81.2500 (80.3576)  Acc@5: 100.0000 (98.8369)  time: 0.3449  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:26  Lr: 0.001875  Loss: 0.4132  Acc@1: 81.2500 (80.3707)  Acc@5: 100.0000 (98.8365)  time: 0.3447  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:22  Lr: 0.001875  Loss: 0.5074  Acc@1: 81.2500 (80.3837)  Acc@5: 100.0000 (98.8331)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:19  Lr: 0.001875  Loss: 0.6264  Acc@1: 87.5000 (80.4141)  Acc@5: 100.0000 (98.8356)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:15  Lr: 0.001875  Loss: 0.4432  Acc@1: 81.2500 (80.4180)  Acc@5: 100.0000 (98.8265)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:12  Lr: 0.001875  Loss: 0.5825  Acc@1: 81.2500 (80.4132)  Acc@5: 100.0000 (98.8145)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:08  Lr: 0.001875  Loss: 0.2753  Acc@1: 75.0000 (80.4228)  Acc@5: 100.0000 (98.8171)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:05  Lr: 0.001875  Loss: 0.6261  Acc@1: 81.2500 (80.4094)  Acc@5: 100.0000 (98.8168)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:02  Lr: 0.001875  Loss: 0.6252  Acc@1: 81.2500 (80.4075)  Acc@5: 100.0000 (98.8193)  time: 0.3464  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2190/3750]  eta: 0:08:58  Lr: 0.001875  Loss: 0.2288  Acc@1: 81.2500 (80.4142)  Acc@5: 100.0000 (98.8219)  time: 0.3465  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2200/3750]  eta: 0:08:55  Lr: 0.001875  Loss: 0.1919  Acc@1: 81.2500 (80.4294)  Acc@5: 100.0000 (98.8216)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:51  Lr: 0.001875  Loss: 0.3813  Acc@1: 81.2500 (80.4104)  Acc@5: 100.0000 (98.8128)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:48  Lr: 0.001875  Loss: 0.5840  Acc@1: 81.2500 (80.4199)  Acc@5: 100.0000 (98.8125)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:44  Lr: 0.001875  Loss: 0.4351  Acc@1: 75.0000 (80.3928)  Acc@5: 100.0000 (98.8122)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:41  Lr: 0.001875  Loss: 0.7544  Acc@1: 81.2500 (80.3882)  Acc@5: 100.0000 (98.8175)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:37  Lr: 0.001875  Loss: 0.8133  Acc@1: 81.2500 (80.3698)  Acc@5: 100.0000 (98.8144)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:34  Lr: 0.001875  Loss: 0.8219  Acc@1: 75.0000 (80.3489)  Acc@5: 100.0000 (98.8114)  time: 0.3448  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:30  Lr: 0.001875  Loss: 0.3230  Acc@1: 75.0000 (80.3363)  Acc@5: 100.0000 (98.8083)  time: 0.3460  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:27  Lr: 0.001875  Loss: 0.7805  Acc@1: 81.2500 (80.3184)  Acc@5: 100.0000 (98.8081)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:24  Lr: 0.001875  Loss: 0.6848  Acc@1: 75.0000 (80.3034)  Acc@5: 100.0000 (98.8078)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:20  Lr: 0.001875  Loss: 0.2630  Acc@1: 75.0000 (80.3075)  Acc@5: 100.0000 (98.7994)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:17  Lr: 0.001875  Loss: 0.2005  Acc@1: 81.2500 (80.3061)  Acc@5: 100.0000 (98.8019)  time: 0.3459  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:13  Lr: 0.001875  Loss: 0.3730  Acc@1: 81.2500 (80.3075)  Acc@5: 100.0000 (98.7990)  time: 0.3467  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:10  Lr: 0.001875  Loss: 0.6387  Acc@1: 81.2500 (80.3169)  Acc@5: 100.0000 (98.8042)  time: 0.3456  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:06  Lr: 0.001875  Loss: 0.3253  Acc@1: 81.2500 (80.3262)  Acc@5: 100.0000 (98.8066)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:03  Lr: 0.001875  Loss: 0.9860  Acc@1: 81.2500 (80.3116)  Acc@5: 100.0000 (98.8037)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2360/3750]  eta: 0:07:59  Lr: 0.001875  Loss: 0.8250  Acc@1: 81.2500 (80.3341)  Acc@5: 100.0000 (98.8061)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2370/3750]  eta: 0:07:56  Lr: 0.001875  Loss: 0.6842  Acc@1: 81.2500 (80.3195)  Acc@5: 100.0000 (98.8006)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:52  Lr: 0.001875  Loss: 0.8860  Acc@1: 75.0000 (80.3050)  Acc@5: 100.0000 (98.8030)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:49  Lr: 0.001875  Loss: 0.4604  Acc@1: 75.0000 (80.3011)  Acc@5: 100.0000 (98.8028)  time: 0.3453  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:46  Lr: 0.001875  Loss: 0.2748  Acc@1: 81.2500 (80.3077)  Acc@5: 100.0000 (98.8026)  time: 0.3444  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:42  Lr: 0.001875  Loss: 0.9512  Acc@1: 81.2500 (80.2831)  Acc@5: 100.0000 (98.7894)  time: 0.3448  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:39  Lr: 0.001875  Loss: 0.2815  Acc@1: 81.2500 (80.3026)  Acc@5: 100.0000 (98.7944)  time: 0.3458  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:35  Lr: 0.001875  Loss: 0.3798  Acc@1: 81.2500 (80.2962)  Acc@5: 100.0000 (98.7968)  time: 0.3456  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:32  Lr: 0.001875  Loss: 0.5061  Acc@1: 81.2500 (80.2975)  Acc@5: 100.0000 (98.8017)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:28  Lr: 0.001875  Loss: 0.5927  Acc@1: 81.2500 (80.2759)  Acc@5: 100.0000 (98.7888)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:25  Lr: 0.001875  Loss: 0.3481  Acc@1: 87.5000 (80.3027)  Acc@5: 100.0000 (98.7937)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:21  Lr: 0.001875  Loss: 0.2212  Acc@1: 81.2500 (80.2939)  Acc@5: 100.0000 (98.7935)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:18  Lr: 0.001875  Loss: 0.5612  Acc@1: 81.2500 (80.3053)  Acc@5: 100.0000 (98.7933)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:14  Lr: 0.001875  Loss: 0.7606  Acc@1: 81.2500 (80.3191)  Acc@5: 100.0000 (98.7957)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:11  Lr: 0.001875  Loss: 0.2588  Acc@1: 81.2500 (80.3154)  Acc@5: 100.0000 (98.7955)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:08  Lr: 0.001875  Loss: 0.4257  Acc@1: 87.5000 (80.3490)  Acc@5: 100.0000 (98.8003)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:04  Lr: 0.001875  Loss: 0.6327  Acc@1: 81.2500 (80.3476)  Acc@5: 100.0000 (98.8050)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:01  Lr: 0.001875  Loss: 0.6602  Acc@1: 81.2500 (80.3413)  Acc@5: 100.0000 (98.7974)  time: 0.3448  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2540/3750]  eta: 0:06:57  Lr: 0.001875  Loss: 0.2611  Acc@1: 81.2500 (80.3375)  Acc@5: 100.0000 (98.7948)  time: 0.3448  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:54  Lr: 0.001875  Loss: 0.2705  Acc@1: 81.2500 (80.3361)  Acc@5: 100.0000 (98.7995)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:50  Lr: 0.001875  Loss: 0.6555  Acc@1: 81.2500 (80.3495)  Acc@5: 100.0000 (98.7993)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:47  Lr: 0.001875  Loss: 0.3282  Acc@1: 81.2500 (80.3651)  Acc@5: 100.0000 (98.8040)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:43  Lr: 0.001875  Loss: 0.2205  Acc@1: 81.2500 (80.3589)  Acc@5: 100.0000 (98.8062)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:40  Lr: 0.001875  Loss: 0.4074  Acc@1: 75.0000 (80.3551)  Acc@5: 100.0000 (98.8060)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:36  Lr: 0.001875  Loss: 0.9686  Acc@1: 81.2500 (80.3513)  Acc@5: 100.0000 (98.8082)  time: 0.3452  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:33  Lr: 0.001875  Loss: 0.7392  Acc@1: 81.2500 (80.3595)  Acc@5: 100.0000 (98.8055)  time: 0.3451  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:30  Lr: 0.001875  Loss: 0.9022  Acc@1: 81.2500 (80.3534)  Acc@5: 100.0000 (98.8006)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:26  Lr: 0.001875  Loss: 0.4243  Acc@1: 75.0000 (80.3639)  Acc@5: 100.0000 (98.8004)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:23  Lr: 0.001875  Loss: 0.9666  Acc@1: 81.2500 (80.3602)  Acc@5: 100.0000 (98.8002)  time: 0.3450  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:19  Lr: 0.001875  Loss: 0.3592  Acc@1: 75.0000 (80.3353)  Acc@5: 100.0000 (98.7976)  time: 0.3445  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:16  Lr: 0.001875  Loss: 0.5031  Acc@1: 75.0000 (80.3293)  Acc@5: 100.0000 (98.7951)  time: 0.3452  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:12  Lr: 0.001875  Loss: 0.3169  Acc@1: 75.0000 (80.3070)  Acc@5: 100.0000 (98.7949)  time: 0.3453  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:09  Lr: 0.001875  Loss: 0.2669  Acc@1: 75.0000 (80.3105)  Acc@5: 100.0000 (98.7948)  time: 0.3452  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:05  Lr: 0.001875  Loss: 0.5817  Acc@1: 75.0000 (80.3001)  Acc@5: 100.0000 (98.7899)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:02  Lr: 0.001875  Loss: 0.6686  Acc@1: 75.0000 (80.2897)  Acc@5: 100.0000 (98.7921)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2710/3750]  eta: 0:05:58  Lr: 0.001875  Loss: 0.3008  Acc@1: 75.0000 (80.2840)  Acc@5: 100.0000 (98.7897)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:55  Lr: 0.001875  Loss: 0.5410  Acc@1: 75.0000 (80.2669)  Acc@5: 100.0000 (98.7918)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:52  Lr: 0.001875  Loss: 0.5960  Acc@1: 75.0000 (80.2682)  Acc@5: 100.0000 (98.7962)  time: 0.3450  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:48  Lr: 0.001875  Loss: 0.4889  Acc@1: 81.2500 (80.2741)  Acc@5: 100.0000 (98.7983)  time: 0.3444  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:45  Lr: 0.001875  Loss: 1.0682  Acc@1: 81.2500 (80.2822)  Acc@5: 100.0000 (98.7982)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:41  Lr: 0.001875  Loss: 0.4701  Acc@1: 81.2500 (80.2993)  Acc@5: 100.0000 (98.8025)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:38  Lr: 0.001875  Loss: 0.5699  Acc@1: 81.2500 (80.3185)  Acc@5: 100.0000 (98.8046)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:34  Lr: 0.001875  Loss: 0.3480  Acc@1: 81.2500 (80.3241)  Acc@5: 100.0000 (98.7999)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:31  Lr: 0.001875  Loss: 0.4414  Acc@1: 81.2500 (80.3386)  Acc@5: 100.0000 (98.7975)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:27  Lr: 0.001875  Loss: 0.4528  Acc@1: 81.2500 (80.3374)  Acc@5: 100.0000 (98.7995)  time: 0.3436  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:24  Lr: 0.001875  Loss: 0.4727  Acc@1: 81.2500 (80.3251)  Acc@5: 100.0000 (98.7994)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:20  Lr: 0.001875  Loss: 0.5137  Acc@1: 81.2500 (80.3394)  Acc@5: 100.0000 (98.7992)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:17  Lr: 0.001875  Loss: 0.7509  Acc@1: 81.2500 (80.3537)  Acc@5: 100.0000 (98.8012)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:14  Lr: 0.001875  Loss: 0.2571  Acc@1: 81.2500 (80.3546)  Acc@5: 100.0000 (98.8010)  time: 0.3441  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:10  Lr: 0.001875  Loss: 0.5407  Acc@1: 75.0000 (80.3468)  Acc@5: 100.0000 (98.8052)  time: 0.3447  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:07  Lr: 0.001875  Loss: 0.5913  Acc@1: 81.2500 (80.3631)  Acc@5: 100.0000 (98.8072)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:03  Lr: 0.001875  Loss: 0.7546  Acc@1: 81.2500 (80.3705)  Acc@5: 100.0000 (98.8070)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:00  Lr: 0.001875  Loss: 0.5440  Acc@1: 81.2500 (80.3801)  Acc@5: 100.0000 (98.8090)  time: 0.3451  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2890/3750]  eta: 0:04:56  Lr: 0.001875  Loss: 0.4082  Acc@1: 81.2500 (80.3917)  Acc@5: 100.0000 (98.8066)  time: 0.3450  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:53  Lr: 0.001875  Loss: 0.5468  Acc@1: 81.2500 (80.3925)  Acc@5: 100.0000 (98.8064)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:49  Lr: 0.001875  Loss: 0.5967  Acc@1: 81.2500 (80.3847)  Acc@5: 100.0000 (98.8084)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:46  Lr: 0.001875  Loss: 0.2434  Acc@1: 81.2500 (80.3856)  Acc@5: 100.0000 (98.8082)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:43  Lr: 0.001875  Loss: 0.3041  Acc@1: 81.2500 (80.3907)  Acc@5: 100.0000 (98.8101)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:39  Lr: 0.001875  Loss: 0.9216  Acc@1: 75.0000 (80.3702)  Acc@5: 100.0000 (98.8121)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:36  Lr: 0.001875  Loss: 0.7775  Acc@1: 75.0000 (80.3732)  Acc@5: 100.0000 (98.8118)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:32  Lr: 0.001875  Loss: 0.5835  Acc@1: 75.0000 (80.3466)  Acc@5: 100.0000 (98.8159)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:29  Lr: 0.001875  Loss: 0.9792  Acc@1: 75.0000 (80.3265)  Acc@5: 100.0000 (98.8156)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:25  Lr: 0.001875  Loss: 0.3222  Acc@1: 81.2500 (80.3547)  Acc@5: 100.0000 (98.8196)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:22  Lr: 0.001875  Loss: 0.9122  Acc@1: 81.2500 (80.3452)  Acc@5: 100.0000 (98.8152)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:18  Lr: 0.001875  Loss: 0.3128  Acc@1: 81.2500 (80.3482)  Acc@5: 100.0000 (98.8150)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:15  Lr: 0.001875  Loss: 0.3941  Acc@1: 81.2500 (80.3491)  Acc@5: 100.0000 (98.8189)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:11  Lr: 0.001875  Loss: 0.9280  Acc@1: 81.2500 (80.3418)  Acc@5: 100.0000 (98.8187)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:08  Lr: 0.001875  Loss: 0.3991  Acc@1: 81.2500 (80.3489)  Acc@5: 100.0000 (98.8185)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:05  Lr: 0.001875  Loss: 0.4954  Acc@1: 81.2500 (80.3436)  Acc@5: 100.0000 (98.8162)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:01  Lr: 0.001875  Loss: 0.7191  Acc@1: 75.0000 (80.3282)  Acc@5: 100.0000 (98.8160)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3060/3750]  eta: 0:03:58  Lr: 0.001875  Loss: 0.2045  Acc@1: 75.0000 (80.3353)  Acc@5: 100.0000 (98.8157)  time: 0.3440  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.6531  Acc@1: 81.2500 (80.3342)  Acc@5: 100.0000 (98.8176)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:51  Lr: 0.001875  Loss: 0.5384  Acc@1: 81.2500 (80.3351)  Acc@5: 100.0000 (98.8153)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:47  Lr: 0.001875  Loss: 0.7789  Acc@1: 81.2500 (80.3421)  Acc@5: 100.0000 (98.8151)  time: 0.3469  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:44  Lr: 0.001875  Loss: 0.3102  Acc@1: 81.2500 (80.3309)  Acc@5: 100.0000 (98.8169)  time: 0.3464  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:40  Lr: 0.001875  Loss: 0.4623  Acc@1: 81.2500 (80.3279)  Acc@5: 100.0000 (98.8207)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:37  Lr: 0.001875  Loss: 0.4553  Acc@1: 81.2500 (80.3288)  Acc@5: 100.0000 (98.8245)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.6698  Acc@1: 75.0000 (80.3258)  Acc@5: 100.0000 (98.8203)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.7525  Acc@1: 81.2500 (80.3227)  Acc@5: 100.0000 (98.8141)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:27  Lr: 0.001875  Loss: 0.1819  Acc@1: 81.2500 (80.3257)  Acc@5: 100.0000 (98.8159)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.3198  Acc@1: 81.2500 (80.3306)  Acc@5: 100.0000 (98.8156)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:20  Lr: 0.001875  Loss: 0.8310  Acc@1: 81.2500 (80.3295)  Acc@5: 100.0000 (98.8194)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:16  Lr: 0.001875  Loss: 0.3260  Acc@1: 81.2500 (80.3344)  Acc@5: 100.0000 (98.8172)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:13  Lr: 0.001875  Loss: 0.7174  Acc@1: 75.0000 (80.3216)  Acc@5: 100.0000 (98.8170)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:09  Lr: 0.001875  Loss: 0.7738  Acc@1: 75.0000 (80.3147)  Acc@5: 100.0000 (98.8129)  time: 0.3447  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:06  Lr: 0.001875  Loss: 0.2065  Acc@1: 81.2500 (80.3196)  Acc@5: 100.0000 (98.8146)  time: 0.3474  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:02  Lr: 0.001875  Loss: 0.4416  Acc@1: 81.2500 (80.3264)  Acc@5: 100.0000 (98.8144)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 0.6932  Acc@1: 81.2500 (80.3157)  Acc@5: 100.0000 (98.8162)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:56  Lr: 0.001875  Loss: 0.4220  Acc@1: 75.0000 (80.3147)  Acc@5: 100.0000 (98.8160)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.3465  Acc@1: 81.2500 (80.3253)  Acc@5: 100.0000 (98.8177)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:49  Lr: 0.001875  Loss: 0.4656  Acc@1: 81.2500 (80.3243)  Acc@5: 100.0000 (98.8213)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 0.6253  Acc@1: 81.2500 (80.3386)  Acc@5: 100.0000 (98.8230)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:42  Lr: 0.001875  Loss: 0.2505  Acc@1: 87.5000 (80.3414)  Acc@5: 100.0000 (98.8247)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 1.1744  Acc@1: 75.0000 (80.3213)  Acc@5: 100.0000 (98.8149)  time: 0.3448  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:35  Lr: 0.001875  Loss: 0.4993  Acc@1: 75.0000 (80.3223)  Acc@5: 100.0000 (98.8129)  time: 0.3452  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:31  Lr: 0.001875  Loss: 0.6275  Acc@1: 87.5000 (80.3420)  Acc@5: 100.0000 (98.8146)  time: 0.3447  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.7279  Acc@1: 87.5000 (80.3561)  Acc@5: 100.0000 (98.8144)  time: 0.3449  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:24  Lr: 0.001875  Loss: 0.3636  Acc@1: 81.2500 (80.3569)  Acc@5: 100.0000 (98.8142)  time: 0.3455  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.6906  Acc@1: 81.2500 (80.3652)  Acc@5: 100.0000 (98.8158)  time: 0.3452  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:18  Lr: 0.001875  Loss: 0.6231  Acc@1: 81.2500 (80.3753)  Acc@5: 100.0000 (98.8175)  time: 0.3451  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.4940  Acc@1: 81.2500 (80.3704)  Acc@5: 100.0000 (98.8192)  time: 0.3454  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:11  Lr: 0.001875  Loss: 0.8446  Acc@1: 75.0000 (80.3563)  Acc@5: 100.0000 (98.8208)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.7048  Acc@1: 75.0000 (80.3553)  Acc@5: 100.0000 (98.8225)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:04  Lr: 0.001875  Loss: 0.6120  Acc@1: 81.2500 (80.3506)  Acc@5: 100.0000 (98.8223)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 0.4030  Acc@1: 81.2500 (80.3532)  Acc@5: 100.0000 (98.8239)  time: 0.3459  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.2990  Acc@1: 81.2500 (80.3650)  Acc@5: 100.0000 (98.8273)  time: 0.3451  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 0.6517  Acc@1: 81.2500 (80.3621)  Acc@5: 100.0000 (98.8271)  time: 0.3439  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.4098  Acc@1: 81.2500 (80.3610)  Acc@5: 100.0000 (98.8251)  time: 0.3441  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:46  Lr: 0.001875  Loss: 0.2860  Acc@1: 75.0000 (80.3509)  Acc@5: 100.0000 (98.8230)  time: 0.3448  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.2875  Acc@1: 81.2500 (80.3734)  Acc@5: 100.0000 (98.8246)  time: 0.3454  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: 0.5596  Acc@1: 81.2500 (80.3633)  Acc@5: 100.0000 (98.8244)  time: 0.3452  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.5151  Acc@1: 81.2500 (80.3713)  Acc@5: 100.0000 (98.8242)  time: 0.3449  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: 0.7931  Acc@1: 81.2500 (80.3702)  Acc@5: 100.0000 (98.8204)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.7580  Acc@1: 75.0000 (80.3692)  Acc@5: 100.0000 (98.8202)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.2177  Acc@1: 81.2500 (80.3788)  Acc@5: 100.0000 (98.8236)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.3212  Acc@1: 81.2500 (80.3706)  Acc@5: 100.0000 (98.8269)  time: 0.3458  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.3004  Acc@1: 75.0000 (80.3678)  Acc@5: 100.0000 (98.8231)  time: 0.3462  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 0.3702  Acc@1: 75.0000 (80.3561)  Acc@5: 100.0000 (98.8194)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.6164  Acc@1: 75.0000 (80.3534)  Acc@5: 100.0000 (98.8157)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: 0.1683  Acc@1: 81.2500 (80.3682)  Acc@5: 100.0000 (98.8155)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.1433  Acc@1: 81.2500 (80.3707)  Acc@5: 100.0000 (98.8153)  time: 0.3437  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: 0.5273  Acc@1: 81.2500 (80.3889)  Acc@5: 100.0000 (98.8169)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1567  Acc@1: 87.5000 (80.4000)  Acc@5: 100.0000 (98.8184)  time: 0.3454  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.3791  Acc@1: 81.2500 (80.3972)  Acc@5: 100.0000 (98.8182)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.7032  Acc@1: 81.2500 (80.3978)  Acc@5: 100.0000 (98.8180)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7956  Acc@1: 75.0000 (80.3881)  Acc@5: 100.0000 (98.8178)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1950  Acc@1: 81.2500 (80.4060)  Acc@5: 100.0000 (98.8177)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.7406  Acc@1: 87.5000 (80.4238)  Acc@5: 100.0000 (98.8192)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 0.6105  Acc@1: 87.5000 (80.4312)  Acc@5: 100.0000 (98.8207)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4454  Acc@1: 81.2500 (80.4334)  Acc@5: 100.0000 (98.8188)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: 0.5141  Acc@1: 81.2500 (80.4391)  Acc@5: 100.0000 (98.8186)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.6490  Acc@1: 81.2500 (80.4311)  Acc@5: 100.0000 (98.8184)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.4776  Acc@1: 81.2500 (80.4333)  Acc@5: 100.0000 (98.8217)  time: 0.3445  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 0.4290  Acc@1: 81.2500 (80.4321)  Acc@5: 100.0000 (98.8198)  time: 0.3447  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.5289  Acc@1: 75.0000 (80.4225)  Acc@5: 100.0000 (98.8230)  time: 0.3456  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.8275  Acc@1: 75.0000 (80.4197)  Acc@5: 100.0000 (98.8244)  time: 0.3456  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.2864  Acc@1: 81.2500 (80.4236)  Acc@5: 100.0000 (98.8259)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2798  Acc@1: 81.2500 (80.4275)  Acc@5: 100.0000 (98.8224)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 1.3083  Acc@1: 81.2500 (80.4197)  Acc@5: 100.0000 (98.8205)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7325  Acc@1: 75.0000 (80.4167)  Acc@5: 100.0000 (98.8167)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[3/5] Total time: 0:21:34 (0.3453 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.7325  Acc@1: 75.0000 (80.4167)  Acc@5: 100.0000 (98.8167)
Train: Epoch[4/5]  [   0/3750]  eta: 0:44:11  Lr: 0.001875  Loss: 0.6953  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.7071  data: 0.3611  max mem: 2503
Train: Epoch[4/5]  [  10/3750]  eta: 0:23:31  Lr: 0.001875  Loss: 0.5714  Acc@1: 81.2500 (77.2727)  Acc@5: 93.7500 (96.0227)  time: 0.3773  data: 0.0331  max mem: 2503
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:29  Lr: 0.001875  Loss: 0.2671  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.6190)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:03  Lr: 0.001875  Loss: 0.8858  Acc@1: 87.5000 (80.6452)  Acc@5: 100.0000 (97.7823)  time: 0.3439  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [  40/3750]  eta: 0:21:50  Lr: 0.001875  Loss: 0.3319  Acc@1: 87.5000 (82.1646)  Acc@5: 100.0000 (98.0183)  time: 0.3446  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [  50/3750]  eta: 0:21:40  Lr: 0.001875  Loss: 0.8772  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.2843)  time: 0.3452  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:32  Lr: 0.001875  Loss: 0.6737  Acc@1: 75.0000 (80.3279)  Acc@5: 100.0000 (98.0533)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:26  Lr: 0.001875  Loss: 0.4725  Acc@1: 81.2500 (80.1056)  Acc@5: 100.0000 (98.0634)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:20  Lr: 0.001875  Loss: 0.5909  Acc@1: 81.2500 (79.9383)  Acc@5: 100.0000 (98.1481)  time: 0.3442  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:15  Lr: 0.001875  Loss: 0.3083  Acc@1: 81.2500 (79.7390)  Acc@5: 100.0000 (98.2143)  time: 0.3445  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:09  Lr: 0.001875  Loss: 0.3755  Acc@1: 81.2500 (79.6411)  Acc@5: 100.0000 (98.3292)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:05  Lr: 0.001875  Loss: 0.5269  Acc@1: 81.2500 (79.8423)  Acc@5: 100.0000 (98.3671)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:01  Lr: 0.001875  Loss: 1.0661  Acc@1: 81.2500 (79.3388)  Acc@5: 100.0000 (98.2955)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 130/3750]  eta: 0:20:57  Lr: 0.001875  Loss: 0.5536  Acc@1: 81.2500 (79.8187)  Acc@5: 100.0000 (98.4256)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 140/3750]  eta: 0:20:53  Lr: 0.001875  Loss: 0.5682  Acc@1: 87.5000 (79.7872)  Acc@5: 100.0000 (98.4929)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 150/3750]  eta: 0:20:49  Lr: 0.001875  Loss: 0.6400  Acc@1: 75.0000 (79.6358)  Acc@5: 100.0000 (98.5099)  time: 0.3457  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 160/3750]  eta: 0:20:46  Lr: 0.001875  Loss: 0.6155  Acc@1: 75.0000 (79.5807)  Acc@5: 100.0000 (98.4860)  time: 0.3469  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:42  Lr: 0.001875  Loss: 0.6260  Acc@1: 81.2500 (79.7149)  Acc@5: 100.0000 (98.4649)  time: 0.3468  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:38  Lr: 0.001875  Loss: 0.5747  Acc@1: 81.2500 (79.6961)  Acc@5: 100.0000 (98.4807)  time: 0.3463  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:35  Lr: 0.001875  Loss: 0.4935  Acc@1: 87.5000 (80.0065)  Acc@5: 100.0000 (98.4620)  time: 0.3470  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:32  Lr: 0.001875  Loss: 0.9346  Acc@1: 87.5000 (80.0373)  Acc@5: 100.0000 (98.5386)  time: 0.3475  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:28  Lr: 0.001875  Loss: 0.3309  Acc@1: 81.2500 (80.0652)  Acc@5: 100.0000 (98.6078)  time: 0.3464  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:24  Lr: 0.001875  Loss: 1.4345  Acc@1: 81.2500 (80.0339)  Acc@5: 100.0000 (98.6143)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:21  Lr: 0.001875  Loss: 0.3385  Acc@1: 81.2500 (80.0866)  Acc@5: 100.0000 (98.6742)  time: 0.3462  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:17  Lr: 0.001875  Loss: 0.4443  Acc@1: 81.2500 (80.1867)  Acc@5: 100.0000 (98.6774)  time: 0.3461  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:13  Lr: 0.001875  Loss: 0.3600  Acc@1: 87.5000 (80.2789)  Acc@5: 100.0000 (98.7052)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:09  Lr: 0.001875  Loss: 1.1169  Acc@1: 81.2500 (80.3400)  Acc@5: 100.0000 (98.6830)  time: 0.3449  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:06  Lr: 0.001875  Loss: 0.6421  Acc@1: 81.2500 (80.4428)  Acc@5: 100.0000 (98.6854)  time: 0.3448  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:02  Lr: 0.001875  Loss: 0.4218  Acc@1: 81.2500 (80.3158)  Acc@5: 100.0000 (98.6877)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 290/3750]  eta: 0:19:58  Lr: 0.001875  Loss: 0.5846  Acc@1: 75.0000 (80.1976)  Acc@5: 100.0000 (98.7113)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 300/3750]  eta: 0:19:55  Lr: 0.001875  Loss: 1.3762  Acc@1: 75.0000 (80.1495)  Acc@5: 100.0000 (98.6296)  time: 0.3452  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 310/3750]  eta: 0:19:51  Lr: 0.001875  Loss: 0.5799  Acc@1: 81.2500 (80.1849)  Acc@5: 100.0000 (98.6535)  time: 0.3452  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 320/3750]  eta: 0:19:47  Lr: 0.001875  Loss: 0.3947  Acc@1: 81.2500 (80.3933)  Acc@5: 100.0000 (98.6760)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:44  Lr: 0.001875  Loss: 0.6861  Acc@1: 81.2500 (80.3437)  Acc@5: 100.0000 (98.6971)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:40  Lr: 0.001875  Loss: 0.7539  Acc@1: 81.2500 (80.4252)  Acc@5: 100.0000 (98.7353)  time: 0.3454  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:37  Lr: 0.001875  Loss: 0.4494  Acc@1: 81.2500 (80.4665)  Acc@5: 100.0000 (98.7536)  time: 0.3460  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:33  Lr: 0.001875  Loss: 0.4096  Acc@1: 81.2500 (80.5402)  Acc@5: 100.0000 (98.7708)  time: 0.3454  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:30  Lr: 0.001875  Loss: 0.6767  Acc@1: 87.5000 (80.7446)  Acc@5: 100.0000 (98.8039)  time: 0.3462  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:26  Lr: 0.001875  Loss: 0.5847  Acc@1: 81.2500 (80.6430)  Acc@5: 100.0000 (98.7861)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:23  Lr: 0.001875  Loss: 0.3400  Acc@1: 75.0000 (80.5627)  Acc@5: 100.0000 (98.8171)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:19  Lr: 0.001875  Loss: 0.7331  Acc@1: 75.0000 (80.5175)  Acc@5: 100.0000 (98.8466)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:16  Lr: 0.001875  Loss: 1.2990  Acc@1: 81.2500 (80.4897)  Acc@5: 100.0000 (98.8443)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:12  Lr: 0.001875  Loss: 0.2332  Acc@1: 81.2500 (80.5523)  Acc@5: 100.0000 (98.8569)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:08  Lr: 0.001875  Loss: 0.5470  Acc@1: 81.2500 (80.6845)  Acc@5: 100.0000 (98.8544)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:05  Lr: 0.001875  Loss: 0.3928  Acc@1: 81.2500 (80.6973)  Acc@5: 100.0000 (98.8804)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:01  Lr: 0.001875  Loss: 0.3874  Acc@1: 81.2500 (80.6957)  Acc@5: 100.0000 (98.9052)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 460/3750]  eta: 0:18:58  Lr: 0.001875  Loss: 0.6584  Acc@1: 81.2500 (80.7213)  Acc@5: 100.0000 (98.9154)  time: 0.3467  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 470/3750]  eta: 0:18:55  Lr: 0.001875  Loss: 0.3457  Acc@1: 81.2500 (80.7059)  Acc@5: 100.0000 (98.9119)  time: 0.3456  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 480/3750]  eta: 0:18:51  Lr: 0.001875  Loss: 0.7739  Acc@1: 81.2500 (80.7822)  Acc@5: 100.0000 (98.9345)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 490/3750]  eta: 0:18:47  Lr: 0.001875  Loss: 0.3904  Acc@1: 87.5000 (80.7536)  Acc@5: 100.0000 (98.9435)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:44  Lr: 0.001875  Loss: 0.8526  Acc@1: 81.2500 (80.7011)  Acc@5: 100.0000 (98.9521)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:41  Lr: 0.001875  Loss: 0.8360  Acc@1: 75.0000 (80.6385)  Acc@5: 100.0000 (98.9359)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:37  Lr: 0.001875  Loss: 0.4453  Acc@1: 75.0000 (80.6022)  Acc@5: 100.0000 (98.9443)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:34  Lr: 0.001875  Loss: 0.3433  Acc@1: 81.2500 (80.6026)  Acc@5: 100.0000 (98.9407)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:30  Lr: 0.001875  Loss: 0.6936  Acc@1: 81.2500 (80.5799)  Acc@5: 100.0000 (98.9256)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:27  Lr: 0.001875  Loss: 0.9764  Acc@1: 81.2500 (80.5694)  Acc@5: 100.0000 (98.9338)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:23  Lr: 0.001875  Loss: 0.9541  Acc@1: 81.2500 (80.5816)  Acc@5: 100.0000 (98.9305)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:19  Lr: 0.001875  Loss: 0.3280  Acc@1: 81.2500 (80.6918)  Acc@5: 100.0000 (98.9383)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:16  Lr: 0.001875  Loss: 0.6735  Acc@1: 81.2500 (80.6368)  Acc@5: 100.0000 (98.9458)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:13  Lr: 0.001875  Loss: 0.4658  Acc@1: 81.2500 (80.7424)  Acc@5: 100.0000 (98.9530)  time: 0.3462  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:09  Lr: 0.001875  Loss: 0.5642  Acc@1: 87.5000 (80.8340)  Acc@5: 100.0000 (98.9601)  time: 0.3472  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:06  Lr: 0.001875  Loss: 0.6241  Acc@1: 81.2500 (80.7999)  Acc@5: 100.0000 (98.9771)  time: 0.3470  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:02  Lr: 0.001875  Loss: 0.1611  Acc@1: 81.2500 (80.8776)  Acc@5: 100.0000 (98.9835)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 630/3750]  eta: 0:17:59  Lr: 0.001875  Loss: 0.4991  Acc@1: 81.2500 (80.8538)  Acc@5: 100.0000 (98.9897)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 640/3750]  eta: 0:17:55  Lr: 0.001875  Loss: 0.7514  Acc@1: 75.0000 (80.7625)  Acc@5: 100.0000 (98.9860)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 650/3750]  eta: 0:17:52  Lr: 0.001875  Loss: 0.3602  Acc@1: 81.2500 (80.7700)  Acc@5: 100.0000 (98.9631)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 660/3750]  eta: 0:17:49  Lr: 0.001875  Loss: 0.1519  Acc@1: 81.2500 (80.8340)  Acc@5: 100.0000 (98.9788)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:45  Lr: 0.001875  Loss: 0.6342  Acc@1: 81.2500 (80.8029)  Acc@5: 100.0000 (98.9847)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:42  Lr: 0.001875  Loss: 0.5926  Acc@1: 81.2500 (80.8462)  Acc@5: 100.0000 (98.9996)  time: 0.3457  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:38  Lr: 0.001875  Loss: 0.3836  Acc@1: 87.5000 (80.9787)  Acc@5: 100.0000 (99.0141)  time: 0.3463  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:35  Lr: 0.001875  Loss: 0.8094  Acc@1: 87.5000 (80.9914)  Acc@5: 100.0000 (99.0282)  time: 0.3463  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:31  Lr: 0.001875  Loss: 0.4301  Acc@1: 81.2500 (81.0478)  Acc@5: 100.0000 (99.0331)  time: 0.3460  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:28  Lr: 0.001875  Loss: 0.4767  Acc@1: 81.2500 (81.0420)  Acc@5: 100.0000 (99.0465)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:24  Lr: 0.001875  Loss: 0.5699  Acc@1: 81.2500 (81.0534)  Acc@5: 100.0000 (99.0510)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:21  Lr: 0.001875  Loss: 0.1430  Acc@1: 81.2500 (81.0138)  Acc@5: 100.0000 (99.0385)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:17  Lr: 0.001875  Loss: 0.6051  Acc@1: 81.2500 (81.0003)  Acc@5: 100.0000 (99.0346)  time: 0.3465  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:14  Lr: 0.001875  Loss: 0.5433  Acc@1: 81.2500 (80.9708)  Acc@5: 100.0000 (99.0391)  time: 0.3470  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:10  Lr: 0.001875  Loss: 0.4753  Acc@1: 81.2500 (81.0392)  Acc@5: 100.0000 (99.0516)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:07  Lr: 0.001875  Loss: 0.6217  Acc@1: 87.5000 (81.0339)  Acc@5: 100.0000 (99.0397)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:03  Lr: 0.001875  Loss: 0.6710  Acc@1: 81.2500 (81.0051)  Acc@5: 100.0000 (99.0360)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:00  Lr: 0.001875  Loss: 0.4554  Acc@1: 87.5000 (81.1017)  Acc@5: 100.0000 (99.0481)  time: 0.3463  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 810/3750]  eta: 0:16:57  Lr: 0.001875  Loss: 0.6970  Acc@1: 87.5000 (81.0805)  Acc@5: 100.0000 (99.0367)  time: 0.3462  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 820/3750]  eta: 0:16:53  Lr: 0.001875  Loss: 0.8107  Acc@1: 81.2500 (81.0521)  Acc@5: 100.0000 (99.0104)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 830/3750]  eta: 0:16:50  Lr: 0.001875  Loss: 0.6261  Acc@1: 81.2500 (81.0394)  Acc@5: 100.0000 (98.9922)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:46  Lr: 0.001875  Loss: 0.5916  Acc@1: 81.2500 (81.0419)  Acc@5: 100.0000 (98.9967)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:43  Lr: 0.001875  Loss: 0.9488  Acc@1: 81.2500 (81.0444)  Acc@5: 100.0000 (99.0085)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:39  Lr: 0.001875  Loss: 0.4443  Acc@1: 81.2500 (81.0976)  Acc@5: 100.0000 (99.0128)  time: 0.3445  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:36  Lr: 0.001875  Loss: 0.3649  Acc@1: 87.5000 (81.1567)  Acc@5: 100.0000 (99.0169)  time: 0.3445  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:32  Lr: 0.001875  Loss: 0.6631  Acc@1: 81.2500 (81.1649)  Acc@5: 100.0000 (99.0210)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:29  Lr: 0.001875  Loss: 0.4053  Acc@1: 81.2500 (81.1728)  Acc@5: 100.0000 (99.0250)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:25  Lr: 0.001875  Loss: 0.8261  Acc@1: 81.2500 (81.1251)  Acc@5: 100.0000 (99.0219)  time: 0.3437  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:22  Lr: 0.001875  Loss: 0.5837  Acc@1: 75.0000 (81.0922)  Acc@5: 100.0000 (99.0327)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:18  Lr: 0.001875  Loss: 0.3664  Acc@1: 75.0000 (81.0600)  Acc@5: 100.0000 (99.0296)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:15  Lr: 0.001875  Loss: 0.3806  Acc@1: 81.2500 (81.0956)  Acc@5: 100.0000 (99.0400)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:11  Lr: 0.001875  Loss: 0.6471  Acc@1: 81.2500 (81.0308)  Acc@5: 100.0000 (99.0436)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:08  Lr: 0.001875  Loss: 0.2803  Acc@1: 81.2500 (81.0528)  Acc@5: 100.0000 (99.0339)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:04  Lr: 0.001875  Loss: 0.5817  Acc@1: 81.2500 (81.0029)  Acc@5: 100.0000 (99.0049)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:00  Lr: 0.001875  Loss: 1.1577  Acc@1: 75.0000 (81.0247)  Acc@5: 100.0000 (99.0023)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 980/3750]  eta: 0:15:57  Lr: 0.001875  Loss: 0.0700  Acc@1: 81.2500 (81.0143)  Acc@5: 100.0000 (99.0061)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 990/3750]  eta: 0:15:53  Lr: 0.001875  Loss: 0.8023  Acc@1: 75.0000 (80.9473)  Acc@5: 100.0000 (99.0035)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1000/3750]  eta: 0:15:50  Lr: 0.001875  Loss: 0.4577  Acc@1: 75.0000 (80.9628)  Acc@5: 100.0000 (99.0072)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:46  Lr: 0.001875  Loss: 0.3810  Acc@1: 87.5000 (80.9904)  Acc@5: 100.0000 (99.0109)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:43  Lr: 0.001875  Loss: 0.7021  Acc@1: 87.5000 (81.0419)  Acc@5: 100.0000 (99.0083)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:39  Lr: 0.001875  Loss: 0.6006  Acc@1: 87.5000 (81.0924)  Acc@5: 100.0000 (99.0119)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:36  Lr: 0.001875  Loss: 0.1275  Acc@1: 87.5000 (81.1299)  Acc@5: 100.0000 (99.0154)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:32  Lr: 0.001875  Loss: 0.6583  Acc@1: 81.2500 (81.0775)  Acc@5: 100.0000 (99.0128)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:29  Lr: 0.001875  Loss: 0.3842  Acc@1: 81.2500 (81.0792)  Acc@5: 100.0000 (99.0163)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:25  Lr: 0.001875  Loss: 0.3554  Acc@1: 81.2500 (81.0749)  Acc@5: 100.0000 (99.0079)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:22  Lr: 0.001875  Loss: 0.4672  Acc@1: 81.2500 (81.1055)  Acc@5: 100.0000 (99.0113)  time: 0.3437  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:18  Lr: 0.001875  Loss: 0.4722  Acc@1: 87.5000 (81.1182)  Acc@5: 100.0000 (99.0032)  time: 0.3441  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:15  Lr: 0.001875  Loss: 0.5076  Acc@1: 81.2500 (81.0911)  Acc@5: 100.0000 (99.0009)  time: 0.3447  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:12  Lr: 0.001875  Loss: 0.7326  Acc@1: 81.2500 (81.0869)  Acc@5: 100.0000 (98.9986)  time: 0.3459  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:08  Lr: 0.001875  Loss: 1.1006  Acc@1: 81.2500 (81.0493)  Acc@5: 100.0000 (98.9909)  time: 0.3455  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:05  Lr: 0.001875  Loss: 0.3427  Acc@1: 81.2500 (81.0069)  Acc@5: 100.0000 (98.9998)  time: 0.3473  data: 0.0033  max mem: 2503
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:01  Lr: 0.001875  Loss: 0.5448  Acc@1: 75.0000 (80.9652)  Acc@5: 100.0000 (99.0031)  time: 0.3487  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [1150/3750]  eta: 0:14:58  Lr: 0.001875  Loss: 0.2322  Acc@1: 75.0000 (80.9296)  Acc@5: 100.0000 (98.9954)  time: 0.3474  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1160/3750]  eta: 0:14:55  Lr: 0.001875  Loss: 0.1284  Acc@1: 81.2500 (80.9216)  Acc@5: 100.0000 (98.9826)  time: 0.3467  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1170/3750]  eta: 0:14:51  Lr: 0.001875  Loss: 0.2297  Acc@1: 81.2500 (80.9511)  Acc@5: 100.0000 (98.9806)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:48  Lr: 0.001875  Loss: 0.8158  Acc@1: 75.0000 (80.9166)  Acc@5: 100.0000 (98.9839)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:44  Lr: 0.001875  Loss: 0.3957  Acc@1: 75.0000 (80.9037)  Acc@5: 100.0000 (98.9872)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:41  Lr: 0.001875  Loss: 0.5725  Acc@1: 75.0000 (80.8545)  Acc@5: 100.0000 (98.9852)  time: 0.3438  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:37  Lr: 0.001875  Loss: 0.5937  Acc@1: 75.0000 (80.8371)  Acc@5: 100.0000 (98.9884)  time: 0.3443  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:34  Lr: 0.001875  Loss: 0.5077  Acc@1: 81.2500 (80.8405)  Acc@5: 100.0000 (98.9814)  time: 0.3457  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:30  Lr: 0.001875  Loss: 0.5558  Acc@1: 87.5000 (80.8540)  Acc@5: 100.0000 (98.9795)  time: 0.3464  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:27  Lr: 0.001875  Loss: 0.6872  Acc@1: 75.0000 (80.8219)  Acc@5: 100.0000 (98.9726)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:23  Lr: 0.001875  Loss: 0.6521  Acc@1: 81.2500 (80.8503)  Acc@5: 100.0000 (98.9708)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:20  Lr: 0.001875  Loss: 0.1749  Acc@1: 87.5000 (80.8981)  Acc@5: 100.0000 (98.9790)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:16  Lr: 0.001875  Loss: 0.8050  Acc@1: 87.5000 (80.9156)  Acc@5: 100.0000 (98.9673)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:13  Lr: 0.001875  Loss: 0.2267  Acc@1: 81.2500 (80.9085)  Acc@5: 100.0000 (98.9657)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:09  Lr: 0.001875  Loss: 0.4695  Acc@1: 81.2500 (80.9063)  Acc@5: 100.0000 (98.9591)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:06  Lr: 0.001875  Loss: 0.8182  Acc@1: 81.2500 (80.9137)  Acc@5: 100.0000 (98.9479)  time: 0.3457  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:03  Lr: 0.001875  Loss: 0.8843  Acc@1: 81.2500 (80.9115)  Acc@5: 100.0000 (98.9464)  time: 0.3474  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1320/3750]  eta: 0:13:59  Lr: 0.001875  Loss: 0.3267  Acc@1: 81.2500 (80.9472)  Acc@5: 100.0000 (98.9497)  time: 0.3463  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1330/3750]  eta: 0:13:56  Lr: 0.001875  Loss: 0.3878  Acc@1: 87.5000 (80.9776)  Acc@5: 100.0000 (98.9482)  time: 0.3449  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1340/3750]  eta: 0:13:52  Lr: 0.001875  Loss: 0.2143  Acc@1: 81.2500 (81.0030)  Acc@5: 100.0000 (98.9467)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:49  Lr: 0.001875  Loss: 0.5432  Acc@1: 75.0000 (80.9215)  Acc@5: 100.0000 (98.9499)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:45  Lr: 0.001875  Loss: 0.3503  Acc@1: 75.0000 (80.9377)  Acc@5: 100.0000 (98.9438)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:42  Lr: 0.001875  Loss: 0.5950  Acc@1: 81.2500 (80.9628)  Acc@5: 100.0000 (98.9469)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:38  Lr: 0.001875  Loss: 0.8655  Acc@1: 75.0000 (80.9106)  Acc@5: 100.0000 (98.9365)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:35  Lr: 0.001875  Loss: 0.5578  Acc@1: 75.0000 (80.9355)  Acc@5: 100.0000 (98.9306)  time: 0.3468  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:31  Lr: 0.001875  Loss: 0.5458  Acc@1: 81.2500 (80.8976)  Acc@5: 100.0000 (98.9249)  time: 0.3458  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:28  Lr: 0.001875  Loss: 0.3467  Acc@1: 81.2500 (80.9045)  Acc@5: 100.0000 (98.9325)  time: 0.3467  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:25  Lr: 0.001875  Loss: 0.5740  Acc@1: 87.5000 (80.9333)  Acc@5: 100.0000 (98.9312)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:21  Lr: 0.001875  Loss: 0.4499  Acc@1: 81.2500 (80.9399)  Acc@5: 100.0000 (98.9343)  time: 0.3448  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:18  Lr: 0.001875  Loss: 0.5741  Acc@1: 81.2500 (80.9334)  Acc@5: 100.0000 (98.9244)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:14  Lr: 0.001875  Loss: 0.2683  Acc@1: 81.2500 (80.9356)  Acc@5: 100.0000 (98.9145)  time: 0.3455  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:11  Lr: 0.001875  Loss: 0.4878  Acc@1: 81.2500 (80.9292)  Acc@5: 100.0000 (98.9091)  time: 0.3459  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:07  Lr: 0.001875  Loss: 0.4911  Acc@1: 81.2500 (80.9058)  Acc@5: 100.0000 (98.9123)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:04  Lr: 0.001875  Loss: 0.4736  Acc@1: 81.2500 (80.8997)  Acc@5: 100.0000 (98.9154)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:00  Lr: 0.001875  Loss: 0.6274  Acc@1: 81.2500 (80.9063)  Acc@5: 100.0000 (98.9185)  time: 0.3435  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1500/3750]  eta: 0:12:57  Lr: 0.001875  Loss: 0.4044  Acc@1: 81.2500 (80.9169)  Acc@5: 100.0000 (98.9132)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1510/3750]  eta: 0:12:53  Lr: 0.001875  Loss: 0.5520  Acc@1: 81.2500 (80.9232)  Acc@5: 100.0000 (98.9204)  time: 0.3438  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:50  Lr: 0.001875  Loss: 0.6233  Acc@1: 81.2500 (80.9500)  Acc@5: 100.0000 (98.9234)  time: 0.3450  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:46  Lr: 0.001875  Loss: 0.4046  Acc@1: 81.2500 (80.9642)  Acc@5: 100.0000 (98.9223)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:43  Lr: 0.001875  Loss: 0.8498  Acc@1: 81.2500 (80.9255)  Acc@5: 100.0000 (98.9252)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:39  Lr: 0.001875  Loss: 0.5027  Acc@1: 75.0000 (80.9196)  Acc@5: 100.0000 (98.9321)  time: 0.3442  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:36  Lr: 0.001875  Loss: 0.3140  Acc@1: 75.0000 (80.8897)  Acc@5: 100.0000 (98.9270)  time: 0.3448  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:32  Lr: 0.001875  Loss: 0.6161  Acc@1: 75.0000 (80.8561)  Acc@5: 100.0000 (98.9258)  time: 0.3442  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:29  Lr: 0.001875  Loss: 1.0623  Acc@1: 75.0000 (80.8626)  Acc@5: 100.0000 (98.9208)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:26  Lr: 0.001875  Loss: 0.2303  Acc@1: 81.2500 (80.8572)  Acc@5: 100.0000 (98.9197)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:22  Lr: 0.001875  Loss: 0.7649  Acc@1: 81.2500 (80.8674)  Acc@5: 100.0000 (98.9225)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:19  Lr: 0.001875  Loss: 0.4355  Acc@1: 81.2500 (80.8504)  Acc@5: 100.0000 (98.9215)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:15  Lr: 0.001875  Loss: 0.7102  Acc@1: 81.2500 (80.8336)  Acc@5: 100.0000 (98.9166)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:12  Lr: 0.001875  Loss: 0.4890  Acc@1: 81.2500 (80.8400)  Acc@5: 100.0000 (98.9194)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:08  Lr: 0.001875  Loss: 0.3822  Acc@1: 81.2500 (80.8501)  Acc@5: 100.0000 (98.9222)  time: 0.3442  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:05  Lr: 0.001875  Loss: 0.5928  Acc@1: 81.2500 (80.8677)  Acc@5: 100.0000 (98.9135)  time: 0.3449  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:01  Lr: 0.001875  Loss: 0.6433  Acc@1: 81.2500 (80.8436)  Acc@5: 100.0000 (98.9126)  time: 0.3450  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1670/3750]  eta: 0:11:58  Lr: 0.001875  Loss: 0.2901  Acc@1: 81.2500 (80.8535)  Acc@5: 100.0000 (98.9191)  time: 0.3445  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1680/3750]  eta: 0:11:54  Lr: 0.001875  Loss: 0.4414  Acc@1: 81.2500 (80.8559)  Acc@5: 100.0000 (98.9181)  time: 0.3439  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:51  Lr: 0.001875  Loss: 0.3837  Acc@1: 81.2500 (80.8767)  Acc@5: 100.0000 (98.9134)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:47  Lr: 0.001875  Loss: 0.2225  Acc@1: 87.5000 (80.8862)  Acc@5: 100.0000 (98.9087)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:44  Lr: 0.001875  Loss: 0.5302  Acc@1: 87.5000 (80.9103)  Acc@5: 100.0000 (98.9151)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:41  Lr: 0.001875  Loss: 0.8598  Acc@1: 81.2500 (80.9050)  Acc@5: 100.0000 (98.9141)  time: 0.3451  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:37  Lr: 0.001875  Loss: 0.3268  Acc@1: 81.2500 (80.9070)  Acc@5: 100.0000 (98.9132)  time: 0.3457  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:34  Lr: 0.001875  Loss: 0.2744  Acc@1: 87.5000 (80.9484)  Acc@5: 100.0000 (98.9194)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:30  Lr: 0.001875  Loss: 0.6345  Acc@1: 87.5000 (80.9573)  Acc@5: 100.0000 (98.9256)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:27  Lr: 0.001875  Loss: 0.7608  Acc@1: 81.2500 (80.9590)  Acc@5: 100.0000 (98.9211)  time: 0.3456  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:23  Lr: 0.001875  Loss: 0.4473  Acc@1: 81.2500 (80.9571)  Acc@5: 100.0000 (98.9166)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:20  Lr: 0.001875  Loss: 0.3374  Acc@1: 81.2500 (80.9622)  Acc@5: 100.0000 (98.9156)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:16  Lr: 0.001875  Loss: 0.4280  Acc@1: 81.2500 (80.9708)  Acc@5: 100.0000 (98.9182)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:13  Lr: 0.001875  Loss: 0.6147  Acc@1: 81.2500 (80.9620)  Acc@5: 100.0000 (98.9207)  time: 0.3431  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:09  Lr: 0.001875  Loss: 0.5566  Acc@1: 81.2500 (80.9705)  Acc@5: 100.0000 (98.9129)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:06  Lr: 0.001875  Loss: 0.3172  Acc@1: 81.2500 (80.9617)  Acc@5: 100.0000 (98.9154)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:02  Lr: 0.001875  Loss: 0.3593  Acc@1: 81.2500 (80.9667)  Acc@5: 100.0000 (98.9179)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1840/3750]  eta: 0:10:59  Lr: 0.001875  Loss: 0.3513  Acc@1: 81.2500 (80.9784)  Acc@5: 100.0000 (98.9204)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1850/3750]  eta: 0:10:55  Lr: 0.001875  Loss: 0.6821  Acc@1: 81.2500 (80.9529)  Acc@5: 100.0000 (98.9229)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:52  Lr: 0.001875  Loss: 0.7963  Acc@1: 81.2500 (80.9511)  Acc@5: 100.0000 (98.9186)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:49  Lr: 0.001875  Loss: 0.3477  Acc@1: 81.2500 (80.9360)  Acc@5: 100.0000 (98.9110)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:45  Lr: 0.001875  Loss: 0.3888  Acc@1: 75.0000 (80.9177)  Acc@5: 100.0000 (98.9068)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:42  Lr: 0.001875  Loss: 0.8633  Acc@1: 75.0000 (80.8765)  Acc@5: 100.0000 (98.9126)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:38  Lr: 0.001875  Loss: 0.4715  Acc@1: 75.0000 (80.8851)  Acc@5: 100.0000 (98.9118)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:35  Lr: 0.001875  Loss: 0.3187  Acc@1: 81.2500 (80.8739)  Acc@5: 100.0000 (98.9175)  time: 0.3429  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:31  Lr: 0.001875  Loss: 0.8582  Acc@1: 75.0000 (80.8531)  Acc@5: 100.0000 (98.9068)  time: 0.3437  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:28  Lr: 0.001875  Loss: 0.4608  Acc@1: 81.2500 (80.8389)  Acc@5: 100.0000 (98.8995)  time: 0.3438  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:24  Lr: 0.001875  Loss: 0.5420  Acc@1: 81.2500 (80.8411)  Acc@5: 100.0000 (98.9052)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:21  Lr: 0.001875  Loss: 0.9369  Acc@1: 81.2500 (80.8752)  Acc@5: 100.0000 (98.9076)  time: 0.3462  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:17  Lr: 0.001875  Loss: 0.3641  Acc@1: 87.5000 (80.8899)  Acc@5: 100.0000 (98.9068)  time: 0.3450  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:14  Lr: 0.001875  Loss: 0.6973  Acc@1: 75.0000 (80.8568)  Acc@5: 100.0000 (98.8997)  time: 0.3441  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:10  Lr: 0.001875  Loss: 0.3583  Acc@1: 75.0000 (80.8619)  Acc@5: 100.0000 (98.9021)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:07  Lr: 0.001875  Loss: 0.8238  Acc@1: 81.2500 (80.8670)  Acc@5: 100.0000 (98.9044)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:04  Lr: 0.001875  Loss: 0.3745  Acc@1: 81.2500 (80.8658)  Acc@5: 100.0000 (98.9005)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:00  Lr: 0.001875  Loss: 0.5725  Acc@1: 81.2500 (80.8491)  Acc@5: 100.0000 (98.8967)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2020/3750]  eta: 0:09:57  Lr: 0.001875  Loss: 0.4558  Acc@1: 81.2500 (80.8449)  Acc@5: 100.0000 (98.8960)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2030/3750]  eta: 0:09:53  Lr: 0.001875  Loss: 0.3501  Acc@1: 81.2500 (80.8500)  Acc@5: 100.0000 (98.8983)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:50  Lr: 0.001875  Loss: 0.5472  Acc@1: 81.2500 (80.8458)  Acc@5: 100.0000 (98.8976)  time: 0.3433  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:46  Lr: 0.001875  Loss: 0.2196  Acc@1: 81.2500 (80.8264)  Acc@5: 100.0000 (98.8999)  time: 0.3444  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:43  Lr: 0.001875  Loss: 0.9123  Acc@1: 81.2500 (80.8527)  Acc@5: 100.0000 (98.9053)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:39  Lr: 0.001875  Loss: 0.5430  Acc@1: 81.2500 (80.8456)  Acc@5: 100.0000 (98.9045)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:36  Lr: 0.001875  Loss: 0.7109  Acc@1: 75.0000 (80.8385)  Acc@5: 100.0000 (98.9038)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:32  Lr: 0.001875  Loss: 0.3506  Acc@1: 75.0000 (80.8256)  Acc@5: 100.0000 (98.9030)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:29  Lr: 0.001875  Loss: 0.7764  Acc@1: 81.2500 (80.8157)  Acc@5: 100.0000 (98.9023)  time: 0.3440  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:26  Lr: 0.001875  Loss: 0.0259  Acc@1: 81.2500 (80.8237)  Acc@5: 100.0000 (98.8986)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:22  Lr: 0.001875  Loss: 0.5151  Acc@1: 81.2500 (80.8227)  Acc@5: 100.0000 (98.9038)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:19  Lr: 0.001875  Loss: 0.9056  Acc@1: 81.2500 (80.8159)  Acc@5: 100.0000 (98.9031)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:15  Lr: 0.001875  Loss: 0.7568  Acc@1: 75.0000 (80.8034)  Acc@5: 100.0000 (98.8965)  time: 0.3439  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:12  Lr: 0.001875  Loss: 0.5187  Acc@1: 81.2500 (80.8083)  Acc@5: 100.0000 (98.8988)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:08  Lr: 0.001875  Loss: 0.7867  Acc@1: 75.0000 (80.7901)  Acc@5: 100.0000 (98.9010)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:05  Lr: 0.001875  Loss: 0.5130  Acc@1: 81.2500 (80.7951)  Acc@5: 100.0000 (98.9003)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:01  Lr: 0.001875  Loss: 0.2999  Acc@1: 81.2500 (80.7886)  Acc@5: 100.0000 (98.9025)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2190/3750]  eta: 0:08:58  Lr: 0.001875  Loss: 0.4582  Acc@1: 75.0000 (80.7793)  Acc@5: 100.0000 (98.8989)  time: 0.3452  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2200/3750]  eta: 0:08:54  Lr: 0.001875  Loss: 0.8906  Acc@1: 81.2500 (80.7729)  Acc@5: 100.0000 (98.8954)  time: 0.3452  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:51  Lr: 0.001875  Loss: 0.2940  Acc@1: 81.2500 (80.7949)  Acc@5: 100.0000 (98.8976)  time: 0.3445  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:48  Lr: 0.001875  Loss: 1.0541  Acc@1: 87.5000 (80.7941)  Acc@5: 100.0000 (98.8997)  time: 0.3464  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:44  Lr: 0.001875  Loss: 0.6615  Acc@1: 81.2500 (80.8074)  Acc@5: 100.0000 (98.9046)  time: 0.3464  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:41  Lr: 0.001875  Loss: 0.4829  Acc@1: 81.2500 (80.7926)  Acc@5: 100.0000 (98.9067)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:37  Lr: 0.001875  Loss: 0.5640  Acc@1: 81.2500 (80.8058)  Acc@5: 100.0000 (98.9116)  time: 0.3433  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:34  Lr: 0.001875  Loss: 0.5037  Acc@1: 81.2500 (80.7994)  Acc@5: 100.0000 (98.9136)  time: 0.3437  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:30  Lr: 0.001875  Loss: 0.5109  Acc@1: 81.2500 (80.8097)  Acc@5: 100.0000 (98.9102)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:27  Lr: 0.001875  Loss: 0.6221  Acc@1: 81.2500 (80.8226)  Acc@5: 100.0000 (98.9122)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:23  Lr: 0.001875  Loss: 0.2914  Acc@1: 81.2500 (80.8108)  Acc@5: 100.0000 (98.9060)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:20  Lr: 0.001875  Loss: 0.5907  Acc@1: 81.2500 (80.8127)  Acc@5: 100.0000 (98.9054)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:16  Lr: 0.001875  Loss: 0.7960  Acc@1: 81.2500 (80.8065)  Acc@5: 100.0000 (98.9020)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:13  Lr: 0.001875  Loss: 0.6534  Acc@1: 81.2500 (80.8003)  Acc@5: 100.0000 (98.9013)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:10  Lr: 0.001875  Loss: 0.5522  Acc@1: 81.2500 (80.7995)  Acc@5: 100.0000 (98.9060)  time: 0.3424  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:06  Lr: 0.001875  Loss: 0.2189  Acc@1: 81.2500 (80.7614)  Acc@5: 100.0000 (98.8974)  time: 0.3430  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:03  Lr: 0.001875  Loss: 0.3588  Acc@1: 81.2500 (80.7635)  Acc@5: 100.0000 (98.8967)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2360/3750]  eta: 0:07:59  Lr: 0.001875  Loss: 0.5080  Acc@1: 81.2500 (80.7523)  Acc@5: 100.0000 (98.9014)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2370/3750]  eta: 0:07:56  Lr: 0.001875  Loss: 0.7062  Acc@1: 75.0000 (80.7518)  Acc@5: 100.0000 (98.9061)  time: 0.3436  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:52  Lr: 0.001875  Loss: 0.6140  Acc@1: 81.2500 (80.7591)  Acc@5: 100.0000 (98.9028)  time: 0.3437  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:49  Lr: 0.001875  Loss: 0.6471  Acc@1: 81.2500 (80.7586)  Acc@5: 100.0000 (98.9047)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:45  Lr: 0.001875  Loss: 0.6950  Acc@1: 81.2500 (80.7450)  Acc@5: 100.0000 (98.9067)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:42  Lr: 0.001875  Loss: 0.4146  Acc@1: 81.2500 (80.7419)  Acc@5: 100.0000 (98.8983)  time: 0.3433  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:38  Lr: 0.001875  Loss: 0.1042  Acc@1: 81.2500 (80.7569)  Acc@5: 100.0000 (98.9002)  time: 0.3446  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:35  Lr: 0.001875  Loss: 0.5764  Acc@1: 81.2500 (80.7487)  Acc@5: 100.0000 (98.8996)  time: 0.3441  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:31  Lr: 0.001875  Loss: 0.3881  Acc@1: 81.2500 (80.7635)  Acc@5: 100.0000 (98.9041)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:28  Lr: 0.001875  Loss: 1.2402  Acc@1: 81.2500 (80.7630)  Acc@5: 100.0000 (98.9035)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:25  Lr: 0.001875  Loss: 0.9387  Acc@1: 81.2500 (80.7599)  Acc@5: 100.0000 (98.8978)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:21  Lr: 0.001875  Loss: 0.2113  Acc@1: 81.2500 (80.7770)  Acc@5: 100.0000 (98.9023)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:18  Lr: 0.001875  Loss: 0.7362  Acc@1: 81.2500 (80.7588)  Acc@5: 100.0000 (98.9042)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:14  Lr: 0.001875  Loss: 0.4467  Acc@1: 81.2500 (80.7582)  Acc@5: 100.0000 (98.9036)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:11  Lr: 0.001875  Loss: 0.4299  Acc@1: 81.2500 (80.7577)  Acc@5: 100.0000 (98.9079)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:07  Lr: 0.001875  Loss: 0.4757  Acc@1: 81.2500 (80.7721)  Acc@5: 100.0000 (98.9098)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:04  Lr: 0.001875  Loss: 1.0762  Acc@1: 81.2500 (80.7641)  Acc@5: 100.0000 (98.9067)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:00  Lr: 0.001875  Loss: 1.1823  Acc@1: 75.0000 (80.7388)  Acc@5: 100.0000 (98.9036)  time: 0.3447  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2540/3750]  eta: 0:06:57  Lr: 0.001875  Loss: 0.3788  Acc@1: 75.0000 (80.7384)  Acc@5: 100.0000 (98.9079)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:53  Lr: 0.001875  Loss: 0.7036  Acc@1: 81.2500 (80.7355)  Acc@5: 100.0000 (98.9073)  time: 0.3444  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:50  Lr: 0.001875  Loss: 0.5046  Acc@1: 81.2500 (80.7351)  Acc@5: 100.0000 (98.9091)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:47  Lr: 0.001875  Loss: 0.8252  Acc@1: 81.2500 (80.7225)  Acc@5: 100.0000 (98.9109)  time: 0.3445  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:43  Lr: 0.001875  Loss: 0.8021  Acc@1: 81.2500 (80.7318)  Acc@5: 100.0000 (98.9103)  time: 0.3455  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:40  Lr: 0.001875  Loss: 0.7099  Acc@1: 81.2500 (80.7362)  Acc@5: 100.0000 (98.9145)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:36  Lr: 0.001875  Loss: 0.3055  Acc@1: 81.2500 (80.7262)  Acc@5: 100.0000 (98.9163)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:33  Lr: 0.001875  Loss: 0.2580  Acc@1: 81.2500 (80.7090)  Acc@5: 100.0000 (98.9180)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:29  Lr: 0.001875  Loss: 0.4883  Acc@1: 81.2500 (80.7206)  Acc@5: 100.0000 (98.9150)  time: 0.3438  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:26  Lr: 0.001875  Loss: 0.5844  Acc@1: 81.2500 (80.7369)  Acc@5: 100.0000 (98.9191)  time: 0.3453  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:22  Lr: 0.001875  Loss: 0.5082  Acc@1: 81.2500 (80.7365)  Acc@5: 100.0000 (98.9209)  time: 0.3453  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:19  Lr: 0.001875  Loss: 0.5004  Acc@1: 81.2500 (80.7431)  Acc@5: 100.0000 (98.9226)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:16  Lr: 0.001875  Loss: 0.5262  Acc@1: 81.2500 (80.7403)  Acc@5: 100.0000 (98.9219)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:12  Lr: 0.001875  Loss: 0.8270  Acc@1: 81.2500 (80.7305)  Acc@5: 100.0000 (98.9166)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:09  Lr: 0.001875  Loss: 0.1881  Acc@1: 81.2500 (80.7535)  Acc@5: 100.0000 (98.9160)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:05  Lr: 0.001875  Loss: 0.7301  Acc@1: 81.2500 (80.7460)  Acc@5: 100.0000 (98.9130)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:02  Lr: 0.001875  Loss: 0.6582  Acc@1: 81.2500 (80.7386)  Acc@5: 100.0000 (98.9078)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2710/3750]  eta: 0:05:58  Lr: 0.001875  Loss: 0.7154  Acc@1: 81.2500 (80.7382)  Acc@5: 100.0000 (98.9118)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:55  Lr: 0.001875  Loss: 0.3527  Acc@1: 81.2500 (80.7447)  Acc@5: 100.0000 (98.9135)  time: 0.3446  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:51  Lr: 0.001875  Loss: 0.2358  Acc@1: 81.2500 (80.7442)  Acc@5: 100.0000 (98.9107)  time: 0.3447  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:48  Lr: 0.001875  Loss: 0.1952  Acc@1: 81.2500 (80.7598)  Acc@5: 100.0000 (98.9146)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:44  Lr: 0.001875  Loss: 0.7598  Acc@1: 81.2500 (80.7638)  Acc@5: 100.0000 (98.9118)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:41  Lr: 0.001875  Loss: 0.3474  Acc@1: 81.2500 (80.7588)  Acc@5: 100.0000 (98.9066)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:38  Lr: 0.001875  Loss: 0.3698  Acc@1: 81.2500 (80.7515)  Acc@5: 100.0000 (98.9016)  time: 0.3443  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:34  Lr: 0.001875  Loss: 0.4022  Acc@1: 81.2500 (80.7623)  Acc@5: 100.0000 (98.9010)  time: 0.3436  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:31  Lr: 0.001875  Loss: 0.6076  Acc@1: 87.5000 (80.7596)  Acc@5: 100.0000 (98.8982)  time: 0.3430  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:27  Lr: 0.001875  Loss: 0.6504  Acc@1: 75.0000 (80.7479)  Acc@5: 100.0000 (98.8999)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:24  Lr: 0.001875  Loss: 0.6745  Acc@1: 81.2500 (80.7542)  Acc@5: 100.0000 (98.8972)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:20  Lr: 0.001875  Loss: 0.7749  Acc@1: 81.2500 (80.7493)  Acc@5: 100.0000 (98.9011)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:17  Lr: 0.001875  Loss: 0.7207  Acc@1: 75.0000 (80.7356)  Acc@5: 100.0000 (98.9006)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:13  Lr: 0.001875  Loss: 0.6263  Acc@1: 81.2500 (80.7308)  Acc@5: 100.0000 (98.9000)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:10  Lr: 0.001875  Loss: 0.4625  Acc@1: 81.2500 (80.7502)  Acc@5: 100.0000 (98.9017)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:06  Lr: 0.001875  Loss: 0.7438  Acc@1: 87.5000 (80.7607)  Acc@5: 100.0000 (98.9012)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:03  Lr: 0.001875  Loss: 0.6104  Acc@1: 87.5000 (80.7645)  Acc@5: 100.0000 (98.9006)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:00  Lr: 0.001875  Loss: 0.5070  Acc@1: 87.5000 (80.7684)  Acc@5: 100.0000 (98.8936)  time: 0.3450  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2890/3750]  eta: 0:04:56  Lr: 0.001875  Loss: 0.5614  Acc@1: 81.2500 (80.7657)  Acc@5: 100.0000 (98.8931)  time: 0.3443  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:53  Lr: 0.001875  Loss: 0.5373  Acc@1: 81.2500 (80.7760)  Acc@5: 100.0000 (98.8948)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:49  Lr: 0.001875  Loss: 0.4955  Acc@1: 81.2500 (80.7798)  Acc@5: 100.0000 (98.8986)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:46  Lr: 0.001875  Loss: 1.0091  Acc@1: 81.2500 (80.7814)  Acc@5: 100.0000 (98.8938)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:42  Lr: 0.001875  Loss: 0.7929  Acc@1: 81.2500 (80.7787)  Acc@5: 100.0000 (98.8912)  time: 0.3433  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:39  Lr: 0.001875  Loss: 0.5027  Acc@1: 81.2500 (80.7888)  Acc@5: 100.0000 (98.8928)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:35  Lr: 0.001875  Loss: 0.7384  Acc@1: 81.2500 (80.7819)  Acc@5: 100.0000 (98.8923)  time: 0.3442  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:32  Lr: 0.001875  Loss: 0.6037  Acc@1: 81.2500 (80.7920)  Acc@5: 100.0000 (98.8918)  time: 0.3445  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:29  Lr: 0.001875  Loss: 0.4255  Acc@1: 81.2500 (80.7977)  Acc@5: 100.0000 (98.8935)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:25  Lr: 0.001875  Loss: 0.1995  Acc@1: 81.2500 (80.7929)  Acc@5: 100.0000 (98.8930)  time: 0.3450  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:22  Lr: 0.001875  Loss: 0.8552  Acc@1: 81.2500 (80.7903)  Acc@5: 100.0000 (98.8967)  time: 0.3450  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:18  Lr: 0.001875  Loss: 0.5676  Acc@1: 75.0000 (80.7772)  Acc@5: 100.0000 (98.8920)  time: 0.3449  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:15  Lr: 0.001875  Loss: 0.7472  Acc@1: 81.2500 (80.7747)  Acc@5: 100.0000 (98.8916)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:11  Lr: 0.001875  Loss: 0.3321  Acc@1: 81.2500 (80.7555)  Acc@5: 100.0000 (98.8932)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:08  Lr: 0.001875  Loss: 0.3395  Acc@1: 75.0000 (80.7386)  Acc@5: 100.0000 (98.8948)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:04  Lr: 0.001875  Loss: 0.2709  Acc@1: 81.2500 (80.7321)  Acc@5: 100.0000 (98.8943)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:01  Lr: 0.001875  Loss: 0.5815  Acc@1: 81.2500 (80.7379)  Acc@5: 100.0000 (98.8938)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3060/3750]  eta: 0:03:57  Lr: 0.001875  Loss: 0.2396  Acc@1: 81.2500 (80.7375)  Acc@5: 100.0000 (98.8974)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.6669  Acc@1: 81.2500 (80.7229)  Acc@5: 100.0000 (98.9010)  time: 0.3456  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:51  Lr: 0.001875  Loss: 0.9440  Acc@1: 75.0000 (80.7185)  Acc@5: 100.0000 (98.8965)  time: 0.3447  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:47  Lr: 0.001875  Loss: 0.7091  Acc@1: 81.2500 (80.7243)  Acc@5: 100.0000 (98.9000)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:44  Lr: 0.001875  Loss: 0.2686  Acc@1: 81.2500 (80.7421)  Acc@5: 100.0000 (98.9036)  time: 0.3445  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:40  Lr: 0.001875  Loss: 0.5499  Acc@1: 87.5000 (80.7578)  Acc@5: 100.0000 (98.9031)  time: 0.3456  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:37  Lr: 0.001875  Loss: 0.7629  Acc@1: 81.2500 (80.7514)  Acc@5: 100.0000 (98.9026)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.2897  Acc@1: 81.2500 (80.7609)  Acc@5: 100.0000 (98.9061)  time: 0.3454  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.3607  Acc@1: 87.5000 (80.7665)  Acc@5: 100.0000 (98.9096)  time: 0.3450  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:26  Lr: 0.001875  Loss: 0.4670  Acc@1: 81.2500 (80.7462)  Acc@5: 100.0000 (98.9130)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.8533  Acc@1: 75.0000 (80.7438)  Acc@5: 100.0000 (98.9145)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:20  Lr: 0.001875  Loss: 1.0008  Acc@1: 81.2500 (80.7494)  Acc@5: 100.0000 (98.9140)  time: 0.3450  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:16  Lr: 0.001875  Loss: 0.4247  Acc@1: 81.2500 (80.7490)  Acc@5: 100.0000 (98.9135)  time: 0.3458  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:13  Lr: 0.001875  Loss: 0.8361  Acc@1: 81.2500 (80.7486)  Acc@5: 100.0000 (98.9149)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:09  Lr: 0.001875  Loss: 0.2953  Acc@1: 81.2500 (80.7599)  Acc@5: 100.0000 (98.9164)  time: 0.3438  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:06  Lr: 0.001875  Loss: 0.3086  Acc@1: 87.5000 (80.7712)  Acc@5: 100.0000 (98.9139)  time: 0.3452  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:02  Lr: 0.001875  Loss: 0.6334  Acc@1: 87.5000 (80.7746)  Acc@5: 100.0000 (98.9153)  time: 0.3449  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 0.4678  Acc@1: 81.2500 (80.7722)  Acc@5: 100.0000 (98.9167)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:55  Lr: 0.001875  Loss: 0.3607  Acc@1: 81.2500 (80.7698)  Acc@5: 100.0000 (98.9162)  time: 0.3441  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.6621  Acc@1: 81.2500 (80.7848)  Acc@5: 100.0000 (98.9176)  time: 0.3437  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:48  Lr: 0.001875  Loss: 0.1860  Acc@1: 81.2500 (80.7574)  Acc@5: 100.0000 (98.9171)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 0.9405  Acc@1: 75.0000 (80.7589)  Acc@5: 100.0000 (98.9166)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:42  Lr: 0.001875  Loss: 0.6376  Acc@1: 81.2500 (80.7585)  Acc@5: 100.0000 (98.9199)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 0.5788  Acc@1: 81.2500 (80.7334)  Acc@5: 100.0000 (98.9175)  time: 0.3431  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:35  Lr: 0.001875  Loss: 0.4358  Acc@1: 75.0000 (80.7274)  Acc@5: 100.0000 (98.9132)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:31  Lr: 0.001875  Loss: 0.2141  Acc@1: 81.2500 (80.7403)  Acc@5: 100.0000 (98.9127)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.3247  Acc@1: 81.2500 (80.7343)  Acc@5: 100.0000 (98.9141)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:24  Lr: 0.001875  Loss: 0.4456  Acc@1: 81.2500 (80.7471)  Acc@5: 100.0000 (98.9136)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.4548  Acc@1: 81.2500 (80.7487)  Acc@5: 100.0000 (98.9150)  time: 0.3446  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:17  Lr: 0.001875  Loss: 0.7451  Acc@1: 81.2500 (80.7334)  Acc@5: 100.0000 (98.9182)  time: 0.3440  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.4298  Acc@1: 81.2500 (80.7405)  Acc@5: 100.0000 (98.9215)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:11  Lr: 0.001875  Loss: 0.5176  Acc@1: 81.2500 (80.7494)  Acc@5: 100.0000 (98.9247)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.4945  Acc@1: 87.5000 (80.7657)  Acc@5: 100.0000 (98.9260)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:04  Lr: 0.001875  Loss: 0.3321  Acc@1: 81.2500 (80.7579)  Acc@5: 100.0000 (98.9273)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 1.1215  Acc@1: 81.2500 (80.7648)  Acc@5: 100.0000 (98.9286)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.4529  Acc@1: 81.2500 (80.7644)  Acc@5: 100.0000 (98.9281)  time: 0.3448  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 1.0232  Acc@1: 75.0000 (80.7439)  Acc@5: 100.0000 (98.9276)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.4134  Acc@1: 81.2500 (80.7527)  Acc@5: 100.0000 (98.9252)  time: 0.3440  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:46  Lr: 0.001875  Loss: 0.2391  Acc@1: 87.5000 (80.7705)  Acc@5: 100.0000 (98.9247)  time: 0.3445  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.6198  Acc@1: 81.2500 (80.7628)  Acc@5: 100.0000 (98.9260)  time: 0.3445  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: 0.4638  Acc@1: 81.2500 (80.7642)  Acc@5: 100.0000 (98.9255)  time: 0.3440  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.4621  Acc@1: 81.2500 (80.7584)  Acc@5: 100.0000 (98.9232)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: 0.5870  Acc@1: 87.5000 (80.7742)  Acc@5: 100.0000 (98.9263)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.6411  Acc@1: 81.2500 (80.7577)  Acc@5: 100.0000 (98.9258)  time: 0.3433  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.1850  Acc@1: 75.0000 (80.7519)  Acc@5: 100.0000 (98.9271)  time: 0.3430  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.6191  Acc@1: 81.2500 (80.7640)  Acc@5: 100.0000 (98.9301)  time: 0.3431  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.4290  Acc@1: 81.2500 (80.7636)  Acc@5: 100.0000 (98.9314)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 0.3948  Acc@1: 87.5000 (80.7685)  Acc@5: 100.0000 (98.9327)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.7156  Acc@1: 81.2500 (80.7540)  Acc@5: 100.0000 (98.9322)  time: 0.3437  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:08  Lr: 0.001875  Loss: 0.6850  Acc@1: 81.2500 (80.7625)  Acc@5: 100.0000 (98.9316)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.4247  Acc@1: 81.2500 (80.7568)  Acc@5: 100.0000 (98.9329)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: 0.8655  Acc@1: 81.2500 (80.7599)  Acc@5: 100.0000 (98.9289)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 0.6219  Acc@1: 81.2500 (80.7578)  Acc@5: 100.0000 (98.9284)  time: 0.3450  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.5297  Acc@1: 81.2500 (80.7644)  Acc@5: 100.0000 (98.9314)  time: 0.3450  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2978  Acc@1: 81.2500 (80.7658)  Acc@5: 100.0000 (98.9343)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2292  Acc@1: 81.2500 (80.7619)  Acc@5: 100.0000 (98.9338)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2534  Acc@1: 81.2500 (80.7771)  Acc@5: 100.0000 (98.9368)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.9341  Acc@1: 87.5000 (80.7784)  Acc@5: 100.0000 (98.9328)  time: 0.3459  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 0.4938  Acc@1: 87.5000 (80.7985)  Acc@5: 100.0000 (98.9306)  time: 0.3461  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3285  Acc@1: 81.2500 (80.7964)  Acc@5: 100.0000 (98.9335)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1130  Acc@1: 81.2500 (80.8095)  Acc@5: 100.0000 (98.9330)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.6642  Acc@1: 81.2500 (80.8039)  Acc@5: 100.0000 (98.9325)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.9115  Acc@1: 75.0000 (80.7933)  Acc@5: 100.0000 (98.9354)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 0.2709  Acc@1: 75.0000 (80.7725)  Acc@5: 100.0000 (98.9298)  time: 0.3461  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.6945  Acc@1: 81.2500 (80.7721)  Acc@5: 100.0000 (98.9277)  time: 0.3463  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.4399  Acc@1: 81.2500 (80.7784)  Acc@5: 100.0000 (98.9289)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.5220  Acc@1: 81.2500 (80.7931)  Acc@5: 100.0000 (98.9284)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.6261  Acc@1: 81.2500 (80.7944)  Acc@5: 100.0000 (98.9296)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.6180  Acc@1: 81.2500 (80.7906)  Acc@5: 100.0000 (98.9258)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1862  Acc@1: 81.2500 (80.7900)  Acc@5: 100.0000 (98.9283)  time: 0.3457  data: 0.0015  max mem: 2503
Train: Epoch[4/5] Total time: 0:21:33 (0.3450 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.1862  Acc@1: 81.2500 (80.7900)  Acc@5: 100.0000 (98.9283)
Train: Epoch[5/5]  [   0/3750]  eta: 0:52:53  Lr: 0.001875  Loss: 0.4289  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8461  data: 0.5023  max mem: 2503
Train: Epoch[5/5]  [  10/3750]  eta: 0:24:25  Lr: 0.001875  Loss: 0.4382  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3919  data: 0.0460  max mem: 2503
Train: Epoch[5/5]  [  20/3750]  eta: 0:23:03  Lr: 0.001875  Loss: 1.0473  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (99.1071)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:28  Lr: 0.001875  Loss: 0.7060  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (99.3952)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:10  Lr: 0.001875  Loss: 0.6272  Acc@1: 81.2500 (83.3841)  Acc@5: 100.0000 (99.3902)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [  50/3750]  eta: 0:21:56  Lr: 0.001875  Loss: 0.2570  Acc@1: 81.2500 (83.2108)  Acc@5: 100.0000 (99.5098)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:46  Lr: 0.001875  Loss: 0.7868  Acc@1: 81.2500 (82.5820)  Acc@5: 100.0000 (99.3852)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:38  Lr: 0.001875  Loss: 0.3937  Acc@1: 81.2500 (82.0423)  Acc@5: 100.0000 (99.2077)  time: 0.3451  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:31  Lr: 0.001875  Loss: 0.5367  Acc@1: 81.2500 (81.8673)  Acc@5: 100.0000 (99.2284)  time: 0.3453  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:25  Lr: 0.001875  Loss: 0.4561  Acc@1: 81.2500 (81.9368)  Acc@5: 100.0000 (99.2445)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:18  Lr: 0.001875  Loss: 0.6667  Acc@1: 81.2500 (81.9307)  Acc@5: 100.0000 (99.1955)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:13  Lr: 0.001875  Loss: 0.1820  Acc@1: 81.2500 (81.9257)  Acc@5: 100.0000 (99.0991)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:07  Lr: 0.001875  Loss: 0.7034  Acc@1: 81.2500 (82.0248)  Acc@5: 100.0000 (99.0702)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:03  Lr: 0.001875  Loss: 0.7830  Acc@1: 81.2500 (81.9656)  Acc@5: 100.0000 (99.1412)  time: 0.3448  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 140/3750]  eta: 0:20:58  Lr: 0.001875  Loss: 0.9389  Acc@1: 81.2500 (81.8262)  Acc@5: 100.0000 (99.1135)  time: 0.3446  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 150/3750]  eta: 0:20:54  Lr: 0.001875  Loss: 0.6061  Acc@1: 81.2500 (81.9123)  Acc@5: 100.0000 (99.1308)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 160/3750]  eta: 0:20:49  Lr: 0.001875  Loss: 0.5722  Acc@1: 81.2500 (81.7158)  Acc@5: 100.0000 (99.1460)  time: 0.3447  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:45  Lr: 0.001875  Loss: 0.6265  Acc@1: 81.2500 (81.8713)  Acc@5: 100.0000 (99.1594)  time: 0.3441  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:41  Lr: 0.001875  Loss: 0.4412  Acc@1: 81.2500 (81.9061)  Acc@5: 100.0000 (99.1713)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:37  Lr: 0.001875  Loss: 0.3718  Acc@1: 81.2500 (81.9372)  Acc@5: 100.0000 (99.1492)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:32  Lr: 0.001875  Loss: 0.4839  Acc@1: 81.2500 (81.9963)  Acc@5: 100.0000 (99.1915)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:28  Lr: 0.001875  Loss: 0.3803  Acc@1: 81.2500 (81.7536)  Acc@5: 100.0000 (99.2299)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:25  Lr: 0.001875  Loss: 0.2928  Acc@1: 75.0000 (81.7308)  Acc@5: 100.0000 (99.1516)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:21  Lr: 0.001875  Loss: 0.6073  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (99.1883)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:17  Lr: 0.001875  Loss: 0.3224  Acc@1: 81.2500 (81.5871)  Acc@5: 100.0000 (99.1961)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:14  Lr: 0.001875  Loss: 0.3814  Acc@1: 87.5000 (81.8476)  Acc@5: 100.0000 (99.2032)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:10  Lr: 0.001875  Loss: 0.7624  Acc@1: 87.5000 (81.8487)  Acc@5: 100.0000 (99.2098)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:06  Lr: 0.001875  Loss: 0.5629  Acc@1: 75.0000 (81.6190)  Acc@5: 100.0000 (99.1467)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:03  Lr: 0.001875  Loss: 0.6254  Acc@1: 75.0000 (81.3612)  Acc@5: 100.0000 (99.1548)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 290/3750]  eta: 0:19:59  Lr: 0.001875  Loss: 0.2092  Acc@1: 75.0000 (81.4648)  Acc@5: 100.0000 (99.1624)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 300/3750]  eta: 0:19:55  Lr: 0.001875  Loss: 0.2155  Acc@1: 87.5000 (81.6030)  Acc@5: 100.0000 (99.1487)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 310/3750]  eta: 0:19:52  Lr: 0.001875  Loss: 0.7231  Acc@1: 87.5000 (81.6921)  Acc@5: 100.0000 (99.1559)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 320/3750]  eta: 0:19:48  Lr: 0.001875  Loss: 0.5921  Acc@1: 81.2500 (81.5615)  Acc@5: 100.0000 (99.1628)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:45  Lr: 0.001875  Loss: 0.5652  Acc@1: 81.2500 (81.5332)  Acc@5: 100.0000 (99.1503)  time: 0.3453  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:41  Lr: 0.001875  Loss: 0.5683  Acc@1: 75.0000 (81.4883)  Acc@5: 100.0000 (99.1752)  time: 0.3458  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:37  Lr: 0.001875  Loss: 0.1850  Acc@1: 81.2500 (81.4637)  Acc@5: 100.0000 (99.1631)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:34  Lr: 0.001875  Loss: 0.1388  Acc@1: 81.2500 (81.4924)  Acc@5: 100.0000 (99.1517)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:30  Lr: 0.001875  Loss: 0.4723  Acc@1: 81.2500 (81.4522)  Acc@5: 100.0000 (99.1408)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:26  Lr: 0.001875  Loss: 0.7979  Acc@1: 81.2500 (81.3976)  Acc@5: 100.0000 (99.1306)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:23  Lr: 0.001875  Loss: 0.3222  Acc@1: 81.2500 (81.4418)  Acc@5: 100.0000 (99.1368)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:19  Lr: 0.001875  Loss: 0.8351  Acc@1: 87.5000 (81.4059)  Acc@5: 100.0000 (99.1116)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:16  Lr: 0.001875  Loss: 0.8730  Acc@1: 81.2500 (81.3412)  Acc@5: 100.0000 (99.1028)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:12  Lr: 0.001875  Loss: 0.6157  Acc@1: 75.0000 (81.1609)  Acc@5: 100.0000 (99.0944)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:09  Lr: 0.001875  Loss: 0.4157  Acc@1: 75.0000 (81.0615)  Acc@5: 100.0000 (99.1154)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:05  Lr: 0.001875  Loss: 0.5390  Acc@1: 75.0000 (81.0232)  Acc@5: 100.0000 (99.0788)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:02  Lr: 0.001875  Loss: 1.3719  Acc@1: 75.0000 (81.0006)  Acc@5: 100.0000 (99.0715)  time: 0.3468  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 460/3750]  eta: 0:18:58  Lr: 0.001875  Loss: 0.9456  Acc@1: 81.2500 (81.0331)  Acc@5: 100.0000 (99.0645)  time: 0.3458  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 470/3750]  eta: 0:18:55  Lr: 0.001875  Loss: 0.4607  Acc@1: 87.5000 (81.1173)  Acc@5: 100.0000 (99.0446)  time: 0.3447  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 480/3750]  eta: 0:18:51  Lr: 0.001875  Loss: 0.3318  Acc@1: 87.5000 (81.1201)  Acc@5: 100.0000 (99.0255)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:48  Lr: 0.001875  Loss: 0.3984  Acc@1: 81.2500 (81.1609)  Acc@5: 100.0000 (99.0453)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:44  Lr: 0.001875  Loss: 0.5116  Acc@1: 81.2500 (81.1627)  Acc@5: 100.0000 (99.0269)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:41  Lr: 0.001875  Loss: 0.0851  Acc@1: 81.2500 (81.1766)  Acc@5: 100.0000 (99.0338)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:37  Lr: 0.001875  Loss: 0.7470  Acc@1: 81.2500 (81.2380)  Acc@5: 100.0000 (99.0283)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:34  Lr: 0.001875  Loss: 0.7194  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (99.0466)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:30  Lr: 0.001875  Loss: 0.5645  Acc@1: 81.2500 (81.2384)  Acc@5: 100.0000 (99.0642)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:26  Lr: 0.001875  Loss: 0.4221  Acc@1: 81.2500 (81.2387)  Acc@5: 100.0000 (99.0812)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:23  Lr: 0.001875  Loss: 0.5386  Acc@1: 81.2500 (81.2054)  Acc@5: 100.0000 (99.0865)  time: 0.3446  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:19  Lr: 0.001875  Loss: 0.1051  Acc@1: 81.2500 (81.2281)  Acc@5: 100.0000 (99.1025)  time: 0.3449  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:16  Lr: 0.001875  Loss: 0.3205  Acc@1: 81.2500 (81.2392)  Acc@5: 100.0000 (99.1071)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:12  Lr: 0.001875  Loss: 0.8112  Acc@1: 81.2500 (81.2288)  Acc@5: 100.0000 (99.1117)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:09  Lr: 0.001875  Loss: 0.4088  Acc@1: 81.2500 (81.3228)  Acc@5: 100.0000 (99.1265)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:05  Lr: 0.001875  Loss: 0.4808  Acc@1: 81.2500 (81.3830)  Acc@5: 100.0000 (99.1305)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:02  Lr: 0.001875  Loss: 0.3846  Acc@1: 81.2500 (81.3808)  Acc@5: 100.0000 (99.1244)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 630/3750]  eta: 0:17:58  Lr: 0.001875  Loss: 0.8497  Acc@1: 87.5000 (81.4481)  Acc@5: 100.0000 (99.1284)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 640/3750]  eta: 0:17:55  Lr: 0.001875  Loss: 0.3246  Acc@1: 87.5000 (81.4060)  Acc@5: 100.0000 (99.1322)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 650/3750]  eta: 0:17:51  Lr: 0.001875  Loss: 0.1809  Acc@1: 81.2500 (81.4708)  Acc@5: 100.0000 (99.1359)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:48  Lr: 0.001875  Loss: 0.1776  Acc@1: 81.2500 (81.4958)  Acc@5: 100.0000 (99.1301)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:44  Lr: 0.001875  Loss: 0.5284  Acc@1: 81.2500 (81.4083)  Acc@5: 100.0000 (99.1338)  time: 0.3457  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:41  Lr: 0.001875  Loss: 1.1326  Acc@1: 81.2500 (81.3326)  Acc@5: 100.0000 (99.1281)  time: 0.3451  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:37  Lr: 0.001875  Loss: 0.4114  Acc@1: 81.2500 (81.3495)  Acc@5: 100.0000 (99.1136)  time: 0.3447  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:34  Lr: 0.001875  Loss: 0.4106  Acc@1: 81.2500 (81.3302)  Acc@5: 100.0000 (99.0995)  time: 0.3447  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:30  Lr: 0.001875  Loss: 0.1897  Acc@1: 81.2500 (81.3379)  Acc@5: 100.0000 (99.0946)  time: 0.3451  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:27  Lr: 0.001875  Loss: 0.7861  Acc@1: 81.2500 (81.2587)  Acc@5: 100.0000 (99.0898)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:23  Lr: 0.001875  Loss: 0.3086  Acc@1: 81.2500 (81.2671)  Acc@5: 100.0000 (99.0852)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:20  Lr: 0.001875  Loss: 0.7988  Acc@1: 81.2500 (81.2669)  Acc@5: 100.0000 (99.0975)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:16  Lr: 0.001875  Loss: 0.2750  Acc@1: 81.2500 (81.3166)  Acc@5: 100.0000 (99.1095)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:13  Lr: 0.001875  Loss: 0.4973  Acc@1: 81.2500 (81.3403)  Acc@5: 100.0000 (99.1212)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:09  Lr: 0.001875  Loss: 0.4735  Acc@1: 81.2500 (81.3067)  Acc@5: 100.0000 (99.1326)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:06  Lr: 0.001875  Loss: 1.0256  Acc@1: 81.2500 (81.3300)  Acc@5: 100.0000 (99.1197)  time: 0.3438  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:02  Lr: 0.001875  Loss: 0.5530  Acc@1: 81.2500 (81.3685)  Acc@5: 100.0000 (99.1229)  time: 0.3439  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 800/3750]  eta: 0:16:59  Lr: 0.001875  Loss: 0.9230  Acc@1: 81.2500 (81.3826)  Acc@5: 100.0000 (99.1183)  time: 0.3441  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 810/3750]  eta: 0:16:55  Lr: 0.001875  Loss: 0.6397  Acc@1: 81.2500 (81.3733)  Acc@5: 100.0000 (99.1292)  time: 0.3438  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 820/3750]  eta: 0:16:52  Lr: 0.001875  Loss: 0.4078  Acc@1: 81.2500 (81.3794)  Acc@5: 100.0000 (99.1169)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 830/3750]  eta: 0:16:48  Lr: 0.001875  Loss: 0.7649  Acc@1: 81.2500 (81.3628)  Acc@5: 100.0000 (99.1125)  time: 0.3449  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:45  Lr: 0.001875  Loss: 0.5977  Acc@1: 81.2500 (81.3615)  Acc@5: 100.0000 (99.0933)  time: 0.3460  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:41  Lr: 0.001875  Loss: 0.8303  Acc@1: 81.2500 (81.3528)  Acc@5: 100.0000 (99.0967)  time: 0.3464  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:38  Lr: 0.001875  Loss: 0.8703  Acc@1: 81.2500 (81.3444)  Acc@5: 100.0000 (99.0854)  time: 0.3452  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:34  Lr: 0.001875  Loss: 0.6453  Acc@1: 81.2500 (81.3935)  Acc@5: 100.0000 (99.0815)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:31  Lr: 0.001875  Loss: 0.7515  Acc@1: 87.5000 (81.4061)  Acc@5: 100.0000 (99.0848)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:28  Lr: 0.001875  Loss: 0.3848  Acc@1: 81.2500 (81.4184)  Acc@5: 100.0000 (99.0811)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:24  Lr: 0.001875  Loss: 0.4388  Acc@1: 81.2500 (81.3818)  Acc@5: 100.0000 (99.0844)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:21  Lr: 0.001875  Loss: 0.3748  Acc@1: 81.2500 (81.4352)  Acc@5: 100.0000 (99.0944)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:17  Lr: 0.001875  Loss: 0.4232  Acc@1: 81.2500 (81.4536)  Acc@5: 100.0000 (99.0907)  time: 0.3465  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:14  Lr: 0.001875  Loss: 0.5382  Acc@1: 81.2500 (81.4245)  Acc@5: 100.0000 (99.0937)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:10  Lr: 0.001875  Loss: 0.8826  Acc@1: 81.2500 (81.4094)  Acc@5: 100.0000 (99.0967)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:07  Lr: 0.001875  Loss: 0.7359  Acc@1: 81.2500 (81.3880)  Acc@5: 100.0000 (99.0996)  time: 0.3458  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:03  Lr: 0.001875  Loss: 0.5969  Acc@1: 81.2500 (81.4321)  Acc@5: 100.0000 (99.0895)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:00  Lr: 0.001875  Loss: 0.3324  Acc@1: 81.2500 (81.4495)  Acc@5: 100.0000 (99.0860)  time: 0.3440  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 980/3750]  eta: 0:15:56  Lr: 0.001875  Loss: 0.1811  Acc@1: 81.2500 (81.5048)  Acc@5: 100.0000 (99.0826)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 990/3750]  eta: 0:15:53  Lr: 0.001875  Loss: 0.1384  Acc@1: 81.2500 (81.5275)  Acc@5: 100.0000 (99.0855)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1000/3750]  eta: 0:15:49  Lr: 0.001875  Loss: 0.5160  Acc@1: 87.5000 (81.5747)  Acc@5: 100.0000 (99.0947)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:46  Lr: 0.001875  Loss: 0.7233  Acc@1: 87.5000 (81.5962)  Acc@5: 100.0000 (99.1036)  time: 0.3440  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:42  Lr: 0.001875  Loss: 0.3222  Acc@1: 81.2500 (81.6234)  Acc@5: 100.0000 (99.1124)  time: 0.3439  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:39  Lr: 0.001875  Loss: 0.6927  Acc@1: 81.2500 (81.5834)  Acc@5: 100.0000 (99.1210)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:35  Lr: 0.001875  Loss: 0.3728  Acc@1: 81.2500 (81.5742)  Acc@5: 100.0000 (99.1114)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:32  Lr: 0.001875  Loss: 0.4252  Acc@1: 81.2500 (81.5473)  Acc@5: 100.0000 (99.1199)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:29  Lr: 0.001875  Loss: 0.6120  Acc@1: 75.0000 (81.5269)  Acc@5: 100.0000 (99.1223)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:25  Lr: 0.001875  Loss: 0.2879  Acc@1: 81.2500 (81.5651)  Acc@5: 100.0000 (99.1246)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:22  Lr: 0.001875  Loss: 0.6358  Acc@1: 81.2500 (81.5506)  Acc@5: 100.0000 (99.1270)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:18  Lr: 0.001875  Loss: 0.2413  Acc@1: 87.5000 (81.5823)  Acc@5: 100.0000 (99.1235)  time: 0.3437  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:15  Lr: 0.001875  Loss: 0.6822  Acc@1: 87.5000 (81.5679)  Acc@5: 100.0000 (99.1201)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:11  Lr: 0.001875  Loss: 0.7555  Acc@1: 87.5000 (81.5707)  Acc@5: 100.0000 (99.1280)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:08  Lr: 0.001875  Loss: 0.5220  Acc@1: 87.5000 (81.6291)  Acc@5: 100.0000 (99.1247)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:04  Lr: 0.001875  Loss: 0.2142  Acc@1: 87.5000 (81.6313)  Acc@5: 100.0000 (99.1269)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:01  Lr: 0.001875  Loss: 0.7633  Acc@1: 75.0000 (81.5567)  Acc@5: 100.0000 (99.1291)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1150/3750]  eta: 0:14:57  Lr: 0.001875  Loss: 0.4123  Acc@1: 75.0000 (81.5269)  Acc@5: 100.0000 (99.1366)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1160/3750]  eta: 0:14:54  Lr: 0.001875  Loss: 0.6089  Acc@1: 75.0000 (81.5192)  Acc@5: 100.0000 (99.1171)  time: 0.3455  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1170/3750]  eta: 0:14:50  Lr: 0.001875  Loss: 0.2966  Acc@1: 81.2500 (81.5222)  Acc@5: 100.0000 (99.1033)  time: 0.3453  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:47  Lr: 0.001875  Loss: 0.2154  Acc@1: 81.2500 (81.5411)  Acc@5: 100.0000 (99.1109)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:43  Lr: 0.001875  Loss: 0.6921  Acc@1: 81.2500 (81.5281)  Acc@5: 100.0000 (99.1131)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:40  Lr: 0.001875  Loss: 0.5278  Acc@1: 81.2500 (81.5570)  Acc@5: 100.0000 (99.1205)  time: 0.3453  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:36  Lr: 0.001875  Loss: 0.6818  Acc@1: 81.2500 (81.5287)  Acc@5: 100.0000 (99.1278)  time: 0.3453  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:33  Lr: 0.001875  Loss: 0.9269  Acc@1: 81.2500 (81.5264)  Acc@5: 100.0000 (99.1247)  time: 0.3444  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:30  Lr: 0.001875  Loss: 0.2615  Acc@1: 81.2500 (81.5597)  Acc@5: 100.0000 (99.1267)  time: 0.3448  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:26  Lr: 0.001875  Loss: 0.1976  Acc@1: 87.5000 (81.5673)  Acc@5: 100.0000 (99.1338)  time: 0.3444  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:23  Lr: 0.001875  Loss: 0.6249  Acc@1: 81.2500 (81.5797)  Acc@5: 100.0000 (99.1357)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:19  Lr: 0.001875  Loss: 0.3241  Acc@1: 81.2500 (81.5771)  Acc@5: 100.0000 (99.1425)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:16  Lr: 0.001875  Loss: 0.6688  Acc@1: 75.0000 (81.5450)  Acc@5: 100.0000 (99.1395)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:12  Lr: 0.001875  Loss: 0.6835  Acc@1: 75.0000 (81.5379)  Acc@5: 100.0000 (99.1462)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:09  Lr: 0.001875  Loss: 0.5175  Acc@1: 81.2500 (81.5356)  Acc@5: 100.0000 (99.1479)  time: 0.3440  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:05  Lr: 0.001875  Loss: 0.4585  Acc@1: 81.2500 (81.5238)  Acc@5: 100.0000 (99.1497)  time: 0.3441  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:02  Lr: 0.001875  Loss: 0.3242  Acc@1: 81.2500 (81.5122)  Acc@5: 100.0000 (99.1323)  time: 0.3447  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1320/3750]  eta: 0:13:58  Lr: 0.001875  Loss: 1.0099  Acc@1: 81.2500 (81.5055)  Acc@5: 100.0000 (99.1389)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1330/3750]  eta: 0:13:55  Lr: 0.001875  Loss: 0.5529  Acc@1: 81.2500 (81.5177)  Acc@5: 100.0000 (99.1407)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1340/3750]  eta: 0:13:51  Lr: 0.001875  Loss: 0.5562  Acc@1: 81.2500 (81.4924)  Acc@5: 100.0000 (99.1378)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:48  Lr: 0.001875  Loss: 0.3145  Acc@1: 81.2500 (81.5229)  Acc@5: 100.0000 (99.1395)  time: 0.3443  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:44  Lr: 0.001875  Loss: 0.8096  Acc@1: 87.5000 (81.5669)  Acc@5: 100.0000 (99.1367)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:41  Lr: 0.001875  Loss: 0.4109  Acc@1: 81.2500 (81.5554)  Acc@5: 100.0000 (99.1430)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:38  Lr: 0.001875  Loss: 0.4859  Acc@1: 81.2500 (81.5713)  Acc@5: 100.0000 (99.1492)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:34  Lr: 0.001875  Loss: 0.5277  Acc@1: 81.2500 (81.5510)  Acc@5: 100.0000 (99.1418)  time: 0.3474  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:31  Lr: 0.001875  Loss: 0.4243  Acc@1: 81.2500 (81.5177)  Acc@5: 100.0000 (99.1435)  time: 0.3477  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:27  Lr: 0.001875  Loss: 0.7436  Acc@1: 81.2500 (81.5202)  Acc@5: 100.0000 (99.1407)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:24  Lr: 0.001875  Loss: 0.1530  Acc@1: 81.2500 (81.5095)  Acc@5: 100.0000 (99.1335)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:20  Lr: 0.001875  Loss: 0.3796  Acc@1: 81.2500 (81.4902)  Acc@5: 100.0000 (99.1396)  time: 0.3437  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:17  Lr: 0.001875  Loss: 0.5484  Acc@1: 81.2500 (81.4625)  Acc@5: 100.0000 (99.1369)  time: 0.3453  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:13  Lr: 0.001875  Loss: 1.1220  Acc@1: 81.2500 (81.4568)  Acc@5: 100.0000 (99.1428)  time: 0.3465  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:10  Lr: 0.001875  Loss: 0.8223  Acc@1: 81.2500 (81.4553)  Acc@5: 100.0000 (99.1444)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:07  Lr: 0.001875  Loss: 0.3181  Acc@1: 87.5000 (81.4752)  Acc@5: 100.0000 (99.1332)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:03  Lr: 0.001875  Loss: 0.5788  Acc@1: 81.2500 (81.4610)  Acc@5: 100.0000 (99.1349)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:00  Lr: 0.001875  Loss: 0.3344  Acc@1: 81.2500 (81.4847)  Acc@5: 100.0000 (99.1407)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1500/3750]  eta: 0:12:56  Lr: 0.001875  Loss: 0.3597  Acc@1: 81.2500 (81.4790)  Acc@5: 100.0000 (99.1464)  time: 0.3460  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1510/3750]  eta: 0:12:53  Lr: 0.001875  Loss: 0.4418  Acc@1: 81.2500 (81.4692)  Acc@5: 100.0000 (99.1479)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:49  Lr: 0.001875  Loss: 1.0897  Acc@1: 81.2500 (81.4513)  Acc@5: 100.0000 (99.1371)  time: 0.3463  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:46  Lr: 0.001875  Loss: 0.7664  Acc@1: 81.2500 (81.4378)  Acc@5: 100.0000 (99.1386)  time: 0.3445  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:42  Lr: 0.001875  Loss: 0.8288  Acc@1: 75.0000 (81.4487)  Acc@5: 100.0000 (99.1361)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:39  Lr: 0.001875  Loss: 0.7097  Acc@1: 81.2500 (81.4515)  Acc@5: 100.0000 (99.1377)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:35  Lr: 0.001875  Loss: 0.7349  Acc@1: 81.2500 (81.4822)  Acc@5: 100.0000 (99.1392)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:32  Lr: 0.001875  Loss: 0.6939  Acc@1: 81.2500 (81.4648)  Acc@5: 100.0000 (99.1367)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:29  Lr: 0.001875  Loss: 0.5227  Acc@1: 81.2500 (81.4753)  Acc@5: 100.0000 (99.1382)  time: 0.3456  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:25  Lr: 0.001875  Loss: 0.3618  Acc@1: 81.2500 (81.4778)  Acc@5: 100.0000 (99.1397)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:22  Lr: 0.001875  Loss: 0.6184  Acc@1: 81.2500 (81.4803)  Acc@5: 100.0000 (99.1334)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:18  Lr: 0.001875  Loss: 0.5999  Acc@1: 87.5000 (81.4983)  Acc@5: 100.0000 (99.1387)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:15  Lr: 0.001875  Loss: 0.4460  Acc@1: 81.2500 (81.4968)  Acc@5: 100.0000 (99.1363)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:11  Lr: 0.001875  Loss: 0.6608  Acc@1: 81.2500 (81.4838)  Acc@5: 100.0000 (99.1378)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:08  Lr: 0.001875  Loss: 0.6400  Acc@1: 81.2500 (81.4899)  Acc@5: 100.0000 (99.1354)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:04  Lr: 0.001875  Loss: 0.8166  Acc@1: 81.2500 (81.4998)  Acc@5: 100.0000 (99.1255)  time: 0.3445  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:01  Lr: 0.001875  Loss: 0.6393  Acc@1: 81.2500 (81.5021)  Acc@5: 100.0000 (99.1233)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1670/3750]  eta: 0:11:57  Lr: 0.001875  Loss: 0.2790  Acc@1: 81.2500 (81.5156)  Acc@5: 100.0000 (99.1285)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1680/3750]  eta: 0:11:54  Lr: 0.001875  Loss: 0.3224  Acc@1: 81.2500 (81.5289)  Acc@5: 100.0000 (99.1337)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:50  Lr: 0.001875  Loss: 0.2268  Acc@1: 81.2500 (81.5161)  Acc@5: 100.0000 (99.1351)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:47  Lr: 0.001875  Loss: 0.6903  Acc@1: 81.2500 (81.5146)  Acc@5: 100.0000 (99.1329)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:44  Lr: 0.001875  Loss: 0.4458  Acc@1: 81.2500 (81.4984)  Acc@5: 100.0000 (99.1233)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:40  Lr: 0.001875  Loss: 0.1488  Acc@1: 81.2500 (81.4969)  Acc@5: 100.0000 (99.1248)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:37  Lr: 0.001875  Loss: 0.4820  Acc@1: 81.2500 (81.4955)  Acc@5: 100.0000 (99.1298)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:33  Lr: 0.001875  Loss: 0.3169  Acc@1: 81.2500 (81.4546)  Acc@5: 100.0000 (99.1312)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:30  Lr: 0.001875  Loss: 0.4247  Acc@1: 81.2500 (81.4713)  Acc@5: 100.0000 (99.1148)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:26  Lr: 0.001875  Loss: 0.4769  Acc@1: 81.2500 (81.4771)  Acc@5: 100.0000 (99.1092)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:23  Lr: 0.001875  Loss: 1.0661  Acc@1: 81.2500 (81.4653)  Acc@5: 100.0000 (99.1107)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:19  Lr: 0.001875  Loss: 0.6498  Acc@1: 81.2500 (81.4570)  Acc@5: 100.0000 (99.1086)  time: 0.3439  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:16  Lr: 0.001875  Loss: 0.6964  Acc@1: 81.2500 (81.4594)  Acc@5: 100.0000 (99.1136)  time: 0.3441  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:12  Lr: 0.001875  Loss: 0.6928  Acc@1: 81.2500 (81.4270)  Acc@5: 100.0000 (99.1116)  time: 0.3438  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:09  Lr: 0.001875  Loss: 0.3122  Acc@1: 75.0000 (81.4191)  Acc@5: 100.0000 (99.0958)  time: 0.3435  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:05  Lr: 0.001875  Loss: 0.1664  Acc@1: 81.2500 (81.4147)  Acc@5: 100.0000 (99.0973)  time: 0.3441  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:02  Lr: 0.001875  Loss: 0.3218  Acc@1: 81.2500 (81.4275)  Acc@5: 100.0000 (99.1023)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1840/3750]  eta: 0:10:59  Lr: 0.001875  Loss: 0.4708  Acc@1: 81.2500 (81.4163)  Acc@5: 100.0000 (99.0902)  time: 0.3450  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1850/3750]  eta: 0:10:55  Lr: 0.001875  Loss: 0.4622  Acc@1: 81.2500 (81.4222)  Acc@5: 100.0000 (99.0951)  time: 0.3456  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:52  Lr: 0.001875  Loss: 0.5079  Acc@1: 81.2500 (81.3978)  Acc@5: 100.0000 (99.0932)  time: 0.3441  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:48  Lr: 0.001875  Loss: 0.4323  Acc@1: 81.2500 (81.4137)  Acc@5: 100.0000 (99.0914)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:45  Lr: 0.001875  Loss: 0.4166  Acc@1: 81.2500 (81.4028)  Acc@5: 100.0000 (99.0929)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:41  Lr: 0.001875  Loss: 0.4130  Acc@1: 81.2500 (81.4285)  Acc@5: 100.0000 (99.0911)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:38  Lr: 0.001875  Loss: 0.7632  Acc@1: 87.5000 (81.4177)  Acc@5: 100.0000 (99.0893)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:34  Lr: 0.001875  Loss: 0.4754  Acc@1: 81.2500 (81.3874)  Acc@5: 100.0000 (99.0875)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:31  Lr: 0.001875  Loss: 0.4840  Acc@1: 81.2500 (81.3932)  Acc@5: 100.0000 (99.0858)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:27  Lr: 0.001875  Loss: 0.7915  Acc@1: 81.2500 (81.3859)  Acc@5: 100.0000 (99.0743)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:24  Lr: 0.001875  Loss: 0.2618  Acc@1: 81.2500 (81.3756)  Acc@5: 100.0000 (99.0726)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:21  Lr: 0.001875  Loss: 0.4260  Acc@1: 81.2500 (81.3685)  Acc@5: 100.0000 (99.0710)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:17  Lr: 0.001875  Loss: 0.2654  Acc@1: 81.2500 (81.3616)  Acc@5: 100.0000 (99.0694)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:14  Lr: 0.001875  Loss: 0.6308  Acc@1: 81.2500 (81.3673)  Acc@5: 100.0000 (99.0677)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:10  Lr: 0.001875  Loss: 0.4554  Acc@1: 81.2500 (81.3636)  Acc@5: 100.0000 (99.0661)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:07  Lr: 0.001875  Loss: 0.3186  Acc@1: 81.2500 (81.3567)  Acc@5: 100.0000 (99.0645)  time: 0.3436  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:03  Lr: 0.001875  Loss: 0.8138  Acc@1: 81.2500 (81.3718)  Acc@5: 100.0000 (99.0630)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:00  Lr: 0.001875  Loss: 0.4202  Acc@1: 81.2500 (81.3619)  Acc@5: 100.0000 (99.0583)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2020/3750]  eta: 0:09:56  Lr: 0.001875  Loss: 0.4307  Acc@1: 81.2500 (81.3953)  Acc@5: 100.0000 (99.0599)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2030/3750]  eta: 0:09:53  Lr: 0.001875  Loss: 0.1294  Acc@1: 87.5000 (81.4223)  Acc@5: 100.0000 (99.0614)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:49  Lr: 0.001875  Loss: 0.3273  Acc@1: 81.2500 (81.4215)  Acc@5: 100.0000 (99.0599)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:46  Lr: 0.001875  Loss: 0.3180  Acc@1: 81.2500 (81.4298)  Acc@5: 100.0000 (99.0584)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:43  Lr: 0.001875  Loss: 0.2111  Acc@1: 81.2500 (81.4532)  Acc@5: 100.0000 (99.0599)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:39  Lr: 0.001875  Loss: 0.5618  Acc@1: 81.2500 (81.4431)  Acc@5: 100.0000 (99.0584)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:36  Lr: 0.001875  Loss: 0.3348  Acc@1: 81.2500 (81.4542)  Acc@5: 100.0000 (99.0539)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:32  Lr: 0.001875  Loss: 0.2433  Acc@1: 81.2500 (81.4503)  Acc@5: 100.0000 (99.0525)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:29  Lr: 0.001875  Loss: 0.5424  Acc@1: 81.2500 (81.4344)  Acc@5: 100.0000 (99.0540)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:25  Lr: 0.001875  Loss: 0.3054  Acc@1: 81.2500 (81.4306)  Acc@5: 100.0000 (99.0526)  time: 0.3453  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:22  Lr: 0.001875  Loss: 0.3245  Acc@1: 81.2500 (81.4121)  Acc@5: 100.0000 (99.0512)  time: 0.3445  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:18  Lr: 0.001875  Loss: 0.1907  Acc@1: 81.2500 (81.4142)  Acc@5: 100.0000 (99.0556)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:15  Lr: 0.001875  Loss: 0.1825  Acc@1: 81.2500 (81.4222)  Acc@5: 100.0000 (99.0513)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:11  Lr: 0.001875  Loss: 0.4644  Acc@1: 87.5000 (81.4476)  Acc@5: 100.0000 (99.0528)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:08  Lr: 0.001875  Loss: 0.3803  Acc@1: 87.5000 (81.4553)  Acc@5: 100.0000 (99.0543)  time: 0.3440  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:05  Lr: 0.001875  Loss: 0.8696  Acc@1: 81.2500 (81.4515)  Acc@5: 100.0000 (99.0529)  time: 0.3441  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:01  Lr: 0.001875  Loss: 0.5201  Acc@1: 81.2500 (81.4563)  Acc@5: 100.0000 (99.0486)  time: 0.3440  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2190/3750]  eta: 0:08:58  Lr: 0.001875  Loss: 0.3096  Acc@1: 81.2500 (81.4639)  Acc@5: 100.0000 (99.0472)  time: 0.3434  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2200/3750]  eta: 0:08:54  Lr: 0.001875  Loss: 0.1945  Acc@1: 81.2500 (81.4658)  Acc@5: 100.0000 (99.0487)  time: 0.3433  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:51  Lr: 0.001875  Loss: 0.4033  Acc@1: 81.2500 (81.4620)  Acc@5: 100.0000 (99.0530)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:47  Lr: 0.001875  Loss: 0.4321  Acc@1: 81.2500 (81.4836)  Acc@5: 100.0000 (99.0489)  time: 0.3441  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:44  Lr: 0.001875  Loss: 0.2856  Acc@1: 81.2500 (81.4937)  Acc@5: 100.0000 (99.0503)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:40  Lr: 0.001875  Loss: 0.7574  Acc@1: 81.2500 (81.4982)  Acc@5: 100.0000 (99.0490)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:37  Lr: 0.001875  Loss: 0.8085  Acc@1: 81.2500 (81.4805)  Acc@5: 100.0000 (99.0449)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:33  Lr: 0.001875  Loss: 0.3174  Acc@1: 75.0000 (81.4850)  Acc@5: 100.0000 (99.0463)  time: 0.3455  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:30  Lr: 0.001875  Loss: 0.9242  Acc@1: 75.0000 (81.4812)  Acc@5: 100.0000 (99.0450)  time: 0.3453  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:27  Lr: 0.001875  Loss: 0.1165  Acc@1: 87.5000 (81.5185)  Acc@5: 100.0000 (99.0465)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:23  Lr: 0.001875  Loss: 0.2679  Acc@1: 87.5000 (81.5337)  Acc@5: 100.0000 (99.0479)  time: 0.3445  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:20  Lr: 0.001875  Loss: 0.5705  Acc@1: 87.5000 (81.5298)  Acc@5: 100.0000 (99.0520)  time: 0.3447  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:16  Lr: 0.001875  Loss: 0.5584  Acc@1: 81.2500 (81.5204)  Acc@5: 100.0000 (99.0507)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:13  Lr: 0.001875  Loss: 0.5676  Acc@1: 81.2500 (81.5166)  Acc@5: 100.0000 (99.0494)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:09  Lr: 0.001875  Loss: 0.6375  Acc@1: 81.2500 (81.5128)  Acc@5: 100.0000 (99.0482)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:06  Lr: 0.001875  Loss: 0.9590  Acc@1: 81.2500 (81.5036)  Acc@5: 100.0000 (99.0469)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:02  Lr: 0.001875  Loss: 0.2592  Acc@1: 81.2500 (81.5132)  Acc@5: 100.0000 (99.0509)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2360/3750]  eta: 0:07:59  Lr: 0.001875  Loss: 0.2792  Acc@1: 87.5000 (81.5571)  Acc@5: 100.0000 (99.0523)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2370/3750]  eta: 0:07:55  Lr: 0.001875  Loss: 0.4554  Acc@1: 87.5000 (81.5584)  Acc@5: 100.0000 (99.0537)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:52  Lr: 0.001875  Loss: 0.5608  Acc@1: 81.2500 (81.5571)  Acc@5: 100.0000 (99.0576)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:49  Lr: 0.001875  Loss: 0.1580  Acc@1: 81.2500 (81.5820)  Acc@5: 100.0000 (99.0590)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:45  Lr: 0.001875  Loss: 0.5505  Acc@1: 87.5000 (81.5858)  Acc@5: 100.0000 (99.0577)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:42  Lr: 0.001875  Loss: 0.6696  Acc@1: 81.2500 (81.5740)  Acc@5: 100.0000 (99.0590)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:38  Lr: 0.001875  Loss: 0.5222  Acc@1: 81.2500 (81.5675)  Acc@5: 100.0000 (99.0577)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:35  Lr: 0.001875  Loss: 0.5759  Acc@1: 81.2500 (81.5817)  Acc@5: 100.0000 (99.0616)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:31  Lr: 0.001875  Loss: 0.5102  Acc@1: 81.2500 (81.5726)  Acc@5: 100.0000 (99.0578)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:28  Lr: 0.001875  Loss: 1.0442  Acc@1: 81.2500 (81.5611)  Acc@5: 100.0000 (99.0591)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:24  Lr: 0.001875  Loss: 0.4623  Acc@1: 81.2500 (81.5395)  Acc@5: 100.0000 (99.0578)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:21  Lr: 0.001875  Loss: 0.3331  Acc@1: 81.2500 (81.5611)  Acc@5: 100.0000 (99.0540)  time: 0.3431  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:17  Lr: 0.001875  Loss: 0.6177  Acc@1: 81.2500 (81.5498)  Acc@5: 100.0000 (99.0503)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:14  Lr: 0.001875  Loss: 0.2307  Acc@1: 81.2500 (81.5536)  Acc@5: 100.0000 (99.0516)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:11  Lr: 0.001875  Loss: 0.5748  Acc@1: 87.5000 (81.5699)  Acc@5: 100.0000 (99.0529)  time: 0.3434  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:07  Lr: 0.001875  Loss: 0.4769  Acc@1: 87.5000 (81.5736)  Acc@5: 100.0000 (99.0542)  time: 0.3433  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:04  Lr: 0.001875  Loss: 0.6190  Acc@1: 87.5000 (81.5921)  Acc@5: 100.0000 (99.0554)  time: 0.3460  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:00  Lr: 0.001875  Loss: 0.5403  Acc@1: 81.2500 (81.5834)  Acc@5: 100.0000 (99.0592)  time: 0.3478  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2540/3750]  eta: 0:06:57  Lr: 0.001875  Loss: 0.4409  Acc@1: 81.2500 (81.5698)  Acc@5: 100.0000 (99.0555)  time: 0.3457  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:53  Lr: 0.001875  Loss: 0.9535  Acc@1: 81.2500 (81.5661)  Acc@5: 100.0000 (99.0494)  time: 0.3447  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:50  Lr: 0.001875  Loss: 0.6778  Acc@1: 81.2500 (81.5795)  Acc@5: 100.0000 (99.0507)  time: 0.3454  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:46  Lr: 0.001875  Loss: 0.7130  Acc@1: 81.2500 (81.5636)  Acc@5: 100.0000 (99.0544)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:43  Lr: 0.001875  Loss: 0.5370  Acc@1: 81.2500 (81.5503)  Acc@5: 100.0000 (99.0580)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:40  Lr: 0.001875  Loss: 0.7646  Acc@1: 81.2500 (81.5539)  Acc@5: 100.0000 (99.0617)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:36  Lr: 0.001875  Loss: 0.4051  Acc@1: 81.2500 (81.5504)  Acc@5: 100.0000 (99.0629)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:33  Lr: 0.001875  Loss: 1.2933  Acc@1: 81.2500 (81.5205)  Acc@5: 100.0000 (99.0641)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:29  Lr: 0.001875  Loss: 0.5504  Acc@1: 81.2500 (81.5314)  Acc@5: 100.0000 (99.0652)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:26  Lr: 0.001875  Loss: 0.2128  Acc@1: 87.5000 (81.5517)  Acc@5: 100.0000 (99.0664)  time: 0.3465  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:22  Lr: 0.001875  Loss: 0.5359  Acc@1: 81.2500 (81.5222)  Acc@5: 100.0000 (99.0629)  time: 0.3455  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:19  Lr: 0.001875  Loss: 0.4940  Acc@1: 75.0000 (81.5188)  Acc@5: 100.0000 (99.0570)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:15  Lr: 0.001875  Loss: 0.2621  Acc@1: 81.2500 (81.5154)  Acc@5: 100.0000 (99.0535)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:12  Lr: 0.001875  Loss: 0.4762  Acc@1: 81.2500 (81.5191)  Acc@5: 100.0000 (99.0570)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:09  Lr: 0.001875  Loss: 0.2420  Acc@1: 81.2500 (81.5041)  Acc@5: 100.0000 (99.0605)  time: 0.3451  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:05  Lr: 0.001875  Loss: 0.3076  Acc@1: 81.2500 (81.4962)  Acc@5: 100.0000 (99.0617)  time: 0.3455  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:02  Lr: 0.001875  Loss: 0.1662  Acc@1: 81.2500 (81.5045)  Acc@5: 100.0000 (99.0652)  time: 0.3449  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2710/3750]  eta: 0:05:58  Lr: 0.001875  Loss: 0.3508  Acc@1: 81.2500 (81.5105)  Acc@5: 100.0000 (99.0640)  time: 0.3456  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:55  Lr: 0.001875  Loss: 0.7399  Acc@1: 81.2500 (81.5096)  Acc@5: 100.0000 (99.0674)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:51  Lr: 0.001875  Loss: 0.4587  Acc@1: 81.2500 (81.5063)  Acc@5: 100.0000 (99.0686)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:48  Lr: 0.001875  Loss: 0.6122  Acc@1: 81.2500 (81.5145)  Acc@5: 100.0000 (99.0674)  time: 0.3449  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:44  Lr: 0.001875  Loss: 0.5880  Acc@1: 81.2500 (81.5204)  Acc@5: 100.0000 (99.0685)  time: 0.3444  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:41  Lr: 0.001875  Loss: 0.6308  Acc@1: 81.2500 (81.5148)  Acc@5: 100.0000 (99.0719)  time: 0.3436  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:37  Lr: 0.001875  Loss: 0.3916  Acc@1: 81.2500 (81.5116)  Acc@5: 100.0000 (99.0707)  time: 0.3436  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:34  Lr: 0.001875  Loss: 0.1565  Acc@1: 81.2500 (81.5152)  Acc@5: 100.0000 (99.0718)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:31  Lr: 0.001875  Loss: 0.4305  Acc@1: 81.2500 (81.5142)  Acc@5: 100.0000 (99.0729)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:27  Lr: 0.001875  Loss: 0.7524  Acc@1: 81.2500 (81.5245)  Acc@5: 100.0000 (99.0718)  time: 0.3424  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:24  Lr: 0.001875  Loss: 0.4328  Acc@1: 81.2500 (81.5235)  Acc@5: 100.0000 (99.0706)  time: 0.3436  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:20  Lr: 0.001875  Loss: 0.2079  Acc@1: 81.2500 (81.5380)  Acc@5: 100.0000 (99.0717)  time: 0.3441  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:17  Lr: 0.001875  Loss: 0.4172  Acc@1: 87.5000 (81.5480)  Acc@5: 100.0000 (99.0750)  time: 0.3438  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:13  Lr: 0.001875  Loss: 0.4244  Acc@1: 81.2500 (81.5536)  Acc@5: 100.0000 (99.0760)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:10  Lr: 0.001875  Loss: 0.4027  Acc@1: 81.2500 (81.5481)  Acc@5: 100.0000 (99.0749)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:06  Lr: 0.001875  Loss: 0.4829  Acc@1: 81.2500 (81.5558)  Acc@5: 100.0000 (99.0738)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:03  Lr: 0.001875  Loss: 0.6463  Acc@1: 81.2500 (81.5613)  Acc@5: 100.0000 (99.0726)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:00  Lr: 0.001875  Loss: 0.3645  Acc@1: 81.2500 (81.5515)  Acc@5: 100.0000 (99.0715)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2890/3750]  eta: 0:04:56  Lr: 0.001875  Loss: 0.3514  Acc@1: 81.2500 (81.5591)  Acc@5: 100.0000 (99.0726)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:53  Lr: 0.001875  Loss: 0.7986  Acc@1: 87.5000 (81.5753)  Acc@5: 100.0000 (99.0693)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:49  Lr: 0.001875  Loss: 0.7163  Acc@1: 87.5000 (81.5871)  Acc@5: 100.0000 (99.0725)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:46  Lr: 0.001875  Loss: 0.1312  Acc@1: 81.2500 (81.5817)  Acc@5: 100.0000 (99.0757)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:42  Lr: 0.001875  Loss: 0.6350  Acc@1: 81.2500 (81.5741)  Acc@5: 100.0000 (99.0745)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:39  Lr: 0.001875  Loss: 0.5577  Acc@1: 81.2500 (81.5815)  Acc@5: 100.0000 (99.0756)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:35  Lr: 0.001875  Loss: 0.4395  Acc@1: 81.2500 (81.5868)  Acc@5: 100.0000 (99.0745)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:32  Lr: 0.001875  Loss: 0.3976  Acc@1: 81.2500 (81.5941)  Acc@5: 100.0000 (99.0755)  time: 0.3437  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:28  Lr: 0.001875  Loss: 0.3814  Acc@1: 81.2500 (81.5824)  Acc@5: 100.0000 (99.0786)  time: 0.3435  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:25  Lr: 0.001875  Loss: 0.2663  Acc@1: 81.2500 (81.5938)  Acc@5: 100.0000 (99.0775)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:22  Lr: 0.001875  Loss: 0.6648  Acc@1: 81.2500 (81.6094)  Acc@5: 100.0000 (99.0785)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:18  Lr: 0.001875  Loss: 0.4777  Acc@1: 81.2500 (81.6124)  Acc@5: 100.0000 (99.0816)  time: 0.3451  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:15  Lr: 0.001875  Loss: 0.5122  Acc@1: 81.2500 (81.6216)  Acc@5: 100.0000 (99.0805)  time: 0.3448  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:11  Lr: 0.001875  Loss: 0.6351  Acc@1: 87.5000 (81.6245)  Acc@5: 100.0000 (99.0835)  time: 0.3431  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:08  Lr: 0.001875  Loss: 0.1792  Acc@1: 81.2500 (81.6274)  Acc@5: 100.0000 (99.0865)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:04  Lr: 0.001875  Loss: 0.5283  Acc@1: 81.2500 (81.6241)  Acc@5: 100.0000 (99.0875)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:01  Lr: 0.001875  Loss: 1.0211  Acc@1: 81.2500 (81.6290)  Acc@5: 100.0000 (99.0884)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3060/3750]  eta: 0:03:57  Lr: 0.001875  Loss: 0.3856  Acc@1: 81.2500 (81.6298)  Acc@5: 100.0000 (99.0873)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.4938  Acc@1: 81.2500 (81.6163)  Acc@5: 100.0000 (99.0882)  time: 0.3441  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:51  Lr: 0.001875  Loss: 0.6702  Acc@1: 75.0000 (81.6172)  Acc@5: 100.0000 (99.0871)  time: 0.3443  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:47  Lr: 0.001875  Loss: 0.9455  Acc@1: 81.2500 (81.6119)  Acc@5: 100.0000 (99.0840)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:44  Lr: 0.001875  Loss: 0.8205  Acc@1: 81.2500 (81.6067)  Acc@5: 100.0000 (99.0789)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:40  Lr: 0.001875  Loss: 0.5205  Acc@1: 81.2500 (81.5996)  Acc@5: 100.0000 (99.0779)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:37  Lr: 0.001875  Loss: 0.7620  Acc@1: 81.2500 (81.5964)  Acc@5: 100.0000 (99.0768)  time: 0.3449  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.6470  Acc@1: 81.2500 (81.5794)  Acc@5: 100.0000 (99.0738)  time: 0.3437  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:30  Lr: 0.001875  Loss: 0.8934  Acc@1: 81.2500 (81.5763)  Acc@5: 100.0000 (99.0747)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:26  Lr: 0.001875  Loss: 0.6372  Acc@1: 81.2500 (81.5634)  Acc@5: 100.0000 (99.0737)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:23  Lr: 0.001875  Loss: 0.4824  Acc@1: 81.2500 (81.5644)  Acc@5: 100.0000 (99.0707)  time: 0.3454  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:19  Lr: 0.001875  Loss: 0.5414  Acc@1: 81.2500 (81.5535)  Acc@5: 100.0000 (99.0717)  time: 0.3471  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:16  Lr: 0.001875  Loss: 0.6004  Acc@1: 81.2500 (81.5565)  Acc@5: 100.0000 (99.0707)  time: 0.3466  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:13  Lr: 0.001875  Loss: 0.1894  Acc@1: 81.2500 (81.5595)  Acc@5: 100.0000 (99.0696)  time: 0.3452  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:09  Lr: 0.001875  Loss: 0.5208  Acc@1: 81.2500 (81.5604)  Acc@5: 100.0000 (99.0667)  time: 0.3465  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:06  Lr: 0.001875  Loss: 0.4603  Acc@1: 81.2500 (81.5673)  Acc@5: 100.0000 (99.0677)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:02  Lr: 0.001875  Loss: 0.6216  Acc@1: 81.2500 (81.5624)  Acc@5: 100.0000 (99.0667)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3230/3750]  eta: 0:02:59  Lr: 0.001875  Loss: 0.3467  Acc@1: 81.2500 (81.5769)  Acc@5: 100.0000 (99.0696)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:55  Lr: 0.001875  Loss: 0.4864  Acc@1: 81.2500 (81.5798)  Acc@5: 100.0000 (99.0686)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:52  Lr: 0.001875  Loss: 0.5988  Acc@1: 81.2500 (81.5730)  Acc@5: 100.0000 (99.0695)  time: 0.3440  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:48  Lr: 0.001875  Loss: 0.7637  Acc@1: 81.2500 (81.5643)  Acc@5: 100.0000 (99.0685)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:45  Lr: 0.001875  Loss: 0.1911  Acc@1: 81.2500 (81.5748)  Acc@5: 100.0000 (99.0657)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:42  Lr: 0.001875  Loss: 0.5859  Acc@1: 81.2500 (81.5738)  Acc@5: 100.0000 (99.0666)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:38  Lr: 0.001875  Loss: 0.5207  Acc@1: 81.2500 (81.5747)  Acc@5: 100.0000 (99.0675)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:35  Lr: 0.001875  Loss: 0.5380  Acc@1: 75.0000 (81.5624)  Acc@5: 100.0000 (99.0685)  time: 0.3470  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:31  Lr: 0.001875  Loss: 0.4614  Acc@1: 75.0000 (81.5558)  Acc@5: 100.0000 (99.0618)  time: 0.3469  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:28  Lr: 0.001875  Loss: 0.8073  Acc@1: 75.0000 (81.5492)  Acc@5: 100.0000 (99.0609)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:24  Lr: 0.001875  Loss: 0.3239  Acc@1: 81.2500 (81.5446)  Acc@5: 100.0000 (99.0600)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:21  Lr: 0.001875  Loss: 0.2930  Acc@1: 81.2500 (81.5531)  Acc@5: 100.0000 (99.0590)  time: 0.3457  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:17  Lr: 0.001875  Loss: 0.4730  Acc@1: 81.2500 (81.5466)  Acc@5: 100.0000 (99.0600)  time: 0.3457  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:14  Lr: 0.001875  Loss: 0.5195  Acc@1: 81.2500 (81.5475)  Acc@5: 100.0000 (99.0609)  time: 0.3448  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:11  Lr: 0.001875  Loss: 0.5237  Acc@1: 81.2500 (81.5411)  Acc@5: 100.0000 (99.0600)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:07  Lr: 0.001875  Loss: 0.9272  Acc@1: 81.2500 (81.5347)  Acc@5: 100.0000 (99.0554)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:04  Lr: 0.001875  Loss: 0.5842  Acc@1: 81.2500 (81.5357)  Acc@5: 100.0000 (99.0563)  time: 0.3456  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:00  Lr: 0.001875  Loss: 0.2783  Acc@1: 81.2500 (81.5422)  Acc@5: 100.0000 (99.0536)  time: 0.3452  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:57  Lr: 0.001875  Loss: 0.4561  Acc@1: 81.2500 (81.5358)  Acc@5: 100.0000 (99.0527)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 0.6798  Acc@1: 81.2500 (81.5405)  Acc@5: 100.0000 (99.0536)  time: 0.3459  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:50  Lr: 0.001875  Loss: 0.4296  Acc@1: 81.2500 (81.5415)  Acc@5: 100.0000 (99.0528)  time: 0.3460  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:46  Lr: 0.001875  Loss: 0.7191  Acc@1: 81.2500 (81.5442)  Acc@5: 100.0000 (99.0537)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:43  Lr: 0.001875  Loss: 0.5048  Acc@1: 81.2500 (81.5506)  Acc@5: 100.0000 (99.0528)  time: 0.3452  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: 0.5103  Acc@1: 81.2500 (81.5498)  Acc@5: 100.0000 (99.0519)  time: 0.3451  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:36  Lr: 0.001875  Loss: 0.3731  Acc@1: 81.2500 (81.5381)  Acc@5: 100.0000 (99.0475)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: 0.6832  Acc@1: 81.2500 (81.5391)  Acc@5: 100.0000 (99.0484)  time: 0.3453  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:29  Lr: 0.001875  Loss: 0.3656  Acc@1: 81.2500 (81.5329)  Acc@5: 100.0000 (99.0493)  time: 0.3452  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: 0.2929  Acc@1: 81.2500 (81.5267)  Acc@5: 100.0000 (99.0485)  time: 0.3442  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:22  Lr: 0.001875  Loss: 0.4745  Acc@1: 75.0000 (81.5206)  Acc@5: 100.0000 (99.0476)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: 0.3446  Acc@1: 81.2500 (81.5269)  Acc@5: 100.0000 (99.0503)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:15  Lr: 0.001875  Loss: 0.5894  Acc@1: 81.2500 (81.5226)  Acc@5: 100.0000 (99.0530)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: 0.2619  Acc@1: 81.2500 (81.5130)  Acc@5: 100.0000 (99.0504)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:08  Lr: 0.001875  Loss: 0.1958  Acc@1: 81.2500 (81.5105)  Acc@5: 100.0000 (99.0496)  time: 0.3462  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: 0.7313  Acc@1: 81.2500 (81.5098)  Acc@5: 100.0000 (99.0505)  time: 0.3455  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: 0.3641  Acc@1: 81.2500 (81.5073)  Acc@5: 100.0000 (99.0479)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:58  Lr: 0.001875  Loss: 1.1204  Acc@1: 81.2500 (81.4926)  Acc@5: 100.0000 (99.0488)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: 0.5500  Acc@1: 81.2500 (81.5093)  Acc@5: 100.0000 (99.0514)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3028  Acc@1: 81.2500 (81.5034)  Acc@5: 100.0000 (99.0523)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: 0.8413  Acc@1: 81.2500 (81.4958)  Acc@5: 100.0000 (99.0532)  time: 0.3455  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:44  Lr: 0.001875  Loss: 0.7566  Acc@1: 81.2500 (81.4727)  Acc@5: 100.0000 (99.0541)  time: 0.3450  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: 0.5798  Acc@1: 75.0000 (81.4755)  Acc@5: 100.0000 (99.0533)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:37  Lr: 0.001875  Loss: 0.5754  Acc@1: 81.2500 (81.4835)  Acc@5: 100.0000 (99.0559)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3970  Acc@1: 87.5000 (81.4862)  Acc@5: 100.0000 (99.0585)  time: 0.3448  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: 0.3796  Acc@1: 81.2500 (81.4805)  Acc@5: 100.0000 (99.0559)  time: 0.3464  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.8339  Acc@1: 81.2500 (81.4884)  Acc@5: 100.0000 (99.0585)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: 0.4564  Acc@1: 87.5000 (81.4877)  Acc@5: 100.0000 (99.0560)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: 1.0481  Acc@1: 87.5000 (81.4904)  Acc@5: 100.0000 (99.0568)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: 0.8991  Acc@1: 81.2500 (81.4864)  Acc@5: 100.0000 (99.0577)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: 0.8033  Acc@1: 75.0000 (81.4757)  Acc@5: 100.0000 (99.0535)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: 0.5537  Acc@1: 81.2500 (81.4852)  Acc@5: 100.0000 (99.0544)  time: 0.3451  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: 0.7401  Acc@1: 81.2500 (81.4761)  Acc@5: 100.0000 (99.0502)  time: 0.3453  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.4320  Acc@1: 81.2500 (81.4872)  Acc@5: 100.0000 (99.0527)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6174  Acc@1: 87.5000 (81.4933)  Acc@5: 100.0000 (99.0533)  time: 0.3466  data: 0.0016  max mem: 2503
Train: Epoch[5/5] Total time: 0:21:33 (0.3450 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.6174  Acc@1: 87.5000 (81.4933)  Acc@5: 100.0000 (99.0533)
Test: [Task 1]  [   0/1627]  eta: 0:16:15  Loss: 3.0090 (3.0090)  Acc@1: 50.0000 (50.0000)  Acc@5: 56.2500 (56.2500)  time: 0.5995  data: 0.3830  max mem: 2503
Test: [Task 1]  [  10/1627]  eta: 0:06:43  Loss: 2.9646 (2.8759)  Acc@1: 31.2500 (28.9773)  Acc@5: 56.2500 (52.2727)  time: 0.2495  data: 0.0350  max mem: 2503
Test: [Task 1]  [  20/1627]  eta: 0:06:14  Loss: 2.9588 (2.8559)  Acc@1: 31.2500 (30.9524)  Acc@5: 50.0000 (53.2738)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [  30/1627]  eta: 0:06:02  Loss: 2.8658 (2.9245)  Acc@1: 25.0000 (29.6371)  Acc@5: 50.0000 (51.0081)  time: 0.2149  data: 0.0003  max mem: 2503
Test: [Task 1]  [  40/1627]  eta: 0:05:55  Loss: 2.8658 (2.9223)  Acc@1: 25.0000 (29.7256)  Acc@5: 50.0000 (51.0671)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 1]  [  50/1627]  eta: 0:05:50  Loss: 2.8116 (2.9085)  Acc@1: 25.0000 (29.2892)  Acc@5: 50.0000 (50.8578)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 1]  [  60/1627]  eta: 0:05:46  Loss: 2.9149 (2.9229)  Acc@1: 25.0000 (28.2787)  Acc@5: 50.0000 (50.8197)  time: 0.2154  data: 0.0004  max mem: 2503
Test: [Task 1]  [  70/1627]  eta: 0:05:43  Loss: 2.9149 (2.9225)  Acc@1: 25.0000 (28.9613)  Acc@5: 50.0000 (50.7042)  time: 0.2155  data: 0.0004  max mem: 2503
Test: [Task 1]  [  80/1627]  eta: 0:05:40  Loss: 2.7726 (2.9132)  Acc@1: 25.0000 (28.7037)  Acc@5: 50.0000 (51.1574)  time: 0.2159  data: 0.0008  max mem: 2503
Test: [Task 1]  [  90/1627]  eta: 0:05:37  Loss: 2.7450 (2.9020)  Acc@1: 31.2500 (28.9148)  Acc@5: 56.2500 (51.7857)  time: 0.2154  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 100/1627]  eta: 0:05:34  Loss: 2.9289 (2.9094)  Acc@1: 31.2500 (29.0223)  Acc@5: 56.2500 (51.6708)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 110/1627]  eta: 0:05:31  Loss: 2.9806 (2.9183)  Acc@1: 25.0000 (28.8288)  Acc@5: 43.7500 (51.1261)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 120/1627]  eta: 0:05:28  Loss: 2.8205 (2.9158)  Acc@1: 25.0000 (28.7190)  Acc@5: 50.0000 (51.3946)  time: 0.2148  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 130/1627]  eta: 0:05:26  Loss: 2.8205 (2.9167)  Acc@1: 25.0000 (28.8168)  Acc@5: 50.0000 (51.3359)  time: 0.2149  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 140/1627]  eta: 0:05:23  Loss: 2.8158 (2.9113)  Acc@1: 31.2500 (29.0337)  Acc@5: 50.0000 (51.2855)  time: 0.2146  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 150/1627]  eta: 0:05:21  Loss: 2.7491 (2.9031)  Acc@1: 31.2500 (29.3046)  Acc@5: 50.0000 (51.3659)  time: 0.2150  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 160/1627]  eta: 0:05:18  Loss: 2.7491 (2.8985)  Acc@1: 31.2500 (29.3866)  Acc@5: 50.0000 (51.4752)  time: 0.2152  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 170/1627]  eta: 0:05:16  Loss: 2.7261 (2.8836)  Acc@1: 31.2500 (29.6784)  Acc@5: 56.2500 (51.8640)  time: 0.2154  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 180/1627]  eta: 0:05:14  Loss: 2.8569 (2.8907)  Acc@1: 31.2500 (29.4890)  Acc@5: 56.2500 (51.6229)  time: 0.2149  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 190/1627]  eta: 0:05:11  Loss: 2.8070 (2.8831)  Acc@1: 31.2500 (29.7448)  Acc@5: 56.2500 (51.7997)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 200/1627]  eta: 0:05:09  Loss: 2.8728 (2.8943)  Acc@1: 25.0000 (29.4465)  Acc@5: 56.2500 (51.2749)  time: 0.2149  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 210/1627]  eta: 0:05:07  Loss: 2.9901 (2.8916)  Acc@1: 25.0000 (29.5320)  Acc@5: 43.7500 (51.4218)  time: 0.2155  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 220/1627]  eta: 0:05:04  Loss: 2.9550 (2.9036)  Acc@1: 25.0000 (29.3269)  Acc@5: 43.7500 (51.1312)  time: 0.2150  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 230/1627]  eta: 0:05:02  Loss: 3.0620 (2.9086)  Acc@1: 25.0000 (29.1396)  Acc@5: 43.7500 (51.0552)  time: 0.2156  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 240/1627]  eta: 0:05:00  Loss: 2.8151 (2.9052)  Acc@1: 25.0000 (29.2531)  Acc@5: 50.0000 (51.0892)  time: 0.2156  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 250/1627]  eta: 0:04:58  Loss: 2.7593 (2.9062)  Acc@1: 25.0000 (29.2829)  Acc@5: 50.0000 (51.0458)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 260/1627]  eta: 0:04:55  Loss: 2.9099 (2.9050)  Acc@1: 31.2500 (29.4540)  Acc@5: 43.7500 (51.0536)  time: 0.2149  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 270/1627]  eta: 0:04:53  Loss: 2.6769 (2.8960)  Acc@1: 37.5000 (29.6125)  Acc@5: 50.0000 (51.2454)  time: 0.2150  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 280/1627]  eta: 0:04:51  Loss: 2.6738 (2.8917)  Acc@1: 37.5000 (29.8043)  Acc@5: 50.0000 (51.3345)  time: 0.2151  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 290/1627]  eta: 0:04:49  Loss: 2.6945 (2.8863)  Acc@1: 31.2500 (29.9399)  Acc@5: 56.2500 (51.4390)  time: 0.2151  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 300/1627]  eta: 0:04:46  Loss: 2.6945 (2.8801)  Acc@1: 31.2500 (30.1080)  Acc@5: 56.2500 (51.7027)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 310/1627]  eta: 0:04:44  Loss: 2.7180 (2.8791)  Acc@1: 31.2500 (30.0241)  Acc@5: 56.2500 (51.8690)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 320/1627]  eta: 0:04:42  Loss: 2.8719 (2.8824)  Acc@1: 25.0000 (29.9455)  Acc@5: 50.0000 (51.8692)  time: 0.2154  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 330/1627]  eta: 0:04:40  Loss: 2.9604 (2.8860)  Acc@1: 25.0000 (29.9094)  Acc@5: 50.0000 (51.7560)  time: 0.2155  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 340/1627]  eta: 0:04:38  Loss: 2.9895 (2.8918)  Acc@1: 25.0000 (29.8204)  Acc@5: 50.0000 (51.6312)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 350/1627]  eta: 0:04:35  Loss: 2.9895 (2.8946)  Acc@1: 25.0000 (29.7721)  Acc@5: 50.0000 (51.6916)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 360/1627]  eta: 0:04:33  Loss: 3.0059 (2.8937)  Acc@1: 25.0000 (29.7611)  Acc@5: 50.0000 (51.7832)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 2.7394 (2.8935)  Acc@1: 31.2500 (29.6327)  Acc@5: 50.0000 (51.8194)  time: 0.2147  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 380/1627]  eta: 0:04:29  Loss: 2.7984 (2.8966)  Acc@1: 25.0000 (29.5112)  Acc@5: 50.0000 (51.7881)  time: 0.2151  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 390/1627]  eta: 0:04:27  Loss: 2.9562 (2.8965)  Acc@1: 25.0000 (29.6355)  Acc@5: 56.2500 (51.8862)  time: 0.2157  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 400/1627]  eta: 0:04:24  Loss: 2.9562 (2.9005)  Acc@1: 31.2500 (29.5511)  Acc@5: 56.2500 (51.7612)  time: 0.2163  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 410/1627]  eta: 0:04:22  Loss: 2.9336 (2.9005)  Acc@1: 25.0000 (29.5012)  Acc@5: 50.0000 (51.7792)  time: 0.2158  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 420/1627]  eta: 0:04:20  Loss: 2.8223 (2.9001)  Acc@1: 25.0000 (29.5279)  Acc@5: 50.0000 (51.7518)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 430/1627]  eta: 0:04:18  Loss: 2.5973 (2.8940)  Acc@1: 37.5000 (29.7129)  Acc@5: 56.2500 (51.8852)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 440/1627]  eta: 0:04:16  Loss: 2.8214 (2.8974)  Acc@1: 31.2500 (29.6910)  Acc@5: 50.0000 (51.7715)  time: 0.2149  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 450/1627]  eta: 0:04:13  Loss: 3.1183 (2.9046)  Acc@1: 25.0000 (29.5177)  Acc@5: 50.0000 (51.6630)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 460/1627]  eta: 0:04:11  Loss: 3.0677 (2.9059)  Acc@1: 25.0000 (29.4469)  Acc@5: 50.0000 (51.5727)  time: 0.2151  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 470/1627]  eta: 0:04:09  Loss: 2.9749 (2.9066)  Acc@1: 25.0000 (29.4453)  Acc@5: 50.0000 (51.5393)  time: 0.2157  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 480/1627]  eta: 0:04:07  Loss: 3.0150 (2.9092)  Acc@1: 25.0000 (29.3139)  Acc@5: 43.7500 (51.4033)  time: 0.2152  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 2.9242 (2.9097)  Acc@1: 18.7500 (29.2770)  Acc@5: 50.0000 (51.4129)  time: 0.2155  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 2.9242 (2.9123)  Acc@1: 25.0000 (29.2540)  Acc@5: 50.0000 (51.3473)  time: 0.2153  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 510/1627]  eta: 0:04:00  Loss: 3.0311 (2.9114)  Acc@1: 25.0000 (29.2074)  Acc@5: 43.7500 (51.3943)  time: 0.2150  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 520/1627]  eta: 0:03:58  Loss: 2.9071 (2.9162)  Acc@1: 25.0000 (29.1627)  Acc@5: 43.7500 (51.2716)  time: 0.2146  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 530/1627]  eta: 0:03:56  Loss: 2.6172 (2.9070)  Acc@1: 31.2500 (29.3785)  Acc@5: 56.2500 (51.6125)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 2.4860 (2.9063)  Acc@1: 37.5000 (29.3900)  Acc@5: 62.5000 (51.6289)  time: 0.2144  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 2.8804 (2.9107)  Acc@1: 25.0000 (29.2763)  Acc@5: 50.0000 (51.4973)  time: 0.2146  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 3.1360 (2.9135)  Acc@1: 18.7500 (29.1555)  Acc@5: 43.7500 (51.5263)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 570/1627]  eta: 0:03:47  Loss: 2.9758 (2.9124)  Acc@1: 25.0000 (29.1703)  Acc@5: 50.0000 (51.5543)  time: 0.2142  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 580/1627]  eta: 0:03:45  Loss: 2.9448 (2.9150)  Acc@1: 25.0000 (29.0985)  Acc@5: 50.0000 (51.5706)  time: 0.2149  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 590/1627]  eta: 0:03:43  Loss: 2.9448 (2.9126)  Acc@1: 25.0000 (29.2407)  Acc@5: 50.0000 (51.6286)  time: 0.2146  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 2.7526 (2.9128)  Acc@1: 37.5000 (29.3469)  Acc@5: 56.2500 (51.6223)  time: 0.2137  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 2.7231 (2.9087)  Acc@1: 37.5000 (29.4804)  Acc@5: 56.2500 (51.7185)  time: 0.2138  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 2.7523 (2.9090)  Acc@1: 31.2500 (29.4384)  Acc@5: 56.2500 (51.7009)  time: 0.2155  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 630/1627]  eta: 0:03:34  Loss: 2.8162 (2.9070)  Acc@1: 31.2500 (29.4077)  Acc@5: 56.2500 (51.7631)  time: 0.2153  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 640/1627]  eta: 0:03:32  Loss: 2.6627 (2.9048)  Acc@1: 25.0000 (29.4169)  Acc@5: 56.2500 (51.8233)  time: 0.2142  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 650/1627]  eta: 0:03:30  Loss: 2.6873 (2.9037)  Acc@1: 25.0000 (29.3875)  Acc@5: 56.2500 (51.9201)  time: 0.2151  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 2.8381 (2.9019)  Acc@1: 25.0000 (29.3778)  Acc@5: 56.2500 (51.9856)  time: 0.2157  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 2.8564 (2.9025)  Acc@1: 25.0000 (29.3685)  Acc@5: 56.2500 (51.9467)  time: 0.2157  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 2.9007 (2.9004)  Acc@1: 31.2500 (29.4328)  Acc@5: 50.0000 (52.0283)  time: 0.2159  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 690/1627]  eta: 0:03:21  Loss: 2.8832 (2.9014)  Acc@1: 31.2500 (29.4591)  Acc@5: 50.0000 (51.9627)  time: 0.2157  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 700/1627]  eta: 0:03:19  Loss: 2.8832 (2.9016)  Acc@1: 25.0000 (29.4223)  Acc@5: 56.2500 (51.9882)  time: 0.2152  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 710/1627]  eta: 0:03:17  Loss: 2.6938 (2.8978)  Acc@1: 31.2500 (29.4831)  Acc@5: 56.2500 (52.0921)  time: 0.2155  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 2.7209 (2.8969)  Acc@1: 31.2500 (29.5076)  Acc@5: 56.2500 (52.1151)  time: 0.2167  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 2.8314 (2.8977)  Acc@1: 31.2500 (29.5058)  Acc@5: 50.0000 (52.1204)  time: 0.2170  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 2.8736 (2.8976)  Acc@1: 31.2500 (29.4872)  Acc@5: 50.0000 (52.1508)  time: 0.2156  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 2.8949 (2.8992)  Acc@1: 25.0000 (29.4358)  Acc@5: 50.0000 (52.1305)  time: 0.2153  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 760/1627]  eta: 0:03:06  Loss: 3.0596 (2.9011)  Acc@1: 25.0000 (29.4596)  Acc@5: 50.0000 (52.0943)  time: 0.2155  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 770/1627]  eta: 0:03:04  Loss: 2.7802 (2.9003)  Acc@1: 31.2500 (29.4747)  Acc@5: 56.2500 (52.1563)  time: 0.2148  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 780/1627]  eta: 0:03:02  Loss: 2.7802 (2.9011)  Acc@1: 31.2500 (29.4254)  Acc@5: 56.2500 (52.1607)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 2.9569 (2.9043)  Acc@1: 18.7500 (29.3458)  Acc@5: 50.0000 (52.0544)  time: 0.2153  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 3.1784 (2.9065)  Acc@1: 18.7500 (29.2993)  Acc@5: 43.7500 (51.9585)  time: 0.2153  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 3.0807 (2.9070)  Acc@1: 25.0000 (29.2694)  Acc@5: 43.7500 (51.9343)  time: 0.2144  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 820/1627]  eta: 0:02:53  Loss: 3.0127 (2.9086)  Acc@1: 31.2500 (29.2403)  Acc@5: 43.7500 (51.8499)  time: 0.2144  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 830/1627]  eta: 0:02:51  Loss: 2.9743 (2.9060)  Acc@1: 31.2500 (29.2795)  Acc@5: 50.0000 (51.9856)  time: 0.2148  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 2.4600 (2.9024)  Acc@1: 37.5000 (29.3549)  Acc@5: 56.2500 (52.0809)  time: 0.2156  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 2.8401 (2.9051)  Acc@1: 25.0000 (29.3111)  Acc@5: 50.0000 (51.9903)  time: 0.2154  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 2.9465 (2.9045)  Acc@1: 25.0000 (29.3264)  Acc@5: 50.0000 (51.9890)  time: 0.2168  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 2.7114 (2.9023)  Acc@1: 31.2500 (29.3628)  Acc@5: 56.2500 (52.0881)  time: 0.2172  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 880/1627]  eta: 0:02:40  Loss: 3.0413 (2.9056)  Acc@1: 25.0000 (29.2281)  Acc@5: 50.0000 (52.0077)  time: 0.2149  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 890/1627]  eta: 0:02:38  Loss: 3.1358 (2.9081)  Acc@1: 18.7500 (29.1877)  Acc@5: 43.7500 (51.9080)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 900/1627]  eta: 0:02:36  Loss: 2.9596 (2.9078)  Acc@1: 25.0000 (29.1829)  Acc@5: 50.0000 (51.9284)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 2.9624 (2.9095)  Acc@1: 25.0000 (29.1507)  Acc@5: 50.0000 (51.8524)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 2.8710 (2.9088)  Acc@1: 25.0000 (29.1531)  Acc@5: 50.0000 (51.9137)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 2.7687 (2.9068)  Acc@1: 31.2500 (29.2226)  Acc@5: 50.0000 (51.9603)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 940/1627]  eta: 0:02:27  Loss: 2.8100 (2.9075)  Acc@1: 31.2500 (29.1777)  Acc@5: 50.0000 (51.8996)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 950/1627]  eta: 0:02:25  Loss: 3.0027 (2.9076)  Acc@1: 25.0000 (29.1732)  Acc@5: 56.2500 (51.9387)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 960/1627]  eta: 0:02:23  Loss: 2.7943 (2.9059)  Acc@1: 31.2500 (29.2144)  Acc@5: 56.2500 (52.0031)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 2.5387 (2.9046)  Acc@1: 31.2500 (29.2482)  Acc@5: 62.5000 (52.0597)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 2.6591 (2.9024)  Acc@1: 37.5000 (29.3005)  Acc@5: 56.2500 (52.0961)  time: 0.2151  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 2.9679 (2.9053)  Acc@1: 25.0000 (29.2571)  Acc@5: 43.7500 (52.0434)  time: 0.2146  data: 0.0008  max mem: 2503
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 3.1857 (2.9066)  Acc@1: 25.0000 (29.2395)  Acc@5: 43.7500 (52.0105)  time: 0.2141  data: 0.0004  max mem: 2503
Test: [Task 1]  [1010/1627]  eta: 0:02:12  Loss: 2.7861 (2.9062)  Acc@1: 31.2500 (29.2409)  Acc@5: 50.0000 (51.9782)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 2.7910 (2.9055)  Acc@1: 31.2500 (29.2789)  Acc@5: 50.0000 (51.9956)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 2.7910 (2.9039)  Acc@1: 31.2500 (29.2980)  Acc@5: 56.2500 (52.0308)  time: 0.2149  data: 0.0005  max mem: 2503
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 2.7531 (2.9031)  Acc@1: 31.2500 (29.3408)  Acc@5: 56.2500 (52.0653)  time: 0.2143  data: 0.0004  max mem: 2503
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 2.7230 (2.9012)  Acc@1: 31.2500 (29.4006)  Acc@5: 56.2500 (52.1230)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 2.7230 (2.9013)  Acc@1: 31.2500 (29.3885)  Acc@5: 56.2500 (52.1206)  time: 0.2150  data: 0.0008  max mem: 2503
Test: [Task 1]  [1070/1627]  eta: 0:01:59  Loss: 2.8190 (2.9021)  Acc@1: 25.0000 (29.3651)  Acc@5: 50.0000 (52.1008)  time: 0.2143  data: 0.0007  max mem: 2503
Test: [Task 1]  [1080/1627]  eta: 0:01:57  Loss: 2.9170 (2.9031)  Acc@1: 25.0000 (29.3363)  Acc@5: 50.0000 (52.0756)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 2.9269 (2.9036)  Acc@1: 25.0000 (29.3194)  Acc@5: 43.7500 (52.0337)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 2.8478 (2.9027)  Acc@1: 25.0000 (29.3143)  Acc@5: 43.7500 (52.0947)  time: 0.2142  data: 0.0006  max mem: 2503
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 2.9531 (2.9043)  Acc@1: 18.7500 (29.2811)  Acc@5: 43.7500 (52.0196)  time: 0.2151  data: 0.0013  max mem: 2503
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 2.9531 (2.9024)  Acc@1: 25.0000 (29.3265)  Acc@5: 50.0000 (52.0796)  time: 0.2150  data: 0.0010  max mem: 2503
Test: [Task 1]  [1130/1627]  eta: 0:01:46  Loss: 2.8000 (2.9026)  Acc@1: 25.0000 (29.2827)  Acc@5: 50.0000 (52.0502)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1140/1627]  eta: 0:01:44  Loss: 2.9887 (2.9041)  Acc@1: 18.7500 (29.2397)  Acc@5: 50.0000 (52.0158)  time: 0.2140  data: 0.0002  max mem: 2503
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 3.0044 (2.9041)  Acc@1: 25.0000 (29.2246)  Acc@5: 50.0000 (52.0200)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 2.7167 (2.9031)  Acc@1: 25.0000 (29.2259)  Acc@5: 50.0000 (52.0403)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 2.8600 (2.9031)  Acc@1: 31.2500 (29.2325)  Acc@5: 50.0000 (51.9962)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 2.9200 (2.9038)  Acc@1: 31.2500 (29.2178)  Acc@5: 50.0000 (51.9898)  time: 0.2156  data: 0.0003  max mem: 2503
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 2.9771 (2.9034)  Acc@1: 31.2500 (29.2506)  Acc@5: 50.0000 (51.9941)  time: 0.2153  data: 0.0005  max mem: 2503
Test: [Task 1]  [1200/1627]  eta: 0:01:31  Loss: 2.8975 (2.9028)  Acc@1: 31.2500 (29.2621)  Acc@5: 56.2500 (52.0348)  time: 0.2148  data: 0.0007  max mem: 2503
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 2.8975 (2.9036)  Acc@1: 25.0000 (29.2114)  Acc@5: 50.0000 (51.9922)  time: 0.2165  data: 0.0010  max mem: 2503
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 2.9733 (2.9037)  Acc@1: 25.0000 (29.2127)  Acc@5: 50.0000 (51.9758)  time: 0.2163  data: 0.0007  max mem: 2503
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 2.9312 (2.9041)  Acc@1: 25.0000 (29.1887)  Acc@5: 50.0000 (51.9598)  time: 0.2156  data: 0.0003  max mem: 2503
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 2.7815 (2.9032)  Acc@1: 25.0000 (29.2103)  Acc@5: 56.2500 (52.0195)  time: 0.2154  data: 0.0005  max mem: 2503
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 2.9517 (2.9040)  Acc@1: 18.7500 (29.1567)  Acc@5: 50.0000 (52.0084)  time: 0.2142  data: 0.0005  max mem: 2503
Test: [Task 1]  [1260/1627]  eta: 0:01:18  Loss: 2.9517 (2.9036)  Acc@1: 25.0000 (29.1683)  Acc@5: 50.0000 (51.9776)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 1]  [1270/1627]  eta: 0:01:16  Loss: 2.8154 (2.9037)  Acc@1: 31.2500 (29.1896)  Acc@5: 50.0000 (51.9817)  time: 0.2144  data: 0.0004  max mem: 2503
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 2.8945 (2.9026)  Acc@1: 31.2500 (29.2106)  Acc@5: 50.0000 (52.0199)  time: 0.2153  data: 0.0010  max mem: 2503
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 2.7236 (2.9018)  Acc@1: 31.2500 (29.2167)  Acc@5: 56.2500 (52.0285)  time: 0.2152  data: 0.0012  max mem: 2503
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 2.7340 (2.9017)  Acc@1: 31.2500 (29.2419)  Acc@5: 50.0000 (52.0129)  time: 0.2146  data: 0.0007  max mem: 2503
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 2.7603 (2.9014)  Acc@1: 31.2500 (29.2525)  Acc@5: 50.0000 (52.0118)  time: 0.2151  data: 0.0003  max mem: 2503
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 2.7188 (2.8989)  Acc@1: 37.5000 (29.3291)  Acc@5: 56.2500 (52.0581)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [1330/1627]  eta: 0:01:03  Loss: 2.8345 (2.9009)  Acc@1: 31.2500 (29.2778)  Acc@5: 50.0000 (52.0098)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 3.0650 (2.9014)  Acc@1: 25.0000 (29.2739)  Acc@5: 43.7500 (51.9761)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 2.9901 (2.9020)  Acc@1: 25.0000 (29.2469)  Acc@5: 43.7500 (51.9800)  time: 0.2141  data: 0.0002  max mem: 2503
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 2.8235 (2.9016)  Acc@1: 25.0000 (29.2662)  Acc@5: 50.0000 (51.9655)  time: 0.2141  data: 0.0005  max mem: 2503
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 2.7272 (2.9013)  Acc@1: 31.2500 (29.2943)  Acc@5: 50.0000 (51.9466)  time: 0.2143  data: 0.0005  max mem: 2503
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 2.7215 (2.9002)  Acc@1: 31.2500 (29.3447)  Acc@5: 56.2500 (51.9777)  time: 0.2156  data: 0.0010  max mem: 2503
Test: [Task 1]  [1390/1627]  eta: 0:00:50  Loss: 2.5871 (2.8988)  Acc@1: 31.2500 (29.3853)  Acc@5: 56.2500 (51.9995)  time: 0.2156  data: 0.0011  max mem: 2503
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 2.9412 (2.9002)  Acc@1: 31.2500 (29.3406)  Acc@5: 50.0000 (51.9584)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 2.8097 (2.8986)  Acc@1: 31.2500 (29.3808)  Acc@5: 50.0000 (52.0110)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 2.7483 (2.8979)  Acc@1: 31.2500 (29.4027)  Acc@5: 56.2500 (52.0232)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 2.8386 (2.8990)  Acc@1: 25.0000 (29.3894)  Acc@5: 50.0000 (51.9960)  time: 0.2156  data: 0.0012  max mem: 2503
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 2.7520 (2.8972)  Acc@1: 31.2500 (29.4197)  Acc@5: 56.2500 (52.0515)  time: 0.2160  data: 0.0013  max mem: 2503
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 2.8680 (2.8981)  Acc@1: 31.2500 (29.3935)  Acc@5: 56.2500 (52.0072)  time: 0.2145  data: 0.0004  max mem: 2503
Test: [Task 1]  [1460/1627]  eta: 0:00:35  Loss: 2.9541 (2.8983)  Acc@1: 25.0000 (29.3934)  Acc@5: 50.0000 (52.0106)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 2.9805 (2.8988)  Acc@1: 31.2500 (29.4188)  Acc@5: 50.0000 (52.0012)  time: 0.2150  data: 0.0003  max mem: 2503
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 2.9451 (2.8991)  Acc@1: 31.2500 (29.4227)  Acc@5: 50.0000 (52.0172)  time: 0.2157  data: 0.0002  max mem: 2503
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 2.8792 (2.8987)  Acc@1: 31.2500 (29.4266)  Acc@5: 50.0000 (52.0288)  time: 0.2149  data: 0.0002  max mem: 2503
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.8840 (2.8995)  Acc@1: 25.0000 (29.4137)  Acc@5: 50.0000 (52.0195)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 2.9818 (2.9001)  Acc@1: 25.0000 (29.3804)  Acc@5: 56.2500 (52.0268)  time: 0.2147  data: 0.0005  max mem: 2503
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 2.8914 (2.8991)  Acc@1: 25.0000 (29.3886)  Acc@5: 62.5000 (52.0751)  time: 0.2144  data: 0.0004  max mem: 2503
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 2.7559 (2.8993)  Acc@1: 25.0000 (29.3721)  Acc@5: 56.2500 (52.0738)  time: 0.2162  data: 0.0021  max mem: 2503
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 2.8175 (2.8984)  Acc@1: 25.0000 (29.4006)  Acc@5: 50.0000 (52.0847)  time: 0.2161  data: 0.0021  max mem: 2503
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.7142 (2.8974)  Acc@1: 31.2500 (29.4084)  Acc@5: 56.2500 (52.1236)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.6666 (2.8952)  Acc@1: 37.5000 (29.4763)  Acc@5: 56.2500 (52.1941)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.7948 (2.8960)  Acc@1: 37.5000 (29.4438)  Acc@5: 56.2500 (52.2000)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.8203 (2.8950)  Acc@1: 25.0000 (29.4711)  Acc@5: 56.2500 (52.2256)  time: 0.2148  data: 0.0004  max mem: 2503
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 2.9539 (2.8963)  Acc@1: 25.0000 (29.4430)  Acc@5: 50.0000 (52.1881)  time: 0.2153  data: 0.0011  max mem: 2503
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 3.0488 (2.8968)  Acc@1: 25.0000 (29.4152)  Acc@5: 43.7500 (52.1666)  time: 0.2148  data: 0.0010  max mem: 2503
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.9982 (2.8961)  Acc@1: 25.0000 (29.4576)  Acc@5: 50.0000 (52.1958)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 3.0010 (2.8962)  Acc@1: 31.2500 (29.4610)  Acc@5: 50.0000 (52.1900)  time: 0.2154  data: 0.0006  max mem: 2503
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.6765 (2.8951)  Acc@1: 37.5000 (29.4868)  Acc@5: 50.0000 (52.2011)  time: 0.2153  data: 0.0006  max mem: 2503
Test: [Task 1] Total time: 0:05:50 (0.2153 s / it)
* Acc@1 29.487 Acc@5 52.201 loss 2.895
Test: [Task 2]  [  0/625]  eta: 0:06:17  Loss: 0.8135 (0.8135)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6042  data: 0.3857  max mem: 2503
Test: [Task 2]  [ 10/625]  eta: 0:02:33  Loss: 0.9601 (1.0728)  Acc@1: 68.7500 (65.3409)  Acc@5: 93.7500 (94.8864)  time: 0.2498  data: 0.0353  max mem: 2503
Test: [Task 2]  [ 20/625]  eta: 0:02:21  Loss: 0.9477 (1.0387)  Acc@1: 62.5000 (65.1786)  Acc@5: 100.0000 (95.5357)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 2]  [ 30/625]  eta: 0:02:15  Loss: 0.9635 (1.0771)  Acc@1: 62.5000 (65.1210)  Acc@5: 93.7500 (94.7581)  time: 0.2150  data: 0.0005  max mem: 2503
Test: [Task 2]  [ 40/625]  eta: 0:02:11  Loss: 1.1538 (1.0949)  Acc@1: 62.5000 (64.1768)  Acc@5: 93.7500 (94.5122)  time: 0.2154  data: 0.0007  max mem: 2503
Test: [Task 2]  [ 50/625]  eta: 0:02:07  Loss: 1.1538 (1.1057)  Acc@1: 62.5000 (63.7255)  Acc@5: 93.7500 (94.3627)  time: 0.2150  data: 0.0007  max mem: 2503
Test: [Task 2]  [ 60/625]  eta: 0:02:05  Loss: 1.1759 (1.1078)  Acc@1: 62.5000 (63.0123)  Acc@5: 93.7500 (94.2623)  time: 0.2153  data: 0.0005  max mem: 2503
Test: [Task 2]  [ 70/625]  eta: 0:02:02  Loss: 1.0929 (1.1119)  Acc@1: 62.5000 (62.8521)  Acc@5: 93.7500 (94.4542)  time: 0.2146  data: 0.0002  max mem: 2503
Test: [Task 2]  [ 80/625]  eta: 0:01:59  Loss: 1.1184 (1.1194)  Acc@1: 62.5000 (62.5772)  Acc@5: 93.7500 (94.4444)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 2]  [ 90/625]  eta: 0:01:57  Loss: 1.0839 (1.1195)  Acc@1: 56.2500 (62.1566)  Acc@5: 93.7500 (94.4368)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 2]  [100/625]  eta: 0:01:54  Loss: 1.0839 (1.1291)  Acc@1: 56.2500 (61.2624)  Acc@5: 93.7500 (94.3069)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 2]  [110/625]  eta: 0:01:52  Loss: 1.1222 (1.1267)  Acc@1: 56.2500 (61.2050)  Acc@5: 93.7500 (94.4820)  time: 0.2147  data: 0.0007  max mem: 2503
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 1.1222 (1.1256)  Acc@1: 62.5000 (61.3120)  Acc@5: 93.7500 (94.5248)  time: 0.2159  data: 0.0008  max mem: 2503
Test: [Task 2]  [130/625]  eta: 0:01:47  Loss: 1.1523 (1.1347)  Acc@1: 62.5000 (61.3550)  Acc@5: 93.7500 (94.6088)  time: 0.2161  data: 0.0008  max mem: 2503
Test: [Task 2]  [140/625]  eta: 0:01:45  Loss: 1.1521 (1.1375)  Acc@1: 62.5000 (61.3475)  Acc@5: 93.7500 (94.4592)  time: 0.2150  data: 0.0007  max mem: 2503
Test: [Task 2]  [150/625]  eta: 0:01:43  Loss: 1.1188 (1.1394)  Acc@1: 62.5000 (61.3411)  Acc@5: 93.7500 (94.4950)  time: 0.2147  data: 0.0007  max mem: 2503
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 1.0755 (1.1439)  Acc@1: 62.5000 (61.1413)  Acc@5: 93.7500 (94.4876)  time: 0.2155  data: 0.0007  max mem: 2503
Test: [Task 2]  [170/625]  eta: 0:01:38  Loss: 1.0981 (1.1423)  Acc@1: 62.5000 (61.2208)  Acc@5: 93.7500 (94.4444)  time: 0.2154  data: 0.0003  max mem: 2503
Test: [Task 2]  [180/625]  eta: 0:01:36  Loss: 1.1205 (1.1441)  Acc@1: 62.5000 (61.2569)  Acc@5: 93.7500 (94.4751)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 1.1205 (1.1484)  Acc@1: 56.2500 (60.9948)  Acc@5: 93.7500 (94.4372)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 1.2526 (1.1553)  Acc@1: 56.2500 (60.7587)  Acc@5: 93.7500 (94.4652)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 2]  [210/625]  eta: 0:01:29  Loss: 1.1492 (1.1516)  Acc@1: 56.2500 (60.9301)  Acc@5: 93.7500 (94.4905)  time: 0.2150  data: 0.0003  max mem: 2503
Test: [Task 2]  [220/625]  eta: 0:01:27  Loss: 1.1195 (1.1466)  Acc@1: 62.5000 (61.1425)  Acc@5: 93.7500 (94.5984)  time: 0.2147  data: 0.0007  max mem: 2503
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 1.0059 (1.1464)  Acc@1: 62.5000 (61.0931)  Acc@5: 100.0000 (94.6429)  time: 0.2151  data: 0.0007  max mem: 2503
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 1.1386 (1.1470)  Acc@1: 56.2500 (61.0218)  Acc@5: 100.0000 (94.6836)  time: 0.2146  data: 0.0002  max mem: 2503
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 1.1386 (1.1446)  Acc@1: 62.5000 (61.2301)  Acc@5: 93.7500 (94.5717)  time: 0.2144  data: 0.0002  max mem: 2503
Test: [Task 2]  [260/625]  eta: 0:01:18  Loss: 1.0453 (1.1391)  Acc@1: 62.5000 (61.3027)  Acc@5: 93.7500 (94.5642)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 2]  [270/625]  eta: 0:01:16  Loss: 1.0303 (1.1404)  Acc@1: 62.5000 (61.5314)  Acc@5: 93.7500 (94.5341)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 1.1946 (1.1432)  Acc@1: 56.2500 (61.4324)  Acc@5: 93.7500 (94.4840)  time: 0.2152  data: 0.0008  max mem: 2503
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 1.1050 (1.1428)  Acc@1: 62.5000 (61.5120)  Acc@5: 93.7500 (94.3514)  time: 0.2154  data: 0.0008  max mem: 2503
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.9648 (1.1455)  Acc@1: 62.5000 (61.3787)  Acc@5: 93.7500 (94.3314)  time: 0.2158  data: 0.0013  max mem: 2503
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 1.3594 (1.1472)  Acc@1: 56.2500 (61.3143)  Acc@5: 93.7500 (94.2725)  time: 0.2157  data: 0.0013  max mem: 2503
Test: [Task 2]  [320/625]  eta: 0:01:05  Loss: 0.9493 (1.1375)  Acc@1: 62.5000 (61.4681)  Acc@5: 100.0000 (94.4120)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 0.9074 (1.1341)  Acc@1: 62.5000 (61.4992)  Acc@5: 100.0000 (94.5619)  time: 0.2139  data: 0.0002  max mem: 2503
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.7737 (1.1193)  Acc@1: 68.7500 (62.0601)  Acc@5: 100.0000 (94.6848)  time: 0.2147  data: 0.0002  max mem: 2503
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.6923 (1.1097)  Acc@1: 81.2500 (62.3219)  Acc@5: 100.0000 (94.8184)  time: 0.2159  data: 0.0003  max mem: 2503
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.9093 (1.1101)  Acc@1: 62.5000 (62.3442)  Acc@5: 100.0000 (94.8580)  time: 0.2157  data: 0.0005  max mem: 2503
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.9030 (1.1021)  Acc@1: 62.5000 (62.5337)  Acc@5: 100.0000 (94.9629)  time: 0.2161  data: 0.0009  max mem: 2503
Test: [Task 2]  [380/625]  eta: 0:00:52  Loss: 0.9688 (1.1034)  Acc@1: 68.7500 (62.5984)  Acc@5: 93.7500 (94.8655)  time: 0.2160  data: 0.0007  max mem: 2503
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 0.9637 (1.0961)  Acc@1: 68.7500 (62.8197)  Acc@5: 93.7500 (94.9329)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.7988 (1.0871)  Acc@1: 68.7500 (63.1390)  Acc@5: 100.0000 (95.0125)  time: 0.2145  data: 0.0004  max mem: 2503
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.7348 (1.0857)  Acc@1: 75.0000 (63.1843)  Acc@5: 100.0000 (95.0578)  time: 0.2152  data: 0.0007  max mem: 2503
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 1.1670 (1.0917)  Acc@1: 56.2500 (62.9602)  Acc@5: 100.0000 (95.1010)  time: 0.2149  data: 0.0006  max mem: 2503
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 1.1776 (1.0887)  Acc@1: 56.2500 (63.1090)  Acc@5: 100.0000 (95.1856)  time: 0.2139  data: 0.0002  max mem: 2503
Test: [Task 2]  [440/625]  eta: 0:00:39  Loss: 0.6608 (1.0803)  Acc@1: 68.7500 (63.2937)  Acc@5: 100.0000 (95.2664)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.6904 (1.0739)  Acc@1: 68.7500 (63.4562)  Acc@5: 100.0000 (95.3437)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.6854 (1.0667)  Acc@1: 68.7500 (63.6795)  Acc@5: 100.0000 (95.4176)  time: 0.2148  data: 0.0004  max mem: 2503
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.8595 (1.0656)  Acc@1: 68.7500 (63.6810)  Acc@5: 100.0000 (95.4883)  time: 0.2152  data: 0.0011  max mem: 2503
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.8863 (1.0660)  Acc@1: 62.5000 (63.6305)  Acc@5: 100.0000 (95.5042)  time: 0.2153  data: 0.0012  max mem: 2503
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.8582 (1.0599)  Acc@1: 62.5000 (63.9002)  Acc@5: 100.0000 (95.5321)  time: 0.2146  data: 0.0006  max mem: 2503
Test: [Task 2]  [500/625]  eta: 0:00:26  Loss: 0.7679 (1.0556)  Acc@1: 81.2500 (64.1218)  Acc@5: 100.0000 (95.6088)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.9588 (1.0553)  Acc@1: 62.5000 (64.1145)  Acc@5: 100.0000 (95.6703)  time: 0.2155  data: 0.0004  max mem: 2503
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 1.2421 (1.0649)  Acc@1: 56.2500 (63.7236)  Acc@5: 100.0000 (95.6574)  time: 0.2160  data: 0.0004  max mem: 2503
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 1.1831 (1.0643)  Acc@1: 50.0000 (63.6535)  Acc@5: 100.0000 (95.7156)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.9123 (1.0606)  Acc@1: 68.7500 (63.7015)  Acc@5: 100.0000 (95.7602)  time: 0.2155  data: 0.0014  max mem: 2503
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.6892 (1.0518)  Acc@1: 68.7500 (64.0086)  Acc@5: 100.0000 (95.8258)  time: 0.2165  data: 0.0015  max mem: 2503
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.6195 (1.0446)  Acc@1: 81.2500 (64.2714)  Acc@5: 100.0000 (95.8890)  time: 0.2150  data: 0.0003  max mem: 2503
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.7638 (1.0456)  Acc@1: 75.0000 (64.2842)  Acc@5: 100.0000 (95.8954)  time: 0.2156  data: 0.0004  max mem: 2503
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.7877 (1.0395)  Acc@1: 68.7500 (64.5331)  Acc@5: 100.0000 (95.9337)  time: 0.2170  data: 0.0007  max mem: 2503
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.7556 (1.0356)  Acc@1: 75.0000 (64.7314)  Acc@5: 100.0000 (95.9285)  time: 0.2153  data: 0.0006  max mem: 2503
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.0825 (1.0390)  Acc@1: 62.5000 (64.5175)  Acc@5: 93.7500 (95.9131)  time: 0.2155  data: 0.0008  max mem: 2503
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 1.3834 (1.0491)  Acc@1: 50.0000 (64.2390)  Acc@5: 93.7500 (95.8265)  time: 0.2169  data: 0.0016  max mem: 2503
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 1.1663 (1.0494)  Acc@1: 56.2500 (64.2411)  Acc@5: 93.7500 (95.8434)  time: 0.2155  data: 0.0011  max mem: 2503
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.0134 (1.0491)  Acc@1: 62.5000 (64.2800)  Acc@5: 93.7500 (95.8200)  time: 0.2157  data: 0.0011  max mem: 2503
Test: [Task 2] Total time: 0:02:14 (0.2160 s / it)
* Acc@1 64.280 Acc@5 95.820 loss 1.049
Test: [Task 3]  [  0/625]  eta: 0:05:32  Loss: 0.2055 (0.2055)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5316  data: 0.3155  max mem: 2503
Test: [Task 3]  [ 10/625]  eta: 0:02:29  Loss: 0.3003 (0.3567)  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (98.2955)  time: 0.2433  data: 0.0289  max mem: 2503
Test: [Task 3]  [ 20/625]  eta: 0:02:18  Loss: 0.4035 (0.4295)  Acc@1: 93.7500 (92.5595)  Acc@5: 100.0000 (96.7262)  time: 0.2144  data: 0.0005  max mem: 2503
Test: [Task 3]  [ 30/625]  eta: 0:02:13  Loss: 0.3381 (0.3794)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (97.7823)  time: 0.2150  data: 0.0005  max mem: 2503
Test: [Task 3]  [ 40/625]  eta: 0:02:10  Loss: 0.2296 (0.3532)  Acc@1: 93.7500 (94.0549)  Acc@5: 100.0000 (98.1707)  time: 0.2156  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 50/625]  eta: 0:02:07  Loss: 0.2369 (0.3514)  Acc@1: 93.7500 (94.3627)  Acc@5: 100.0000 (98.0392)  time: 0.2150  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 60/625]  eta: 0:02:04  Loss: 0.3303 (0.3496)  Acc@1: 93.7500 (94.3648)  Acc@5: 100.0000 (97.9508)  time: 0.2153  data: 0.0010  max mem: 2503
Test: [Task 3]  [ 70/625]  eta: 0:02:01  Loss: 0.2752 (0.3363)  Acc@1: 93.7500 (94.6303)  Acc@5: 100.0000 (98.0634)  time: 0.2155  data: 0.0010  max mem: 2503
Test: [Task 3]  [ 80/625]  eta: 0:01:59  Loss: 0.3057 (0.3455)  Acc@1: 93.7500 (94.2901)  Acc@5: 100.0000 (98.0710)  time: 0.2153  data: 0.0010  max mem: 2503
Test: [Task 3]  [ 90/625]  eta: 0:01:56  Loss: 0.3020 (0.3440)  Acc@1: 93.7500 (94.3681)  Acc@5: 100.0000 (98.0769)  time: 0.2152  data: 0.0010  max mem: 2503
Test: [Task 3]  [100/625]  eta: 0:01:54  Loss: 0.2559 (0.3396)  Acc@1: 93.7500 (94.4926)  Acc@5: 100.0000 (98.1436)  time: 0.2156  data: 0.0005  max mem: 2503
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 0.2546 (0.3362)  Acc@1: 100.0000 (94.5946)  Acc@5: 100.0000 (98.2545)  time: 0.2155  data: 0.0004  max mem: 2503
Test: [Task 3]  [120/625]  eta: 0:01:50  Loss: 0.2585 (0.3388)  Acc@1: 100.0000 (94.5248)  Acc@5: 100.0000 (98.2438)  time: 0.2154  data: 0.0003  max mem: 2503
Test: [Task 3]  [130/625]  eta: 0:01:47  Loss: 0.2587 (0.3381)  Acc@1: 93.7500 (94.5611)  Acc@5: 100.0000 (98.2824)  time: 0.2158  data: 0.0004  max mem: 2503
Test: [Task 3]  [140/625]  eta: 0:01:45  Loss: 0.2592 (0.3458)  Acc@1: 93.7500 (94.2376)  Acc@5: 100.0000 (98.1383)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 0.4079 (0.3524)  Acc@1: 87.5000 (94.0397)  Acc@5: 100.0000 (98.1374)  time: 0.2148  data: 0.0005  max mem: 2503
Test: [Task 3]  [160/625]  eta: 0:01:41  Loss: 0.3596 (0.3566)  Acc@1: 93.7500 (93.8665)  Acc@5: 100.0000 (98.0978)  time: 0.2169  data: 0.0016  max mem: 2503
Test: [Task 3]  [170/625]  eta: 0:01:38  Loss: 0.3255 (0.3590)  Acc@1: 93.7500 (93.8231)  Acc@5: 100.0000 (98.1360)  time: 0.2165  data: 0.0014  max mem: 2503
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.4247 (0.3614)  Acc@1: 87.5000 (93.6809)  Acc@5: 100.0000 (98.1354)  time: 0.2145  data: 0.0002  max mem: 2503
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.3757 (0.3603)  Acc@1: 93.7500 (93.6846)  Acc@5: 100.0000 (98.2003)  time: 0.2166  data: 0.0017  max mem: 2503
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 0.3202 (0.3619)  Acc@1: 93.7500 (93.6256)  Acc@5: 100.0000 (98.2276)  time: 0.2168  data: 0.0018  max mem: 2503
Test: [Task 3]  [210/625]  eta: 0:01:30  Loss: 0.2821 (0.3604)  Acc@1: 100.0000 (93.7204)  Acc@5: 100.0000 (98.2524)  time: 0.2156  data: 0.0003  max mem: 2503
Test: [Task 3]  [220/625]  eta: 0:01:27  Loss: 0.2857 (0.3628)  Acc@1: 93.7500 (93.6652)  Acc@5: 100.0000 (98.1335)  time: 0.2151  data: 0.0003  max mem: 2503
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.3895 (0.3638)  Acc@1: 93.7500 (93.5877)  Acc@5: 100.0000 (98.1331)  time: 0.2151  data: 0.0004  max mem: 2503
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.3356 (0.3666)  Acc@1: 93.7500 (93.5685)  Acc@5: 100.0000 (98.0809)  time: 0.2162  data: 0.0008  max mem: 2503
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.2844 (0.3668)  Acc@1: 93.7500 (93.5757)  Acc@5: 100.0000 (98.1076)  time: 0.2149  data: 0.0007  max mem: 2503
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.2669 (0.3670)  Acc@1: 93.7500 (93.5584)  Acc@5: 100.0000 (98.0843)  time: 0.2149  data: 0.0011  max mem: 2503
Test: [Task 3]  [270/625]  eta: 0:01:16  Loss: 0.3004 (0.3671)  Acc@1: 93.7500 (93.4963)  Acc@5: 100.0000 (98.0397)  time: 0.2155  data: 0.0011  max mem: 2503
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 0.3378 (0.3678)  Acc@1: 93.7500 (93.4609)  Acc@5: 100.0000 (98.0427)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.3559 (0.3683)  Acc@1: 93.7500 (93.4278)  Acc@5: 100.0000 (98.0455)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.3450 (0.3694)  Acc@1: 93.7500 (93.3347)  Acc@5: 100.0000 (98.0066)  time: 0.2149  data: 0.0011  max mem: 2503
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.3140 (0.3699)  Acc@1: 93.7500 (93.3481)  Acc@5: 100.0000 (98.0105)  time: 0.2164  data: 0.0022  max mem: 2503
Test: [Task 3]  [320/625]  eta: 0:01:05  Loss: 0.2400 (0.3668)  Acc@1: 93.7500 (93.3995)  Acc@5: 100.0000 (98.0530)  time: 0.2157  data: 0.0014  max mem: 2503
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 0.2759 (0.3677)  Acc@1: 93.7500 (93.3535)  Acc@5: 100.0000 (98.0551)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.2853 (0.3653)  Acc@1: 93.7500 (93.3834)  Acc@5: 100.0000 (98.0755)  time: 0.2154  data: 0.0011  max mem: 2503
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.2817 (0.3654)  Acc@1: 93.7500 (93.3405)  Acc@5: 100.0000 (98.0947)  time: 0.2155  data: 0.0014  max mem: 2503
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.3313 (0.3664)  Acc@1: 93.7500 (93.3345)  Acc@5: 100.0000 (98.0956)  time: 0.2153  data: 0.0008  max mem: 2503
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.3313 (0.3676)  Acc@1: 93.7500 (93.2951)  Acc@5: 100.0000 (98.0458)  time: 0.2154  data: 0.0011  max mem: 2503
Test: [Task 3]  [380/625]  eta: 0:00:52  Loss: 0.3414 (0.3683)  Acc@1: 93.7500 (93.2743)  Acc@5: 100.0000 (98.0479)  time: 0.2145  data: 0.0009  max mem: 2503
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.3137 (0.3672)  Acc@1: 93.7500 (93.3344)  Acc@5: 100.0000 (98.0499)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.2595 (0.3652)  Acc@1: 93.7500 (93.3759)  Acc@5: 100.0000 (98.0673)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.3518 (0.3665)  Acc@1: 93.7500 (93.3698)  Acc@5: 100.0000 (98.0535)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.3925 (0.3661)  Acc@1: 93.7500 (93.3195)  Acc@5: 100.0000 (98.0701)  time: 0.2145  data: 0.0005  max mem: 2503
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.3115 (0.3653)  Acc@1: 93.7500 (93.3150)  Acc@5: 100.0000 (98.0713)  time: 0.2150  data: 0.0005  max mem: 2503
Test: [Task 3]  [440/625]  eta: 0:00:39  Loss: 0.3342 (0.3657)  Acc@1: 93.7500 (93.3248)  Acc@5: 100.0000 (98.0584)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.2384 (0.3651)  Acc@1: 93.7500 (93.3204)  Acc@5: 100.0000 (98.0737)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.2235 (0.3619)  Acc@1: 93.7500 (93.3975)  Acc@5: 100.0000 (98.1020)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.2576 (0.3622)  Acc@1: 93.7500 (93.4183)  Acc@5: 100.0000 (98.1024)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.3785 (0.3637)  Acc@1: 93.7500 (93.3992)  Acc@5: 100.0000 (98.0639)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.3895 (0.3637)  Acc@1: 93.7500 (93.3809)  Acc@5: 100.0000 (98.0652)  time: 0.2141  data: 0.0002  max mem: 2503
Test: [Task 3]  [500/625]  eta: 0:00:26  Loss: 0.3374 (0.3626)  Acc@1: 93.7500 (93.3757)  Acc@5: 100.0000 (98.0788)  time: 0.2142  data: 0.0002  max mem: 2503
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.2398 (0.3619)  Acc@1: 93.7500 (93.3953)  Acc@5: 100.0000 (98.1042)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.3546 (0.3648)  Acc@1: 93.7500 (93.3301)  Acc@5: 100.0000 (98.0806)  time: 0.2141  data: 0.0004  max mem: 2503
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.3725 (0.3655)  Acc@1: 93.7500 (93.3145)  Acc@5: 100.0000 (98.0932)  time: 0.2144  data: 0.0004  max mem: 2503
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.4342 (0.3674)  Acc@1: 93.7500 (93.2763)  Acc@5: 100.0000 (98.0707)  time: 0.2146  data: 0.0004  max mem: 2503
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.4342 (0.3689)  Acc@1: 93.7500 (93.2509)  Acc@5: 93.7500 (98.0263)  time: 0.2147  data: 0.0004  max mem: 2503
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.3960 (0.3691)  Acc@1: 93.7500 (93.2821)  Acc@5: 100.0000 (98.0169)  time: 0.2148  data: 0.0006  max mem: 2503
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.2712 (0.3680)  Acc@1: 93.7500 (93.3231)  Acc@5: 100.0000 (98.0407)  time: 0.2148  data: 0.0006  max mem: 2503
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.3496 (0.3703)  Acc@1: 93.7500 (93.2552)  Acc@5: 100.0000 (98.0207)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.3698 (0.3700)  Acc@1: 93.7500 (93.2635)  Acc@5: 100.0000 (98.0330)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.2458 (0.3686)  Acc@1: 93.7500 (93.3028)  Acc@5: 100.0000 (98.0449)  time: 0.2154  data: 0.0007  max mem: 2503
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.3088 (0.3684)  Acc@1: 93.7500 (93.2999)  Acc@5: 100.0000 (98.0462)  time: 0.2157  data: 0.0007  max mem: 2503
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.3581 (0.3707)  Acc@1: 93.7500 (93.2166)  Acc@5: 100.0000 (98.0274)  time: 0.2160  data: 0.0013  max mem: 2503
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.3126 (0.3697)  Acc@1: 93.7500 (93.2400)  Acc@5: 100.0000 (98.0400)  time: 0.2157  data: 0.0013  max mem: 2503
Test: [Task 3] Total time: 0:02:14 (0.2158 s / it)
* Acc@1 93.240 Acc@5 98.040 loss 0.370
Test: [Task 4]  [ 0/29]  eta: 0:00:14  Loss: 1.4075 (1.4075)  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 0.4931  data: 0.2714  max mem: 2503
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 1.8487 (1.7731)  Acc@1: 56.2500 (54.5455)  Acc@5: 81.2500 (82.3864)  time: 0.2402  data: 0.0250  max mem: 2503
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.8487 (1.7456)  Acc@1: 56.2500 (56.8452)  Acc@5: 81.2500 (80.9524)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.9128 (1.7561)  Acc@1: 56.2500 (56.4270)  Acc@5: 81.2500 (81.0458)  time: 0.2120  data: 0.0002  max mem: 2503
Test: [Task 4] Total time: 0:00:06 (0.2291 s / it)
* Acc@1 56.427 Acc@5 81.046 loss 1.756
Test: [Task 5]  [  0/625]  eta: 0:05:54  Loss: 0.2242 (0.2242)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5667  data: 0.3492  max mem: 2503
Test: [Task 5]  [ 10/625]  eta: 0:02:31  Loss: 0.4715 (0.4759)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.2465  data: 0.0320  max mem: 2503
Test: [Task 5]  [ 20/625]  eta: 0:02:20  Loss: 0.4445 (0.4177)  Acc@1: 87.5000 (90.7738)  Acc@5: 100.0000 (98.8095)  time: 0.2151  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 30/625]  eta: 0:02:14  Loss: 0.4570 (0.4473)  Acc@1: 87.5000 (89.9194)  Acc@5: 100.0000 (98.7903)  time: 0.2154  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 40/625]  eta: 0:02:10  Loss: 0.4570 (0.4404)  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (98.9329)  time: 0.2153  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 50/625]  eta: 0:02:07  Loss: 0.4482 (0.4530)  Acc@1: 87.5000 (89.3382)  Acc@5: 100.0000 (98.6520)  time: 0.2154  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 60/625]  eta: 0:02:04  Loss: 0.4082 (0.4469)  Acc@1: 87.5000 (89.5492)  Acc@5: 100.0000 (98.7705)  time: 0.2150  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 70/625]  eta: 0:02:02  Loss: 0.4343 (0.4486)  Acc@1: 87.5000 (89.2606)  Acc@5: 100.0000 (98.7676)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 80/625]  eta: 0:01:59  Loss: 0.4628 (0.4566)  Acc@1: 87.5000 (88.8889)  Acc@5: 100.0000 (98.6883)  time: 0.2154  data: 0.0009  max mem: 2503
Test: [Task 5]  [ 90/625]  eta: 0:01:57  Loss: 0.3680 (0.4447)  Acc@1: 93.7500 (89.2857)  Acc@5: 100.0000 (98.6264)  time: 0.2156  data: 0.0010  max mem: 2503
Test: [Task 5]  [100/625]  eta: 0:01:54  Loss: 0.3665 (0.4501)  Acc@1: 87.5000 (89.0470)  Acc@5: 100.0000 (98.5767)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 5]  [110/625]  eta: 0:01:52  Loss: 0.4495 (0.4526)  Acc@1: 87.5000 (89.0203)  Acc@5: 100.0000 (98.4797)  time: 0.2151  data: 0.0004  max mem: 2503
Test: [Task 5]  [120/625]  eta: 0:01:50  Loss: 0.3876 (0.4437)  Acc@1: 87.5000 (89.1012)  Acc@5: 100.0000 (98.5021)  time: 0.2158  data: 0.0005  max mem: 2503
Test: [Task 5]  [130/625]  eta: 0:01:47  Loss: 0.4094 (0.4475)  Acc@1: 81.2500 (88.7405)  Acc@5: 100.0000 (98.5210)  time: 0.2160  data: 0.0007  max mem: 2503
Test: [Task 5]  [140/625]  eta: 0:01:45  Loss: 0.4716 (0.4455)  Acc@1: 87.5000 (88.7855)  Acc@5: 100.0000 (98.4929)  time: 0.2155  data: 0.0007  max mem: 2503
Test: [Task 5]  [150/625]  eta: 0:01:43  Loss: 0.4220 (0.4462)  Acc@1: 87.5000 (88.6589)  Acc@5: 100.0000 (98.4272)  time: 0.2154  data: 0.0007  max mem: 2503
Test: [Task 5]  [160/625]  eta: 0:01:41  Loss: 0.5331 (0.4514)  Acc@1: 87.5000 (88.4705)  Acc@5: 100.0000 (98.3307)  time: 0.2156  data: 0.0011  max mem: 2503
Test: [Task 5]  [170/625]  eta: 0:01:38  Loss: 0.5221 (0.4588)  Acc@1: 87.5000 (88.1944)  Acc@5: 100.0000 (98.3187)  time: 0.2158  data: 0.0014  max mem: 2503
Test: [Task 5]  [180/625]  eta: 0:01:36  Loss: 0.4731 (0.4596)  Acc@1: 87.5000 (88.2942)  Acc@5: 100.0000 (98.2735)  time: 0.2154  data: 0.0010  max mem: 2503
Test: [Task 5]  [190/625]  eta: 0:01:34  Loss: 0.5487 (0.4702)  Acc@1: 87.5000 (87.9581)  Acc@5: 100.0000 (98.0694)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 5]  [200/625]  eta: 0:01:32  Loss: 0.5045 (0.4674)  Acc@1: 87.5000 (87.9353)  Acc@5: 100.0000 (98.0721)  time: 0.2145  data: 0.0005  max mem: 2503
Test: [Task 5]  [210/625]  eta: 0:01:29  Loss: 0.5047 (0.4743)  Acc@1: 87.5000 (87.7962)  Acc@5: 100.0000 (97.9858)  time: 0.2142  data: 0.0005  max mem: 2503
Test: [Task 5]  [220/625]  eta: 0:01:27  Loss: 0.5508 (0.4754)  Acc@1: 87.5000 (87.7545)  Acc@5: 100.0000 (97.9638)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 5]  [230/625]  eta: 0:01:25  Loss: 0.4756 (0.4745)  Acc@1: 87.5000 (87.7706)  Acc@5: 100.0000 (97.9708)  time: 0.2151  data: 0.0006  max mem: 2503
Test: [Task 5]  [240/625]  eta: 0:01:23  Loss: 0.4320 (0.4749)  Acc@1: 87.5000 (87.8112)  Acc@5: 100.0000 (97.9772)  time: 0.2158  data: 0.0008  max mem: 2503
Test: [Task 5]  [250/625]  eta: 0:01:21  Loss: 0.4193 (0.4754)  Acc@1: 87.5000 (87.7988)  Acc@5: 100.0000 (97.9333)  time: 0.2145  data: 0.0004  max mem: 2503
Test: [Task 5]  [260/625]  eta: 0:01:18  Loss: 0.4893 (0.4776)  Acc@1: 87.5000 (87.7395)  Acc@5: 100.0000 (97.9167)  time: 0.2141  data: 0.0005  max mem: 2503
Test: [Task 5]  [270/625]  eta: 0:01:16  Loss: 0.4297 (0.4756)  Acc@1: 87.5000 (87.8459)  Acc@5: 100.0000 (97.9474)  time: 0.2142  data: 0.0006  max mem: 2503
Test: [Task 5]  [280/625]  eta: 0:01:14  Loss: 0.3854 (0.4734)  Acc@1: 87.5000 (87.8781)  Acc@5: 100.0000 (97.9760)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 5]  [290/625]  eta: 0:01:12  Loss: 0.3881 (0.4718)  Acc@1: 87.5000 (87.9725)  Acc@5: 100.0000 (98.0026)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 5]  [300/625]  eta: 0:01:10  Loss: 0.4399 (0.4743)  Acc@1: 87.5000 (87.8530)  Acc@5: 100.0000 (98.0482)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 5]  [310/625]  eta: 0:01:08  Loss: 0.5227 (0.4744)  Acc@1: 87.5000 (87.9019)  Acc@5: 100.0000 (98.0305)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 5]  [320/625]  eta: 0:01:05  Loss: 0.5227 (0.4751)  Acc@1: 87.5000 (87.9478)  Acc@5: 100.0000 (98.0530)  time: 0.2150  data: 0.0007  max mem: 2503
Test: [Task 5]  [330/625]  eta: 0:01:03  Loss: 0.4482 (0.4753)  Acc@1: 87.5000 (87.8965)  Acc@5: 100.0000 (98.0551)  time: 0.2152  data: 0.0010  max mem: 2503
Test: [Task 5]  [340/625]  eta: 0:01:01  Loss: 0.3604 (0.4714)  Acc@1: 87.5000 (88.0315)  Acc@5: 100.0000 (98.0572)  time: 0.2146  data: 0.0006  max mem: 2503
Test: [Task 5]  [350/625]  eta: 0:00:59  Loss: 0.4430 (0.4759)  Acc@1: 87.5000 (87.8739)  Acc@5: 100.0000 (98.0591)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 5]  [360/625]  eta: 0:00:57  Loss: 0.4489 (0.4743)  Acc@1: 87.5000 (87.9501)  Acc@5: 100.0000 (98.0956)  time: 0.2139  data: 0.0002  max mem: 2503
Test: [Task 5]  [370/625]  eta: 0:00:55  Loss: 0.3725 (0.4724)  Acc@1: 93.7500 (87.9885)  Acc@5: 100.0000 (98.1301)  time: 0.2146  data: 0.0006  max mem: 2503
Test: [Task 5]  [380/625]  eta: 0:00:52  Loss: 0.4479 (0.4742)  Acc@1: 87.5000 (87.9921)  Acc@5: 100.0000 (98.0971)  time: 0.2153  data: 0.0008  max mem: 2503
Test: [Task 5]  [390/625]  eta: 0:00:50  Loss: 0.4551 (0.4743)  Acc@1: 87.5000 (87.9955)  Acc@5: 100.0000 (98.0818)  time: 0.2149  data: 0.0006  max mem: 2503
Test: [Task 5]  [400/625]  eta: 0:00:48  Loss: 0.4371 (0.4738)  Acc@1: 87.5000 (87.9676)  Acc@5: 100.0000 (98.0985)  time: 0.2145  data: 0.0004  max mem: 2503
Test: [Task 5]  [410/625]  eta: 0:00:46  Loss: 0.4288 (0.4737)  Acc@1: 87.5000 (87.9866)  Acc@5: 100.0000 (98.0687)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 5]  [420/625]  eta: 0:00:44  Loss: 0.5020 (0.4745)  Acc@1: 87.5000 (87.8563)  Acc@5: 100.0000 (98.0998)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 5]  [430/625]  eta: 0:00:42  Loss: 0.4124 (0.4736)  Acc@1: 87.5000 (87.8770)  Acc@5: 100.0000 (98.1148)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 5]  [440/625]  eta: 0:00:39  Loss: 0.4124 (0.4731)  Acc@1: 87.5000 (87.8401)  Acc@5: 100.0000 (98.1434)  time: 0.2139  data: 0.0003  max mem: 2503
Test: [Task 5]  [450/625]  eta: 0:00:37  Loss: 0.4425 (0.4723)  Acc@1: 87.5000 (87.8465)  Acc@5: 100.0000 (98.1707)  time: 0.2150  data: 0.0013  max mem: 2503
Test: [Task 5]  [460/625]  eta: 0:00:35  Loss: 0.4261 (0.4720)  Acc@1: 87.5000 (87.8796)  Acc@5: 100.0000 (98.1969)  time: 0.2160  data: 0.0023  max mem: 2503
Test: [Task 5]  [470/625]  eta: 0:00:33  Loss: 0.3655 (0.4680)  Acc@1: 93.7500 (88.0042)  Acc@5: 100.0000 (98.2219)  time: 0.2152  data: 0.0013  max mem: 2503
Test: [Task 5]  [480/625]  eta: 0:00:31  Loss: 0.3344 (0.4677)  Acc@1: 93.7500 (88.0068)  Acc@5: 100.0000 (98.2199)  time: 0.2151  data: 0.0005  max mem: 2503
Test: [Task 5]  [490/625]  eta: 0:00:29  Loss: 0.4203 (0.4677)  Acc@1: 93.7500 (88.0474)  Acc@5: 100.0000 (98.2179)  time: 0.2150  data: 0.0005  max mem: 2503
Test: [Task 5]  [500/625]  eta: 0:00:26  Loss: 0.4605 (0.4689)  Acc@1: 87.5000 (87.9865)  Acc@5: 100.0000 (98.2036)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 5]  [510/625]  eta: 0:00:24  Loss: 0.4980 (0.4694)  Acc@1: 87.5000 (88.0137)  Acc@5: 100.0000 (98.2143)  time: 0.2159  data: 0.0012  max mem: 2503
Test: [Task 5]  [520/625]  eta: 0:00:22  Loss: 0.4476 (0.4682)  Acc@1: 87.5000 (88.0518)  Acc@5: 100.0000 (98.2246)  time: 0.2163  data: 0.0012  max mem: 2503
Test: [Task 5]  [530/625]  eta: 0:00:20  Loss: 0.4101 (0.4666)  Acc@1: 93.7500 (88.1238)  Acc@5: 100.0000 (98.2462)  time: 0.2157  data: 0.0007  max mem: 2503
Test: [Task 5]  [540/625]  eta: 0:00:18  Loss: 0.3484 (0.4654)  Acc@1: 93.7500 (88.1238)  Acc@5: 100.0000 (98.2671)  time: 0.2157  data: 0.0008  max mem: 2503
Test: [Task 5]  [550/625]  eta: 0:00:16  Loss: 0.3604 (0.4664)  Acc@1: 87.5000 (88.0785)  Acc@5: 100.0000 (98.2645)  time: 0.2155  data: 0.0003  max mem: 2503
Test: [Task 5]  [560/625]  eta: 0:00:14  Loss: 0.4268 (0.4664)  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.2620)  time: 0.2155  data: 0.0003  max mem: 2503
Test: [Task 5]  [570/625]  eta: 0:00:11  Loss: 0.3354 (0.4654)  Acc@1: 87.5000 (88.1239)  Acc@5: 100.0000 (98.2596)  time: 0.2160  data: 0.0008  max mem: 2503
Test: [Task 5]  [580/625]  eta: 0:00:09  Loss: 0.4501 (0.4670)  Acc@1: 87.5000 (88.0701)  Acc@5: 100.0000 (98.2573)  time: 0.2167  data: 0.0015  max mem: 2503
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 0.4902 (0.4662)  Acc@1: 87.5000 (88.0711)  Acc@5: 100.0000 (98.2551)  time: 0.2157  data: 0.0011  max mem: 2503
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 0.4814 (0.4652)  Acc@1: 87.5000 (88.1240)  Acc@5: 100.0000 (98.2633)  time: 0.2153  data: 0.0011  max mem: 2503
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.4003 (0.4645)  Acc@1: 87.5000 (88.1240)  Acc@5: 100.0000 (98.2406)  time: 0.2162  data: 0.0019  max mem: 2503
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.3422 (0.4625)  Acc@1: 87.5000 (88.2246)  Acc@5: 100.0000 (98.2488)  time: 0.2156  data: 0.0011  max mem: 2503
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.3614 (0.4629)  Acc@1: 87.5000 (88.2000)  Acc@5: 100.0000 (98.2600)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 5] Total time: 0:02:14 (0.2158 s / it)
* Acc@1 88.200 Acc@5 98.260 loss 0.463
{0: {0: 25002, 1: 25002, 2: 25002, 3: 25002, 4: 25, 5: 25, 6: 25, 7: 25, 8: 146, 9: 146, 10: 146, 11: 146, 12: 67, 13: 67, 14: 67, 15: 67, 16: 792, 17: 792, 18: 792, 19: 792}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 9896, 5: 9896, 6: 9896, 7: 9896, 8: 0, 9: 0, 10: 0, 11: 0, 12: 104, 13: 104, 14: 104, 15: 104, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 151, 1: 151, 2: 151, 3: 151, 4: 14, 5: 14, 6: 14, 7: 14, 8: 9679, 9: 9679, 10: 9679, 11: 9679, 12: 46, 13: 46, 14: 46, 15: 46, 16: 110, 17: 110, 18: 110, 19: 110}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 30, 5: 30, 6: 30, 7: 30, 8: 0, 9: 0, 10: 0, 11: 0, 12: 428, 13: 428, 14: 428, 15: 428, 16: 1, 17: 1, 18: 1, 19: 1}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 262, 5: 262, 6: 262, 7: 262, 8: 0, 9: 0, 10: 0, 11: 0, 12: 93, 13: 93, 14: 93, 15: 93, 16: 9645, 17: 9645, 18: 9645, 19: 9645}}
[Average accuracy till task5]	Acc@1: 66.3268	Acc@5: 85.0734	Loss: 1.3066	Forgetting: 23.3483	Backward: -23.3483
Total training time: 8:37:57
