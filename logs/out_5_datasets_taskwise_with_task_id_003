/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_5_datasets_taskwise_with_task_id_003', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=40, length=10, top_k=8, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=True, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=False, train_type='task_wise', eval_task_id=True, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=False, prompts_per_task=4, prompts_per_class=1, freeze_keys=False)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 376370
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 3:06:24  Lr: 0.030000  Loss: 2.3030  Acc@1: 12.5000 (12.5000)  Acc@5: 56.2500 (56.2500)  time: 2.4425  data: 0.5529  max mem: 2898
Train: Epoch[1/5]  [  10/4579]  eta: 0:43:51  Lr: 0.030000  Loss: 1.2437  Acc@1: 12.5000 (20.4545)  Acc@5: 56.2500 (59.0909)  time: 0.5760  data: 0.0508  max mem: 2904
Train: Epoch[1/5]  [  20/4579]  eta: 0:37:09  Lr: 0.030000  Loss: 0.2059  Acc@1: 18.7500 (22.6190)  Acc@5: 68.7500 (66.6667)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [  30/4579]  eta: 0:34:39  Lr: 0.030000  Loss: 0.1939  Acc@1: 18.7500 (22.1774)  Acc@5: 68.7500 (65.9274)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [  40/4579]  eta: 0:33:22  Lr: 0.030000  Loss: -0.0989  Acc@1: 25.0000 (23.7805)  Acc@5: 68.7500 (67.3780)  time: 0.3908  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [  50/4579]  eta: 0:32:33  Lr: 0.030000  Loss: -0.5232  Acc@1: 25.0000 (24.7549)  Acc@5: 75.0000 (68.7500)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [  60/4579]  eta: 0:32:02  Lr: 0.030000  Loss: -0.1197  Acc@1: 31.2500 (25.6148)  Acc@5: 68.7500 (68.1352)  time: 0.3934  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [  70/4579]  eta: 0:31:36  Lr: 0.030000  Loss: -0.3783  Acc@1: 37.5000 (27.8169)  Acc@5: 68.7500 (69.1901)  time: 0.3933  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [  80/4579]  eta: 0:31:17  Lr: 0.030000  Loss: -0.5210  Acc@1: 37.5000 (28.3951)  Acc@5: 75.0000 (70.6019)  time: 0.3928  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [  90/4579]  eta: 0:30:59  Lr: 0.030000  Loss: -0.7297  Acc@1: 37.5000 (28.9835)  Acc@5: 75.0000 (71.6346)  time: 0.3918  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [ 100/4579]  eta: 0:30:46  Lr: 0.030000  Loss: -0.9414  Acc@1: 37.5000 (29.6411)  Acc@5: 75.0000 (71.9678)  time: 0.3912  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 110/4579]  eta: 0:30:33  Lr: 0.030000  Loss: -1.2061  Acc@1: 31.2500 (29.8986)  Acc@5: 75.0000 (72.4662)  time: 0.3924  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 120/4579]  eta: 0:30:22  Lr: 0.030000  Loss: -0.8202  Acc@1: 37.5000 (30.8884)  Acc@5: 81.2500 (73.2438)  time: 0.3913  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 130/4579]  eta: 0:30:13  Lr: 0.030000  Loss: -0.7858  Acc@1: 37.5000 (31.2023)  Acc@5: 81.2500 (73.7595)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 140/4579]  eta: 0:30:04  Lr: 0.030000  Loss: -0.8369  Acc@1: 37.5000 (32.0035)  Acc@5: 81.2500 (74.3351)  time: 0.3934  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [ 150/4579]  eta: 0:29:56  Lr: 0.030000  Loss: -0.6801  Acc@1: 43.7500 (32.8228)  Acc@5: 81.2500 (75.0414)  time: 0.3933  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [ 160/4579]  eta: 0:29:48  Lr: 0.030000  Loss: -0.1538  Acc@1: 31.2500 (32.6863)  Acc@5: 81.2500 (75.1165)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 170/4579]  eta: 0:29:41  Lr: 0.030000  Loss: -1.0408  Acc@1: 31.2500 (33.2968)  Acc@5: 81.2500 (75.6213)  time: 0.3919  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [ 180/4579]  eta: 0:29:35  Lr: 0.030000  Loss: -1.1769  Acc@1: 37.5000 (33.7017)  Acc@5: 81.2500 (75.7597)  time: 0.3942  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [ 190/4579]  eta: 0:29:28  Lr: 0.030000  Loss: -0.9954  Acc@1: 43.7500 (34.2277)  Acc@5: 81.2500 (76.2435)  time: 0.3939  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 200/4579]  eta: 0:29:22  Lr: 0.030000  Loss: -1.1099  Acc@1: 43.7500 (34.6393)  Acc@5: 81.2500 (76.7102)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 210/4579]  eta: 0:29:16  Lr: 0.030000  Loss: -0.8835  Acc@1: 43.7500 (35.0711)  Acc@5: 87.5000 (77.0438)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 220/4579]  eta: 0:29:10  Lr: 0.030000  Loss: -0.6050  Acc@1: 37.5000 (35.4072)  Acc@5: 81.2500 (77.3756)  time: 0.3930  data: 0.0013  max mem: 2904
Train: Epoch[1/5]  [ 230/4579]  eta: 0:29:05  Lr: 0.030000  Loss: -0.8027  Acc@1: 37.5000 (35.6061)  Acc@5: 81.2500 (77.5433)  time: 0.3946  data: 0.0016  max mem: 2904
Train: Epoch[1/5]  [ 240/4579]  eta: 0:29:00  Lr: 0.030000  Loss: -0.4680  Acc@1: 37.5000 (35.5290)  Acc@5: 81.2500 (77.6971)  time: 0.3955  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [ 250/4579]  eta: 0:28:55  Lr: 0.030000  Loss: -0.9491  Acc@1: 37.5000 (35.9562)  Acc@5: 87.5000 (78.0627)  time: 0.3947  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 260/4579]  eta: 0:28:50  Lr: 0.030000  Loss: -0.8189  Acc@1: 43.7500 (36.3027)  Acc@5: 87.5000 (78.2328)  time: 0.3947  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 270/4579]  eta: 0:28:44  Lr: 0.030000  Loss: -0.7654  Acc@1: 43.7500 (36.6236)  Acc@5: 81.2500 (78.3672)  time: 0.3934  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [ 280/4579]  eta: 0:28:40  Lr: 0.030000  Loss: -0.6653  Acc@1: 43.7500 (36.9884)  Acc@5: 81.2500 (78.6032)  time: 0.3950  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [ 290/4579]  eta: 0:28:37  Lr: 0.030000  Loss: -0.9019  Acc@1: 43.7500 (37.2852)  Acc@5: 87.5000 (78.9304)  time: 0.4010  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [ 300/4579]  eta: 0:28:32  Lr: 0.030000  Loss: -0.7272  Acc@1: 50.0000 (37.8115)  Acc@5: 87.5000 (79.3397)  time: 0.3988  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [ 310/4579]  eta: 0:28:27  Lr: 0.030000  Loss: -0.9034  Acc@1: 50.0000 (38.2436)  Acc@5: 87.5000 (79.4413)  time: 0.3931  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 320/4579]  eta: 0:28:22  Lr: 0.030000  Loss: -0.9820  Acc@1: 50.0000 (38.5319)  Acc@5: 81.2500 (79.6924)  time: 0.3942  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 330/4579]  eta: 0:28:18  Lr: 0.030000  Loss: -0.0803  Acc@1: 50.0000 (38.8784)  Acc@5: 87.5000 (79.8338)  time: 0.3957  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [ 340/4579]  eta: 0:28:13  Lr: 0.030000  Loss: -0.7696  Acc@1: 50.0000 (39.0213)  Acc@5: 87.5000 (79.9853)  time: 0.3954  data: 0.0017  max mem: 2904
Train: Epoch[1/5]  [ 350/4579]  eta: 0:28:09  Lr: 0.030000  Loss: -1.1264  Acc@1: 43.7500 (39.2806)  Acc@5: 87.5000 (80.1282)  time: 0.3957  data: 0.0015  max mem: 2904
Train: Epoch[1/5]  [ 360/4579]  eta: 0:28:04  Lr: 0.030000  Loss: -1.2590  Acc@1: 50.0000 (39.5949)  Acc@5: 87.5000 (80.2285)  time: 0.3962  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 370/4579]  eta: 0:28:00  Lr: 0.030000  Loss: -1.1953  Acc@1: 50.0000 (39.8753)  Acc@5: 81.2500 (80.4414)  time: 0.3948  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 380/4579]  eta: 0:27:55  Lr: 0.030000  Loss: -1.5744  Acc@1: 43.7500 (40.2067)  Acc@5: 87.5000 (80.6594)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 390/4579]  eta: 0:27:50  Lr: 0.030000  Loss: -0.8737  Acc@1: 43.7500 (40.3932)  Acc@5: 87.5000 (80.7225)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 400/4579]  eta: 0:27:46  Lr: 0.030000  Loss: -0.9800  Acc@1: 43.7500 (40.6016)  Acc@5: 81.2500 (80.7824)  time: 0.3951  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 410/4579]  eta: 0:27:41  Lr: 0.030000  Loss: -0.3160  Acc@1: 56.2500 (40.9063)  Acc@5: 87.5000 (80.9459)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 420/4579]  eta: 0:27:37  Lr: 0.030000  Loss: -0.4806  Acc@1: 56.2500 (41.1372)  Acc@5: 87.5000 (81.0125)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 430/4579]  eta: 0:27:32  Lr: 0.030000  Loss: -1.3856  Acc@1: 50.0000 (41.3138)  Acc@5: 87.5000 (81.1920)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 440/4579]  eta: 0:27:28  Lr: 0.030000  Loss: -1.4579  Acc@1: 50.0000 (41.4824)  Acc@5: 87.5000 (81.2925)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 450/4579]  eta: 0:27:24  Lr: 0.030000  Loss: -1.1201  Acc@1: 50.0000 (41.6851)  Acc@5: 81.2500 (81.3747)  time: 0.3950  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [ 460/4579]  eta: 0:27:20  Lr: 0.030000  Loss: -1.1936  Acc@1: 50.0000 (41.8926)  Acc@5: 87.5000 (81.5347)  time: 0.3960  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [ 470/4579]  eta: 0:27:15  Lr: 0.030000  Loss: -0.7455  Acc@1: 50.0000 (42.1444)  Acc@5: 87.5000 (81.6215)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 480/4579]  eta: 0:27:11  Lr: 0.030000  Loss: -1.1822  Acc@1: 50.0000 (42.3467)  Acc@5: 87.5000 (81.7957)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 490/4579]  eta: 0:27:06  Lr: 0.030000  Loss: -0.9209  Acc@1: 50.0000 (42.4898)  Acc@5: 87.5000 (81.8865)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 500/4579]  eta: 0:27:02  Lr: 0.030000  Loss: -1.6411  Acc@1: 50.0000 (42.7645)  Acc@5: 87.5000 (82.1233)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 510/4579]  eta: 0:26:58  Lr: 0.030000  Loss: -0.9590  Acc@1: 50.0000 (42.9183)  Acc@5: 87.5000 (82.1551)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 520/4579]  eta: 0:26:53  Lr: 0.030000  Loss: -1.2125  Acc@1: 50.0000 (42.9702)  Acc@5: 87.5000 (82.1857)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 530/4579]  eta: 0:26:49  Lr: 0.030000  Loss: -1.1601  Acc@1: 50.0000 (43.2792)  Acc@5: 87.5000 (82.4153)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 540/4579]  eta: 0:26:44  Lr: 0.030000  Loss: -1.1801  Acc@1: 56.2500 (43.5536)  Acc@5: 93.7500 (82.6479)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 550/4579]  eta: 0:26:40  Lr: 0.030000  Loss: -1.1232  Acc@1: 56.2500 (43.8067)  Acc@5: 93.7500 (82.7700)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 560/4579]  eta: 0:26:36  Lr: 0.030000  Loss: -0.7102  Acc@1: 56.2500 (43.9617)  Acc@5: 87.5000 (82.8431)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 570/4579]  eta: 0:26:32  Lr: 0.030000  Loss: -1.3163  Acc@1: 50.0000 (44.0236)  Acc@5: 87.5000 (82.8262)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 580/4579]  eta: 0:26:27  Lr: 0.030000  Loss: -0.6554  Acc@1: 50.0000 (44.2341)  Acc@5: 81.2500 (82.8959)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 590/4579]  eta: 0:26:23  Lr: 0.030000  Loss: -1.5077  Acc@1: 56.2500 (44.3845)  Acc@5: 87.5000 (83.0372)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 600/4579]  eta: 0:26:19  Lr: 0.030000  Loss: -1.0969  Acc@1: 50.0000 (44.4884)  Acc@5: 87.5000 (83.0699)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 610/4579]  eta: 0:26:15  Lr: 0.030000  Loss: -0.8077  Acc@1: 50.0000 (44.5274)  Acc@5: 87.5000 (83.1219)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 620/4579]  eta: 0:26:11  Lr: 0.030000  Loss: -0.9584  Acc@1: 50.0000 (44.6659)  Acc@5: 81.2500 (83.1421)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 630/4579]  eta: 0:26:06  Lr: 0.030000  Loss: -1.1378  Acc@1: 56.2500 (44.7801)  Acc@5: 87.5000 (83.2310)  time: 0.3938  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 640/4579]  eta: 0:26:02  Lr: 0.030000  Loss: -0.9192  Acc@1: 56.2500 (44.9395)  Acc@5: 87.5000 (83.2488)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 650/4579]  eta: 0:25:58  Lr: 0.030000  Loss: -1.0136  Acc@1: 56.2500 (45.0365)  Acc@5: 81.2500 (83.2757)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 660/4579]  eta: 0:25:54  Lr: 0.030000  Loss: -1.6311  Acc@1: 50.0000 (45.0927)  Acc@5: 87.5000 (83.3585)  time: 0.3916  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 670/4579]  eta: 0:25:50  Lr: 0.030000  Loss: -1.9297  Acc@1: 56.2500 (45.2776)  Acc@5: 93.7500 (83.4855)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 680/4579]  eta: 0:25:45  Lr: 0.030000  Loss: -0.9205  Acc@1: 56.2500 (45.4387)  Acc@5: 87.5000 (83.5536)  time: 0.3931  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 690/4579]  eta: 0:25:41  Lr: 0.030000  Loss: -1.3980  Acc@1: 56.2500 (45.5409)  Acc@5: 87.5000 (83.5926)  time: 0.3933  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 700/4579]  eta: 0:25:37  Lr: 0.030000  Loss: -1.4484  Acc@1: 50.0000 (45.6580)  Acc@5: 87.5000 (83.7197)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 710/4579]  eta: 0:25:33  Lr: 0.030000  Loss: -0.9170  Acc@1: 62.5000 (45.8333)  Acc@5: 93.7500 (83.8080)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 720/4579]  eta: 0:25:29  Lr: 0.030000  Loss: -1.0207  Acc@1: 50.0000 (45.8998)  Acc@5: 87.5000 (83.8679)  time: 0.3937  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 730/4579]  eta: 0:25:25  Lr: 0.030000  Loss: -1.3624  Acc@1: 56.2500 (46.0841)  Acc@5: 87.5000 (83.9176)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 740/4579]  eta: 0:25:21  Lr: 0.030000  Loss: -0.5997  Acc@1: 56.2500 (46.0948)  Acc@5: 87.5000 (83.9744)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 750/4579]  eta: 0:25:16  Lr: 0.030000  Loss: -1.3207  Acc@1: 50.0000 (46.1967)  Acc@5: 87.5000 (83.9880)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 760/4579]  eta: 0:25:12  Lr: 0.030000  Loss: -1.1435  Acc@1: 56.2500 (46.2549)  Acc@5: 87.5000 (84.0177)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 770/4579]  eta: 0:25:08  Lr: 0.030000  Loss: -1.0340  Acc@1: 50.0000 (46.3927)  Acc@5: 81.2500 (84.0224)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 780/4579]  eta: 0:25:04  Lr: 0.030000  Loss: -1.6041  Acc@1: 56.2500 (46.5349)  Acc@5: 87.5000 (84.1229)  time: 0.3946  data: 0.0018  max mem: 2904
Train: Epoch[1/5]  [ 790/4579]  eta: 0:25:00  Lr: 0.030000  Loss: -1.2585  Acc@1: 56.2500 (46.6656)  Acc@5: 87.5000 (84.1498)  time: 0.3941  data: 0.0023  max mem: 2904
Train: Epoch[1/5]  [ 800/4579]  eta: 0:24:56  Lr: 0.030000  Loss: -0.9598  Acc@1: 56.2500 (46.7775)  Acc@5: 87.5000 (84.2072)  time: 0.3927  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [ 810/4579]  eta: 0:24:52  Lr: 0.030000  Loss: -1.0562  Acc@1: 56.2500 (46.8789)  Acc@5: 87.5000 (84.2633)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 820/4579]  eta: 0:24:48  Lr: 0.030000  Loss: -1.6396  Acc@1: 50.0000 (46.9854)  Acc@5: 93.7500 (84.3940)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 830/4579]  eta: 0:24:44  Lr: 0.030000  Loss: -1.1760  Acc@1: 50.0000 (46.9540)  Acc@5: 93.7500 (84.4314)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 840/4579]  eta: 0:24:40  Lr: 0.030000  Loss: -1.8886  Acc@1: 50.0000 (47.1017)  Acc@5: 87.5000 (84.5199)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 850/4579]  eta: 0:24:36  Lr: 0.030000  Loss: -0.6378  Acc@1: 62.5000 (47.2826)  Acc@5: 93.7500 (84.6063)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 860/4579]  eta: 0:24:32  Lr: 0.030000  Loss: -1.6586  Acc@1: 62.5000 (47.4231)  Acc@5: 93.7500 (84.6690)  time: 0.3949  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 870/4579]  eta: 0:24:28  Lr: 0.030000  Loss: -0.6217  Acc@1: 56.2500 (47.5244)  Acc@5: 87.5000 (84.7087)  time: 0.3958  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 880/4579]  eta: 0:24:24  Lr: 0.030000  Loss: -1.0332  Acc@1: 56.2500 (47.6518)  Acc@5: 87.5000 (84.7262)  time: 0.3986  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 890/4579]  eta: 0:24:20  Lr: 0.030000  Loss: -0.8029  Acc@1: 56.2500 (47.7764)  Acc@5: 93.7500 (84.7854)  time: 0.3983  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 900/4579]  eta: 0:24:16  Lr: 0.030000  Loss: -1.8194  Acc@1: 62.5000 (47.9467)  Acc@5: 93.7500 (84.8710)  time: 0.3957  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 910/4579]  eta: 0:24:12  Lr: 0.030000  Loss: -0.2768  Acc@1: 56.2500 (47.9898)  Acc@5: 87.5000 (84.8998)  time: 0.3944  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [ 920/4579]  eta: 0:24:08  Lr: 0.030000  Loss: -0.0156  Acc@1: 50.0000 (48.0456)  Acc@5: 87.5000 (84.9416)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 930/4579]  eta: 0:24:04  Lr: 0.030000  Loss: -0.7614  Acc@1: 56.2500 (48.1136)  Acc@5: 87.5000 (84.9825)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [ 940/4579]  eta: 0:24:00  Lr: 0.030000  Loss: -1.6746  Acc@1: 50.0000 (48.1403)  Acc@5: 87.5000 (84.9894)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 950/4579]  eta: 0:23:56  Lr: 0.030000  Loss: -0.8178  Acc@1: 50.0000 (48.2058)  Acc@5: 87.5000 (85.0223)  time: 0.3936  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [ 960/4579]  eta: 0:23:52  Lr: 0.030000  Loss: -1.7034  Acc@1: 62.5000 (48.4001)  Acc@5: 87.5000 (85.0741)  time: 0.3954  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [ 970/4579]  eta: 0:23:48  Lr: 0.030000  Loss: -0.5868  Acc@1: 62.5000 (48.4938)  Acc@5: 93.7500 (85.1184)  time: 0.3960  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 980/4579]  eta: 0:23:44  Lr: 0.030000  Loss: -1.2531  Acc@1: 56.2500 (48.5155)  Acc@5: 93.7500 (85.1491)  time: 0.3984  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [ 990/4579]  eta: 0:23:40  Lr: 0.030000  Loss: -1.7008  Acc@1: 56.2500 (48.6314)  Acc@5: 87.5000 (85.1854)  time: 0.3975  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1000/4579]  eta: 0:23:36  Lr: 0.030000  Loss: -1.2097  Acc@1: 56.2500 (48.7263)  Acc@5: 87.5000 (85.2273)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1010/4579]  eta: 0:23:32  Lr: 0.030000  Loss: -1.1930  Acc@1: 56.2500 (48.8254)  Acc@5: 87.5000 (85.2065)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1020/4579]  eta: 0:23:28  Lr: 0.030000  Loss: -1.5184  Acc@1: 56.2500 (48.9349)  Acc@5: 87.5000 (85.2473)  time: 0.3949  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1030/4579]  eta: 0:23:24  Lr: 0.030000  Loss: -0.8196  Acc@1: 56.2500 (48.9937)  Acc@5: 87.5000 (85.2873)  time: 0.3959  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1040/4579]  eta: 0:23:20  Lr: 0.030000  Loss: -1.8036  Acc@1: 56.2500 (49.0994)  Acc@5: 93.7500 (85.3626)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1050/4579]  eta: 0:23:16  Lr: 0.030000  Loss: -1.0722  Acc@1: 56.2500 (49.1199)  Acc@5: 93.7500 (85.3889)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1060/4579]  eta: 0:23:12  Lr: 0.030000  Loss: -1.3087  Acc@1: 56.2500 (49.2401)  Acc@5: 87.5000 (85.4324)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1070/4579]  eta: 0:23:08  Lr: 0.030000  Loss: -1.4583  Acc@1: 56.2500 (49.2822)  Acc@5: 93.7500 (85.4809)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1080/4579]  eta: 0:23:04  Lr: 0.030000  Loss: -0.7312  Acc@1: 56.2500 (49.3698)  Acc@5: 87.5000 (85.5111)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1090/4579]  eta: 0:23:00  Lr: 0.030000  Loss: -0.9286  Acc@1: 56.2500 (49.4271)  Acc@5: 87.5000 (85.5351)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1100/4579]  eta: 0:22:56  Lr: 0.030000  Loss: -1.1599  Acc@1: 56.2500 (49.4380)  Acc@5: 87.5000 (85.5870)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1110/4579]  eta: 0:22:52  Lr: 0.030000  Loss: -1.6367  Acc@1: 56.2500 (49.5050)  Acc@5: 87.5000 (85.6211)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1120/4579]  eta: 0:22:48  Lr: 0.030000  Loss: -0.9607  Acc@1: 56.2500 (49.6041)  Acc@5: 93.7500 (85.6713)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1130/4579]  eta: 0:22:44  Lr: 0.030000  Loss: -1.5026  Acc@1: 62.5000 (49.7182)  Acc@5: 87.5000 (85.6930)  time: 0.3965  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1140/4579]  eta: 0:22:40  Lr: 0.030000  Loss: -1.4034  Acc@1: 62.5000 (49.8466)  Acc@5: 87.5000 (85.7417)  time: 0.3957  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [1150/4579]  eta: 0:22:36  Lr: 0.030000  Loss: -1.2324  Acc@1: 62.5000 (49.9457)  Acc@5: 93.7500 (85.8058)  time: 0.3957  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [1160/4579]  eta: 0:22:32  Lr: 0.030000  Loss: -1.1692  Acc@1: 56.2500 (49.9623)  Acc@5: 93.7500 (85.8419)  time: 0.3977  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1170/4579]  eta: 0:22:28  Lr: 0.030000  Loss: -1.6127  Acc@1: 50.0000 (50.0480)  Acc@5: 93.7500 (85.8988)  time: 0.3962  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1180/4579]  eta: 0:22:24  Lr: 0.030000  Loss: -1.3386  Acc@1: 62.5000 (50.1693)  Acc@5: 93.7500 (85.9229)  time: 0.3940  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [1190/4579]  eta: 0:22:20  Lr: 0.030000  Loss: -1.2482  Acc@1: 62.5000 (50.2257)  Acc@5: 87.5000 (85.9572)  time: 0.3917  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1200/4579]  eta: 0:22:16  Lr: 0.030000  Loss: -1.4376  Acc@1: 56.2500 (50.2550)  Acc@5: 87.5000 (85.9804)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1210/4579]  eta: 0:22:12  Lr: 0.030000  Loss: -1.3672  Acc@1: 56.2500 (50.3148)  Acc@5: 93.7500 (86.0239)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1220/4579]  eta: 0:22:08  Lr: 0.030000  Loss: -1.1707  Acc@1: 50.0000 (50.3686)  Acc@5: 93.7500 (86.0309)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1230/4579]  eta: 0:22:04  Lr: 0.030000  Loss: -1.2679  Acc@1: 50.0000 (50.4011)  Acc@5: 87.5000 (86.0479)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1240/4579]  eta: 0:22:00  Lr: 0.030000  Loss: -1.3932  Acc@1: 50.0000 (50.4180)  Acc@5: 87.5000 (86.0647)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1250/4579]  eta: 0:21:56  Lr: 0.030000  Loss: -0.8706  Acc@1: 50.0000 (50.4297)  Acc@5: 87.5000 (86.0961)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1260/4579]  eta: 0:21:52  Lr: 0.030000  Loss: -1.0326  Acc@1: 56.2500 (50.4659)  Acc@5: 87.5000 (86.1271)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1270/4579]  eta: 0:21:48  Lr: 0.030000  Loss: -1.6076  Acc@1: 56.2500 (50.5507)  Acc@5: 93.7500 (86.1723)  time: 0.3943  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1280/4579]  eta: 0:21:44  Lr: 0.030000  Loss: -1.2363  Acc@1: 56.2500 (50.6148)  Acc@5: 87.5000 (86.2022)  time: 0.3958  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1290/4579]  eta: 0:21:40  Lr: 0.030000  Loss: -1.0101  Acc@1: 56.2500 (50.6584)  Acc@5: 93.7500 (86.2461)  time: 0.3973  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1300/4579]  eta: 0:21:36  Lr: 0.030000  Loss: -0.5650  Acc@1: 62.5000 (50.7302)  Acc@5: 93.7500 (86.2798)  time: 0.3964  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1310/4579]  eta: 0:21:32  Lr: 0.030000  Loss: -0.8197  Acc@1: 56.2500 (50.7437)  Acc@5: 93.7500 (86.3177)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1320/4579]  eta: 0:21:28  Lr: 0.030000  Loss: -0.8378  Acc@1: 50.0000 (50.7712)  Acc@5: 87.5000 (86.3314)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1330/4579]  eta: 0:21:24  Lr: 0.030000  Loss: -1.4206  Acc@1: 56.2500 (50.8264)  Acc@5: 87.5000 (86.3683)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1340/4579]  eta: 0:21:20  Lr: 0.030000  Loss: -1.5790  Acc@1: 56.2500 (50.8762)  Acc@5: 87.5000 (86.3768)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1350/4579]  eta: 0:21:16  Lr: 0.030000  Loss: -1.2967  Acc@1: 56.2500 (50.9484)  Acc@5: 87.5000 (86.3897)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1360/4579]  eta: 0:21:12  Lr: 0.030000  Loss: -1.5878  Acc@1: 62.5000 (51.0424)  Acc@5: 87.5000 (86.4025)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1370/4579]  eta: 0:21:08  Lr: 0.030000  Loss: -1.2033  Acc@1: 62.5000 (51.1306)  Acc@5: 87.5000 (86.4013)  time: 0.3946  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [1380/4579]  eta: 0:21:04  Lr: 0.030000  Loss: -0.8402  Acc@1: 62.5000 (51.1948)  Acc@5: 87.5000 (86.4003)  time: 0.3929  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [1390/4579]  eta: 0:21:00  Lr: 0.030000  Loss: -0.6665  Acc@1: 62.5000 (51.2761)  Acc@5: 87.5000 (86.4171)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1400/4579]  eta: 0:20:56  Lr: 0.030000  Loss: -1.6875  Acc@1: 62.5000 (51.3116)  Acc@5: 87.5000 (86.4293)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1410/4579]  eta: 0:20:52  Lr: 0.030000  Loss: -1.6591  Acc@1: 56.2500 (51.3687)  Acc@5: 87.5000 (86.4635)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1420/4579]  eta: 0:20:48  Lr: 0.030000  Loss: -1.3881  Acc@1: 62.5000 (51.4382)  Acc@5: 87.5000 (86.4752)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[1/5]  [1430/4579]  eta: 0:20:44  Lr: 0.030000  Loss: -1.1106  Acc@1: 62.5000 (51.5330)  Acc@5: 87.5000 (86.5173)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1440/4579]  eta: 0:20:40  Lr: 0.030000  Loss: -1.9656  Acc@1: 62.5000 (51.5614)  Acc@5: 87.5000 (86.5068)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1450/4579]  eta: 0:20:36  Lr: 0.030000  Loss: -1.8605  Acc@1: 56.2500 (51.5937)  Acc@5: 87.5000 (86.5050)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1460/4579]  eta: 0:20:32  Lr: 0.030000  Loss: -0.8002  Acc@1: 56.2500 (51.6427)  Acc@5: 87.5000 (86.5033)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1470/4579]  eta: 0:20:28  Lr: 0.030000  Loss: -0.8162  Acc@1: 56.2500 (51.6995)  Acc@5: 87.5000 (86.5270)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1480/4579]  eta: 0:20:24  Lr: 0.030000  Loss: -1.1893  Acc@1: 50.0000 (51.7176)  Acc@5: 93.7500 (86.5547)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1490/4579]  eta: 0:20:20  Lr: 0.030000  Loss: -1.4967  Acc@1: 56.2500 (51.7899)  Acc@5: 87.5000 (86.5610)  time: 0.3922  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1500/4579]  eta: 0:20:16  Lr: 0.030000  Loss: -1.5054  Acc@1: 68.7500 (51.8862)  Acc@5: 93.7500 (86.6048)  time: 0.3929  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1510/4579]  eta: 0:20:12  Lr: 0.030000  Loss: -1.2823  Acc@1: 56.2500 (51.8738)  Acc@5: 93.7500 (86.6231)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1520/4579]  eta: 0:20:08  Lr: 0.030000  Loss: -1.6946  Acc@1: 56.2500 (51.9477)  Acc@5: 93.7500 (86.6617)  time: 0.3947  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1530/4579]  eta: 0:20:04  Lr: 0.030000  Loss: -1.1602  Acc@1: 62.5000 (51.9881)  Acc@5: 93.7500 (86.6876)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1540/4579]  eta: 0:20:00  Lr: 0.030000  Loss: -1.5501  Acc@1: 56.2500 (52.0482)  Acc@5: 87.5000 (86.6970)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1550/4579]  eta: 0:19:56  Lr: 0.030000  Loss: -1.4956  Acc@1: 56.2500 (52.1196)  Acc@5: 87.5000 (86.7102)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1560/4579]  eta: 0:19:52  Lr: 0.030000  Loss: -0.9453  Acc@1: 62.5000 (52.1781)  Acc@5: 87.5000 (86.7112)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1570/4579]  eta: 0:19:48  Lr: 0.030000  Loss: -1.5695  Acc@1: 62.5000 (52.2319)  Acc@5: 87.5000 (86.7282)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1580/4579]  eta: 0:19:44  Lr: 0.030000  Loss: -0.4270  Acc@1: 62.5000 (52.2533)  Acc@5: 87.5000 (86.7252)  time: 0.3941  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [1590/4579]  eta: 0:19:40  Lr: 0.030000  Loss: -1.2946  Acc@1: 56.2500 (52.2784)  Acc@5: 93.7500 (86.7536)  time: 0.3940  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [1600/4579]  eta: 0:19:36  Lr: 0.030000  Loss: -0.7227  Acc@1: 56.2500 (52.2915)  Acc@5: 93.7500 (86.7817)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1610/4579]  eta: 0:19:32  Lr: 0.030000  Loss: -0.9662  Acc@1: 56.2500 (52.3510)  Acc@5: 93.7500 (86.8094)  time: 0.3938  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1620/4579]  eta: 0:19:28  Lr: 0.030000  Loss: -0.4876  Acc@1: 56.2500 (52.3635)  Acc@5: 87.5000 (86.8253)  time: 0.3936  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [1630/4579]  eta: 0:19:24  Lr: 0.030000  Loss: -0.6886  Acc@1: 56.2500 (52.3720)  Acc@5: 93.7500 (86.8562)  time: 0.3931  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1640/4579]  eta: 0:19:20  Lr: 0.030000  Loss: -1.4180  Acc@1: 56.2500 (52.4109)  Acc@5: 87.5000 (86.8449)  time: 0.3948  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1650/4579]  eta: 0:19:16  Lr: 0.030000  Loss: -1.5792  Acc@1: 56.2500 (52.4114)  Acc@5: 87.5000 (86.8716)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1660/4579]  eta: 0:19:12  Lr: 0.030000  Loss: -1.5650  Acc@1: 56.2500 (52.4571)  Acc@5: 93.7500 (86.8980)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1670/4579]  eta: 0:19:08  Lr: 0.030000  Loss: -1.5841  Acc@1: 62.5000 (52.5284)  Acc@5: 93.7500 (86.9539)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1680/4579]  eta: 0:19:04  Lr: 0.030000  Loss: -1.0094  Acc@1: 62.5000 (52.5729)  Acc@5: 93.7500 (86.9795)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1690/4579]  eta: 0:19:00  Lr: 0.030000  Loss: -0.9127  Acc@1: 56.2500 (52.5909)  Acc@5: 93.7500 (86.9899)  time: 0.3937  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1700/4579]  eta: 0:18:56  Lr: 0.030000  Loss: -1.5583  Acc@1: 56.2500 (52.6492)  Acc@5: 87.5000 (87.0297)  time: 0.3943  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1710/4579]  eta: 0:18:52  Lr: 0.030000  Loss: -1.6600  Acc@1: 62.5000 (52.7031)  Acc@5: 93.7500 (87.0507)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1720/4579]  eta: 0:18:48  Lr: 0.030000  Loss: -1.4860  Acc@1: 56.2500 (52.6838)  Acc@5: 93.7500 (87.0569)  time: 0.3941  data: 0.0010  max mem: 2904
Train: Epoch[1/5]  [1730/4579]  eta: 0:18:44  Lr: 0.030000  Loss: -1.3261  Acc@1: 56.2500 (52.7405)  Acc@5: 87.5000 (87.0739)  time: 0.3942  data: 0.0010  max mem: 2904
Train: Epoch[1/5]  [1740/4579]  eta: 0:18:41  Lr: 0.030000  Loss: -1.2969  Acc@1: 62.5000 (52.7750)  Acc@5: 87.5000 (87.0800)  time: 0.3948  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1750/4579]  eta: 0:18:37  Lr: 0.030000  Loss: -0.4007  Acc@1: 62.5000 (52.8198)  Acc@5: 87.5000 (87.0752)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1760/4579]  eta: 0:18:33  Lr: 0.030000  Loss: -1.5807  Acc@1: 56.2500 (52.8535)  Acc@5: 87.5000 (87.0777)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1770/4579]  eta: 0:18:29  Lr: 0.030000  Loss: -1.7571  Acc@1: 56.2500 (52.8797)  Acc@5: 87.5000 (87.0871)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1780/4579]  eta: 0:18:25  Lr: 0.030000  Loss: -1.1583  Acc@1: 56.2500 (52.9092)  Acc@5: 93.7500 (87.1070)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1790/4579]  eta: 0:18:21  Lr: 0.030000  Loss: -1.6173  Acc@1: 56.2500 (52.9697)  Acc@5: 93.7500 (87.1057)  time: 0.3919  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1800/4579]  eta: 0:18:17  Lr: 0.030000  Loss: -2.1214  Acc@1: 62.5000 (53.0365)  Acc@5: 87.5000 (87.1009)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1810/4579]  eta: 0:18:13  Lr: 0.030000  Loss: -1.0312  Acc@1: 56.2500 (53.0335)  Acc@5: 87.5000 (87.1135)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1820/4579]  eta: 0:18:09  Lr: 0.030000  Loss: -1.7007  Acc@1: 50.0000 (53.0375)  Acc@5: 93.7500 (87.1396)  time: 0.3944  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1830/4579]  eta: 0:18:05  Lr: 0.030000  Loss: -1.1423  Acc@1: 56.2500 (53.0789)  Acc@5: 93.7500 (87.1655)  time: 0.3950  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1840/4579]  eta: 0:18:01  Lr: 0.030000  Loss: -1.3378  Acc@1: 62.5000 (53.1233)  Acc@5: 93.7500 (87.1877)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1850/4579]  eta: 0:17:57  Lr: 0.030000  Loss: -1.5176  Acc@1: 62.5000 (53.1571)  Acc@5: 87.5000 (87.1927)  time: 0.3942  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [1860/4579]  eta: 0:17:53  Lr: 0.030000  Loss: -1.9824  Acc@1: 68.7500 (53.2375)  Acc@5: 87.5000 (87.2145)  time: 0.3951  data: 0.0010  max mem: 2904
Train: Epoch[1/5]  [1870/4579]  eta: 0:17:49  Lr: 0.030000  Loss: -1.7122  Acc@1: 68.7500 (53.3004)  Acc@5: 93.7500 (87.2394)  time: 0.3926  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [1880/4579]  eta: 0:17:45  Lr: 0.030000  Loss: -1.6260  Acc@1: 62.5000 (53.3659)  Acc@5: 93.7500 (87.2774)  time: 0.3928  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [1890/4579]  eta: 0:17:41  Lr: 0.030000  Loss: -1.8620  Acc@1: 62.5000 (53.4340)  Acc@5: 93.7500 (87.3149)  time: 0.3940  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [1900/4579]  eta: 0:17:37  Lr: 0.030000  Loss: -1.6184  Acc@1: 62.5000 (53.4587)  Acc@5: 93.7500 (87.3389)  time: 0.3947  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1910/4579]  eta: 0:17:33  Lr: 0.030000  Loss: -0.4996  Acc@1: 56.2500 (53.4537)  Acc@5: 87.5000 (87.3365)  time: 0.3974  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [1920/4579]  eta: 0:17:29  Lr: 0.030000  Loss: -1.2063  Acc@1: 62.5000 (53.5138)  Acc@5: 87.5000 (87.3536)  time: 0.3992  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1930/4579]  eta: 0:17:25  Lr: 0.030000  Loss: -1.6600  Acc@1: 62.5000 (53.5571)  Acc@5: 87.5000 (87.3641)  time: 0.3984  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [1940/4579]  eta: 0:17:21  Lr: 0.030000  Loss: -1.9452  Acc@1: 62.5000 (53.5903)  Acc@5: 87.5000 (87.3776)  time: 0.3983  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [1950/4579]  eta: 0:17:18  Lr: 0.030000  Loss: -1.2795  Acc@1: 62.5000 (53.6263)  Acc@5: 87.5000 (87.3847)  time: 0.3978  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [1960/4579]  eta: 0:17:14  Lr: 0.030000  Loss: -1.1605  Acc@1: 62.5000 (53.6812)  Acc@5: 87.5000 (87.3980)  time: 0.3969  data: 0.0013  max mem: 2904
Train: Epoch[1/5]  [1970/4579]  eta: 0:17:10  Lr: 0.030000  Loss: -1.9236  Acc@1: 62.5000 (53.7227)  Acc@5: 93.7500 (87.4239)  time: 0.3970  data: 0.0019  max mem: 2904
Train: Epoch[1/5]  [1980/4579]  eta: 0:17:06  Lr: 0.030000  Loss: -1.1551  Acc@1: 56.2500 (53.7450)  Acc@5: 93.7500 (87.4527)  time: 0.3951  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [1990/4579]  eta: 0:17:02  Lr: 0.030000  Loss: -1.0383  Acc@1: 56.2500 (53.7638)  Acc@5: 93.7500 (87.4655)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2000/4579]  eta: 0:16:58  Lr: 0.030000  Loss: -2.0636  Acc@1: 56.2500 (53.8075)  Acc@5: 93.7500 (87.4813)  time: 0.3942  data: 0.0013  max mem: 2904
Train: Epoch[1/5]  [2010/4579]  eta: 0:16:54  Lr: 0.030000  Loss: -1.3694  Acc@1: 56.2500 (53.8414)  Acc@5: 93.7500 (87.4969)  time: 0.3955  data: 0.0019  max mem: 2904
Train: Epoch[1/5]  [2020/4579]  eta: 0:16:50  Lr: 0.030000  Loss: -1.6257  Acc@1: 62.5000 (53.8997)  Acc@5: 87.5000 (87.5000)  time: 0.3950  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [2030/4579]  eta: 0:16:46  Lr: 0.030000  Loss: -1.3112  Acc@1: 62.5000 (53.9266)  Acc@5: 87.5000 (87.5000)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2040/4579]  eta: 0:16:42  Lr: 0.030000  Loss: -2.1954  Acc@1: 62.5000 (53.9962)  Acc@5: 93.7500 (87.5306)  time: 0.3957  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2050/4579]  eta: 0:16:38  Lr: 0.030000  Loss: -1.6221  Acc@1: 62.5000 (54.0163)  Acc@5: 93.7500 (87.5366)  time: 0.3976  data: 0.0016  max mem: 2904
Train: Epoch[1/5]  [2060/4579]  eta: 0:16:34  Lr: 0.030000  Loss: -0.9693  Acc@1: 68.7500 (54.0939)  Acc@5: 93.7500 (87.5576)  time: 0.3948  data: 0.0022  max mem: 2904
Train: Epoch[1/5]  [2070/4579]  eta: 0:16:30  Lr: 0.030000  Loss: -2.2908  Acc@1: 68.7500 (54.1556)  Acc@5: 93.7500 (87.5815)  time: 0.3973  data: 0.0018  max mem: 2904
Train: Epoch[1/5]  [2080/4579]  eta: 0:16:26  Lr: 0.030000  Loss: -1.7315  Acc@1: 56.2500 (54.1717)  Acc@5: 93.7500 (87.6051)  time: 0.3977  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [2090/4579]  eta: 0:16:22  Lr: 0.030000  Loss: -1.4406  Acc@1: 56.2500 (54.1906)  Acc@5: 93.7500 (87.6196)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2100/4579]  eta: 0:16:18  Lr: 0.030000  Loss: -1.7690  Acc@1: 56.2500 (54.2361)  Acc@5: 93.7500 (87.6428)  time: 0.3959  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2110/4579]  eta: 0:16:14  Lr: 0.030000  Loss: -1.3808  Acc@1: 56.2500 (54.2515)  Acc@5: 87.5000 (87.6243)  time: 0.3974  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2120/4579]  eta: 0:16:11  Lr: 0.030000  Loss: -1.1786  Acc@1: 56.2500 (54.2993)  Acc@5: 93.7500 (87.6621)  time: 0.3965  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2130/4579]  eta: 0:16:07  Lr: 0.030000  Loss: -0.9342  Acc@1: 56.2500 (54.3319)  Acc@5: 93.7500 (87.6584)  time: 0.3975  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2140/4579]  eta: 0:16:03  Lr: 0.030000  Loss: -1.6731  Acc@1: 62.5000 (54.3934)  Acc@5: 93.7500 (87.6810)  time: 0.4008  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [2150/4579]  eta: 0:15:59  Lr: 0.030000  Loss: -1.5766  Acc@1: 68.7500 (54.4456)  Acc@5: 93.7500 (87.7150)  time: 0.4005  data: 0.0010  max mem: 2904
Train: Epoch[1/5]  [2160/4579]  eta: 0:15:55  Lr: 0.030000  Loss: -1.8164  Acc@1: 62.5000 (54.4887)  Acc@5: 93.7500 (87.7285)  time: 0.3967  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [2170/4579]  eta: 0:15:51  Lr: 0.030000  Loss: -1.1159  Acc@1: 62.5000 (54.5198)  Acc@5: 87.5000 (87.7246)  time: 0.3965  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [2180/4579]  eta: 0:15:47  Lr: 0.030000  Loss: -1.1591  Acc@1: 62.5000 (54.5564)  Acc@5: 87.5000 (87.7378)  time: 0.3946  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2190/4579]  eta: 0:15:43  Lr: 0.030000  Loss: -1.9240  Acc@1: 62.5000 (54.5784)  Acc@5: 87.5000 (87.7482)  time: 0.3943  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2200/4579]  eta: 0:15:39  Lr: 0.030000  Loss: -1.3999  Acc@1: 62.5000 (54.6172)  Acc@5: 87.5000 (87.7499)  time: 0.3978  data: 0.0021  max mem: 2904
Train: Epoch[1/5]  [2210/4579]  eta: 0:15:35  Lr: 0.030000  Loss: -1.4789  Acc@1: 62.5000 (54.6416)  Acc@5: 87.5000 (87.7516)  time: 0.4017  data: 0.0034  max mem: 2904
Train: Epoch[1/5]  [2220/4579]  eta: 0:15:31  Lr: 0.030000  Loss: -1.9988  Acc@1: 62.5000 (54.6826)  Acc@5: 93.7500 (87.7730)  time: 0.3996  data: 0.0027  max mem: 2904
Train: Epoch[1/5]  [2230/4579]  eta: 0:15:27  Lr: 0.030000  Loss: -1.6882  Acc@1: 68.7500 (54.7372)  Acc@5: 93.7500 (87.8054)  time: 0.3948  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [2240/4579]  eta: 0:15:24  Lr: 0.030000  Loss: -1.2278  Acc@1: 68.7500 (54.7579)  Acc@5: 93.7500 (87.8235)  time: 0.3973  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2250/4579]  eta: 0:15:20  Lr: 0.030000  Loss: -1.4666  Acc@1: 62.5000 (54.8173)  Acc@5: 93.7500 (87.8526)  time: 0.4005  data: 0.0018  max mem: 2904
Train: Epoch[1/5]  [2260/4579]  eta: 0:15:16  Lr: 0.030000  Loss: -0.9029  Acc@1: 62.5000 (54.8540)  Acc@5: 93.7500 (87.8676)  time: 0.3998  data: 0.0019  max mem: 2904
Train: Epoch[1/5]  [2270/4579]  eta: 0:15:12  Lr: 0.030000  Loss: -1.6420  Acc@1: 62.5000 (54.8822)  Acc@5: 87.5000 (87.8715)  time: 0.3972  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2280/4579]  eta: 0:15:08  Lr: 0.030000  Loss: -1.8040  Acc@1: 62.5000 (54.9293)  Acc@5: 87.5000 (87.8754)  time: 0.3947  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [2290/4579]  eta: 0:15:04  Lr: 0.030000  Loss: -1.6437  Acc@1: 62.5000 (54.9433)  Acc@5: 93.7500 (87.8928)  time: 0.3952  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [2300/4579]  eta: 0:15:00  Lr: 0.030000  Loss: -1.1872  Acc@1: 62.5000 (54.9707)  Acc@5: 93.7500 (87.9020)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2310/4579]  eta: 0:14:56  Lr: 0.030000  Loss: -1.7137  Acc@1: 62.5000 (54.9870)  Acc@5: 87.5000 (87.9165)  time: 0.3972  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [2320/4579]  eta: 0:14:52  Lr: 0.030000  Loss: -1.0217  Acc@1: 56.2500 (55.0059)  Acc@5: 93.7500 (87.9255)  time: 0.4024  data: 0.0014  max mem: 2904
Train: Epoch[1/5]  [2330/4579]  eta: 0:14:48  Lr: 0.030000  Loss: -1.6581  Acc@1: 62.5000 (55.0649)  Acc@5: 93.7500 (87.9344)  time: 0.3990  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [2340/4579]  eta: 0:14:44  Lr: 0.030000  Loss: -1.3739  Acc@1: 68.7500 (55.1207)  Acc@5: 93.7500 (87.9592)  time: 0.3964  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2350/4579]  eta: 0:14:40  Lr: 0.030000  Loss: -1.5156  Acc@1: 62.5000 (55.1494)  Acc@5: 93.7500 (87.9652)  time: 0.3988  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [2360/4579]  eta: 0:14:36  Lr: 0.030000  Loss: -1.9787  Acc@1: 62.5000 (55.1938)  Acc@5: 93.7500 (87.9844)  time: 0.3949  data: 0.0010  max mem: 2904
Train: Epoch[1/5]  [2370/4579]  eta: 0:14:32  Lr: 0.030000  Loss: -1.9642  Acc@1: 62.5000 (55.2220)  Acc@5: 93.7500 (87.9929)  time: 0.3928  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [2380/4579]  eta: 0:14:29  Lr: 0.030000  Loss: -1.3144  Acc@1: 62.5000 (55.2604)  Acc@5: 93.7500 (88.0276)  time: 0.3978  data: 0.0023  max mem: 2904
Train: Epoch[1/5]  [2390/4579]  eta: 0:14:25  Lr: 0.030000  Loss: -1.3671  Acc@1: 62.5000 (55.2959)  Acc@5: 93.7500 (88.0489)  time: 0.3970  data: 0.0024  max mem: 2904
Train: Epoch[1/5]  [2400/4579]  eta: 0:14:21  Lr: 0.030000  Loss: -1.9343  Acc@1: 62.5000 (55.3311)  Acc@5: 93.7500 (88.0466)  time: 0.3950  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [2410/4579]  eta: 0:14:17  Lr: 0.030000  Loss: -1.8258  Acc@1: 68.7500 (55.3790)  Acc@5: 93.7500 (88.0729)  time: 0.3959  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2420/4579]  eta: 0:14:13  Lr: 0.030000  Loss: -1.3053  Acc@1: 62.5000 (55.4162)  Acc@5: 93.7500 (88.0809)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2430/4579]  eta: 0:14:09  Lr: 0.030000  Loss: -1.0078  Acc@1: 62.5000 (55.4453)  Acc@5: 87.5000 (88.0913)  time: 0.3937  data: 0.0015  max mem: 2904
Train: Epoch[1/5]  [2440/4579]  eta: 0:14:05  Lr: 0.030000  Loss: -1.7025  Acc@1: 56.2500 (55.4563)  Acc@5: 87.5000 (88.0787)  time: 0.3937  data: 0.0015  max mem: 2904
Train: Epoch[1/5]  [2450/4579]  eta: 0:14:01  Lr: 0.030000  Loss: -1.8191  Acc@1: 56.2500 (55.4774)  Acc@5: 87.5000 (88.0635)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2460/4579]  eta: 0:13:57  Lr: 0.030000  Loss: -1.2062  Acc@1: 62.5000 (55.5237)  Acc@5: 87.5000 (88.0663)  time: 0.3946  data: 0.0019  max mem: 2904
Train: Epoch[1/5]  [2470/4579]  eta: 0:13:53  Lr: 0.030000  Loss: -1.6232  Acc@1: 62.5000 (55.5393)  Acc@5: 87.5000 (88.0868)  time: 0.4010  data: 0.0026  max mem: 2904
Train: Epoch[1/5]  [2480/4579]  eta: 0:13:49  Lr: 0.030000  Loss: -1.8296  Acc@1: 62.5000 (55.5421)  Acc@5: 87.5000 (88.0718)  time: 0.3982  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [2490/4579]  eta: 0:13:45  Lr: 0.030000  Loss: -2.1150  Acc@1: 62.5000 (55.5701)  Acc@5: 87.5000 (88.0721)  time: 0.3965  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [2500/4579]  eta: 0:13:41  Lr: 0.030000  Loss: -1.8596  Acc@1: 62.5000 (55.6103)  Acc@5: 93.7500 (88.0898)  time: 0.3965  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [2510/4579]  eta: 0:13:37  Lr: 0.030000  Loss: -1.5656  Acc@1: 62.5000 (55.6501)  Acc@5: 93.7500 (88.0974)  time: 0.3947  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [2520/4579]  eta: 0:13:33  Lr: 0.030000  Loss: -1.5325  Acc@1: 62.5000 (55.6922)  Acc@5: 93.7500 (88.1124)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2530/4579]  eta: 0:13:29  Lr: 0.030000  Loss: -1.3093  Acc@1: 62.5000 (55.7141)  Acc@5: 93.7500 (88.1124)  time: 0.3916  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2540/4579]  eta: 0:13:25  Lr: 0.030000  Loss: -1.4991  Acc@1: 62.5000 (55.7212)  Acc@5: 93.7500 (88.1248)  time: 0.3936  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [2550/4579]  eta: 0:13:21  Lr: 0.030000  Loss: -1.7450  Acc@1: 62.5000 (55.7551)  Acc@5: 93.7500 (88.1346)  time: 0.3936  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [2560/4579]  eta: 0:13:17  Lr: 0.030000  Loss: -0.6788  Acc@1: 62.5000 (55.7888)  Acc@5: 87.5000 (88.1296)  time: 0.3932  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2570/4579]  eta: 0:13:13  Lr: 0.030000  Loss: -1.4240  Acc@1: 62.5000 (55.8197)  Acc@5: 87.5000 (88.1272)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2580/4579]  eta: 0:13:09  Lr: 0.030000  Loss: -1.3591  Acc@1: 56.2500 (55.8432)  Acc@5: 93.7500 (88.1441)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2590/4579]  eta: 0:13:05  Lr: 0.030000  Loss: -1.3536  Acc@1: 62.5000 (55.8737)  Acc@5: 93.7500 (88.1682)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2600/4579]  eta: 0:13:01  Lr: 0.030000  Loss: -1.6214  Acc@1: 62.5000 (55.9112)  Acc@5: 93.7500 (88.1848)  time: 0.3927  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2610/4579]  eta: 0:12:57  Lr: 0.030000  Loss: -1.2829  Acc@1: 62.5000 (55.9460)  Acc@5: 93.7500 (88.1846)  time: 0.3930  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2620/4579]  eta: 0:12:53  Lr: 0.030000  Loss: -1.5283  Acc@1: 68.7500 (55.9853)  Acc@5: 93.7500 (88.2011)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2630/4579]  eta: 0:12:49  Lr: 0.030000  Loss: -1.4137  Acc@1: 62.5000 (55.9626)  Acc@5: 87.5000 (88.1842)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2640/4579]  eta: 0:12:46  Lr: 0.030000  Loss: -1.8014  Acc@1: 56.2500 (55.9778)  Acc@5: 87.5000 (88.1910)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2650/4579]  eta: 0:12:42  Lr: 0.030000  Loss: -1.4808  Acc@1: 62.5000 (56.0284)  Acc@5: 93.7500 (88.2002)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2660/4579]  eta: 0:12:38  Lr: 0.030000  Loss: -1.2804  Acc@1: 62.5000 (56.0433)  Acc@5: 87.5000 (88.2023)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2670/4579]  eta: 0:12:34  Lr: 0.030000  Loss: -1.1125  Acc@1: 68.7500 (56.1049)  Acc@5: 87.5000 (88.2207)  time: 0.3941  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2680/4579]  eta: 0:12:30  Lr: 0.030000  Loss: -1.8205  Acc@1: 68.7500 (56.1055)  Acc@5: 93.7500 (88.2227)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2690/4579]  eta: 0:12:26  Lr: 0.030000  Loss: -1.7693  Acc@1: 56.2500 (56.1153)  Acc@5: 87.5000 (88.2270)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2700/4579]  eta: 0:12:22  Lr: 0.030000  Loss: -1.6695  Acc@1: 62.5000 (56.1505)  Acc@5: 93.7500 (88.2382)  time: 0.3959  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2710/4579]  eta: 0:12:18  Lr: 0.030000  Loss: -1.6011  Acc@1: 68.7500 (56.1901)  Acc@5: 93.7500 (88.2631)  time: 0.3960  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2720/4579]  eta: 0:12:14  Lr: 0.030000  Loss: -1.5773  Acc@1: 62.5000 (56.2018)  Acc@5: 93.7500 (88.2810)  time: 0.3950  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2730/4579]  eta: 0:12:10  Lr: 0.030000  Loss: -1.5827  Acc@1: 68.7500 (56.2523)  Acc@5: 93.7500 (88.2850)  time: 0.3945  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [2740/4579]  eta: 0:12:06  Lr: 0.030000  Loss: -1.4379  Acc@1: 68.7500 (56.2682)  Acc@5: 93.7500 (88.2844)  time: 0.3925  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2750/4579]  eta: 0:12:02  Lr: 0.030000  Loss: -0.8919  Acc@1: 62.5000 (56.2909)  Acc@5: 87.5000 (88.2929)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2760/4579]  eta: 0:11:58  Lr: 0.030000  Loss: -1.9254  Acc@1: 62.5000 (56.3066)  Acc@5: 87.5000 (88.3036)  time: 0.3956  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2770/4579]  eta: 0:11:54  Lr: 0.030000  Loss: -1.0810  Acc@1: 62.5000 (56.3425)  Acc@5: 87.5000 (88.3075)  time: 0.3959  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2780/4579]  eta: 0:11:50  Lr: 0.030000  Loss: -1.4206  Acc@1: 62.5000 (56.3534)  Acc@5: 87.5000 (88.3136)  time: 0.3958  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2790/4579]  eta: 0:11:46  Lr: 0.030000  Loss: -1.3393  Acc@1: 62.5000 (56.4000)  Acc@5: 93.7500 (88.3308)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2800/4579]  eta: 0:11:42  Lr: 0.030000  Loss: -2.0389  Acc@1: 68.7500 (56.4374)  Acc@5: 93.7500 (88.3524)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2810/4579]  eta: 0:11:38  Lr: 0.030000  Loss: -1.3717  Acc@1: 62.5000 (56.4501)  Acc@5: 93.7500 (88.3605)  time: 0.3943  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2820/4579]  eta: 0:11:34  Lr: 0.030000  Loss: -1.9271  Acc@1: 62.5000 (56.4871)  Acc@5: 93.7500 (88.3818)  time: 0.3947  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [2830/4579]  eta: 0:11:30  Lr: 0.030000  Loss: -1.6223  Acc@1: 62.5000 (56.5083)  Acc@5: 93.7500 (88.3941)  time: 0.3957  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2840/4579]  eta: 0:11:26  Lr: 0.030000  Loss: -1.5140  Acc@1: 56.2500 (56.5140)  Acc@5: 87.5000 (88.3954)  time: 0.3954  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2850/4579]  eta: 0:11:22  Lr: 0.030000  Loss: -1.2101  Acc@1: 62.5000 (56.5438)  Acc@5: 87.5000 (88.4120)  time: 0.3944  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [2860/4579]  eta: 0:11:19  Lr: 0.030000  Loss: -1.3999  Acc@1: 62.5000 (56.5602)  Acc@5: 93.7500 (88.4197)  time: 0.3936  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2870/4579]  eta: 0:11:15  Lr: 0.030000  Loss: -1.7735  Acc@1: 68.7500 (56.6135)  Acc@5: 93.7500 (88.4361)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2880/4579]  eta: 0:11:11  Lr: 0.030000  Loss: -1.7077  Acc@1: 68.7500 (56.6362)  Acc@5: 93.7500 (88.4524)  time: 0.3948  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2890/4579]  eta: 0:11:07  Lr: 0.030000  Loss: -1.7720  Acc@1: 62.5000 (56.6608)  Acc@5: 93.7500 (88.4620)  time: 0.3957  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2900/4579]  eta: 0:11:03  Lr: 0.030000  Loss: -1.1004  Acc@1: 62.5000 (56.6658)  Acc@5: 93.7500 (88.4544)  time: 0.3946  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [2910/4579]  eta: 0:10:59  Lr: 0.030000  Loss: -0.9230  Acc@1: 56.2500 (56.6622)  Acc@5: 87.5000 (88.4576)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2920/4579]  eta: 0:10:55  Lr: 0.030000  Loss: -1.1265  Acc@1: 56.2500 (56.6458)  Acc@5: 87.5000 (88.4607)  time: 0.3938  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2930/4579]  eta: 0:10:51  Lr: 0.030000  Loss: -0.9242  Acc@1: 56.2500 (56.6722)  Acc@5: 87.5000 (88.4681)  time: 0.3942  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [2940/4579]  eta: 0:10:47  Lr: 0.030000  Loss: -1.6346  Acc@1: 62.5000 (56.6963)  Acc@5: 93.7500 (88.4776)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2950/4579]  eta: 0:10:43  Lr: 0.030000  Loss: -1.2558  Acc@1: 62.5000 (56.7032)  Acc@5: 93.7500 (88.4827)  time: 0.3921  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2960/4579]  eta: 0:10:39  Lr: 0.030000  Loss: -1.8582  Acc@1: 62.5000 (56.7207)  Acc@5: 93.7500 (88.4900)  time: 0.3928  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [2970/4579]  eta: 0:10:35  Lr: 0.030000  Loss: -1.8181  Acc@1: 62.5000 (56.7338)  Acc@5: 87.5000 (88.4908)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [2980/4579]  eta: 0:10:31  Lr: 0.030000  Loss: -1.5838  Acc@1: 62.5000 (56.7742)  Acc@5: 87.5000 (88.5001)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [2990/4579]  eta: 0:10:27  Lr: 0.030000  Loss: -1.3676  Acc@1: 68.7500 (56.8100)  Acc@5: 93.7500 (88.5155)  time: 0.3955  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3000/4579]  eta: 0:10:23  Lr: 0.030000  Loss: -1.6782  Acc@1: 62.5000 (56.8373)  Acc@5: 87.5000 (88.5184)  time: 0.3958  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3010/4579]  eta: 0:10:19  Lr: 0.030000  Loss: -1.4724  Acc@1: 62.5000 (56.8665)  Acc@5: 87.5000 (88.5316)  time: 0.3938  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3020/4579]  eta: 0:10:15  Lr: 0.030000  Loss: -1.5971  Acc@1: 62.5000 (56.8831)  Acc@5: 93.7500 (88.5427)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3030/4579]  eta: 0:10:11  Lr: 0.030000  Loss: -0.9155  Acc@1: 56.2500 (56.8810)  Acc@5: 93.7500 (88.5434)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3040/4579]  eta: 0:10:07  Lr: 0.030000  Loss: -0.7591  Acc@1: 62.5000 (56.8974)  Acc@5: 87.5000 (88.5420)  time: 0.3945  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3050/4579]  eta: 0:10:03  Lr: 0.030000  Loss: -2.0651  Acc@1: 62.5000 (56.9117)  Acc@5: 87.5000 (88.5509)  time: 0.3945  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3060/4579]  eta: 0:09:59  Lr: 0.030000  Loss: -1.8141  Acc@1: 68.7500 (56.9606)  Acc@5: 87.5000 (88.5556)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3070/4579]  eta: 0:09:55  Lr: 0.030000  Loss: -2.2001  Acc@1: 68.7500 (56.9969)  Acc@5: 93.7500 (88.5746)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3080/4579]  eta: 0:09:51  Lr: 0.030000  Loss: -1.6617  Acc@1: 62.5000 (57.0026)  Acc@5: 93.7500 (88.5812)  time: 0.3927  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3090/4579]  eta: 0:09:48  Lr: 0.030000  Loss: -0.6950  Acc@1: 62.5000 (57.0204)  Acc@5: 87.5000 (88.5878)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3100/4579]  eta: 0:09:44  Lr: 0.030000  Loss: -1.5376  Acc@1: 62.5000 (57.0340)  Acc@5: 87.5000 (88.5803)  time: 0.3924  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3110/4579]  eta: 0:09:40  Lr: 0.030000  Loss: -1.3805  Acc@1: 62.5000 (57.0556)  Acc@5: 87.5000 (88.5829)  time: 0.3917  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3120/4579]  eta: 0:09:36  Lr: 0.030000  Loss: -1.7997  Acc@1: 62.5000 (57.0690)  Acc@5: 93.7500 (88.5854)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3130/4579]  eta: 0:09:32  Lr: 0.030000  Loss: -1.2555  Acc@1: 62.5000 (57.0884)  Acc@5: 93.7500 (88.5999)  time: 0.3947  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3140/4579]  eta: 0:09:28  Lr: 0.030000  Loss: -1.5718  Acc@1: 62.5000 (57.0957)  Acc@5: 87.5000 (88.5964)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3150/4579]  eta: 0:09:24  Lr: 0.030000  Loss: -1.8141  Acc@1: 62.5000 (57.1049)  Acc@5: 87.5000 (88.6028)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3160/4579]  eta: 0:09:20  Lr: 0.030000  Loss: -0.8058  Acc@1: 62.5000 (57.1200)  Acc@5: 87.5000 (88.5914)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3170/4579]  eta: 0:09:16  Lr: 0.030000  Loss: -1.4493  Acc@1: 62.5000 (57.1429)  Acc@5: 87.5000 (88.5900)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3180/4579]  eta: 0:09:12  Lr: 0.030000  Loss: -1.2729  Acc@1: 62.5000 (57.1617)  Acc@5: 87.5000 (88.5905)  time: 0.3922  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3190/4579]  eta: 0:09:08  Lr: 0.030000  Loss: -1.0668  Acc@1: 56.2500 (57.1706)  Acc@5: 87.5000 (88.5870)  time: 0.3916  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3200/4579]  eta: 0:09:04  Lr: 0.030000  Loss: -0.9114  Acc@1: 56.2500 (57.1657)  Acc@5: 87.5000 (88.5836)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3210/4579]  eta: 0:09:00  Lr: 0.030000  Loss: -0.6390  Acc@1: 56.2500 (57.1843)  Acc@5: 87.5000 (88.5842)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3220/4579]  eta: 0:08:56  Lr: 0.030000  Loss: -1.7414  Acc@1: 62.5000 (57.1989)  Acc@5: 87.5000 (88.5886)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3230/4579]  eta: 0:08:52  Lr: 0.030000  Loss: -1.5227  Acc@1: 62.5000 (57.2075)  Acc@5: 87.5000 (88.5833)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3240/4579]  eta: 0:08:48  Lr: 0.030000  Loss: -1.9211  Acc@1: 62.5000 (57.2258)  Acc@5: 93.7500 (88.5953)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3250/4579]  eta: 0:08:44  Lr: 0.030000  Loss: -1.7000  Acc@1: 62.5000 (57.2574)  Acc@5: 93.7500 (88.6054)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3260/4579]  eta: 0:08:40  Lr: 0.030000  Loss: -0.5393  Acc@1: 56.2500 (57.2600)  Acc@5: 93.7500 (88.6135)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3270/4579]  eta: 0:08:36  Lr: 0.030000  Loss: -1.3170  Acc@1: 56.2500 (57.2780)  Acc@5: 87.5000 (88.6197)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3280/4579]  eta: 0:08:32  Lr: 0.030000  Loss: -1.6792  Acc@1: 62.5000 (57.2939)  Acc@5: 87.5000 (88.6182)  time: 0.3934  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3290/4579]  eta: 0:08:28  Lr: 0.030000  Loss: -1.2626  Acc@1: 62.5000 (57.3211)  Acc@5: 87.5000 (88.6129)  time: 0.3950  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3300/4579]  eta: 0:08:24  Lr: 0.030000  Loss: -1.7900  Acc@1: 56.2500 (57.3141)  Acc@5: 87.5000 (88.6133)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3310/4579]  eta: 0:08:20  Lr: 0.030000  Loss: -1.7563  Acc@1: 62.5000 (57.3486)  Acc@5: 87.5000 (88.6043)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3320/4579]  eta: 0:08:17  Lr: 0.030000  Loss: -1.4982  Acc@1: 62.5000 (57.3660)  Acc@5: 87.5000 (88.6066)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3330/4579]  eta: 0:08:13  Lr: 0.030000  Loss: -0.6293  Acc@1: 62.5000 (57.3758)  Acc@5: 93.7500 (88.6220)  time: 0.3934  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3340/4579]  eta: 0:08:09  Lr: 0.030000  Loss: -1.4830  Acc@1: 62.5000 (57.4005)  Acc@5: 93.7500 (88.6280)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3350/4579]  eta: 0:08:05  Lr: 0.030000  Loss: -1.7192  Acc@1: 62.5000 (57.4082)  Acc@5: 93.7500 (88.6303)  time: 0.3944  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3360/4579]  eta: 0:08:01  Lr: 0.030000  Loss: -1.5303  Acc@1: 62.5000 (57.4141)  Acc@5: 87.5000 (88.6306)  time: 0.3937  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3370/4579]  eta: 0:07:57  Lr: 0.030000  Loss: -0.9310  Acc@1: 62.5000 (57.4199)  Acc@5: 87.5000 (88.6328)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3380/4579]  eta: 0:07:53  Lr: 0.030000  Loss: -1.7729  Acc@1: 62.5000 (57.4442)  Acc@5: 87.5000 (88.6332)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3390/4579]  eta: 0:07:49  Lr: 0.030000  Loss: -1.4813  Acc@1: 62.5000 (57.4554)  Acc@5: 87.5000 (88.6372)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3400/4579]  eta: 0:07:45  Lr: 0.030000  Loss: -1.8565  Acc@1: 62.5000 (57.4684)  Acc@5: 87.5000 (88.6283)  time: 0.3937  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3410/4579]  eta: 0:07:41  Lr: 0.030000  Loss: -1.6650  Acc@1: 68.7500 (57.5070)  Acc@5: 87.5000 (88.6415)  time: 0.3938  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3420/4579]  eta: 0:07:37  Lr: 0.030000  Loss: -1.7549  Acc@1: 62.5000 (57.5307)  Acc@5: 93.7500 (88.6437)  time: 0.3949  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [3430/4579]  eta: 0:07:33  Lr: 0.030000  Loss: -1.9042  Acc@1: 68.7500 (57.5816)  Acc@5: 93.7500 (88.6604)  time: 0.3955  data: 0.0010  max mem: 2904
Train: Epoch[1/5]  [3440/4579]  eta: 0:07:29  Lr: 0.030000  Loss: -1.8781  Acc@1: 68.7500 (57.6050)  Acc@5: 93.7500 (88.6734)  time: 0.3941  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3450/4579]  eta: 0:07:25  Lr: 0.030000  Loss: -1.7681  Acc@1: 68.7500 (57.6373)  Acc@5: 93.7500 (88.6754)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3460/4579]  eta: 0:07:21  Lr: 0.030000  Loss: -1.2616  Acc@1: 68.7500 (57.6459)  Acc@5: 87.5000 (88.6792)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3470/4579]  eta: 0:07:17  Lr: 0.030000  Loss: -2.1919  Acc@1: 68.7500 (57.6797)  Acc@5: 93.7500 (88.6866)  time: 0.3948  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3480/4579]  eta: 0:07:13  Lr: 0.030000  Loss: -1.5663  Acc@1: 68.7500 (57.7043)  Acc@5: 93.7500 (88.6958)  time: 0.3954  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3490/4579]  eta: 0:07:09  Lr: 0.030000  Loss: -1.2625  Acc@1: 62.5000 (57.7073)  Acc@5: 93.7500 (88.6959)  time: 0.3967  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3500/4579]  eta: 0:07:05  Lr: 0.030000  Loss: -2.2819  Acc@1: 62.5000 (57.7442)  Acc@5: 93.7500 (88.7068)  time: 0.3969  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3510/4579]  eta: 0:07:01  Lr: 0.030000  Loss: -1.6096  Acc@1: 68.7500 (57.7631)  Acc@5: 93.7500 (88.7194)  time: 0.3962  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3520/4579]  eta: 0:06:58  Lr: 0.030000  Loss: -1.6669  Acc@1: 62.5000 (57.7819)  Acc@5: 93.7500 (88.7408)  time: 0.3953  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3530/4579]  eta: 0:06:54  Lr: 0.030000  Loss: -1.0531  Acc@1: 62.5000 (57.7793)  Acc@5: 93.7500 (88.7337)  time: 0.3937  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3540/4579]  eta: 0:06:50  Lr: 0.030000  Loss: -1.8586  Acc@1: 62.5000 (57.8174)  Acc@5: 93.7500 (88.7496)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3550/4579]  eta: 0:06:46  Lr: 0.030000  Loss: -0.8338  Acc@1: 62.5000 (57.8129)  Acc@5: 93.7500 (88.7444)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3560/4579]  eta: 0:06:42  Lr: 0.030000  Loss: -1.2795  Acc@1: 56.2500 (57.8191)  Acc@5: 87.5000 (88.7496)  time: 0.3945  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3570/4579]  eta: 0:06:38  Lr: 0.030000  Loss: -0.7979  Acc@1: 56.2500 (57.8129)  Acc@5: 87.5000 (88.7374)  time: 0.3944  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3580/4579]  eta: 0:06:34  Lr: 0.030000  Loss: -0.8938  Acc@1: 56.2500 (57.8016)  Acc@5: 81.2500 (88.7182)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3590/4579]  eta: 0:06:30  Lr: 0.030000  Loss: -1.7333  Acc@1: 62.5000 (57.8182)  Acc@5: 87.5000 (88.7288)  time: 0.3955  data: 0.0011  max mem: 2904
Train: Epoch[1/5]  [3600/4579]  eta: 0:06:26  Lr: 0.030000  Loss: -1.2600  Acc@1: 62.5000 (57.8329)  Acc@5: 93.7500 (88.7410)  time: 0.3957  data: 0.0012  max mem: 2904
Train: Epoch[1/5]  [3610/4579]  eta: 0:06:22  Lr: 0.030000  Loss: -2.2082  Acc@1: 62.5000 (57.8614)  Acc@5: 93.7500 (88.7514)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3620/4579]  eta: 0:06:18  Lr: 0.030000  Loss: -1.4521  Acc@1: 62.5000 (57.8828)  Acc@5: 87.5000 (88.7531)  time: 0.3944  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3630/4579]  eta: 0:06:14  Lr: 0.030000  Loss: -1.8084  Acc@1: 62.5000 (57.9059)  Acc@5: 87.5000 (88.7548)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3640/4579]  eta: 0:06:10  Lr: 0.030000  Loss: -1.7743  Acc@1: 62.5000 (57.9185)  Acc@5: 87.5000 (88.7531)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3650/4579]  eta: 0:06:06  Lr: 0.030000  Loss: -1.8779  Acc@1: 62.5000 (57.9447)  Acc@5: 93.7500 (88.7634)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3660/4579]  eta: 0:06:02  Lr: 0.030000  Loss: -1.5428  Acc@1: 68.7500 (57.9640)  Acc@5: 93.7500 (88.7599)  time: 0.3943  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3670/4579]  eta: 0:05:58  Lr: 0.030000  Loss: -1.5313  Acc@1: 62.5000 (57.9815)  Acc@5: 93.7500 (88.7820)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3680/4579]  eta: 0:05:54  Lr: 0.030000  Loss: -0.3105  Acc@1: 62.5000 (57.9785)  Acc@5: 93.7500 (88.7887)  time: 0.3940  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3690/4579]  eta: 0:05:50  Lr: 0.030000  Loss: -1.3878  Acc@1: 62.5000 (57.9975)  Acc@5: 93.7500 (88.8022)  time: 0.3943  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3700/4579]  eta: 0:05:46  Lr: 0.030000  Loss: -1.5957  Acc@1: 62.5000 (58.0130)  Acc@5: 93.7500 (88.8105)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3710/4579]  eta: 0:05:42  Lr: 0.030000  Loss: -1.7978  Acc@1: 68.7500 (58.0319)  Acc@5: 87.5000 (88.8052)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3720/4579]  eta: 0:05:39  Lr: 0.030000  Loss: -1.2935  Acc@1: 62.5000 (58.0506)  Acc@5: 87.5000 (88.8068)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3730/4579]  eta: 0:05:35  Lr: 0.030000  Loss: -1.7832  Acc@1: 68.7500 (58.0793)  Acc@5: 93.7500 (88.8200)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3740/4579]  eta: 0:05:31  Lr: 0.030000  Loss: -1.5440  Acc@1: 68.7500 (58.0994)  Acc@5: 93.7500 (88.8332)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3750/4579]  eta: 0:05:27  Lr: 0.030000  Loss: -1.9897  Acc@1: 68.7500 (58.1245)  Acc@5: 93.7500 (88.8530)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3760/4579]  eta: 0:05:23  Lr: 0.030000  Loss: -1.6162  Acc@1: 68.7500 (58.1528)  Acc@5: 93.7500 (88.8544)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3770/4579]  eta: 0:05:19  Lr: 0.030000  Loss: -1.5079  Acc@1: 62.5000 (58.1610)  Acc@5: 93.7500 (88.8640)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3780/4579]  eta: 0:05:15  Lr: 0.030000  Loss: -1.9542  Acc@1: 68.7500 (58.1890)  Acc@5: 93.7500 (88.8770)  time: 0.3925  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [3790/4579]  eta: 0:05:11  Lr: 0.030000  Loss: -1.8890  Acc@1: 68.7500 (58.2053)  Acc@5: 93.7500 (88.8882)  time: 0.3923  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [3800/4579]  eta: 0:05:07  Lr: 0.030000  Loss: -1.3062  Acc@1: 62.5000 (58.2117)  Acc@5: 93.7500 (88.8861)  time: 0.3937  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3810/4579]  eta: 0:05:03  Lr: 0.030000  Loss: -1.7460  Acc@1: 68.7500 (58.2491)  Acc@5: 87.5000 (88.8924)  time: 0.3943  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3820/4579]  eta: 0:04:59  Lr: 0.030000  Loss: -1.8525  Acc@1: 68.7500 (58.2603)  Acc@5: 87.5000 (88.8936)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3830/4579]  eta: 0:04:55  Lr: 0.030000  Loss: -2.1478  Acc@1: 68.7500 (58.2779)  Acc@5: 93.7500 (88.9014)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3840/4579]  eta: 0:04:51  Lr: 0.030000  Loss: -1.5133  Acc@1: 62.5000 (58.2758)  Acc@5: 87.5000 (88.8929)  time: 0.3938  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3850/4579]  eta: 0:04:47  Lr: 0.030000  Loss: -1.5720  Acc@1: 62.5000 (58.2933)  Acc@5: 87.5000 (88.8941)  time: 0.3934  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [3860/4579]  eta: 0:04:43  Lr: 0.030000  Loss: -1.4315  Acc@1: 68.7500 (58.3220)  Acc@5: 93.7500 (88.9067)  time: 0.3922  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:39  Lr: 0.030000  Loss: -1.7428  Acc@1: 62.5000 (58.3312)  Acc@5: 93.7500 (88.9095)  time: 0.3916  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:35  Lr: 0.030000  Loss: -1.1760  Acc@1: 56.2500 (58.3339)  Acc@5: 93.7500 (88.9172)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3890/4579]  eta: 0:04:31  Lr: 0.030000  Loss: -1.8740  Acc@1: 62.5000 (58.3414)  Acc@5: 93.7500 (88.9248)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3900/4579]  eta: 0:04:27  Lr: 0.030000  Loss: -0.9348  Acc@1: 62.5000 (58.3440)  Acc@5: 93.7500 (88.9259)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [3910/4579]  eta: 0:04:23  Lr: 0.030000  Loss: -1.6151  Acc@1: 56.2500 (58.3435)  Acc@5: 93.7500 (88.9303)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3920/4579]  eta: 0:04:20  Lr: 0.030000  Loss: -1.2726  Acc@1: 62.5000 (58.3556)  Acc@5: 93.7500 (88.9362)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3930/4579]  eta: 0:04:16  Lr: 0.030000  Loss: -1.2193  Acc@1: 62.5000 (58.3662)  Acc@5: 87.5000 (88.9357)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3940/4579]  eta: 0:04:12  Lr: 0.030000  Loss: -1.5661  Acc@1: 62.5000 (58.3799)  Acc@5: 93.7500 (88.9463)  time: 0.3958  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3950/4579]  eta: 0:04:08  Lr: 0.030000  Loss: -0.9090  Acc@1: 62.5000 (58.3903)  Acc@5: 87.5000 (88.9411)  time: 0.3963  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3960/4579]  eta: 0:04:04  Lr: 0.030000  Loss: -1.8648  Acc@1: 62.5000 (58.3991)  Acc@5: 87.5000 (88.9453)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3970/4579]  eta: 0:04:00  Lr: 0.030000  Loss: -1.8660  Acc@1: 62.5000 (58.4173)  Acc@5: 93.7500 (88.9559)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [3980/4579]  eta: 0:03:56  Lr: 0.030000  Loss: -1.8314  Acc@1: 68.7500 (58.4432)  Acc@5: 93.7500 (88.9663)  time: 0.3941  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [3990/4579]  eta: 0:03:52  Lr: 0.030000  Loss: -1.4698  Acc@1: 68.7500 (58.4597)  Acc@5: 93.7500 (88.9736)  time: 0.3939  data: 0.0007  max mem: 2904
Train: Epoch[1/5]  [4000/4579]  eta: 0:03:48  Lr: 0.030000  Loss: -0.6187  Acc@1: 62.5000 (58.4619)  Acc@5: 93.7500 (88.9746)  time: 0.3961  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:44  Lr: 0.030000  Loss: -1.6189  Acc@1: 62.5000 (58.4782)  Acc@5: 93.7500 (88.9834)  time: 0.3967  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:40  Lr: 0.030000  Loss: -0.8886  Acc@1: 62.5000 (58.4991)  Acc@5: 93.7500 (88.9937)  time: 0.3948  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:36  Lr: 0.030000  Loss: -1.2767  Acc@1: 62.5000 (58.5122)  Acc@5: 93.7500 (89.0040)  time: 0.3952  data: 0.0008  max mem: 2904
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:32  Lr: 0.030000  Loss: -1.8290  Acc@1: 62.5000 (58.5282)  Acc@5: 93.7500 (89.0080)  time: 0.3973  data: 0.0009  max mem: 2904
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:28  Lr: 0.030000  Loss: -1.2407  Acc@1: 62.5000 (58.5272)  Acc@5: 93.7500 (89.0135)  time: 0.3960  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4060/4579]  eta: 0:03:24  Lr: 0.030000  Loss: -0.6696  Acc@1: 62.5000 (58.5478)  Acc@5: 93.7500 (89.0236)  time: 0.3932  data: 0.0003  max mem: 2904
Train: Epoch[1/5]  [4070/4579]  eta: 0:03:20  Lr: 0.030000  Loss: -1.4235  Acc@1: 68.7500 (58.5759)  Acc@5: 93.7500 (89.0322)  time: 0.3946  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4080/4579]  eta: 0:03:16  Lr: 0.030000  Loss: -1.6222  Acc@1: 62.5000 (58.5763)  Acc@5: 93.7500 (89.0361)  time: 0.3953  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4090/4579]  eta: 0:03:12  Lr: 0.030000  Loss: -1.2609  Acc@1: 62.5000 (58.5890)  Acc@5: 87.5000 (89.0354)  time: 0.3936  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4100/4579]  eta: 0:03:09  Lr: 0.030000  Loss: -1.8018  Acc@1: 68.7500 (58.6016)  Acc@5: 87.5000 (89.0362)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4110/4579]  eta: 0:03:05  Lr: 0.030000  Loss: -1.6345  Acc@1: 62.5000 (58.6034)  Acc@5: 87.5000 (89.0340)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4120/4579]  eta: 0:03:01  Lr: 0.030000  Loss: -1.6221  Acc@1: 56.2500 (58.6023)  Acc@5: 87.5000 (89.0363)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4130/4579]  eta: 0:02:57  Lr: 0.030000  Loss: -1.5645  Acc@1: 62.5000 (58.6193)  Acc@5: 93.7500 (89.0417)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4140/4579]  eta: 0:02:53  Lr: 0.030000  Loss: -2.0119  Acc@1: 62.5000 (58.6241)  Acc@5: 87.5000 (89.0410)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:49  Lr: 0.030000  Loss: -1.6358  Acc@1: 62.5000 (58.6259)  Acc@5: 87.5000 (89.0508)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:45  Lr: 0.030000  Loss: -1.2603  Acc@1: 62.5000 (58.6428)  Acc@5: 93.7500 (89.0546)  time: 0.3925  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:41  Lr: 0.030000  Loss: -1.0040  Acc@1: 62.5000 (58.6445)  Acc@5: 93.7500 (89.0584)  time: 0.3921  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:37  Lr: 0.030000  Loss: -1.4195  Acc@1: 62.5000 (58.6642)  Acc@5: 93.7500 (89.0651)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:33  Lr: 0.030000  Loss: -0.9840  Acc@1: 75.0000 (58.6912)  Acc@5: 93.7500 (89.0748)  time: 0.3962  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:29  Lr: 0.030000  Loss: -1.5199  Acc@1: 68.7500 (58.7048)  Acc@5: 93.7500 (89.0815)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:25  Lr: 0.030000  Loss: -1.6571  Acc@1: 68.7500 (58.7227)  Acc@5: 93.7500 (89.0940)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:21  Lr: 0.030000  Loss: -1.1963  Acc@1: 62.5000 (58.7228)  Acc@5: 93.7500 (89.0962)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:17  Lr: 0.030000  Loss: -1.1352  Acc@1: 62.5000 (58.7228)  Acc@5: 87.5000 (89.0939)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4240/4579]  eta: 0:02:13  Lr: 0.030000  Loss: -1.8055  Acc@1: 62.5000 (58.7538)  Acc@5: 87.5000 (89.0990)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4250/4579]  eta: 0:02:09  Lr: 0.030000  Loss: -1.0743  Acc@1: 68.7500 (58.7759)  Acc@5: 93.7500 (89.1114)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4260/4579]  eta: 0:02:05  Lr: 0.030000  Loss: -2.2459  Acc@1: 68.7500 (58.7934)  Acc@5: 93.7500 (89.1164)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4270/4579]  eta: 0:02:01  Lr: 0.030000  Loss: -1.6083  Acc@1: 68.7500 (58.8211)  Acc@5: 93.7500 (89.1258)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4280/4579]  eta: 0:01:57  Lr: 0.030000  Loss: -1.8270  Acc@1: 68.7500 (58.8356)  Acc@5: 93.7500 (89.1337)  time: 0.3935  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:54  Lr: 0.030000  Loss: -0.8585  Acc@1: 68.7500 (58.8528)  Acc@5: 93.7500 (89.1444)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:50  Lr: 0.030000  Loss: -1.3294  Acc@1: 62.5000 (58.8540)  Acc@5: 87.5000 (89.1319)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:46  Lr: 0.030000  Loss: -1.4014  Acc@1: 56.2500 (58.8582)  Acc@5: 87.5000 (89.1339)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:42  Lr: 0.030000  Loss: -1.3388  Acc@1: 62.5000 (58.8724)  Acc@5: 93.7500 (89.1330)  time: 0.3951  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:38  Lr: 0.030000  Loss: -0.4868  Acc@1: 62.5000 (58.8793)  Acc@5: 93.7500 (89.1422)  time: 0.3953  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:34  Lr: 0.030000  Loss: -1.8400  Acc@1: 68.7500 (58.8934)  Acc@5: 93.7500 (89.1471)  time: 0.3957  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:30  Lr: 0.030000  Loss: -1.1206  Acc@1: 68.7500 (58.9103)  Acc@5: 93.7500 (89.1519)  time: 0.3943  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:26  Lr: 0.030000  Loss: -1.5799  Acc@1: 62.5000 (58.9185)  Acc@5: 87.5000 (89.1453)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:22  Lr: 0.030000  Loss: -1.7804  Acc@1: 62.5000 (58.9425)  Acc@5: 87.5000 (89.1515)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:18  Lr: 0.030000  Loss: -1.5922  Acc@1: 62.5000 (58.9520)  Acc@5: 87.5000 (89.1449)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:14  Lr: 0.030000  Loss: -1.5513  Acc@1: 56.2500 (58.9558)  Acc@5: 87.5000 (89.1397)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:10  Lr: 0.030000  Loss: -1.4263  Acc@1: 62.5000 (58.9752)  Acc@5: 87.5000 (89.1488)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4410/4579]  eta: 0:01:06  Lr: 0.030000  Loss: -1.4445  Acc@1: 68.7500 (58.9804)  Acc@5: 87.5000 (89.1422)  time: 0.3934  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4420/4579]  eta: 0:01:02  Lr: 0.030000  Loss: -1.2448  Acc@1: 62.5000 (58.9869)  Acc@5: 87.5000 (89.1441)  time: 0.3928  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4430/4579]  eta: 0:00:58  Lr: 0.030000  Loss: -1.9845  Acc@1: 62.5000 (58.9977)  Acc@5: 93.7500 (89.1475)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:54  Lr: 0.030000  Loss: -1.3621  Acc@1: 62.5000 (59.0070)  Acc@5: 93.7500 (89.1494)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:50  Lr: 0.030000  Loss: -1.5352  Acc@1: 68.7500 (59.0275)  Acc@5: 93.7500 (89.1569)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:46  Lr: 0.030000  Loss: -1.5493  Acc@1: 68.7500 (59.0465)  Acc@5: 87.5000 (89.1560)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:42  Lr: 0.030000  Loss: -1.5421  Acc@1: 62.5000 (59.0654)  Acc@5: 93.7500 (89.1663)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:39  Lr: 0.030000  Loss: -1.5517  Acc@1: 62.5000 (59.0730)  Acc@5: 93.7500 (89.1668)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:35  Lr: 0.030000  Loss: -1.7795  Acc@1: 62.5000 (59.0807)  Acc@5: 93.7500 (89.1756)  time: 0.3943  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:31  Lr: 0.030000  Loss: -2.0100  Acc@1: 62.5000 (59.0966)  Acc@5: 93.7500 (89.1830)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:27  Lr: 0.030000  Loss: -1.4101  Acc@1: 62.5000 (59.1097)  Acc@5: 93.7500 (89.1820)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:23  Lr: 0.030000  Loss: -1.5640  Acc@1: 68.7500 (59.1365)  Acc@5: 87.5000 (89.1810)  time: 0.3936  data: 0.0006  max mem: 2904
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:19  Lr: 0.030000  Loss: -1.2186  Acc@1: 68.7500 (59.1508)  Acc@5: 93.7500 (89.1884)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:15  Lr: 0.030000  Loss: -1.8720  Acc@1: 62.5000 (59.1541)  Acc@5: 93.7500 (89.1902)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:11  Lr: 0.030000  Loss: -1.2900  Acc@1: 62.5000 (59.1656)  Acc@5: 93.7500 (89.1988)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:07  Lr: 0.030000  Loss: -2.1444  Acc@1: 68.7500 (59.1797)  Acc@5: 93.7500 (89.2033)  time: 0.3969  data: 0.0021  max mem: 2904
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: -1.5727  Acc@1: 62.5000 (59.2034)  Acc@5: 93.7500 (89.2064)  time: 0.3981  data: 0.0027  max mem: 2904
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: -2.2775  Acc@1: 62.5000 (59.2203)  Acc@5: 93.7500 (89.2092)  time: 0.3908  data: 0.0010  max mem: 2904
Train: Epoch[1/5] Total time: 0:30:07 (0.3946 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.2775  Acc@1: 62.5000 (59.2203)  Acc@5: 93.7500 (89.2092)
Train: Epoch[2/5]  [   0/4579]  eta: 1:02:00  Lr: 0.030000  Loss: -1.8454  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.8125  data: 0.4179  max mem: 2904
Train: Epoch[2/5]  [  10/4579]  eta: 0:32:50  Lr: 0.030000  Loss: -2.1441  Acc@1: 68.7500 (64.7727)  Acc@5: 93.7500 (91.4773)  time: 0.4312  data: 0.0383  max mem: 2904
Train: Epoch[2/5]  [  20/4579]  eta: 0:31:19  Lr: 0.030000  Loss: -1.1403  Acc@1: 68.7500 (65.7738)  Acc@5: 93.7500 (91.9643)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [  30/4579]  eta: 0:30:45  Lr: 0.030000  Loss: -1.7021  Acc@1: 68.7500 (65.5242)  Acc@5: 93.7500 (90.7258)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [  40/4579]  eta: 0:30:24  Lr: 0.030000  Loss: -1.4575  Acc@1: 75.0000 (67.2256)  Acc@5: 93.7500 (91.6159)  time: 0.3912  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [  50/4579]  eta: 0:30:16  Lr: 0.030000  Loss: -0.3967  Acc@1: 68.7500 (66.6667)  Acc@5: 93.7500 (90.8088)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [  60/4579]  eta: 0:30:05  Lr: 0.030000  Loss: -1.8403  Acc@1: 62.5000 (65.9836)  Acc@5: 87.5000 (90.4713)  time: 0.3948  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [  70/4579]  eta: 0:29:57  Lr: 0.030000  Loss: -1.0703  Acc@1: 68.7500 (65.8451)  Acc@5: 93.7500 (90.4930)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [  80/4579]  eta: 0:29:49  Lr: 0.030000  Loss: -1.5477  Acc@1: 56.2500 (64.8920)  Acc@5: 93.7500 (89.9691)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [  90/4579]  eta: 0:29:43  Lr: 0.030000  Loss: -1.0297  Acc@1: 62.5000 (64.8352)  Acc@5: 87.5000 (89.7665)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 100/4579]  eta: 0:29:38  Lr: 0.030000  Loss: -1.5723  Acc@1: 62.5000 (64.9134)  Acc@5: 93.7500 (90.0371)  time: 0.3938  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 110/4579]  eta: 0:29:31  Lr: 0.030000  Loss: -1.8612  Acc@1: 68.7500 (65.6532)  Acc@5: 93.7500 (90.3153)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 120/4579]  eta: 0:29:26  Lr: 0.030000  Loss: -1.3350  Acc@1: 68.7500 (65.8574)  Acc@5: 93.7500 (90.5992)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 130/4579]  eta: 0:29:20  Lr: 0.030000  Loss: -1.2048  Acc@1: 62.5000 (65.9351)  Acc@5: 93.7500 (90.7443)  time: 0.3914  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 140/4579]  eta: 0:29:15  Lr: 0.030000  Loss: -1.5578  Acc@1: 62.5000 (65.9574)  Acc@5: 93.7500 (90.8688)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 150/4579]  eta: 0:29:10  Lr: 0.030000  Loss: -1.6512  Acc@1: 62.5000 (65.4801)  Acc@5: 93.7500 (90.8526)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 160/4579]  eta: 0:29:05  Lr: 0.030000  Loss: -1.2967  Acc@1: 62.5000 (65.4503)  Acc@5: 93.7500 (90.8773)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 170/4579]  eta: 0:29:00  Lr: 0.030000  Loss: -1.7023  Acc@1: 62.5000 (65.6433)  Acc@5: 93.7500 (90.8991)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 180/4579]  eta: 0:28:55  Lr: 0.030000  Loss: -1.7759  Acc@1: 62.5000 (65.5732)  Acc@5: 93.7500 (90.8149)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[2/5]  [ 190/4579]  eta: 0:28:51  Lr: 0.030000  Loss: -1.1487  Acc@1: 62.5000 (65.3469)  Acc@5: 93.7500 (90.7723)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 200/4579]  eta: 0:28:46  Lr: 0.030000  Loss: -1.1978  Acc@1: 56.2500 (65.1119)  Acc@5: 93.7500 (90.9204)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 210/4579]  eta: 0:28:42  Lr: 0.030000  Loss: -1.5413  Acc@1: 56.2500 (64.9882)  Acc@5: 87.5000 (90.6991)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 220/4579]  eta: 0:28:37  Lr: 0.030000  Loss: -1.5662  Acc@1: 68.7500 (65.2432)  Acc@5: 93.7500 (90.8654)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 230/4579]  eta: 0:28:33  Lr: 0.030000  Loss: -1.3552  Acc@1: 68.7500 (65.2056)  Acc@5: 93.7500 (90.7468)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 240/4579]  eta: 0:28:28  Lr: 0.030000  Loss: -1.6984  Acc@1: 68.7500 (65.3786)  Acc@5: 87.5000 (90.8973)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 250/4579]  eta: 0:28:24  Lr: 0.030000  Loss: -1.7552  Acc@1: 62.5000 (65.3884)  Acc@5: 93.7500 (90.8616)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 260/4579]  eta: 0:28:19  Lr: 0.030000  Loss: -1.4134  Acc@1: 62.5000 (65.3496)  Acc@5: 93.7500 (90.8764)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 270/4579]  eta: 0:28:15  Lr: 0.030000  Loss: -1.9052  Acc@1: 68.7500 (65.6596)  Acc@5: 93.7500 (90.9594)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 280/4579]  eta: 0:28:11  Lr: 0.030000  Loss: -1.0370  Acc@1: 68.7500 (65.7696)  Acc@5: 93.7500 (91.1032)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 290/4579]  eta: 0:28:07  Lr: 0.030000  Loss: -1.4628  Acc@1: 62.5000 (65.7646)  Acc@5: 93.7500 (91.0653)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 300/4579]  eta: 0:28:03  Lr: 0.030000  Loss: -1.2921  Acc@1: 62.5000 (65.6977)  Acc@5: 93.7500 (91.0299)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 310/4579]  eta: 0:27:59  Lr: 0.030000  Loss: -1.5744  Acc@1: 56.2500 (65.6953)  Acc@5: 93.7500 (91.0571)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 320/4579]  eta: 0:27:55  Lr: 0.030000  Loss: -1.0739  Acc@1: 62.5000 (65.6153)  Acc@5: 87.5000 (90.9657)  time: 0.3949  data: 0.0019  max mem: 2904
Train: Epoch[2/5]  [ 330/4579]  eta: 0:27:52  Lr: 0.030000  Loss: -1.5572  Acc@1: 62.5000 (65.5589)  Acc@5: 87.5000 (90.9743)  time: 0.3966  data: 0.0019  max mem: 2904
Train: Epoch[2/5]  [ 340/4579]  eta: 0:27:48  Lr: 0.030000  Loss: -1.3080  Acc@1: 62.5000 (65.4875)  Acc@5: 93.7500 (91.0007)  time: 0.3959  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 350/4579]  eta: 0:27:44  Lr: 0.030000  Loss: -1.4667  Acc@1: 62.5000 (65.4558)  Acc@5: 93.7500 (91.0256)  time: 0.3954  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 360/4579]  eta: 0:27:40  Lr: 0.030000  Loss: -2.1281  Acc@1: 68.7500 (65.6337)  Acc@5: 93.7500 (91.1877)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 370/4579]  eta: 0:27:36  Lr: 0.030000  Loss: -1.5871  Acc@1: 68.7500 (65.6840)  Acc@5: 93.7500 (91.1725)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 380/4579]  eta: 0:27:32  Lr: 0.030000  Loss: -1.4264  Acc@1: 62.5000 (65.5840)  Acc@5: 87.5000 (91.1417)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 390/4579]  eta: 0:27:28  Lr: 0.030000  Loss: -0.7881  Acc@1: 62.5000 (65.3133)  Acc@5: 93.7500 (91.1285)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 400/4579]  eta: 0:27:24  Lr: 0.030000  Loss: -1.3847  Acc@1: 62.5000 (65.3522)  Acc@5: 93.7500 (91.2095)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 410/4579]  eta: 0:27:20  Lr: 0.030000  Loss: -2.1487  Acc@1: 62.5000 (65.4349)  Acc@5: 93.7500 (91.2561)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 420/4579]  eta: 0:27:16  Lr: 0.030000  Loss: -1.2755  Acc@1: 62.5000 (65.3949)  Acc@5: 93.7500 (91.2856)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 430/4579]  eta: 0:27:13  Lr: 0.030000  Loss: -1.1670  Acc@1: 56.2500 (65.3277)  Acc@5: 93.7500 (91.2993)  time: 0.3955  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [ 440/4579]  eta: 0:27:09  Lr: 0.030000  Loss: -1.3700  Acc@1: 68.7500 (65.3912)  Acc@5: 93.7500 (91.3690)  time: 0.3946  data: 0.0013  max mem: 2904
Train: Epoch[2/5]  [ 450/4579]  eta: 0:27:05  Lr: 0.030000  Loss: -2.0540  Acc@1: 68.7500 (65.3963)  Acc@5: 93.7500 (91.3525)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 460/4579]  eta: 0:27:01  Lr: 0.030000  Loss: -1.7819  Acc@1: 68.7500 (65.3471)  Acc@5: 93.7500 (91.3910)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 470/4579]  eta: 0:26:57  Lr: 0.030000  Loss: -0.9845  Acc@1: 68.7500 (65.3264)  Acc@5: 93.7500 (91.3615)  time: 0.3944  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 480/4579]  eta: 0:26:53  Lr: 0.030000  Loss: -1.3039  Acc@1: 62.5000 (65.3067)  Acc@5: 93.7500 (91.3721)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 490/4579]  eta: 0:26:49  Lr: 0.030000  Loss: -1.1307  Acc@1: 62.5000 (65.3259)  Acc@5: 87.5000 (91.3442)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 500/4579]  eta: 0:26:45  Lr: 0.030000  Loss: -1.3909  Acc@1: 68.7500 (65.4067)  Acc@5: 87.5000 (91.3423)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 510/4579]  eta: 0:26:40  Lr: 0.030000  Loss: -1.7916  Acc@1: 68.7500 (65.4843)  Acc@5: 93.7500 (91.3650)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 520/4579]  eta: 0:26:36  Lr: 0.030000  Loss: -1.5682  Acc@1: 68.7500 (65.5830)  Acc@5: 93.7500 (91.3988)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 530/4579]  eta: 0:26:32  Lr: 0.030000  Loss: -0.8257  Acc@1: 68.7500 (65.5014)  Acc@5: 87.5000 (91.3842)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 540/4579]  eta: 0:26:28  Lr: 0.030000  Loss: -1.8864  Acc@1: 68.7500 (65.6770)  Acc@5: 93.7500 (91.4164)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 550/4579]  eta: 0:26:24  Lr: 0.030000  Loss: -1.1694  Acc@1: 68.7500 (65.7101)  Acc@5: 93.7500 (91.3907)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 560/4579]  eta: 0:26:21  Lr: 0.030000  Loss: -1.7173  Acc@1: 62.5000 (65.6306)  Acc@5: 93.7500 (91.3659)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 570/4579]  eta: 0:26:17  Lr: 0.030000  Loss: -1.8444  Acc@1: 62.5000 (65.6305)  Acc@5: 87.5000 (91.2763)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 580/4579]  eta: 0:26:12  Lr: 0.030000  Loss: -2.0273  Acc@1: 62.5000 (65.7164)  Acc@5: 93.7500 (91.3296)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 590/4579]  eta: 0:26:08  Lr: 0.030000  Loss: -1.6560  Acc@1: 68.7500 (65.7149)  Acc@5: 93.7500 (91.2437)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 600/4579]  eta: 0:26:04  Lr: 0.030000  Loss: -1.7813  Acc@1: 62.5000 (65.5886)  Acc@5: 93.7500 (91.2958)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 610/4579]  eta: 0:26:00  Lr: 0.030000  Loss: -1.4765  Acc@1: 62.5000 (65.5381)  Acc@5: 93.7500 (91.2848)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 620/4579]  eta: 0:25:57  Lr: 0.030000  Loss: -1.4392  Acc@1: 62.5000 (65.4992)  Acc@5: 87.5000 (91.2742)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 630/4579]  eta: 0:25:53  Lr: 0.030000  Loss: -1.9981  Acc@1: 62.5000 (65.5408)  Acc@5: 93.7500 (91.3332)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 640/4579]  eta: 0:25:49  Lr: 0.030000  Loss: -2.4061  Acc@1: 62.5000 (65.5616)  Acc@5: 93.7500 (91.3807)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 650/4579]  eta: 0:25:45  Lr: 0.030000  Loss: -1.5969  Acc@1: 62.5000 (65.6010)  Acc@5: 93.7500 (91.3786)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 660/4579]  eta: 0:25:41  Lr: 0.030000  Loss: -2.0739  Acc@1: 75.0000 (65.6581)  Acc@5: 93.7500 (91.3956)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 670/4579]  eta: 0:25:37  Lr: 0.030000  Loss: -1.8312  Acc@1: 68.7500 (65.6297)  Acc@5: 93.7500 (91.3841)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 680/4579]  eta: 0:25:33  Lr: 0.030000  Loss: -1.3939  Acc@1: 62.5000 (65.5929)  Acc@5: 87.5000 (91.3271)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 690/4579]  eta: 0:25:29  Lr: 0.030000  Loss: -1.7045  Acc@1: 56.2500 (65.4848)  Acc@5: 93.7500 (91.3350)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 700/4579]  eta: 0:25:25  Lr: 0.030000  Loss: -1.8894  Acc@1: 68.7500 (65.5849)  Acc@5: 93.7500 (91.3249)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 710/4579]  eta: 0:25:21  Lr: 0.030000  Loss: -0.9614  Acc@1: 68.7500 (65.6206)  Acc@5: 93.7500 (91.3678)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 720/4579]  eta: 0:25:17  Lr: 0.030000  Loss: -0.8971  Acc@1: 68.7500 (65.6727)  Acc@5: 93.7500 (91.3662)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 730/4579]  eta: 0:25:13  Lr: 0.030000  Loss: -1.6355  Acc@1: 68.7500 (65.6891)  Acc@5: 93.7500 (91.3902)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 740/4579]  eta: 0:25:08  Lr: 0.030000  Loss: -1.6789  Acc@1: 68.7500 (65.7642)  Acc@5: 93.7500 (91.4474)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 750/4579]  eta: 0:25:04  Lr: 0.030000  Loss: -1.4973  Acc@1: 62.5000 (65.7041)  Acc@5: 93.7500 (91.4780)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 760/4579]  eta: 0:25:00  Lr: 0.030000  Loss: -1.3213  Acc@1: 56.2500 (65.6045)  Acc@5: 93.7500 (91.4997)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 770/4579]  eta: 0:24:56  Lr: 0.030000  Loss: -1.6680  Acc@1: 62.5000 (65.6047)  Acc@5: 93.7500 (91.5126)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 780/4579]  eta: 0:24:53  Lr: 0.030000  Loss: -1.1728  Acc@1: 62.5000 (65.5090)  Acc@5: 93.7500 (91.4853)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 790/4579]  eta: 0:24:49  Lr: 0.030000  Loss: -1.3607  Acc@1: 62.5000 (65.5341)  Acc@5: 87.5000 (91.4507)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 800/4579]  eta: 0:24:44  Lr: 0.030000  Loss: -1.2283  Acc@1: 62.5000 (65.4494)  Acc@5: 87.5000 (91.4638)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 810/4579]  eta: 0:24:41  Lr: 0.030000  Loss: -1.4730  Acc@1: 56.2500 (65.3668)  Acc@5: 87.5000 (91.4457)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 820/4579]  eta: 0:24:37  Lr: 0.030000  Loss: -1.3830  Acc@1: 56.2500 (65.3167)  Acc@5: 87.5000 (91.4205)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 830/4579]  eta: 0:24:33  Lr: 0.030000  Loss: -0.8443  Acc@1: 62.5000 (65.3204)  Acc@5: 87.5000 (91.4185)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [ 840/4579]  eta: 0:24:29  Lr: 0.030000  Loss: -1.5512  Acc@1: 62.5000 (65.3760)  Acc@5: 93.7500 (91.4685)  time: 0.3954  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [ 850/4579]  eta: 0:24:25  Lr: 0.030000  Loss: -1.5633  Acc@1: 62.5000 (65.3422)  Acc@5: 93.7500 (91.4953)  time: 0.3937  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [ 860/4579]  eta: 0:24:21  Lr: 0.030000  Loss: -2.0386  Acc@1: 62.5000 (65.3600)  Acc@5: 93.7500 (91.4925)  time: 0.3926  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [ 870/4579]  eta: 0:24:17  Lr: 0.030000  Loss: -0.7582  Acc@1: 62.5000 (65.3487)  Acc@5: 93.7500 (91.5327)  time: 0.3932  data: 0.0013  max mem: 2904
Train: Epoch[2/5]  [ 880/4579]  eta: 0:24:13  Lr: 0.030000  Loss: -1.5432  Acc@1: 68.7500 (65.3944)  Acc@5: 93.7500 (91.5508)  time: 0.3930  data: 0.0011  max mem: 2904
Train: Epoch[2/5]  [ 890/4579]  eta: 0:24:09  Lr: 0.030000  Loss: -1.6184  Acc@1: 68.7500 (65.3900)  Acc@5: 93.7500 (91.5755)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 900/4579]  eta: 0:24:05  Lr: 0.030000  Loss: -1.9580  Acc@1: 62.5000 (65.3926)  Acc@5: 93.7500 (91.5996)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 910/4579]  eta: 0:24:01  Lr: 0.030000  Loss: -1.1827  Acc@1: 68.7500 (65.4295)  Acc@5: 93.7500 (91.5683)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 920/4579]  eta: 0:23:57  Lr: 0.030000  Loss: -1.4622  Acc@1: 68.7500 (65.4452)  Acc@5: 93.7500 (91.5852)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 930/4579]  eta: 0:23:54  Lr: 0.030000  Loss: -1.9047  Acc@1: 62.5000 (65.4135)  Acc@5: 93.7500 (91.5749)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 940/4579]  eta: 0:23:50  Lr: 0.030000  Loss: -1.2398  Acc@1: 62.5000 (65.4291)  Acc@5: 93.7500 (91.5848)  time: 0.3935  data: 0.0003  max mem: 2904
Train: Epoch[2/5]  [ 950/4579]  eta: 0:23:46  Lr: 0.030000  Loss: -1.4914  Acc@1: 68.7500 (65.4180)  Acc@5: 93.7500 (91.5878)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [ 960/4579]  eta: 0:23:42  Lr: 0.030000  Loss: -1.7679  Acc@1: 68.7500 (65.4136)  Acc@5: 93.7500 (91.5843)  time: 0.3937  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 970/4579]  eta: 0:23:38  Lr: 0.030000  Loss: -1.8009  Acc@1: 68.7500 (65.5124)  Acc@5: 93.7500 (91.6323)  time: 0.3956  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 980/4579]  eta: 0:23:34  Lr: 0.030000  Loss: -1.4044  Acc@1: 68.7500 (65.4689)  Acc@5: 93.7500 (91.6603)  time: 0.3979  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [ 990/4579]  eta: 0:23:30  Lr: 0.030000  Loss: -1.5592  Acc@1: 62.5000 (65.4831)  Acc@5: 93.7500 (91.6688)  time: 0.3953  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1000/4579]  eta: 0:23:26  Lr: 0.030000  Loss: -1.3605  Acc@1: 62.5000 (65.4845)  Acc@5: 93.7500 (91.6958)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1010/4579]  eta: 0:23:23  Lr: 0.030000  Loss: -1.0413  Acc@1: 62.5000 (65.4983)  Acc@5: 93.7500 (91.7285)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1020/4579]  eta: 0:23:19  Lr: 0.030000  Loss: -1.5044  Acc@1: 62.5000 (65.4873)  Acc@5: 93.7500 (91.6993)  time: 0.3944  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1030/4579]  eta: 0:23:15  Lr: 0.030000  Loss: -1.4328  Acc@1: 62.5000 (65.4522)  Acc@5: 87.5000 (91.6889)  time: 0.3943  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1040/4579]  eta: 0:23:11  Lr: 0.030000  Loss: -1.5844  Acc@1: 68.7500 (65.4659)  Acc@5: 93.7500 (91.7087)  time: 0.3940  data: 0.0011  max mem: 2904
Train: Epoch[2/5]  [1050/4579]  eta: 0:23:07  Lr: 0.030000  Loss: -1.9002  Acc@1: 68.7500 (65.5209)  Acc@5: 93.7500 (91.7519)  time: 0.3939  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [1060/4579]  eta: 0:23:03  Lr: 0.030000  Loss: -1.3492  Acc@1: 68.7500 (65.5219)  Acc@5: 93.7500 (91.7825)  time: 0.3938  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1070/4579]  eta: 0:22:59  Lr: 0.030000  Loss: -1.8517  Acc@1: 68.7500 (65.5404)  Acc@5: 93.7500 (91.7892)  time: 0.3938  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1080/4579]  eta: 0:22:55  Lr: 0.030000  Loss: -2.1058  Acc@1: 62.5000 (65.5238)  Acc@5: 93.7500 (91.7784)  time: 0.3942  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1090/4579]  eta: 0:22:51  Lr: 0.030000  Loss: -0.9333  Acc@1: 62.5000 (65.4789)  Acc@5: 93.7500 (91.7679)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1100/4579]  eta: 0:22:47  Lr: 0.030000  Loss: -1.5585  Acc@1: 62.5000 (65.5257)  Acc@5: 93.7500 (91.7518)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1110/4579]  eta: 0:22:44  Lr: 0.030000  Loss: -1.5738  Acc@1: 68.7500 (65.4984)  Acc@5: 87.5000 (91.7192)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1120/4579]  eta: 0:22:40  Lr: 0.030000  Loss: -1.5041  Acc@1: 62.5000 (65.4550)  Acc@5: 87.5000 (91.6983)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1130/4579]  eta: 0:22:36  Lr: 0.030000  Loss: -2.3346  Acc@1: 62.5000 (65.4896)  Acc@5: 93.7500 (91.7385)  time: 0.3949  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1140/4579]  eta: 0:22:32  Lr: 0.030000  Loss: -1.7186  Acc@1: 68.7500 (65.5346)  Acc@5: 93.7500 (91.7397)  time: 0.3942  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1150/4579]  eta: 0:22:28  Lr: 0.030000  Loss: -2.0147  Acc@1: 75.0000 (65.5951)  Acc@5: 93.7500 (91.7735)  time: 0.3937  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [1160/4579]  eta: 0:22:24  Lr: 0.030000  Loss: -1.6368  Acc@1: 75.0000 (65.6869)  Acc@5: 93.7500 (91.7959)  time: 0.3941  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [1170/4579]  eta: 0:22:20  Lr: 0.030000  Loss: -1.8839  Acc@1: 75.0000 (65.6810)  Acc@5: 93.7500 (91.7912)  time: 0.3958  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1180/4579]  eta: 0:22:16  Lr: 0.030000  Loss: -2.2341  Acc@1: 68.7500 (65.7017)  Acc@5: 93.7500 (91.7760)  time: 0.3967  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1190/4579]  eta: 0:22:12  Lr: 0.030000  Loss: -2.3675  Acc@1: 62.5000 (65.6434)  Acc@5: 87.5000 (91.7664)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1200/4579]  eta: 0:22:08  Lr: 0.030000  Loss: -1.4800  Acc@1: 68.7500 (65.6744)  Acc@5: 93.7500 (91.7829)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1210/4579]  eta: 0:22:04  Lr: 0.030000  Loss: -1.4568  Acc@1: 68.7500 (65.6431)  Acc@5: 87.5000 (91.7320)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1220/4579]  eta: 0:22:01  Lr: 0.030000  Loss: -1.3859  Acc@1: 62.5000 (65.6071)  Acc@5: 87.5000 (91.7179)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1230/4579]  eta: 0:21:57  Lr: 0.030000  Loss: -1.4667  Acc@1: 62.5000 (65.6225)  Acc@5: 93.7500 (91.7090)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1240/4579]  eta: 0:21:53  Lr: 0.030000  Loss: -1.5939  Acc@1: 68.7500 (65.6426)  Acc@5: 93.7500 (91.7053)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1250/4579]  eta: 0:21:49  Lr: 0.030000  Loss: -1.0006  Acc@1: 68.7500 (65.6775)  Acc@5: 93.7500 (91.7166)  time: 0.3939  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1260/4579]  eta: 0:21:45  Lr: 0.030000  Loss: -1.4738  Acc@1: 62.5000 (65.6622)  Acc@5: 93.7500 (91.7080)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1270/4579]  eta: 0:21:41  Lr: 0.030000  Loss: -1.3887  Acc@1: 62.5000 (65.6422)  Acc@5: 87.5000 (91.6699)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1280/4579]  eta: 0:21:37  Lr: 0.030000  Loss: -1.8344  Acc@1: 62.5000 (65.6372)  Acc@5: 87.5000 (91.6569)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1290/4579]  eta: 0:21:33  Lr: 0.030000  Loss: -1.7460  Acc@1: 62.5000 (65.5935)  Acc@5: 87.5000 (91.6296)  time: 0.3944  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1300/4579]  eta: 0:21:29  Lr: 0.030000  Loss: -2.1569  Acc@1: 62.5000 (65.6034)  Acc@5: 93.7500 (91.6458)  time: 0.3966  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1310/4579]  eta: 0:21:25  Lr: 0.030000  Loss: -1.1192  Acc@1: 68.7500 (65.6226)  Acc@5: 93.7500 (91.6476)  time: 0.3986  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1320/4579]  eta: 0:21:22  Lr: 0.030000  Loss: -1.1403  Acc@1: 68.7500 (65.6368)  Acc@5: 93.7500 (91.6588)  time: 0.3976  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [1330/4579]  eta: 0:21:18  Lr: 0.030000  Loss: -1.0057  Acc@1: 62.5000 (65.5522)  Acc@5: 93.7500 (91.6369)  time: 0.3937  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1340/4579]  eta: 0:21:14  Lr: 0.030000  Loss: -0.7616  Acc@1: 62.5000 (65.5388)  Acc@5: 87.5000 (91.6154)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1350/4579]  eta: 0:21:10  Lr: 0.030000  Loss: -1.7658  Acc@1: 68.7500 (65.5672)  Acc@5: 93.7500 (91.6266)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1360/4579]  eta: 0:21:06  Lr: 0.030000  Loss: -1.3529  Acc@1: 62.5000 (65.5079)  Acc@5: 87.5000 (91.6008)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1370/4579]  eta: 0:21:02  Lr: 0.030000  Loss: -1.5689  Acc@1: 62.5000 (65.5042)  Acc@5: 87.5000 (91.5801)  time: 0.3963  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1380/4579]  eta: 0:20:58  Lr: 0.030000  Loss: -1.2993  Acc@1: 68.7500 (65.5005)  Acc@5: 93.7500 (91.6003)  time: 0.3976  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1390/4579]  eta: 0:20:54  Lr: 0.030000  Loss: -0.9949  Acc@1: 68.7500 (65.5239)  Acc@5: 93.7500 (91.6157)  time: 0.3971  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1400/4579]  eta: 0:20:50  Lr: 0.030000  Loss: -1.5993  Acc@1: 68.7500 (65.5425)  Acc@5: 93.7500 (91.6221)  time: 0.3949  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1410/4579]  eta: 0:20:46  Lr: 0.030000  Loss: -1.7157  Acc@1: 68.7500 (65.5608)  Acc@5: 93.7500 (91.6327)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1420/4579]  eta: 0:20:42  Lr: 0.030000  Loss: -1.5428  Acc@1: 68.7500 (65.5612)  Acc@5: 87.5000 (91.6300)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1430/4579]  eta: 0:20:38  Lr: 0.030000  Loss: -1.5381  Acc@1: 62.5000 (65.5660)  Acc@5: 93.7500 (91.6405)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1440/4579]  eta: 0:20:34  Lr: 0.030000  Loss: -1.6930  Acc@1: 62.5000 (65.5404)  Acc@5: 93.7500 (91.6291)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1450/4579]  eta: 0:20:31  Lr: 0.030000  Loss: -1.8452  Acc@1: 62.5000 (65.5324)  Acc@5: 93.7500 (91.6480)  time: 0.3958  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1460/4579]  eta: 0:20:27  Lr: 0.030000  Loss: -1.5352  Acc@1: 62.5000 (65.5287)  Acc@5: 93.7500 (91.6453)  time: 0.3960  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1470/4579]  eta: 0:20:23  Lr: 0.030000  Loss: -1.9410  Acc@1: 62.5000 (65.5124)  Acc@5: 93.7500 (91.6426)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1480/4579]  eta: 0:20:19  Lr: 0.030000  Loss: -1.7168  Acc@1: 62.5000 (65.4878)  Acc@5: 93.7500 (91.6442)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1490/4579]  eta: 0:20:15  Lr: 0.030000  Loss: -1.2228  Acc@1: 62.5000 (65.4468)  Acc@5: 93.7500 (91.6457)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1500/4579]  eta: 0:20:11  Lr: 0.030000  Loss: -1.6775  Acc@1: 62.5000 (65.4439)  Acc@5: 93.7500 (91.6472)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1510/4579]  eta: 0:20:07  Lr: 0.030000  Loss: -1.5696  Acc@1: 68.7500 (65.4451)  Acc@5: 93.7500 (91.6529)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1520/4579]  eta: 0:20:03  Lr: 0.030000  Loss: -1.4354  Acc@1: 62.5000 (65.4545)  Acc@5: 93.7500 (91.6420)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1530/4579]  eta: 0:19:59  Lr: 0.030000  Loss: -0.9177  Acc@1: 62.5000 (65.4597)  Acc@5: 93.7500 (91.6476)  time: 0.3937  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [1540/4579]  eta: 0:19:55  Lr: 0.030000  Loss: -1.1869  Acc@1: 68.7500 (65.5054)  Acc@5: 93.7500 (91.6491)  time: 0.3944  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [1550/4579]  eta: 0:19:51  Lr: 0.030000  Loss: -1.6540  Acc@1: 68.7500 (65.5061)  Acc@5: 93.7500 (91.6304)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1560/4579]  eta: 0:19:47  Lr: 0.030000  Loss: -1.0285  Acc@1: 62.5000 (65.4628)  Acc@5: 93.7500 (91.6119)  time: 0.3917  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1570/4579]  eta: 0:19:43  Lr: 0.030000  Loss: -1.9599  Acc@1: 56.2500 (65.4599)  Acc@5: 87.5000 (91.6096)  time: 0.3918  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1580/4579]  eta: 0:19:39  Lr: 0.030000  Loss: -1.7277  Acc@1: 68.7500 (65.4451)  Acc@5: 93.7500 (91.6232)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1590/4579]  eta: 0:19:35  Lr: 0.030000  Loss: -1.5193  Acc@1: 62.5000 (65.4266)  Acc@5: 93.7500 (91.6169)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1600/4579]  eta: 0:19:31  Lr: 0.030000  Loss: -1.9992  Acc@1: 62.5000 (65.4083)  Acc@5: 93.7500 (91.6302)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1610/4579]  eta: 0:19:27  Lr: 0.030000  Loss: -1.1361  Acc@1: 56.2500 (65.3476)  Acc@5: 93.7500 (91.6201)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1620/4579]  eta: 0:19:23  Lr: 0.030000  Loss: -1.6642  Acc@1: 62.5000 (65.3339)  Acc@5: 93.7500 (91.6178)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1630/4579]  eta: 0:19:19  Lr: 0.030000  Loss: -1.3553  Acc@1: 62.5000 (65.3165)  Acc@5: 93.7500 (91.6271)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1640/4579]  eta: 0:19:16  Lr: 0.030000  Loss: -1.9211  Acc@1: 68.7500 (65.3298)  Acc@5: 93.7500 (91.6324)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1650/4579]  eta: 0:19:12  Lr: 0.030000  Loss: -1.5986  Acc@1: 68.7500 (65.3278)  Acc@5: 93.7500 (91.6263)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1660/4579]  eta: 0:19:08  Lr: 0.030000  Loss: -1.4740  Acc@1: 62.5000 (65.3108)  Acc@5: 87.5000 (91.5977)  time: 0.3957  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [1670/4579]  eta: 0:19:04  Lr: 0.030000  Loss: -1.5360  Acc@1: 62.5000 (65.3089)  Acc@5: 87.5000 (91.5732)  time: 0.3958  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1680/4579]  eta: 0:19:00  Lr: 0.030000  Loss: -1.6484  Acc@1: 68.7500 (65.3406)  Acc@5: 87.5000 (91.5750)  time: 0.3934  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1690/4579]  eta: 0:18:56  Lr: 0.030000  Loss: -1.4695  Acc@1: 68.7500 (65.3570)  Acc@5: 87.5000 (91.5767)  time: 0.3935  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1700/4579]  eta: 0:18:52  Lr: 0.030000  Loss: -1.1325  Acc@1: 62.5000 (65.3549)  Acc@5: 93.7500 (91.5822)  time: 0.3934  data: 0.0003  max mem: 2904
Train: Epoch[2/5]  [1710/4579]  eta: 0:18:48  Lr: 0.030000  Loss: -1.8191  Acc@1: 62.5000 (65.3711)  Acc@5: 93.7500 (91.5766)  time: 0.3927  data: 0.0003  max mem: 2904
Train: Epoch[2/5]  [1720/4579]  eta: 0:18:44  Lr: 0.030000  Loss: -0.9041  Acc@1: 62.5000 (65.3508)  Acc@5: 87.5000 (91.5529)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1730/4579]  eta: 0:18:40  Lr: 0.030000  Loss: -1.7767  Acc@1: 62.5000 (65.3705)  Acc@5: 87.5000 (91.5547)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1740/4579]  eta: 0:18:36  Lr: 0.030000  Loss: -1.6377  Acc@1: 68.7500 (65.3791)  Acc@5: 93.7500 (91.5530)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1750/4579]  eta: 0:18:32  Lr: 0.030000  Loss: -1.3535  Acc@1: 62.5000 (65.3448)  Acc@5: 93.7500 (91.5441)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1760/4579]  eta: 0:18:28  Lr: 0.030000  Loss: -1.9004  Acc@1: 68.7500 (65.3819)  Acc@5: 93.7500 (91.5531)  time: 0.3938  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1770/4579]  eta: 0:18:24  Lr: 0.030000  Loss: -1.4664  Acc@1: 68.7500 (65.3797)  Acc@5: 93.7500 (91.5443)  time: 0.3948  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1780/4579]  eta: 0:18:21  Lr: 0.030000  Loss: -1.5315  Acc@1: 62.5000 (65.3846)  Acc@5: 93.7500 (91.5392)  time: 0.3948  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [1790/4579]  eta: 0:18:17  Lr: 0.030000  Loss: -1.0486  Acc@1: 62.5000 (65.3615)  Acc@5: 93.7500 (91.5341)  time: 0.3946  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [1800/4579]  eta: 0:18:13  Lr: 0.030000  Loss: -0.9590  Acc@1: 62.5000 (65.3561)  Acc@5: 93.7500 (91.5221)  time: 0.3951  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [1810/4579]  eta: 0:18:09  Lr: 0.030000  Loss: -1.6163  Acc@1: 68.7500 (65.3644)  Acc@5: 93.7500 (91.5137)  time: 0.3941  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1820/4579]  eta: 0:18:05  Lr: 0.030000  Loss: -2.0761  Acc@1: 62.5000 (65.3796)  Acc@5: 87.5000 (91.5019)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1830/4579]  eta: 0:18:01  Lr: 0.030000  Loss: -1.7907  Acc@1: 68.7500 (65.4185)  Acc@5: 87.5000 (91.5108)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1840/4579]  eta: 0:17:57  Lr: 0.030000  Loss: -1.2070  Acc@1: 68.7500 (65.4196)  Acc@5: 93.7500 (91.5094)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1850/4579]  eta: 0:17:53  Lr: 0.030000  Loss: -1.8671  Acc@1: 68.7500 (65.4038)  Acc@5: 93.7500 (91.5080)  time: 0.3943  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1860/4579]  eta: 0:17:49  Lr: 0.030000  Loss: -1.5555  Acc@1: 62.5000 (65.3949)  Acc@5: 93.7500 (91.5066)  time: 0.3949  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1870/4579]  eta: 0:17:45  Lr: 0.030000  Loss: -1.1310  Acc@1: 56.2500 (65.3594)  Acc@5: 93.7500 (91.5086)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1880/4579]  eta: 0:17:41  Lr: 0.030000  Loss: -1.5503  Acc@1: 56.2500 (65.3376)  Acc@5: 93.7500 (91.5205)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1890/4579]  eta: 0:17:37  Lr: 0.030000  Loss: -1.5161  Acc@1: 62.5000 (65.3556)  Acc@5: 93.7500 (91.5422)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1900/4579]  eta: 0:17:33  Lr: 0.030000  Loss: -1.9243  Acc@1: 68.7500 (65.3603)  Acc@5: 93.7500 (91.5373)  time: 0.3941  data: 0.0015  max mem: 2904
Train: Epoch[2/5]  [1910/4579]  eta: 0:17:30  Lr: 0.030000  Loss: -2.1726  Acc@1: 62.5000 (65.3650)  Acc@5: 87.5000 (91.5195)  time: 0.3955  data: 0.0014  max mem: 2904
Train: Epoch[2/5]  [1920/4579]  eta: 0:17:26  Lr: 0.030000  Loss: -2.1606  Acc@1: 62.5000 (65.3859)  Acc@5: 93.7500 (91.5311)  time: 0.3953  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1930/4579]  eta: 0:17:22  Lr: 0.030000  Loss: -0.8840  Acc@1: 68.7500 (65.4001)  Acc@5: 93.7500 (91.5296)  time: 0.3951  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [1940/4579]  eta: 0:17:18  Lr: 0.030000  Loss: -1.1566  Acc@1: 68.7500 (65.3787)  Acc@5: 93.7500 (91.5250)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1950/4579]  eta: 0:17:14  Lr: 0.030000  Loss: -1.1015  Acc@1: 68.7500 (65.3895)  Acc@5: 93.7500 (91.5236)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1960/4579]  eta: 0:17:10  Lr: 0.030000  Loss: -1.7139  Acc@1: 68.7500 (65.4258)  Acc@5: 93.7500 (91.5286)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1970/4579]  eta: 0:17:06  Lr: 0.030000  Loss: -2.0797  Acc@1: 68.7500 (65.4205)  Acc@5: 93.7500 (91.5303)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [1980/4579]  eta: 0:17:02  Lr: 0.030000  Loss: -1.5973  Acc@1: 62.5000 (65.4404)  Acc@5: 93.7500 (91.5257)  time: 0.3934  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [1990/4579]  eta: 0:16:58  Lr: 0.030000  Loss: -0.4031  Acc@1: 62.5000 (65.4131)  Acc@5: 93.7500 (91.5087)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2000/4579]  eta: 0:16:54  Lr: 0.030000  Loss: -1.6913  Acc@1: 62.5000 (65.4079)  Acc@5: 93.7500 (91.5011)  time: 0.3977  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2010/4579]  eta: 0:16:50  Lr: 0.030000  Loss: -2.1229  Acc@1: 62.5000 (65.4308)  Acc@5: 93.7500 (91.4968)  time: 0.3999  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2020/4579]  eta: 0:16:46  Lr: 0.030000  Loss: -1.8896  Acc@1: 68.7500 (65.4534)  Acc@5: 93.7500 (91.5017)  time: 0.3965  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2030/4579]  eta: 0:16:43  Lr: 0.030000  Loss: -1.8193  Acc@1: 68.7500 (65.4450)  Acc@5: 87.5000 (91.4820)  time: 0.3966  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2040/4579]  eta: 0:16:39  Lr: 0.030000  Loss: -1.6549  Acc@1: 68.7500 (65.4857)  Acc@5: 93.7500 (91.5023)  time: 0.3969  data: 0.0017  max mem: 2904
Train: Epoch[2/5]  [2050/4579]  eta: 0:16:35  Lr: 0.030000  Loss: -0.6641  Acc@1: 68.7500 (65.4772)  Acc@5: 93.7500 (91.4920)  time: 0.3937  data: 0.0017  max mem: 2904
Train: Epoch[2/5]  [2060/4579]  eta: 0:16:31  Lr: 0.030000  Loss: -0.6213  Acc@1: 62.5000 (65.4658)  Acc@5: 87.5000 (91.4787)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2070/4579]  eta: 0:16:27  Lr: 0.030000  Loss: -1.5854  Acc@1: 68.7500 (65.5058)  Acc@5: 93.7500 (91.4806)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2080/4579]  eta: 0:16:23  Lr: 0.030000  Loss: -2.2087  Acc@1: 75.0000 (65.5364)  Acc@5: 93.7500 (91.4825)  time: 0.3945  data: 0.0013  max mem: 2904
Train: Epoch[2/5]  [2090/4579]  eta: 0:16:19  Lr: 0.030000  Loss: -1.5453  Acc@1: 68.7500 (65.5099)  Acc@5: 93.7500 (91.4993)  time: 0.3939  data: 0.0011  max mem: 2904
Train: Epoch[2/5]  [2100/4579]  eta: 0:16:15  Lr: 0.030000  Loss: -1.2339  Acc@1: 68.7500 (65.5343)  Acc@5: 93.7500 (91.5100)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2110/4579]  eta: 0:16:11  Lr: 0.030000  Loss: -1.6384  Acc@1: 68.7500 (65.5347)  Acc@5: 93.7500 (91.5206)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2120/4579]  eta: 0:16:07  Lr: 0.030000  Loss: -1.1081  Acc@1: 68.7500 (65.5469)  Acc@5: 93.7500 (91.5164)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2130/4579]  eta: 0:16:03  Lr: 0.030000  Loss: -1.2299  Acc@1: 68.7500 (65.5678)  Acc@5: 93.7500 (91.5210)  time: 0.3923  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2140/4579]  eta: 0:15:59  Lr: 0.030000  Loss: -1.5248  Acc@1: 68.7500 (65.5535)  Acc@5: 93.7500 (91.5256)  time: 0.3931  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2150/4579]  eta: 0:15:55  Lr: 0.030000  Loss: -1.4262  Acc@1: 62.5000 (65.5364)  Acc@5: 93.7500 (91.5185)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2160/4579]  eta: 0:15:51  Lr: 0.030000  Loss: -2.1425  Acc@1: 62.5000 (65.5368)  Acc@5: 93.7500 (91.5288)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2170/4579]  eta: 0:15:47  Lr: 0.030000  Loss: -1.4647  Acc@1: 62.5000 (65.5372)  Acc@5: 93.7500 (91.5333)  time: 0.3921  data: 0.0003  max mem: 2904
Train: Epoch[2/5]  [2180/4579]  eta: 0:15:43  Lr: 0.030000  Loss: -1.3428  Acc@1: 62.5000 (65.5347)  Acc@5: 93.7500 (91.5320)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2190/4579]  eta: 0:15:39  Lr: 0.030000  Loss: -1.6420  Acc@1: 68.7500 (65.5637)  Acc@5: 93.7500 (91.5364)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2200/4579]  eta: 0:15:35  Lr: 0.030000  Loss: -1.8097  Acc@1: 68.7500 (65.5867)  Acc@5: 93.7500 (91.5465)  time: 0.3934  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2210/4579]  eta: 0:15:32  Lr: 0.030000  Loss: -1.9703  Acc@1: 68.7500 (65.6095)  Acc@5: 93.7500 (91.5536)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2220/4579]  eta: 0:15:28  Lr: 0.030000  Loss: -1.5773  Acc@1: 68.7500 (65.6152)  Acc@5: 93.7500 (91.5719)  time: 0.3927  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2230/4579]  eta: 0:15:24  Lr: 0.030000  Loss: -1.2412  Acc@1: 62.5000 (65.6180)  Acc@5: 93.7500 (91.5705)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2240/4579]  eta: 0:15:20  Lr: 0.030000  Loss: -1.7699  Acc@1: 62.5000 (65.6348)  Acc@5: 93.7500 (91.5718)  time: 0.3928  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2250/4579]  eta: 0:15:16  Lr: 0.030000  Loss: -1.2286  Acc@1: 68.7500 (65.6208)  Acc@5: 87.5000 (91.5565)  time: 0.3939  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [2260/4579]  eta: 0:15:12  Lr: 0.030000  Loss: -1.8194  Acc@1: 62.5000 (65.6153)  Acc@5: 93.7500 (91.5662)  time: 0.3943  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2270/4579]  eta: 0:15:08  Lr: 0.030000  Loss: -1.4859  Acc@1: 62.5000 (65.6126)  Acc@5: 93.7500 (91.5703)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2280/4579]  eta: 0:15:04  Lr: 0.030000  Loss: -0.8205  Acc@1: 62.5000 (65.6181)  Acc@5: 93.7500 (91.5717)  time: 0.3928  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [2290/4579]  eta: 0:15:00  Lr: 0.030000  Loss: -1.5037  Acc@1: 62.5000 (65.6400)  Acc@5: 93.7500 (91.5675)  time: 0.3930  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2300/4579]  eta: 0:14:56  Lr: 0.030000  Loss: -1.8783  Acc@1: 62.5000 (65.6318)  Acc@5: 87.5000 (91.5472)  time: 0.3928  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [2310/4579]  eta: 0:14:52  Lr: 0.030000  Loss: -1.4127  Acc@1: 62.5000 (65.6182)  Acc@5: 93.7500 (91.5621)  time: 0.3937  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [2320/4579]  eta: 0:14:48  Lr: 0.030000  Loss: -2.0854  Acc@1: 68.7500 (65.6587)  Acc@5: 93.7500 (91.5554)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2330/4579]  eta: 0:14:44  Lr: 0.030000  Loss: -1.7947  Acc@1: 68.7500 (65.6397)  Acc@5: 93.7500 (91.5487)  time: 0.3934  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2340/4579]  eta: 0:14:40  Lr: 0.030000  Loss: -0.9015  Acc@1: 62.5000 (65.6237)  Acc@5: 87.5000 (91.5367)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2350/4579]  eta: 0:14:36  Lr: 0.030000  Loss: -1.1703  Acc@1: 62.5000 (65.6423)  Acc@5: 87.5000 (91.5382)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2360/4579]  eta: 0:14:32  Lr: 0.030000  Loss: -1.8446  Acc@1: 68.7500 (65.6528)  Acc@5: 93.7500 (91.5528)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2370/4579]  eta: 0:14:29  Lr: 0.030000  Loss: -1.9581  Acc@1: 75.0000 (65.6922)  Acc@5: 100.0000 (91.5700)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2380/4579]  eta: 0:14:25  Lr: 0.030000  Loss: -1.6463  Acc@1: 75.0000 (65.6946)  Acc@5: 93.7500 (91.5582)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2390/4579]  eta: 0:14:21  Lr: 0.030000  Loss: -0.8062  Acc@1: 56.2500 (65.6812)  Acc@5: 93.7500 (91.5517)  time: 0.3942  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2400/4579]  eta: 0:14:17  Lr: 0.030000  Loss: -1.2761  Acc@1: 62.5000 (65.6914)  Acc@5: 93.7500 (91.5556)  time: 0.3965  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2410/4579]  eta: 0:14:13  Lr: 0.030000  Loss: -0.3219  Acc@1: 68.7500 (65.7067)  Acc@5: 93.7500 (91.5595)  time: 0.3959  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2420/4579]  eta: 0:14:09  Lr: 0.030000  Loss: -1.5619  Acc@1: 68.7500 (65.7037)  Acc@5: 93.7500 (91.5608)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2430/4579]  eta: 0:14:05  Lr: 0.030000  Loss: -1.3829  Acc@1: 68.7500 (65.7343)  Acc@5: 93.7500 (91.5647)  time: 0.3925  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [2440/4579]  eta: 0:14:01  Lr: 0.030000  Loss: -1.2380  Acc@1: 75.0000 (65.7441)  Acc@5: 93.7500 (91.5660)  time: 0.3932  data: 0.0009  max mem: 2904
Train: Epoch[2/5]  [2450/4579]  eta: 0:13:57  Lr: 0.030000  Loss: -1.0331  Acc@1: 68.7500 (65.7589)  Acc@5: 93.7500 (91.5698)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2460/4579]  eta: 0:13:53  Lr: 0.030000  Loss: -1.6675  Acc@1: 68.7500 (65.7913)  Acc@5: 93.7500 (91.5761)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2470/4579]  eta: 0:13:49  Lr: 0.030000  Loss: -2.1326  Acc@1: 68.7500 (65.8058)  Acc@5: 93.7500 (91.5773)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2480/4579]  eta: 0:13:45  Lr: 0.030000  Loss: -1.4733  Acc@1: 68.7500 (65.8253)  Acc@5: 93.7500 (91.5861)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2490/4579]  eta: 0:13:41  Lr: 0.030000  Loss: -2.1373  Acc@1: 68.7500 (65.8345)  Acc@5: 93.7500 (91.5973)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2500/4579]  eta: 0:13:37  Lr: 0.030000  Loss: -1.0959  Acc@1: 68.7500 (65.8212)  Acc@5: 93.7500 (91.5909)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2510/4579]  eta: 0:13:33  Lr: 0.030000  Loss: -2.1780  Acc@1: 68.7500 (65.8527)  Acc@5: 93.7500 (91.5945)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2520/4579]  eta: 0:13:30  Lr: 0.030000  Loss: -1.6312  Acc@1: 68.7500 (65.8618)  Acc@5: 93.7500 (91.6006)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2530/4579]  eta: 0:13:26  Lr: 0.030000  Loss: -1.5488  Acc@1: 68.7500 (65.8559)  Acc@5: 93.7500 (91.6016)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2540/4579]  eta: 0:13:22  Lr: 0.030000  Loss: -1.6642  Acc@1: 68.7500 (65.8722)  Acc@5: 87.5000 (91.5978)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2550/4579]  eta: 0:13:18  Lr: 0.030000  Loss: -1.2531  Acc@1: 68.7500 (65.8639)  Acc@5: 93.7500 (91.6038)  time: 0.3943  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2560/4579]  eta: 0:13:14  Lr: 0.030000  Loss: -2.0217  Acc@1: 68.7500 (65.8751)  Acc@5: 93.7500 (91.6097)  time: 0.3953  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2570/4579]  eta: 0:13:10  Lr: 0.030000  Loss: -1.7403  Acc@1: 68.7500 (65.8936)  Acc@5: 93.7500 (91.6253)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2580/4579]  eta: 0:13:06  Lr: 0.030000  Loss: -1.9150  Acc@1: 68.7500 (65.8902)  Acc@5: 93.7500 (91.6263)  time: 0.3933  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [2590/4579]  eta: 0:13:02  Lr: 0.030000  Loss: -1.5607  Acc@1: 62.5000 (65.8867)  Acc@5: 87.5000 (91.6176)  time: 0.3925  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2600/4579]  eta: 0:12:58  Lr: 0.030000  Loss: -2.0752  Acc@1: 68.7500 (65.9097)  Acc@5: 93.7500 (91.6186)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2610/4579]  eta: 0:12:54  Lr: 0.030000  Loss: -1.6369  Acc@1: 68.7500 (65.9230)  Acc@5: 93.7500 (91.6172)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2620/4579]  eta: 0:12:50  Lr: 0.030000  Loss: -1.6816  Acc@1: 68.7500 (65.9290)  Acc@5: 93.7500 (91.6301)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2630/4579]  eta: 0:12:46  Lr: 0.030000  Loss: -1.6310  Acc@1: 68.7500 (65.9326)  Acc@5: 93.7500 (91.6382)  time: 0.3914  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2640/4579]  eta: 0:12:42  Lr: 0.030000  Loss: -1.3060  Acc@1: 62.5000 (65.9149)  Acc@5: 93.7500 (91.6485)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2650/4579]  eta: 0:12:38  Lr: 0.030000  Loss: -1.5584  Acc@1: 62.5000 (65.8926)  Acc@5: 93.7500 (91.6423)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2660/4579]  eta: 0:12:34  Lr: 0.030000  Loss: -1.9192  Acc@1: 68.7500 (65.8845)  Acc@5: 93.7500 (91.6432)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2670/4579]  eta: 0:12:30  Lr: 0.030000  Loss: -1.5387  Acc@1: 68.7500 (65.8812)  Acc@5: 93.7500 (91.6487)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2680/4579]  eta: 0:12:26  Lr: 0.030000  Loss: -1.5657  Acc@1: 68.7500 (65.8943)  Acc@5: 93.7500 (91.6496)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2690/4579]  eta: 0:12:23  Lr: 0.030000  Loss: -1.6223  Acc@1: 68.7500 (65.8979)  Acc@5: 93.7500 (91.6620)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2700/4579]  eta: 0:12:19  Lr: 0.030000  Loss: -1.5020  Acc@1: 68.7500 (65.8830)  Acc@5: 93.7500 (91.6512)  time: 0.3926  data: 0.0010  max mem: 2904
Train: Epoch[2/5]  [2710/4579]  eta: 0:12:15  Lr: 0.030000  Loss: -0.9206  Acc@1: 62.5000 (65.8705)  Acc@5: 93.7500 (91.6567)  time: 0.3953  data: 0.0011  max mem: 2904
Train: Epoch[2/5]  [2720/4579]  eta: 0:12:11  Lr: 0.030000  Loss: -2.0051  Acc@1: 62.5000 (65.8834)  Acc@5: 93.7500 (91.6667)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2730/4579]  eta: 0:12:07  Lr: 0.030000  Loss: -1.9164  Acc@1: 68.7500 (65.8916)  Acc@5: 93.7500 (91.6720)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2740/4579]  eta: 0:12:03  Lr: 0.030000  Loss: -1.3238  Acc@1: 68.7500 (65.8906)  Acc@5: 93.7500 (91.6659)  time: 0.3944  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2750/4579]  eta: 0:11:59  Lr: 0.030000  Loss: -1.5595  Acc@1: 68.7500 (65.8897)  Acc@5: 93.7500 (91.6758)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2760/4579]  eta: 0:11:55  Lr: 0.030000  Loss: -2.1042  Acc@1: 68.7500 (65.9068)  Acc@5: 93.7500 (91.6787)  time: 0.3944  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2770/4579]  eta: 0:11:51  Lr: 0.030000  Loss: -1.1908  Acc@1: 68.7500 (65.8990)  Acc@5: 93.7500 (91.6772)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2780/4579]  eta: 0:11:47  Lr: 0.030000  Loss: -0.9876  Acc@1: 62.5000 (65.8936)  Acc@5: 93.7500 (91.6712)  time: 0.3955  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2790/4579]  eta: 0:11:43  Lr: 0.030000  Loss: -1.8930  Acc@1: 68.7500 (65.8836)  Acc@5: 93.7500 (91.6764)  time: 0.3971  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2800/4579]  eta: 0:11:39  Lr: 0.030000  Loss: -2.0317  Acc@1: 68.7500 (65.8916)  Acc@5: 93.7500 (91.6838)  time: 0.3948  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2810/4579]  eta: 0:11:35  Lr: 0.030000  Loss: -1.6130  Acc@1: 68.7500 (65.8974)  Acc@5: 93.7500 (91.6822)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2820/4579]  eta: 0:11:31  Lr: 0.030000  Loss: -2.3230  Acc@1: 68.7500 (65.9208)  Acc@5: 93.7500 (91.6807)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2830/4579]  eta: 0:11:28  Lr: 0.030000  Loss: -1.6245  Acc@1: 75.0000 (65.9374)  Acc@5: 93.7500 (91.6814)  time: 0.3945  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2840/4579]  eta: 0:11:24  Lr: 0.030000  Loss: -1.4986  Acc@1: 68.7500 (65.9363)  Acc@5: 93.7500 (91.6865)  time: 0.3948  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2850/4579]  eta: 0:11:20  Lr: 0.030000  Loss: -1.1590  Acc@1: 62.5000 (65.9374)  Acc@5: 93.7500 (91.6893)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2860/4579]  eta: 0:11:16  Lr: 0.030000  Loss: -1.3308  Acc@1: 62.5000 (65.9210)  Acc@5: 93.7500 (91.6856)  time: 0.3938  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [2870/4579]  eta: 0:11:12  Lr: 0.030000  Loss: -0.9916  Acc@1: 62.5000 (65.9156)  Acc@5: 93.7500 (91.6884)  time: 0.3929  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [2880/4579]  eta: 0:11:08  Lr: 0.030000  Loss: -1.3172  Acc@1: 62.5000 (65.8973)  Acc@5: 87.5000 (91.6717)  time: 0.3926  data: 0.0003  max mem: 2904
Train: Epoch[2/5]  [2890/4579]  eta: 0:11:04  Lr: 0.030000  Loss: -1.9382  Acc@1: 62.5000 (65.9028)  Acc@5: 93.7500 (91.6854)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2900/4579]  eta: 0:11:00  Lr: 0.030000  Loss: -1.4301  Acc@1: 62.5000 (65.8975)  Acc@5: 93.7500 (91.6774)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2910/4579]  eta: 0:10:56  Lr: 0.030000  Loss: -1.4841  Acc@1: 62.5000 (65.9030)  Acc@5: 93.7500 (91.6803)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2920/4579]  eta: 0:10:52  Lr: 0.030000  Loss: -1.7048  Acc@1: 62.5000 (65.9021)  Acc@5: 93.7500 (91.6874)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2930/4579]  eta: 0:10:48  Lr: 0.030000  Loss: -1.7199  Acc@1: 68.7500 (65.9246)  Acc@5: 93.7500 (91.6880)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [2940/4579]  eta: 0:10:44  Lr: 0.030000  Loss: -1.5670  Acc@1: 68.7500 (65.9363)  Acc@5: 93.7500 (91.6886)  time: 0.3960  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [2950/4579]  eta: 0:10:40  Lr: 0.030000  Loss: -1.4693  Acc@1: 68.7500 (65.9543)  Acc@5: 93.7500 (91.6829)  time: 0.3968  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [2960/4579]  eta: 0:10:36  Lr: 0.030000  Loss: -0.9761  Acc@1: 68.7500 (65.9617)  Acc@5: 93.7500 (91.6878)  time: 0.3963  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2970/4579]  eta: 0:10:33  Lr: 0.030000  Loss: -1.6306  Acc@1: 68.7500 (65.9795)  Acc@5: 93.7500 (91.6884)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [2980/4579]  eta: 0:10:29  Lr: 0.030000  Loss: -1.1410  Acc@1: 68.7500 (65.9888)  Acc@5: 93.7500 (91.6869)  time: 0.3929  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [2990/4579]  eta: 0:10:25  Lr: 0.030000  Loss: -2.0151  Acc@1: 68.7500 (65.9896)  Acc@5: 93.7500 (91.6834)  time: 0.3941  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [3000/4579]  eta: 0:10:21  Lr: 0.030000  Loss: -1.6488  Acc@1: 62.5000 (65.9759)  Acc@5: 93.7500 (91.6840)  time: 0.3957  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3010/4579]  eta: 0:10:17  Lr: 0.030000  Loss: -2.2643  Acc@1: 62.5000 (65.9914)  Acc@5: 93.7500 (91.6930)  time: 0.3949  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3020/4579]  eta: 0:10:13  Lr: 0.030000  Loss: -1.7492  Acc@1: 68.7500 (65.9964)  Acc@5: 93.7500 (91.6811)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3030/4579]  eta: 0:10:09  Lr: 0.030000  Loss: -1.1165  Acc@1: 68.7500 (66.0034)  Acc@5: 87.5000 (91.6756)  time: 0.3943  data: 0.0003  max mem: 2904
Train: Epoch[2/5]  [3040/4579]  eta: 0:10:05  Lr: 0.030000  Loss: -1.7099  Acc@1: 68.7500 (66.0001)  Acc@5: 93.7500 (91.6763)  time: 0.3950  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3050/4579]  eta: 0:10:01  Lr: 0.030000  Loss: -1.2979  Acc@1: 62.5000 (65.9927)  Acc@5: 93.7500 (91.6687)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3060/4579]  eta: 0:09:57  Lr: 0.030000  Loss: -2.0740  Acc@1: 62.5000 (65.9772)  Acc@5: 93.7500 (91.6673)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3070/4579]  eta: 0:09:53  Lr: 0.030000  Loss: -1.4804  Acc@1: 62.5000 (65.9516)  Acc@5: 87.5000 (91.6395)  time: 0.3978  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3080/4579]  eta: 0:09:49  Lr: 0.030000  Loss: -2.0247  Acc@1: 56.2500 (65.9303)  Acc@5: 87.5000 (91.6362)  time: 0.3974  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3090/4579]  eta: 0:09:45  Lr: 0.030000  Loss: -1.7744  Acc@1: 62.5000 (65.9435)  Acc@5: 93.7500 (91.6370)  time: 0.3948  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3100/4579]  eta: 0:09:41  Lr: 0.030000  Loss: -0.7158  Acc@1: 68.7500 (65.9344)  Acc@5: 87.5000 (91.6277)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3110/4579]  eta: 0:09:37  Lr: 0.030000  Loss: -1.6434  Acc@1: 68.7500 (65.9495)  Acc@5: 93.7500 (91.6365)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3120/4579]  eta: 0:09:34  Lr: 0.030000  Loss: -1.7216  Acc@1: 68.7500 (65.9484)  Acc@5: 93.7500 (91.6353)  time: 0.3922  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [3130/4579]  eta: 0:09:30  Lr: 0.030000  Loss: -1.2640  Acc@1: 56.2500 (65.9274)  Acc@5: 93.7500 (91.6301)  time: 0.3925  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [3140/4579]  eta: 0:09:26  Lr: 0.030000  Loss: -1.1425  Acc@1: 62.5000 (65.9304)  Acc@5: 93.7500 (91.6328)  time: 0.3930  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [3150/4579]  eta: 0:09:22  Lr: 0.030000  Loss: -1.3519  Acc@1: 62.5000 (65.9116)  Acc@5: 93.7500 (91.6356)  time: 0.3931  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [3160/4579]  eta: 0:09:18  Lr: 0.030000  Loss: -1.0292  Acc@1: 62.5000 (65.9008)  Acc@5: 93.7500 (91.6383)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3170/4579]  eta: 0:09:14  Lr: 0.030000  Loss: -1.3429  Acc@1: 68.7500 (65.9118)  Acc@5: 93.7500 (91.6410)  time: 0.3948  data: 0.0009  max mem: 2904
Train: Epoch[2/5]  [3180/4579]  eta: 0:09:10  Lr: 0.030000  Loss: -1.4500  Acc@1: 68.7500 (65.9148)  Acc@5: 93.7500 (91.6398)  time: 0.3966  data: 0.0010  max mem: 2904
Train: Epoch[2/5]  [3190/4579]  eta: 0:09:06  Lr: 0.030000  Loss: -1.1504  Acc@1: 68.7500 (65.9198)  Acc@5: 93.7500 (91.6406)  time: 0.3959  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [3200/4579]  eta: 0:09:02  Lr: 0.030000  Loss: -2.0165  Acc@1: 75.0000 (65.9501)  Acc@5: 93.7500 (91.6471)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3210/4579]  eta: 0:08:58  Lr: 0.030000  Loss: -1.6272  Acc@1: 75.0000 (65.9549)  Acc@5: 93.7500 (91.6479)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3220/4579]  eta: 0:08:54  Lr: 0.030000  Loss: -1.7834  Acc@1: 62.5000 (65.9384)  Acc@5: 87.5000 (91.6408)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3230/4579]  eta: 0:08:50  Lr: 0.030000  Loss: -1.6041  Acc@1: 62.5000 (65.9297)  Acc@5: 87.5000 (91.6435)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3240/4579]  eta: 0:08:46  Lr: 0.030000  Loss: -1.7257  Acc@1: 62.5000 (65.9422)  Acc@5: 93.7500 (91.6384)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [3250/4579]  eta: 0:08:42  Lr: 0.030000  Loss: -1.2977  Acc@1: 62.5000 (65.9316)  Acc@5: 93.7500 (91.6430)  time: 0.3953  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [3260/4579]  eta: 0:08:39  Lr: 0.030000  Loss: -1.5768  Acc@1: 68.7500 (65.9326)  Acc@5: 93.7500 (91.6303)  time: 0.3959  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3270/4579]  eta: 0:08:35  Lr: 0.030000  Loss: -0.9040  Acc@1: 68.7500 (65.9374)  Acc@5: 87.5000 (91.6329)  time: 0.3942  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3280/4579]  eta: 0:08:31  Lr: 0.030000  Loss: -1.4293  Acc@1: 62.5000 (65.9345)  Acc@5: 93.7500 (91.6470)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3290/4579]  eta: 0:08:27  Lr: 0.030000  Loss: -1.4607  Acc@1: 62.5000 (65.9241)  Acc@5: 93.7500 (91.6401)  time: 0.3946  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3300/4579]  eta: 0:08:23  Lr: 0.030000  Loss: -1.2556  Acc@1: 62.5000 (65.9175)  Acc@5: 93.7500 (91.6446)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3310/4579]  eta: 0:08:19  Lr: 0.030000  Loss: -1.5189  Acc@1: 62.5000 (65.8997)  Acc@5: 93.7500 (91.6358)  time: 0.3907  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3320/4579]  eta: 0:08:15  Lr: 0.030000  Loss: -1.5171  Acc@1: 62.5000 (65.8988)  Acc@5: 93.7500 (91.6384)  time: 0.3914  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3330/4579]  eta: 0:08:11  Lr: 0.030000  Loss: -1.9828  Acc@1: 75.0000 (65.9243)  Acc@5: 93.7500 (91.6467)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3340/4579]  eta: 0:08:07  Lr: 0.030000  Loss: -1.7212  Acc@1: 75.0000 (65.9402)  Acc@5: 93.7500 (91.6455)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3350/4579]  eta: 0:08:03  Lr: 0.030000  Loss: -1.2382  Acc@1: 68.7500 (65.9523)  Acc@5: 93.7500 (91.6592)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:59  Lr: 0.030000  Loss: -1.8164  Acc@1: 68.7500 (65.9607)  Acc@5: 93.7500 (91.6617)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3370/4579]  eta: 0:07:55  Lr: 0.030000  Loss: -1.7921  Acc@1: 62.5000 (65.9671)  Acc@5: 93.7500 (91.6642)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3380/4579]  eta: 0:07:51  Lr: 0.030000  Loss: -1.4507  Acc@1: 62.5000 (65.9513)  Acc@5: 93.7500 (91.6611)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3390/4579]  eta: 0:07:47  Lr: 0.030000  Loss: -1.6503  Acc@1: 62.5000 (65.9448)  Acc@5: 93.7500 (91.6636)  time: 0.3938  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3400/4579]  eta: 0:07:43  Lr: 0.030000  Loss: -1.4870  Acc@1: 62.5000 (65.9475)  Acc@5: 93.7500 (91.6697)  time: 0.3965  data: 0.0013  max mem: 2904
Train: Epoch[2/5]  [3410/4579]  eta: 0:07:39  Lr: 0.030000  Loss: -1.6037  Acc@1: 75.0000 (65.9722)  Acc@5: 93.7500 (91.6703)  time: 0.3968  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [3420/4579]  eta: 0:07:36  Lr: 0.030000  Loss: -1.8363  Acc@1: 75.0000 (65.9803)  Acc@5: 93.7500 (91.6801)  time: 0.3952  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3430/4579]  eta: 0:07:32  Lr: 0.030000  Loss: -1.8220  Acc@1: 68.7500 (66.0030)  Acc@5: 100.0000 (91.6897)  time: 0.3942  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3440/4579]  eta: 0:07:28  Lr: 0.030000  Loss: -1.4106  Acc@1: 75.0000 (66.0092)  Acc@5: 87.5000 (91.6721)  time: 0.3940  data: 0.0011  max mem: 2904
Train: Epoch[2/5]  [3450/4579]  eta: 0:07:24  Lr: 0.030000  Loss: -1.4924  Acc@1: 62.5000 (65.9990)  Acc@5: 87.5000 (91.6673)  time: 0.3941  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [3460/4579]  eta: 0:07:20  Lr: 0.030000  Loss: -1.5897  Acc@1: 62.5000 (66.0160)  Acc@5: 93.7500 (91.6751)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3470/4579]  eta: 0:07:16  Lr: 0.030000  Loss: -0.9061  Acc@1: 62.5000 (65.9950)  Acc@5: 93.7500 (91.6667)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3480/4579]  eta: 0:07:12  Lr: 0.030000  Loss: -1.5712  Acc@1: 62.5000 (65.9976)  Acc@5: 93.7500 (91.6709)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3490/4579]  eta: 0:07:08  Lr: 0.030000  Loss: -1.5988  Acc@1: 62.5000 (65.9947)  Acc@5: 93.7500 (91.6732)  time: 0.3934  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3500/4579]  eta: 0:07:04  Lr: 0.030000  Loss: -1.7413  Acc@1: 68.7500 (66.0133)  Acc@5: 93.7500 (91.6756)  time: 0.3942  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3510/4579]  eta: 0:07:00  Lr: 0.030000  Loss: -1.7699  Acc@1: 75.0000 (66.0264)  Acc@5: 93.7500 (91.6655)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:56  Lr: 0.030000  Loss: -1.7686  Acc@1: 68.7500 (66.0342)  Acc@5: 93.7500 (91.6643)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:52  Lr: 0.030000  Loss: -1.7816  Acc@1: 75.0000 (66.0613)  Acc@5: 93.7500 (91.6667)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3540/4579]  eta: 0:06:48  Lr: 0.030000  Loss: -1.8735  Acc@1: 75.0000 (66.0671)  Acc@5: 93.7500 (91.6673)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3550/4579]  eta: 0:06:44  Lr: 0.030000  Loss: -1.4783  Acc@1: 75.0000 (66.0747)  Acc@5: 93.7500 (91.6731)  time: 0.3934  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3560/4579]  eta: 0:06:40  Lr: 0.030000  Loss: -1.7551  Acc@1: 68.7500 (66.0892)  Acc@5: 93.7500 (91.6807)  time: 0.3945  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3570/4579]  eta: 0:06:37  Lr: 0.030000  Loss: -1.9053  Acc@1: 75.0000 (66.1072)  Acc@5: 93.7500 (91.6865)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3580/4579]  eta: 0:06:33  Lr: 0.030000  Loss: -1.7200  Acc@1: 68.7500 (66.1041)  Acc@5: 93.7500 (91.6800)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3590/4579]  eta: 0:06:29  Lr: 0.030000  Loss: -1.7845  Acc@1: 62.5000 (66.1097)  Acc@5: 93.7500 (91.6858)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3600/4579]  eta: 0:06:25  Lr: 0.030000  Loss: -1.3414  Acc@1: 68.7500 (66.1275)  Acc@5: 100.0000 (91.6950)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3610/4579]  eta: 0:06:21  Lr: 0.030000  Loss: -1.6883  Acc@1: 68.7500 (66.1330)  Acc@5: 93.7500 (91.6955)  time: 0.3952  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3620/4579]  eta: 0:06:17  Lr: 0.030000  Loss: -1.3801  Acc@1: 68.7500 (66.1385)  Acc@5: 93.7500 (91.6995)  time: 0.3963  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3630/4579]  eta: 0:06:13  Lr: 0.030000  Loss: -1.5919  Acc@1: 68.7500 (66.1474)  Acc@5: 93.7500 (91.6965)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3640/4579]  eta: 0:06:09  Lr: 0.030000  Loss: -1.9289  Acc@1: 62.5000 (66.1391)  Acc@5: 87.5000 (91.6884)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3650/4579]  eta: 0:06:05  Lr: 0.030000  Loss: -2.0247  Acc@1: 62.5000 (66.1360)  Acc@5: 93.7500 (91.6821)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3660/4579]  eta: 0:06:01  Lr: 0.030000  Loss: -1.7446  Acc@1: 68.7500 (66.1363)  Acc@5: 93.7500 (91.6843)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:57  Lr: 0.030000  Loss: -1.3334  Acc@1: 68.7500 (66.1400)  Acc@5: 93.7500 (91.6933)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:53  Lr: 0.030000  Loss: -1.8318  Acc@1: 68.7500 (66.1471)  Acc@5: 93.7500 (91.7023)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:49  Lr: 0.030000  Loss: -2.1288  Acc@1: 68.7500 (66.1592)  Acc@5: 93.7500 (91.7062)  time: 0.3934  data: 0.0010  max mem: 2904
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:45  Lr: 0.030000  Loss: -1.5436  Acc@1: 62.5000 (66.1612)  Acc@5: 93.7500 (91.7083)  time: 0.3943  data: 0.0018  max mem: 2904
Train: Epoch[2/5]  [3710/4579]  eta: 0:05:41  Lr: 0.030000  Loss: -1.8518  Acc@1: 62.5000 (66.1631)  Acc@5: 93.7500 (91.7172)  time: 0.3937  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [3720/4579]  eta: 0:05:38  Lr: 0.030000  Loss: -2.0099  Acc@1: 68.7500 (66.1667)  Acc@5: 93.7500 (91.7277)  time: 0.3931  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [3730/4579]  eta: 0:05:34  Lr: 0.030000  Loss: -1.5362  Acc@1: 68.7500 (66.1803)  Acc@5: 93.7500 (91.7348)  time: 0.3937  data: 0.0013  max mem: 2904
Train: Epoch[2/5]  [3740/4579]  eta: 0:05:30  Lr: 0.030000  Loss: -1.3759  Acc@1: 75.0000 (66.2122)  Acc@5: 93.7500 (91.7469)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3750/4579]  eta: 0:05:26  Lr: 0.030000  Loss: -1.8681  Acc@1: 75.0000 (66.2340)  Acc@5: 93.7500 (91.7505)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3760/4579]  eta: 0:05:22  Lr: 0.030000  Loss: -1.6845  Acc@1: 68.7500 (66.2291)  Acc@5: 93.7500 (91.7509)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3770/4579]  eta: 0:05:18  Lr: 0.030000  Loss: -1.9570  Acc@1: 68.7500 (66.2507)  Acc@5: 93.7500 (91.7595)  time: 0.3956  data: 0.0013  max mem: 2904
Train: Epoch[2/5]  [3780/4579]  eta: 0:05:14  Lr: 0.030000  Loss: -1.3783  Acc@1: 68.7500 (66.2589)  Acc@5: 93.7500 (91.7548)  time: 0.3976  data: 0.0013  max mem: 2904
Train: Epoch[2/5]  [3790/4579]  eta: 0:05:10  Lr: 0.030000  Loss: -2.2772  Acc@1: 68.7500 (66.2589)  Acc@5: 93.7500 (91.7634)  time: 0.3942  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3800/4579]  eta: 0:05:06  Lr: 0.030000  Loss: -1.3830  Acc@1: 62.5000 (66.2605)  Acc@5: 93.7500 (91.7637)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3810/4579]  eta: 0:05:02  Lr: 0.030000  Loss: -1.1189  Acc@1: 62.5000 (66.2703)  Acc@5: 93.7500 (91.7656)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:58  Lr: 0.030000  Loss: -1.1245  Acc@1: 68.7500 (66.2768)  Acc@5: 93.7500 (91.7659)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:54  Lr: 0.030000  Loss: -1.7076  Acc@1: 62.5000 (66.2637)  Acc@5: 93.7500 (91.7646)  time: 0.3925  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:50  Lr: 0.030000  Loss: -1.8405  Acc@1: 62.5000 (66.2555)  Acc@5: 93.7500 (91.7697)  time: 0.3925  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:46  Lr: 0.030000  Loss: -1.9042  Acc@1: 68.7500 (66.2896)  Acc@5: 93.7500 (91.7700)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:42  Lr: 0.030000  Loss: -1.5471  Acc@1: 75.0000 (66.3041)  Acc@5: 93.7500 (91.7686)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:38  Lr: 0.030000  Loss: -2.1154  Acc@1: 68.7500 (66.3120)  Acc@5: 93.7500 (91.7705)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:35  Lr: 0.030000  Loss: -1.2806  Acc@1: 62.5000 (66.3086)  Acc@5: 93.7500 (91.7692)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3890/4579]  eta: 0:04:31  Lr: 0.030000  Loss: -1.6229  Acc@1: 62.5000 (66.3036)  Acc@5: 93.7500 (91.7679)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3900/4579]  eta: 0:04:27  Lr: 0.030000  Loss: -1.8052  Acc@1: 62.5000 (66.3067)  Acc@5: 93.7500 (91.7665)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3910/4579]  eta: 0:04:23  Lr: 0.030000  Loss: -1.9757  Acc@1: 68.7500 (66.3114)  Acc@5: 93.7500 (91.7684)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3920/4579]  eta: 0:04:19  Lr: 0.030000  Loss: -1.0940  Acc@1: 68.7500 (66.3112)  Acc@5: 93.7500 (91.7751)  time: 0.3938  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [3930/4579]  eta: 0:04:15  Lr: 0.030000  Loss: -1.8850  Acc@1: 68.7500 (66.3190)  Acc@5: 93.7500 (91.7753)  time: 0.3938  data: 0.0011  max mem: 2904
Train: Epoch[2/5]  [3940/4579]  eta: 0:04:11  Lr: 0.030000  Loss: -1.6697  Acc@1: 68.7500 (66.3363)  Acc@5: 93.7500 (91.7756)  time: 0.3939  data: 0.0010  max mem: 2904
Train: Epoch[2/5]  [3950/4579]  eta: 0:04:07  Lr: 0.030000  Loss: -1.2665  Acc@1: 68.7500 (66.3234)  Acc@5: 93.7500 (91.7711)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3960/4579]  eta: 0:04:03  Lr: 0.030000  Loss: -1.8563  Acc@1: 68.7500 (66.3358)  Acc@5: 93.7500 (91.7776)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:59  Lr: 0.030000  Loss: -1.4585  Acc@1: 68.7500 (66.3451)  Acc@5: 93.7500 (91.7747)  time: 0.3939  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:55  Lr: 0.030000  Loss: -1.5834  Acc@1: 68.7500 (66.3574)  Acc@5: 93.7500 (91.7813)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:51  Lr: 0.030000  Loss: -1.5105  Acc@1: 68.7500 (66.3618)  Acc@5: 93.7500 (91.7846)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:47  Lr: 0.030000  Loss: -1.4269  Acc@1: 68.7500 (66.3709)  Acc@5: 93.7500 (91.7864)  time: 0.3944  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:43  Lr: 0.030000  Loss: -1.7944  Acc@1: 68.7500 (66.3722)  Acc@5: 93.7500 (91.7913)  time: 0.3944  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:39  Lr: 0.030000  Loss: -1.1544  Acc@1: 68.7500 (66.3594)  Acc@5: 87.5000 (91.7853)  time: 0.3950  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:36  Lr: 0.030000  Loss: -1.3544  Acc@1: 68.7500 (66.3731)  Acc@5: 93.7500 (91.8026)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:32  Lr: 0.030000  Loss: -1.0554  Acc@1: 68.7500 (66.3774)  Acc@5: 100.0000 (91.7997)  time: 0.3944  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:28  Lr: 0.030000  Loss: -1.6614  Acc@1: 68.7500 (66.3725)  Acc@5: 93.7500 (91.8060)  time: 0.3949  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [4060/4579]  eta: 0:03:24  Lr: 0.030000  Loss: -1.2384  Acc@1: 68.7500 (66.3784)  Acc@5: 93.7500 (91.8139)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [4070/4579]  eta: 0:03:20  Lr: 0.030000  Loss: -1.9409  Acc@1: 68.7500 (66.3765)  Acc@5: 93.7500 (91.8110)  time: 0.3943  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4080/4579]  eta: 0:03:16  Lr: 0.030000  Loss: -1.3276  Acc@1: 62.5000 (66.3777)  Acc@5: 93.7500 (91.8111)  time: 0.3938  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4090/4579]  eta: 0:03:12  Lr: 0.030000  Loss: -0.8463  Acc@1: 62.5000 (66.3698)  Acc@5: 93.7500 (91.8159)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4100/4579]  eta: 0:03:08  Lr: 0.030000  Loss: -1.7377  Acc@1: 62.5000 (66.3588)  Acc@5: 93.7500 (91.8069)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4110/4579]  eta: 0:03:04  Lr: 0.030000  Loss: -1.6718  Acc@1: 62.5000 (66.3586)  Acc@5: 87.5000 (91.8055)  time: 0.3949  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4120/4579]  eta: 0:03:00  Lr: 0.030000  Loss: -1.6381  Acc@1: 62.5000 (66.3492)  Acc@5: 87.5000 (91.8011)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:56  Lr: 0.030000  Loss: -1.3587  Acc@1: 68.7500 (66.3489)  Acc@5: 87.5000 (91.7953)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:52  Lr: 0.030000  Loss: -1.9106  Acc@1: 68.7500 (66.3593)  Acc@5: 87.5000 (91.7955)  time: 0.3958  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:48  Lr: 0.030000  Loss: -1.2927  Acc@1: 62.5000 (66.3500)  Acc@5: 87.5000 (91.7866)  time: 0.3933  data: 0.0003  max mem: 2904
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:44  Lr: 0.030000  Loss: -1.2918  Acc@1: 62.5000 (66.3527)  Acc@5: 93.7500 (91.7898)  time: 0.3921  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:40  Lr: 0.030000  Loss: -1.8617  Acc@1: 62.5000 (66.3465)  Acc@5: 93.7500 (91.7885)  time: 0.3924  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:37  Lr: 0.030000  Loss: -1.8542  Acc@1: 62.5000 (66.3537)  Acc@5: 93.7500 (91.8007)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:33  Lr: 0.030000  Loss: -1.4013  Acc@1: 68.7500 (66.3595)  Acc@5: 93.7500 (91.8054)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:29  Lr: 0.030000  Loss: -1.8481  Acc@1: 68.7500 (66.3622)  Acc@5: 93.7500 (91.8070)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:25  Lr: 0.030000  Loss: -1.6938  Acc@1: 62.5000 (66.3604)  Acc@5: 93.7500 (91.8131)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:21  Lr: 0.030000  Loss: -1.4055  Acc@1: 62.5000 (66.3557)  Acc@5: 93.7500 (91.8118)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:17  Lr: 0.030000  Loss: -0.7950  Acc@1: 62.5000 (66.3377)  Acc@5: 93.7500 (91.8149)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4240/4579]  eta: 0:02:13  Lr: 0.030000  Loss: -1.1658  Acc@1: 56.2500 (66.3243)  Acc@5: 93.7500 (91.8091)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4250/4579]  eta: 0:02:09  Lr: 0.030000  Loss: -1.6153  Acc@1: 62.5000 (66.3315)  Acc@5: 93.7500 (91.8093)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4260/4579]  eta: 0:02:05  Lr: 0.030000  Loss: -1.7671  Acc@1: 68.7500 (66.3357)  Acc@5: 93.7500 (91.8080)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4270/4579]  eta: 0:02:01  Lr: 0.030000  Loss: -1.6525  Acc@1: 68.7500 (66.3311)  Acc@5: 87.5000 (91.8008)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:57  Lr: 0.030000  Loss: -1.6774  Acc@1: 62.5000 (66.3134)  Acc@5: 87.5000 (91.7966)  time: 0.3930  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:53  Lr: 0.030000  Loss: -1.2520  Acc@1: 62.5000 (66.3118)  Acc@5: 87.5000 (91.7837)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:49  Lr: 0.030000  Loss: -1.4748  Acc@1: 62.5000 (66.3131)  Acc@5: 87.5000 (91.7781)  time: 0.3916  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:45  Lr: 0.030000  Loss: -1.6732  Acc@1: 62.5000 (66.3086)  Acc@5: 87.5000 (91.7754)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:41  Lr: 0.030000  Loss: -1.8851  Acc@1: 68.7500 (66.3142)  Acc@5: 93.7500 (91.7785)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:37  Lr: 0.030000  Loss: -1.0150  Acc@1: 68.7500 (66.3069)  Acc@5: 93.7500 (91.7744)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:34  Lr: 0.030000  Loss: -2.2668  Acc@1: 62.5000 (66.3067)  Acc@5: 93.7500 (91.7746)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:30  Lr: 0.030000  Loss: -1.5106  Acc@1: 62.5000 (66.2965)  Acc@5: 93.7500 (91.7720)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:26  Lr: 0.030000  Loss: -1.2727  Acc@1: 62.5000 (66.2864)  Acc@5: 87.5000 (91.7694)  time: 0.3937  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:22  Lr: 0.030000  Loss: -2.1043  Acc@1: 62.5000 (66.2863)  Acc@5: 93.7500 (91.7725)  time: 0.3924  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:18  Lr: 0.030000  Loss: -0.9653  Acc@1: 62.5000 (66.2820)  Acc@5: 93.7500 (91.7699)  time: 0.3917  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:14  Lr: 0.030000  Loss: -1.6579  Acc@1: 68.7500 (66.2918)  Acc@5: 87.5000 (91.7644)  time: 0.3922  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:10  Lr: 0.030000  Loss: -1.3016  Acc@1: 68.7500 (66.2974)  Acc@5: 93.7500 (91.7632)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4410/4579]  eta: 0:01:06  Lr: 0.030000  Loss: -1.3690  Acc@1: 68.7500 (66.3030)  Acc@5: 93.7500 (91.7635)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4420/4579]  eta: 0:01:02  Lr: 0.030000  Loss: -1.0708  Acc@1: 62.5000 (66.2972)  Acc@5: 93.7500 (91.7680)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:58  Lr: 0.030000  Loss: -1.7165  Acc@1: 62.5000 (66.2957)  Acc@5: 93.7500 (91.7710)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:54  Lr: 0.030000  Loss: -1.4538  Acc@1: 68.7500 (66.3139)  Acc@5: 93.7500 (91.7769)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:50  Lr: 0.030000  Loss: -2.0084  Acc@1: 68.7500 (66.3250)  Acc@5: 93.7500 (91.7785)  time: 0.3927  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:46  Lr: 0.030000  Loss: -2.1875  Acc@1: 68.7500 (66.3318)  Acc@5: 93.7500 (91.7816)  time: 0.3930  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:42  Lr: 0.030000  Loss: -1.8473  Acc@1: 62.5000 (66.3205)  Acc@5: 93.7500 (91.7804)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:38  Lr: 0.030000  Loss: -1.7309  Acc@1: 68.7500 (66.3342)  Acc@5: 93.7500 (91.7875)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:35  Lr: 0.030000  Loss: -1.6463  Acc@1: 62.5000 (66.3215)  Acc@5: 93.7500 (91.7905)  time: 0.3956  data: 0.0012  max mem: 2904
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:31  Lr: 0.030000  Loss: -1.6534  Acc@1: 62.5000 (66.3172)  Acc@5: 93.7500 (91.7935)  time: 0.3960  data: 0.0014  max mem: 2904
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:27  Lr: 0.030000  Loss: -1.8085  Acc@1: 68.7500 (66.3171)  Acc@5: 93.7500 (91.7923)  time: 0.3933  data: 0.0006  max mem: 2904
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:23  Lr: 0.030000  Loss: -1.9364  Acc@1: 68.7500 (66.3169)  Acc@5: 93.7500 (91.7897)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:19  Lr: 0.030000  Loss: -1.1534  Acc@1: 62.5000 (66.2988)  Acc@5: 93.7500 (91.7899)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:15  Lr: 0.030000  Loss: -1.7965  Acc@1: 62.5000 (66.3029)  Acc@5: 93.7500 (91.7928)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:11  Lr: 0.030000  Loss: -1.5533  Acc@1: 68.7500 (66.3069)  Acc@5: 93.7500 (91.7861)  time: 0.3929  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:07  Lr: 0.030000  Loss: -0.2880  Acc@1: 68.7500 (66.3067)  Acc@5: 93.7500 (91.7822)  time: 0.3928  data: 0.0007  max mem: 2904
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: -1.1311  Acc@1: 62.5000 (66.2929)  Acc@5: 87.5000 (91.7742)  time: 0.3933  data: 0.0008  max mem: 2904
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: -1.8617  Acc@1: 68.7500 (66.3049)  Acc@5: 93.7500 (91.7769)  time: 0.3864  data: 0.0007  max mem: 2904
Train: Epoch[2/5] Total time: 0:30:02 (0.3936 s / it)
{0: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.8617  Acc@1: 68.7500 (66.3049)  Acc@5: 93.7500 (91.7769)
Train: Epoch[3/5]  [   0/4579]  eta: 0:54:45  Lr: 0.030000  Loss: -2.0810  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7176  data: 0.3232  max mem: 2904
Train: Epoch[3/5]  [  10/4579]  eta: 0:32:31  Lr: 0.030000  Loss: -1.3565  Acc@1: 62.5000 (63.6364)  Acc@5: 93.7500 (92.0455)  time: 0.4271  data: 0.0300  max mem: 2904
Train: Epoch[3/5]  [  20/4579]  eta: 0:31:23  Lr: 0.030000  Loss: -2.1495  Acc@1: 62.5000 (66.3690)  Acc@5: 93.7500 (92.8571)  time: 0.3978  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [  30/4579]  eta: 0:30:54  Lr: 0.030000  Loss: -2.0234  Acc@1: 68.7500 (67.1371)  Acc@5: 93.7500 (92.1371)  time: 0.3971  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [  40/4579]  eta: 0:30:34  Lr: 0.030000  Loss: -2.0937  Acc@1: 68.7500 (66.3110)  Acc@5: 87.5000 (91.3110)  time: 0.3947  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [  50/4579]  eta: 0:30:22  Lr: 0.030000  Loss: -0.8306  Acc@1: 68.7500 (67.0343)  Acc@5: 93.7500 (91.6667)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [  60/4579]  eta: 0:30:11  Lr: 0.030000  Loss: -1.2453  Acc@1: 68.7500 (67.1107)  Acc@5: 93.7500 (92.0082)  time: 0.3944  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [  70/4579]  eta: 0:30:03  Lr: 0.030000  Loss: -1.0784  Acc@1: 62.5000 (66.2852)  Acc@5: 93.7500 (91.8134)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [  80/4579]  eta: 0:29:56  Lr: 0.030000  Loss: -2.1030  Acc@1: 62.5000 (66.2809)  Acc@5: 87.5000 (91.5895)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [  90/4579]  eta: 0:29:49  Lr: 0.030000  Loss: -0.8276  Acc@1: 62.5000 (65.5907)  Acc@5: 93.7500 (91.4835)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 100/4579]  eta: 0:29:42  Lr: 0.030000  Loss: -1.5998  Acc@1: 62.5000 (66.4604)  Acc@5: 93.7500 (91.7079)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 110/4579]  eta: 0:29:35  Lr: 0.030000  Loss: -1.9044  Acc@1: 68.7500 (66.4977)  Acc@5: 93.7500 (92.0045)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 120/4579]  eta: 0:29:29  Lr: 0.030000  Loss: -1.4833  Acc@1: 62.5000 (66.6322)  Acc@5: 93.7500 (91.8905)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 130/4579]  eta: 0:29:24  Lr: 0.030000  Loss: -1.9898  Acc@1: 62.5000 (66.6031)  Acc@5: 87.5000 (91.8416)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 140/4579]  eta: 0:29:19  Lr: 0.030000  Loss: -1.5961  Acc@1: 68.7500 (66.9770)  Acc@5: 93.7500 (91.8883)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 150/4579]  eta: 0:29:14  Lr: 0.030000  Loss: -1.7348  Acc@1: 68.7500 (66.8460)  Acc@5: 93.7500 (92.0530)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 160/4579]  eta: 0:29:10  Lr: 0.030000  Loss: -1.7431  Acc@1: 62.5000 (66.8090)  Acc@5: 93.7500 (92.0031)  time: 0.3952  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 170/4579]  eta: 0:29:06  Lr: 0.030000  Loss: -1.7957  Acc@1: 68.7500 (67.0322)  Acc@5: 93.7500 (91.9225)  time: 0.3955  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 180/4579]  eta: 0:29:02  Lr: 0.030000  Loss: -2.1955  Acc@1: 68.7500 (66.9199)  Acc@5: 93.7500 (92.0580)  time: 0.3943  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 190/4579]  eta: 0:28:57  Lr: 0.030000  Loss: -1.5230  Acc@1: 68.7500 (67.1466)  Acc@5: 93.7500 (91.9830)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 200/4579]  eta: 0:28:52  Lr: 0.030000  Loss: -1.8047  Acc@1: 68.7500 (67.1331)  Acc@5: 93.7500 (91.9776)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 210/4579]  eta: 0:28:48  Lr: 0.030000  Loss: -0.6673  Acc@1: 68.7500 (67.0912)  Acc@5: 93.7500 (92.0024)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 220/4579]  eta: 0:28:43  Lr: 0.030000  Loss: -1.8329  Acc@1: 68.7500 (67.0814)  Acc@5: 93.7500 (91.8552)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 230/4579]  eta: 0:28:39  Lr: 0.030000  Loss: -1.7241  Acc@1: 62.5000 (67.1266)  Acc@5: 93.7500 (91.9643)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 240/4579]  eta: 0:28:34  Lr: 0.030000  Loss: -0.8016  Acc@1: 68.7500 (67.1940)  Acc@5: 93.7500 (91.9606)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 250/4579]  eta: 0:28:30  Lr: 0.030000  Loss: -1.2312  Acc@1: 68.7500 (67.2560)  Acc@5: 93.7500 (92.0568)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 260/4579]  eta: 0:28:26  Lr: 0.030000  Loss: -1.0547  Acc@1: 68.7500 (67.1456)  Acc@5: 87.5000 (91.8822)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 270/4579]  eta: 0:28:21  Lr: 0.030000  Loss: -1.7221  Acc@1: 68.7500 (67.1587)  Acc@5: 87.5000 (91.8358)  time: 0.3936  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [ 280/4579]  eta: 0:28:17  Lr: 0.030000  Loss: -1.3292  Acc@1: 68.7500 (67.3043)  Acc@5: 93.7500 (91.9039)  time: 0.3945  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [ 290/4579]  eta: 0:28:14  Lr: 0.030000  Loss: -1.9657  Acc@1: 68.7500 (67.2251)  Acc@5: 93.7500 (91.9459)  time: 0.3950  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 300/4579]  eta: 0:28:09  Lr: 0.030000  Loss: -1.3057  Acc@1: 62.5000 (67.0266)  Acc@5: 93.7500 (91.8812)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 310/4579]  eta: 0:28:05  Lr: 0.030000  Loss: -2.0600  Acc@1: 62.5000 (67.1222)  Acc@5: 93.7500 (91.9614)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 320/4579]  eta: 0:28:02  Lr: 0.030000  Loss: -1.6418  Acc@1: 68.7500 (67.1340)  Acc@5: 93.7500 (91.9782)  time: 0.3954  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 330/4579]  eta: 0:27:58  Lr: 0.030000  Loss: -1.6870  Acc@1: 68.7500 (67.2961)  Acc@5: 93.7500 (92.0695)  time: 0.3956  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 340/4579]  eta: 0:27:54  Lr: 0.030000  Loss: -1.6481  Acc@1: 68.7500 (67.3387)  Acc@5: 93.7500 (92.1738)  time: 0.3947  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 350/4579]  eta: 0:27:49  Lr: 0.030000  Loss: -1.5027  Acc@1: 68.7500 (67.3789)  Acc@5: 93.7500 (92.1830)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 360/4579]  eta: 0:27:45  Lr: 0.030000  Loss: -1.7885  Acc@1: 68.7500 (67.4861)  Acc@5: 93.7500 (92.1572)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 370/4579]  eta: 0:27:41  Lr: 0.030000  Loss: -1.9955  Acc@1: 68.7500 (67.4360)  Acc@5: 93.7500 (92.1327)  time: 0.3914  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 380/4579]  eta: 0:27:36  Lr: 0.030000  Loss: -1.5232  Acc@1: 68.7500 (67.3720)  Acc@5: 93.7500 (92.0768)  time: 0.3919  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [ 390/4579]  eta: 0:27:32  Lr: 0.030000  Loss: -1.6882  Acc@1: 62.5000 (67.3114)  Acc@5: 93.7500 (92.0396)  time: 0.3917  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 400/4579]  eta: 0:27:28  Lr: 0.030000  Loss: -1.7814  Acc@1: 68.7500 (67.3628)  Acc@5: 93.7500 (92.1135)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 410/4579]  eta: 0:27:24  Lr: 0.030000  Loss: -1.9571  Acc@1: 68.7500 (67.3966)  Acc@5: 93.7500 (92.1381)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 420/4579]  eta: 0:27:20  Lr: 0.030000  Loss: -1.3095  Acc@1: 68.7500 (67.4287)  Acc@5: 93.7500 (92.0873)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 430/4579]  eta: 0:27:16  Lr: 0.030000  Loss: -0.9436  Acc@1: 62.5000 (67.2129)  Acc@5: 87.5000 (91.9809)  time: 0.3930  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 440/4579]  eta: 0:27:12  Lr: 0.030000  Loss: -1.4677  Acc@1: 62.5000 (67.1627)  Acc@5: 93.7500 (92.0351)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 450/4579]  eta: 0:27:08  Lr: 0.030000  Loss: -1.6343  Acc@1: 68.7500 (67.1286)  Acc@5: 93.7500 (92.1147)  time: 0.3948  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 460/4579]  eta: 0:27:04  Lr: 0.030000  Loss: -1.2269  Acc@1: 62.5000 (67.0553)  Acc@5: 93.7500 (92.1773)  time: 0.3943  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 470/4579]  eta: 0:26:59  Lr: 0.030000  Loss: -1.3636  Acc@1: 62.5000 (67.1311)  Acc@5: 93.7500 (92.1709)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 480/4579]  eta: 0:26:55  Lr: 0.030000  Loss: -1.7531  Acc@1: 68.7500 (67.2427)  Acc@5: 93.7500 (92.2037)  time: 0.3904  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 490/4579]  eta: 0:26:51  Lr: 0.030000  Loss: -1.8484  Acc@1: 68.7500 (67.4007)  Acc@5: 93.7500 (92.2352)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 500/4579]  eta: 0:26:47  Lr: 0.030000  Loss: -2.3000  Acc@1: 75.0000 (67.5150)  Acc@5: 93.7500 (92.2405)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 510/4579]  eta: 0:26:43  Lr: 0.030000  Loss: -2.2043  Acc@1: 68.7500 (67.4902)  Acc@5: 93.7500 (92.2823)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 520/4579]  eta: 0:26:38  Lr: 0.030000  Loss: -1.3599  Acc@1: 68.7500 (67.5384)  Acc@5: 93.7500 (92.2505)  time: 0.3904  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 530/4579]  eta: 0:26:34  Lr: 0.030000  Loss: -1.7783  Acc@1: 68.7500 (67.5965)  Acc@5: 93.7500 (92.3140)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 540/4579]  eta: 0:26:30  Lr: 0.030000  Loss: -2.3656  Acc@1: 68.7500 (67.6409)  Acc@5: 93.7500 (92.3406)  time: 0.3904  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 550/4579]  eta: 0:26:26  Lr: 0.030000  Loss: -2.0713  Acc@1: 68.7500 (67.7064)  Acc@5: 93.7500 (92.3435)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 560/4579]  eta: 0:26:22  Lr: 0.030000  Loss: -1.2957  Acc@1: 68.7500 (67.7028)  Acc@5: 93.7500 (92.3797)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 570/4579]  eta: 0:26:17  Lr: 0.030000  Loss: -1.6557  Acc@1: 68.7500 (67.7430)  Acc@5: 93.7500 (92.3708)  time: 0.3901  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 580/4579]  eta: 0:26:13  Lr: 0.030000  Loss: -1.3759  Acc@1: 68.7500 (67.7496)  Acc@5: 93.7500 (92.4053)  time: 0.3904  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 590/4579]  eta: 0:26:09  Lr: 0.030000  Loss: -1.1155  Acc@1: 75.0000 (67.7982)  Acc@5: 93.7500 (92.4281)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 600/4579]  eta: 0:26:05  Lr: 0.030000  Loss: -1.6234  Acc@1: 75.0000 (67.9077)  Acc@5: 93.7500 (92.4189)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 610/4579]  eta: 0:26:01  Lr: 0.030000  Loss: -1.5283  Acc@1: 68.7500 (67.8294)  Acc@5: 93.7500 (92.3588)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 620/4579]  eta: 0:25:57  Lr: 0.030000  Loss: -1.3822  Acc@1: 62.5000 (67.7939)  Acc@5: 93.7500 (92.3410)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 630/4579]  eta: 0:25:53  Lr: 0.030000  Loss: -1.5753  Acc@1: 68.7500 (67.8387)  Acc@5: 93.7500 (92.3534)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 640/4579]  eta: 0:25:49  Lr: 0.030000  Loss: -1.8152  Acc@1: 68.7500 (67.8335)  Acc@5: 93.7500 (92.3264)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 650/4579]  eta: 0:25:45  Lr: 0.030000  Loss: -1.1860  Acc@1: 68.7500 (67.7515)  Acc@5: 93.7500 (92.3099)  time: 0.3900  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 660/4579]  eta: 0:25:40  Lr: 0.030000  Loss: -1.6717  Acc@1: 62.5000 (67.7099)  Acc@5: 93.7500 (92.2750)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 670/4579]  eta: 0:25:37  Lr: 0.030000  Loss: -1.5036  Acc@1: 68.7500 (67.7068)  Acc@5: 93.7500 (92.2783)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 680/4579]  eta: 0:25:32  Lr: 0.030000  Loss: -1.7247  Acc@1: 68.7500 (67.7496)  Acc@5: 93.7500 (92.2907)  time: 0.3915  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [ 690/4579]  eta: 0:25:28  Lr: 0.030000  Loss: -1.1138  Acc@1: 68.7500 (67.7732)  Acc@5: 93.7500 (92.2757)  time: 0.3908  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 700/4579]  eta: 0:25:24  Lr: 0.030000  Loss: -1.7453  Acc@1: 62.5000 (67.7693)  Acc@5: 93.7500 (92.2700)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 710/4579]  eta: 0:25:20  Lr: 0.030000  Loss: -1.7207  Acc@1: 75.0000 (67.8797)  Acc@5: 93.7500 (92.2996)  time: 0.3911  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 720/4579]  eta: 0:25:16  Lr: 0.030000  Loss: -2.2036  Acc@1: 68.7500 (67.7878)  Acc@5: 93.7500 (92.3197)  time: 0.3900  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 730/4579]  eta: 0:25:12  Lr: 0.030000  Loss: -1.3444  Acc@1: 62.5000 (67.8266)  Acc@5: 93.7500 (92.3051)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 740/4579]  eta: 0:25:08  Lr: 0.030000  Loss: -1.2578  Acc@1: 75.0000 (67.8897)  Acc@5: 93.7500 (92.3499)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 750/4579]  eta: 0:25:04  Lr: 0.030000  Loss: -1.9510  Acc@1: 75.0000 (67.9677)  Acc@5: 93.7500 (92.3519)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 760/4579]  eta: 0:25:00  Lr: 0.030000  Loss: -2.0612  Acc@1: 68.7500 (67.9862)  Acc@5: 93.7500 (92.3867)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 770/4579]  eta: 0:24:56  Lr: 0.030000  Loss: -1.5780  Acc@1: 68.7500 (67.9961)  Acc@5: 100.0000 (92.4287)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 780/4579]  eta: 0:24:52  Lr: 0.030000  Loss: -1.6589  Acc@1: 75.0000 (67.9978)  Acc@5: 93.7500 (92.4136)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 790/4579]  eta: 0:24:48  Lr: 0.030000  Loss: -1.9744  Acc@1: 75.0000 (67.9994)  Acc@5: 93.7500 (92.4305)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 800/4579]  eta: 0:24:44  Lr: 0.030000  Loss: -1.5824  Acc@1: 68.7500 (68.0087)  Acc@5: 93.7500 (92.4547)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 810/4579]  eta: 0:24:40  Lr: 0.030000  Loss: -1.4100  Acc@1: 68.7500 (68.0102)  Acc@5: 93.7500 (92.4476)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 820/4579]  eta: 0:24:36  Lr: 0.030000  Loss: -1.2767  Acc@1: 68.7500 (68.0420)  Acc@5: 93.7500 (92.4482)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 830/4579]  eta: 0:24:32  Lr: 0.030000  Loss: -1.7412  Acc@1: 75.0000 (68.1483)  Acc@5: 87.5000 (92.4188)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 840/4579]  eta: 0:24:28  Lr: 0.030000  Loss: -1.4064  Acc@1: 75.0000 (68.1926)  Acc@5: 87.5000 (92.4123)  time: 0.3915  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [ 850/4579]  eta: 0:24:24  Lr: 0.030000  Loss: -0.8366  Acc@1: 68.7500 (68.1625)  Acc@5: 87.5000 (92.3766)  time: 0.3921  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [ 860/4579]  eta: 0:24:20  Lr: 0.030000  Loss: -1.7791  Acc@1: 68.7500 (68.1983)  Acc@5: 93.7500 (92.3563)  time: 0.3912  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 870/4579]  eta: 0:24:16  Lr: 0.030000  Loss: -1.4226  Acc@1: 75.0000 (68.2262)  Acc@5: 87.5000 (92.3220)  time: 0.3920  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [ 880/4579]  eta: 0:24:12  Lr: 0.030000  Loss: -1.5264  Acc@1: 68.7500 (68.2179)  Acc@5: 87.5000 (92.3028)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 890/4579]  eta: 0:24:08  Lr: 0.030000  Loss: -2.0270  Acc@1: 68.7500 (68.2520)  Acc@5: 93.7500 (92.3050)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [ 900/4579]  eta: 0:24:05  Lr: 0.030000  Loss: -1.0911  Acc@1: 68.7500 (68.3060)  Acc@5: 93.7500 (92.3349)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 910/4579]  eta: 0:24:01  Lr: 0.030000  Loss: -1.3995  Acc@1: 68.7500 (68.3864)  Acc@5: 93.7500 (92.3916)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 920/4579]  eta: 0:23:57  Lr: 0.030000  Loss: -1.2656  Acc@1: 68.7500 (68.3768)  Acc@5: 93.7500 (92.3996)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 930/4579]  eta: 0:23:53  Lr: 0.030000  Loss: -1.6202  Acc@1: 68.7500 (68.3942)  Acc@5: 93.7500 (92.3939)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 940/4579]  eta: 0:23:49  Lr: 0.030000  Loss: -2.0534  Acc@1: 68.7500 (68.4113)  Acc@5: 93.7500 (92.4283)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 950/4579]  eta: 0:23:45  Lr: 0.030000  Loss: -1.8048  Acc@1: 75.0000 (68.4937)  Acc@5: 100.0000 (92.4685)  time: 0.3924  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [ 960/4579]  eta: 0:23:41  Lr: 0.030000  Loss: -1.6100  Acc@1: 75.0000 (68.5224)  Acc@5: 93.7500 (92.4623)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 970/4579]  eta: 0:23:37  Lr: 0.030000  Loss: -1.2380  Acc@1: 68.7500 (68.4539)  Acc@5: 93.7500 (92.4434)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 980/4579]  eta: 0:23:33  Lr: 0.030000  Loss: -1.9847  Acc@1: 62.5000 (68.4314)  Acc@5: 93.7500 (92.4312)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [ 990/4579]  eta: 0:23:29  Lr: 0.030000  Loss: -1.2711  Acc@1: 62.5000 (68.3905)  Acc@5: 93.7500 (92.4004)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1000/4579]  eta: 0:23:25  Lr: 0.030000  Loss: -1.5451  Acc@1: 62.5000 (68.3254)  Acc@5: 93.7500 (92.4013)  time: 0.3924  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [1010/4579]  eta: 0:23:21  Lr: 0.030000  Loss: -1.6480  Acc@1: 62.5000 (68.3173)  Acc@5: 93.7500 (92.4085)  time: 0.3930  data: 0.0009  max mem: 2904
Train: Epoch[3/5]  [1020/4579]  eta: 0:23:17  Lr: 0.030000  Loss: -2.1082  Acc@1: 68.7500 (68.3154)  Acc@5: 93.7500 (92.3972)  time: 0.3929  data: 0.0007  max mem: 2904
Train: Epoch[3/5]  [1030/4579]  eta: 0:23:13  Lr: 0.030000  Loss: -1.2632  Acc@1: 68.7500 (68.3135)  Acc@5: 93.7500 (92.3982)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1040/4579]  eta: 0:23:09  Lr: 0.030000  Loss: -1.8953  Acc@1: 68.7500 (68.3297)  Acc@5: 93.7500 (92.3571)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1050/4579]  eta: 0:23:05  Lr: 0.030000  Loss: -1.9101  Acc@1: 68.7500 (68.3694)  Acc@5: 87.5000 (92.3466)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1060/4579]  eta: 0:23:01  Lr: 0.030000  Loss: -2.0919  Acc@1: 68.7500 (68.3789)  Acc@5: 93.7500 (92.3716)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1070/4579]  eta: 0:22:57  Lr: 0.030000  Loss: -1.5212  Acc@1: 68.7500 (68.3532)  Acc@5: 93.7500 (92.3553)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1080/4579]  eta: 0:22:53  Lr: 0.030000  Loss: -1.3969  Acc@1: 62.5000 (68.3568)  Acc@5: 93.7500 (92.3393)  time: 0.3911  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1090/4579]  eta: 0:22:49  Lr: 0.030000  Loss: -1.8549  Acc@1: 68.7500 (68.3891)  Acc@5: 93.7500 (92.3407)  time: 0.3907  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1100/4579]  eta: 0:22:46  Lr: 0.030000  Loss: -1.9725  Acc@1: 68.7500 (68.3924)  Acc@5: 93.7500 (92.3138)  time: 0.3916  data: 0.0008  max mem: 2904
Train: Epoch[3/5]  [1110/4579]  eta: 0:22:42  Lr: 0.030000  Loss: -2.1195  Acc@1: 62.5000 (68.3112)  Acc@5: 87.5000 (92.2761)  time: 0.3929  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [1120/4579]  eta: 0:22:38  Lr: 0.030000  Loss: -1.4496  Acc@1: 62.5000 (68.3095)  Acc@5: 87.5000 (92.2837)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1130/4579]  eta: 0:22:34  Lr: 0.030000  Loss: -2.0607  Acc@1: 68.7500 (68.3134)  Acc@5: 93.7500 (92.3022)  time: 0.3918  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [1140/4579]  eta: 0:22:30  Lr: 0.030000  Loss: -1.2679  Acc@1: 62.5000 (68.2351)  Acc@5: 93.7500 (92.2820)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1150/4579]  eta: 0:22:26  Lr: 0.030000  Loss: -1.1176  Acc@1: 62.5000 (68.2613)  Acc@5: 93.7500 (92.2839)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1160/4579]  eta: 0:22:22  Lr: 0.030000  Loss: -1.6220  Acc@1: 68.7500 (68.2332)  Acc@5: 93.7500 (92.2427)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1170/4579]  eta: 0:22:18  Lr: 0.030000  Loss: -1.4446  Acc@1: 62.5000 (68.1896)  Acc@5: 87.5000 (92.2235)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1180/4579]  eta: 0:22:14  Lr: 0.030000  Loss: -1.1349  Acc@1: 68.7500 (68.1890)  Acc@5: 93.7500 (92.2206)  time: 0.3904  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1190/4579]  eta: 0:22:10  Lr: 0.030000  Loss: -1.8835  Acc@1: 68.7500 (68.2462)  Acc@5: 93.7500 (92.2492)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1200/4579]  eta: 0:22:06  Lr: 0.030000  Loss: -2.2375  Acc@1: 75.0000 (68.2608)  Acc@5: 93.7500 (92.2929)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1210/4579]  eta: 0:22:02  Lr: 0.030000  Loss: -1.8032  Acc@1: 68.7500 (68.2855)  Acc@5: 93.7500 (92.2843)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1220/4579]  eta: 0:21:58  Lr: 0.030000  Loss: -2.0314  Acc@1: 68.7500 (68.2740)  Acc@5: 93.7500 (92.2707)  time: 0.3902  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1230/4579]  eta: 0:21:54  Lr: 0.030000  Loss: -1.5938  Acc@1: 68.7500 (68.2474)  Acc@5: 93.7500 (92.2522)  time: 0.3899  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1240/4579]  eta: 0:21:50  Lr: 0.030000  Loss: -1.3338  Acc@1: 68.7500 (68.2313)  Acc@5: 93.7500 (92.2542)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1250/4579]  eta: 0:21:46  Lr: 0.030000  Loss: -2.0036  Acc@1: 68.7500 (68.2454)  Acc@5: 93.7500 (92.2712)  time: 0.3906  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1260/4579]  eta: 0:21:42  Lr: 0.030000  Loss: -1.5545  Acc@1: 68.7500 (68.2246)  Acc@5: 93.7500 (92.2581)  time: 0.3900  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1270/4579]  eta: 0:21:38  Lr: 0.030000  Loss: -1.7648  Acc@1: 68.7500 (68.2435)  Acc@5: 93.7500 (92.2797)  time: 0.3901  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1280/4579]  eta: 0:21:34  Lr: 0.030000  Loss: -1.8062  Acc@1: 68.7500 (68.2621)  Acc@5: 93.7500 (92.2814)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1290/4579]  eta: 0:21:30  Lr: 0.030000  Loss: -0.9746  Acc@1: 68.7500 (68.2465)  Acc@5: 93.7500 (92.2637)  time: 0.3921  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1300/4579]  eta: 0:21:26  Lr: 0.030000  Loss: -0.6680  Acc@1: 62.5000 (68.2071)  Acc@5: 93.7500 (92.2463)  time: 0.3911  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1310/4579]  eta: 0:21:22  Lr: 0.030000  Loss: -1.8194  Acc@1: 68.7500 (68.2113)  Acc@5: 93.7500 (92.2626)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1320/4579]  eta: 0:21:18  Lr: 0.030000  Loss: -1.3778  Acc@1: 68.7500 (68.2438)  Acc@5: 93.7500 (92.2833)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1330/4579]  eta: 0:21:14  Lr: 0.030000  Loss: -1.3457  Acc@1: 68.7500 (68.2288)  Acc@5: 93.7500 (92.2802)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1340/4579]  eta: 0:21:10  Lr: 0.030000  Loss: -1.9388  Acc@1: 62.5000 (68.2280)  Acc@5: 93.7500 (92.2819)  time: 0.3911  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1350/4579]  eta: 0:21:06  Lr: 0.030000  Loss: -1.8515  Acc@1: 62.5000 (68.2272)  Acc@5: 93.7500 (92.2650)  time: 0.3903  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1360/4579]  eta: 0:21:02  Lr: 0.030000  Loss: -1.7291  Acc@1: 68.7500 (68.2494)  Acc@5: 93.7500 (92.2805)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1370/4579]  eta: 0:20:58  Lr: 0.030000  Loss: -2.1064  Acc@1: 68.7500 (68.1984)  Acc@5: 93.7500 (92.2593)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1380/4579]  eta: 0:20:54  Lr: 0.030000  Loss: -1.7319  Acc@1: 62.5000 (68.1843)  Acc@5: 87.5000 (92.2565)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1390/4579]  eta: 0:20:51  Lr: 0.030000  Loss: -1.3708  Acc@1: 68.7500 (68.1794)  Acc@5: 93.7500 (92.2628)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1400/4579]  eta: 0:20:47  Lr: 0.030000  Loss: -1.4616  Acc@1: 68.7500 (68.1968)  Acc@5: 93.7500 (92.2645)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1410/4579]  eta: 0:20:43  Lr: 0.030000  Loss: -1.8087  Acc@1: 68.7500 (68.1963)  Acc@5: 93.7500 (92.2661)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1420/4579]  eta: 0:20:39  Lr: 0.030000  Loss: -1.3012  Acc@1: 68.7500 (68.1782)  Acc@5: 93.7500 (92.2546)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1430/4579]  eta: 0:20:35  Lr: 0.030000  Loss: -1.6285  Acc@1: 68.7500 (68.1910)  Acc@5: 93.7500 (92.2694)  time: 0.3922  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1440/4579]  eta: 0:20:31  Lr: 0.030000  Loss: -1.9189  Acc@1: 68.7500 (68.1731)  Acc@5: 93.7500 (92.2406)  time: 0.3931  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [1450/4579]  eta: 0:20:27  Lr: 0.030000  Loss: -1.4803  Acc@1: 68.7500 (68.1943)  Acc@5: 93.7500 (92.2596)  time: 0.3927  data: 0.0013  max mem: 2904
Train: Epoch[3/5]  [1460/4579]  eta: 0:20:23  Lr: 0.030000  Loss: -1.7084  Acc@1: 68.7500 (68.1939)  Acc@5: 93.7500 (92.2570)  time: 0.3932  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [1470/4579]  eta: 0:20:19  Lr: 0.030000  Loss: -1.3250  Acc@1: 68.7500 (68.1382)  Acc@5: 87.5000 (92.2289)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1480/4579]  eta: 0:20:15  Lr: 0.030000  Loss: -1.4501  Acc@1: 68.7500 (68.1465)  Acc@5: 93.7500 (92.2223)  time: 0.3928  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [1490/4579]  eta: 0:20:11  Lr: 0.030000  Loss: -1.9224  Acc@1: 68.7500 (68.1380)  Acc@5: 93.7500 (92.2242)  time: 0.3930  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [1500/4579]  eta: 0:20:07  Lr: 0.030000  Loss: -1.4999  Acc@1: 68.7500 (68.1546)  Acc@5: 93.7500 (92.2385)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1510/4579]  eta: 0:20:03  Lr: 0.030000  Loss: -1.2093  Acc@1: 68.7500 (68.1420)  Acc@5: 93.7500 (92.2444)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1520/4579]  eta: 0:20:00  Lr: 0.030000  Loss: -1.2735  Acc@1: 68.7500 (68.1460)  Acc@5: 87.5000 (92.2378)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1530/4579]  eta: 0:19:56  Lr: 0.030000  Loss: -2.0728  Acc@1: 75.0000 (68.1948)  Acc@5: 93.7500 (92.2640)  time: 0.3927  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1540/4579]  eta: 0:19:52  Lr: 0.030000  Loss: -1.1718  Acc@1: 75.0000 (68.2025)  Acc@5: 93.7500 (92.2656)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1550/4579]  eta: 0:19:48  Lr: 0.030000  Loss: -1.5306  Acc@1: 68.7500 (68.2060)  Acc@5: 93.7500 (92.2832)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1560/4579]  eta: 0:19:44  Lr: 0.030000  Loss: -1.6673  Acc@1: 68.7500 (68.2055)  Acc@5: 93.7500 (92.2966)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1570/4579]  eta: 0:19:40  Lr: 0.030000  Loss: -1.1614  Acc@1: 62.5000 (68.1891)  Acc@5: 93.7500 (92.2701)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1580/4579]  eta: 0:19:36  Lr: 0.030000  Loss: -1.0691  Acc@1: 68.7500 (68.2084)  Acc@5: 87.5000 (92.2715)  time: 0.3934  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [1590/4579]  eta: 0:19:32  Lr: 0.030000  Loss: -2.0209  Acc@1: 68.7500 (68.2197)  Acc@5: 93.7500 (92.2729)  time: 0.3923  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [1600/4579]  eta: 0:19:28  Lr: 0.030000  Loss: -1.2619  Acc@1: 68.7500 (68.2152)  Acc@5: 93.7500 (92.2822)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1610/4579]  eta: 0:19:24  Lr: 0.030000  Loss: -1.3508  Acc@1: 62.5000 (68.1875)  Acc@5: 93.7500 (92.2719)  time: 0.3914  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [1620/4579]  eta: 0:19:20  Lr: 0.030000  Loss: -1.9200  Acc@1: 68.7500 (68.1909)  Acc@5: 93.7500 (92.2579)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1630/4579]  eta: 0:19:16  Lr: 0.030000  Loss: -1.5167  Acc@1: 62.5000 (68.1101)  Acc@5: 87.5000 (92.2249)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1640/4579]  eta: 0:19:12  Lr: 0.030000  Loss: -1.5548  Acc@1: 62.5000 (68.1216)  Acc@5: 93.7500 (92.2342)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1650/4579]  eta: 0:19:08  Lr: 0.030000  Loss: -2.0074  Acc@1: 68.7500 (68.1292)  Acc@5: 93.7500 (92.2244)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1660/4579]  eta: 0:19:05  Lr: 0.030000  Loss: -1.8724  Acc@1: 68.7500 (68.1442)  Acc@5: 93.7500 (92.2223)  time: 0.3914  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1670/4579]  eta: 0:19:01  Lr: 0.030000  Loss: -2.0215  Acc@1: 68.7500 (68.1516)  Acc@5: 93.7500 (92.2202)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1680/4579]  eta: 0:18:57  Lr: 0.030000  Loss: -0.7222  Acc@1: 68.7500 (68.1402)  Acc@5: 93.7500 (92.2256)  time: 0.3911  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1690/4579]  eta: 0:18:53  Lr: 0.030000  Loss: -1.7304  Acc@1: 62.5000 (68.1143)  Acc@5: 93.7500 (92.2051)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1700/4579]  eta: 0:18:49  Lr: 0.030000  Loss: -1.6564  Acc@1: 68.7500 (68.1143)  Acc@5: 93.7500 (92.2252)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1710/4579]  eta: 0:18:45  Lr: 0.030000  Loss: -1.9280  Acc@1: 68.7500 (68.1071)  Acc@5: 93.7500 (92.2414)  time: 0.3902  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1720/4579]  eta: 0:18:41  Lr: 0.030000  Loss: -1.1329  Acc@1: 68.7500 (68.1036)  Acc@5: 93.7500 (92.2393)  time: 0.3906  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1730/4579]  eta: 0:18:37  Lr: 0.030000  Loss: -1.7143  Acc@1: 68.7500 (68.1109)  Acc@5: 93.7500 (92.2516)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1740/4579]  eta: 0:18:33  Lr: 0.030000  Loss: -1.5587  Acc@1: 68.7500 (68.0715)  Acc@5: 93.7500 (92.2638)  time: 0.3902  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1750/4579]  eta: 0:18:29  Lr: 0.030000  Loss: -1.7930  Acc@1: 68.7500 (68.0932)  Acc@5: 93.7500 (92.2687)  time: 0.3897  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1760/4579]  eta: 0:18:25  Lr: 0.030000  Loss: -1.6649  Acc@1: 68.7500 (68.1147)  Acc@5: 93.7500 (92.2665)  time: 0.3912  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [1770/4579]  eta: 0:18:21  Lr: 0.030000  Loss: -1.4383  Acc@1: 68.7500 (68.0830)  Acc@5: 93.7500 (92.2678)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1780/4579]  eta: 0:18:17  Lr: 0.030000  Loss: -1.0564  Acc@1: 68.7500 (68.0938)  Acc@5: 87.5000 (92.2551)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1790/4579]  eta: 0:18:13  Lr: 0.030000  Loss: -1.7440  Acc@1: 68.7500 (68.1044)  Acc@5: 87.5000 (92.2494)  time: 0.3910  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1800/4579]  eta: 0:18:09  Lr: 0.030000  Loss: -1.3291  Acc@1: 68.7500 (68.1080)  Acc@5: 93.7500 (92.2474)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1810/4579]  eta: 0:18:05  Lr: 0.030000  Loss: -2.0203  Acc@1: 68.7500 (68.1288)  Acc@5: 93.7500 (92.2453)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1820/4579]  eta: 0:18:01  Lr: 0.030000  Loss: -1.7454  Acc@1: 68.7500 (68.1253)  Acc@5: 93.7500 (92.2467)  time: 0.3911  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1830/4579]  eta: 0:17:58  Lr: 0.030000  Loss: -1.5505  Acc@1: 68.7500 (68.1390)  Acc@5: 93.7500 (92.2481)  time: 0.3908  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [1840/4579]  eta: 0:17:54  Lr: 0.030000  Loss: -1.2077  Acc@1: 68.7500 (68.1118)  Acc@5: 93.7500 (92.2461)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1850/4579]  eta: 0:17:50  Lr: 0.030000  Loss: -1.4750  Acc@1: 62.5000 (68.1152)  Acc@5: 93.7500 (92.2441)  time: 0.3914  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [1860/4579]  eta: 0:17:46  Lr: 0.030000  Loss: -1.5250  Acc@1: 62.5000 (68.1085)  Acc@5: 93.7500 (92.2387)  time: 0.3905  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1870/4579]  eta: 0:17:42  Lr: 0.030000  Loss: -2.3698  Acc@1: 68.7500 (68.1220)  Acc@5: 87.5000 (92.2368)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1880/4579]  eta: 0:17:38  Lr: 0.030000  Loss: -1.9324  Acc@1: 68.7500 (68.1220)  Acc@5: 93.7500 (92.2415)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1890/4579]  eta: 0:17:34  Lr: 0.030000  Loss: -1.3809  Acc@1: 68.7500 (68.1452)  Acc@5: 93.7500 (92.2561)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1900/4579]  eta: 0:17:30  Lr: 0.030000  Loss: -1.4307  Acc@1: 62.5000 (68.1188)  Acc@5: 93.7500 (92.2409)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1910/4579]  eta: 0:17:26  Lr: 0.030000  Loss: -1.6158  Acc@1: 62.5000 (68.1122)  Acc@5: 87.5000 (92.2390)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1920/4579]  eta: 0:17:22  Lr: 0.030000  Loss: -1.9914  Acc@1: 68.7500 (68.1351)  Acc@5: 93.7500 (92.2631)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1930/4579]  eta: 0:17:18  Lr: 0.030000  Loss: -1.8012  Acc@1: 68.7500 (68.1253)  Acc@5: 93.7500 (92.2644)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1940/4579]  eta: 0:17:14  Lr: 0.030000  Loss: -2.0339  Acc@1: 68.7500 (68.1607)  Acc@5: 93.7500 (92.2785)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1950/4579]  eta: 0:17:10  Lr: 0.030000  Loss: -2.0015  Acc@1: 75.0000 (68.1670)  Acc@5: 93.7500 (92.2636)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1960/4579]  eta: 0:17:07  Lr: 0.030000  Loss: -2.2563  Acc@1: 75.0000 (68.2050)  Acc@5: 93.7500 (92.2712)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1970/4579]  eta: 0:17:03  Lr: 0.030000  Loss: -2.0142  Acc@1: 68.7500 (68.2046)  Acc@5: 93.7500 (92.2818)  time: 0.3936  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [1980/4579]  eta: 0:16:59  Lr: 0.030000  Loss: -2.1178  Acc@1: 68.7500 (68.2168)  Acc@5: 93.7500 (92.2829)  time: 0.3947  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [1990/4579]  eta: 0:16:55  Lr: 0.030000  Loss: -1.3832  Acc@1: 68.7500 (68.2069)  Acc@5: 93.7500 (92.2809)  time: 0.3947  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2000/4579]  eta: 0:16:51  Lr: 0.030000  Loss: -1.4556  Acc@1: 62.5000 (68.1659)  Acc@5: 93.7500 (92.2664)  time: 0.3944  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2010/4579]  eta: 0:16:47  Lr: 0.030000  Loss: -1.7794  Acc@1: 62.5000 (68.1502)  Acc@5: 93.7500 (92.2737)  time: 0.3927  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2020/4579]  eta: 0:16:43  Lr: 0.030000  Loss: -1.1437  Acc@1: 68.7500 (68.1593)  Acc@5: 93.7500 (92.2810)  time: 0.3917  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2030/4579]  eta: 0:16:39  Lr: 0.030000  Loss: -1.3166  Acc@1: 68.7500 (68.1345)  Acc@5: 93.7500 (92.2790)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2040/4579]  eta: 0:16:35  Lr: 0.030000  Loss: -1.6119  Acc@1: 75.0000 (68.1743)  Acc@5: 93.7500 (92.2893)  time: 0.3940  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2050/4579]  eta: 0:16:31  Lr: 0.030000  Loss: -1.9850  Acc@1: 75.0000 (68.1802)  Acc@5: 93.7500 (92.2812)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2060/4579]  eta: 0:16:27  Lr: 0.030000  Loss: -1.3015  Acc@1: 68.7500 (68.2041)  Acc@5: 93.7500 (92.3035)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2070/4579]  eta: 0:16:24  Lr: 0.030000  Loss: -1.8420  Acc@1: 75.0000 (68.2158)  Acc@5: 93.7500 (92.3075)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2080/4579]  eta: 0:16:20  Lr: 0.030000  Loss: -1.7185  Acc@1: 68.7500 (68.1914)  Acc@5: 93.7500 (92.3024)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2090/4579]  eta: 0:16:16  Lr: 0.030000  Loss: -1.6493  Acc@1: 68.7500 (68.1761)  Acc@5: 93.7500 (92.3033)  time: 0.3932  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [2100/4579]  eta: 0:16:12  Lr: 0.030000  Loss: -1.4951  Acc@1: 68.7500 (68.1967)  Acc@5: 93.7500 (92.3102)  time: 0.3924  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [2110/4579]  eta: 0:16:08  Lr: 0.030000  Loss: -1.7663  Acc@1: 75.0000 (68.2260)  Acc@5: 93.7500 (92.3052)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2120/4579]  eta: 0:16:04  Lr: 0.030000  Loss: -1.2096  Acc@1: 68.7500 (68.2137)  Acc@5: 93.7500 (92.3032)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2130/4579]  eta: 0:16:00  Lr: 0.030000  Loss: -1.8228  Acc@1: 68.7500 (68.2221)  Acc@5: 87.5000 (92.2982)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2140/4579]  eta: 0:15:56  Lr: 0.030000  Loss: -1.2244  Acc@1: 68.7500 (68.2158)  Acc@5: 87.5000 (92.2904)  time: 0.3950  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2150/4579]  eta: 0:15:52  Lr: 0.030000  Loss: -1.8627  Acc@1: 75.0000 (68.2386)  Acc@5: 93.7500 (92.2972)  time: 0.3965  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2160/4579]  eta: 0:15:48  Lr: 0.030000  Loss: -1.4515  Acc@1: 75.0000 (68.2612)  Acc@5: 93.7500 (92.3010)  time: 0.3967  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2170/4579]  eta: 0:15:45  Lr: 0.030000  Loss: -1.4253  Acc@1: 75.0000 (68.2692)  Acc@5: 93.7500 (92.3163)  time: 0.3983  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2180/4579]  eta: 0:15:41  Lr: 0.030000  Loss: -1.7919  Acc@1: 75.0000 (68.3087)  Acc@5: 93.7500 (92.3229)  time: 0.3992  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [2190/4579]  eta: 0:15:37  Lr: 0.030000  Loss: -1.2414  Acc@1: 75.0000 (68.3193)  Acc@5: 93.7500 (92.3266)  time: 0.3974  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [2200/4579]  eta: 0:15:33  Lr: 0.030000  Loss: -1.5943  Acc@1: 68.7500 (68.3354)  Acc@5: 93.7500 (92.3359)  time: 0.3967  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2210/4579]  eta: 0:15:29  Lr: 0.030000  Loss: -1.9396  Acc@1: 68.7500 (68.3458)  Acc@5: 93.7500 (92.3310)  time: 0.3951  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2220/4579]  eta: 0:15:25  Lr: 0.030000  Loss: -2.0561  Acc@1: 68.7500 (68.3335)  Acc@5: 93.7500 (92.3148)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2230/4579]  eta: 0:15:21  Lr: 0.030000  Loss: -2.1394  Acc@1: 68.7500 (68.3466)  Acc@5: 93.7500 (92.3157)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2240/4579]  eta: 0:15:17  Lr: 0.030000  Loss: -2.1278  Acc@1: 68.7500 (68.3595)  Acc@5: 93.7500 (92.3249)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2250/4579]  eta: 0:15:13  Lr: 0.030000  Loss: -1.7083  Acc@1: 68.7500 (68.3474)  Acc@5: 87.5000 (92.3145)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2260/4579]  eta: 0:15:09  Lr: 0.030000  Loss: -1.4837  Acc@1: 68.7500 (68.3492)  Acc@5: 87.5000 (92.3209)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2270/4579]  eta: 0:15:06  Lr: 0.030000  Loss: -1.4332  Acc@1: 68.7500 (68.3647)  Acc@5: 93.7500 (92.3272)  time: 0.3943  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2280/4579]  eta: 0:15:02  Lr: 0.030000  Loss: -2.0150  Acc@1: 68.7500 (68.3883)  Acc@5: 93.7500 (92.3334)  time: 0.3952  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2290/4579]  eta: 0:14:58  Lr: 0.030000  Loss: -2.0523  Acc@1: 75.0000 (68.4035)  Acc@5: 93.7500 (92.3450)  time: 0.3941  data: 0.0007  max mem: 2904
Train: Epoch[3/5]  [2300/4579]  eta: 0:14:54  Lr: 0.030000  Loss: -1.5384  Acc@1: 75.0000 (68.4105)  Acc@5: 93.7500 (92.3539)  time: 0.3927  data: 0.0007  max mem: 2904
Train: Epoch[3/5]  [2310/4579]  eta: 0:14:50  Lr: 0.030000  Loss: -1.3832  Acc@1: 68.7500 (68.4038)  Acc@5: 93.7500 (92.3653)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2320/4579]  eta: 0:14:46  Lr: 0.030000  Loss: -1.8194  Acc@1: 68.7500 (68.4242)  Acc@5: 93.7500 (92.3659)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2330/4579]  eta: 0:14:42  Lr: 0.030000  Loss: -1.6676  Acc@1: 68.7500 (68.4068)  Acc@5: 93.7500 (92.3477)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2340/4579]  eta: 0:14:38  Lr: 0.030000  Loss: -1.9728  Acc@1: 68.7500 (68.4323)  Acc@5: 93.7500 (92.3537)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2350/4579]  eta: 0:14:34  Lr: 0.030000  Loss: -1.9183  Acc@1: 68.7500 (68.3991)  Acc@5: 93.7500 (92.3357)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2360/4579]  eta: 0:14:30  Lr: 0.030000  Loss: -1.1633  Acc@1: 62.5000 (68.3926)  Acc@5: 87.5000 (92.3338)  time: 0.3916  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2370/4579]  eta: 0:14:26  Lr: 0.030000  Loss: -1.6459  Acc@1: 68.7500 (68.3941)  Acc@5: 93.7500 (92.3318)  time: 0.3916  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [2380/4579]  eta: 0:14:22  Lr: 0.030000  Loss: -1.6110  Acc@1: 68.7500 (68.4035)  Acc@5: 93.7500 (92.3325)  time: 0.3924  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [2390/4579]  eta: 0:14:18  Lr: 0.030000  Loss: -1.7975  Acc@1: 68.7500 (68.4128)  Acc@5: 93.7500 (92.3358)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2400/4579]  eta: 0:14:14  Lr: 0.030000  Loss: -1.3265  Acc@1: 68.7500 (68.4012)  Acc@5: 93.7500 (92.3417)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2410/4579]  eta: 0:14:11  Lr: 0.030000  Loss: -1.9688  Acc@1: 75.0000 (68.4363)  Acc@5: 93.7500 (92.3528)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2420/4579]  eta: 0:14:07  Lr: 0.030000  Loss: -1.9462  Acc@1: 75.0000 (68.4325)  Acc@5: 93.7500 (92.3508)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2430/4579]  eta: 0:14:03  Lr: 0.030000  Loss: -1.5430  Acc@1: 68.7500 (68.4518)  Acc@5: 93.7500 (92.3617)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2440/4579]  eta: 0:13:59  Lr: 0.030000  Loss: -1.6554  Acc@1: 68.7500 (68.4402)  Acc@5: 93.7500 (92.3699)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2450/4579]  eta: 0:13:55  Lr: 0.030000  Loss: -1.5882  Acc@1: 62.5000 (68.4338)  Acc@5: 93.7500 (92.3552)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2460/4579]  eta: 0:13:51  Lr: 0.030000  Loss: -1.6958  Acc@1: 68.7500 (68.4351)  Acc@5: 93.7500 (92.3532)  time: 0.3930  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2470/4579]  eta: 0:13:47  Lr: 0.030000  Loss: -1.7880  Acc@1: 68.7500 (68.4136)  Acc@5: 87.5000 (92.3412)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2480/4579]  eta: 0:13:43  Lr: 0.030000  Loss: -1.9491  Acc@1: 62.5000 (68.4124)  Acc@5: 87.5000 (92.3317)  time: 0.3919  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2490/4579]  eta: 0:13:39  Lr: 0.030000  Loss: -1.7129  Acc@1: 62.5000 (68.4163)  Acc@5: 93.7500 (92.3249)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2500/4579]  eta: 0:13:35  Lr: 0.030000  Loss: -0.6536  Acc@1: 62.5000 (68.3901)  Acc@5: 87.5000 (92.3056)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2510/4579]  eta: 0:13:31  Lr: 0.030000  Loss: -0.9667  Acc@1: 62.5000 (68.3692)  Acc@5: 93.7500 (92.3088)  time: 0.3922  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2520/4579]  eta: 0:13:27  Lr: 0.030000  Loss: -1.5692  Acc@1: 62.5000 (68.3558)  Acc@5: 93.7500 (92.3022)  time: 0.3924  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [2530/4579]  eta: 0:13:23  Lr: 0.030000  Loss: -1.6396  Acc@1: 68.7500 (68.3623)  Acc@5: 93.7500 (92.3104)  time: 0.3937  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [2540/4579]  eta: 0:13:20  Lr: 0.030000  Loss: -1.7245  Acc@1: 68.7500 (68.3442)  Acc@5: 93.7500 (92.3037)  time: 0.3952  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [2550/4579]  eta: 0:13:16  Lr: 0.030000  Loss: -1.3017  Acc@1: 62.5000 (68.3457)  Acc@5: 93.7500 (92.3167)  time: 0.3977  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [2560/4579]  eta: 0:13:12  Lr: 0.030000  Loss: -1.8761  Acc@1: 68.7500 (68.3546)  Acc@5: 93.7500 (92.3077)  time: 0.3955  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2570/4579]  eta: 0:13:08  Lr: 0.030000  Loss: -1.0200  Acc@1: 75.0000 (68.3610)  Acc@5: 93.7500 (92.2987)  time: 0.3916  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2580/4579]  eta: 0:13:04  Lr: 0.030000  Loss: -1.0459  Acc@1: 68.7500 (68.3529)  Acc@5: 87.5000 (92.2947)  time: 0.3899  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2590/4579]  eta: 0:13:00  Lr: 0.030000  Loss: -1.5302  Acc@1: 62.5000 (68.3279)  Acc@5: 93.7500 (92.2882)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2600/4579]  eta: 0:12:56  Lr: 0.030000  Loss: -1.3227  Acc@1: 62.5000 (68.3199)  Acc@5: 93.7500 (92.2914)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2610/4579]  eta: 0:12:52  Lr: 0.030000  Loss: -1.5492  Acc@1: 68.7500 (68.3048)  Acc@5: 93.7500 (92.2827)  time: 0.3916  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2620/4579]  eta: 0:12:48  Lr: 0.030000  Loss: -1.6412  Acc@1: 68.7500 (68.3160)  Acc@5: 93.7500 (92.2835)  time: 0.3916  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2630/4579]  eta: 0:12:44  Lr: 0.030000  Loss: -2.0517  Acc@1: 75.0000 (68.3414)  Acc@5: 93.7500 (92.2867)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2640/4579]  eta: 0:12:40  Lr: 0.030000  Loss: -1.8488  Acc@1: 68.7500 (68.3406)  Acc@5: 93.7500 (92.2875)  time: 0.3926  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2650/4579]  eta: 0:12:36  Lr: 0.030000  Loss: -1.5937  Acc@1: 68.7500 (68.3398)  Acc@5: 93.7500 (92.2836)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2660/4579]  eta: 0:12:32  Lr: 0.030000  Loss: -1.7391  Acc@1: 62.5000 (68.3084)  Acc@5: 87.5000 (92.2585)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2670/4579]  eta: 0:12:29  Lr: 0.030000  Loss: -1.9137  Acc@1: 56.2500 (68.3007)  Acc@5: 87.5000 (92.2571)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2680/4579]  eta: 0:12:25  Lr: 0.030000  Loss: -2.0113  Acc@1: 68.7500 (68.3047)  Acc@5: 87.5000 (92.2510)  time: 0.3917  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2690/4579]  eta: 0:12:21  Lr: 0.030000  Loss: -2.1433  Acc@1: 68.7500 (68.3110)  Acc@5: 93.7500 (92.2659)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2700/4579]  eta: 0:12:17  Lr: 0.030000  Loss: -1.4300  Acc@1: 75.0000 (68.3173)  Acc@5: 93.7500 (92.2552)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2710/4579]  eta: 0:12:13  Lr: 0.030000  Loss: -1.4945  Acc@1: 68.7500 (68.3143)  Acc@5: 93.7500 (92.2561)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2720/4579]  eta: 0:12:09  Lr: 0.030000  Loss: -1.6741  Acc@1: 68.7500 (68.3182)  Acc@5: 93.7500 (92.2685)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2730/4579]  eta: 0:12:05  Lr: 0.030000  Loss: -1.7750  Acc@1: 68.7500 (68.3175)  Acc@5: 93.7500 (92.2579)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2740/4579]  eta: 0:12:01  Lr: 0.030000  Loss: -1.5037  Acc@1: 68.7500 (68.3236)  Acc@5: 87.5000 (92.2542)  time: 0.3923  data: 0.0008  max mem: 2904
Train: Epoch[3/5]  [2750/4579]  eta: 0:11:57  Lr: 0.030000  Loss: -1.8902  Acc@1: 68.7500 (68.3570)  Acc@5: 93.7500 (92.2619)  time: 0.3929  data: 0.0008  max mem: 2904
Train: Epoch[3/5]  [2760/4579]  eta: 0:11:53  Lr: 0.030000  Loss: -1.9162  Acc@1: 81.2500 (68.3742)  Acc@5: 93.7500 (92.2696)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2770/4579]  eta: 0:11:49  Lr: 0.030000  Loss: -1.6958  Acc@1: 68.7500 (68.3485)  Acc@5: 93.7500 (92.2726)  time: 0.3915  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2780/4579]  eta: 0:11:45  Lr: 0.030000  Loss: -1.4094  Acc@1: 62.5000 (68.3387)  Acc@5: 87.5000 (92.2577)  time: 0.3916  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2790/4579]  eta: 0:11:41  Lr: 0.030000  Loss: -1.3159  Acc@1: 62.5000 (68.3335)  Acc@5: 87.5000 (92.2407)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2800/4579]  eta: 0:11:38  Lr: 0.030000  Loss: -1.4941  Acc@1: 68.7500 (68.3372)  Acc@5: 93.7500 (92.2461)  time: 0.3921  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [2810/4579]  eta: 0:11:34  Lr: 0.030000  Loss: -1.6271  Acc@1: 68.7500 (68.3409)  Acc@5: 93.7500 (92.2381)  time: 0.3909  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2820/4579]  eta: 0:11:30  Lr: 0.030000  Loss: -1.7343  Acc@1: 68.7500 (68.3534)  Acc@5: 93.7500 (92.2412)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2830/4579]  eta: 0:11:26  Lr: 0.030000  Loss: -1.9528  Acc@1: 75.0000 (68.3592)  Acc@5: 93.7500 (92.2510)  time: 0.3929  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [2840/4579]  eta: 0:11:22  Lr: 0.030000  Loss: -1.8756  Acc@1: 68.7500 (68.3628)  Acc@5: 93.7500 (92.2474)  time: 0.3924  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [2850/4579]  eta: 0:11:18  Lr: 0.030000  Loss: -2.2132  Acc@1: 68.7500 (68.3642)  Acc@5: 93.7500 (92.2505)  time: 0.3925  data: 0.0009  max mem: 2904
Train: Epoch[3/5]  [2860/4579]  eta: 0:11:14  Lr: 0.030000  Loss: -1.5356  Acc@1: 68.7500 (68.3677)  Acc@5: 93.7500 (92.2470)  time: 0.3937  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2870/4579]  eta: 0:11:10  Lr: 0.030000  Loss: -1.3736  Acc@1: 68.7500 (68.3756)  Acc@5: 93.7500 (92.2523)  time: 0.3943  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [2880/4579]  eta: 0:11:06  Lr: 0.030000  Loss: -1.0747  Acc@1: 62.5000 (68.3638)  Acc@5: 93.7500 (92.2510)  time: 0.3929  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [2890/4579]  eta: 0:11:02  Lr: 0.030000  Loss: -2.3286  Acc@1: 68.7500 (68.3760)  Acc@5: 93.7500 (92.2583)  time: 0.3919  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2900/4579]  eta: 0:10:58  Lr: 0.030000  Loss: -0.8951  Acc@1: 68.7500 (68.3730)  Acc@5: 93.7500 (92.2570)  time: 0.3922  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [2910/4579]  eta: 0:10:54  Lr: 0.030000  Loss: -1.0160  Acc@1: 62.5000 (68.3657)  Acc@5: 93.7500 (92.2600)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2920/4579]  eta: 0:10:50  Lr: 0.030000  Loss: -1.7282  Acc@1: 62.5000 (68.3477)  Acc@5: 93.7500 (92.2608)  time: 0.3948  data: 0.0007  max mem: 2904
Train: Epoch[3/5]  [2930/4579]  eta: 0:10:47  Lr: 0.030000  Loss: -1.9592  Acc@1: 68.7500 (68.3726)  Acc@5: 93.7500 (92.2701)  time: 0.3961  data: 0.0007  max mem: 2904
Train: Epoch[3/5]  [2940/4579]  eta: 0:10:43  Lr: 0.030000  Loss: -2.2385  Acc@1: 75.0000 (68.3781)  Acc@5: 93.7500 (92.2730)  time: 0.3976  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [2950/4579]  eta: 0:10:39  Lr: 0.030000  Loss: -1.9774  Acc@1: 68.7500 (68.3836)  Acc@5: 93.7500 (92.2738)  time: 0.3953  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [2960/4579]  eta: 0:10:35  Lr: 0.030000  Loss: -1.9318  Acc@1: 68.7500 (68.3680)  Acc@5: 93.7500 (92.2703)  time: 0.3906  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [2970/4579]  eta: 0:10:31  Lr: 0.030000  Loss: -1.8148  Acc@1: 68.7500 (68.3734)  Acc@5: 93.7500 (92.2690)  time: 0.3915  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [2980/4579]  eta: 0:10:27  Lr: 0.030000  Loss: -2.0364  Acc@1: 68.7500 (68.3684)  Acc@5: 93.7500 (92.2740)  time: 0.3940  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [2990/4579]  eta: 0:10:23  Lr: 0.030000  Loss: -1.9315  Acc@1: 68.7500 (68.3634)  Acc@5: 93.7500 (92.2747)  time: 0.3941  data: 0.0013  max mem: 2904
Train: Epoch[3/5]  [3000/4579]  eta: 0:10:19  Lr: 0.030000  Loss: -2.3778  Acc@1: 68.7500 (68.3772)  Acc@5: 93.7500 (92.2651)  time: 0.3927  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [3010/4579]  eta: 0:10:15  Lr: 0.030000  Loss: -2.1078  Acc@1: 68.7500 (68.3764)  Acc@5: 93.7500 (92.2700)  time: 0.3914  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3020/4579]  eta: 0:10:11  Lr: 0.030000  Loss: -1.3949  Acc@1: 68.7500 (68.3776)  Acc@5: 93.7500 (92.2770)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3030/4579]  eta: 0:10:07  Lr: 0.030000  Loss: -1.2551  Acc@1: 68.7500 (68.3809)  Acc@5: 93.7500 (92.2633)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3040/4579]  eta: 0:10:03  Lr: 0.030000  Loss: -1.9785  Acc@1: 68.7500 (68.3718)  Acc@5: 87.5000 (92.2661)  time: 0.3900  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3050/4579]  eta: 0:09:59  Lr: 0.030000  Loss: -1.7515  Acc@1: 75.0000 (68.3895)  Acc@5: 93.7500 (92.2648)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3060/4579]  eta: 0:09:56  Lr: 0.030000  Loss: -1.7225  Acc@1: 68.7500 (68.3743)  Acc@5: 93.7500 (92.2595)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3070/4579]  eta: 0:09:52  Lr: 0.030000  Loss: -2.0573  Acc@1: 68.7500 (68.3877)  Acc@5: 93.7500 (92.2521)  time: 0.3901  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3080/4579]  eta: 0:09:48  Lr: 0.030000  Loss: -1.8057  Acc@1: 62.5000 (68.3767)  Acc@5: 93.7500 (92.2509)  time: 0.3914  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [3090/4579]  eta: 0:09:44  Lr: 0.030000  Loss: -2.0508  Acc@1: 62.5000 (68.3840)  Acc@5: 93.7500 (92.2578)  time: 0.3906  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [3100/4579]  eta: 0:09:40  Lr: 0.030000  Loss: -1.0841  Acc@1: 68.7500 (68.3872)  Acc@5: 93.7500 (92.2565)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3110/4579]  eta: 0:09:36  Lr: 0.030000  Loss: -1.7140  Acc@1: 68.7500 (68.4004)  Acc@5: 93.7500 (92.2734)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3120/4579]  eta: 0:09:32  Lr: 0.030000  Loss: -1.1986  Acc@1: 62.5000 (68.3815)  Acc@5: 93.7500 (92.2701)  time: 0.3957  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3130/4579]  eta: 0:09:28  Lr: 0.030000  Loss: -1.3561  Acc@1: 62.5000 (68.3807)  Acc@5: 93.7500 (92.2728)  time: 0.3942  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3140/4579]  eta: 0:09:24  Lr: 0.030000  Loss: -1.5101  Acc@1: 68.7500 (68.3799)  Acc@5: 93.7500 (92.2835)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3150/4579]  eta: 0:09:20  Lr: 0.030000  Loss: -1.5494  Acc@1: 68.7500 (68.3831)  Acc@5: 93.7500 (92.2644)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3160/4579]  eta: 0:09:16  Lr: 0.030000  Loss: -2.0882  Acc@1: 62.5000 (68.3427)  Acc@5: 87.5000 (92.2572)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3170/4579]  eta: 0:09:12  Lr: 0.030000  Loss: -1.8628  Acc@1: 62.5000 (68.3538)  Acc@5: 87.5000 (92.2580)  time: 0.3897  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3180/4579]  eta: 0:09:08  Lr: 0.030000  Loss: -1.3399  Acc@1: 68.7500 (68.3570)  Acc@5: 93.7500 (92.2568)  time: 0.3902  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3190/4579]  eta: 0:09:04  Lr: 0.030000  Loss: -1.4480  Acc@1: 68.7500 (68.3426)  Acc@5: 93.7500 (92.2497)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3200/4579]  eta: 0:09:01  Lr: 0.030000  Loss: -1.8996  Acc@1: 62.5000 (68.3146)  Acc@5: 87.5000 (92.2466)  time: 0.3934  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [3210/4579]  eta: 0:08:57  Lr: 0.030000  Loss: -1.8104  Acc@1: 62.5000 (68.3023)  Acc@5: 93.7500 (92.2454)  time: 0.3915  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [3220/4579]  eta: 0:08:53  Lr: 0.030000  Loss: -1.1958  Acc@1: 62.5000 (68.2940)  Acc@5: 93.7500 (92.2404)  time: 0.3904  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3230/4579]  eta: 0:08:49  Lr: 0.030000  Loss: -1.2433  Acc@1: 68.7500 (68.3012)  Acc@5: 93.7500 (92.2392)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3240/4579]  eta: 0:08:45  Lr: 0.030000  Loss: -1.4684  Acc@1: 75.0000 (68.3161)  Acc@5: 93.7500 (92.2381)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3250/4579]  eta: 0:08:41  Lr: 0.030000  Loss: -1.6479  Acc@1: 68.7500 (68.3155)  Acc@5: 93.7500 (92.2447)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3260/4579]  eta: 0:08:37  Lr: 0.030000  Loss: -1.8348  Acc@1: 68.7500 (68.3264)  Acc@5: 93.7500 (92.2474)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3270/4579]  eta: 0:08:33  Lr: 0.030000  Loss: -1.8238  Acc@1: 75.0000 (68.3411)  Acc@5: 93.7500 (92.2501)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3280/4579]  eta: 0:08:29  Lr: 0.030000  Loss: -1.5633  Acc@1: 75.0000 (68.3519)  Acc@5: 93.7500 (92.2489)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3290/4579]  eta: 0:08:25  Lr: 0.030000  Loss: -2.1500  Acc@1: 75.0000 (68.3873)  Acc@5: 93.7500 (92.2554)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3300/4579]  eta: 0:08:21  Lr: 0.030000  Loss: -1.8929  Acc@1: 75.0000 (68.3903)  Acc@5: 93.7500 (92.2637)  time: 0.3898  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3310/4579]  eta: 0:08:17  Lr: 0.030000  Loss: -2.0282  Acc@1: 68.7500 (68.3857)  Acc@5: 93.7500 (92.2569)  time: 0.3904  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [3320/4579]  eta: 0:08:13  Lr: 0.030000  Loss: -1.5202  Acc@1: 62.5000 (68.3717)  Acc@5: 93.7500 (92.2501)  time: 0.3907  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [3330/4579]  eta: 0:08:09  Lr: 0.030000  Loss: -1.3286  Acc@1: 62.5000 (68.3729)  Acc@5: 93.7500 (92.2565)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3340/4579]  eta: 0:08:06  Lr: 0.030000  Loss: -1.2320  Acc@1: 68.7500 (68.3833)  Acc@5: 93.7500 (92.2516)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3350/4579]  eta: 0:08:02  Lr: 0.030000  Loss: -1.9097  Acc@1: 68.7500 (68.3863)  Acc@5: 93.7500 (92.2542)  time: 0.3938  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [3360/4579]  eta: 0:07:58  Lr: 0.030000  Loss: -1.4382  Acc@1: 68.7500 (68.3930)  Acc@5: 93.7500 (92.2530)  time: 0.3934  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [3370/4579]  eta: 0:07:54  Lr: 0.030000  Loss: -1.3343  Acc@1: 68.7500 (68.3810)  Acc@5: 93.7500 (92.2538)  time: 0.3910  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [3380/4579]  eta: 0:07:50  Lr: 0.030000  Loss: -1.2293  Acc@1: 62.5000 (68.3710)  Acc@5: 93.7500 (92.2527)  time: 0.3926  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [3390/4579]  eta: 0:07:46  Lr: 0.030000  Loss: -1.3675  Acc@1: 62.5000 (68.3685)  Acc@5: 93.7500 (92.2552)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3400/4579]  eta: 0:07:42  Lr: 0.030000  Loss: -1.7054  Acc@1: 75.0000 (68.3806)  Acc@5: 93.7500 (92.2560)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3410/4579]  eta: 0:07:38  Lr: 0.030000  Loss: -1.8408  Acc@1: 68.7500 (68.3725)  Acc@5: 93.7500 (92.2512)  time: 0.3914  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [3420/4579]  eta: 0:07:34  Lr: 0.030000  Loss: -1.8273  Acc@1: 68.7500 (68.3864)  Acc@5: 87.5000 (92.2428)  time: 0.3948  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3430/4579]  eta: 0:07:30  Lr: 0.030000  Loss: -1.2903  Acc@1: 68.7500 (68.3875)  Acc@5: 87.5000 (92.2381)  time: 0.3967  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3440/4579]  eta: 0:07:26  Lr: 0.030000  Loss: -1.4444  Acc@1: 68.7500 (68.3940)  Acc@5: 93.7500 (92.2388)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3450/4579]  eta: 0:07:22  Lr: 0.030000  Loss: -1.5791  Acc@1: 75.0000 (68.4150)  Acc@5: 93.7500 (92.2522)  time: 0.3927  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [3460/4579]  eta: 0:07:19  Lr: 0.030000  Loss: -1.6858  Acc@1: 75.0000 (68.4105)  Acc@5: 93.7500 (92.2512)  time: 0.3938  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [3470/4579]  eta: 0:07:15  Lr: 0.030000  Loss: -1.5146  Acc@1: 68.7500 (68.4097)  Acc@5: 87.5000 (92.2393)  time: 0.3941  data: 0.0018  max mem: 2904
Train: Epoch[3/5]  [3480/4579]  eta: 0:07:11  Lr: 0.030000  Loss: -2.0996  Acc@1: 68.7500 (68.4017)  Acc@5: 93.7500 (92.2472)  time: 0.3930  data: 0.0019  max mem: 2904
Train: Epoch[3/5]  [3490/4579]  eta: 0:07:07  Lr: 0.030000  Loss: -1.9106  Acc@1: 68.7500 (68.4170)  Acc@5: 93.7500 (92.2497)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3500/4579]  eta: 0:07:03  Lr: 0.030000  Loss: -2.5033  Acc@1: 68.7500 (68.4304)  Acc@5: 93.7500 (92.2522)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3510/4579]  eta: 0:06:59  Lr: 0.030000  Loss: -1.6289  Acc@1: 75.0000 (68.4420)  Acc@5: 93.7500 (92.2529)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3520/4579]  eta: 0:06:55  Lr: 0.030000  Loss: -1.6549  Acc@1: 68.7500 (68.4429)  Acc@5: 93.7500 (92.2572)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3530/4579]  eta: 0:06:51  Lr: 0.030000  Loss: -1.2806  Acc@1: 62.5000 (68.4261)  Acc@5: 93.7500 (92.2525)  time: 0.3903  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3540/4579]  eta: 0:06:47  Lr: 0.030000  Loss: -1.1162  Acc@1: 62.5000 (68.4164)  Acc@5: 87.5000 (92.2427)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3550/4579]  eta: 0:06:43  Lr: 0.030000  Loss: -2.2450  Acc@1: 68.7500 (68.4173)  Acc@5: 93.7500 (92.2416)  time: 0.3928  data: 0.0013  max mem: 2904
Train: Epoch[3/5]  [3560/4579]  eta: 0:06:39  Lr: 0.030000  Loss: -2.0076  Acc@1: 68.7500 (68.4235)  Acc@5: 93.7500 (92.2423)  time: 0.3936  data: 0.0020  max mem: 2904
Train: Epoch[3/5]  [3570/4579]  eta: 0:06:35  Lr: 0.030000  Loss: -2.0308  Acc@1: 75.0000 (68.4472)  Acc@5: 93.7500 (92.2518)  time: 0.3913  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [3580/4579]  eta: 0:06:31  Lr: 0.030000  Loss: -1.4872  Acc@1: 75.0000 (68.4428)  Acc@5: 93.7500 (92.2473)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3590/4579]  eta: 0:06:27  Lr: 0.030000  Loss: -2.1069  Acc@1: 68.7500 (68.4593)  Acc@5: 93.7500 (92.2480)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3600/4579]  eta: 0:06:24  Lr: 0.030000  Loss: -1.6026  Acc@1: 68.7500 (68.4584)  Acc@5: 93.7500 (92.2487)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3610/4579]  eta: 0:06:20  Lr: 0.030000  Loss: -1.5707  Acc@1: 68.7500 (68.4679)  Acc@5: 93.7500 (92.2494)  time: 0.3932  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3620/4579]  eta: 0:06:16  Lr: 0.030000  Loss: -1.9664  Acc@1: 68.7500 (68.4756)  Acc@5: 93.7500 (92.2656)  time: 0.3930  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [3630/4579]  eta: 0:06:12  Lr: 0.030000  Loss: -1.8448  Acc@1: 68.7500 (68.4729)  Acc@5: 100.0000 (92.2749)  time: 0.3927  data: 0.0017  max mem: 2904
Train: Epoch[3/5]  [3640/4579]  eta: 0:06:08  Lr: 0.030000  Loss: -1.7852  Acc@1: 62.5000 (68.4719)  Acc@5: 93.7500 (92.2789)  time: 0.3928  data: 0.0025  max mem: 2904
Train: Epoch[3/5]  [3650/4579]  eta: 0:06:04  Lr: 0.030000  Loss: -1.2739  Acc@1: 68.7500 (68.4641)  Acc@5: 93.7500 (92.2778)  time: 0.3918  data: 0.0020  max mem: 2904
Train: Epoch[3/5]  [3660/4579]  eta: 0:06:00  Lr: 0.030000  Loss: -2.3860  Acc@1: 68.7500 (68.4751)  Acc@5: 93.7500 (92.2767)  time: 0.3911  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [3670/4579]  eta: 0:05:56  Lr: 0.030000  Loss: -1.5660  Acc@1: 68.7500 (68.4776)  Acc@5: 87.5000 (92.2654)  time: 0.3919  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [3680/4579]  eta: 0:05:52  Lr: 0.030000  Loss: -1.6434  Acc@1: 68.7500 (68.4817)  Acc@5: 93.7500 (92.2660)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3690/4579]  eta: 0:05:48  Lr: 0.030000  Loss: -1.6151  Acc@1: 75.0000 (68.4926)  Acc@5: 93.7500 (92.2751)  time: 0.3917  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:44  Lr: 0.030000  Loss: -1.3348  Acc@1: 68.7500 (68.4866)  Acc@5: 93.7500 (92.2707)  time: 0.3905  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3710/4579]  eta: 0:05:40  Lr: 0.030000  Loss: -1.7464  Acc@1: 68.7500 (68.4906)  Acc@5: 93.7500 (92.2747)  time: 0.3914  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [3720/4579]  eta: 0:05:36  Lr: 0.030000  Loss: -1.6131  Acc@1: 68.7500 (68.4846)  Acc@5: 93.7500 (92.2685)  time: 0.3918  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [3730/4579]  eta: 0:05:33  Lr: 0.030000  Loss: -2.0494  Acc@1: 68.7500 (68.4786)  Acc@5: 93.7500 (92.2759)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3740/4579]  eta: 0:05:29  Lr: 0.030000  Loss: -1.4282  Acc@1: 68.7500 (68.4860)  Acc@5: 93.7500 (92.2748)  time: 0.3920  data: 0.0007  max mem: 2904
Train: Epoch[3/5]  [3750/4579]  eta: 0:05:25  Lr: 0.030000  Loss: -1.0701  Acc@1: 75.0000 (68.4751)  Acc@5: 93.7500 (92.2671)  time: 0.3916  data: 0.0007  max mem: 2904
Train: Epoch[3/5]  [3760/4579]  eta: 0:05:21  Lr: 0.030000  Loss: -1.5444  Acc@1: 68.7500 (68.4825)  Acc@5: 87.5000 (92.2594)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3770/4579]  eta: 0:05:17  Lr: 0.030000  Loss: -1.2522  Acc@1: 75.0000 (68.4964)  Acc@5: 93.7500 (92.2716)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3780/4579]  eta: 0:05:13  Lr: 0.030000  Loss: -1.5849  Acc@1: 68.7500 (68.4954)  Acc@5: 93.7500 (92.2722)  time: 0.3921  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [3790/4579]  eta: 0:05:09  Lr: 0.030000  Loss: -1.4340  Acc@1: 68.7500 (68.4895)  Acc@5: 93.7500 (92.2745)  time: 0.3909  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [3800/4579]  eta: 0:05:05  Lr: 0.030000  Loss: -1.9628  Acc@1: 62.5000 (68.4803)  Acc@5: 93.7500 (92.2800)  time: 0.3914  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3810/4579]  eta: 0:05:01  Lr: 0.030000  Loss: -1.4021  Acc@1: 62.5000 (68.4679)  Acc@5: 93.7500 (92.2806)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3820/4579]  eta: 0:04:57  Lr: 0.030000  Loss: -1.9947  Acc@1: 62.5000 (68.4638)  Acc@5: 93.7500 (92.2877)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3830/4579]  eta: 0:04:53  Lr: 0.030000  Loss: -1.8753  Acc@1: 68.7500 (68.4645)  Acc@5: 93.7500 (92.2882)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3840/4579]  eta: 0:04:49  Lr: 0.030000  Loss: -1.9673  Acc@1: 68.7500 (68.4750)  Acc@5: 93.7500 (92.2986)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [3850/4579]  eta: 0:04:45  Lr: 0.030000  Loss: -2.0861  Acc@1: 68.7500 (68.4709)  Acc@5: 93.7500 (92.2991)  time: 0.3921  data: 0.0013  max mem: 2904
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:42  Lr: 0.030000  Loss: -1.6536  Acc@1: 75.0000 (68.4861)  Acc@5: 93.7500 (92.3077)  time: 0.3918  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:38  Lr: 0.030000  Loss: -1.6607  Acc@1: 75.0000 (68.4917)  Acc@5: 93.7500 (92.3130)  time: 0.3922  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:34  Lr: 0.030000  Loss: -1.8613  Acc@1: 68.7500 (68.4956)  Acc@5: 93.7500 (92.3135)  time: 0.3929  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3890/4579]  eta: 0:04:30  Lr: 0.030000  Loss: -1.6494  Acc@1: 68.7500 (68.5010)  Acc@5: 93.7500 (92.3220)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [3900/4579]  eta: 0:04:26  Lr: 0.030000  Loss: -1.6638  Acc@1: 68.7500 (68.5065)  Acc@5: 93.7500 (92.3241)  time: 0.3915  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [3910/4579]  eta: 0:04:22  Lr: 0.030000  Loss: -1.2200  Acc@1: 68.7500 (68.5055)  Acc@5: 93.7500 (92.3325)  time: 0.3923  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [3920/4579]  eta: 0:04:18  Lr: 0.030000  Loss: -0.6615  Acc@1: 68.7500 (68.4982)  Acc@5: 93.7500 (92.3282)  time: 0.3943  data: 0.0026  max mem: 2904
Train: Epoch[3/5]  [3930/4579]  eta: 0:04:14  Lr: 0.030000  Loss: -1.1152  Acc@1: 68.7500 (68.4988)  Acc@5: 93.7500 (92.3270)  time: 0.3956  data: 0.0032  max mem: 2904
Train: Epoch[3/5]  [3940/4579]  eta: 0:04:10  Lr: 0.030000  Loss: -1.7374  Acc@1: 68.7500 (68.4915)  Acc@5: 93.7500 (92.3195)  time: 0.3962  data: 0.0019  max mem: 2904
Train: Epoch[3/5]  [3950/4579]  eta: 0:04:06  Lr: 0.030000  Loss: -2.1721  Acc@1: 68.7500 (68.4969)  Acc@5: 93.7500 (92.3216)  time: 0.3963  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [3960/4579]  eta: 0:04:02  Lr: 0.030000  Loss: -2.2024  Acc@1: 75.0000 (68.5102)  Acc@5: 93.7500 (92.3236)  time: 0.3936  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [3970/4579]  eta: 0:03:58  Lr: 0.030000  Loss: -1.7565  Acc@1: 68.7500 (68.4950)  Acc@5: 93.7500 (92.3162)  time: 0.3916  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [3980/4579]  eta: 0:03:54  Lr: 0.030000  Loss: -1.6704  Acc@1: 62.5000 (68.4815)  Acc@5: 93.7500 (92.3119)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [3990/4579]  eta: 0:03:51  Lr: 0.030000  Loss: -1.9481  Acc@1: 68.7500 (68.4916)  Acc@5: 93.7500 (92.3077)  time: 0.3928  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4000/4579]  eta: 0:03:47  Lr: 0.030000  Loss: -0.7792  Acc@1: 68.7500 (68.4954)  Acc@5: 93.7500 (92.3129)  time: 0.3935  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:43  Lr: 0.030000  Loss: -1.5943  Acc@1: 68.7500 (68.4929)  Acc@5: 93.7500 (92.3118)  time: 0.3916  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:39  Lr: 0.030000  Loss: -1.4519  Acc@1: 68.7500 (68.4873)  Acc@5: 87.5000 (92.3014)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:35  Lr: 0.030000  Loss: -1.7869  Acc@1: 68.7500 (68.4926)  Acc@5: 93.7500 (92.3081)  time: 0.3938  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:31  Lr: 0.030000  Loss: -1.4299  Acc@1: 68.7500 (68.4793)  Acc@5: 93.7500 (92.3116)  time: 0.3944  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:27  Lr: 0.030000  Loss: -1.2057  Acc@1: 62.5000 (68.4661)  Acc@5: 87.5000 (92.2997)  time: 0.3930  data: 0.0012  max mem: 2904
Train: Epoch[3/5]  [4060/4579]  eta: 0:03:23  Lr: 0.030000  Loss: -1.7827  Acc@1: 68.7500 (68.4668)  Acc@5: 93.7500 (92.3095)  time: 0.3916  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [4070/4579]  eta: 0:03:19  Lr: 0.030000  Loss: -1.8009  Acc@1: 68.7500 (68.4767)  Acc@5: 93.7500 (92.3130)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4080/4579]  eta: 0:03:15  Lr: 0.030000  Loss: -1.7637  Acc@1: 75.0000 (68.4805)  Acc@5: 93.7500 (92.3135)  time: 0.3935  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4090/4579]  eta: 0:03:11  Lr: 0.030000  Loss: -1.6459  Acc@1: 75.0000 (68.4918)  Acc@5: 93.7500 (92.3185)  time: 0.3941  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [4100/4579]  eta: 0:03:07  Lr: 0.030000  Loss: -1.8782  Acc@1: 75.0000 (68.4955)  Acc@5: 93.7500 (92.3250)  time: 0.3941  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [4110/4579]  eta: 0:03:04  Lr: 0.030000  Loss: -1.8534  Acc@1: 68.7500 (68.4976)  Acc@5: 93.7500 (92.3300)  time: 0.3935  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [4120/4579]  eta: 0:03:00  Lr: 0.030000  Loss: -1.7472  Acc@1: 68.7500 (68.5058)  Acc@5: 93.7500 (92.3380)  time: 0.3927  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [4130/4579]  eta: 0:02:56  Lr: 0.030000  Loss: -1.9822  Acc@1: 68.7500 (68.5110)  Acc@5: 93.7500 (92.3414)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [4140/4579]  eta: 0:02:52  Lr: 0.030000  Loss: -1.5163  Acc@1: 68.7500 (68.5100)  Acc@5: 93.7500 (92.3388)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:48  Lr: 0.030000  Loss: -2.2624  Acc@1: 68.7500 (68.5196)  Acc@5: 93.7500 (92.3407)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:44  Lr: 0.030000  Loss: -1.2160  Acc@1: 68.7500 (68.5142)  Acc@5: 93.7500 (92.3441)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:40  Lr: 0.030000  Loss: -1.6831  Acc@1: 68.7500 (68.5222)  Acc@5: 93.7500 (92.3475)  time: 0.3947  data: 0.0020  max mem: 2904
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:36  Lr: 0.030000  Loss: -1.0112  Acc@1: 62.5000 (68.5183)  Acc@5: 93.7500 (92.3508)  time: 0.3948  data: 0.0020  max mem: 2904
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:32  Lr: 0.030000  Loss: -1.3538  Acc@1: 62.5000 (68.5039)  Acc@5: 93.7500 (92.3467)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:28  Lr: 0.030000  Loss: -1.9032  Acc@1: 62.5000 (68.5030)  Acc@5: 93.7500 (92.3471)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:24  Lr: 0.030000  Loss: -2.3364  Acc@1: 68.7500 (68.5007)  Acc@5: 93.7500 (92.3355)  time: 0.3923  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:20  Lr: 0.030000  Loss: -1.4488  Acc@1: 68.7500 (68.4998)  Acc@5: 87.5000 (92.3256)  time: 0.3918  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:16  Lr: 0.030000  Loss: -1.3936  Acc@1: 75.0000 (68.5092)  Acc@5: 93.7500 (92.3319)  time: 0.3918  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [4240/4579]  eta: 0:02:13  Lr: 0.030000  Loss: -1.6232  Acc@1: 75.0000 (68.5186)  Acc@5: 93.7500 (92.3338)  time: 0.3933  data: 0.0025  max mem: 2904
Train: Epoch[3/5]  [4250/4579]  eta: 0:02:09  Lr: 0.030000  Loss: -1.8135  Acc@1: 68.7500 (68.5133)  Acc@5: 93.7500 (92.3327)  time: 0.3925  data: 0.0018  max mem: 2904
Train: Epoch[3/5]  [4260/4579]  eta: 0:02:05  Lr: 0.030000  Loss: -2.3777  Acc@1: 68.7500 (68.5168)  Acc@5: 93.7500 (92.3448)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4270/4579]  eta: 0:02:01  Lr: 0.030000  Loss: -1.2329  Acc@1: 75.0000 (68.5334)  Acc@5: 93.7500 (92.3423)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4280/4579]  eta: 0:01:57  Lr: 0.030000  Loss: -1.3264  Acc@1: 68.7500 (68.5193)  Acc@5: 93.7500 (92.3412)  time: 0.3916  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:53  Lr: 0.030000  Loss: -1.7918  Acc@1: 62.5000 (68.5170)  Acc@5: 93.7500 (92.3401)  time: 0.3940  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:49  Lr: 0.030000  Loss: -1.7977  Acc@1: 68.7500 (68.5117)  Acc@5: 87.5000 (92.3303)  time: 0.3963  data: 0.0005  max mem: 2904
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:45  Lr: 0.030000  Loss: -2.0771  Acc@1: 68.7500 (68.5238)  Acc@5: 93.7500 (92.3336)  time: 0.3962  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:41  Lr: 0.030000  Loss: -1.8862  Acc@1: 75.0000 (68.5287)  Acc@5: 93.7500 (92.3340)  time: 0.3944  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:37  Lr: 0.030000  Loss: -1.2292  Acc@1: 56.2500 (68.5061)  Acc@5: 93.7500 (92.3271)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:33  Lr: 0.030000  Loss: -1.5181  Acc@1: 56.2500 (68.5052)  Acc@5: 87.5000 (92.3246)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:29  Lr: 0.030000  Loss: -1.7873  Acc@1: 68.7500 (68.5001)  Acc@5: 93.7500 (92.3222)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:25  Lr: 0.030000  Loss: -2.0347  Acc@1: 68.7500 (68.5006)  Acc@5: 93.7500 (92.3183)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:22  Lr: 0.030000  Loss: -1.9961  Acc@1: 68.7500 (68.5026)  Acc@5: 93.7500 (92.3216)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:18  Lr: 0.030000  Loss: -1.3812  Acc@1: 68.7500 (68.5046)  Acc@5: 93.7500 (92.3177)  time: 0.3889  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:14  Lr: 0.030000  Loss: -1.8876  Acc@1: 68.7500 (68.5038)  Acc@5: 93.7500 (92.3138)  time: 0.3895  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:10  Lr: 0.030000  Loss: -2.2260  Acc@1: 68.7500 (68.5072)  Acc@5: 93.7500 (92.3128)  time: 0.3907  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [4410/4579]  eta: 0:01:06  Lr: 0.030000  Loss: -1.9730  Acc@1: 68.7500 (68.5261)  Acc@5: 93.7500 (92.3161)  time: 0.3905  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [4420/4579]  eta: 0:01:02  Lr: 0.030000  Loss: -2.1062  Acc@1: 68.7500 (68.5365)  Acc@5: 93.7500 (92.3250)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4430/4579]  eta: 0:00:58  Lr: 0.030000  Loss: -2.2142  Acc@1: 68.7500 (68.5427)  Acc@5: 93.7500 (92.3282)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:54  Lr: 0.030000  Loss: -2.0653  Acc@1: 68.7500 (68.5445)  Acc@5: 93.7500 (92.3300)  time: 0.3902  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:50  Lr: 0.030000  Loss: -1.6221  Acc@1: 68.7500 (68.5464)  Acc@5: 93.7500 (92.3262)  time: 0.3926  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:46  Lr: 0.030000  Loss: -2.1740  Acc@1: 68.7500 (68.5469)  Acc@5: 93.7500 (92.3209)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:42  Lr: 0.030000  Loss: -1.6973  Acc@1: 62.5000 (68.5403)  Acc@5: 93.7500 (92.3200)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:38  Lr: 0.030000  Loss: -1.8045  Acc@1: 68.7500 (68.5505)  Acc@5: 93.7500 (92.3245)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:34  Lr: 0.030000  Loss: -1.8880  Acc@1: 68.7500 (68.5496)  Acc@5: 93.7500 (92.3194)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:30  Lr: 0.030000  Loss: -2.0055  Acc@1: 68.7500 (68.5487)  Acc@5: 93.7500 (92.3156)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:27  Lr: 0.030000  Loss: -2.0683  Acc@1: 68.7500 (68.5519)  Acc@5: 93.7500 (92.3160)  time: 0.3941  data: 0.0010  max mem: 2904
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:23  Lr: 0.030000  Loss: -1.7851  Acc@1: 68.7500 (68.5551)  Acc@5: 93.7500 (92.3136)  time: 0.3954  data: 0.0011  max mem: 2904
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:19  Lr: 0.030000  Loss: -0.9411  Acc@1: 68.7500 (68.5445)  Acc@5: 93.7500 (92.3058)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:15  Lr: 0.030000  Loss: -2.0343  Acc@1: 62.5000 (68.5367)  Acc@5: 93.7500 (92.3076)  time: 0.3910  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:11  Lr: 0.030000  Loss: -1.3863  Acc@1: 68.7500 (68.5413)  Acc@5: 93.7500 (92.3053)  time: 0.3923  data: 0.0006  max mem: 2904
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:07  Lr: 0.030000  Loss: -1.4941  Acc@1: 75.0000 (68.5650)  Acc@5: 93.7500 (92.3112)  time: 0.3936  data: 0.0013  max mem: 2904
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: -1.1597  Acc@1: 75.0000 (68.5681)  Acc@5: 93.7500 (92.3130)  time: 0.3938  data: 0.0020  max mem: 2904
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: -1.8699  Acc@1: 68.7500 (68.5627)  Acc@5: 93.7500 (92.3161)  time: 0.3847  data: 0.0011  max mem: 2904
Train: Epoch[3/5] Total time: 0:29:57 (0.3925 s / it)
{0: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.8699  Acc@1: 68.7500 (68.5627)  Acc@5: 93.7500 (92.3161)
Train: Epoch[4/5]  [   0/4579]  eta: 0:47:38  Lr: 0.030000  Loss: -1.3844  Acc@1: 50.0000 (50.0000)  Acc@5: 81.2500 (81.2500)  time: 0.6242  data: 0.2239  max mem: 2904
Train: Epoch[4/5]  [  10/4579]  eta: 0:31:27  Lr: 0.030000  Loss: -0.5828  Acc@1: 62.5000 (61.3636)  Acc@5: 93.7500 (89.7727)  time: 0.4132  data: 0.0207  max mem: 2904
Train: Epoch[4/5]  [  20/4579]  eta: 0:30:46  Lr: 0.030000  Loss: -1.4443  Acc@1: 62.5000 (63.6905)  Acc@5: 93.7500 (90.7738)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [  30/4579]  eta: 0:30:30  Lr: 0.030000  Loss: -1.4645  Acc@1: 68.7500 (66.3306)  Acc@5: 93.7500 (91.9355)  time: 0.3965  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [  40/4579]  eta: 0:30:18  Lr: 0.030000  Loss: -1.6933  Acc@1: 68.7500 (67.8354)  Acc@5: 93.7500 (92.0732)  time: 0.3960  data: 0.0013  max mem: 2904
Train: Epoch[4/5]  [  50/4579]  eta: 0:30:07  Lr: 0.030000  Loss: -1.0738  Acc@1: 68.7500 (66.9118)  Acc@5: 87.5000 (91.6667)  time: 0.3939  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [  60/4579]  eta: 0:29:58  Lr: 0.030000  Loss: -1.3548  Acc@1: 75.0000 (67.9303)  Acc@5: 87.5000 (92.1107)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [  70/4579]  eta: 0:29:51  Lr: 0.030000  Loss: -1.4693  Acc@1: 75.0000 (68.4859)  Acc@5: 87.5000 (91.8134)  time: 0.3931  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [  80/4579]  eta: 0:29:44  Lr: 0.030000  Loss: -2.1657  Acc@1: 68.7500 (68.3642)  Acc@5: 87.5000 (91.8210)  time: 0.3928  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [  90/4579]  eta: 0:29:38  Lr: 0.030000  Loss: -1.5224  Acc@1: 68.7500 (68.4753)  Acc@5: 93.7500 (92.1016)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 100/4579]  eta: 0:29:32  Lr: 0.030000  Loss: -1.6885  Acc@1: 68.7500 (68.8738)  Acc@5: 93.7500 (92.3886)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 110/4579]  eta: 0:29:27  Lr: 0.030000  Loss: -1.2583  Acc@1: 68.7500 (69.2568)  Acc@5: 93.7500 (92.3986)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 120/4579]  eta: 0:29:22  Lr: 0.030000  Loss: -1.7047  Acc@1: 68.7500 (68.8017)  Acc@5: 93.7500 (92.1488)  time: 0.3927  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 130/4579]  eta: 0:29:17  Lr: 0.030000  Loss: -2.2647  Acc@1: 68.7500 (69.0363)  Acc@5: 93.7500 (92.1756)  time: 0.3925  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [ 140/4579]  eta: 0:29:12  Lr: 0.030000  Loss: -1.7408  Acc@1: 68.7500 (69.2819)  Acc@5: 93.7500 (92.3316)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 150/4579]  eta: 0:29:07  Lr: 0.030000  Loss: -1.2364  Acc@1: 68.7500 (69.2467)  Acc@5: 93.7500 (92.1772)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 160/4579]  eta: 0:29:03  Lr: 0.030000  Loss: -1.5580  Acc@1: 62.5000 (68.9053)  Acc@5: 93.7500 (92.1972)  time: 0.3919  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 170/4579]  eta: 0:28:58  Lr: 0.030000  Loss: -1.4783  Acc@1: 68.7500 (68.8231)  Acc@5: 93.7500 (92.2149)  time: 0.3917  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 180/4579]  eta: 0:28:53  Lr: 0.030000  Loss: -2.0859  Acc@1: 68.7500 (68.8191)  Acc@5: 93.7500 (92.3343)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 190/4579]  eta: 0:28:49  Lr: 0.030000  Loss: -1.8548  Acc@1: 68.7500 (68.6846)  Acc@5: 93.7500 (92.2448)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 200/4579]  eta: 0:28:44  Lr: 0.030000  Loss: -1.4556  Acc@1: 68.7500 (68.6567)  Acc@5: 87.5000 (92.0709)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 210/4579]  eta: 0:28:40  Lr: 0.030000  Loss: -1.4958  Acc@1: 68.7500 (68.4242)  Acc@5: 93.7500 (92.0912)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 220/4579]  eta: 0:28:36  Lr: 0.030000  Loss: -2.4586  Acc@1: 68.7500 (68.7217)  Acc@5: 93.7500 (92.2511)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 230/4579]  eta: 0:28:31  Lr: 0.030000  Loss: -2.0416  Acc@1: 75.0000 (68.8853)  Acc@5: 93.7500 (92.3160)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 240/4579]  eta: 0:28:27  Lr: 0.030000  Loss: -2.0001  Acc@1: 75.0000 (68.9315)  Acc@5: 93.7500 (92.2459)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 250/4579]  eta: 0:28:23  Lr: 0.030000  Loss: -1.5813  Acc@1: 68.7500 (69.0986)  Acc@5: 93.7500 (92.3058)  time: 0.3919  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 260/4579]  eta: 0:28:19  Lr: 0.030000  Loss: -1.1876  Acc@1: 68.7500 (69.0374)  Acc@5: 93.7500 (92.3132)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [ 270/4579]  eta: 0:28:15  Lr: 0.030000  Loss: -1.4909  Acc@1: 68.7500 (68.8884)  Acc@5: 93.7500 (92.3662)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [ 280/4579]  eta: 0:28:11  Lr: 0.030000  Loss: -1.9732  Acc@1: 68.7500 (68.9502)  Acc@5: 93.7500 (92.3043)  time: 0.3935  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 290/4579]  eta: 0:28:06  Lr: 0.030000  Loss: -1.3402  Acc@1: 68.7500 (68.9003)  Acc@5: 93.7500 (92.3754)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 300/4579]  eta: 0:28:03  Lr: 0.030000  Loss: -1.1789  Acc@1: 62.5000 (68.7085)  Acc@5: 93.7500 (92.3173)  time: 0.3923  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [ 310/4579]  eta: 0:27:59  Lr: 0.030000  Loss: -1.4240  Acc@1: 62.5000 (68.5088)  Acc@5: 93.7500 (92.2830)  time: 0.3939  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [ 320/4579]  eta: 0:27:54  Lr: 0.030000  Loss: -1.7458  Acc@1: 62.5000 (68.4579)  Acc@5: 93.7500 (92.2702)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 330/4579]  eta: 0:27:50  Lr: 0.030000  Loss: -1.5104  Acc@1: 68.7500 (68.5423)  Acc@5: 93.7500 (92.3150)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 340/4579]  eta: 0:27:46  Lr: 0.030000  Loss: -1.6178  Acc@1: 68.7500 (68.4751)  Acc@5: 93.7500 (92.2837)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 350/4579]  eta: 0:27:42  Lr: 0.030000  Loss: -1.6531  Acc@1: 68.7500 (68.5719)  Acc@5: 93.7500 (92.2543)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 360/4579]  eta: 0:27:38  Lr: 0.030000  Loss: -1.4979  Acc@1: 68.7500 (68.5422)  Acc@5: 93.7500 (92.2611)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 370/4579]  eta: 0:27:34  Lr: 0.030000  Loss: -2.1331  Acc@1: 68.7500 (68.5310)  Acc@5: 93.7500 (92.2338)  time: 0.3914  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 380/4579]  eta: 0:27:30  Lr: 0.030000  Loss: -2.2289  Acc@1: 68.7500 (68.6352)  Acc@5: 93.7500 (92.2080)  time: 0.3924  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 390/4579]  eta: 0:27:26  Lr: 0.030000  Loss: -1.6579  Acc@1: 68.7500 (68.6861)  Acc@5: 87.5000 (92.1196)  time: 0.3933  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 400/4579]  eta: 0:27:22  Lr: 0.030000  Loss: -1.2821  Acc@1: 75.0000 (68.9214)  Acc@5: 93.7500 (92.1602)  time: 0.3917  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 410/4579]  eta: 0:27:18  Lr: 0.030000  Loss: -1.2489  Acc@1: 75.0000 (69.0845)  Acc@5: 93.7500 (92.2141)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 420/4579]  eta: 0:27:14  Lr: 0.030000  Loss: -1.5899  Acc@1: 75.0000 (69.1657)  Acc@5: 93.7500 (92.3397)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 430/4579]  eta: 0:27:09  Lr: 0.030000  Loss: -1.7591  Acc@1: 75.0000 (69.3010)  Acc@5: 93.7500 (92.2999)  time: 0.3910  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [ 440/4579]  eta: 0:27:05  Lr: 0.030000  Loss: -1.8537  Acc@1: 75.0000 (69.4019)  Acc@5: 93.7500 (92.3044)  time: 0.3916  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 450/4579]  eta: 0:27:02  Lr: 0.030000  Loss: -1.7971  Acc@1: 75.0000 (69.4706)  Acc@5: 93.7500 (92.2810)  time: 0.3925  data: 0.0008  max mem: 2904
Train: Epoch[4/5]  [ 460/4579]  eta: 0:26:57  Lr: 0.030000  Loss: -1.7160  Acc@1: 68.7500 (69.4143)  Acc@5: 93.7500 (92.2451)  time: 0.3919  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 470/4579]  eta: 0:26:53  Lr: 0.030000  Loss: -1.6454  Acc@1: 68.7500 (69.4135)  Acc@5: 93.7500 (92.2107)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 480/4579]  eta: 0:26:50  Lr: 0.030000  Loss: -1.8802  Acc@1: 68.7500 (69.3737)  Acc@5: 93.7500 (92.2427)  time: 0.3923  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 490/4579]  eta: 0:26:45  Lr: 0.030000  Loss: -1.8731  Acc@1: 68.7500 (69.4119)  Acc@5: 93.7500 (92.2734)  time: 0.3918  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 500/4579]  eta: 0:26:42  Lr: 0.030000  Loss: -1.3125  Acc@1: 75.0000 (69.4486)  Acc@5: 93.7500 (92.3154)  time: 0.3921  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 510/4579]  eta: 0:26:38  Lr: 0.030000  Loss: -1.5487  Acc@1: 68.7500 (69.4227)  Acc@5: 93.7500 (92.3312)  time: 0.3931  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 520/4579]  eta: 0:26:34  Lr: 0.030000  Loss: -1.7756  Acc@1: 68.7500 (69.4458)  Acc@5: 93.7500 (92.3464)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 530/4579]  eta: 0:26:30  Lr: 0.030000  Loss: -1.8157  Acc@1: 68.7500 (69.4562)  Acc@5: 93.7500 (92.3376)  time: 0.3921  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 540/4579]  eta: 0:26:26  Lr: 0.030000  Loss: -1.6530  Acc@1: 68.7500 (69.3392)  Acc@5: 93.7500 (92.3406)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 550/4579]  eta: 0:26:22  Lr: 0.030000  Loss: -2.1670  Acc@1: 62.5000 (69.2831)  Acc@5: 93.7500 (92.3548)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 560/4579]  eta: 0:26:18  Lr: 0.030000  Loss: -1.5022  Acc@1: 68.7500 (69.2402)  Acc@5: 93.7500 (92.3685)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 570/4579]  eta: 0:26:14  Lr: 0.030000  Loss: -1.9707  Acc@1: 68.7500 (69.2973)  Acc@5: 93.7500 (92.3818)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 580/4579]  eta: 0:26:10  Lr: 0.030000  Loss: -1.7107  Acc@1: 68.7500 (69.3954)  Acc@5: 93.7500 (92.3946)  time: 0.3940  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 590/4579]  eta: 0:26:06  Lr: 0.030000  Loss: -1.3514  Acc@1: 68.7500 (69.4162)  Acc@5: 93.7500 (92.3964)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 600/4579]  eta: 0:26:02  Lr: 0.030000  Loss: -1.7410  Acc@1: 75.0000 (69.4572)  Acc@5: 93.7500 (92.4397)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 610/4579]  eta: 0:25:58  Lr: 0.030000  Loss: -1.9385  Acc@1: 68.7500 (69.5172)  Acc@5: 93.7500 (92.4509)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 620/4579]  eta: 0:25:54  Lr: 0.030000  Loss: -2.1270  Acc@1: 68.7500 (69.4143)  Acc@5: 93.7500 (92.4215)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 630/4579]  eta: 0:25:50  Lr: 0.030000  Loss: -1.4262  Acc@1: 62.5000 (69.3938)  Acc@5: 87.5000 (92.3831)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 640/4579]  eta: 0:25:46  Lr: 0.030000  Loss: -1.9192  Acc@1: 68.7500 (69.4228)  Acc@5: 93.7500 (92.3459)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 650/4579]  eta: 0:25:42  Lr: 0.030000  Loss: -1.2506  Acc@1: 68.7500 (69.4508)  Acc@5: 93.7500 (92.3579)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 660/4579]  eta: 0:25:38  Lr: 0.030000  Loss: -1.2927  Acc@1: 68.7500 (69.4213)  Acc@5: 87.5000 (92.3033)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 670/4579]  eta: 0:25:35  Lr: 0.030000  Loss: -1.7995  Acc@1: 68.7500 (69.4300)  Acc@5: 87.5000 (92.3156)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [ 680/4579]  eta: 0:25:31  Lr: 0.030000  Loss: -1.2749  Acc@1: 62.5000 (69.3374)  Acc@5: 93.7500 (92.3183)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [ 690/4579]  eta: 0:25:27  Lr: 0.030000  Loss: -1.7003  Acc@1: 62.5000 (69.3651)  Acc@5: 93.7500 (92.3300)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 700/4579]  eta: 0:25:23  Lr: 0.030000  Loss: -2.1558  Acc@1: 75.0000 (69.4544)  Acc@5: 93.7500 (92.3770)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [ 710/4579]  eta: 0:25:19  Lr: 0.030000  Loss: -1.8347  Acc@1: 75.0000 (69.4796)  Acc@5: 93.7500 (92.3699)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 720/4579]  eta: 0:25:15  Lr: 0.030000  Loss: -1.4355  Acc@1: 68.7500 (69.5215)  Acc@5: 93.7500 (92.3717)  time: 0.3928  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [ 730/4579]  eta: 0:25:11  Lr: 0.030000  Loss: -1.7892  Acc@1: 68.7500 (69.5024)  Acc@5: 93.7500 (92.3820)  time: 0.3926  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [ 740/4579]  eta: 0:25:07  Lr: 0.030000  Loss: -1.7372  Acc@1: 68.7500 (69.5007)  Acc@5: 93.7500 (92.3667)  time: 0.3926  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 750/4579]  eta: 0:25:03  Lr: 0.030000  Loss: -1.6736  Acc@1: 68.7500 (69.5739)  Acc@5: 93.7500 (92.4018)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 760/4579]  eta: 0:24:59  Lr: 0.030000  Loss: -1.6890  Acc@1: 75.0000 (69.5056)  Acc@5: 93.7500 (92.3784)  time: 0.3916  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 770/4579]  eta: 0:24:55  Lr: 0.030000  Loss: -1.4295  Acc@1: 68.7500 (69.4471)  Acc@5: 93.7500 (92.3800)  time: 0.3921  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 780/4579]  eta: 0:24:51  Lr: 0.030000  Loss: -1.8540  Acc@1: 68.7500 (69.4542)  Acc@5: 93.7500 (92.3816)  time: 0.3916  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 790/4579]  eta: 0:24:47  Lr: 0.030000  Loss: -2.0898  Acc@1: 68.7500 (69.4453)  Acc@5: 93.7500 (92.4147)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [ 800/4579]  eta: 0:24:43  Lr: 0.030000  Loss: -1.8059  Acc@1: 62.5000 (69.3664)  Acc@5: 93.7500 (92.3689)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [ 810/4579]  eta: 0:24:39  Lr: 0.030000  Loss: -1.6436  Acc@1: 62.5000 (69.3280)  Acc@5: 87.5000 (92.3243)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 820/4579]  eta: 0:24:35  Lr: 0.030000  Loss: -1.5525  Acc@1: 68.7500 (69.3210)  Acc@5: 87.5000 (92.3188)  time: 0.3913  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 830/4579]  eta: 0:24:31  Lr: 0.030000  Loss: -1.4355  Acc@1: 68.7500 (69.3066)  Acc@5: 93.7500 (92.3360)  time: 0.3931  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [ 840/4579]  eta: 0:24:27  Lr: 0.030000  Loss: -1.5655  Acc@1: 68.7500 (69.3297)  Acc@5: 93.7500 (92.3306)  time: 0.3917  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 850/4579]  eta: 0:24:23  Lr: 0.030000  Loss: -2.1863  Acc@1: 68.7500 (69.3596)  Acc@5: 93.7500 (92.3252)  time: 0.3904  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 860/4579]  eta: 0:24:19  Lr: 0.030000  Loss: -0.6586  Acc@1: 75.0000 (69.3961)  Acc@5: 93.7500 (92.3200)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 870/4579]  eta: 0:24:15  Lr: 0.030000  Loss: -1.4934  Acc@1: 68.7500 (69.3743)  Acc@5: 93.7500 (92.3220)  time: 0.3919  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [ 880/4579]  eta: 0:24:11  Lr: 0.030000  Loss: -1.9196  Acc@1: 68.7500 (69.3033)  Acc@5: 93.7500 (92.3170)  time: 0.3910  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 890/4579]  eta: 0:24:07  Lr: 0.030000  Loss: -1.7465  Acc@1: 68.7500 (69.2831)  Acc@5: 93.7500 (92.3190)  time: 0.3902  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 900/4579]  eta: 0:24:04  Lr: 0.030000  Loss: -1.8120  Acc@1: 68.7500 (69.3188)  Acc@5: 93.7500 (92.3488)  time: 0.3926  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 910/4579]  eta: 0:24:00  Lr: 0.030000  Loss: -1.8940  Acc@1: 68.7500 (69.2577)  Acc@5: 93.7500 (92.3642)  time: 0.3924  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [ 920/4579]  eta: 0:23:56  Lr: 0.030000  Loss: -1.2429  Acc@1: 68.7500 (69.2725)  Acc@5: 93.7500 (92.3928)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 930/4579]  eta: 0:23:52  Lr: 0.030000  Loss: -1.4668  Acc@1: 68.7500 (69.2535)  Acc@5: 93.7500 (92.3671)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 940/4579]  eta: 0:23:48  Lr: 0.030000  Loss: -2.3052  Acc@1: 68.7500 (69.2747)  Acc@5: 87.5000 (92.3618)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 950/4579]  eta: 0:23:44  Lr: 0.030000  Loss: -2.1000  Acc@1: 68.7500 (69.2363)  Acc@5: 87.5000 (92.3239)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 960/4579]  eta: 0:23:40  Lr: 0.030000  Loss: -1.8488  Acc@1: 68.7500 (69.2443)  Acc@5: 93.7500 (92.3257)  time: 0.3942  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 970/4579]  eta: 0:23:36  Lr: 0.030000  Loss: -1.3306  Acc@1: 68.7500 (69.2327)  Acc@5: 93.7500 (92.3275)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [ 980/4579]  eta: 0:23:32  Lr: 0.030000  Loss: -1.4902  Acc@1: 68.7500 (69.2342)  Acc@5: 93.7500 (92.3101)  time: 0.3921  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [ 990/4579]  eta: 0:23:28  Lr: 0.030000  Loss: -1.6701  Acc@1: 68.7500 (69.2293)  Acc@5: 93.7500 (92.3184)  time: 0.3926  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [1000/4579]  eta: 0:23:24  Lr: 0.030000  Loss: -1.8104  Acc@1: 68.7500 (69.2682)  Acc@5: 93.7500 (92.3264)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1010/4579]  eta: 0:23:20  Lr: 0.030000  Loss: -1.5633  Acc@1: 68.7500 (69.2878)  Acc@5: 93.7500 (92.3281)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1020/4579]  eta: 0:23:16  Lr: 0.030000  Loss: -1.3630  Acc@1: 75.0000 (69.3315)  Acc@5: 93.7500 (92.3176)  time: 0.3918  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1030/4579]  eta: 0:23:12  Lr: 0.030000  Loss: -1.4134  Acc@1: 75.0000 (69.3441)  Acc@5: 93.7500 (92.3618)  time: 0.3911  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [1040/4579]  eta: 0:23:09  Lr: 0.030000  Loss: -1.2327  Acc@1: 68.7500 (69.3444)  Acc@5: 93.7500 (92.3451)  time: 0.3931  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1050/4579]  eta: 0:23:05  Lr: 0.030000  Loss: -2.1684  Acc@1: 62.5000 (69.3030)  Acc@5: 93.7500 (92.3347)  time: 0.3929  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1060/4579]  eta: 0:23:01  Lr: 0.030000  Loss: -1.6730  Acc@1: 68.7500 (69.3273)  Acc@5: 93.7500 (92.3127)  time: 0.3906  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1070/4579]  eta: 0:22:57  Lr: 0.030000  Loss: -1.9721  Acc@1: 68.7500 (69.2810)  Acc@5: 93.7500 (92.3144)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1080/4579]  eta: 0:22:53  Lr: 0.030000  Loss: -1.6986  Acc@1: 68.7500 (69.2935)  Acc@5: 87.5000 (92.3046)  time: 0.3961  data: 0.0008  max mem: 2904
Train: Epoch[4/5]  [1090/4579]  eta: 0:22:49  Lr: 0.030000  Loss: -1.6222  Acc@1: 68.7500 (69.2828)  Acc@5: 87.5000 (92.2949)  time: 0.3970  data: 0.0008  max mem: 2904
Train: Epoch[4/5]  [1100/4579]  eta: 0:22:45  Lr: 0.030000  Loss: -1.6872  Acc@1: 68.7500 (69.2950)  Acc@5: 87.5000 (92.2797)  time: 0.3959  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1110/4579]  eta: 0:22:42  Lr: 0.030000  Loss: -1.9610  Acc@1: 75.0000 (69.3407)  Acc@5: 93.7500 (92.2986)  time: 0.3970  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1120/4579]  eta: 0:22:38  Lr: 0.030000  Loss: -1.8593  Acc@1: 68.7500 (69.3354)  Acc@5: 93.7500 (92.3060)  time: 0.3976  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1130/4579]  eta: 0:22:34  Lr: 0.030000  Loss: -0.9672  Acc@1: 68.7500 (69.3523)  Acc@5: 93.7500 (92.2856)  time: 0.3970  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1140/4579]  eta: 0:22:30  Lr: 0.030000  Loss: -1.2582  Acc@1: 62.5000 (69.3306)  Acc@5: 87.5000 (92.2436)  time: 0.3954  data: 0.0019  max mem: 2904
Train: Epoch[4/5]  [1150/4579]  eta: 0:22:26  Lr: 0.030000  Loss: -1.7977  Acc@1: 68.7500 (69.3799)  Acc@5: 87.5000 (92.2459)  time: 0.3942  data: 0.0025  max mem: 2904
Train: Epoch[4/5]  [1160/4579]  eta: 0:22:22  Lr: 0.030000  Loss: -1.3995  Acc@1: 75.0000 (69.3960)  Acc@5: 93.7500 (92.2588)  time: 0.3936  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1170/4579]  eta: 0:22:18  Lr: 0.030000  Loss: -1.7837  Acc@1: 68.7500 (69.3851)  Acc@5: 93.7500 (92.2235)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1180/4579]  eta: 0:22:14  Lr: 0.030000  Loss: -1.5224  Acc@1: 68.7500 (69.3321)  Acc@5: 87.5000 (92.2153)  time: 0.3919  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [1190/4579]  eta: 0:22:10  Lr: 0.030000  Loss: -1.7097  Acc@1: 68.7500 (69.3640)  Acc@5: 93.7500 (92.2177)  time: 0.3915  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [1200/4579]  eta: 0:22:06  Lr: 0.030000  Loss: -1.8856  Acc@1: 75.0000 (69.3016)  Acc@5: 93.7500 (92.1992)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1210/4579]  eta: 0:22:03  Lr: 0.030000  Loss: -1.6344  Acc@1: 68.7500 (69.2971)  Acc@5: 93.7500 (92.1862)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1220/4579]  eta: 0:21:59  Lr: 0.030000  Loss: -1.9643  Acc@1: 68.7500 (69.2824)  Acc@5: 93.7500 (92.1939)  time: 0.3922  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1230/4579]  eta: 0:21:55  Lr: 0.030000  Loss: -1.9363  Acc@1: 68.7500 (69.2983)  Acc@5: 93.7500 (92.2065)  time: 0.3930  data: 0.0016  max mem: 2904
Train: Epoch[4/5]  [1240/4579]  eta: 0:21:51  Lr: 0.030000  Loss: -1.4656  Acc@1: 68.7500 (69.2889)  Acc@5: 100.0000 (92.2341)  time: 0.3945  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [1250/4579]  eta: 0:21:47  Lr: 0.030000  Loss: -1.9870  Acc@1: 68.7500 (69.3145)  Acc@5: 93.7500 (92.2462)  time: 0.3936  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [1260/4579]  eta: 0:21:43  Lr: 0.030000  Loss: -1.1725  Acc@1: 75.0000 (69.3150)  Acc@5: 93.7500 (92.2532)  time: 0.3952  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [1270/4579]  eta: 0:21:39  Lr: 0.030000  Loss: -2.3538  Acc@1: 68.7500 (69.3548)  Acc@5: 93.7500 (92.2600)  time: 0.3979  data: 0.0020  max mem: 2904
Train: Epoch[4/5]  [1280/4579]  eta: 0:21:35  Lr: 0.030000  Loss: -0.9162  Acc@1: 62.5000 (69.3452)  Acc@5: 93.7500 (92.2326)  time: 0.3944  data: 0.0007  max mem: 2904
Train: Epoch[4/5]  [1290/4579]  eta: 0:21:31  Lr: 0.030000  Loss: -1.4243  Acc@1: 62.5000 (69.3213)  Acc@5: 93.7500 (92.2250)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1300/4579]  eta: 0:21:27  Lr: 0.030000  Loss: -1.2611  Acc@1: 62.5000 (69.2977)  Acc@5: 93.7500 (92.2079)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1310/4579]  eta: 0:21:24  Lr: 0.030000  Loss: -1.3630  Acc@1: 62.5000 (69.2649)  Acc@5: 87.5000 (92.1768)  time: 0.3936  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1320/4579]  eta: 0:21:20  Lr: 0.030000  Loss: -1.8381  Acc@1: 62.5000 (69.2184)  Acc@5: 87.5000 (92.1840)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1330/4579]  eta: 0:21:16  Lr: 0.030000  Loss: -1.6419  Acc@1: 68.7500 (69.2384)  Acc@5: 93.7500 (92.1863)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1340/4579]  eta: 0:21:12  Lr: 0.030000  Loss: -1.5890  Acc@1: 68.7500 (69.2161)  Acc@5: 93.7500 (92.1793)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1350/4579]  eta: 0:21:08  Lr: 0.030000  Loss: -1.7825  Acc@1: 68.7500 (69.1849)  Acc@5: 93.7500 (92.1817)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1360/4579]  eta: 0:21:04  Lr: 0.030000  Loss: -1.3917  Acc@1: 62.5000 (69.1863)  Acc@5: 93.7500 (92.1841)  time: 0.3911  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1370/4579]  eta: 0:21:00  Lr: 0.030000  Loss: -1.4735  Acc@1: 68.7500 (69.1922)  Acc@5: 93.7500 (92.1727)  time: 0.3916  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [1380/4579]  eta: 0:20:56  Lr: 0.030000  Loss: -1.2963  Acc@1: 68.7500 (69.1437)  Acc@5: 93.7500 (92.1751)  time: 0.3913  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [1390/4579]  eta: 0:20:52  Lr: 0.030000  Loss: -1.3571  Acc@1: 75.0000 (69.2128)  Acc@5: 93.7500 (92.2088)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1400/4579]  eta: 0:20:48  Lr: 0.030000  Loss: -0.9242  Acc@1: 75.0000 (69.2006)  Acc@5: 93.7500 (92.1975)  time: 0.3922  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [1410/4579]  eta: 0:20:44  Lr: 0.030000  Loss: -1.6820  Acc@1: 68.7500 (69.2062)  Acc@5: 93.7500 (92.2085)  time: 0.3921  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [1420/4579]  eta: 0:20:40  Lr: 0.030000  Loss: -1.0584  Acc@1: 68.7500 (69.2030)  Acc@5: 93.7500 (92.2018)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1430/4579]  eta: 0:20:36  Lr: 0.030000  Loss: -1.3791  Acc@1: 68.7500 (69.2261)  Acc@5: 93.7500 (92.2082)  time: 0.3902  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1440/4579]  eta: 0:20:32  Lr: 0.030000  Loss: -2.1670  Acc@1: 68.7500 (69.2228)  Acc@5: 93.7500 (92.2016)  time: 0.3911  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1450/4579]  eta: 0:20:28  Lr: 0.030000  Loss: -1.5181  Acc@1: 62.5000 (69.2066)  Acc@5: 87.5000 (92.1864)  time: 0.3919  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [1460/4579]  eta: 0:20:24  Lr: 0.030000  Loss: -1.6099  Acc@1: 62.5000 (69.1735)  Acc@5: 87.5000 (92.1586)  time: 0.3911  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [1470/4579]  eta: 0:20:20  Lr: 0.030000  Loss: -1.7549  Acc@1: 68.7500 (69.2004)  Acc@5: 93.7500 (92.1609)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1480/4579]  eta: 0:20:16  Lr: 0.030000  Loss: -1.2291  Acc@1: 75.0000 (69.2184)  Acc@5: 93.7500 (92.1548)  time: 0.3941  data: 0.0007  max mem: 2904
Train: Epoch[4/5]  [1490/4579]  eta: 0:20:12  Lr: 0.030000  Loss: -1.9500  Acc@1: 75.0000 (69.2237)  Acc@5: 93.7500 (92.1571)  time: 0.3940  data: 0.0013  max mem: 2904
Train: Epoch[4/5]  [1500/4579]  eta: 0:20:08  Lr: 0.030000  Loss: -1.6467  Acc@1: 68.7500 (69.2164)  Acc@5: 93.7500 (92.1386)  time: 0.3916  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [1510/4579]  eta: 0:20:04  Lr: 0.030000  Loss: -1.4905  Acc@1: 62.5000 (69.1926)  Acc@5: 93.7500 (92.1492)  time: 0.3907  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1520/4579]  eta: 0:20:01  Lr: 0.030000  Loss: -2.0907  Acc@1: 62.5000 (69.1774)  Acc@5: 93.7500 (92.1639)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1530/4579]  eta: 0:19:57  Lr: 0.030000  Loss: -1.6382  Acc@1: 68.7500 (69.1460)  Acc@5: 93.7500 (92.1702)  time: 0.3916  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [1540/4579]  eta: 0:19:53  Lr: 0.030000  Loss: -0.9473  Acc@1: 62.5000 (69.1353)  Acc@5: 93.7500 (92.1642)  time: 0.3930  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [1550/4579]  eta: 0:19:49  Lr: 0.030000  Loss: -1.8466  Acc@1: 68.7500 (69.1610)  Acc@5: 93.7500 (92.1905)  time: 0.3923  data: 0.0014  max mem: 2904
Train: Epoch[4/5]  [1560/4579]  eta: 0:19:45  Lr: 0.030000  Loss: -1.9092  Acc@1: 75.0000 (69.1704)  Acc@5: 93.7500 (92.1925)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1570/4579]  eta: 0:19:41  Lr: 0.030000  Loss: -1.3919  Acc@1: 68.7500 (69.1876)  Acc@5: 93.7500 (92.2024)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1580/4579]  eta: 0:19:37  Lr: 0.030000  Loss: -1.9331  Acc@1: 68.7500 (69.1928)  Acc@5: 93.7500 (92.2241)  time: 0.3906  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [1590/4579]  eta: 0:19:33  Lr: 0.030000  Loss: -1.7702  Acc@1: 68.7500 (69.1664)  Acc@5: 93.7500 (92.2062)  time: 0.3930  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [1600/4579]  eta: 0:19:29  Lr: 0.030000  Loss: -1.7740  Acc@1: 68.7500 (69.1716)  Acc@5: 93.7500 (92.2158)  time: 0.3943  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1610/4579]  eta: 0:19:25  Lr: 0.030000  Loss: -1.5043  Acc@1: 68.7500 (69.1457)  Acc@5: 93.7500 (92.1943)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1620/4579]  eta: 0:19:21  Lr: 0.030000  Loss: -2.0525  Acc@1: 68.7500 (69.1664)  Acc@5: 87.5000 (92.1923)  time: 0.3908  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1630/4579]  eta: 0:19:17  Lr: 0.030000  Loss: -1.8445  Acc@1: 68.7500 (69.1447)  Acc@5: 93.7500 (92.1980)  time: 0.3917  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [1640/4579]  eta: 0:19:13  Lr: 0.030000  Loss: -1.2748  Acc@1: 68.7500 (69.1271)  Acc@5: 93.7500 (92.2037)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1650/4579]  eta: 0:19:09  Lr: 0.030000  Loss: -1.4071  Acc@1: 68.7500 (69.1096)  Acc@5: 93.7500 (92.2093)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1660/4579]  eta: 0:19:05  Lr: 0.030000  Loss: -1.5110  Acc@1: 68.7500 (69.1714)  Acc@5: 93.7500 (92.2185)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1670/4579]  eta: 0:19:02  Lr: 0.030000  Loss: -1.6583  Acc@1: 68.7500 (69.1465)  Acc@5: 93.7500 (92.2240)  time: 0.3957  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1680/4579]  eta: 0:18:58  Lr: 0.030000  Loss: -1.6027  Acc@1: 68.7500 (69.1478)  Acc@5: 93.7500 (92.2368)  time: 0.3956  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1690/4579]  eta: 0:18:54  Lr: 0.030000  Loss: -1.1588  Acc@1: 68.7500 (69.1085)  Acc@5: 93.7500 (92.2383)  time: 0.3924  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1700/4579]  eta: 0:18:50  Lr: 0.030000  Loss: -2.1560  Acc@1: 62.5000 (69.0660)  Acc@5: 93.7500 (92.2252)  time: 0.3931  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [1710/4579]  eta: 0:18:46  Lr: 0.030000  Loss: -1.9083  Acc@1: 68.7500 (69.0824)  Acc@5: 87.5000 (92.2195)  time: 0.3934  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [1720/4579]  eta: 0:18:42  Lr: 0.030000  Loss: -1.6223  Acc@1: 68.7500 (69.0151)  Acc@5: 93.7500 (92.2102)  time: 0.3915  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1730/4579]  eta: 0:18:38  Lr: 0.030000  Loss: -1.7929  Acc@1: 62.5000 (69.0461)  Acc@5: 93.7500 (92.2155)  time: 0.3916  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1740/4579]  eta: 0:18:34  Lr: 0.030000  Loss: -1.7838  Acc@1: 62.5000 (69.0264)  Acc@5: 93.7500 (92.2171)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1750/4579]  eta: 0:18:30  Lr: 0.030000  Loss: -0.3322  Acc@1: 62.5000 (69.0213)  Acc@5: 93.7500 (92.2223)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1760/4579]  eta: 0:18:26  Lr: 0.030000  Loss: -1.4774  Acc@1: 68.7500 (69.0552)  Acc@5: 100.0000 (92.2416)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1770/4579]  eta: 0:18:22  Lr: 0.030000  Loss: -1.2294  Acc@1: 68.7500 (69.0253)  Acc@5: 93.7500 (92.2396)  time: 0.3935  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [1780/4579]  eta: 0:18:18  Lr: 0.030000  Loss: -2.0967  Acc@1: 62.5000 (69.0378)  Acc@5: 93.7500 (92.2551)  time: 0.3936  data: 0.0021  max mem: 2904
Train: Epoch[4/5]  [1790/4579]  eta: 0:18:14  Lr: 0.030000  Loss: -2.0522  Acc@1: 75.0000 (69.0501)  Acc@5: 93.7500 (92.2669)  time: 0.3927  data: 0.0014  max mem: 2904
Train: Epoch[4/5]  [1800/4579]  eta: 0:18:10  Lr: 0.030000  Loss: -1.4883  Acc@1: 68.7500 (69.0693)  Acc@5: 93.7500 (92.2890)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [1810/4579]  eta: 0:18:07  Lr: 0.030000  Loss: -2.2987  Acc@1: 68.7500 (69.0813)  Acc@5: 93.7500 (92.3005)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1820/4579]  eta: 0:18:03  Lr: 0.030000  Loss: -1.4797  Acc@1: 75.0000 (69.1001)  Acc@5: 93.7500 (92.3153)  time: 0.3917  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1830/4579]  eta: 0:17:59  Lr: 0.030000  Loss: -1.7138  Acc@1: 75.0000 (69.0982)  Acc@5: 93.7500 (92.3164)  time: 0.3928  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [1840/4579]  eta: 0:17:55  Lr: 0.030000  Loss: -1.8397  Acc@1: 68.7500 (69.0827)  Acc@5: 93.7500 (92.3207)  time: 0.3934  data: 0.0013  max mem: 2904
Train: Epoch[4/5]  [1850/4579]  eta: 0:17:51  Lr: 0.030000  Loss: -1.8953  Acc@1: 68.7500 (69.1012)  Acc@5: 93.7500 (92.3318)  time: 0.3929  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1860/4579]  eta: 0:17:47  Lr: 0.030000  Loss: -1.3625  Acc@1: 62.5000 (69.1093)  Acc@5: 93.7500 (92.3294)  time: 0.3934  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [1870/4579]  eta: 0:17:43  Lr: 0.030000  Loss: -1.2591  Acc@1: 75.0000 (69.1308)  Acc@5: 93.7500 (92.3270)  time: 0.3927  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [1880/4579]  eta: 0:17:39  Lr: 0.030000  Loss: -2.1049  Acc@1: 68.7500 (69.1221)  Acc@5: 93.7500 (92.3212)  time: 0.3921  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1890/4579]  eta: 0:17:35  Lr: 0.030000  Loss: -1.5737  Acc@1: 68.7500 (69.1036)  Acc@5: 93.7500 (92.3288)  time: 0.3925  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1900/4579]  eta: 0:17:31  Lr: 0.030000  Loss: -1.7450  Acc@1: 68.7500 (69.0985)  Acc@5: 93.7500 (92.3133)  time: 0.3931  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1910/4579]  eta: 0:17:27  Lr: 0.030000  Loss: -2.1586  Acc@1: 75.0000 (69.1425)  Acc@5: 93.7500 (92.3371)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [1920/4579]  eta: 0:17:23  Lr: 0.030000  Loss: -1.2459  Acc@1: 75.0000 (69.1372)  Acc@5: 93.7500 (92.3412)  time: 0.3935  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [1930/4579]  eta: 0:17:20  Lr: 0.030000  Loss: -1.4822  Acc@1: 68.7500 (69.1319)  Acc@5: 93.7500 (92.3421)  time: 0.3928  data: 0.0013  max mem: 2904
Train: Epoch[4/5]  [1940/4579]  eta: 0:17:16  Lr: 0.030000  Loss: -1.9397  Acc@1: 68.7500 (69.1267)  Acc@5: 93.7500 (92.3364)  time: 0.3923  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1950/4579]  eta: 0:17:12  Lr: 0.030000  Loss: -0.8186  Acc@1: 68.7500 (69.1440)  Acc@5: 93.7500 (92.3405)  time: 0.3910  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1960/4579]  eta: 0:17:08  Lr: 0.030000  Loss: -2.0835  Acc@1: 68.7500 (69.1229)  Acc@5: 93.7500 (92.3381)  time: 0.3925  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [1970/4579]  eta: 0:17:04  Lr: 0.030000  Loss: -1.8047  Acc@1: 62.5000 (69.0988)  Acc@5: 93.7500 (92.3421)  time: 0.3944  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [1980/4579]  eta: 0:17:00  Lr: 0.030000  Loss: -1.7262  Acc@1: 68.7500 (69.1223)  Acc@5: 93.7500 (92.3523)  time: 0.3945  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [1990/4579]  eta: 0:16:56  Lr: 0.030000  Loss: -0.8159  Acc@1: 68.7500 (69.1141)  Acc@5: 93.7500 (92.3594)  time: 0.3937  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [2000/4579]  eta: 0:16:52  Lr: 0.030000  Loss: -1.0269  Acc@1: 68.7500 (69.1217)  Acc@5: 93.7500 (92.3569)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2010/4579]  eta: 0:16:48  Lr: 0.030000  Loss: -1.6901  Acc@1: 68.7500 (69.1105)  Acc@5: 93.7500 (92.3608)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2020/4579]  eta: 0:16:44  Lr: 0.030000  Loss: -1.7603  Acc@1: 68.7500 (69.1149)  Acc@5: 93.7500 (92.3707)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2030/4579]  eta: 0:16:40  Lr: 0.030000  Loss: -1.7303  Acc@1: 68.7500 (69.1131)  Acc@5: 93.7500 (92.3837)  time: 0.3924  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2040/4579]  eta: 0:16:36  Lr: 0.030000  Loss: -1.8465  Acc@1: 68.7500 (69.1083)  Acc@5: 93.7500 (92.3904)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2050/4579]  eta: 0:16:32  Lr: 0.030000  Loss: -1.2310  Acc@1: 68.7500 (69.1096)  Acc@5: 93.7500 (92.4000)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2060/4579]  eta: 0:16:29  Lr: 0.030000  Loss: -1.7698  Acc@1: 62.5000 (69.0987)  Acc@5: 93.7500 (92.4036)  time: 0.3929  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [2070/4579]  eta: 0:16:25  Lr: 0.030000  Loss: -1.4148  Acc@1: 68.7500 (69.1001)  Acc@5: 93.7500 (92.4010)  time: 0.3937  data: 0.0019  max mem: 2904
Train: Epoch[4/5]  [2080/4579]  eta: 0:16:21  Lr: 0.030000  Loss: -1.1387  Acc@1: 62.5000 (69.0533)  Acc@5: 93.7500 (92.3925)  time: 0.3912  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [2090/4579]  eta: 0:16:17  Lr: 0.030000  Loss: -1.2791  Acc@1: 62.5000 (69.0250)  Acc@5: 93.7500 (92.3840)  time: 0.3894  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2100/4579]  eta: 0:16:13  Lr: 0.030000  Loss: -1.9214  Acc@1: 62.5000 (69.0148)  Acc@5: 87.5000 (92.3667)  time: 0.3895  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2110/4579]  eta: 0:16:09  Lr: 0.030000  Loss: -2.0369  Acc@1: 75.0000 (69.0372)  Acc@5: 87.5000 (92.3733)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2120/4579]  eta: 0:16:05  Lr: 0.030000  Loss: -2.1958  Acc@1: 75.0000 (69.0594)  Acc@5: 93.7500 (92.3886)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2130/4579]  eta: 0:16:01  Lr: 0.030000  Loss: -1.1335  Acc@1: 68.7500 (69.0668)  Acc@5: 93.7500 (92.3862)  time: 0.3904  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2140/4579]  eta: 0:15:57  Lr: 0.030000  Loss: -1.5571  Acc@1: 68.7500 (69.0828)  Acc@5: 93.7500 (92.3897)  time: 0.3912  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [2150/4579]  eta: 0:15:53  Lr: 0.030000  Loss: -2.3425  Acc@1: 68.7500 (69.0841)  Acc@5: 93.7500 (92.3756)  time: 0.3927  data: 0.0013  max mem: 2904
Train: Epoch[4/5]  [2160/4579]  eta: 0:15:49  Lr: 0.030000  Loss: -1.5074  Acc@1: 62.5000 (69.0681)  Acc@5: 93.7500 (92.3704)  time: 0.3917  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2170/4579]  eta: 0:15:45  Lr: 0.030000  Loss: -2.1185  Acc@1: 68.7500 (69.0724)  Acc@5: 93.7500 (92.3624)  time: 0.3913  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2180/4579]  eta: 0:15:41  Lr: 0.030000  Loss: -1.8689  Acc@1: 68.7500 (69.0824)  Acc@5: 93.7500 (92.3745)  time: 0.3941  data: 0.0024  max mem: 2904
Train: Epoch[4/5]  [2190/4579]  eta: 0:15:37  Lr: 0.030000  Loss: -2.0999  Acc@1: 68.7500 (69.0666)  Acc@5: 93.7500 (92.3694)  time: 0.3939  data: 0.0024  max mem: 2904
Train: Epoch[4/5]  [2200/4579]  eta: 0:15:33  Lr: 0.030000  Loss: -1.5403  Acc@1: 68.7500 (69.0624)  Acc@5: 93.7500 (92.3756)  time: 0.3913  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [2210/4579]  eta: 0:15:29  Lr: 0.030000  Loss: -1.5328  Acc@1: 68.7500 (69.0609)  Acc@5: 93.7500 (92.3592)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2220/4579]  eta: 0:15:25  Lr: 0.030000  Loss: -1.2643  Acc@1: 75.0000 (69.0877)  Acc@5: 93.7500 (92.3627)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2230/4579]  eta: 0:15:22  Lr: 0.030000  Loss: -2.3683  Acc@1: 75.0000 (69.1142)  Acc@5: 93.7500 (92.3745)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2240/4579]  eta: 0:15:18  Lr: 0.030000  Loss: -1.6803  Acc@1: 68.7500 (69.1209)  Acc@5: 93.7500 (92.3862)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2250/4579]  eta: 0:15:14  Lr: 0.030000  Loss: -1.7788  Acc@1: 68.7500 (69.1165)  Acc@5: 93.7500 (92.3784)  time: 0.3910  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [2260/4579]  eta: 0:15:10  Lr: 0.030000  Loss: -1.3990  Acc@1: 68.7500 (69.1398)  Acc@5: 93.7500 (92.3817)  time: 0.3914  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [2270/4579]  eta: 0:15:06  Lr: 0.030000  Loss: -1.9777  Acc@1: 68.7500 (69.1518)  Acc@5: 93.7500 (92.3629)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2280/4579]  eta: 0:15:02  Lr: 0.030000  Loss: -1.5292  Acc@1: 68.7500 (69.1528)  Acc@5: 87.5000 (92.3608)  time: 0.3923  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2290/4579]  eta: 0:14:58  Lr: 0.030000  Loss: -2.2649  Acc@1: 68.7500 (69.1456)  Acc@5: 93.7500 (92.3778)  time: 0.3919  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2300/4579]  eta: 0:14:54  Lr: 0.030000  Loss: -1.2694  Acc@1: 68.7500 (69.1656)  Acc@5: 93.7500 (92.3810)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2310/4579]  eta: 0:14:50  Lr: 0.030000  Loss: -2.2206  Acc@1: 68.7500 (69.1719)  Acc@5: 93.7500 (92.3707)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2320/4579]  eta: 0:14:46  Lr: 0.030000  Loss: -2.0252  Acc@1: 75.0000 (69.1889)  Acc@5: 93.7500 (92.3794)  time: 0.3905  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [2330/4579]  eta: 0:14:42  Lr: 0.030000  Loss: -2.0119  Acc@1: 75.0000 (69.1951)  Acc@5: 93.7500 (92.3852)  time: 0.3927  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [2340/4579]  eta: 0:14:38  Lr: 0.030000  Loss: -1.2479  Acc@1: 62.5000 (69.1638)  Acc@5: 93.7500 (92.3804)  time: 0.3926  data: 0.0008  max mem: 2904
Train: Epoch[4/5]  [2350/4579]  eta: 0:14:34  Lr: 0.030000  Loss: -2.1880  Acc@1: 62.5000 (69.1621)  Acc@5: 93.7500 (92.3809)  time: 0.3917  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2360/4579]  eta: 0:14:30  Lr: 0.030000  Loss: -0.8743  Acc@1: 68.7500 (69.1656)  Acc@5: 93.7500 (92.3788)  time: 0.3911  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2370/4579]  eta: 0:14:26  Lr: 0.030000  Loss: -1.8059  Acc@1: 68.7500 (69.1639)  Acc@5: 93.7500 (92.3819)  time: 0.3920  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2380/4579]  eta: 0:14:23  Lr: 0.030000  Loss: -1.8436  Acc@1: 75.0000 (69.2041)  Acc@5: 93.7500 (92.3929)  time: 0.3939  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2390/4579]  eta: 0:14:19  Lr: 0.030000  Loss: -1.9193  Acc@1: 75.0000 (69.2127)  Acc@5: 93.7500 (92.3881)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2400/4579]  eta: 0:14:15  Lr: 0.030000  Loss: -1.8277  Acc@1: 68.7500 (69.2212)  Acc@5: 93.7500 (92.3782)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2410/4579]  eta: 0:14:11  Lr: 0.030000  Loss: -1.7154  Acc@1: 68.7500 (69.2140)  Acc@5: 87.5000 (92.3813)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2420/4579]  eta: 0:14:07  Lr: 0.030000  Loss: -2.1650  Acc@1: 68.7500 (69.2224)  Acc@5: 100.0000 (92.3973)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2430/4579]  eta: 0:14:03  Lr: 0.030000  Loss: -2.0637  Acc@1: 75.0000 (69.2385)  Acc@5: 93.7500 (92.4028)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2440/4579]  eta: 0:13:59  Lr: 0.030000  Loss: -1.6804  Acc@1: 68.7500 (69.2211)  Acc@5: 93.7500 (92.3955)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2450/4579]  eta: 0:13:55  Lr: 0.030000  Loss: -2.0492  Acc@1: 68.7500 (69.2447)  Acc@5: 93.7500 (92.4087)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2460/4579]  eta: 0:13:51  Lr: 0.030000  Loss: -1.7150  Acc@1: 68.7500 (69.2503)  Acc@5: 100.0000 (92.4218)  time: 0.3920  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [2470/4579]  eta: 0:13:47  Lr: 0.030000  Loss: -1.4254  Acc@1: 68.7500 (69.2533)  Acc@5: 93.7500 (92.4272)  time: 0.3928  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [2480/4579]  eta: 0:13:43  Lr: 0.030000  Loss: -2.1601  Acc@1: 75.0000 (69.2715)  Acc@5: 93.7500 (92.4350)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2490/4579]  eta: 0:13:39  Lr: 0.030000  Loss: -1.6614  Acc@1: 75.0000 (69.2920)  Acc@5: 93.7500 (92.4328)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2500/4579]  eta: 0:13:35  Lr: 0.030000  Loss: -1.1742  Acc@1: 75.0000 (69.2973)  Acc@5: 93.7500 (92.4380)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2510/4579]  eta: 0:13:32  Lr: 0.030000  Loss: -0.9602  Acc@1: 62.5000 (69.2802)  Acc@5: 93.7500 (92.4383)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2520/4579]  eta: 0:13:28  Lr: 0.030000  Loss: -1.2310  Acc@1: 62.5000 (69.2731)  Acc@5: 93.7500 (92.4336)  time: 0.3911  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2530/4579]  eta: 0:13:24  Lr: 0.030000  Loss: -1.8297  Acc@1: 68.7500 (69.2908)  Acc@5: 93.7500 (92.4338)  time: 0.3927  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2540/4579]  eta: 0:13:20  Lr: 0.030000  Loss: -0.8781  Acc@1: 68.7500 (69.2862)  Acc@5: 93.7500 (92.4365)  time: 0.3930  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2550/4579]  eta: 0:13:16  Lr: 0.030000  Loss: -1.7478  Acc@1: 68.7500 (69.2792)  Acc@5: 93.7500 (92.4343)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2560/4579]  eta: 0:13:12  Lr: 0.030000  Loss: -2.0139  Acc@1: 75.0000 (69.2967)  Acc@5: 87.5000 (92.4224)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2570/4579]  eta: 0:13:08  Lr: 0.030000  Loss: -1.5125  Acc@1: 75.0000 (69.3261)  Acc@5: 87.5000 (92.4276)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2580/4579]  eta: 0:13:04  Lr: 0.030000  Loss: -1.7986  Acc@1: 75.0000 (69.3433)  Acc@5: 93.7500 (92.4375)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2590/4579]  eta: 0:13:00  Lr: 0.030000  Loss: -1.5046  Acc@1: 68.7500 (69.3313)  Acc@5: 93.7500 (92.4305)  time: 0.3907  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [2600/4579]  eta: 0:12:56  Lr: 0.030000  Loss: -0.9540  Acc@1: 68.7500 (69.3099)  Acc@5: 93.7500 (92.4212)  time: 0.3915  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2610/4579]  eta: 0:12:52  Lr: 0.030000  Loss: -1.2269  Acc@1: 68.7500 (69.3197)  Acc@5: 93.7500 (92.4311)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2620/4579]  eta: 0:12:48  Lr: 0.030000  Loss: -1.9292  Acc@1: 68.7500 (69.3175)  Acc@5: 93.7500 (92.4218)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2630/4579]  eta: 0:12:44  Lr: 0.030000  Loss: -1.4192  Acc@1: 68.7500 (69.3320)  Acc@5: 93.7500 (92.4292)  time: 0.3919  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2640/4579]  eta: 0:12:40  Lr: 0.030000  Loss: -2.3403  Acc@1: 75.0000 (69.3582)  Acc@5: 93.7500 (92.4366)  time: 0.3924  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [2650/4579]  eta: 0:12:36  Lr: 0.030000  Loss: -2.0811  Acc@1: 75.0000 (69.3700)  Acc@5: 93.7500 (92.4439)  time: 0.3923  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [2660/4579]  eta: 0:12:33  Lr: 0.030000  Loss: -1.7208  Acc@1: 68.7500 (69.3795)  Acc@5: 100.0000 (92.4676)  time: 0.3923  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [2670/4579]  eta: 0:12:29  Lr: 0.030000  Loss: -1.0294  Acc@1: 68.7500 (69.3701)  Acc@5: 100.0000 (92.4677)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2680/4579]  eta: 0:12:25  Lr: 0.030000  Loss: -1.8564  Acc@1: 68.7500 (69.3561)  Acc@5: 93.7500 (92.4492)  time: 0.3902  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2690/4579]  eta: 0:12:21  Lr: 0.030000  Loss: -1.3369  Acc@1: 75.0000 (69.3910)  Acc@5: 93.7500 (92.4563)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2700/4579]  eta: 0:12:17  Lr: 0.030000  Loss: -1.6776  Acc@1: 75.0000 (69.3910)  Acc@5: 93.7500 (92.4542)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2710/4579]  eta: 0:12:13  Lr: 0.030000  Loss: -1.7282  Acc@1: 68.7500 (69.3817)  Acc@5: 93.7500 (92.4497)  time: 0.3896  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2720/4579]  eta: 0:12:09  Lr: 0.030000  Loss: -1.7202  Acc@1: 68.7500 (69.3931)  Acc@5: 93.7500 (92.4637)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2730/4579]  eta: 0:12:05  Lr: 0.030000  Loss: -1.7098  Acc@1: 75.0000 (69.4251)  Acc@5: 93.7500 (92.4661)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2740/4579]  eta: 0:12:01  Lr: 0.030000  Loss: -1.7462  Acc@1: 81.2500 (69.4455)  Acc@5: 93.7500 (92.4685)  time: 0.3919  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2750/4579]  eta: 0:11:57  Lr: 0.030000  Loss: -1.8480  Acc@1: 68.7500 (69.4520)  Acc@5: 93.7500 (92.4664)  time: 0.3915  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [2760/4579]  eta: 0:11:53  Lr: 0.030000  Loss: -1.5829  Acc@1: 68.7500 (69.4721)  Acc@5: 93.7500 (92.4823)  time: 0.3911  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [2770/4579]  eta: 0:11:49  Lr: 0.030000  Loss: -1.8603  Acc@1: 68.7500 (69.4560)  Acc@5: 93.7500 (92.4689)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [2780/4579]  eta: 0:11:45  Lr: 0.030000  Loss: -1.7495  Acc@1: 68.7500 (69.4512)  Acc@5: 87.5000 (92.4667)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [2790/4579]  eta: 0:11:41  Lr: 0.030000  Loss: -1.7661  Acc@1: 75.0000 (69.4711)  Acc@5: 93.7500 (92.4669)  time: 0.3902  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2800/4579]  eta: 0:11:37  Lr: 0.030000  Loss: -1.2905  Acc@1: 75.0000 (69.4618)  Acc@5: 93.7500 (92.4781)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2810/4579]  eta: 0:11:34  Lr: 0.030000  Loss: -1.5636  Acc@1: 68.7500 (69.4704)  Acc@5: 93.7500 (92.4782)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2820/4579]  eta: 0:11:30  Lr: 0.030000  Loss: -2.3086  Acc@1: 75.0000 (69.4900)  Acc@5: 93.7500 (92.4871)  time: 0.3893  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2830/4579]  eta: 0:11:26  Lr: 0.030000  Loss: -1.1262  Acc@1: 68.7500 (69.4587)  Acc@5: 93.7500 (92.4960)  time: 0.3890  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2840/4579]  eta: 0:11:22  Lr: 0.030000  Loss: -2.0383  Acc@1: 62.5000 (69.4540)  Acc@5: 93.7500 (92.5026)  time: 0.3894  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [2850/4579]  eta: 0:11:18  Lr: 0.030000  Loss: -2.1559  Acc@1: 68.7500 (69.4603)  Acc@5: 93.7500 (92.4982)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2860/4579]  eta: 0:11:14  Lr: 0.030000  Loss: -1.4419  Acc@1: 68.7500 (69.4491)  Acc@5: 93.7500 (92.4983)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2870/4579]  eta: 0:11:10  Lr: 0.030000  Loss: -1.3931  Acc@1: 68.7500 (69.4423)  Acc@5: 87.5000 (92.4721)  time: 0.3895  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2880/4579]  eta: 0:11:06  Lr: 0.030000  Loss: -1.7688  Acc@1: 68.7500 (69.4594)  Acc@5: 87.5000 (92.4679)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2890/4579]  eta: 0:11:02  Lr: 0.030000  Loss: -2.0785  Acc@1: 75.0000 (69.4915)  Acc@5: 93.7500 (92.4810)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2900/4579]  eta: 0:10:58  Lr: 0.030000  Loss: -1.7644  Acc@1: 75.0000 (69.4933)  Acc@5: 93.7500 (92.4832)  time: 0.3895  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [2910/4579]  eta: 0:10:54  Lr: 0.030000  Loss: -1.7089  Acc@1: 68.7500 (69.5058)  Acc@5: 93.7500 (92.4790)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2920/4579]  eta: 0:10:50  Lr: 0.030000  Loss: -1.8662  Acc@1: 75.0000 (69.5160)  Acc@5: 93.7500 (92.4855)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [2930/4579]  eta: 0:10:46  Lr: 0.030000  Loss: -1.4527  Acc@1: 68.7500 (69.5262)  Acc@5: 93.7500 (92.4940)  time: 0.3910  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2940/4579]  eta: 0:10:42  Lr: 0.030000  Loss: -1.8684  Acc@1: 68.7500 (69.5235)  Acc@5: 93.7500 (92.4940)  time: 0.3934  data: 0.0023  max mem: 2904
Train: Epoch[4/5]  [2950/4579]  eta: 0:10:39  Lr: 0.030000  Loss: -2.0415  Acc@1: 68.7500 (69.5167)  Acc@5: 93.7500 (92.5025)  time: 0.3939  data: 0.0024  max mem: 2904
Train: Epoch[4/5]  [2960/4579]  eta: 0:10:35  Lr: 0.030000  Loss: -1.2565  Acc@1: 68.7500 (69.5225)  Acc@5: 93.7500 (92.5046)  time: 0.3919  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [2970/4579]  eta: 0:10:31  Lr: 0.030000  Loss: -2.0331  Acc@1: 75.0000 (69.5199)  Acc@5: 87.5000 (92.4899)  time: 0.3929  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [2980/4579]  eta: 0:10:27  Lr: 0.030000  Loss: -1.9677  Acc@1: 68.7500 (69.5278)  Acc@5: 93.7500 (92.4983)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [2990/4579]  eta: 0:10:23  Lr: 0.030000  Loss: -1.8172  Acc@1: 62.5000 (69.5085)  Acc@5: 93.7500 (92.4941)  time: 0.3899  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3000/4579]  eta: 0:10:19  Lr: 0.030000  Loss: -1.6573  Acc@1: 62.5000 (69.5039)  Acc@5: 93.7500 (92.4921)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3010/4579]  eta: 0:10:15  Lr: 0.030000  Loss: -1.7876  Acc@1: 68.7500 (69.4931)  Acc@5: 93.7500 (92.4880)  time: 0.3906  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3020/4579]  eta: 0:10:11  Lr: 0.030000  Loss: -1.7997  Acc@1: 68.7500 (69.4906)  Acc@5: 93.7500 (92.4839)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3030/4579]  eta: 0:10:07  Lr: 0.030000  Loss: -1.1743  Acc@1: 68.7500 (69.4800)  Acc@5: 93.7500 (92.4922)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3040/4579]  eta: 0:10:03  Lr: 0.030000  Loss: -1.5251  Acc@1: 68.7500 (69.4796)  Acc@5: 93.7500 (92.4963)  time: 0.3919  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3050/4579]  eta: 0:09:59  Lr: 0.030000  Loss: -1.2939  Acc@1: 68.7500 (69.4834)  Acc@5: 93.7500 (92.5045)  time: 0.3920  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3060/4579]  eta: 0:09:55  Lr: 0.030000  Loss: -1.3725  Acc@1: 75.0000 (69.4891)  Acc@5: 93.7500 (92.5045)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3070/4579]  eta: 0:09:51  Lr: 0.030000  Loss: -2.2196  Acc@1: 75.0000 (69.4949)  Acc@5: 93.7500 (92.5106)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3080/4579]  eta: 0:09:47  Lr: 0.030000  Loss: -1.2696  Acc@1: 75.0000 (69.4925)  Acc@5: 93.7500 (92.4984)  time: 0.3929  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3090/4579]  eta: 0:09:44  Lr: 0.030000  Loss: -2.0978  Acc@1: 68.7500 (69.4880)  Acc@5: 87.5000 (92.4923)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3100/4579]  eta: 0:09:40  Lr: 0.030000  Loss: -1.3632  Acc@1: 75.0000 (69.4977)  Acc@5: 93.7500 (92.4964)  time: 0.3903  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3110/4579]  eta: 0:09:36  Lr: 0.030000  Loss: -1.0939  Acc@1: 68.7500 (69.4853)  Acc@5: 93.7500 (92.4984)  time: 0.3914  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [3120/4579]  eta: 0:09:32  Lr: 0.030000  Loss: -1.4512  Acc@1: 68.7500 (69.4849)  Acc@5: 93.7500 (92.4964)  time: 0.3924  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3130/4579]  eta: 0:09:28  Lr: 0.030000  Loss: -1.6669  Acc@1: 75.0000 (69.5165)  Acc@5: 93.7500 (92.5004)  time: 0.3914  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3140/4579]  eta: 0:09:24  Lr: 0.030000  Loss: -1.9804  Acc@1: 75.0000 (69.5320)  Acc@5: 93.7500 (92.5143)  time: 0.3920  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3150/4579]  eta: 0:09:20  Lr: 0.030000  Loss: -1.2371  Acc@1: 68.7500 (69.5176)  Acc@5: 93.7500 (92.4984)  time: 0.3925  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3160/4579]  eta: 0:09:16  Lr: 0.030000  Loss: -1.1452  Acc@1: 68.7500 (69.5270)  Acc@5: 93.7500 (92.5004)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3170/4579]  eta: 0:09:12  Lr: 0.030000  Loss: -1.6036  Acc@1: 68.7500 (69.5226)  Acc@5: 93.7500 (92.5004)  time: 0.3915  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3180/4579]  eta: 0:09:08  Lr: 0.030000  Loss: -1.7965  Acc@1: 68.7500 (69.5320)  Acc@5: 93.7500 (92.5024)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3190/4579]  eta: 0:09:04  Lr: 0.030000  Loss: -2.1679  Acc@1: 68.7500 (69.5393)  Acc@5: 93.7500 (92.5043)  time: 0.3924  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3200/4579]  eta: 0:09:00  Lr: 0.030000  Loss: -1.3385  Acc@1: 68.7500 (69.5369)  Acc@5: 93.7500 (92.5141)  time: 0.3932  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3210/4579]  eta: 0:08:56  Lr: 0.030000  Loss: -1.8346  Acc@1: 68.7500 (69.5403)  Acc@5: 93.7500 (92.5179)  time: 0.3954  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3220/4579]  eta: 0:08:53  Lr: 0.030000  Loss: -1.0025  Acc@1: 68.7500 (69.5456)  Acc@5: 93.7500 (92.5179)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3230/4579]  eta: 0:08:49  Lr: 0.030000  Loss: -1.7715  Acc@1: 68.7500 (69.5508)  Acc@5: 93.7500 (92.5101)  time: 0.3923  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3240/4579]  eta: 0:08:45  Lr: 0.030000  Loss: -1.6796  Acc@1: 75.0000 (69.5619)  Acc@5: 93.7500 (92.5216)  time: 0.3932  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [3250/4579]  eta: 0:08:41  Lr: 0.030000  Loss: -2.3068  Acc@1: 75.0000 (69.5747)  Acc@5: 93.7500 (92.5311)  time: 0.3932  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [3260/4579]  eta: 0:08:37  Lr: 0.030000  Loss: -1.3844  Acc@1: 68.7500 (69.5626)  Acc@5: 93.7500 (92.5253)  time: 0.3934  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3270/4579]  eta: 0:08:33  Lr: 0.030000  Loss: -1.5514  Acc@1: 62.5000 (69.5430)  Acc@5: 93.7500 (92.5271)  time: 0.3946  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3280/4579]  eta: 0:08:29  Lr: 0.030000  Loss: -1.4151  Acc@1: 62.5000 (69.5272)  Acc@5: 93.7500 (92.5232)  time: 0.3951  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [3290/4579]  eta: 0:08:25  Lr: 0.030000  Loss: -2.3996  Acc@1: 68.7500 (69.5362)  Acc@5: 93.7500 (92.5251)  time: 0.3945  data: 0.0019  max mem: 2904
Train: Epoch[4/5]  [3300/4579]  eta: 0:08:21  Lr: 0.030000  Loss: -1.9035  Acc@1: 68.7500 (69.5301)  Acc@5: 93.7500 (92.5250)  time: 0.3940  data: 0.0019  max mem: 2904
Train: Epoch[4/5]  [3310/4579]  eta: 0:08:17  Lr: 0.030000  Loss: -1.8553  Acc@1: 62.5000 (69.5051)  Acc@5: 93.7500 (92.5136)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3320/4579]  eta: 0:08:13  Lr: 0.030000  Loss: -1.4189  Acc@1: 62.5000 (69.4971)  Acc@5: 87.5000 (92.4947)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3330/4579]  eta: 0:08:09  Lr: 0.030000  Loss: -2.1848  Acc@1: 68.7500 (69.5062)  Acc@5: 93.7500 (92.5004)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3340/4579]  eta: 0:08:06  Lr: 0.030000  Loss: -2.5167  Acc@1: 68.7500 (69.5151)  Acc@5: 93.7500 (92.4948)  time: 0.3926  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3350/4579]  eta: 0:08:02  Lr: 0.030000  Loss: -1.6269  Acc@1: 68.7500 (69.5259)  Acc@5: 93.7500 (92.4948)  time: 0.3927  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3360/4579]  eta: 0:07:58  Lr: 0.030000  Loss: -1.4132  Acc@1: 68.7500 (69.5254)  Acc@5: 93.7500 (92.4911)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3370/4579]  eta: 0:07:54  Lr: 0.030000  Loss: -0.7668  Acc@1: 68.7500 (69.5157)  Acc@5: 93.7500 (92.4874)  time: 0.3919  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3380/4579]  eta: 0:07:50  Lr: 0.030000  Loss: -1.6295  Acc@1: 68.7500 (69.5209)  Acc@5: 93.7500 (92.4837)  time: 0.3921  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3390/4579]  eta: 0:07:46  Lr: 0.030000  Loss: -1.6879  Acc@1: 68.7500 (69.5296)  Acc@5: 93.7500 (92.4819)  time: 0.3946  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [3400/4579]  eta: 0:07:42  Lr: 0.030000  Loss: -1.9688  Acc@1: 75.0000 (69.5310)  Acc@5: 93.7500 (92.4820)  time: 0.3962  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [3410/4579]  eta: 0:07:38  Lr: 0.030000  Loss: -1.7374  Acc@1: 68.7500 (69.5232)  Acc@5: 93.7500 (92.4784)  time: 0.3939  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [3420/4579]  eta: 0:07:34  Lr: 0.030000  Loss: -1.8144  Acc@1: 62.5000 (69.5064)  Acc@5: 93.7500 (92.4821)  time: 0.3934  data: 0.0018  max mem: 2904
Train: Epoch[4/5]  [3430/4579]  eta: 0:07:30  Lr: 0.030000  Loss: -1.6742  Acc@1: 68.7500 (69.5151)  Acc@5: 93.7500 (92.4840)  time: 0.3934  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3440/4579]  eta: 0:07:26  Lr: 0.030000  Loss: -1.3299  Acc@1: 75.0000 (69.5165)  Acc@5: 93.7500 (92.4822)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3450/4579]  eta: 0:07:22  Lr: 0.030000  Loss: -1.8748  Acc@1: 75.0000 (69.5106)  Acc@5: 93.7500 (92.4913)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3460/4579]  eta: 0:07:18  Lr: 0.030000  Loss: -1.3779  Acc@1: 75.0000 (69.5301)  Acc@5: 93.7500 (92.4986)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3470/4579]  eta: 0:07:15  Lr: 0.030000  Loss: -1.7919  Acc@1: 68.7500 (69.5189)  Acc@5: 93.7500 (92.5040)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3480/4579]  eta: 0:07:11  Lr: 0.030000  Loss: -1.2565  Acc@1: 68.7500 (69.5238)  Acc@5: 93.7500 (92.5040)  time: 0.3914  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [3490/4579]  eta: 0:07:07  Lr: 0.030000  Loss: -1.2716  Acc@1: 68.7500 (69.5091)  Acc@5: 93.7500 (92.4968)  time: 0.3925  data: 0.0014  max mem: 2904
Train: Epoch[4/5]  [3500/4579]  eta: 0:07:03  Lr: 0.030000  Loss: -1.3061  Acc@1: 68.7500 (69.5194)  Acc@5: 93.7500 (92.5004)  time: 0.3928  data: 0.0018  max mem: 2904
Train: Epoch[4/5]  [3510/4579]  eta: 0:06:59  Lr: 0.030000  Loss: -1.3748  Acc@1: 62.5000 (69.5048)  Acc@5: 87.5000 (92.4879)  time: 0.3915  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3520/4579]  eta: 0:06:55  Lr: 0.030000  Loss: -1.1403  Acc@1: 62.5000 (69.5044)  Acc@5: 87.5000 (92.4773)  time: 0.3916  data: 0.0008  max mem: 2904
Train: Epoch[4/5]  [3530/4579]  eta: 0:06:51  Lr: 0.030000  Loss: -1.2604  Acc@1: 68.7500 (69.4934)  Acc@5: 93.7500 (92.4827)  time: 0.3913  data: 0.0008  max mem: 2904
Train: Epoch[4/5]  [3540/4579]  eta: 0:06:47  Lr: 0.030000  Loss: -2.0086  Acc@1: 68.7500 (69.4913)  Acc@5: 93.7500 (92.4880)  time: 0.3891  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3550/4579]  eta: 0:06:43  Lr: 0.030000  Loss: -1.1310  Acc@1: 68.7500 (69.4980)  Acc@5: 93.7500 (92.5004)  time: 0.3888  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3560/4579]  eta: 0:06:39  Lr: 0.030000  Loss: -1.9241  Acc@1: 75.0000 (69.5205)  Acc@5: 100.0000 (92.5109)  time: 0.3900  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3570/4579]  eta: 0:06:35  Lr: 0.030000  Loss: -1.8040  Acc@1: 75.0000 (69.5358)  Acc@5: 93.7500 (92.5126)  time: 0.3903  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3580/4579]  eta: 0:06:31  Lr: 0.030000  Loss: -1.5864  Acc@1: 75.0000 (69.5371)  Acc@5: 93.7500 (92.5143)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3590/4579]  eta: 0:06:27  Lr: 0.030000  Loss: -1.5134  Acc@1: 68.7500 (69.5332)  Acc@5: 93.7500 (92.5212)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [3600/4579]  eta: 0:06:24  Lr: 0.030000  Loss: -1.6508  Acc@1: 62.5000 (69.5137)  Acc@5: 93.7500 (92.5125)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3610/4579]  eta: 0:06:20  Lr: 0.030000  Loss: -1.8559  Acc@1: 68.7500 (69.5081)  Acc@5: 87.5000 (92.5073)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3620/4579]  eta: 0:06:16  Lr: 0.030000  Loss: -1.9441  Acc@1: 68.7500 (69.5129)  Acc@5: 93.7500 (92.5107)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3630/4579]  eta: 0:06:12  Lr: 0.030000  Loss: -1.4771  Acc@1: 68.7500 (69.5056)  Acc@5: 93.7500 (92.5055)  time: 0.3913  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [3640/4579]  eta: 0:06:08  Lr: 0.030000  Loss: -1.4541  Acc@1: 68.7500 (69.5053)  Acc@5: 93.7500 (92.5003)  time: 0.3920  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [3650/4579]  eta: 0:06:04  Lr: 0.030000  Loss: -1.7632  Acc@1: 68.7500 (69.5084)  Acc@5: 93.7500 (92.5038)  time: 0.3931  data: 0.0008  max mem: 2904
Train: Epoch[4/5]  [3660/4579]  eta: 0:06:00  Lr: 0.030000  Loss: -1.8572  Acc@1: 75.0000 (69.5251)  Acc@5: 93.7500 (92.5072)  time: 0.3934  data: 0.0008  max mem: 2904
Train: Epoch[4/5]  [3670/4579]  eta: 0:05:56  Lr: 0.030000  Loss: -1.9080  Acc@1: 75.0000 (69.5349)  Acc@5: 93.7500 (92.5020)  time: 0.3923  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3680/4579]  eta: 0:05:52  Lr: 0.030000  Loss: -1.3366  Acc@1: 68.7500 (69.5225)  Acc@5: 87.5000 (92.4969)  time: 0.3934  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [3690/4579]  eta: 0:05:48  Lr: 0.030000  Loss: -1.9924  Acc@1: 62.5000 (69.5205)  Acc@5: 93.7500 (92.4902)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [3700/4579]  eta: 0:05:44  Lr: 0.030000  Loss: -1.5568  Acc@1: 68.7500 (69.5302)  Acc@5: 93.7500 (92.4885)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3710/4579]  eta: 0:05:40  Lr: 0.030000  Loss: -2.3351  Acc@1: 68.7500 (69.5298)  Acc@5: 93.7500 (92.4801)  time: 0.3921  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [3720/4579]  eta: 0:05:36  Lr: 0.030000  Loss: -2.1533  Acc@1: 68.7500 (69.5344)  Acc@5: 93.7500 (92.4852)  time: 0.3914  data: 0.0007  max mem: 2904
Train: Epoch[4/5]  [3730/4579]  eta: 0:05:33  Lr: 0.030000  Loss: -1.4806  Acc@1: 68.7500 (69.5373)  Acc@5: 93.7500 (92.4886)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3740/4579]  eta: 0:05:29  Lr: 0.030000  Loss: -1.5222  Acc@1: 68.7500 (69.5536)  Acc@5: 93.7500 (92.4953)  time: 0.3951  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3750/4579]  eta: 0:05:25  Lr: 0.030000  Loss: -1.8941  Acc@1: 68.7500 (69.5448)  Acc@5: 93.7500 (92.4953)  time: 0.3944  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [3760/4579]  eta: 0:05:21  Lr: 0.030000  Loss: -1.7272  Acc@1: 62.5000 (69.5344)  Acc@5: 93.7500 (92.4953)  time: 0.3926  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3770/4579]  eta: 0:05:17  Lr: 0.030000  Loss: -1.8028  Acc@1: 68.7500 (69.5406)  Acc@5: 93.7500 (92.5070)  time: 0.3942  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3780/4579]  eta: 0:05:13  Lr: 0.030000  Loss: -1.9720  Acc@1: 75.0000 (69.5534)  Acc@5: 93.7500 (92.5069)  time: 0.3935  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3790/4579]  eta: 0:05:09  Lr: 0.030000  Loss: -1.9314  Acc@1: 75.0000 (69.5661)  Acc@5: 93.7500 (92.5102)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3800/4579]  eta: 0:05:05  Lr: 0.030000  Loss: -1.5493  Acc@1: 75.0000 (69.5689)  Acc@5: 93.7500 (92.5168)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3810/4579]  eta: 0:05:01  Lr: 0.030000  Loss: -1.5667  Acc@1: 68.7500 (69.5634)  Acc@5: 93.7500 (92.5184)  time: 0.3941  data: 0.0018  max mem: 2904
Train: Epoch[4/5]  [3820/4579]  eta: 0:04:57  Lr: 0.030000  Loss: -1.8539  Acc@1: 68.7500 (69.5695)  Acc@5: 93.7500 (92.5134)  time: 0.3942  data: 0.0024  max mem: 2904
Train: Epoch[4/5]  [3830/4579]  eta: 0:04:53  Lr: 0.030000  Loss: -1.3733  Acc@1: 68.7500 (69.5576)  Acc@5: 93.7500 (92.5052)  time: 0.3929  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [3840/4579]  eta: 0:04:49  Lr: 0.030000  Loss: -1.2340  Acc@1: 68.7500 (69.5717)  Acc@5: 93.7500 (92.5020)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3850/4579]  eta: 0:04:45  Lr: 0.030000  Loss: -1.6215  Acc@1: 68.7500 (69.5696)  Acc@5: 93.7500 (92.5052)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3860/4579]  eta: 0:04:42  Lr: 0.030000  Loss: -1.9617  Acc@1: 68.7500 (69.5642)  Acc@5: 93.7500 (92.5052)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3870/4579]  eta: 0:04:38  Lr: 0.030000  Loss: -1.6767  Acc@1: 68.7500 (69.5702)  Acc@5: 93.7500 (92.5084)  time: 0.3945  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [3880/4579]  eta: 0:04:34  Lr: 0.030000  Loss: -1.7184  Acc@1: 62.5000 (69.5568)  Acc@5: 93.7500 (92.5084)  time: 0.3952  data: 0.0031  max mem: 2904
Train: Epoch[4/5]  [3890/4579]  eta: 0:04:30  Lr: 0.030000  Loss: -1.2516  Acc@1: 68.7500 (69.5515)  Acc@5: 93.7500 (92.5035)  time: 0.3961  data: 0.0025  max mem: 2904
Train: Epoch[4/5]  [3900/4579]  eta: 0:04:26  Lr: 0.030000  Loss: -1.4372  Acc@1: 68.7500 (69.5463)  Acc@5: 93.7500 (92.5067)  time: 0.3976  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [3910/4579]  eta: 0:04:22  Lr: 0.030000  Loss: -1.2183  Acc@1: 68.7500 (69.5522)  Acc@5: 93.7500 (92.5051)  time: 0.3980  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [3920/4579]  eta: 0:04:18  Lr: 0.030000  Loss: -1.9055  Acc@1: 75.0000 (69.5581)  Acc@5: 93.7500 (92.4971)  time: 0.3976  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3930/4579]  eta: 0:04:14  Lr: 0.030000  Loss: -2.0826  Acc@1: 75.0000 (69.5752)  Acc@5: 93.7500 (92.5067)  time: 0.3978  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3940/4579]  eta: 0:04:10  Lr: 0.030000  Loss: -2.0771  Acc@1: 75.0000 (69.5762)  Acc@5: 93.7500 (92.5130)  time: 0.3972  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3950/4579]  eta: 0:04:06  Lr: 0.030000  Loss: -2.0899  Acc@1: 62.5000 (69.5757)  Acc@5: 93.7500 (92.5114)  time: 0.3967  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3960/4579]  eta: 0:04:02  Lr: 0.030000  Loss: -1.1015  Acc@1: 62.5000 (69.5752)  Acc@5: 93.7500 (92.5082)  time: 0.3966  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3970/4579]  eta: 0:03:58  Lr: 0.030000  Loss: -1.8827  Acc@1: 68.7500 (69.5732)  Acc@5: 93.7500 (92.5113)  time: 0.3953  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3980/4579]  eta: 0:03:55  Lr: 0.030000  Loss: -2.0861  Acc@1: 75.0000 (69.5789)  Acc@5: 93.7500 (92.5050)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [3990/4579]  eta: 0:03:51  Lr: 0.030000  Loss: -1.3202  Acc@1: 75.0000 (69.5847)  Acc@5: 93.7500 (92.5081)  time: 0.3946  data: 0.0019  max mem: 2904
Train: Epoch[4/5]  [4000/4579]  eta: 0:03:47  Lr: 0.030000  Loss: -1.6557  Acc@1: 68.7500 (69.5732)  Acc@5: 93.7500 (92.5097)  time: 0.3961  data: 0.0018  max mem: 2904
Train: Epoch[4/5]  [4010/4579]  eta: 0:03:43  Lr: 0.030000  Loss: -2.0131  Acc@1: 68.7500 (69.5821)  Acc@5: 93.7500 (92.5128)  time: 0.3960  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4020/4579]  eta: 0:03:39  Lr: 0.030000  Loss: -1.0774  Acc@1: 68.7500 (69.5831)  Acc@5: 93.7500 (92.5174)  time: 0.3977  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4030/4579]  eta: 0:03:35  Lr: 0.030000  Loss: -1.3623  Acc@1: 68.7500 (69.5966)  Acc@5: 93.7500 (92.5158)  time: 0.3968  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4040/4579]  eta: 0:03:31  Lr: 0.030000  Loss: -1.8168  Acc@1: 68.7500 (69.5898)  Acc@5: 93.7500 (92.5173)  time: 0.3955  data: 0.0017  max mem: 2904
Train: Epoch[4/5]  [4050/4579]  eta: 0:03:27  Lr: 0.030000  Loss: -1.6230  Acc@1: 68.7500 (69.5816)  Acc@5: 93.7500 (92.5111)  time: 0.3949  data: 0.0018  max mem: 2904
Train: Epoch[4/5]  [4060/4579]  eta: 0:03:23  Lr: 0.030000  Loss: -2.0778  Acc@1: 68.7500 (69.5888)  Acc@5: 93.7500 (92.5142)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [4070/4579]  eta: 0:03:19  Lr: 0.030000  Loss: -1.1710  Acc@1: 75.0000 (69.5990)  Acc@5: 93.7500 (92.5095)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4080/4579]  eta: 0:03:15  Lr: 0.030000  Loss: -2.1300  Acc@1: 75.0000 (69.6015)  Acc@5: 93.7500 (92.5110)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4090/4579]  eta: 0:03:11  Lr: 0.030000  Loss: -1.6492  Acc@1: 68.7500 (69.6116)  Acc@5: 93.7500 (92.5095)  time: 0.3917  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [4100/4579]  eta: 0:03:07  Lr: 0.030000  Loss: -1.9341  Acc@1: 68.7500 (69.6202)  Acc@5: 93.7500 (92.5079)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4110/4579]  eta: 0:03:04  Lr: 0.030000  Loss: -1.9896  Acc@1: 75.0000 (69.6272)  Acc@5: 93.7500 (92.5094)  time: 0.3910  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4120/4579]  eta: 0:03:00  Lr: 0.030000  Loss: -1.6227  Acc@1: 68.7500 (69.6205)  Acc@5: 93.7500 (92.5049)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4130/4579]  eta: 0:02:56  Lr: 0.030000  Loss: -1.4313  Acc@1: 68.7500 (69.6290)  Acc@5: 93.7500 (92.5018)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4140/4579]  eta: 0:02:52  Lr: 0.030000  Loss: -1.1884  Acc@1: 75.0000 (69.6254)  Acc@5: 93.7500 (92.5018)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4150/4579]  eta: 0:02:48  Lr: 0.030000  Loss: -1.5672  Acc@1: 68.7500 (69.6293)  Acc@5: 93.7500 (92.5063)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4160/4579]  eta: 0:02:44  Lr: 0.030000  Loss: -2.3552  Acc@1: 68.7500 (69.6362)  Acc@5: 93.7500 (92.5078)  time: 0.3908  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4170/4579]  eta: 0:02:40  Lr: 0.030000  Loss: -1.2980  Acc@1: 68.7500 (69.6266)  Acc@5: 87.5000 (92.5003)  time: 0.3910  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4180/4579]  eta: 0:02:36  Lr: 0.030000  Loss: -1.8256  Acc@1: 75.0000 (69.6424)  Acc@5: 87.5000 (92.5003)  time: 0.3950  data: 0.0022  max mem: 2904
Train: Epoch[4/5]  [4190/4579]  eta: 0:02:32  Lr: 0.030000  Loss: -1.9997  Acc@1: 75.0000 (69.6239)  Acc@5: 87.5000 (92.4958)  time: 0.4000  data: 0.0028  max mem: 2904
Train: Epoch[4/5]  [4200/4579]  eta: 0:02:28  Lr: 0.030000  Loss: -1.9988  Acc@1: 68.7500 (69.6263)  Acc@5: 93.7500 (92.5033)  time: 0.3975  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [4210/4579]  eta: 0:02:24  Lr: 0.030000  Loss: -1.6932  Acc@1: 68.7500 (69.6242)  Acc@5: 93.7500 (92.5107)  time: 0.3929  data: 0.0006  max mem: 2904
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:20  Lr: 0.030000  Loss: -1.6789  Acc@1: 68.7500 (69.6266)  Acc@5: 93.7500 (92.5181)  time: 0.3928  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:16  Lr: 0.030000  Loss: -1.2459  Acc@1: 75.0000 (69.6289)  Acc@5: 93.7500 (92.5047)  time: 0.3939  data: 0.0025  max mem: 2904
Train: Epoch[4/5]  [4240/4579]  eta: 0:02:13  Lr: 0.030000  Loss: -1.7073  Acc@1: 68.7500 (69.6195)  Acc@5: 87.5000 (92.5062)  time: 0.3924  data: 0.0019  max mem: 2904
Train: Epoch[4/5]  [4250/4579]  eta: 0:02:09  Lr: 0.030000  Loss: -1.7028  Acc@1: 68.7500 (69.6204)  Acc@5: 93.7500 (92.5076)  time: 0.3918  data: 0.0007  max mem: 2904
Train: Epoch[4/5]  [4260/4579]  eta: 0:02:05  Lr: 0.030000  Loss: -1.8191  Acc@1: 75.0000 (69.6315)  Acc@5: 93.7500 (92.4974)  time: 0.3916  data: 0.0007  max mem: 2904
Train: Epoch[4/5]  [4270/4579]  eta: 0:02:01  Lr: 0.030000  Loss: -1.6087  Acc@1: 68.7500 (69.6251)  Acc@5: 93.7500 (92.4900)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4280/4579]  eta: 0:01:57  Lr: 0.030000  Loss: -0.9568  Acc@1: 68.7500 (69.6187)  Acc@5: 93.7500 (92.4930)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4290/4579]  eta: 0:01:53  Lr: 0.030000  Loss: -1.5234  Acc@1: 68.7500 (69.6283)  Acc@5: 93.7500 (92.4988)  time: 0.3914  data: 0.0011  max mem: 2904
Train: Epoch[4/5]  [4300/4579]  eta: 0:01:49  Lr: 0.030000  Loss: -1.7399  Acc@1: 68.7500 (69.6292)  Acc@5: 93.7500 (92.4988)  time: 0.3924  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [4310/4579]  eta: 0:01:45  Lr: 0.030000  Loss: -1.3298  Acc@1: 68.7500 (69.6315)  Acc@5: 93.7500 (92.5017)  time: 0.3922  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4320/4579]  eta: 0:01:41  Lr: 0.030000  Loss: -2.2903  Acc@1: 68.7500 (69.6396)  Acc@5: 93.7500 (92.5046)  time: 0.3948  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [4330/4579]  eta: 0:01:37  Lr: 0.030000  Loss: -1.9784  Acc@1: 75.0000 (69.6563)  Acc@5: 93.7500 (92.5075)  time: 0.3942  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [4340/4579]  eta: 0:01:33  Lr: 0.030000  Loss: -1.7452  Acc@1: 75.0000 (69.6556)  Acc@5: 93.7500 (92.5046)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:29  Lr: 0.030000  Loss: -1.4595  Acc@1: 68.7500 (69.6578)  Acc@5: 87.5000 (92.4960)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:25  Lr: 0.030000  Loss: -1.8142  Acc@1: 75.0000 (69.6687)  Acc@5: 93.7500 (92.5032)  time: 0.3900  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:22  Lr: 0.030000  Loss: -1.9645  Acc@1: 75.0000 (69.6708)  Acc@5: 93.7500 (92.5046)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:18  Lr: 0.030000  Loss: -2.0122  Acc@1: 68.7500 (69.6716)  Acc@5: 93.7500 (92.5117)  time: 0.3904  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:14  Lr: 0.030000  Loss: -0.8076  Acc@1: 68.7500 (69.6809)  Acc@5: 93.7500 (92.5117)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:10  Lr: 0.030000  Loss: -1.5573  Acc@1: 75.0000 (69.6972)  Acc@5: 93.7500 (92.5173)  time: 0.3921  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4410/4579]  eta: 0:01:06  Lr: 0.030000  Loss: -1.3636  Acc@1: 68.7500 (69.6880)  Acc@5: 93.7500 (92.5145)  time: 0.3923  data: 0.0009  max mem: 2904
Train: Epoch[4/5]  [4420/4579]  eta: 0:01:02  Lr: 0.030000  Loss: -2.4531  Acc@1: 68.7500 (69.7071)  Acc@5: 93.7500 (92.5158)  time: 0.3931  data: 0.0016  max mem: 2904
Train: Epoch[4/5]  [4430/4579]  eta: 0:00:58  Lr: 0.030000  Loss: -1.9910  Acc@1: 75.0000 (69.6993)  Acc@5: 93.7500 (92.5130)  time: 0.3909  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [4440/4579]  eta: 0:00:54  Lr: 0.030000  Loss: -1.8537  Acc@1: 68.7500 (69.6943)  Acc@5: 93.7500 (92.5087)  time: 0.3895  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4450/4579]  eta: 0:00:50  Lr: 0.030000  Loss: -1.0205  Acc@1: 62.5000 (69.6810)  Acc@5: 93.7500 (92.5129)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4460/4579]  eta: 0:00:46  Lr: 0.030000  Loss: -1.2789  Acc@1: 68.7500 (69.6761)  Acc@5: 93.7500 (92.5087)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:42  Lr: 0.030000  Loss: -1.5502  Acc@1: 68.7500 (69.6754)  Acc@5: 93.7500 (92.5115)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:38  Lr: 0.030000  Loss: -1.3871  Acc@1: 68.7500 (69.6817)  Acc@5: 93.7500 (92.5170)  time: 0.3902  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:34  Lr: 0.030000  Loss: -1.8246  Acc@1: 68.7500 (69.6782)  Acc@5: 93.7500 (92.5198)  time: 0.3889  data: 0.0010  max mem: 2904
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:31  Lr: 0.030000  Loss: -1.3970  Acc@1: 75.0000 (69.6803)  Acc@5: 93.7500 (92.5239)  time: 0.3896  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:27  Lr: 0.030000  Loss: -2.0227  Acc@1: 62.5000 (69.6700)  Acc@5: 100.0000 (92.5321)  time: 0.3904  data: 0.0003  max mem: 2904
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:23  Lr: 0.030000  Loss: -2.1389  Acc@1: 68.7500 (69.6776)  Acc@5: 100.0000 (92.5390)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:19  Lr: 0.030000  Loss: -1.7621  Acc@1: 68.7500 (69.6783)  Acc@5: 93.7500 (92.5361)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:15  Lr: 0.030000  Loss: -1.2779  Acc@1: 68.7500 (69.6845)  Acc@5: 93.7500 (92.5429)  time: 0.3899  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:11  Lr: 0.030000  Loss: -2.2367  Acc@1: 62.5000 (69.6674)  Acc@5: 93.7500 (92.5456)  time: 0.3906  data: 0.0004  max mem: 2904
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:07  Lr: 0.030000  Loss: -1.6561  Acc@1: 68.7500 (69.6777)  Acc@5: 93.7500 (92.5510)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: -0.8342  Acc@1: 68.7500 (69.6825)  Acc@5: 93.7500 (92.5550)  time: 0.3924  data: 0.0012  max mem: 2904
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: -1.6528  Acc@1: 68.7500 (69.6753)  Acc@5: 93.7500 (92.5550)  time: 0.3836  data: 0.0011  max mem: 2904
Train: Epoch[4/5] Total time: 0:29:57 (0.3925 s / it)
{0: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.6528  Acc@1: 68.7500 (69.6753)  Acc@5: 93.7500 (92.5550)
Train: Epoch[5/5]  [   0/4579]  eta: 0:55:53  Lr: 0.030000  Loss: -2.0053  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.7323  data: 0.3421  max mem: 2904
Train: Epoch[5/5]  [  10/4579]  eta: 0:32:16  Lr: 0.030000  Loss: -2.1679  Acc@1: 81.2500 (77.8409)  Acc@5: 93.7500 (93.1818)  time: 0.4238  data: 0.0314  max mem: 2904
Train: Epoch[5/5]  [  20/4579]  eta: 0:31:05  Lr: 0.030000  Loss: -1.4300  Acc@1: 75.0000 (72.9167)  Acc@5: 93.7500 (93.4524)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [  30/4579]  eta: 0:30:35  Lr: 0.030000  Loss: -1.7883  Acc@1: 75.0000 (73.1855)  Acc@5: 93.7500 (94.1532)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [  40/4579]  eta: 0:30:18  Lr: 0.030000  Loss: -1.2006  Acc@1: 75.0000 (72.5610)  Acc@5: 100.0000 (94.3598)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [  50/4579]  eta: 0:30:09  Lr: 0.030000  Loss: -1.5716  Acc@1: 68.7500 (71.0784)  Acc@5: 87.5000 (93.1373)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [  60/4579]  eta: 0:30:01  Lr: 0.030000  Loss: -1.8110  Acc@1: 75.0000 (71.3115)  Acc@5: 93.7500 (93.3402)  time: 0.3942  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [  70/4579]  eta: 0:29:53  Lr: 0.030000  Loss: -1.4071  Acc@1: 75.0000 (71.0387)  Acc@5: 93.7500 (93.4859)  time: 0.3938  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [  80/4579]  eta: 0:29:48  Lr: 0.030000  Loss: -1.3772  Acc@1: 68.7500 (71.1420)  Acc@5: 93.7500 (93.5185)  time: 0.3946  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [  90/4579]  eta: 0:29:41  Lr: 0.030000  Loss: -1.7460  Acc@1: 68.7500 (70.6731)  Acc@5: 93.7500 (92.9945)  time: 0.3935  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [ 100/4579]  eta: 0:29:36  Lr: 0.030000  Loss: -1.8300  Acc@1: 68.7500 (70.2351)  Acc@5: 93.7500 (93.0693)  time: 0.3928  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 110/4579]  eta: 0:29:31  Lr: 0.030000  Loss: -1.3631  Acc@1: 62.5000 (69.8198)  Acc@5: 93.7500 (92.7365)  time: 0.3946  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 120/4579]  eta: 0:29:26  Lr: 0.030000  Loss: -1.6172  Acc@1: 62.5000 (69.9380)  Acc@5: 87.5000 (92.7686)  time: 0.3936  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [ 130/4579]  eta: 0:29:20  Lr: 0.030000  Loss: -1.1333  Acc@1: 68.7500 (69.8950)  Acc@5: 93.7500 (92.7958)  time: 0.3919  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [ 140/4579]  eta: 0:29:15  Lr: 0.030000  Loss: -1.8237  Acc@1: 68.7500 (70.0355)  Acc@5: 93.7500 (92.7748)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 150/4579]  eta: 0:29:10  Lr: 0.030000  Loss: -1.4908  Acc@1: 68.7500 (69.9089)  Acc@5: 93.7500 (92.7152)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 160/4579]  eta: 0:29:05  Lr: 0.030000  Loss: -1.5887  Acc@1: 68.7500 (69.5264)  Acc@5: 93.7500 (92.5466)  time: 0.3917  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 170/4579]  eta: 0:29:00  Lr: 0.030000  Loss: -1.9393  Acc@1: 68.7500 (69.6637)  Acc@5: 87.5000 (92.3246)  time: 0.3920  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 180/4579]  eta: 0:28:55  Lr: 0.030000  Loss: -1.6720  Acc@1: 75.0000 (69.9240)  Acc@5: 93.7500 (92.5414)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 190/4579]  eta: 0:28:51  Lr: 0.030000  Loss: -2.0889  Acc@1: 75.0000 (70.0589)  Acc@5: 93.7500 (92.5720)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 200/4579]  eta: 0:28:46  Lr: 0.030000  Loss: -2.0897  Acc@1: 68.7500 (69.7139)  Acc@5: 93.7500 (92.5684)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 210/4579]  eta: 0:28:41  Lr: 0.030000  Loss: -2.4060  Acc@1: 68.7500 (69.8460)  Acc@5: 93.7500 (92.6244)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 220/4579]  eta: 0:28:37  Lr: 0.030000  Loss: -2.0910  Acc@1: 68.7500 (69.9378)  Acc@5: 93.7500 (92.6753)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 230/4579]  eta: 0:28:33  Lr: 0.030000  Loss: -1.2966  Acc@1: 62.5000 (69.5076)  Acc@5: 87.5000 (92.4784)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 240/4579]  eta: 0:28:28  Lr: 0.030000  Loss: -1.7468  Acc@1: 62.5000 (69.6058)  Acc@5: 87.5000 (92.5311)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 250/4579]  eta: 0:28:24  Lr: 0.030000  Loss: -2.0201  Acc@1: 68.7500 (69.6464)  Acc@5: 93.7500 (92.5797)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 260/4579]  eta: 0:28:20  Lr: 0.030000  Loss: -1.1549  Acc@1: 68.7500 (69.6121)  Acc@5: 93.7500 (92.6006)  time: 0.3921  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [ 270/4579]  eta: 0:28:16  Lr: 0.030000  Loss: -1.6016  Acc@1: 68.7500 (69.8339)  Acc@5: 93.7500 (92.7122)  time: 0.3930  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [ 280/4579]  eta: 0:28:12  Lr: 0.030000  Loss: -1.6748  Acc@1: 75.0000 (69.9066)  Acc@5: 93.7500 (92.7269)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 290/4579]  eta: 0:28:07  Lr: 0.030000  Loss: -1.7229  Acc@1: 62.5000 (69.7165)  Acc@5: 93.7500 (92.6761)  time: 0.3915  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 300/4579]  eta: 0:28:03  Lr: 0.030000  Loss: -1.5616  Acc@1: 68.7500 (69.7882)  Acc@5: 93.7500 (92.6703)  time: 0.3919  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 310/4579]  eta: 0:27:59  Lr: 0.030000  Loss: -1.8659  Acc@1: 68.7500 (69.7548)  Acc@5: 93.7500 (92.4437)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 320/4579]  eta: 0:27:55  Lr: 0.030000  Loss: -2.2002  Acc@1: 68.7500 (69.8403)  Acc@5: 87.5000 (92.4844)  time: 0.3915  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 330/4579]  eta: 0:27:51  Lr: 0.030000  Loss: -1.8914  Acc@1: 68.7500 (69.7885)  Acc@5: 93.7500 (92.4849)  time: 0.3910  data: 0.0014  max mem: 2904
Train: Epoch[5/5]  [ 340/4579]  eta: 0:27:47  Lr: 0.030000  Loss: -2.2357  Acc@1: 68.7500 (69.9230)  Acc@5: 93.7500 (92.5587)  time: 0.3915  data: 0.0013  max mem: 2904
Train: Epoch[5/5]  [ 350/4579]  eta: 0:27:42  Lr: 0.030000  Loss: -0.6743  Acc@1: 68.7500 (69.8718)  Acc@5: 93.7500 (92.5036)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 360/4579]  eta: 0:27:38  Lr: 0.030000  Loss: -1.7207  Acc@1: 68.7500 (70.0312)  Acc@5: 93.7500 (92.5035)  time: 0.3909  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [ 370/4579]  eta: 0:27:34  Lr: 0.030000  Loss: -1.9783  Acc@1: 68.7500 (69.9966)  Acc@5: 93.7500 (92.4865)  time: 0.3922  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [ 380/4579]  eta: 0:27:30  Lr: 0.030000  Loss: -2.4897  Acc@1: 68.7500 (69.9967)  Acc@5: 93.7500 (92.3885)  time: 0.3913  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [ 390/4579]  eta: 0:27:26  Lr: 0.030000  Loss: -1.5017  Acc@1: 68.7500 (69.9488)  Acc@5: 93.7500 (92.3753)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 400/4579]  eta: 0:27:22  Lr: 0.030000  Loss: -1.8744  Acc@1: 68.7500 (69.9501)  Acc@5: 93.7500 (92.3628)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 410/4579]  eta: 0:27:18  Lr: 0.030000  Loss: -1.5023  Acc@1: 68.7500 (69.9970)  Acc@5: 93.7500 (92.4422)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 420/4579]  eta: 0:27:14  Lr: 0.030000  Loss: -1.8614  Acc@1: 68.7500 (70.0713)  Acc@5: 93.7500 (92.5327)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 430/4579]  eta: 0:27:09  Lr: 0.030000  Loss: -1.0584  Acc@1: 68.7500 (70.0406)  Acc@5: 93.7500 (92.5609)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 440/4579]  eta: 0:27:05  Lr: 0.030000  Loss: -1.4633  Acc@1: 68.7500 (69.9121)  Acc@5: 93.7500 (92.5737)  time: 0.3917  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 450/4579]  eta: 0:27:02  Lr: 0.030000  Loss: -1.8820  Acc@1: 68.7500 (69.8586)  Acc@5: 93.7500 (92.6275)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 460/4579]  eta: 0:26:58  Lr: 0.030000  Loss: -1.6676  Acc@1: 68.7500 (69.7939)  Acc@5: 93.7500 (92.6247)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 470/4579]  eta: 0:26:54  Lr: 0.030000  Loss: -1.8678  Acc@1: 68.7500 (69.8116)  Acc@5: 93.7500 (92.6884)  time: 0.3925  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [ 480/4579]  eta: 0:26:50  Lr: 0.030000  Loss: -1.0101  Acc@1: 68.7500 (69.8025)  Acc@5: 93.7500 (92.6715)  time: 0.3918  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [ 490/4579]  eta: 0:26:45  Lr: 0.030000  Loss: -1.3033  Acc@1: 62.5000 (69.7683)  Acc@5: 93.7500 (92.6298)  time: 0.3904  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 500/4579]  eta: 0:26:41  Lr: 0.030000  Loss: -1.1337  Acc@1: 68.7500 (69.7854)  Acc@5: 93.7500 (92.6148)  time: 0.3896  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 510/4579]  eta: 0:26:37  Lr: 0.030000  Loss: -1.7319  Acc@1: 68.7500 (69.7407)  Acc@5: 93.7500 (92.5881)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 520/4579]  eta: 0:26:33  Lr: 0.030000  Loss: -1.3669  Acc@1: 68.7500 (69.7217)  Acc@5: 93.7500 (92.5624)  time: 0.3902  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 530/4579]  eta: 0:26:29  Lr: 0.030000  Loss: -1.7064  Acc@1: 68.7500 (69.7034)  Acc@5: 93.7500 (92.6201)  time: 0.3900  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 540/4579]  eta: 0:26:25  Lr: 0.030000  Loss: -2.0396  Acc@1: 68.7500 (69.6973)  Acc@5: 93.7500 (92.6294)  time: 0.3950  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [ 550/4579]  eta: 0:26:22  Lr: 0.030000  Loss: -1.2941  Acc@1: 68.7500 (69.7142)  Acc@5: 93.7500 (92.6270)  time: 0.3966  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [ 560/4579]  eta: 0:26:18  Lr: 0.030000  Loss: -1.2503  Acc@1: 68.7500 (69.8307)  Acc@5: 93.7500 (92.6582)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 570/4579]  eta: 0:26:14  Lr: 0.030000  Loss: -1.8320  Acc@1: 68.7500 (69.7789)  Acc@5: 93.7500 (92.6992)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 580/4579]  eta: 0:26:10  Lr: 0.030000  Loss: -1.6167  Acc@1: 68.7500 (69.8257)  Acc@5: 93.7500 (92.7496)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 590/4579]  eta: 0:26:06  Lr: 0.030000  Loss: -1.4524  Acc@1: 68.7500 (69.8604)  Acc@5: 93.7500 (92.6819)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 600/4579]  eta: 0:26:02  Lr: 0.030000  Loss: -1.6194  Acc@1: 68.7500 (69.7379)  Acc@5: 87.5000 (92.6581)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 610/4579]  eta: 0:25:58  Lr: 0.030000  Loss: -1.4031  Acc@1: 68.7500 (69.7218)  Acc@5: 93.7500 (92.6350)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 620/4579]  eta: 0:25:54  Lr: 0.030000  Loss: -2.0454  Acc@1: 68.7500 (69.6860)  Acc@5: 93.7500 (92.5926)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 630/4579]  eta: 0:25:50  Lr: 0.030000  Loss: -1.7674  Acc@1: 75.0000 (69.6414)  Acc@5: 93.7500 (92.6307)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 640/4579]  eta: 0:25:45  Lr: 0.030000  Loss: -1.3461  Acc@1: 75.0000 (69.7250)  Acc@5: 93.7500 (92.6580)  time: 0.3892  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 650/4579]  eta: 0:25:41  Lr: 0.030000  Loss: -1.1695  Acc@1: 75.0000 (69.7005)  Acc@5: 93.7500 (92.6267)  time: 0.3897  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 660/4579]  eta: 0:25:37  Lr: 0.030000  Loss: -1.7071  Acc@1: 75.0000 (69.7523)  Acc@5: 93.7500 (92.6626)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 670/4579]  eta: 0:25:33  Lr: 0.030000  Loss: -1.8403  Acc@1: 75.0000 (69.7653)  Acc@5: 93.7500 (92.6602)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 680/4579]  eta: 0:25:29  Lr: 0.030000  Loss: -2.0636  Acc@1: 75.0000 (69.8330)  Acc@5: 93.7500 (92.7037)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 690/4579]  eta: 0:25:25  Lr: 0.030000  Loss: -1.3222  Acc@1: 68.7500 (69.7992)  Acc@5: 93.7500 (92.6918)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 700/4579]  eta: 0:25:21  Lr: 0.030000  Loss: -2.0568  Acc@1: 68.7500 (69.8734)  Acc@5: 93.7500 (92.7336)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 710/4579]  eta: 0:25:17  Lr: 0.030000  Loss: -2.0517  Acc@1: 75.0000 (69.8400)  Acc@5: 93.7500 (92.7215)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 720/4579]  eta: 0:25:13  Lr: 0.030000  Loss: -2.0315  Acc@1: 68.7500 (69.8769)  Acc@5: 93.7500 (92.7011)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 730/4579]  eta: 0:25:10  Lr: 0.030000  Loss: -1.3162  Acc@1: 68.7500 (69.8444)  Acc@5: 93.7500 (92.6813)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 740/4579]  eta: 0:25:06  Lr: 0.030000  Loss: -1.6056  Acc@1: 62.5000 (69.8043)  Acc@5: 87.5000 (92.6029)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 750/4579]  eta: 0:25:02  Lr: 0.030000  Loss: -1.2619  Acc@1: 62.5000 (69.6904)  Acc@5: 87.5000 (92.5599)  time: 0.3924  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 760/4579]  eta: 0:24:58  Lr: 0.030000  Loss: -1.8951  Acc@1: 68.7500 (69.7355)  Acc@5: 93.7500 (92.5673)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 770/4579]  eta: 0:24:54  Lr: 0.030000  Loss: -1.8635  Acc@1: 75.0000 (69.8119)  Acc@5: 93.7500 (92.5827)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 780/4579]  eta: 0:24:50  Lr: 0.030000  Loss: -1.9177  Acc@1: 75.0000 (69.8143)  Acc@5: 93.7500 (92.6216)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 790/4579]  eta: 0:24:46  Lr: 0.030000  Loss: -1.8112  Acc@1: 68.7500 (69.8483)  Acc@5: 93.7500 (92.6201)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 800/4579]  eta: 0:24:42  Lr: 0.030000  Loss: -1.4708  Acc@1: 75.0000 (69.8736)  Acc@5: 93.7500 (92.6264)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 810/4579]  eta: 0:24:38  Lr: 0.030000  Loss: -1.6193  Acc@1: 75.0000 (69.9137)  Acc@5: 93.7500 (92.6711)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 820/4579]  eta: 0:24:34  Lr: 0.030000  Loss: -2.1785  Acc@1: 68.7500 (69.9224)  Acc@5: 93.7500 (92.6462)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 830/4579]  eta: 0:24:30  Lr: 0.030000  Loss: -2.0659  Acc@1: 68.7500 (69.8631)  Acc@5: 87.5000 (92.6068)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 840/4579]  eta: 0:24:26  Lr: 0.030000  Loss: -0.8905  Acc@1: 68.7500 (69.8573)  Acc@5: 87.5000 (92.5832)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 850/4579]  eta: 0:24:23  Lr: 0.030000  Loss: -1.6189  Acc@1: 62.5000 (69.7415)  Acc@5: 87.5000 (92.5382)  time: 0.3922  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [ 860/4579]  eta: 0:24:19  Lr: 0.030000  Loss: -1.5734  Acc@1: 68.7500 (69.7953)  Acc@5: 87.5000 (92.5377)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 870/4579]  eta: 0:24:15  Lr: 0.030000  Loss: -1.4370  Acc@1: 68.7500 (69.7761)  Acc@5: 93.7500 (92.5373)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 880/4579]  eta: 0:24:11  Lr: 0.030000  Loss: -1.9385  Acc@1: 68.7500 (69.7928)  Acc@5: 93.7500 (92.5511)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 890/4579]  eta: 0:24:07  Lr: 0.030000  Loss: -1.8221  Acc@1: 68.7500 (69.7601)  Acc@5: 93.7500 (92.5154)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 900/4579]  eta: 0:24:03  Lr: 0.030000  Loss: -1.8747  Acc@1: 68.7500 (69.7766)  Acc@5: 93.7500 (92.5083)  time: 0.3934  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [ 910/4579]  eta: 0:23:59  Lr: 0.030000  Loss: -1.8978  Acc@1: 75.0000 (69.7654)  Acc@5: 93.7500 (92.5357)  time: 0.3927  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [ 920/4579]  eta: 0:23:55  Lr: 0.030000  Loss: -0.9799  Acc@1: 68.7500 (69.7204)  Acc@5: 93.7500 (92.5489)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [ 930/4579]  eta: 0:23:51  Lr: 0.030000  Loss: -1.7633  Acc@1: 68.7500 (69.7637)  Acc@5: 93.7500 (92.5550)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 940/4579]  eta: 0:23:47  Lr: 0.030000  Loss: -1.2880  Acc@1: 75.0000 (69.7529)  Acc@5: 93.7500 (92.5412)  time: 0.3923  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 950/4579]  eta: 0:23:43  Lr: 0.030000  Loss: -1.8260  Acc@1: 68.7500 (69.7621)  Acc@5: 87.5000 (92.5013)  time: 0.3917  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [ 960/4579]  eta: 0:23:39  Lr: 0.030000  Loss: -1.7887  Acc@1: 62.5000 (69.7125)  Acc@5: 87.5000 (92.5013)  time: 0.3932  data: 0.0019  max mem: 2904
Train: Epoch[5/5]  [ 970/4579]  eta: 0:23:35  Lr: 0.030000  Loss: -2.1147  Acc@1: 62.5000 (69.7477)  Acc@5: 93.7500 (92.5013)  time: 0.3928  data: 0.0020  max mem: 2904
Train: Epoch[5/5]  [ 980/4579]  eta: 0:23:31  Lr: 0.030000  Loss: -1.4701  Acc@1: 75.0000 (69.7949)  Acc@5: 93.7500 (92.5204)  time: 0.3904  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [ 990/4579]  eta: 0:23:27  Lr: 0.030000  Loss: -1.3769  Acc@1: 68.7500 (69.7969)  Acc@5: 93.7500 (92.4950)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1000/4579]  eta: 0:23:23  Lr: 0.030000  Loss: -0.8624  Acc@1: 68.7500 (69.7740)  Acc@5: 87.5000 (92.4825)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1010/4579]  eta: 0:23:20  Lr: 0.030000  Loss: -1.7551  Acc@1: 68.7500 (69.7515)  Acc@5: 93.7500 (92.4827)  time: 0.3925  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [1020/4579]  eta: 0:23:16  Lr: 0.030000  Loss: -2.0555  Acc@1: 68.7500 (69.7539)  Acc@5: 93.7500 (92.4951)  time: 0.3946  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [1030/4579]  eta: 0:23:12  Lr: 0.030000  Loss: -1.7925  Acc@1: 68.7500 (69.7381)  Acc@5: 93.7500 (92.5073)  time: 0.3970  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [1040/4579]  eta: 0:23:08  Lr: 0.030000  Loss: -1.6267  Acc@1: 68.7500 (69.7346)  Acc@5: 93.7500 (92.5192)  time: 0.3943  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1050/4579]  eta: 0:23:04  Lr: 0.030000  Loss: -1.1942  Acc@1: 75.0000 (69.8264)  Acc@5: 100.0000 (92.5666)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1060/4579]  eta: 0:23:00  Lr: 0.030000  Loss: -2.0301  Acc@1: 75.0000 (69.8810)  Acc@5: 93.7500 (92.5601)  time: 0.3924  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1070/4579]  eta: 0:22:56  Lr: 0.030000  Loss: -1.1741  Acc@1: 75.0000 (69.8880)  Acc@5: 93.7500 (92.5712)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1080/4579]  eta: 0:22:52  Lr: 0.030000  Loss: -1.7541  Acc@1: 75.0000 (69.9352)  Acc@5: 93.7500 (92.5937)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1090/4579]  eta: 0:22:48  Lr: 0.030000  Loss: -2.0033  Acc@1: 75.0000 (69.9473)  Acc@5: 93.7500 (92.6043)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1100/4579]  eta: 0:22:44  Lr: 0.030000  Loss: -1.4432  Acc@1: 68.7500 (69.9194)  Acc@5: 93.7500 (92.5920)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1110/4579]  eta: 0:22:41  Lr: 0.030000  Loss: -1.4019  Acc@1: 68.7500 (69.9145)  Acc@5: 93.7500 (92.5743)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1120/4579]  eta: 0:22:37  Lr: 0.030000  Loss: -1.1241  Acc@1: 68.7500 (69.9153)  Acc@5: 93.7500 (92.5903)  time: 0.3928  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1130/4579]  eta: 0:22:33  Lr: 0.030000  Loss: -1.8767  Acc@1: 68.7500 (69.9160)  Acc@5: 93.7500 (92.6006)  time: 0.3935  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [1140/4579]  eta: 0:22:29  Lr: 0.030000  Loss: -2.1098  Acc@1: 62.5000 (69.9003)  Acc@5: 93.7500 (92.6106)  time: 0.3920  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1150/4579]  eta: 0:22:25  Lr: 0.030000  Loss: -1.6938  Acc@1: 68.7500 (69.9120)  Acc@5: 93.7500 (92.6205)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1160/4579]  eta: 0:22:21  Lr: 0.030000  Loss: -1.5441  Acc@1: 68.7500 (69.9397)  Acc@5: 93.7500 (92.6410)  time: 0.3911  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1170/4579]  eta: 0:22:17  Lr: 0.030000  Loss: -1.4892  Acc@1: 62.5000 (69.9082)  Acc@5: 93.7500 (92.6398)  time: 0.3890  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1180/4579]  eta: 0:22:13  Lr: 0.030000  Loss: -2.4667  Acc@1: 62.5000 (69.9196)  Acc@5: 93.7500 (92.6545)  time: 0.3892  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1190/4579]  eta: 0:22:09  Lr: 0.030000  Loss: -1.6851  Acc@1: 68.7500 (69.8678)  Acc@5: 93.7500 (92.6480)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1200/4579]  eta: 0:22:05  Lr: 0.030000  Loss: -1.8285  Acc@1: 68.7500 (69.8637)  Acc@5: 93.7500 (92.6572)  time: 0.3926  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1210/4579]  eta: 0:22:01  Lr: 0.030000  Loss: -1.1321  Acc@1: 68.7500 (69.8648)  Acc@5: 93.7500 (92.6559)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1220/4579]  eta: 0:21:57  Lr: 0.030000  Loss: -1.8992  Acc@1: 68.7500 (69.8710)  Acc@5: 93.7500 (92.6802)  time: 0.3897  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1230/4579]  eta: 0:21:53  Lr: 0.030000  Loss: -1.5969  Acc@1: 68.7500 (69.8721)  Acc@5: 93.7500 (92.6736)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1240/4579]  eta: 0:21:49  Lr: 0.030000  Loss: -1.6924  Acc@1: 68.7500 (69.8932)  Acc@5: 93.7500 (92.6622)  time: 0.3915  data: 0.0013  max mem: 2904
Train: Epoch[5/5]  [1250/4579]  eta: 0:21:45  Lr: 0.030000  Loss: -2.0111  Acc@1: 75.0000 (69.9840)  Acc@5: 93.7500 (92.6859)  time: 0.3904  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [1260/4579]  eta: 0:21:41  Lr: 0.030000  Loss: -1.1784  Acc@1: 68.7500 (69.9247)  Acc@5: 93.7500 (92.6596)  time: 0.3903  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1270/4579]  eta: 0:21:37  Lr: 0.030000  Loss: -1.5160  Acc@1: 68.7500 (69.9695)  Acc@5: 93.7500 (92.6878)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1280/4579]  eta: 0:21:33  Lr: 0.030000  Loss: -2.1762  Acc@1: 75.0000 (69.9941)  Acc@5: 93.7500 (92.7010)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1290/4579]  eta: 0:21:29  Lr: 0.030000  Loss: -1.3968  Acc@1: 75.0000 (70.0087)  Acc@5: 93.7500 (92.6656)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1300/4579]  eta: 0:21:25  Lr: 0.030000  Loss: -1.1438  Acc@1: 68.7500 (69.9990)  Acc@5: 93.7500 (92.6787)  time: 0.3936  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1310/4579]  eta: 0:21:22  Lr: 0.030000  Loss: -1.4466  Acc@1: 62.5000 (69.9752)  Acc@5: 93.7500 (92.7012)  time: 0.3925  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [1320/4579]  eta: 0:21:18  Lr: 0.030000  Loss: -1.9050  Acc@1: 68.7500 (69.9565)  Acc@5: 93.7500 (92.6902)  time: 0.3903  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1330/4579]  eta: 0:21:14  Lr: 0.030000  Loss: -1.5217  Acc@1: 68.7500 (69.9474)  Acc@5: 93.7500 (92.6982)  time: 0.3908  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1340/4579]  eta: 0:21:10  Lr: 0.030000  Loss: -1.6345  Acc@1: 68.7500 (69.9431)  Acc@5: 93.7500 (92.7013)  time: 0.3917  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1350/4579]  eta: 0:21:06  Lr: 0.030000  Loss: -1.7730  Acc@1: 68.7500 (69.9759)  Acc@5: 93.7500 (92.7184)  time: 0.3921  data: 0.0017  max mem: 2904
Train: Epoch[5/5]  [1360/4579]  eta: 0:21:02  Lr: 0.030000  Loss: -1.9420  Acc@1: 68.7500 (70.0083)  Acc@5: 93.7500 (92.7122)  time: 0.3929  data: 0.0017  max mem: 2904
Train: Epoch[5/5]  [1370/4579]  eta: 0:20:58  Lr: 0.030000  Loss: -1.5013  Acc@1: 75.0000 (70.0356)  Acc@5: 93.7500 (92.7380)  time: 0.3937  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [1380/4579]  eta: 0:20:54  Lr: 0.030000  Loss: -1.7418  Acc@1: 75.0000 (70.0398)  Acc@5: 93.7500 (92.7317)  time: 0.3936  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1390/4579]  eta: 0:20:50  Lr: 0.030000  Loss: -1.4205  Acc@1: 68.7500 (70.0710)  Acc@5: 93.7500 (92.7345)  time: 0.3963  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1400/4579]  eta: 0:20:46  Lr: 0.030000  Loss: -1.8274  Acc@1: 75.0000 (70.0839)  Acc@5: 93.7500 (92.7373)  time: 0.3969  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1410/4579]  eta: 0:20:43  Lr: 0.030000  Loss: -2.0985  Acc@1: 62.5000 (70.0345)  Acc@5: 93.7500 (92.7135)  time: 0.3953  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1420/4579]  eta: 0:20:39  Lr: 0.030000  Loss: -1.9460  Acc@1: 62.5000 (70.0387)  Acc@5: 93.7500 (92.7164)  time: 0.3951  data: 0.0017  max mem: 2904
Train: Epoch[5/5]  [1430/4579]  eta: 0:20:35  Lr: 0.030000  Loss: -1.4481  Acc@1: 68.7500 (70.0210)  Acc@5: 93.7500 (92.7105)  time: 0.3932  data: 0.0017  max mem: 2904
Train: Epoch[5/5]  [1440/4579]  eta: 0:20:31  Lr: 0.030000  Loss: -1.2541  Acc@1: 68.7500 (69.9688)  Acc@5: 93.7500 (92.7091)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1450/4579]  eta: 0:20:27  Lr: 0.030000  Loss: -1.7609  Acc@1: 68.7500 (69.9776)  Acc@5: 93.7500 (92.7076)  time: 0.3920  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [1460/4579]  eta: 0:20:23  Lr: 0.030000  Loss: -1.7018  Acc@1: 75.0000 (69.9991)  Acc@5: 93.7500 (92.7190)  time: 0.3931  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [1470/4579]  eta: 0:20:19  Lr: 0.030000  Loss: -1.7934  Acc@1: 75.0000 (69.9992)  Acc@5: 93.7500 (92.7473)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1480/4579]  eta: 0:20:15  Lr: 0.030000  Loss: -1.8323  Acc@1: 68.7500 (69.9992)  Acc@5: 93.7500 (92.7498)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [1490/4579]  eta: 0:20:11  Lr: 0.030000  Loss: -1.9307  Acc@1: 68.7500 (69.9950)  Acc@5: 93.7500 (92.7607)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1500/4579]  eta: 0:20:07  Lr: 0.030000  Loss: -1.9951  Acc@1: 68.7500 (69.9908)  Acc@5: 93.7500 (92.7673)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1510/4579]  eta: 0:20:03  Lr: 0.030000  Loss: -1.8931  Acc@1: 75.0000 (70.0033)  Acc@5: 93.7500 (92.7656)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1520/4579]  eta: 0:19:59  Lr: 0.030000  Loss: -1.8496  Acc@1: 75.0000 (70.0074)  Acc@5: 93.7500 (92.7392)  time: 0.3933  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1530/4579]  eta: 0:19:55  Lr: 0.030000  Loss: -1.9969  Acc@1: 68.7500 (70.0073)  Acc@5: 93.7500 (92.7458)  time: 0.3912  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [1540/4579]  eta: 0:19:52  Lr: 0.030000  Loss: -1.7221  Acc@1: 68.7500 (70.0235)  Acc@5: 93.7500 (92.7563)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1550/4579]  eta: 0:19:48  Lr: 0.030000  Loss: -1.0627  Acc@1: 68.7500 (70.0234)  Acc@5: 93.7500 (92.7627)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1560/4579]  eta: 0:19:44  Lr: 0.030000  Loss: -1.4254  Acc@1: 75.0000 (70.0512)  Acc@5: 100.0000 (92.7731)  time: 0.3916  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1570/4579]  eta: 0:19:40  Lr: 0.030000  Loss: -1.7164  Acc@1: 68.7500 (70.0430)  Acc@5: 93.7500 (92.7634)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [1580/4579]  eta: 0:19:36  Lr: 0.030000  Loss: -1.8046  Acc@1: 68.7500 (70.0506)  Acc@5: 93.7500 (92.7775)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1590/4579]  eta: 0:19:32  Lr: 0.030000  Loss: -1.9260  Acc@1: 68.7500 (70.0464)  Acc@5: 93.7500 (92.7797)  time: 0.3926  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1600/4579]  eta: 0:19:28  Lr: 0.030000  Loss: -2.0856  Acc@1: 68.7500 (70.0070)  Acc@5: 93.7500 (92.7740)  time: 0.3929  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1610/4579]  eta: 0:19:24  Lr: 0.030000  Loss: -1.5513  Acc@1: 68.7500 (70.0186)  Acc@5: 93.7500 (92.7762)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [1620/4579]  eta: 0:19:20  Lr: 0.030000  Loss: -1.7098  Acc@1: 68.7500 (70.0031)  Acc@5: 93.7500 (92.7861)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1630/4579]  eta: 0:19:16  Lr: 0.030000  Loss: -1.9658  Acc@1: 68.7500 (70.0261)  Acc@5: 93.7500 (92.7882)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1640/4579]  eta: 0:19:12  Lr: 0.030000  Loss: -2.0475  Acc@1: 75.0000 (70.0564)  Acc@5: 93.7500 (92.7978)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1650/4579]  eta: 0:19:08  Lr: 0.030000  Loss: -1.9678  Acc@1: 75.0000 (70.0712)  Acc@5: 93.7500 (92.7960)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1660/4579]  eta: 0:19:04  Lr: 0.030000  Loss: -2.1157  Acc@1: 68.7500 (70.0745)  Acc@5: 93.7500 (92.8018)  time: 0.3914  data: 0.0017  max mem: 2904
Train: Epoch[5/5]  [1670/4579]  eta: 0:19:00  Lr: 0.030000  Loss: -1.9650  Acc@1: 75.0000 (70.0853)  Acc@5: 93.7500 (92.8000)  time: 0.3934  data: 0.0024  max mem: 2904
Train: Epoch[5/5]  [1680/4579]  eta: 0:18:56  Lr: 0.030000  Loss: -1.8906  Acc@1: 68.7500 (70.0848)  Acc@5: 93.7500 (92.7982)  time: 0.3933  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1690/4579]  eta: 0:18:53  Lr: 0.030000  Loss: -2.0745  Acc@1: 68.7500 (70.1101)  Acc@5: 93.7500 (92.8223)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1700/4579]  eta: 0:18:49  Lr: 0.030000  Loss: -1.6595  Acc@1: 68.7500 (70.1279)  Acc@5: 93.7500 (92.8204)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1710/4579]  eta: 0:18:45  Lr: 0.030000  Loss: -1.4259  Acc@1: 68.7500 (70.0942)  Acc@5: 93.7500 (92.8076)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1720/4579]  eta: 0:18:41  Lr: 0.030000  Loss: -1.8554  Acc@1: 75.0000 (70.1445)  Acc@5: 93.7500 (92.8203)  time: 0.3915  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1730/4579]  eta: 0:18:37  Lr: 0.030000  Loss: -2.0223  Acc@1: 75.0000 (70.1509)  Acc@5: 93.7500 (92.8185)  time: 0.3937  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [1740/4579]  eta: 0:18:33  Lr: 0.030000  Loss: -1.9842  Acc@1: 75.0000 (70.1465)  Acc@5: 93.7500 (92.8310)  time: 0.3935  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [1750/4579]  eta: 0:18:29  Lr: 0.030000  Loss: -1.7489  Acc@1: 68.7500 (70.1242)  Acc@5: 93.7500 (92.8113)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1760/4579]  eta: 0:18:25  Lr: 0.030000  Loss: -1.1630  Acc@1: 62.5000 (70.0916)  Acc@5: 87.5000 (92.7988)  time: 0.3902  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [1770/4579]  eta: 0:18:21  Lr: 0.030000  Loss: -1.7318  Acc@1: 68.7500 (70.0805)  Acc@5: 93.7500 (92.7866)  time: 0.3911  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [1780/4579]  eta: 0:18:17  Lr: 0.030000  Loss: -1.7228  Acc@1: 68.7500 (70.0976)  Acc@5: 93.7500 (92.7955)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1790/4579]  eta: 0:18:13  Lr: 0.030000  Loss: -1.7909  Acc@1: 75.0000 (70.1040)  Acc@5: 93.7500 (92.7973)  time: 0.3931  data: 0.0024  max mem: 2904
Train: Epoch[5/5]  [1800/4579]  eta: 0:18:09  Lr: 0.030000  Loss: -2.0175  Acc@1: 75.0000 (70.1312)  Acc@5: 93.7500 (92.8026)  time: 0.3930  data: 0.0023  max mem: 2904
Train: Epoch[5/5]  [1810/4579]  eta: 0:18:05  Lr: 0.030000  Loss: -1.4915  Acc@1: 75.0000 (70.1305)  Acc@5: 93.7500 (92.8147)  time: 0.3904  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1820/4579]  eta: 0:18:02  Lr: 0.030000  Loss: -2.3306  Acc@1: 75.0000 (70.1400)  Acc@5: 93.7500 (92.8267)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1830/4579]  eta: 0:17:58  Lr: 0.030000  Loss: -1.8803  Acc@1: 68.7500 (70.1359)  Acc@5: 93.7500 (92.8181)  time: 0.3920  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [1840/4579]  eta: 0:17:54  Lr: 0.030000  Loss: -2.0035  Acc@1: 68.7500 (70.1351)  Acc@5: 93.7500 (92.8232)  time: 0.3914  data: 0.0016  max mem: 2904
Train: Epoch[5/5]  [1850/4579]  eta: 0:17:50  Lr: 0.030000  Loss: -1.4758  Acc@1: 75.0000 (70.1682)  Acc@5: 93.7500 (92.8214)  time: 0.3905  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [1860/4579]  eta: 0:17:46  Lr: 0.030000  Loss: -1.6550  Acc@1: 68.7500 (70.1538)  Acc@5: 93.7500 (92.8164)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [1870/4579]  eta: 0:17:42  Lr: 0.030000  Loss: -1.5221  Acc@1: 68.7500 (70.1664)  Acc@5: 93.7500 (92.8280)  time: 0.3919  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [1880/4579]  eta: 0:17:38  Lr: 0.030000  Loss: -1.2563  Acc@1: 68.7500 (70.1621)  Acc@5: 93.7500 (92.8196)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1890/4579]  eta: 0:17:34  Lr: 0.030000  Loss: -2.0429  Acc@1: 68.7500 (70.1646)  Acc@5: 93.7500 (92.8180)  time: 0.3913  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1900/4579]  eta: 0:17:30  Lr: 0.030000  Loss: -2.1167  Acc@1: 68.7500 (70.1604)  Acc@5: 93.7500 (92.8097)  time: 0.3919  data: 0.0021  max mem: 2904
Train: Epoch[5/5]  [1910/4579]  eta: 0:17:26  Lr: 0.030000  Loss: -1.8690  Acc@1: 75.0000 (70.1923)  Acc@5: 93.7500 (92.8342)  time: 0.3939  data: 0.0027  max mem: 2904
Train: Epoch[5/5]  [1920/4579]  eta: 0:17:22  Lr: 0.030000  Loss: -1.0922  Acc@1: 68.7500 (70.1653)  Acc@5: 100.0000 (92.8260)  time: 0.3925  data: 0.0017  max mem: 2904
Train: Epoch[5/5]  [1930/4579]  eta: 0:17:18  Lr: 0.030000  Loss: -1.5285  Acc@1: 62.5000 (70.1579)  Acc@5: 93.7500 (92.8405)  time: 0.3906  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [1940/4579]  eta: 0:17:14  Lr: 0.030000  Loss: -2.0744  Acc@1: 68.7500 (70.1604)  Acc@5: 100.0000 (92.8613)  time: 0.3921  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [1950/4579]  eta: 0:17:10  Lr: 0.030000  Loss: -1.5320  Acc@1: 68.7500 (70.1820)  Acc@5: 100.0000 (92.8819)  time: 0.3931  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [1960/4579]  eta: 0:17:07  Lr: 0.030000  Loss: -1.7594  Acc@1: 75.0000 (70.1970)  Acc@5: 100.0000 (92.8958)  time: 0.3933  data: 0.0025  max mem: 2904
Train: Epoch[5/5]  [1970/4579]  eta: 0:17:03  Lr: 0.030000  Loss: -2.0213  Acc@1: 75.0000 (70.2055)  Acc@5: 100.0000 (92.8907)  time: 0.3920  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [1980/4579]  eta: 0:16:59  Lr: 0.030000  Loss: -1.8041  Acc@1: 75.0000 (70.2328)  Acc@5: 93.7500 (92.8950)  time: 0.3906  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [1990/4579]  eta: 0:16:55  Lr: 0.030000  Loss: -1.0407  Acc@1: 75.0000 (70.2379)  Acc@5: 93.7500 (92.9087)  time: 0.3900  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2000/4579]  eta: 0:16:51  Lr: 0.030000  Loss: -1.7660  Acc@1: 68.7500 (70.2368)  Acc@5: 93.7500 (92.9004)  time: 0.3908  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2010/4579]  eta: 0:16:47  Lr: 0.030000  Loss: -2.0659  Acc@1: 68.7500 (70.2387)  Acc@5: 93.7500 (92.9046)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2020/4579]  eta: 0:16:43  Lr: 0.030000  Loss: -1.9239  Acc@1: 75.0000 (70.2684)  Acc@5: 93.7500 (92.9212)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2030/4579]  eta: 0:16:39  Lr: 0.030000  Loss: -2.0872  Acc@1: 75.0000 (70.2763)  Acc@5: 93.7500 (92.9284)  time: 0.3921  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2040/4579]  eta: 0:16:35  Lr: 0.030000  Loss: -1.2662  Acc@1: 68.7500 (70.2658)  Acc@5: 93.7500 (92.9171)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2050/4579]  eta: 0:16:31  Lr: 0.030000  Loss: -1.4939  Acc@1: 68.7500 (70.2676)  Acc@5: 87.5000 (92.8998)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2060/4579]  eta: 0:16:27  Lr: 0.030000  Loss: -1.3301  Acc@1: 75.0000 (70.2602)  Acc@5: 93.7500 (92.9039)  time: 0.3920  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2070/4579]  eta: 0:16:23  Lr: 0.030000  Loss: -1.5623  Acc@1: 68.7500 (70.2620)  Acc@5: 93.7500 (92.9050)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2080/4579]  eta: 0:16:19  Lr: 0.030000  Loss: -1.6413  Acc@1: 68.7500 (70.2547)  Acc@5: 93.7500 (92.8820)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2090/4579]  eta: 0:16:16  Lr: 0.030000  Loss: -1.8128  Acc@1: 68.7500 (70.2594)  Acc@5: 93.7500 (92.8862)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2100/4579]  eta: 0:16:12  Lr: 0.030000  Loss: -1.5058  Acc@1: 68.7500 (70.2642)  Acc@5: 93.7500 (92.8903)  time: 0.3927  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2110/4579]  eta: 0:16:08  Lr: 0.030000  Loss: -1.5150  Acc@1: 68.7500 (70.2215)  Acc@5: 93.7500 (92.8766)  time: 0.3940  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [2120/4579]  eta: 0:16:04  Lr: 0.030000  Loss: -2.1680  Acc@1: 68.7500 (70.2440)  Acc@5: 93.7500 (92.8719)  time: 0.3935  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [2130/4579]  eta: 0:16:00  Lr: 0.030000  Loss: -1.3517  Acc@1: 68.7500 (70.2487)  Acc@5: 93.7500 (92.8848)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2140/4579]  eta: 0:15:56  Lr: 0.030000  Loss: -1.0583  Acc@1: 68.7500 (70.2446)  Acc@5: 93.7500 (92.8918)  time: 0.3928  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [2150/4579]  eta: 0:15:52  Lr: 0.030000  Loss: -1.0830  Acc@1: 68.7500 (70.2609)  Acc@5: 93.7500 (92.8870)  time: 0.3933  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [2160/4579]  eta: 0:15:48  Lr: 0.030000  Loss: -1.3682  Acc@1: 75.0000 (70.2713)  Acc@5: 100.0000 (92.9026)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2170/4579]  eta: 0:15:44  Lr: 0.030000  Loss: -1.2114  Acc@1: 75.0000 (70.2844)  Acc@5: 100.0000 (92.9094)  time: 0.3944  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2180/4579]  eta: 0:15:40  Lr: 0.030000  Loss: -1.5459  Acc@1: 75.0000 (70.2946)  Acc@5: 93.7500 (92.9075)  time: 0.3947  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2190/4579]  eta: 0:15:36  Lr: 0.030000  Loss: -1.8541  Acc@1: 68.7500 (70.3075)  Acc@5: 93.7500 (92.9199)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2200/4579]  eta: 0:15:33  Lr: 0.030000  Loss: -1.7836  Acc@1: 68.7500 (70.2834)  Acc@5: 93.7500 (92.9208)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2210/4579]  eta: 0:15:29  Lr: 0.030000  Loss: -1.9293  Acc@1: 68.7500 (70.2849)  Acc@5: 93.7500 (92.9246)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2220/4579]  eta: 0:15:25  Lr: 0.030000  Loss: -0.9827  Acc@1: 68.7500 (70.2555)  Acc@5: 87.5000 (92.9030)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2230/4579]  eta: 0:15:21  Lr: 0.030000  Loss: -2.0912  Acc@1: 68.7500 (70.2544)  Acc@5: 93.7500 (92.9040)  time: 0.3935  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2240/4579]  eta: 0:15:17  Lr: 0.030000  Loss: -1.6487  Acc@1: 68.7500 (70.2700)  Acc@5: 93.7500 (92.9050)  time: 0.3943  data: 0.0019  max mem: 2904
Train: Epoch[5/5]  [2250/4579]  eta: 0:15:13  Lr: 0.030000  Loss: -1.8054  Acc@1: 75.0000 (70.2743)  Acc@5: 93.7500 (92.9032)  time: 0.3947  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [2260/4579]  eta: 0:15:09  Lr: 0.030000  Loss: -1.0340  Acc@1: 75.0000 (70.2731)  Acc@5: 93.7500 (92.8986)  time: 0.3933  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2270/4579]  eta: 0:15:05  Lr: 0.030000  Loss: -1.0224  Acc@1: 75.0000 (70.2829)  Acc@5: 87.5000 (92.8831)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2280/4579]  eta: 0:15:01  Lr: 0.030000  Loss: -1.8464  Acc@1: 75.0000 (70.3200)  Acc@5: 93.7500 (92.8924)  time: 0.3920  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2290/4579]  eta: 0:14:57  Lr: 0.030000  Loss: -1.2008  Acc@1: 68.7500 (70.3023)  Acc@5: 93.7500 (92.8852)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2300/4579]  eta: 0:14:53  Lr: 0.030000  Loss: -1.6434  Acc@1: 62.5000 (70.2982)  Acc@5: 93.7500 (92.8672)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2310/4579]  eta: 0:14:49  Lr: 0.030000  Loss: -1.5870  Acc@1: 62.5000 (70.2861)  Acc@5: 93.7500 (92.8738)  time: 0.3922  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2320/4579]  eta: 0:14:46  Lr: 0.030000  Loss: -1.6376  Acc@1: 68.7500 (70.2822)  Acc@5: 93.7500 (92.8641)  time: 0.3924  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [2330/4579]  eta: 0:14:42  Lr: 0.030000  Loss: -1.3723  Acc@1: 68.7500 (70.2810)  Acc@5: 93.7500 (92.8705)  time: 0.3920  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [2340/4579]  eta: 0:14:38  Lr: 0.030000  Loss: -1.5636  Acc@1: 68.7500 (70.2745)  Acc@5: 93.7500 (92.8690)  time: 0.3932  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2350/4579]  eta: 0:14:34  Lr: 0.030000  Loss: -1.7619  Acc@1: 68.7500 (70.2653)  Acc@5: 93.7500 (92.8727)  time: 0.3937  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [2360/4579]  eta: 0:14:30  Lr: 0.030000  Loss: -1.8350  Acc@1: 68.7500 (70.2748)  Acc@5: 93.7500 (92.8553)  time: 0.3922  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2370/4579]  eta: 0:14:26  Lr: 0.030000  Loss: -1.7311  Acc@1: 75.0000 (70.2789)  Acc@5: 93.7500 (92.8564)  time: 0.3928  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [2380/4579]  eta: 0:14:22  Lr: 0.030000  Loss: -1.9976  Acc@1: 75.0000 (70.2882)  Acc@5: 93.7500 (92.8549)  time: 0.3951  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [2390/4579]  eta: 0:14:18  Lr: 0.030000  Loss: -1.1074  Acc@1: 75.0000 (70.2609)  Acc@5: 93.7500 (92.8508)  time: 0.3932  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2400/4579]  eta: 0:14:14  Lr: 0.030000  Loss: -1.4437  Acc@1: 68.7500 (70.2598)  Acc@5: 93.7500 (92.8493)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2410/4579]  eta: 0:14:10  Lr: 0.030000  Loss: -2.3088  Acc@1: 68.7500 (70.2561)  Acc@5: 93.7500 (92.8583)  time: 0.3936  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2420/4579]  eta: 0:14:06  Lr: 0.030000  Loss: -1.7960  Acc@1: 75.0000 (70.2886)  Acc@5: 93.7500 (92.8723)  time: 0.3939  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [2430/4579]  eta: 0:14:02  Lr: 0.030000  Loss: -1.3279  Acc@1: 75.0000 (70.2669)  Acc@5: 93.7500 (92.8656)  time: 0.3928  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2440/4579]  eta: 0:13:59  Lr: 0.030000  Loss: -1.7621  Acc@1: 75.0000 (70.2786)  Acc@5: 93.7500 (92.8718)  time: 0.3917  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [2450/4579]  eta: 0:13:55  Lr: 0.030000  Loss: -1.9316  Acc@1: 75.0000 (70.2927)  Acc@5: 93.7500 (92.8728)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2460/4579]  eta: 0:13:51  Lr: 0.030000  Loss: -1.5884  Acc@1: 68.7500 (70.2814)  Acc@5: 93.7500 (92.8637)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2470/4579]  eta: 0:13:47  Lr: 0.030000  Loss: -1.9587  Acc@1: 75.0000 (70.3157)  Acc@5: 93.7500 (92.8723)  time: 0.3913  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [2480/4579]  eta: 0:13:43  Lr: 0.030000  Loss: -1.8550  Acc@1: 75.0000 (70.3144)  Acc@5: 93.7500 (92.8733)  time: 0.3918  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [2490/4579]  eta: 0:13:39  Lr: 0.030000  Loss: -1.3108  Acc@1: 75.0000 (70.3207)  Acc@5: 93.7500 (92.8844)  time: 0.3916  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2500/4579]  eta: 0:13:35  Lr: 0.030000  Loss: -1.5764  Acc@1: 75.0000 (70.3169)  Acc@5: 93.7500 (92.8853)  time: 0.3923  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2510/4579]  eta: 0:13:31  Lr: 0.030000  Loss: -1.7782  Acc@1: 68.7500 (70.3131)  Acc@5: 93.7500 (92.8913)  time: 0.3933  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [2520/4579]  eta: 0:13:27  Lr: 0.030000  Loss: -1.3888  Acc@1: 68.7500 (70.3069)  Acc@5: 93.7500 (92.8972)  time: 0.3926  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [2530/4579]  eta: 0:13:23  Lr: 0.030000  Loss: -0.7802  Acc@1: 68.7500 (70.3156)  Acc@5: 93.7500 (92.9030)  time: 0.3932  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2540/4579]  eta: 0:13:19  Lr: 0.030000  Loss: -1.6307  Acc@1: 75.0000 (70.3340)  Acc@5: 93.7500 (92.9186)  time: 0.3937  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [2550/4579]  eta: 0:13:15  Lr: 0.030000  Loss: -1.5924  Acc@1: 68.7500 (70.3278)  Acc@5: 93.7500 (92.9317)  time: 0.3930  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [2560/4579]  eta: 0:13:11  Lr: 0.030000  Loss: -1.7071  Acc@1: 68.7500 (70.3070)  Acc@5: 93.7500 (92.9349)  time: 0.3925  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2570/4579]  eta: 0:13:08  Lr: 0.030000  Loss: -1.7600  Acc@1: 68.7500 (70.3034)  Acc@5: 93.7500 (92.9283)  time: 0.3921  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [2580/4579]  eta: 0:13:04  Lr: 0.030000  Loss: -1.4497  Acc@1: 68.7500 (70.2707)  Acc@5: 87.5000 (92.9170)  time: 0.3918  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [2590/4579]  eta: 0:13:00  Lr: 0.030000  Loss: -1.9362  Acc@1: 68.7500 (70.2576)  Acc@5: 87.5000 (92.9057)  time: 0.3924  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [2600/4579]  eta: 0:12:56  Lr: 0.030000  Loss: -2.2791  Acc@1: 75.0000 (70.2614)  Acc@5: 93.7500 (92.9210)  time: 0.3923  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2610/4579]  eta: 0:12:52  Lr: 0.030000  Loss: -1.6912  Acc@1: 75.0000 (70.2820)  Acc@5: 93.7500 (92.9218)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2620/4579]  eta: 0:12:48  Lr: 0.030000  Loss: -2.2219  Acc@1: 75.0000 (70.2738)  Acc@5: 93.7500 (92.9202)  time: 0.3924  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [2630/4579]  eta: 0:12:44  Lr: 0.030000  Loss: -1.7170  Acc@1: 68.7500 (70.2656)  Acc@5: 93.7500 (92.9186)  time: 0.3937  data: 0.0015  max mem: 2904
Train: Epoch[5/5]  [2640/4579]  eta: 0:12:40  Lr: 0.030000  Loss: -1.4387  Acc@1: 68.7500 (70.2504)  Acc@5: 93.7500 (92.9264)  time: 0.3928  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [2650/4579]  eta: 0:12:36  Lr: 0.030000  Loss: -1.6002  Acc@1: 62.5000 (70.2259)  Acc@5: 93.7500 (92.9083)  time: 0.3923  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2660/4579]  eta: 0:12:32  Lr: 0.030000  Loss: -1.4416  Acc@1: 62.5000 (70.2156)  Acc@5: 93.7500 (92.9209)  time: 0.3912  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2670/4579]  eta: 0:12:28  Lr: 0.030000  Loss: -2.1626  Acc@1: 68.7500 (70.2125)  Acc@5: 93.7500 (92.9100)  time: 0.3909  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [2680/4579]  eta: 0:12:24  Lr: 0.030000  Loss: -1.0116  Acc@1: 75.0000 (70.2023)  Acc@5: 93.7500 (92.8944)  time: 0.3914  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [2690/4579]  eta: 0:12:20  Lr: 0.030000  Loss: -1.8327  Acc@1: 75.0000 (70.2155)  Acc@5: 93.7500 (92.9023)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2700/4579]  eta: 0:12:17  Lr: 0.030000  Loss: -1.0627  Acc@1: 68.7500 (70.2170)  Acc@5: 93.7500 (92.9031)  time: 0.3932  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2710/4579]  eta: 0:12:13  Lr: 0.030000  Loss: -1.5517  Acc@1: 75.0000 (70.2462)  Acc@5: 93.7500 (92.8970)  time: 0.3931  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [2720/4579]  eta: 0:12:09  Lr: 0.030000  Loss: -1.6096  Acc@1: 75.0000 (70.2384)  Acc@5: 93.7500 (92.9116)  time: 0.3929  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [2730/4579]  eta: 0:12:05  Lr: 0.030000  Loss: -1.6586  Acc@1: 68.7500 (70.2421)  Acc@5: 93.7500 (92.9215)  time: 0.3929  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2740/4579]  eta: 0:12:01  Lr: 0.030000  Loss: -1.7903  Acc@1: 75.0000 (70.2549)  Acc@5: 93.7500 (92.9177)  time: 0.3923  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2750/4579]  eta: 0:11:57  Lr: 0.030000  Loss: -1.9369  Acc@1: 75.0000 (70.2585)  Acc@5: 93.7500 (92.9230)  time: 0.3919  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2760/4579]  eta: 0:11:53  Lr: 0.030000  Loss: -1.9186  Acc@1: 75.0000 (70.2848)  Acc@5: 93.7500 (92.9351)  time: 0.3930  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [2770/4579]  eta: 0:11:49  Lr: 0.030000  Loss: -1.9122  Acc@1: 75.0000 (70.2792)  Acc@5: 93.7500 (92.9403)  time: 0.3936  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [2780/4579]  eta: 0:11:45  Lr: 0.030000  Loss: -1.5501  Acc@1: 75.0000 (70.2985)  Acc@5: 93.7500 (92.9522)  time: 0.3954  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [2790/4579]  eta: 0:11:41  Lr: 0.030000  Loss: -1.7099  Acc@1: 75.0000 (70.3086)  Acc@5: 93.7500 (92.9483)  time: 0.3965  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2800/4579]  eta: 0:11:37  Lr: 0.030000  Loss: -2.1248  Acc@1: 68.7500 (70.2941)  Acc@5: 93.7500 (92.9512)  time: 0.3958  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [2810/4579]  eta: 0:11:33  Lr: 0.030000  Loss: -2.1872  Acc@1: 75.0000 (70.3197)  Acc@5: 93.7500 (92.9607)  time: 0.3937  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2820/4579]  eta: 0:11:30  Lr: 0.030000  Loss: -1.5141  Acc@1: 75.0000 (70.2964)  Acc@5: 93.7500 (92.9635)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2830/4579]  eta: 0:11:26  Lr: 0.030000  Loss: -1.2473  Acc@1: 62.5000 (70.2755)  Acc@5: 87.5000 (92.9442)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2840/4579]  eta: 0:11:22  Lr: 0.030000  Loss: -1.9457  Acc@1: 68.7500 (70.2790)  Acc@5: 87.5000 (92.9404)  time: 0.3947  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2850/4579]  eta: 0:11:18  Lr: 0.030000  Loss: -1.6228  Acc@1: 75.0000 (70.2736)  Acc@5: 93.7500 (92.9389)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2860/4579]  eta: 0:11:14  Lr: 0.030000  Loss: -1.6256  Acc@1: 68.7500 (70.2704)  Acc@5: 93.7500 (92.9461)  time: 0.3943  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [2870/4579]  eta: 0:11:10  Lr: 0.030000  Loss: -1.8664  Acc@1: 68.7500 (70.2477)  Acc@5: 93.7500 (92.9424)  time: 0.3938  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2880/4579]  eta: 0:11:06  Lr: 0.030000  Loss: -2.0218  Acc@1: 68.7500 (70.2599)  Acc@5: 93.7500 (92.9430)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2890/4579]  eta: 0:11:02  Lr: 0.030000  Loss: -1.3497  Acc@1: 68.7500 (70.2525)  Acc@5: 93.7500 (92.9328)  time: 0.3920  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2900/4579]  eta: 0:10:58  Lr: 0.030000  Loss: -1.7468  Acc@1: 75.0000 (70.2603)  Acc@5: 87.5000 (92.9270)  time: 0.3926  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [2910/4579]  eta: 0:10:54  Lr: 0.030000  Loss: -1.4750  Acc@1: 75.0000 (70.2637)  Acc@5: 93.7500 (92.9341)  time: 0.3927  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2920/4579]  eta: 0:10:50  Lr: 0.030000  Loss: -1.7907  Acc@1: 68.7500 (70.2606)  Acc@5: 93.7500 (92.9348)  time: 0.3927  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [2930/4579]  eta: 0:10:46  Lr: 0.030000  Loss: -1.6467  Acc@1: 75.0000 (70.2747)  Acc@5: 93.7500 (92.9376)  time: 0.3925  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [2940/4579]  eta: 0:10:43  Lr: 0.030000  Loss: -1.9619  Acc@1: 75.0000 (70.2695)  Acc@5: 93.7500 (92.9340)  time: 0.3917  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2950/4579]  eta: 0:10:39  Lr: 0.030000  Loss: -1.1089  Acc@1: 62.5000 (70.2474)  Acc@5: 87.5000 (92.9240)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2960/4579]  eta: 0:10:35  Lr: 0.030000  Loss: -0.7166  Acc@1: 68.7500 (70.2381)  Acc@5: 93.7500 (92.9247)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2970/4579]  eta: 0:10:31  Lr: 0.030000  Loss: -1.7765  Acc@1: 68.7500 (70.2226)  Acc@5: 93.7500 (92.9127)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [2980/4579]  eta: 0:10:27  Lr: 0.030000  Loss: -1.2038  Acc@1: 68.7500 (70.2176)  Acc@5: 87.5000 (92.8967)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [2990/4579]  eta: 0:10:23  Lr: 0.030000  Loss: -1.5985  Acc@1: 68.7500 (70.2106)  Acc@5: 93.7500 (92.8933)  time: 0.3923  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [3000/4579]  eta: 0:10:19  Lr: 0.030000  Loss: -1.5118  Acc@1: 68.7500 (70.2183)  Acc@5: 93.7500 (92.9044)  time: 0.3917  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [3010/4579]  eta: 0:10:15  Lr: 0.030000  Loss: -1.9952  Acc@1: 68.7500 (70.2155)  Acc@5: 93.7500 (92.9010)  time: 0.3911  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [3020/4579]  eta: 0:10:11  Lr: 0.030000  Loss: -1.5039  Acc@1: 68.7500 (70.2106)  Acc@5: 93.7500 (92.9018)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3030/4579]  eta: 0:10:07  Lr: 0.030000  Loss: -1.4177  Acc@1: 68.7500 (70.2223)  Acc@5: 93.7500 (92.9087)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3040/4579]  eta: 0:10:03  Lr: 0.030000  Loss: -1.9491  Acc@1: 68.7500 (70.2216)  Acc@5: 93.7500 (92.9135)  time: 0.3914  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3050/4579]  eta: 0:09:59  Lr: 0.030000  Loss: -2.0015  Acc@1: 68.7500 (70.2147)  Acc@5: 93.7500 (92.9204)  time: 0.3921  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3060/4579]  eta: 0:09:55  Lr: 0.030000  Loss: -1.6339  Acc@1: 68.7500 (70.2119)  Acc@5: 93.7500 (92.9231)  time: 0.3935  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3070/4579]  eta: 0:09:52  Lr: 0.030000  Loss: -2.0120  Acc@1: 75.0000 (70.2113)  Acc@5: 93.7500 (92.9237)  time: 0.3925  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3080/4579]  eta: 0:09:48  Lr: 0.030000  Loss: -1.8128  Acc@1: 68.7500 (70.2106)  Acc@5: 93.7500 (92.9223)  time: 0.3911  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [3090/4579]  eta: 0:09:44  Lr: 0.030000  Loss: -1.3335  Acc@1: 68.7500 (70.1876)  Acc@5: 93.7500 (92.9169)  time: 0.3919  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [3100/4579]  eta: 0:09:40  Lr: 0.030000  Loss: -1.7150  Acc@1: 62.5000 (70.1810)  Acc@5: 93.7500 (92.9095)  time: 0.3936  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3110/4579]  eta: 0:09:36  Lr: 0.030000  Loss: -1.8422  Acc@1: 68.7500 (70.1844)  Acc@5: 87.5000 (92.9062)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3120/4579]  eta: 0:09:32  Lr: 0.030000  Loss: -2.1957  Acc@1: 75.0000 (70.2099)  Acc@5: 93.7500 (92.9129)  time: 0.3944  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3130/4579]  eta: 0:09:28  Lr: 0.030000  Loss: -1.8087  Acc@1: 75.0000 (70.2172)  Acc@5: 93.7500 (92.9216)  time: 0.3949  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [3140/4579]  eta: 0:09:24  Lr: 0.030000  Loss: -1.9488  Acc@1: 75.0000 (70.2165)  Acc@5: 93.7500 (92.9222)  time: 0.3946  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [3150/4579]  eta: 0:09:20  Lr: 0.030000  Loss: -2.2234  Acc@1: 75.0000 (70.2317)  Acc@5: 93.7500 (92.9268)  time: 0.3941  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3160/4579]  eta: 0:09:16  Lr: 0.030000  Loss: -1.4123  Acc@1: 75.0000 (70.2131)  Acc@5: 93.7500 (92.9156)  time: 0.3945  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3170/4579]  eta: 0:09:12  Lr: 0.030000  Loss: -1.6121  Acc@1: 68.7500 (70.2105)  Acc@5: 87.5000 (92.9044)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3180/4579]  eta: 0:09:08  Lr: 0.030000  Loss: -1.9199  Acc@1: 68.7500 (70.1941)  Acc@5: 87.5000 (92.8875)  time: 0.3899  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3190/4579]  eta: 0:09:04  Lr: 0.030000  Loss: -0.7667  Acc@1: 68.7500 (70.1759)  Acc@5: 93.7500 (92.8804)  time: 0.3894  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3200/4579]  eta: 0:09:01  Lr: 0.030000  Loss: -1.4994  Acc@1: 62.5000 (70.1617)  Acc@5: 93.7500 (92.8792)  time: 0.3910  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3210/4579]  eta: 0:08:57  Lr: 0.030000  Loss: -2.3325  Acc@1: 68.7500 (70.1690)  Acc@5: 93.7500 (92.8858)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3220/4579]  eta: 0:08:53  Lr: 0.030000  Loss: -1.5677  Acc@1: 68.7500 (70.1568)  Acc@5: 93.7500 (92.8943)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3230/4579]  eta: 0:08:49  Lr: 0.030000  Loss: -0.9560  Acc@1: 68.7500 (70.1524)  Acc@5: 93.7500 (92.8950)  time: 0.3912  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3240/4579]  eta: 0:08:45  Lr: 0.030000  Loss: -2.0409  Acc@1: 62.5000 (70.1365)  Acc@5: 93.7500 (92.8861)  time: 0.3911  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3250/4579]  eta: 0:08:41  Lr: 0.030000  Loss: -1.7180  Acc@1: 68.7500 (70.1419)  Acc@5: 93.7500 (92.8810)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3260/4579]  eta: 0:08:37  Lr: 0.030000  Loss: -1.5092  Acc@1: 62.5000 (70.1223)  Acc@5: 93.7500 (92.8856)  time: 0.3900  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3270/4579]  eta: 0:08:33  Lr: 0.030000  Loss: -1.4470  Acc@1: 62.5000 (70.1047)  Acc@5: 93.7500 (92.8825)  time: 0.3901  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3280/4579]  eta: 0:08:29  Lr: 0.030000  Loss: -1.6074  Acc@1: 68.7500 (70.1025)  Acc@5: 93.7500 (92.8890)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3290/4579]  eta: 0:08:25  Lr: 0.030000  Loss: -1.3664  Acc@1: 68.7500 (70.0984)  Acc@5: 93.7500 (92.8935)  time: 0.3909  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3300/4579]  eta: 0:08:21  Lr: 0.030000  Loss: -1.6997  Acc@1: 62.5000 (70.0697)  Acc@5: 93.7500 (92.8847)  time: 0.3906  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [3310/4579]  eta: 0:08:17  Lr: 0.030000  Loss: -2.0839  Acc@1: 62.5000 (70.0600)  Acc@5: 93.7500 (92.8855)  time: 0.3913  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [3320/4579]  eta: 0:08:13  Lr: 0.030000  Loss: -1.7134  Acc@1: 62.5000 (70.0373)  Acc@5: 93.7500 (92.8805)  time: 0.3895  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3330/4579]  eta: 0:08:09  Lr: 0.030000  Loss: -1.6316  Acc@1: 68.7500 (70.0296)  Acc@5: 93.7500 (92.8850)  time: 0.3896  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3340/4579]  eta: 0:08:06  Lr: 0.030000  Loss: -1.3643  Acc@1: 62.5000 (70.0071)  Acc@5: 93.7500 (92.8670)  time: 0.3902  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3350/4579]  eta: 0:08:02  Lr: 0.030000  Loss: -1.3981  Acc@1: 62.5000 (69.9884)  Acc@5: 87.5000 (92.8641)  time: 0.3907  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [3360/4579]  eta: 0:07:58  Lr: 0.030000  Loss: -2.2046  Acc@1: 68.7500 (69.9866)  Acc@5: 93.7500 (92.8537)  time: 0.3921  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [3370/4579]  eta: 0:07:54  Lr: 0.030000  Loss: -1.7619  Acc@1: 68.7500 (69.9755)  Acc@5: 93.7500 (92.8563)  time: 0.3943  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3380/4579]  eta: 0:07:50  Lr: 0.030000  Loss: -1.7949  Acc@1: 68.7500 (69.9774)  Acc@5: 93.7500 (92.8627)  time: 0.3947  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3390/4579]  eta: 0:07:46  Lr: 0.030000  Loss: -1.6042  Acc@1: 62.5000 (69.9628)  Acc@5: 93.7500 (92.8524)  time: 0.3931  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [3400/4579]  eta: 0:07:42  Lr: 0.030000  Loss: -1.7079  Acc@1: 68.7500 (69.9684)  Acc@5: 93.7500 (92.8532)  time: 0.3922  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [3410/4579]  eta: 0:07:38  Lr: 0.030000  Loss: -1.6414  Acc@1: 68.7500 (69.9740)  Acc@5: 93.7500 (92.8595)  time: 0.3922  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [3420/4579]  eta: 0:07:34  Lr: 0.030000  Loss: -2.0118  Acc@1: 68.7500 (69.9868)  Acc@5: 93.7500 (92.8621)  time: 0.3928  data: 0.0019  max mem: 2904
Train: Epoch[5/5]  [3430/4579]  eta: 0:07:30  Lr: 0.030000  Loss: -1.5387  Acc@1: 68.7500 (69.9814)  Acc@5: 93.7500 (92.8519)  time: 0.3930  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [3440/4579]  eta: 0:07:26  Lr: 0.030000  Loss: -1.6463  Acc@1: 68.7500 (69.9742)  Acc@5: 93.7500 (92.8509)  time: 0.3933  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [3450/4579]  eta: 0:07:22  Lr: 0.030000  Loss: -1.8702  Acc@1: 75.0000 (69.9707)  Acc@5: 93.7500 (92.8499)  time: 0.3950  data: 0.0019  max mem: 2904
Train: Epoch[5/5]  [3460/4579]  eta: 0:07:18  Lr: 0.030000  Loss: -1.3487  Acc@1: 68.7500 (69.9689)  Acc@5: 93.7500 (92.8561)  time: 0.3948  data: 0.0025  max mem: 2904
Train: Epoch[5/5]  [3470/4579]  eta: 0:07:15  Lr: 0.030000  Loss: -1.6309  Acc@1: 62.5000 (69.9474)  Acc@5: 93.7500 (92.8515)  time: 0.3923  data: 0.0017  max mem: 2904
Train: Epoch[5/5]  [3480/4579]  eta: 0:07:11  Lr: 0.030000  Loss: -1.8281  Acc@1: 68.7500 (69.9494)  Acc@5: 87.5000 (92.8343)  time: 0.3928  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [3490/4579]  eta: 0:07:07  Lr: 0.030000  Loss: -0.9989  Acc@1: 75.0000 (69.9513)  Acc@5: 93.7500 (92.8316)  time: 0.3941  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [3500/4579]  eta: 0:07:03  Lr: 0.030000  Loss: -1.7906  Acc@1: 62.5000 (69.9282)  Acc@5: 93.7500 (92.8217)  time: 0.3928  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [3510/4579]  eta: 0:06:59  Lr: 0.030000  Loss: -1.2489  Acc@1: 75.0000 (69.9534)  Acc@5: 93.7500 (92.8208)  time: 0.3937  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3520/4579]  eta: 0:06:55  Lr: 0.030000  Loss: -1.2368  Acc@1: 75.0000 (69.9659)  Acc@5: 93.7500 (92.8234)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3530/4579]  eta: 0:06:51  Lr: 0.030000  Loss: -1.7331  Acc@1: 75.0000 (69.9713)  Acc@5: 93.7500 (92.8190)  time: 0.3914  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3540/4579]  eta: 0:06:47  Lr: 0.030000  Loss: -1.5321  Acc@1: 68.7500 (69.9661)  Acc@5: 93.7500 (92.8216)  time: 0.3923  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3550/4579]  eta: 0:06:43  Lr: 0.030000  Loss: -1.7281  Acc@1: 68.7500 (69.9715)  Acc@5: 93.7500 (92.8154)  time: 0.3918  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3560/4579]  eta: 0:06:39  Lr: 0.030000  Loss: -2.2555  Acc@1: 68.7500 (69.9505)  Acc@5: 93.7500 (92.8093)  time: 0.3902  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3570/4579]  eta: 0:06:35  Lr: 0.030000  Loss: -0.4264  Acc@1: 68.7500 (69.9524)  Acc@5: 93.7500 (92.8066)  time: 0.3901  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3580/4579]  eta: 0:06:31  Lr: 0.030000  Loss: -1.6871  Acc@1: 75.0000 (69.9543)  Acc@5: 93.7500 (92.8093)  time: 0.3908  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3590/4579]  eta: 0:06:27  Lr: 0.030000  Loss: -1.4775  Acc@1: 75.0000 (69.9596)  Acc@5: 93.7500 (92.8154)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3600/4579]  eta: 0:06:24  Lr: 0.030000  Loss: -1.6103  Acc@1: 75.0000 (69.9667)  Acc@5: 93.7500 (92.8128)  time: 0.3913  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3610/4579]  eta: 0:06:20  Lr: 0.030000  Loss: -1.8487  Acc@1: 68.7500 (69.9564)  Acc@5: 93.7500 (92.8136)  time: 0.3911  data: 0.0002  max mem: 2904
Train: Epoch[5/5]  [3620/4579]  eta: 0:06:16  Lr: 0.030000  Loss: -2.1925  Acc@1: 68.7500 (69.9617)  Acc@5: 93.7500 (92.8179)  time: 0.3920  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [3630/4579]  eta: 0:06:12  Lr: 0.030000  Loss: -1.5762  Acc@1: 68.7500 (69.9532)  Acc@5: 87.5000 (92.8136)  time: 0.3913  data: 0.0013  max mem: 2904
Train: Epoch[5/5]  [3640/4579]  eta: 0:06:08  Lr: 0.030000  Loss: -1.2199  Acc@1: 68.7500 (69.9482)  Acc@5: 93.7500 (92.8196)  time: 0.3899  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [3650/4579]  eta: 0:06:04  Lr: 0.030000  Loss: -1.5908  Acc@1: 68.7500 (69.9534)  Acc@5: 93.7500 (92.8222)  time: 0.3903  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3660/4579]  eta: 0:06:00  Lr: 0.030000  Loss: -1.8601  Acc@1: 68.7500 (69.9587)  Acc@5: 93.7500 (92.8264)  time: 0.3924  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3670/4579]  eta: 0:05:56  Lr: 0.030000  Loss: -1.6264  Acc@1: 68.7500 (69.9537)  Acc@5: 93.7500 (92.8221)  time: 0.3956  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3680/4579]  eta: 0:05:52  Lr: 0.030000  Loss: -1.3715  Acc@1: 62.5000 (69.9385)  Acc@5: 93.7500 (92.8263)  time: 0.3967  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3690/4579]  eta: 0:05:48  Lr: 0.030000  Loss: -1.8460  Acc@1: 68.7500 (69.9421)  Acc@5: 93.7500 (92.8322)  time: 0.3971  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [3700/4579]  eta: 0:05:44  Lr: 0.030000  Loss: -1.2395  Acc@1: 68.7500 (69.9355)  Acc@5: 93.7500 (92.8296)  time: 0.3954  data: 0.0020  max mem: 2904
Train: Epoch[5/5]  [3710/4579]  eta: 0:05:40  Lr: 0.030000  Loss: -1.6841  Acc@1: 62.5000 (69.9222)  Acc@5: 93.7500 (92.8254)  time: 0.3928  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [3720/4579]  eta: 0:05:36  Lr: 0.030000  Loss: -2.1087  Acc@1: 75.0000 (69.9392)  Acc@5: 93.7500 (92.8262)  time: 0.3915  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3730/4579]  eta: 0:05:33  Lr: 0.030000  Loss: -2.0162  Acc@1: 75.0000 (69.9276)  Acc@5: 93.7500 (92.8270)  time: 0.3913  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3740/4579]  eta: 0:05:29  Lr: 0.030000  Loss: -1.9943  Acc@1: 75.0000 (69.9412)  Acc@5: 93.7500 (92.8328)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3750/4579]  eta: 0:05:25  Lr: 0.030000  Loss: -1.7649  Acc@1: 68.7500 (69.9413)  Acc@5: 93.7500 (92.8186)  time: 0.3905  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3760/4579]  eta: 0:05:21  Lr: 0.030000  Loss: -1.3829  Acc@1: 68.7500 (69.9382)  Acc@5: 93.7500 (92.8260)  time: 0.3902  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [3770/4579]  eta: 0:05:17  Lr: 0.030000  Loss: -1.4128  Acc@1: 68.7500 (69.9367)  Acc@5: 93.7500 (92.8202)  time: 0.3903  data: 0.0009  max mem: 2904
Train: Epoch[5/5]  [3780/4579]  eta: 0:05:13  Lr: 0.030000  Loss: -1.4706  Acc@1: 68.7500 (69.9435)  Acc@5: 93.7500 (92.8260)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3790/4579]  eta: 0:05:09  Lr: 0.030000  Loss: -2.1821  Acc@1: 75.0000 (69.9552)  Acc@5: 93.7500 (92.8334)  time: 0.3907  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3800/4579]  eta: 0:05:05  Lr: 0.030000  Loss: -1.4955  Acc@1: 68.7500 (69.9602)  Acc@5: 93.7500 (92.8374)  time: 0.3898  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3810/4579]  eta: 0:05:01  Lr: 0.030000  Loss: -1.6590  Acc@1: 75.0000 (69.9603)  Acc@5: 93.7500 (92.8316)  time: 0.3901  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [3820/4579]  eta: 0:04:57  Lr: 0.030000  Loss: -1.5536  Acc@1: 68.7500 (69.9539)  Acc@5: 93.7500 (92.8291)  time: 0.3922  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [3830/4579]  eta: 0:04:53  Lr: 0.030000  Loss: -1.9845  Acc@1: 68.7500 (69.9622)  Acc@5: 93.7500 (92.8397)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3840/4579]  eta: 0:04:49  Lr: 0.030000  Loss: -1.6277  Acc@1: 75.0000 (69.9801)  Acc@5: 93.7500 (92.8453)  time: 0.3926  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [3850/4579]  eta: 0:04:45  Lr: 0.030000  Loss: -1.5005  Acc@1: 75.0000 (69.9867)  Acc@5: 93.7500 (92.8541)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3860/4579]  eta: 0:04:42  Lr: 0.030000  Loss: -1.4578  Acc@1: 68.7500 (69.9900)  Acc@5: 93.7500 (92.8597)  time: 0.3936  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [3870/4579]  eta: 0:04:38  Lr: 0.030000  Loss: -1.8713  Acc@1: 68.7500 (69.9932)  Acc@5: 93.7500 (92.8652)  time: 0.3937  data: 0.0016  max mem: 2904
Train: Epoch[5/5]  [3880/4579]  eta: 0:04:34  Lr: 0.030000  Loss: -1.8774  Acc@1: 68.7500 (69.9965)  Acc@5: 93.7500 (92.8643)  time: 0.3920  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [3890/4579]  eta: 0:04:30  Lr: 0.030000  Loss: -1.7151  Acc@1: 68.7500 (70.0093)  Acc@5: 93.7500 (92.8682)  time: 0.3912  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [3900/4579]  eta: 0:04:26  Lr: 0.030000  Loss: -2.1078  Acc@1: 68.7500 (69.9997)  Acc@5: 93.7500 (92.8736)  time: 0.3922  data: 0.0017  max mem: 2904
Train: Epoch[5/5]  [3910/4579]  eta: 0:04:22  Lr: 0.030000  Loss: -1.6200  Acc@1: 62.5000 (69.9853)  Acc@5: 93.7500 (92.8743)  time: 0.3927  data: 0.0022  max mem: 2904
Train: Epoch[5/5]  [3920/4579]  eta: 0:04:18  Lr: 0.030000  Loss: -1.9683  Acc@1: 68.7500 (69.9917)  Acc@5: 93.7500 (92.8733)  time: 0.3920  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [3930/4579]  eta: 0:04:14  Lr: 0.030000  Loss: -1.6173  Acc@1: 75.0000 (70.0108)  Acc@5: 93.7500 (92.8803)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3940/4579]  eta: 0:04:10  Lr: 0.030000  Loss: -2.0352  Acc@1: 75.0000 (70.0155)  Acc@5: 93.7500 (92.8825)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3950/4579]  eta: 0:04:06  Lr: 0.030000  Loss: -2.2214  Acc@1: 75.0000 (70.0266)  Acc@5: 93.7500 (92.8926)  time: 0.3906  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [3960/4579]  eta: 0:04:02  Lr: 0.030000  Loss: -1.5646  Acc@1: 75.0000 (70.0312)  Acc@5: 93.7500 (92.8916)  time: 0.3924  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [3970/4579]  eta: 0:03:58  Lr: 0.030000  Loss: -1.5317  Acc@1: 68.7500 (70.0296)  Acc@5: 93.7500 (92.8922)  time: 0.3916  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [3980/4579]  eta: 0:03:54  Lr: 0.030000  Loss: -1.4172  Acc@1: 68.7500 (70.0295)  Acc@5: 93.7500 (92.8928)  time: 0.3905  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [3990/4579]  eta: 0:03:51  Lr: 0.030000  Loss: -1.8538  Acc@1: 68.7500 (70.0247)  Acc@5: 93.7500 (92.8965)  time: 0.3906  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4000/4579]  eta: 0:03:47  Lr: 0.030000  Loss: -1.3057  Acc@1: 62.5000 (70.0169)  Acc@5: 93.7500 (92.8940)  time: 0.3898  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4010/4579]  eta: 0:03:43  Lr: 0.030000  Loss: -1.0955  Acc@1: 62.5000 (70.0215)  Acc@5: 93.7500 (92.8930)  time: 0.3903  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4020/4579]  eta: 0:03:39  Lr: 0.030000  Loss: -1.6867  Acc@1: 68.7500 (70.0246)  Acc@5: 93.7500 (92.8889)  time: 0.3908  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4030/4579]  eta: 0:03:35  Lr: 0.030000  Loss: -1.5392  Acc@1: 68.7500 (70.0338)  Acc@5: 93.7500 (92.8879)  time: 0.3904  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4040/4579]  eta: 0:03:31  Lr: 0.030000  Loss: -2.1582  Acc@1: 75.0000 (70.0399)  Acc@5: 93.7500 (92.8916)  time: 0.3925  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [4050/4579]  eta: 0:03:27  Lr: 0.030000  Loss: -1.4635  Acc@1: 75.0000 (70.0444)  Acc@5: 93.7500 (92.8876)  time: 0.3935  data: 0.0013  max mem: 2904
Train: Epoch[5/5]  [4060/4579]  eta: 0:03:23  Lr: 0.030000  Loss: -1.6723  Acc@1: 68.7500 (70.0428)  Acc@5: 93.7500 (92.8943)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [4070/4579]  eta: 0:03:19  Lr: 0.030000  Loss: -1.7738  Acc@1: 68.7500 (70.0381)  Acc@5: 93.7500 (92.8887)  time: 0.3920  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [4080/4579]  eta: 0:03:15  Lr: 0.030000  Loss: -2.1109  Acc@1: 75.0000 (70.0533)  Acc@5: 93.7500 (92.8939)  time: 0.3927  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [4090/4579]  eta: 0:03:11  Lr: 0.030000  Loss: -1.8814  Acc@1: 75.0000 (70.0516)  Acc@5: 93.7500 (92.9006)  time: 0.3921  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [4100/4579]  eta: 0:03:07  Lr: 0.030000  Loss: -1.5548  Acc@1: 75.0000 (70.0591)  Acc@5: 93.7500 (92.9072)  time: 0.3909  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4110/4579]  eta: 0:03:03  Lr: 0.030000  Loss: -1.2231  Acc@1: 75.0000 (70.0757)  Acc@5: 93.7500 (92.9062)  time: 0.3922  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [4120/4579]  eta: 0:03:00  Lr: 0.030000  Loss: -1.7763  Acc@1: 75.0000 (70.0801)  Acc@5: 93.7500 (92.9068)  time: 0.3931  data: 0.0018  max mem: 2904
Train: Epoch[5/5]  [4130/4579]  eta: 0:02:56  Lr: 0.030000  Loss: -1.4850  Acc@1: 75.0000 (70.0920)  Acc@5: 93.7500 (92.9073)  time: 0.3919  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [4140/4579]  eta: 0:02:52  Lr: 0.030000  Loss: -2.0667  Acc@1: 75.0000 (70.0842)  Acc@5: 93.7500 (92.9108)  time: 0.3918  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [4150/4579]  eta: 0:02:48  Lr: 0.030000  Loss: -1.4082  Acc@1: 62.5000 (70.0690)  Acc@5: 93.7500 (92.9113)  time: 0.3945  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [4160/4579]  eta: 0:02:44  Lr: 0.030000  Loss: -1.7656  Acc@1: 68.7500 (70.0763)  Acc@5: 87.5000 (92.9089)  time: 0.3966  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [4170/4579]  eta: 0:02:40  Lr: 0.030000  Loss: -1.4877  Acc@1: 68.7500 (70.0806)  Acc@5: 93.7500 (92.9139)  time: 0.3951  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [4180/4579]  eta: 0:02:36  Lr: 0.030000  Loss: -1.9757  Acc@1: 75.0000 (70.0804)  Acc@5: 93.7500 (92.9069)  time: 0.3925  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [4190/4579]  eta: 0:02:32  Lr: 0.030000  Loss: -1.7569  Acc@1: 68.7500 (70.0772)  Acc@5: 93.7500 (92.9059)  time: 0.3921  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [4200/4579]  eta: 0:02:28  Lr: 0.030000  Loss: -1.7310  Acc@1: 68.7500 (70.0741)  Acc@5: 93.7500 (92.9094)  time: 0.3934  data: 0.0008  max mem: 2904
Train: Epoch[5/5]  [4210/4579]  eta: 0:02:24  Lr: 0.030000  Loss: -1.4860  Acc@1: 68.7500 (70.0695)  Acc@5: 93.7500 (92.9099)  time: 0.3927  data: 0.0007  max mem: 2904
Train: Epoch[5/5]  [4220/4579]  eta: 0:02:20  Lr: 0.030000  Loss: -1.4945  Acc@1: 68.7500 (70.0693)  Acc@5: 93.7500 (92.9119)  time: 0.3919  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4230/4579]  eta: 0:02:16  Lr: 0.030000  Loss: -1.9311  Acc@1: 68.7500 (70.0662)  Acc@5: 93.7500 (92.9183)  time: 0.3930  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [4240/4579]  eta: 0:02:12  Lr: 0.030000  Loss: -2.0993  Acc@1: 68.7500 (70.0675)  Acc@5: 93.7500 (92.9144)  time: 0.3924  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [4250/4579]  eta: 0:02:09  Lr: 0.030000  Loss: -1.0113  Acc@1: 68.7500 (70.0673)  Acc@5: 93.7500 (92.9193)  time: 0.3918  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4260/4579]  eta: 0:02:05  Lr: 0.030000  Loss: -1.7781  Acc@1: 68.7500 (70.0701)  Acc@5: 93.7500 (92.9227)  time: 0.3932  data: 0.0005  max mem: 2904
Train: Epoch[5/5]  [4270/4579]  eta: 0:02:01  Lr: 0.030000  Loss: -1.7577  Acc@1: 75.0000 (70.0729)  Acc@5: 93.7500 (92.9276)  time: 0.3926  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [4280/4579]  eta: 0:01:57  Lr: 0.030000  Loss: -1.7538  Acc@1: 68.7500 (70.0844)  Acc@5: 93.7500 (92.9281)  time: 0.3923  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [4290/4579]  eta: 0:01:53  Lr: 0.030000  Loss: -2.3052  Acc@1: 68.7500 (70.0871)  Acc@5: 93.7500 (92.9285)  time: 0.3931  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4300/4579]  eta: 0:01:49  Lr: 0.030000  Loss: -1.7932  Acc@1: 68.7500 (70.0767)  Acc@5: 93.7500 (92.9261)  time: 0.3930  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4310/4579]  eta: 0:01:45  Lr: 0.030000  Loss: -2.3956  Acc@1: 68.7500 (70.0983)  Acc@5: 93.7500 (92.9280)  time: 0.3929  data: 0.0006  max mem: 2904
Train: Epoch[5/5]  [4320/4579]  eta: 0:01:41  Lr: 0.030000  Loss: -1.5281  Acc@1: 81.2500 (70.1111)  Acc@5: 93.7500 (92.9313)  time: 0.3927  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [4330/4579]  eta: 0:01:37  Lr: 0.030000  Loss: -1.4458  Acc@1: 75.0000 (70.1108)  Acc@5: 93.7500 (92.9347)  time: 0.3936  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [4340/4579]  eta: 0:01:33  Lr: 0.030000  Loss: -2.0056  Acc@1: 68.7500 (70.1207)  Acc@5: 93.7500 (92.9409)  time: 0.3934  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4350/4579]  eta: 0:01:29  Lr: 0.030000  Loss: -1.1849  Acc@1: 68.7500 (70.1189)  Acc@5: 93.7500 (92.9456)  time: 0.3920  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4360/4579]  eta: 0:01:25  Lr: 0.030000  Loss: -2.0463  Acc@1: 68.7500 (70.1215)  Acc@5: 93.7500 (92.9460)  time: 0.3929  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:21  Lr: 0.030000  Loss: -1.3269  Acc@1: 75.0000 (70.1284)  Acc@5: 93.7500 (92.9450)  time: 0.3930  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:18  Lr: 0.030000  Loss: -1.6413  Acc@1: 75.0000 (70.1352)  Acc@5: 93.7500 (92.9411)  time: 0.3912  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:14  Lr: 0.030000  Loss: -1.7432  Acc@1: 68.7500 (70.1307)  Acc@5: 87.5000 (92.9373)  time: 0.3907  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:10  Lr: 0.030000  Loss: -1.4457  Acc@1: 68.7500 (70.1204)  Acc@5: 93.7500 (92.9363)  time: 0.3915  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4410/4579]  eta: 0:01:06  Lr: 0.030000  Loss: -2.1822  Acc@1: 68.7500 (70.1357)  Acc@5: 93.7500 (92.9367)  time: 0.3925  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4420/4579]  eta: 0:01:02  Lr: 0.030000  Loss: -1.2451  Acc@1: 75.0000 (70.1312)  Acc@5: 93.7500 (92.9343)  time: 0.3919  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4430/4579]  eta: 0:00:58  Lr: 0.030000  Loss: -1.5794  Acc@1: 68.7500 (70.1238)  Acc@5: 93.7500 (92.9418)  time: 0.3923  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [4440/4579]  eta: 0:00:54  Lr: 0.030000  Loss: -2.2680  Acc@1: 68.7500 (70.1306)  Acc@5: 93.7500 (92.9464)  time: 0.3938  data: 0.0011  max mem: 2904
Train: Epoch[5/5]  [4450/4579]  eta: 0:00:50  Lr: 0.030000  Loss: -1.8976  Acc@1: 75.0000 (70.1317)  Acc@5: 93.7500 (92.9496)  time: 0.3932  data: 0.0004  max mem: 2904
Train: Epoch[5/5]  [4460/4579]  eta: 0:00:46  Lr: 0.030000  Loss: -1.7341  Acc@1: 68.7500 (70.1370)  Acc@5: 100.0000 (92.9570)  time: 0.3941  data: 0.0019  max mem: 2904
Train: Epoch[5/5]  [4470/4579]  eta: 0:00:42  Lr: 0.030000  Loss: -1.4993  Acc@1: 75.0000 (70.1339)  Acc@5: 93.7500 (92.9560)  time: 0.3969  data: 0.0029  max mem: 2904
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:38  Lr: 0.030000  Loss: -1.8498  Acc@1: 68.7500 (70.1406)  Acc@5: 93.7500 (92.9620)  time: 0.3965  data: 0.0022  max mem: 2904
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:34  Lr: 0.030000  Loss: -2.2599  Acc@1: 75.0000 (70.1528)  Acc@5: 93.7500 (92.9651)  time: 0.3953  data: 0.0014  max mem: 2904
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:30  Lr: 0.030000  Loss: -1.9100  Acc@1: 75.0000 (70.1497)  Acc@5: 93.7500 (92.9627)  time: 0.3939  data: 0.0014  max mem: 2904
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:27  Lr: 0.030000  Loss: -1.6530  Acc@1: 75.0000 (70.1535)  Acc@5: 93.7500 (92.9603)  time: 0.3934  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:23  Lr: 0.030000  Loss: -1.3486  Acc@1: 68.7500 (70.1435)  Acc@5: 87.5000 (92.9592)  time: 0.3949  data: 0.0019  max mem: 2904
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:19  Lr: 0.030000  Loss: -1.2764  Acc@1: 68.7500 (70.1459)  Acc@5: 93.7500 (92.9513)  time: 0.3943  data: 0.0026  max mem: 2904
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:15  Lr: 0.030000  Loss: -1.6142  Acc@1: 68.7500 (70.1511)  Acc@5: 93.7500 (92.9558)  time: 0.3932  data: 0.0012  max mem: 2904
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:11  Lr: 0.030000  Loss: -1.7460  Acc@1: 68.7500 (70.1508)  Acc@5: 93.7500 (92.9603)  time: 0.3917  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:07  Lr: 0.030000  Loss: -1.3636  Acc@1: 75.0000 (70.1655)  Acc@5: 93.7500 (92.9634)  time: 0.3910  data: 0.0003  max mem: 2904
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: -2.0581  Acc@1: 68.7500 (70.1611)  Acc@5: 93.7500 (92.9638)  time: 0.3919  data: 0.0010  max mem: 2904
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: -2.0778  Acc@1: 68.7500 (70.1680)  Acc@5: 93.7500 (92.9700)  time: 0.3842  data: 0.0009  max mem: 2904
Train: Epoch[5/5] Total time: 0:29:56 (0.3924 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.0778  Acc@1: 68.7500 (70.1680)  Acc@5: 93.7500 (92.9700)
Test: [Task 1]  [   0/1627]  eta: 0:17:42  Loss: 0.7329 (0.7329)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6531  data: 0.4040  max mem: 2904
Test: [Task 1]  [  10/1627]  eta: 0:07:38  Loss: 0.4562 (0.4716)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.2838  data: 0.0371  max mem: 2904
Test: [Task 1]  [  20/1627]  eta: 0:07:08  Loss: 0.4279 (0.4780)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (98.5119)  time: 0.2474  data: 0.0004  max mem: 2904
Test: [Task 1]  [  30/1627]  eta: 0:06:56  Loss: 0.4697 (0.4760)  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (98.9919)  time: 0.2481  data: 0.0010  max mem: 2904
Test: [Task 1]  [  40/1627]  eta: 0:06:47  Loss: 0.5074 (0.4884)  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (98.7805)  time: 0.2462  data: 0.0010  max mem: 2904
Test: [Task 1]  [  50/1627]  eta: 0:06:40  Loss: 0.4642 (0.4805)  Acc@1: 93.7500 (89.3382)  Acc@5: 100.0000 (99.0196)  time: 0.2431  data: 0.0005  max mem: 2904
Test: [Task 1]  [  60/1627]  eta: 0:06:34  Loss: 0.4224 (0.4947)  Acc@1: 93.7500 (89.2418)  Acc@5: 100.0000 (99.0779)  time: 0.2422  data: 0.0005  max mem: 2904
Test: [Task 1]  [  70/1627]  eta: 0:06:30  Loss: 0.4533 (0.4934)  Acc@1: 87.5000 (89.0845)  Acc@5: 100.0000 (99.0317)  time: 0.2421  data: 0.0003  max mem: 2904
Test: [Task 1]  [  80/1627]  eta: 0:06:26  Loss: 0.3738 (0.4772)  Acc@1: 93.7500 (89.5062)  Acc@5: 100.0000 (99.1512)  time: 0.2425  data: 0.0003  max mem: 2904
Test: [Task 1]  [  90/1627]  eta: 0:06:22  Loss: 0.4037 (0.4897)  Acc@1: 93.7500 (89.3544)  Acc@5: 100.0000 (99.1071)  time: 0.2434  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 100/1627]  eta: 0:06:19  Loss: 0.5967 (0.5010)  Acc@1: 87.5000 (89.1089)  Acc@5: 100.0000 (99.0099)  time: 0.2440  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 110/1627]  eta: 0:06:16  Loss: 0.4167 (0.4900)  Acc@1: 87.5000 (89.2455)  Acc@5: 100.0000 (99.0428)  time: 0.2433  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 120/1627]  eta: 0:06:13  Loss: 0.4148 (0.4936)  Acc@1: 87.5000 (89.2562)  Acc@5: 100.0000 (99.0702)  time: 0.2433  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 130/1627]  eta: 0:06:10  Loss: 0.4148 (0.4937)  Acc@1: 93.7500 (89.3130)  Acc@5: 100.0000 (99.0935)  time: 0.2443  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 140/1627]  eta: 0:06:07  Loss: 0.3872 (0.4891)  Acc@1: 93.7500 (89.4060)  Acc@5: 100.0000 (99.1578)  time: 0.2454  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 150/1627]  eta: 0:06:05  Loss: 0.3872 (0.4811)  Acc@1: 93.7500 (89.6523)  Acc@5: 100.0000 (99.1308)  time: 0.2462  data: 0.0011  max mem: 2904
Test: [Task 1]  [ 160/1627]  eta: 0:06:02  Loss: 0.4279 (0.4805)  Acc@1: 87.5000 (89.5575)  Acc@5: 100.0000 (99.1460)  time: 0.2453  data: 0.0011  max mem: 2904
Test: [Task 1]  [ 170/1627]  eta: 0:05:59  Loss: 0.4295 (0.4752)  Acc@1: 87.5000 (89.6930)  Acc@5: 100.0000 (99.1228)  time: 0.2440  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 180/1627]  eta: 0:05:56  Loss: 0.4096 (0.4748)  Acc@1: 93.7500 (89.9171)  Acc@5: 100.0000 (99.1367)  time: 0.2433  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 190/1627]  eta: 0:05:54  Loss: 0.4301 (0.4730)  Acc@1: 93.7500 (90.0524)  Acc@5: 100.0000 (99.0510)  time: 0.2435  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 200/1627]  eta: 0:05:51  Loss: 0.3678 (0.4728)  Acc@1: 93.7500 (90.1430)  Acc@5: 100.0000 (99.0983)  time: 0.2434  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 210/1627]  eta: 0:05:48  Loss: 0.3678 (0.4753)  Acc@1: 93.7500 (90.1066)  Acc@5: 100.0000 (99.0818)  time: 0.2427  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 220/1627]  eta: 0:05:46  Loss: 0.4376 (0.4754)  Acc@1: 87.5000 (89.9887)  Acc@5: 100.0000 (99.0950)  time: 0.2420  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 230/1627]  eta: 0:05:43  Loss: 0.4469 (0.4741)  Acc@1: 87.5000 (90.0433)  Acc@5: 100.0000 (99.1071)  time: 0.2426  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 240/1627]  eta: 0:05:40  Loss: 0.3886 (0.4702)  Acc@1: 93.7500 (90.1971)  Acc@5: 100.0000 (99.1442)  time: 0.2433  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 250/1627]  eta: 0:05:38  Loss: 0.3644 (0.4779)  Acc@1: 93.7500 (90.1394)  Acc@5: 100.0000 (99.0538)  time: 0.2437  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 260/1627]  eta: 0:05:35  Loss: 0.4191 (0.4780)  Acc@1: 87.5000 (90.1102)  Acc@5: 100.0000 (99.0661)  time: 0.2435  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 270/1627]  eta: 0:05:33  Loss: 0.3636 (0.4726)  Acc@1: 93.7500 (90.2445)  Acc@5: 100.0000 (99.1006)  time: 0.2427  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 280/1627]  eta: 0:05:30  Loss: 0.3705 (0.4749)  Acc@1: 87.5000 (90.1468)  Acc@5: 100.0000 (99.1326)  time: 0.2427  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 290/1627]  eta: 0:05:27  Loss: 0.4669 (0.4768)  Acc@1: 87.5000 (90.1632)  Acc@5: 100.0000 (99.1409)  time: 0.2423  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 300/1627]  eta: 0:05:25  Loss: 0.4157 (0.4752)  Acc@1: 93.7500 (90.1993)  Acc@5: 100.0000 (99.1279)  time: 0.2429  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 310/1627]  eta: 0:05:22  Loss: 0.4145 (0.4751)  Acc@1: 93.7500 (90.1728)  Acc@5: 100.0000 (99.1559)  time: 0.2433  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 320/1627]  eta: 0:05:20  Loss: 0.2927 (0.4707)  Acc@1: 93.7500 (90.3427)  Acc@5: 100.0000 (99.1628)  time: 0.2421  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 330/1627]  eta: 0:05:17  Loss: 0.2927 (0.4701)  Acc@1: 93.7500 (90.3512)  Acc@5: 100.0000 (99.1692)  time: 0.2422  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 340/1627]  eta: 0:05:15  Loss: 0.4170 (0.4723)  Acc@1: 87.5000 (90.3592)  Acc@5: 100.0000 (99.1386)  time: 0.2434  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 350/1627]  eta: 0:05:12  Loss: 0.3743 (0.4717)  Acc@1: 93.7500 (90.4024)  Acc@5: 100.0000 (99.1453)  time: 0.2442  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 360/1627]  eta: 0:05:10  Loss: 0.3279 (0.4718)  Acc@1: 93.7500 (90.3740)  Acc@5: 100.0000 (99.1517)  time: 0.2436  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 370/1627]  eta: 0:05:07  Loss: 0.4398 (0.4722)  Acc@1: 93.7500 (90.4313)  Acc@5: 100.0000 (99.1577)  time: 0.2434  data: 0.0010  max mem: 2904
Test: [Task 1]  [ 380/1627]  eta: 0:05:05  Loss: 0.4286 (0.4717)  Acc@1: 93.7500 (90.4528)  Acc@5: 100.0000 (99.0978)  time: 0.2441  data: 0.0010  max mem: 2904
Test: [Task 1]  [ 390/1627]  eta: 0:05:02  Loss: 0.3233 (0.4710)  Acc@1: 93.7500 (90.5051)  Acc@5: 100.0000 (99.1208)  time: 0.2434  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 400/1627]  eta: 0:05:00  Loss: 0.3233 (0.4701)  Acc@1: 93.7500 (90.5237)  Acc@5: 100.0000 (99.1428)  time: 0.2435  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 410/1627]  eta: 0:04:57  Loss: 0.3975 (0.4747)  Acc@1: 93.7500 (90.4653)  Acc@5: 100.0000 (99.1028)  time: 0.2448  data: 0.0010  max mem: 2904
Test: [Task 1]  [ 420/1627]  eta: 0:04:55  Loss: 0.4602 (0.4737)  Acc@1: 93.7500 (90.4988)  Acc@5: 100.0000 (99.0944)  time: 0.2439  data: 0.0010  max mem: 2904
Test: [Task 1]  [ 430/1627]  eta: 0:04:52  Loss: 0.3887 (0.4725)  Acc@1: 93.7500 (90.4872)  Acc@5: 100.0000 (99.1154)  time: 0.2429  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 440/1627]  eta: 0:04:50  Loss: 0.4336 (0.4719)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (99.1213)  time: 0.2439  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 450/1627]  eta: 0:04:47  Loss: 0.4544 (0.4741)  Acc@1: 87.5000 (90.4102)  Acc@5: 100.0000 (99.0854)  time: 0.2453  data: 0.0005  max mem: 2904
Test: [Task 1]  [ 460/1627]  eta: 0:04:45  Loss: 0.4530 (0.4726)  Acc@1: 93.7500 (90.4149)  Acc@5: 100.0000 (99.0781)  time: 0.2470  data: 0.0005  max mem: 2904
Test: [Task 1]  [ 470/1627]  eta: 0:04:43  Loss: 0.3543 (0.4703)  Acc@1: 93.7500 (90.4459)  Acc@5: 100.0000 (99.0711)  time: 0.2468  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 480/1627]  eta: 0:04:40  Loss: 0.3817 (0.4719)  Acc@1: 87.5000 (90.3846)  Acc@5: 100.0000 (99.0904)  time: 0.2470  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 490/1627]  eta: 0:04:38  Loss: 0.4784 (0.4740)  Acc@1: 87.5000 (90.3004)  Acc@5: 100.0000 (99.0580)  time: 0.2485  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 500/1627]  eta: 0:04:36  Loss: 0.4821 (0.4751)  Acc@1: 87.5000 (90.2944)  Acc@5: 100.0000 (99.0519)  time: 0.2483  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 510/1627]  eta: 0:04:33  Loss: 0.5144 (0.4789)  Acc@1: 87.5000 (90.3009)  Acc@5: 100.0000 (99.0093)  time: 0.2489  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 520/1627]  eta: 0:04:31  Loss: 0.5144 (0.4853)  Acc@1: 93.7500 (90.2951)  Acc@5: 100.0000 (98.9683)  time: 0.2490  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 530/1627]  eta: 0:04:28  Loss: 0.3665 (0.4836)  Acc@1: 87.5000 (90.2895)  Acc@5: 100.0000 (98.9878)  time: 0.2483  data: 0.0013  max mem: 2904
Test: [Task 1]  [ 540/1627]  eta: 0:04:26  Loss: 0.3534 (0.4814)  Acc@1: 93.7500 (90.3304)  Acc@5: 100.0000 (98.9949)  time: 0.2463  data: 0.0013  max mem: 2904
Test: [Task 1]  [ 550/1627]  eta: 0:04:24  Loss: 0.4544 (0.4824)  Acc@1: 87.5000 (90.2790)  Acc@5: 100.0000 (99.0018)  time: 0.2454  data: 0.0013  max mem: 2904
Test: [Task 1]  [ 560/1627]  eta: 0:04:21  Loss: 0.5350 (0.4838)  Acc@1: 87.5000 (90.2518)  Acc@5: 100.0000 (98.9862)  time: 0.2480  data: 0.0013  max mem: 2904
Test: [Task 1]  [ 570/1627]  eta: 0:04:19  Loss: 0.4573 (0.4829)  Acc@1: 87.5000 (90.3240)  Acc@5: 100.0000 (98.9711)  time: 0.2491  data: 0.0011  max mem: 2904
Test: [Task 1]  [ 580/1627]  eta: 0:04:16  Loss: 0.3929 (0.4835)  Acc@1: 93.7500 (90.3077)  Acc@5: 100.0000 (98.9781)  time: 0.2478  data: 0.0011  max mem: 2904
Test: [Task 1]  [ 590/1627]  eta: 0:04:14  Loss: 0.3929 (0.4828)  Acc@1: 93.7500 (90.3342)  Acc@5: 100.0000 (98.9848)  time: 0.2477  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 600/1627]  eta: 0:04:12  Loss: 0.3543 (0.4828)  Acc@1: 93.7500 (90.3182)  Acc@5: 100.0000 (99.0017)  time: 0.2487  data: 0.0005  max mem: 2904
Test: [Task 1]  [ 610/1627]  eta: 0:04:09  Loss: 0.4421 (0.4832)  Acc@1: 93.7500 (90.3335)  Acc@5: 100.0000 (98.9771)  time: 0.2484  data: 0.0012  max mem: 2904
Test: [Task 1]  [ 620/1627]  eta: 0:04:07  Loss: 0.5094 (0.4851)  Acc@1: 87.5000 (90.2476)  Acc@5: 100.0000 (98.9734)  time: 0.2467  data: 0.0012  max mem: 2904
Test: [Task 1]  [ 630/1627]  eta: 0:04:04  Loss: 0.4639 (0.4861)  Acc@1: 87.5000 (90.2239)  Acc@5: 100.0000 (98.9501)  time: 0.2439  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 640/1627]  eta: 0:04:02  Loss: 0.4114 (0.4861)  Acc@1: 87.5000 (90.2106)  Acc@5: 100.0000 (98.9470)  time: 0.2461  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 650/1627]  eta: 0:03:59  Loss: 0.3570 (0.4849)  Acc@1: 87.5000 (90.2170)  Acc@5: 100.0000 (98.9631)  time: 0.2498  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 660/1627]  eta: 0:03:57  Loss: 0.3905 (0.4842)  Acc@1: 87.5000 (90.2042)  Acc@5: 100.0000 (98.9694)  time: 0.2491  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 670/1627]  eta: 0:03:55  Loss: 0.4378 (0.4840)  Acc@1: 87.5000 (90.2012)  Acc@5: 100.0000 (98.9754)  time: 0.2482  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 680/1627]  eta: 0:03:52  Loss: 0.4822 (0.4850)  Acc@1: 87.5000 (90.1982)  Acc@5: 100.0000 (98.9629)  time: 0.2501  data: 0.0018  max mem: 2904
Test: [Task 1]  [ 690/1627]  eta: 0:03:50  Loss: 0.4420 (0.4842)  Acc@1: 87.5000 (90.2044)  Acc@5: 100.0000 (98.9689)  time: 0.2498  data: 0.0018  max mem: 2904
Test: [Task 1]  [ 700/1627]  eta: 0:03:47  Loss: 0.4365 (0.4853)  Acc@1: 87.5000 (90.1658)  Acc@5: 100.0000 (98.9479)  time: 0.2477  data: 0.0009  max mem: 2904
Test: [Task 1]  [ 710/1627]  eta: 0:03:45  Loss: 0.4080 (0.4838)  Acc@1: 93.7500 (90.2250)  Acc@5: 100.0000 (98.9539)  time: 0.2458  data: 0.0008  max mem: 2904
Test: [Task 1]  [ 720/1627]  eta: 0:03:42  Loss: 0.3013 (0.4813)  Acc@1: 93.7500 (90.2999)  Acc@5: 100.0000 (98.9511)  time: 0.2446  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 730/1627]  eta: 0:03:40  Loss: 0.3397 (0.4808)  Acc@1: 93.7500 (90.3129)  Acc@5: 100.0000 (98.9484)  time: 0.2444  data: 0.0005  max mem: 2904
Test: [Task 1]  [ 740/1627]  eta: 0:03:37  Loss: 0.4876 (0.4824)  Acc@1: 87.5000 (90.3003)  Acc@5: 100.0000 (98.9457)  time: 0.2442  data: 0.0005  max mem: 2904
Test: [Task 1]  [ 750/1627]  eta: 0:03:35  Loss: 0.4876 (0.4818)  Acc@1: 87.5000 (90.3046)  Acc@5: 100.0000 (98.9514)  time: 0.2463  data: 0.0011  max mem: 2904
Test: [Task 1]  [ 760/1627]  eta: 0:03:33  Loss: 0.4245 (0.4845)  Acc@1: 87.5000 (90.3006)  Acc@5: 100.0000 (98.9159)  time: 0.2483  data: 0.0011  max mem: 2904
Test: [Task 1]  [ 770/1627]  eta: 0:03:30  Loss: 0.3640 (0.4819)  Acc@1: 93.7500 (90.3534)  Acc@5: 100.0000 (98.9219)  time: 0.2486  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 780/1627]  eta: 0:03:28  Loss: 0.2203 (0.4793)  Acc@1: 93.7500 (90.4209)  Acc@5: 100.0000 (98.9357)  time: 0.2465  data: 0.0011  max mem: 2904
Test: [Task 1]  [ 790/1627]  eta: 0:03:25  Loss: 0.3296 (0.4799)  Acc@1: 93.7500 (90.3919)  Acc@5: 100.0000 (98.9254)  time: 0.2489  data: 0.0019  max mem: 2904
Test: [Task 1]  [ 800/1627]  eta: 0:03:23  Loss: 0.4070 (0.4794)  Acc@1: 87.5000 (90.4104)  Acc@5: 100.0000 (98.9310)  time: 0.2515  data: 0.0016  max mem: 2904
Test: [Task 1]  [ 810/1627]  eta: 0:03:21  Loss: 0.3466 (0.4786)  Acc@1: 93.7500 (90.4054)  Acc@5: 100.0000 (98.9288)  time: 0.2497  data: 0.0008  max mem: 2904
Test: [Task 1]  [ 820/1627]  eta: 0:03:18  Loss: 0.3008 (0.4779)  Acc@1: 93.7500 (90.4157)  Acc@5: 100.0000 (98.9342)  time: 0.2478  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 830/1627]  eta: 0:03:16  Loss: 0.3744 (0.4775)  Acc@1: 93.7500 (90.4182)  Acc@5: 100.0000 (98.9395)  time: 0.2478  data: 0.0020  max mem: 2904
Test: [Task 1]  [ 840/1627]  eta: 0:03:13  Loss: 0.3291 (0.4761)  Acc@1: 93.7500 (90.4504)  Acc@5: 100.0000 (98.9447)  time: 0.2467  data: 0.0020  max mem: 2904
Test: [Task 1]  [ 850/1627]  eta: 0:03:11  Loss: 0.4007 (0.4779)  Acc@1: 93.7500 (90.4157)  Acc@5: 100.0000 (98.9498)  time: 0.2434  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 860/1627]  eta: 0:03:08  Loss: 0.4194 (0.4774)  Acc@1: 93.7500 (90.4399)  Acc@5: 100.0000 (98.9547)  time: 0.2437  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 870/1627]  eta: 0:03:06  Loss: 0.2966 (0.4771)  Acc@1: 93.7500 (90.4564)  Acc@5: 100.0000 (98.9524)  time: 0.2436  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 880/1627]  eta: 0:03:03  Loss: 0.4867 (0.4779)  Acc@1: 87.5000 (90.4228)  Acc@5: 100.0000 (98.9430)  time: 0.2449  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 890/1627]  eta: 0:03:01  Loss: 0.4900 (0.4798)  Acc@1: 87.5000 (90.4181)  Acc@5: 100.0000 (98.9338)  time: 0.2473  data: 0.0007  max mem: 2904
Test: [Task 1]  [ 900/1627]  eta: 0:02:58  Loss: 0.3588 (0.4793)  Acc@1: 93.7500 (90.4204)  Acc@5: 100.0000 (98.9456)  time: 0.2483  data: 0.0007  max mem: 2904
Test: [Task 1]  [ 910/1627]  eta: 0:02:56  Loss: 0.3552 (0.4803)  Acc@1: 93.7500 (90.4363)  Acc@5: 100.0000 (98.9092)  time: 0.2483  data: 0.0003  max mem: 2904
Test: [Task 1]  [ 920/1627]  eta: 0:02:53  Loss: 0.3540 (0.4800)  Acc@1: 93.7500 (90.4655)  Acc@5: 100.0000 (98.9007)  time: 0.2495  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 930/1627]  eta: 0:02:51  Loss: 0.4447 (0.4801)  Acc@1: 93.7500 (90.4672)  Acc@5: 100.0000 (98.8856)  time: 0.2490  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 940/1627]  eta: 0:02:49  Loss: 0.4104 (0.4785)  Acc@1: 93.7500 (90.5154)  Acc@5: 100.0000 (98.8908)  time: 0.2473  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 950/1627]  eta: 0:02:46  Loss: 0.3422 (0.4779)  Acc@1: 93.7500 (90.5297)  Acc@5: 100.0000 (98.9025)  time: 0.2484  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 960/1627]  eta: 0:02:44  Loss: 0.3422 (0.4776)  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (98.9074)  time: 0.2494  data: 0.0005  max mem: 2904
Test: [Task 1]  [ 970/1627]  eta: 0:02:41  Loss: 0.2926 (0.4765)  Acc@1: 93.7500 (90.5317)  Acc@5: 100.0000 (98.9186)  time: 0.2474  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 980/1627]  eta: 0:02:39  Loss: 0.4456 (0.4770)  Acc@1: 87.5000 (90.5262)  Acc@5: 100.0000 (98.9169)  time: 0.2443  data: 0.0004  max mem: 2904
Test: [Task 1]  [ 990/1627]  eta: 0:02:36  Loss: 0.5788 (0.4791)  Acc@1: 87.5000 (90.5020)  Acc@5: 100.0000 (98.9026)  time: 0.2435  data: 0.0004  max mem: 2904
Test: [Task 1]  [1000/1627]  eta: 0:02:34  Loss: 0.5504 (0.4791)  Acc@1: 87.5000 (90.4970)  Acc@5: 100.0000 (98.9073)  time: 0.2439  data: 0.0004  max mem: 2904
Test: [Task 1]  [1010/1627]  eta: 0:02:31  Loss: 0.3916 (0.4788)  Acc@1: 93.7500 (90.5230)  Acc@5: 100.0000 (98.9182)  time: 0.2435  data: 0.0004  max mem: 2904
Test: [Task 1]  [1020/1627]  eta: 0:02:29  Loss: 0.3916 (0.4785)  Acc@1: 93.7500 (90.5056)  Acc@5: 100.0000 (98.9287)  time: 0.2434  data: 0.0003  max mem: 2904
Test: [Task 1]  [1030/1627]  eta: 0:02:26  Loss: 0.3896 (0.4775)  Acc@1: 93.7500 (90.5250)  Acc@5: 100.0000 (98.9270)  time: 0.2439  data: 0.0004  max mem: 2904
Test: [Task 1]  [1040/1627]  eta: 0:02:24  Loss: 0.3101 (0.4765)  Acc@1: 93.7500 (90.5680)  Acc@5: 100.0000 (98.9253)  time: 0.2435  data: 0.0004  max mem: 2904
Test: [Task 1]  [1050/1627]  eta: 0:02:21  Loss: 0.2964 (0.4752)  Acc@1: 93.7500 (90.5923)  Acc@5: 100.0000 (98.9296)  time: 0.2449  data: 0.0003  max mem: 2904
Test: [Task 1]  [1060/1627]  eta: 0:02:19  Loss: 0.4263 (0.4759)  Acc@1: 87.5000 (90.5514)  Acc@5: 100.0000 (98.9161)  time: 0.2453  data: 0.0003  max mem: 2904
Test: [Task 1]  [1070/1627]  eta: 0:02:17  Loss: 0.5029 (0.4769)  Acc@1: 87.5000 (90.5345)  Acc@5: 100.0000 (98.8971)  time: 0.2445  data: 0.0003  max mem: 2904
Test: [Task 1]  [1080/1627]  eta: 0:02:14  Loss: 0.3543 (0.4766)  Acc@1: 87.5000 (90.5469)  Acc@5: 100.0000 (98.8957)  time: 0.2456  data: 0.0004  max mem: 2904
Test: [Task 1]  [1090/1627]  eta: 0:02:12  Loss: 0.3791 (0.4762)  Acc@1: 93.7500 (90.5648)  Acc@5: 100.0000 (98.9058)  time: 0.2451  data: 0.0004  max mem: 2904
Test: [Task 1]  [1100/1627]  eta: 0:02:09  Loss: 0.3791 (0.4756)  Acc@1: 87.5000 (90.5711)  Acc@5: 100.0000 (98.9101)  time: 0.2438  data: 0.0004  max mem: 2904
Test: [Task 1]  [1110/1627]  eta: 0:02:07  Loss: 0.4089 (0.4752)  Acc@1: 87.5000 (90.5772)  Acc@5: 100.0000 (98.9143)  time: 0.2441  data: 0.0004  max mem: 2904
Test: [Task 1]  [1120/1627]  eta: 0:02:04  Loss: 0.4409 (0.4759)  Acc@1: 87.5000 (90.5720)  Acc@5: 100.0000 (98.9072)  time: 0.2445  data: 0.0004  max mem: 2904
Test: [Task 1]  [1130/1627]  eta: 0:02:02  Loss: 0.4488 (0.4761)  Acc@1: 87.5000 (90.5504)  Acc@5: 100.0000 (98.9114)  time: 0.2440  data: 0.0004  max mem: 2904
Test: [Task 1]  [1140/1627]  eta: 0:01:59  Loss: 0.4827 (0.4765)  Acc@1: 87.5000 (90.5291)  Acc@5: 100.0000 (98.9099)  time: 0.2429  data: 0.0003  max mem: 2904
Test: [Task 1]  [1150/1627]  eta: 0:01:57  Loss: 0.5066 (0.4773)  Acc@1: 87.5000 (90.5083)  Acc@5: 100.0000 (98.8923)  time: 0.2428  data: 0.0003  max mem: 2904
Test: [Task 1]  [1160/1627]  eta: 0:01:54  Loss: 0.4317 (0.4770)  Acc@1: 87.5000 (90.5093)  Acc@5: 100.0000 (98.8964)  time: 0.2449  data: 0.0007  max mem: 2904
Test: [Task 1]  [1170/1627]  eta: 0:01:52  Loss: 0.3206 (0.4763)  Acc@1: 93.7500 (90.5156)  Acc@5: 100.0000 (98.9058)  time: 0.2448  data: 0.0007  max mem: 2904
Test: [Task 1]  [1180/1627]  eta: 0:01:49  Loss: 0.3480 (0.4768)  Acc@1: 93.7500 (90.5112)  Acc@5: 100.0000 (98.9098)  time: 0.2433  data: 0.0003  max mem: 2904
Test: [Task 1]  [1190/1627]  eta: 0:01:47  Loss: 0.4000 (0.4764)  Acc@1: 93.7500 (90.5279)  Acc@5: 100.0000 (98.9137)  time: 0.2439  data: 0.0003  max mem: 2904
Test: [Task 1]  [1200/1627]  eta: 0:01:44  Loss: 0.4000 (0.4764)  Acc@1: 87.5000 (90.5235)  Acc@5: 100.0000 (98.9124)  time: 0.2441  data: 0.0004  max mem: 2904
Test: [Task 1]  [1210/1627]  eta: 0:01:42  Loss: 0.3563 (0.4770)  Acc@1: 87.5000 (90.5244)  Acc@5: 100.0000 (98.9110)  time: 0.2438  data: 0.0004  max mem: 2904
Test: [Task 1]  [1220/1627]  eta: 0:01:40  Loss: 0.3683 (0.4765)  Acc@1: 93.7500 (90.5354)  Acc@5: 100.0000 (98.9199)  time: 0.2438  data: 0.0004  max mem: 2904
Test: [Task 1]  [1230/1627]  eta: 0:01:37  Loss: 0.4478 (0.4774)  Acc@1: 87.5000 (90.4803)  Acc@5: 100.0000 (98.9236)  time: 0.2431  data: 0.0004  max mem: 2904
Test: [Task 1]  [1240/1627]  eta: 0:01:35  Loss: 0.4675 (0.4772)  Acc@1: 87.5000 (90.4664)  Acc@5: 100.0000 (98.9323)  time: 0.2432  data: 0.0004  max mem: 2904
Test: [Task 1]  [1250/1627]  eta: 0:01:32  Loss: 0.4973 (0.4774)  Acc@1: 93.7500 (90.4676)  Acc@5: 100.0000 (98.9309)  time: 0.2447  data: 0.0004  max mem: 2904
Test: [Task 1]  [1260/1627]  eta: 0:01:30  Loss: 0.4442 (0.4777)  Acc@1: 93.7500 (90.4689)  Acc@5: 100.0000 (98.9294)  time: 0.2445  data: 0.0004  max mem: 2904
Test: [Task 1]  [1270/1627]  eta: 0:01:27  Loss: 0.4460 (0.4782)  Acc@1: 87.5000 (90.4357)  Acc@5: 100.0000 (98.9231)  time: 0.2439  data: 0.0004  max mem: 2904
Test: [Task 1]  [1280/1627]  eta: 0:01:25  Loss: 0.4389 (0.4773)  Acc@1: 87.5000 (90.4469)  Acc@5: 100.0000 (98.9315)  time: 0.2442  data: 0.0004  max mem: 2904
Test: [Task 1]  [1290/1627]  eta: 0:01:22  Loss: 0.3444 (0.4771)  Acc@1: 93.7500 (90.4628)  Acc@5: 100.0000 (98.9349)  time: 0.2439  data: 0.0004  max mem: 2904
Test: [Task 1]  [1300/1627]  eta: 0:01:20  Loss: 0.4639 (0.4770)  Acc@1: 93.7500 (90.4833)  Acc@5: 100.0000 (98.9335)  time: 0.2432  data: 0.0004  max mem: 2904
Test: [Task 1]  [1310/1627]  eta: 0:01:17  Loss: 0.3658 (0.4761)  Acc@1: 87.5000 (90.4939)  Acc@5: 100.0000 (98.9321)  time: 0.2433  data: 0.0004  max mem: 2904
Test: [Task 1]  [1320/1627]  eta: 0:01:15  Loss: 0.2937 (0.4754)  Acc@1: 93.7500 (90.5044)  Acc@5: 100.0000 (98.9355)  time: 0.2431  data: 0.0003  max mem: 2904
Test: [Task 1]  [1330/1627]  eta: 0:01:12  Loss: 0.2694 (0.4747)  Acc@1: 93.7500 (90.5147)  Acc@5: 100.0000 (98.9388)  time: 0.2425  data: 0.0003  max mem: 2904
Test: [Task 1]  [1340/1627]  eta: 0:01:10  Loss: 0.3795 (0.4750)  Acc@1: 93.7500 (90.5062)  Acc@5: 100.0000 (98.9420)  time: 0.2427  data: 0.0003  max mem: 2904
Test: [Task 1]  [1350/1627]  eta: 0:01:08  Loss: 0.4061 (0.4746)  Acc@1: 93.7500 (90.5163)  Acc@5: 100.0000 (98.9499)  time: 0.2426  data: 0.0003  max mem: 2904
Test: [Task 1]  [1360/1627]  eta: 0:01:05  Loss: 0.4061 (0.4744)  Acc@1: 93.7500 (90.5171)  Acc@5: 100.0000 (98.9576)  time: 0.2423  data: 0.0002  max mem: 2904
Test: [Task 1]  [1370/1627]  eta: 0:01:03  Loss: 0.3743 (0.4736)  Acc@1: 93.7500 (90.5452)  Acc@5: 100.0000 (98.9606)  time: 0.2425  data: 0.0003  max mem: 2904
Test: [Task 1]  [1380/1627]  eta: 0:01:00  Loss: 0.3743 (0.4735)  Acc@1: 93.7500 (90.5549)  Acc@5: 100.0000 (98.9636)  time: 0.2423  data: 0.0003  max mem: 2904
Test: [Task 1]  [1390/1627]  eta: 0:00:58  Loss: 0.5212 (0.4735)  Acc@1: 93.7500 (90.5643)  Acc@5: 100.0000 (98.9666)  time: 0.2419  data: 0.0003  max mem: 2904
Test: [Task 1]  [1400/1627]  eta: 0:00:55  Loss: 0.5577 (0.4739)  Acc@1: 87.5000 (90.5469)  Acc@5: 100.0000 (98.9606)  time: 0.2420  data: 0.0003  max mem: 2904
Test: [Task 1]  [1410/1627]  eta: 0:00:53  Loss: 0.3429 (0.4734)  Acc@1: 93.7500 (90.5563)  Acc@5: 100.0000 (98.9635)  time: 0.2425  data: 0.0003  max mem: 2904
Test: [Task 1]  [1420/1627]  eta: 0:00:50  Loss: 0.3446 (0.4735)  Acc@1: 93.7500 (90.5524)  Acc@5: 100.0000 (98.9664)  time: 0.2432  data: 0.0003  max mem: 2904
Test: [Task 1]  [1430/1627]  eta: 0:00:48  Loss: 0.6389 (0.4757)  Acc@1: 87.5000 (90.5267)  Acc@5: 100.0000 (98.9474)  time: 0.2434  data: 0.0003  max mem: 2904
Test: [Task 1]  [1440/1627]  eta: 0:00:45  Loss: 0.6220 (0.4763)  Acc@1: 87.5000 (90.5101)  Acc@5: 100.0000 (98.9460)  time: 0.2426  data: 0.0003  max mem: 2904
Test: [Task 1]  [1450/1627]  eta: 0:00:43  Loss: 0.5731 (0.4774)  Acc@1: 87.5000 (90.4850)  Acc@5: 100.0000 (98.9361)  time: 0.2427  data: 0.0003  max mem: 2904
Test: [Task 1]  [1460/1627]  eta: 0:00:40  Loss: 0.4672 (0.4773)  Acc@1: 87.5000 (90.4860)  Acc@5: 100.0000 (98.9348)  time: 0.2429  data: 0.0003  max mem: 2904
Test: [Task 1]  [1470/1627]  eta: 0:00:38  Loss: 0.3533 (0.4775)  Acc@1: 93.7500 (90.4912)  Acc@5: 100.0000 (98.9378)  time: 0.2421  data: 0.0003  max mem: 2904
Test: [Task 1]  [1480/1627]  eta: 0:00:36  Loss: 0.3758 (0.4780)  Acc@1: 87.5000 (90.4836)  Acc@5: 100.0000 (98.9407)  time: 0.2422  data: 0.0003  max mem: 2904
Test: [Task 1]  [1490/1627]  eta: 0:00:33  Loss: 0.4429 (0.4786)  Acc@1: 87.5000 (90.4804)  Acc@5: 100.0000 (98.9353)  time: 0.2424  data: 0.0003  max mem: 2904
Test: [Task 1]  [1500/1627]  eta: 0:00:31  Loss: 0.4307 (0.4787)  Acc@1: 93.7500 (90.4772)  Acc@5: 100.0000 (98.9340)  time: 0.2425  data: 0.0003  max mem: 2904
Test: [Task 1]  [1510/1627]  eta: 0:00:28  Loss: 0.4574 (0.4794)  Acc@1: 93.7500 (90.4616)  Acc@5: 100.0000 (98.9287)  time: 0.2423  data: 0.0003  max mem: 2904
Test: [Task 1]  [1520/1627]  eta: 0:00:26  Loss: 0.4302 (0.4787)  Acc@1: 93.7500 (90.4832)  Acc@5: 100.0000 (98.9275)  time: 0.2425  data: 0.0003  max mem: 2904
Test: [Task 1]  [1530/1627]  eta: 0:00:23  Loss: 0.4302 (0.4789)  Acc@1: 93.7500 (90.4719)  Acc@5: 100.0000 (98.9264)  time: 0.2428  data: 0.0004  max mem: 2904
Test: [Task 1]  [1540/1627]  eta: 0:00:21  Loss: 0.3439 (0.4780)  Acc@1: 93.7500 (90.5013)  Acc@5: 100.0000 (98.9333)  time: 0.2426  data: 0.0003  max mem: 2904
Test: [Task 1]  [1550/1627]  eta: 0:00:18  Loss: 0.2779 (0.4774)  Acc@1: 93.7500 (90.5102)  Acc@5: 100.0000 (98.9321)  time: 0.2426  data: 0.0003  max mem: 2904
Test: [Task 1]  [1560/1627]  eta: 0:00:16  Loss: 0.3121 (0.4771)  Acc@1: 93.7500 (90.5229)  Acc@5: 100.0000 (98.9350)  time: 0.2427  data: 0.0003  max mem: 2904
Test: [Task 1]  [1570/1627]  eta: 0:00:13  Loss: 0.3771 (0.4770)  Acc@1: 93.7500 (90.5355)  Acc@5: 100.0000 (98.9338)  time: 0.2433  data: 0.0003  max mem: 2904
Test: [Task 1]  [1580/1627]  eta: 0:00:11  Loss: 0.4465 (0.4768)  Acc@1: 93.7500 (90.5361)  Acc@5: 100.0000 (98.9405)  time: 0.2431  data: 0.0003  max mem: 2904
Test: [Task 1]  [1590/1627]  eta: 0:00:09  Loss: 0.4671 (0.4765)  Acc@1: 87.5000 (90.5209)  Acc@5: 100.0000 (98.9472)  time: 0.2426  data: 0.0003  max mem: 2904
Test: [Task 1]  [1600/1627]  eta: 0:00:06  Loss: 0.4961 (0.4774)  Acc@1: 87.5000 (90.4864)  Acc@5: 100.0000 (98.9382)  time: 0.2429  data: 0.0003  max mem: 2904
Test: [Task 1]  [1610/1627]  eta: 0:00:04  Loss: 0.3783 (0.4768)  Acc@1: 87.5000 (90.5028)  Acc@5: 100.0000 (98.9409)  time: 0.2431  data: 0.0003  max mem: 2904
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.3359 (0.4762)  Acc@1: 93.7500 (90.5151)  Acc@5: 100.0000 (98.9436)  time: 0.2432  data: 0.0003  max mem: 2904
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.3761 (0.4757)  Acc@1: 93.7500 (90.5155)  Acc@5: 100.0000 (98.9474)  time: 0.2427  data: 0.0003  max mem: 2904
Test: [Task 1] Total time: 0:06:38 (0.2452 s / it)
* Acc@1 90.516 Acc@5 98.947 loss 0.476
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 26032, 5: 26032, 6: 26032, 7: 26032, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}}
[Average accuracy till task1]	Acc@1: 90.5155	Acc@5: 98.9474	Loss: 0.4757
Train: Epoch[1/5]  [   0/3750]  eta: 0:49:05  Lr: 0.030000  Loss: 2.3656  Acc@1: 18.7500 (18.7500)  Acc@5: 31.2500 (31.2500)  time: 0.7854  data: 0.3749  max mem: 2904
Train: Epoch[1/5]  [  10/3750]  eta: 0:26:36  Lr: 0.030000  Loss: 0.5292  Acc@1: 37.5000 (35.2273)  Acc@5: 68.7500 (71.0227)  time: 0.4270  data: 0.0344  max mem: 2908
Train: Epoch[1/5]  [  20/3750]  eta: 0:25:29  Lr: 0.030000  Loss: -0.9561  Acc@1: 43.7500 (40.4762)  Acc@5: 87.5000 (81.2500)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [  30/3750]  eta: 0:25:02  Lr: 0.030000  Loss: -1.3190  Acc@1: 50.0000 (44.5565)  Acc@5: 93.7500 (84.2742)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [  40/3750]  eta: 0:24:47  Lr: 0.030000  Loss: -1.6444  Acc@1: 56.2500 (48.7805)  Acc@5: 93.7500 (86.5854)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [  50/3750]  eta: 0:24:36  Lr: 0.030000  Loss: -1.6502  Acc@1: 56.2500 (49.8775)  Acc@5: 93.7500 (87.1324)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [  60/3750]  eta: 0:24:28  Lr: 0.030000  Loss: -0.7097  Acc@1: 50.0000 (51.3320)  Acc@5: 87.5000 (86.8852)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [  70/3750]  eta: 0:24:21  Lr: 0.030000  Loss: -2.0730  Acc@1: 56.2500 (52.2007)  Acc@5: 87.5000 (87.3239)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [  80/3750]  eta: 0:24:15  Lr: 0.030000  Loss: -2.0019  Acc@1: 56.2500 (53.4722)  Acc@5: 93.7500 (88.0401)  time: 0.3922  data: 0.0010  max mem: 2908
Train: Epoch[1/5]  [  90/3750]  eta: 0:24:09  Lr: 0.030000  Loss: -1.5051  Acc@1: 56.2500 (54.3269)  Acc@5: 93.7500 (88.8049)  time: 0.3916  data: 0.0010  max mem: 2908
Train: Epoch[1/5]  [ 100/3750]  eta: 0:24:03  Lr: 0.030000  Loss: -1.9535  Acc@1: 56.2500 (54.4554)  Acc@5: 93.7500 (89.2946)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 110/3750]  eta: 0:23:58  Lr: 0.030000  Loss: -1.9882  Acc@1: 68.7500 (55.6869)  Acc@5: 93.7500 (89.5833)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 120/3750]  eta: 0:23:53  Lr: 0.030000  Loss: -2.2294  Acc@1: 62.5000 (56.4050)  Acc@5: 93.7500 (89.8760)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 130/3750]  eta: 0:23:48  Lr: 0.030000  Loss: -2.0568  Acc@1: 62.5000 (56.9656)  Acc@5: 93.7500 (90.0286)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 140/3750]  eta: 0:23:43  Lr: 0.030000  Loss: -1.8520  Acc@1: 62.5000 (57.7571)  Acc@5: 93.7500 (90.1596)  time: 0.3916  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 150/3750]  eta: 0:23:39  Lr: 0.030000  Loss: -2.2974  Acc@1: 62.5000 (58.3609)  Acc@5: 93.7500 (90.4801)  time: 0.3921  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 160/3750]  eta: 0:23:34  Lr: 0.030000  Loss: -2.6193  Acc@1: 68.7500 (59.2003)  Acc@5: 93.7500 (90.5668)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 170/3750]  eta: 0:23:30  Lr: 0.030000  Loss: -2.4418  Acc@1: 68.7500 (59.7953)  Acc@5: 93.7500 (90.7895)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 180/3750]  eta: 0:23:25  Lr: 0.030000  Loss: -1.7809  Acc@1: 68.7500 (60.4627)  Acc@5: 93.7500 (90.9530)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 190/3750]  eta: 0:23:21  Lr: 0.030000  Loss: -2.0443  Acc@1: 68.7500 (60.7330)  Acc@5: 93.7500 (91.0340)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 200/3750]  eta: 0:23:17  Lr: 0.030000  Loss: -1.9088  Acc@1: 68.7500 (61.2562)  Acc@5: 93.7500 (91.2935)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 210/3750]  eta: 0:23:13  Lr: 0.030000  Loss: -2.2145  Acc@1: 75.0000 (61.7299)  Acc@5: 93.7500 (91.4100)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 220/3750]  eta: 0:23:08  Lr: 0.030000  Loss: -1.4202  Acc@1: 62.5000 (61.7081)  Acc@5: 93.7500 (91.4027)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 230/3750]  eta: 0:23:05  Lr: 0.030000  Loss: -2.1348  Acc@1: 62.5000 (61.8236)  Acc@5: 93.7500 (91.5314)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 240/3750]  eta: 0:23:00  Lr: 0.030000  Loss: -2.3017  Acc@1: 62.5000 (61.9035)  Acc@5: 93.7500 (91.5716)  time: 0.3934  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 250/3750]  eta: 0:22:56  Lr: 0.030000  Loss: -2.1511  Acc@1: 68.7500 (62.2759)  Acc@5: 93.7500 (91.6335)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 260/3750]  eta: 0:22:52  Lr: 0.030000  Loss: -2.3956  Acc@1: 68.7500 (62.5718)  Acc@5: 93.7500 (91.7625)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 270/3750]  eta: 0:22:48  Lr: 0.030000  Loss: -1.5126  Acc@1: 68.7500 (62.7768)  Acc@5: 93.7500 (91.8358)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 280/3750]  eta: 0:22:44  Lr: 0.030000  Loss: -2.4226  Acc@1: 62.5000 (63.1673)  Acc@5: 93.7500 (91.9262)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 290/3750]  eta: 0:22:40  Lr: 0.030000  Loss: -0.8674  Acc@1: 68.7500 (63.2517)  Acc@5: 93.7500 (91.9244)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 300/3750]  eta: 0:22:36  Lr: 0.030000  Loss: -2.4271  Acc@1: 68.7500 (63.5174)  Acc@5: 93.7500 (91.9435)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 310/3750]  eta: 0:22:31  Lr: 0.030000  Loss: -1.9763  Acc@1: 68.7500 (63.6455)  Acc@5: 93.7500 (92.0217)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 320/3750]  eta: 0:22:27  Lr: 0.030000  Loss: -2.2433  Acc@1: 68.7500 (63.9798)  Acc@5: 93.7500 (92.1340)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 330/3750]  eta: 0:22:23  Lr: 0.030000  Loss: -2.1490  Acc@1: 68.7500 (64.1805)  Acc@5: 93.7500 (92.2583)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 340/3750]  eta: 0:22:19  Lr: 0.030000  Loss: -1.6462  Acc@1: 68.7500 (64.3328)  Acc@5: 93.7500 (92.3570)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 350/3750]  eta: 0:22:15  Lr: 0.030000  Loss: -2.3540  Acc@1: 68.7500 (64.5833)  Acc@5: 93.7500 (92.3611)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 360/3750]  eta: 0:22:11  Lr: 0.030000  Loss: -2.4183  Acc@1: 75.0000 (64.8892)  Acc@5: 93.7500 (92.4169)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 370/3750]  eta: 0:22:07  Lr: 0.030000  Loss: -2.1436  Acc@1: 75.0000 (64.9596)  Acc@5: 93.7500 (92.4023)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 380/3750]  eta: 0:22:03  Lr: 0.030000  Loss: -2.6789  Acc@1: 75.0000 (65.3051)  Acc@5: 93.7500 (92.5361)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 390/3750]  eta: 0:21:58  Lr: 0.030000  Loss: -2.3679  Acc@1: 75.0000 (65.4731)  Acc@5: 93.7500 (92.5512)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 400/3750]  eta: 0:21:54  Lr: 0.030000  Loss: -2.7358  Acc@1: 75.0000 (65.6951)  Acc@5: 93.7500 (92.6590)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 410/3750]  eta: 0:21:50  Lr: 0.030000  Loss: -1.9179  Acc@1: 68.7500 (65.7999)  Acc@5: 93.7500 (92.7007)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 420/3750]  eta: 0:21:46  Lr: 0.030000  Loss: -1.9243  Acc@1: 68.7500 (65.8551)  Acc@5: 93.7500 (92.7405)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 430/3750]  eta: 0:21:42  Lr: 0.030000  Loss: -2.2462  Acc@1: 68.7500 (65.9513)  Acc@5: 93.7500 (92.7929)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 440/3750]  eta: 0:21:38  Lr: 0.030000  Loss: -1.6621  Acc@1: 68.7500 (66.1706)  Acc@5: 93.7500 (92.8430)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 450/3750]  eta: 0:21:34  Lr: 0.030000  Loss: -2.2102  Acc@1: 75.0000 (66.3387)  Acc@5: 93.7500 (92.8769)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 460/3750]  eta: 0:21:30  Lr: 0.030000  Loss: -2.5521  Acc@1: 75.0000 (66.4995)  Acc@5: 93.7500 (92.9366)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 470/3750]  eta: 0:21:26  Lr: 0.030000  Loss: -2.5641  Acc@1: 68.7500 (66.5207)  Acc@5: 93.7500 (92.9273)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 480/3750]  eta: 0:21:22  Lr: 0.030000  Loss: -2.5632  Acc@1: 68.7500 (66.6580)  Acc@5: 93.7500 (92.9704)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 490/3750]  eta: 0:21:18  Lr: 0.030000  Loss: -1.7880  Acc@1: 68.7500 (66.7897)  Acc@5: 93.7500 (92.9353)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 500/3750]  eta: 0:21:14  Lr: 0.030000  Loss: -1.6038  Acc@1: 75.0000 (66.9536)  Acc@5: 93.7500 (92.9765)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 510/3750]  eta: 0:21:10  Lr: 0.030000  Loss: -2.1916  Acc@1: 68.7500 (67.0132)  Acc@5: 93.7500 (93.0406)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 520/3750]  eta: 0:21:06  Lr: 0.030000  Loss: -1.8609  Acc@1: 68.7500 (67.0465)  Acc@5: 93.7500 (93.0542)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 530/3750]  eta: 0:21:02  Lr: 0.030000  Loss: -2.4126  Acc@1: 75.0000 (67.1139)  Acc@5: 93.7500 (93.0673)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 540/3750]  eta: 0:20:58  Lr: 0.030000  Loss: -2.4942  Acc@1: 75.0000 (67.2828)  Acc@5: 93.7500 (93.1262)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 550/3750]  eta: 0:20:54  Lr: 0.030000  Loss: -2.6240  Acc@1: 75.0000 (67.4002)  Acc@5: 100.0000 (93.1602)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 560/3750]  eta: 0:20:50  Lr: 0.030000  Loss: -2.3002  Acc@1: 75.0000 (67.5802)  Acc@5: 93.7500 (93.1818)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 570/3750]  eta: 0:20:46  Lr: 0.030000  Loss: -2.4091  Acc@1: 75.0000 (67.7102)  Acc@5: 93.7500 (93.2027)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 580/3750]  eta: 0:20:42  Lr: 0.030000  Loss: -2.5329  Acc@1: 75.0000 (67.8356)  Acc@5: 93.7500 (93.2444)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 590/3750]  eta: 0:20:38  Lr: 0.030000  Loss: -2.5654  Acc@1: 75.0000 (67.9040)  Acc@5: 93.7500 (93.2847)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 600/3750]  eta: 0:20:34  Lr: 0.030000  Loss: -2.5225  Acc@1: 68.7500 (68.0324)  Acc@5: 93.7500 (93.3236)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 610/3750]  eta: 0:20:30  Lr: 0.030000  Loss: -2.6031  Acc@1: 75.0000 (68.1465)  Acc@5: 93.7500 (93.3204)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 620/3750]  eta: 0:20:26  Lr: 0.030000  Loss: -2.0042  Acc@1: 75.0000 (68.1763)  Acc@5: 93.7500 (93.2770)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 630/3750]  eta: 0:20:22  Lr: 0.030000  Loss: -2.3475  Acc@1: 68.7500 (68.1953)  Acc@5: 93.7500 (93.2349)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 640/3750]  eta: 0:20:18  Lr: 0.030000  Loss: -2.5762  Acc@1: 75.0000 (68.2917)  Acc@5: 93.7500 (93.2820)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 650/3750]  eta: 0:20:14  Lr: 0.030000  Loss: -2.6203  Acc@1: 75.0000 (68.4812)  Acc@5: 100.0000 (93.3564)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 660/3750]  eta: 0:20:10  Lr: 0.030000  Loss: -1.9995  Acc@1: 75.0000 (68.5420)  Acc@5: 100.0000 (93.3718)  time: 0.3925  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 670/3750]  eta: 0:20:06  Lr: 0.030000  Loss: -2.8358  Acc@1: 75.0000 (68.6848)  Acc@5: 93.7500 (93.3961)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 680/3750]  eta: 0:20:03  Lr: 0.030000  Loss: -2.0681  Acc@1: 75.0000 (68.7959)  Acc@5: 93.7500 (93.4380)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 690/3750]  eta: 0:19:59  Lr: 0.030000  Loss: -2.3150  Acc@1: 75.0000 (68.8133)  Acc@5: 93.7500 (93.4515)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 700/3750]  eta: 0:19:55  Lr: 0.030000  Loss: -2.3770  Acc@1: 75.0000 (68.8837)  Acc@5: 93.7500 (93.4914)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 710/3750]  eta: 0:19:51  Lr: 0.030000  Loss: -2.5396  Acc@1: 75.0000 (68.9522)  Acc@5: 93.7500 (93.4775)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 720/3750]  eta: 0:19:47  Lr: 0.030000  Loss: -2.2776  Acc@1: 68.7500 (68.9840)  Acc@5: 93.7500 (93.4813)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 730/3750]  eta: 0:19:43  Lr: 0.030000  Loss: -2.1208  Acc@1: 75.0000 (69.1433)  Acc@5: 100.0000 (93.5363)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 740/3750]  eta: 0:19:39  Lr: 0.030000  Loss: -2.2563  Acc@1: 75.0000 (69.1549)  Acc@5: 93.7500 (93.5223)  time: 0.3915  data: 0.0010  max mem: 2908
Train: Epoch[1/5]  [ 750/3750]  eta: 0:19:35  Lr: 0.030000  Loss: -1.9661  Acc@1: 68.7500 (69.1828)  Acc@5: 93.7500 (93.5419)  time: 0.3944  data: 0.0010  max mem: 2908
Train: Epoch[1/5]  [ 760/3750]  eta: 0:19:31  Lr: 0.030000  Loss: -2.7640  Acc@1: 75.0000 (69.2920)  Acc@5: 93.7500 (93.5611)  time: 0.3959  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 770/3750]  eta: 0:19:28  Lr: 0.030000  Loss: -2.2246  Acc@1: 75.0000 (69.3418)  Acc@5: 93.7500 (93.5798)  time: 0.3948  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 780/3750]  eta: 0:19:24  Lr: 0.030000  Loss: -2.1201  Acc@1: 75.0000 (69.3982)  Acc@5: 93.7500 (93.6220)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 790/3750]  eta: 0:19:20  Lr: 0.030000  Loss: -2.6217  Acc@1: 75.0000 (69.5322)  Acc@5: 100.0000 (93.6552)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 800/3750]  eta: 0:19:16  Lr: 0.030000  Loss: -1.9770  Acc@1: 75.0000 (69.6551)  Acc@5: 100.0000 (93.6798)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 810/3750]  eta: 0:19:12  Lr: 0.030000  Loss: -2.1244  Acc@1: 75.0000 (69.6902)  Acc@5: 93.7500 (93.6883)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 820/3750]  eta: 0:19:08  Lr: 0.030000  Loss: -1.9430  Acc@1: 75.0000 (69.6940)  Acc@5: 93.7500 (93.6967)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 830/3750]  eta: 0:19:04  Lr: 0.030000  Loss: -2.4486  Acc@1: 75.0000 (69.7353)  Acc@5: 93.7500 (93.7049)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 840/3750]  eta: 0:19:00  Lr: 0.030000  Loss: -2.5476  Acc@1: 75.0000 (69.7979)  Acc@5: 93.7500 (93.7426)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 850/3750]  eta: 0:18:56  Lr: 0.030000  Loss: -2.1705  Acc@1: 81.2500 (69.8516)  Acc@5: 93.7500 (93.7500)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 860/3750]  eta: 0:18:52  Lr: 0.030000  Loss: -2.2996  Acc@1: 81.2500 (69.9695)  Acc@5: 93.7500 (93.7863)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 870/3750]  eta: 0:18:48  Lr: 0.030000  Loss: -1.7191  Acc@1: 75.0000 (70.0344)  Acc@5: 100.0000 (93.7931)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 880/3750]  eta: 0:18:44  Lr: 0.030000  Loss: -2.0481  Acc@1: 75.0000 (70.0482)  Acc@5: 93.7500 (93.7571)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 890/3750]  eta: 0:18:40  Lr: 0.030000  Loss: -2.3965  Acc@1: 75.0000 (70.1038)  Acc@5: 87.5000 (93.7290)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 900/3750]  eta: 0:18:36  Lr: 0.030000  Loss: -2.2438  Acc@1: 75.0000 (70.1651)  Acc@5: 93.7500 (93.7431)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 910/3750]  eta: 0:18:32  Lr: 0.030000  Loss: -1.6192  Acc@1: 75.0000 (70.2731)  Acc@5: 93.7500 (93.7637)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 920/3750]  eta: 0:18:29  Lr: 0.030000  Loss: -2.4519  Acc@1: 75.0000 (70.2769)  Acc@5: 93.7500 (93.7432)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 930/3750]  eta: 0:18:25  Lr: 0.030000  Loss: -1.2440  Acc@1: 68.7500 (70.2940)  Acc@5: 93.7500 (93.7299)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 940/3750]  eta: 0:18:21  Lr: 0.030000  Loss: -1.8109  Acc@1: 75.0000 (70.3308)  Acc@5: 93.7500 (93.7500)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 950/3750]  eta: 0:18:17  Lr: 0.030000  Loss: -1.9614  Acc@1: 75.0000 (70.3667)  Acc@5: 93.7500 (93.7369)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 960/3750]  eta: 0:18:13  Lr: 0.030000  Loss: -2.7826  Acc@1: 75.0000 (70.4344)  Acc@5: 93.7500 (93.7435)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [ 970/3750]  eta: 0:18:09  Lr: 0.030000  Loss: -2.7490  Acc@1: 75.0000 (70.5072)  Acc@5: 93.7500 (93.7693)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 980/3750]  eta: 0:18:05  Lr: 0.030000  Loss: -2.7321  Acc@1: 75.0000 (70.5212)  Acc@5: 100.0000 (93.8010)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [ 990/3750]  eta: 0:18:01  Lr: 0.030000  Loss: -2.4646  Acc@1: 75.0000 (70.6168)  Acc@5: 93.7500 (93.8005)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1000/3750]  eta: 0:17:57  Lr: 0.030000  Loss: -1.8599  Acc@1: 75.0000 (70.6169)  Acc@5: 93.7500 (93.8000)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1010/3750]  eta: 0:17:53  Lr: 0.030000  Loss: -2.4602  Acc@1: 75.0000 (70.6664)  Acc@5: 93.7500 (93.8056)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1020/3750]  eta: 0:17:49  Lr: 0.030000  Loss: -2.2521  Acc@1: 75.0000 (70.7333)  Acc@5: 93.7500 (93.8173)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1030/3750]  eta: 0:17:45  Lr: 0.030000  Loss: -2.4673  Acc@1: 75.0000 (70.7505)  Acc@5: 93.7500 (93.8288)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1040/3750]  eta: 0:17:41  Lr: 0.030000  Loss: -2.0696  Acc@1: 81.2500 (70.8573)  Acc@5: 100.0000 (93.8581)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1050/3750]  eta: 0:17:37  Lr: 0.030000  Loss: -2.3357  Acc@1: 75.0000 (70.8492)  Acc@5: 93.7500 (93.8392)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1060/3750]  eta: 0:17:33  Lr: 0.030000  Loss: -1.8191  Acc@1: 75.0000 (70.8765)  Acc@5: 93.7500 (93.8266)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1070/3750]  eta: 0:17:29  Lr: 0.030000  Loss: -2.1770  Acc@1: 75.0000 (70.9442)  Acc@5: 93.7500 (93.8025)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1080/3750]  eta: 0:17:26  Lr: 0.030000  Loss: -2.1829  Acc@1: 75.0000 (70.9528)  Acc@5: 93.7500 (93.8078)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1090/3750]  eta: 0:17:22  Lr: 0.030000  Loss: -2.0606  Acc@1: 75.0000 (71.0071)  Acc@5: 93.7500 (93.8187)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1100/3750]  eta: 0:17:18  Lr: 0.030000  Loss: -2.7110  Acc@1: 75.0000 (71.0774)  Acc@5: 93.7500 (93.8295)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1110/3750]  eta: 0:17:14  Lr: 0.030000  Loss: -2.9814  Acc@1: 75.0000 (71.1634)  Acc@5: 93.7500 (93.8344)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1120/3750]  eta: 0:17:10  Lr: 0.030000  Loss: -2.0862  Acc@1: 81.2500 (71.2645)  Acc@5: 93.7500 (93.8671)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1130/3750]  eta: 0:17:06  Lr: 0.030000  Loss: -2.2900  Acc@1: 81.2500 (71.2920)  Acc@5: 100.0000 (93.8826)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1140/3750]  eta: 0:17:02  Lr: 0.030000  Loss: -2.5548  Acc@1: 75.0000 (71.3409)  Acc@5: 100.0000 (93.8979)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1150/3750]  eta: 0:16:58  Lr: 0.030000  Loss: -1.9865  Acc@1: 68.7500 (71.3401)  Acc@5: 93.7500 (93.9020)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1160/3750]  eta: 0:16:54  Lr: 0.030000  Loss: -1.9194  Acc@1: 75.0000 (71.4093)  Acc@5: 93.7500 (93.9276)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1170/3750]  eta: 0:16:50  Lr: 0.030000  Loss: -2.2518  Acc@1: 81.2500 (71.5307)  Acc@5: 93.7500 (93.9528)  time: 0.3898  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1180/3750]  eta: 0:16:46  Lr: 0.030000  Loss: -2.2582  Acc@1: 81.2500 (71.5548)  Acc@5: 93.7500 (93.9670)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1190/3750]  eta: 0:16:42  Lr: 0.030000  Loss: -2.4432  Acc@1: 81.2500 (71.6100)  Acc@5: 93.7500 (93.9704)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1200/3750]  eta: 0:16:38  Lr: 0.030000  Loss: -2.1636  Acc@1: 81.2500 (71.7215)  Acc@5: 93.7500 (93.9894)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1210/3750]  eta: 0:16:34  Lr: 0.030000  Loss: -2.0301  Acc@1: 81.2500 (71.7640)  Acc@5: 93.7500 (94.0184)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1220/3750]  eta: 0:16:30  Lr: 0.030000  Loss: -2.4049  Acc@1: 75.0000 (71.8417)  Acc@5: 100.0000 (94.0315)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1230/3750]  eta: 0:16:26  Lr: 0.030000  Loss: -2.3766  Acc@1: 81.2500 (71.9029)  Acc@5: 100.0000 (94.0496)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1240/3750]  eta: 0:16:22  Lr: 0.030000  Loss: -1.9283  Acc@1: 75.0000 (71.9027)  Acc@5: 93.7500 (94.0572)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1250/3750]  eta: 0:16:19  Lr: 0.030000  Loss: -1.7963  Acc@1: 68.7500 (71.9175)  Acc@5: 93.7500 (94.0548)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1260/3750]  eta: 0:16:15  Lr: 0.030000  Loss: -2.2966  Acc@1: 75.0000 (71.9370)  Acc@5: 93.7500 (94.0573)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1270/3750]  eta: 0:16:11  Lr: 0.030000  Loss: -2.1488  Acc@1: 75.0000 (72.0053)  Acc@5: 93.7500 (94.0844)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1280/3750]  eta: 0:16:07  Lr: 0.030000  Loss: -2.2116  Acc@1: 75.0000 (72.0580)  Acc@5: 100.0000 (94.0964)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1290/3750]  eta: 0:16:03  Lr: 0.030000  Loss: -2.6365  Acc@1: 81.2500 (72.1146)  Acc@5: 93.7500 (94.1131)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1300/3750]  eta: 0:15:59  Lr: 0.030000  Loss: -2.1825  Acc@1: 81.2500 (72.1320)  Acc@5: 93.7500 (94.1199)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1310/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -2.4768  Acc@1: 75.0000 (72.1682)  Acc@5: 93.7500 (94.1362)  time: 0.3895  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1320/3750]  eta: 0:15:51  Lr: 0.030000  Loss: -2.5588  Acc@1: 81.2500 (72.2559)  Acc@5: 100.0000 (94.1569)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1330/3750]  eta: 0:15:47  Lr: 0.030000  Loss: -1.9167  Acc@1: 81.2500 (72.2812)  Acc@5: 93.7500 (94.1210)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1340/3750]  eta: 0:15:43  Lr: 0.030000  Loss: -2.6696  Acc@1: 75.0000 (72.3061)  Acc@5: 93.7500 (94.1462)  time: 0.3926  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1350/3750]  eta: 0:15:39  Lr: 0.030000  Loss: -2.5339  Acc@1: 75.0000 (72.3353)  Acc@5: 100.0000 (94.1432)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1360/3750]  eta: 0:15:35  Lr: 0.030000  Loss: -2.6743  Acc@1: 81.2500 (72.3733)  Acc@5: 93.7500 (94.1587)  time: 0.3939  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1370/3750]  eta: 0:15:31  Lr: 0.030000  Loss: -2.2597  Acc@1: 75.0000 (72.3833)  Acc@5: 93.7500 (94.1512)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1380/3750]  eta: 0:15:28  Lr: 0.030000  Loss: -2.0119  Acc@1: 68.7500 (72.4022)  Acc@5: 93.7500 (94.1709)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1390/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -1.9812  Acc@1: 81.2500 (72.4524)  Acc@5: 93.7500 (94.1724)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1400/3750]  eta: 0:15:20  Lr: 0.030000  Loss: -2.4610  Acc@1: 81.2500 (72.4929)  Acc@5: 93.7500 (94.1916)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1410/3750]  eta: 0:15:16  Lr: 0.030000  Loss: -1.9667  Acc@1: 68.7500 (72.4663)  Acc@5: 93.7500 (94.1929)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1420/3750]  eta: 0:15:12  Lr: 0.030000  Loss: -2.4538  Acc@1: 68.7500 (72.4578)  Acc@5: 93.7500 (94.1986)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1430/3750]  eta: 0:15:08  Lr: 0.030000  Loss: -2.8390  Acc@1: 75.0000 (72.4886)  Acc@5: 93.7500 (94.2042)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1440/3750]  eta: 0:15:04  Lr: 0.030000  Loss: -1.9925  Acc@1: 75.0000 (72.5191)  Acc@5: 93.7500 (94.2054)  time: 0.3921  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1450/3750]  eta: 0:15:00  Lr: 0.030000  Loss: -2.4017  Acc@1: 75.0000 (72.5620)  Acc@5: 100.0000 (94.2152)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1460/3750]  eta: 0:14:56  Lr: 0.030000  Loss: -2.5965  Acc@1: 81.2500 (72.6215)  Acc@5: 100.0000 (94.2377)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1470/3750]  eta: 0:14:52  Lr: 0.030000  Loss: -2.7533  Acc@1: 81.2500 (72.6462)  Acc@5: 100.0000 (94.2641)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1480/3750]  eta: 0:14:48  Lr: 0.030000  Loss: -2.6637  Acc@1: 75.0000 (72.6663)  Acc@5: 93.7500 (94.2733)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1490/3750]  eta: 0:14:44  Lr: 0.030000  Loss: -2.0279  Acc@1: 75.0000 (72.6945)  Acc@5: 93.7500 (94.2907)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1500/3750]  eta: 0:14:40  Lr: 0.030000  Loss: -2.2532  Acc@1: 75.0000 (72.7473)  Acc@5: 100.0000 (94.3038)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1510/3750]  eta: 0:14:37  Lr: 0.030000  Loss: -2.1660  Acc@1: 81.2500 (72.7912)  Acc@5: 100.0000 (94.3043)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1520/3750]  eta: 0:14:33  Lr: 0.030000  Loss: -2.2246  Acc@1: 75.0000 (72.8016)  Acc@5: 100.0000 (94.3171)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1530/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -2.3177  Acc@1: 75.0000 (72.8323)  Acc@5: 100.0000 (94.3297)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1540/3750]  eta: 0:14:25  Lr: 0.030000  Loss: -2.1032  Acc@1: 75.0000 (72.8626)  Acc@5: 93.7500 (94.3381)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1550/3750]  eta: 0:14:21  Lr: 0.030000  Loss: -2.2579  Acc@1: 75.0000 (72.8844)  Acc@5: 100.0000 (94.3544)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1560/3750]  eta: 0:14:17  Lr: 0.030000  Loss: -2.5599  Acc@1: 81.2500 (72.9340)  Acc@5: 100.0000 (94.3706)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1570/3750]  eta: 0:14:13  Lr: 0.030000  Loss: -2.1409  Acc@1: 81.2500 (72.9551)  Acc@5: 100.0000 (94.3905)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1580/3750]  eta: 0:14:09  Lr: 0.030000  Loss: -2.6293  Acc@1: 75.0000 (72.9878)  Acc@5: 100.0000 (94.4102)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1590/3750]  eta: 0:14:05  Lr: 0.030000  Loss: -1.6315  Acc@1: 75.0000 (72.9887)  Acc@5: 100.0000 (94.4139)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1600/3750]  eta: 0:14:01  Lr: 0.030000  Loss: -2.2938  Acc@1: 75.0000 (73.0286)  Acc@5: 93.7500 (94.4136)  time: 0.3923  data: 0.0011  max mem: 2908
Train: Epoch[1/5]  [1610/3750]  eta: 0:13:57  Lr: 0.030000  Loss: -2.0819  Acc@1: 81.2500 (73.1029)  Acc@5: 93.7500 (94.4289)  time: 0.3920  data: 0.0011  max mem: 2908
Train: Epoch[1/5]  [1620/3750]  eta: 0:13:53  Lr: 0.030000  Loss: -2.1278  Acc@1: 87.5000 (73.1763)  Acc@5: 100.0000 (94.4286)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1630/3750]  eta: 0:13:50  Lr: 0.030000  Loss: -2.5107  Acc@1: 75.0000 (73.1606)  Acc@5: 93.7500 (94.4283)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1640/3750]  eta: 0:13:46  Lr: 0.030000  Loss: -2.5844  Acc@1: 75.0000 (73.1833)  Acc@5: 93.7500 (94.4432)  time: 0.3916  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1650/3750]  eta: 0:13:42  Lr: 0.030000  Loss: -2.5568  Acc@1: 75.0000 (73.1905)  Acc@5: 93.7500 (94.4428)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1660/3750]  eta: 0:13:38  Lr: 0.030000  Loss: -2.4849  Acc@1: 75.0000 (73.2014)  Acc@5: 93.7500 (94.4424)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1670/3750]  eta: 0:13:34  Lr: 0.030000  Loss: -1.9244  Acc@1: 81.2500 (73.2683)  Acc@5: 93.7500 (94.4532)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1680/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -2.1359  Acc@1: 75.0000 (73.2562)  Acc@5: 93.7500 (94.4341)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1690/3750]  eta: 0:13:26  Lr: 0.030000  Loss: -2.8063  Acc@1: 75.0000 (73.2887)  Acc@5: 93.7500 (94.4559)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1700/3750]  eta: 0:13:22  Lr: 0.030000  Loss: -1.7213  Acc@1: 75.0000 (73.2951)  Acc@5: 93.7500 (94.4408)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1710/3750]  eta: 0:13:18  Lr: 0.030000  Loss: -1.9983  Acc@1: 75.0000 (73.2868)  Acc@5: 93.7500 (94.4367)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1720/3750]  eta: 0:13:14  Lr: 0.030000  Loss: -2.1447  Acc@1: 75.0000 (73.3258)  Acc@5: 93.7500 (94.4255)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1730/3750]  eta: 0:13:10  Lr: 0.030000  Loss: -2.0259  Acc@1: 75.0000 (73.3427)  Acc@5: 100.0000 (94.4360)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1740/3750]  eta: 0:13:06  Lr: 0.030000  Loss: -2.8114  Acc@1: 75.0000 (73.3810)  Acc@5: 100.0000 (94.4500)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1750/3750]  eta: 0:13:03  Lr: 0.030000  Loss: -2.0674  Acc@1: 81.2500 (73.4188)  Acc@5: 93.7500 (94.4425)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1760/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -2.3045  Acc@1: 81.2500 (73.4277)  Acc@5: 93.7500 (94.4385)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1770/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -1.8832  Acc@1: 81.2500 (73.4649)  Acc@5: 100.0000 (94.4558)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1780/3750]  eta: 0:12:51  Lr: 0.030000  Loss: -2.6596  Acc@1: 81.2500 (73.5366)  Acc@5: 100.0000 (94.4729)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1790/3750]  eta: 0:12:47  Lr: 0.030000  Loss: -2.4007  Acc@1: 87.5000 (73.5797)  Acc@5: 100.0000 (94.4828)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1800/3750]  eta: 0:12:43  Lr: 0.030000  Loss: -2.3480  Acc@1: 81.2500 (73.6154)  Acc@5: 93.7500 (94.4892)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1810/3750]  eta: 0:12:39  Lr: 0.030000  Loss: -2.8698  Acc@1: 81.2500 (73.6610)  Acc@5: 93.7500 (94.4989)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1820/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -2.5553  Acc@1: 75.0000 (73.6752)  Acc@5: 93.7500 (94.5051)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1830/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -2.1735  Acc@1: 75.0000 (73.6995)  Acc@5: 93.7500 (94.5044)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1840/3750]  eta: 0:12:27  Lr: 0.030000  Loss: -2.3300  Acc@1: 75.0000 (73.7065)  Acc@5: 93.7500 (94.5139)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1850/3750]  eta: 0:12:23  Lr: 0.030000  Loss: -2.4911  Acc@1: 75.0000 (73.7270)  Acc@5: 100.0000 (94.5199)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1860/3750]  eta: 0:12:19  Lr: 0.030000  Loss: -2.8303  Acc@1: 75.0000 (73.7339)  Acc@5: 93.7500 (94.5090)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1870/3750]  eta: 0:12:15  Lr: 0.030000  Loss: -2.0598  Acc@1: 81.2500 (73.7607)  Acc@5: 93.7500 (94.5150)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1880/3750]  eta: 0:12:12  Lr: 0.030000  Loss: -2.3690  Acc@1: 81.2500 (73.7939)  Acc@5: 93.7500 (94.5175)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1890/3750]  eta: 0:12:08  Lr: 0.030000  Loss: -2.5741  Acc@1: 81.2500 (73.8366)  Acc@5: 100.0000 (94.5267)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1900/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -2.1689  Acc@1: 81.2500 (73.8592)  Acc@5: 100.0000 (94.5456)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1910/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -2.4785  Acc@1: 81.2500 (73.8913)  Acc@5: 100.0000 (94.5480)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1920/3750]  eta: 0:11:56  Lr: 0.030000  Loss: -2.6116  Acc@1: 75.0000 (73.8840)  Acc@5: 93.7500 (94.5471)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1930/3750]  eta: 0:11:52  Lr: 0.030000  Loss: -2.4114  Acc@1: 75.0000 (73.8995)  Acc@5: 100.0000 (94.5592)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1940/3750]  eta: 0:11:48  Lr: 0.030000  Loss: -2.2592  Acc@1: 81.2500 (73.9245)  Acc@5: 100.0000 (94.5647)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1950/3750]  eta: 0:11:44  Lr: 0.030000  Loss: -1.8887  Acc@1: 75.0000 (73.9300)  Acc@5: 93.7500 (94.5733)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1960/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -2.5212  Acc@1: 81.2500 (73.9546)  Acc@5: 93.7500 (94.5850)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [1970/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -2.4983  Acc@1: 81.2500 (73.9789)  Acc@5: 100.0000 (94.5967)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1980/3750]  eta: 0:11:32  Lr: 0.030000  Loss: -2.2407  Acc@1: 75.0000 (73.9652)  Acc@5: 93.7500 (94.5924)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [1990/3750]  eta: 0:11:28  Lr: 0.030000  Loss: -2.7379  Acc@1: 68.7500 (73.9609)  Acc@5: 93.7500 (94.5850)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2000/3750]  eta: 0:11:24  Lr: 0.030000  Loss: -1.8007  Acc@1: 81.2500 (73.9849)  Acc@5: 93.7500 (94.5902)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2010/3750]  eta: 0:11:21  Lr: 0.030000  Loss: -2.2166  Acc@1: 81.2500 (74.0148)  Acc@5: 93.7500 (94.5860)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2020/3750]  eta: 0:11:17  Lr: 0.030000  Loss: -2.3095  Acc@1: 81.2500 (74.0444)  Acc@5: 93.7500 (94.5943)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2030/3750]  eta: 0:11:13  Lr: 0.030000  Loss: -2.8211  Acc@1: 75.0000 (74.0522)  Acc@5: 93.7500 (94.6024)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2040/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -2.3353  Acc@1: 75.0000 (74.0446)  Acc@5: 93.7500 (94.6013)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2050/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -2.3673  Acc@1: 75.0000 (74.0645)  Acc@5: 100.0000 (94.6124)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2060/3750]  eta: 0:11:01  Lr: 0.030000  Loss: -2.4481  Acc@1: 81.2500 (74.1054)  Acc@5: 100.0000 (94.6203)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2070/3750]  eta: 0:10:57  Lr: 0.030000  Loss: -1.9119  Acc@1: 81.2500 (74.1188)  Acc@5: 93.7500 (94.6252)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2080/3750]  eta: 0:10:53  Lr: 0.030000  Loss: -2.7038  Acc@1: 75.0000 (74.1320)  Acc@5: 93.7500 (94.6300)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2090/3750]  eta: 0:10:49  Lr: 0.030000  Loss: -2.6095  Acc@1: 75.0000 (74.1451)  Acc@5: 93.7500 (94.6437)  time: 0.3916  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2100/3750]  eta: 0:10:45  Lr: 0.030000  Loss: -2.6426  Acc@1: 75.0000 (74.1790)  Acc@5: 100.0000 (94.6454)  time: 0.3924  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2110/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -2.6385  Acc@1: 81.2500 (74.2125)  Acc@5: 93.7500 (94.6530)  time: 0.3926  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2120/3750]  eta: 0:10:37  Lr: 0.030000  Loss: -2.3431  Acc@1: 81.2500 (74.2633)  Acc@5: 100.0000 (94.6635)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2130/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -2.6711  Acc@1: 87.5000 (74.2961)  Acc@5: 100.0000 (94.6739)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2140/3750]  eta: 0:10:30  Lr: 0.030000  Loss: -2.3584  Acc@1: 81.2500 (74.3286)  Acc@5: 93.7500 (94.6725)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2150/3750]  eta: 0:10:26  Lr: 0.030000  Loss: -2.1888  Acc@1: 81.2500 (74.3462)  Acc@5: 93.7500 (94.6595)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2160/3750]  eta: 0:10:22  Lr: 0.030000  Loss: -2.8081  Acc@1: 75.0000 (74.3348)  Acc@5: 93.7500 (94.6668)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2170/3750]  eta: 0:10:18  Lr: 0.030000  Loss: -2.7401  Acc@1: 75.0000 (74.3695)  Acc@5: 100.0000 (94.6712)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2180/3750]  eta: 0:10:14  Lr: 0.030000  Loss: -2.4464  Acc@1: 81.2500 (74.3782)  Acc@5: 93.7500 (94.6727)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2190/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -2.2836  Acc@1: 81.2500 (74.3924)  Acc@5: 93.7500 (94.6799)  time: 0.3929  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2200/3750]  eta: 0:10:06  Lr: 0.030000  Loss: -2.3159  Acc@1: 75.0000 (74.4037)  Acc@5: 100.0000 (94.6899)  time: 0.3938  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2210/3750]  eta: 0:10:02  Lr: 0.030000  Loss: -2.2211  Acc@1: 75.0000 (74.3979)  Acc@5: 93.7500 (94.6828)  time: 0.3933  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2220/3750]  eta: 0:09:58  Lr: 0.030000  Loss: -2.5509  Acc@1: 75.0000 (74.4034)  Acc@5: 93.7500 (94.6814)  time: 0.3921  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2230/3750]  eta: 0:09:54  Lr: 0.030000  Loss: -2.8218  Acc@1: 75.0000 (74.4117)  Acc@5: 93.7500 (94.6913)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2240/3750]  eta: 0:09:51  Lr: 0.030000  Loss: -2.5908  Acc@1: 81.2500 (74.4450)  Acc@5: 93.7500 (94.6982)  time: 0.3928  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2250/3750]  eta: 0:09:47  Lr: 0.030000  Loss: -2.3988  Acc@1: 81.2500 (74.4669)  Acc@5: 93.7500 (94.7079)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2260/3750]  eta: 0:09:43  Lr: 0.030000  Loss: -2.4351  Acc@1: 81.2500 (74.5107)  Acc@5: 93.7500 (94.7092)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2270/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -3.0676  Acc@1: 87.5000 (74.5514)  Acc@5: 93.7500 (94.7050)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2280/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -2.8068  Acc@1: 81.2500 (74.5753)  Acc@5: 93.7500 (94.7008)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2290/3750]  eta: 0:09:31  Lr: 0.030000  Loss: -2.4413  Acc@1: 81.2500 (74.6263)  Acc@5: 93.7500 (94.7103)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2300/3750]  eta: 0:09:27  Lr: 0.030000  Loss: -2.4594  Acc@1: 81.2500 (74.6442)  Acc@5: 100.0000 (94.7197)  time: 0.3919  data: 0.0006  max mem: 2908
Train: Epoch[1/5]  [2310/3750]  eta: 0:09:23  Lr: 0.030000  Loss: -2.2453  Acc@1: 75.0000 (74.6457)  Acc@5: 100.0000 (94.7344)  time: 0.3915  data: 0.0006  max mem: 2908
Train: Epoch[1/5]  [2320/3750]  eta: 0:09:19  Lr: 0.030000  Loss: -2.3582  Acc@1: 81.2500 (74.6742)  Acc@5: 93.7500 (94.7248)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2330/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -2.2382  Acc@1: 81.2500 (74.6917)  Acc@5: 93.7500 (94.7367)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2340/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -2.3265  Acc@1: 81.2500 (74.7304)  Acc@5: 100.0000 (94.7485)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2350/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -2.6830  Acc@1: 81.2500 (74.7395)  Acc@5: 100.0000 (94.7575)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2360/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -2.6528  Acc@1: 81.2500 (74.7670)  Acc@5: 100.0000 (94.7692)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2370/3750]  eta: 0:09:00  Lr: 0.030000  Loss: -2.5652  Acc@1: 87.5000 (74.8102)  Acc@5: 93.7500 (94.7701)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2380/3750]  eta: 0:08:56  Lr: 0.030000  Loss: -1.9880  Acc@1: 81.2500 (74.8031)  Acc@5: 93.7500 (94.7764)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2390/3750]  eta: 0:08:52  Lr: 0.030000  Loss: -1.8605  Acc@1: 68.7500 (74.7961)  Acc@5: 93.7500 (94.7694)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2400/3750]  eta: 0:08:48  Lr: 0.030000  Loss: -2.5141  Acc@1: 68.7500 (74.7996)  Acc@5: 93.7500 (94.7756)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2410/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -2.5445  Acc@1: 75.0000 (74.8134)  Acc@5: 93.7500 (94.7714)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2420/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -2.5365  Acc@1: 75.0000 (74.8115)  Acc@5: 93.7500 (94.7620)  time: 0.3906  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2430/3750]  eta: 0:08:36  Lr: 0.030000  Loss: -2.0389  Acc@1: 75.0000 (74.8277)  Acc@5: 93.7500 (94.7604)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2440/3750]  eta: 0:08:32  Lr: 0.030000  Loss: -2.3187  Acc@1: 75.0000 (74.8131)  Acc@5: 93.7500 (94.7562)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2450/3750]  eta: 0:08:28  Lr: 0.030000  Loss: -2.3420  Acc@1: 68.7500 (74.8190)  Acc@5: 93.7500 (94.7496)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2460/3750]  eta: 0:08:24  Lr: 0.030000  Loss: -2.2006  Acc@1: 81.2500 (74.8603)  Acc@5: 100.0000 (94.7633)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2470/3750]  eta: 0:08:21  Lr: 0.030000  Loss: -2.1312  Acc@1: 81.2500 (74.8685)  Acc@5: 100.0000 (94.7643)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2480/3750]  eta: 0:08:17  Lr: 0.030000  Loss: -2.4084  Acc@1: 75.0000 (74.8665)  Acc@5: 93.7500 (94.7602)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2490/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -2.0814  Acc@1: 75.0000 (74.8921)  Acc@5: 93.7500 (94.7712)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2500/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -2.7331  Acc@1: 81.2500 (74.9200)  Acc@5: 93.7500 (94.7696)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2510/3750]  eta: 0:08:05  Lr: 0.030000  Loss: -2.1960  Acc@1: 81.2500 (74.9129)  Acc@5: 93.7500 (94.7606)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2520/3750]  eta: 0:08:01  Lr: 0.030000  Loss: -2.3969  Acc@1: 81.2500 (74.9504)  Acc@5: 93.7500 (94.7689)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:57  Lr: 0.030000  Loss: -2.3474  Acc@1: 81.2500 (74.9605)  Acc@5: 93.7500 (94.7624)  time: 0.3935  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:53  Lr: 0.030000  Loss: -2.3665  Acc@1: 81.2500 (75.0000)  Acc@5: 93.7500 (94.7708)  time: 0.3957  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2550/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -2.1356  Acc@1: 87.5000 (75.0343)  Acc@5: 100.0000 (94.7790)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2560/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -2.4756  Acc@1: 81.2500 (75.0512)  Acc@5: 100.0000 (94.7970)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2570/3750]  eta: 0:07:41  Lr: 0.030000  Loss: -2.4601  Acc@1: 75.0000 (75.0729)  Acc@5: 100.0000 (94.8099)  time: 0.3929  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2580/3750]  eta: 0:07:37  Lr: 0.030000  Loss: -2.3512  Acc@1: 75.0000 (75.0751)  Acc@5: 93.7500 (94.8058)  time: 0.3930  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2590/3750]  eta: 0:07:34  Lr: 0.030000  Loss: -2.6299  Acc@1: 75.0000 (75.0868)  Acc@5: 93.7500 (94.8041)  time: 0.3920  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2600/3750]  eta: 0:07:30  Lr: 0.030000  Loss: -2.2596  Acc@1: 75.0000 (75.0817)  Acc@5: 93.7500 (94.8121)  time: 0.3912  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2610/3750]  eta: 0:07:26  Lr: 0.030000  Loss: -1.9859  Acc@1: 75.0000 (75.1101)  Acc@5: 100.0000 (94.8200)  time: 0.3900  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2620/3750]  eta: 0:07:22  Lr: 0.030000  Loss: -2.0841  Acc@1: 75.0000 (75.1073)  Acc@5: 100.0000 (94.8207)  time: 0.3899  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2630/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -1.7831  Acc@1: 75.0000 (75.1188)  Acc@5: 93.7500 (94.8119)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2640/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -1.4018  Acc@1: 75.0000 (75.1420)  Acc@5: 93.7500 (94.8149)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2650/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -2.6142  Acc@1: 81.2500 (75.1627)  Acc@5: 100.0000 (94.8251)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2660/3750]  eta: 0:07:06  Lr: 0.030000  Loss: -2.6565  Acc@1: 81.2500 (75.1785)  Acc@5: 100.0000 (94.8304)  time: 0.3929  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2670/3750]  eta: 0:07:02  Lr: 0.030000  Loss: -2.2882  Acc@1: 81.2500 (75.1872)  Acc@5: 93.7500 (94.8240)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:58  Lr: 0.030000  Loss: -1.8198  Acc@1: 75.0000 (75.1888)  Acc@5: 93.7500 (94.8224)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:54  Lr: 0.030000  Loss: -1.9730  Acc@1: 75.0000 (75.2067)  Acc@5: 93.7500 (94.8207)  time: 0.3905  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -2.0652  Acc@1: 75.0000 (75.2198)  Acc@5: 93.7500 (94.8214)  time: 0.3908  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:47  Lr: 0.030000  Loss: -1.9791  Acc@1: 75.0000 (75.2352)  Acc@5: 93.7500 (94.8289)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -2.3904  Acc@1: 75.0000 (75.2412)  Acc@5: 100.0000 (94.8342)  time: 0.3926  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2730/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -2.6245  Acc@1: 81.2500 (75.2540)  Acc@5: 100.0000 (94.8371)  time: 0.3935  data: 0.0007  max mem: 2908
Train: Epoch[1/5]  [2740/3750]  eta: 0:06:35  Lr: 0.030000  Loss: -1.9779  Acc@1: 81.2500 (75.2577)  Acc@5: 93.7500 (94.8377)  time: 0.3920  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2750/3750]  eta: 0:06:31  Lr: 0.030000  Loss: -2.2220  Acc@1: 81.2500 (75.2931)  Acc@5: 93.7500 (94.8337)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2760/3750]  eta: 0:06:27  Lr: 0.030000  Loss: -2.4254  Acc@1: 81.2500 (75.2965)  Acc@5: 93.7500 (94.8343)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2770/3750]  eta: 0:06:23  Lr: 0.030000  Loss: -2.1774  Acc@1: 81.2500 (75.3248)  Acc@5: 100.0000 (94.8439)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2780/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -2.7413  Acc@1: 81.2500 (75.3439)  Acc@5: 100.0000 (94.8580)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2790/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -2.1118  Acc@1: 75.0000 (75.3269)  Acc@5: 100.0000 (94.8562)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2800/3750]  eta: 0:06:11  Lr: 0.030000  Loss: -2.6303  Acc@1: 81.2500 (75.3682)  Acc@5: 93.7500 (94.8657)  time: 0.3920  data: 0.0010  max mem: 2908
Train: Epoch[1/5]  [2810/3750]  eta: 0:06:07  Lr: 0.030000  Loss: -2.4309  Acc@1: 81.2500 (75.3824)  Acc@5: 100.0000 (94.8684)  time: 0.3929  data: 0.0012  max mem: 2908
Train: Epoch[1/5]  [2820/3750]  eta: 0:06:04  Lr: 0.030000  Loss: -2.7024  Acc@1: 87.5000 (75.4165)  Acc@5: 93.7500 (94.8755)  time: 0.3928  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2830/3750]  eta: 0:06:00  Lr: 0.030000  Loss: -2.3436  Acc@1: 81.2500 (75.4437)  Acc@5: 100.0000 (94.8826)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:56  Lr: 0.030000  Loss: -2.2968  Acc@1: 81.2500 (75.4576)  Acc@5: 100.0000 (94.8918)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:52  Lr: 0.030000  Loss: -2.0082  Acc@1: 81.2500 (75.4713)  Acc@5: 100.0000 (94.9009)  time: 0.3926  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -2.4677  Acc@1: 81.2500 (75.4872)  Acc@5: 93.7500 (94.9056)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -2.4442  Acc@1: 81.2500 (75.5072)  Acc@5: 93.7500 (94.9147)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:40  Lr: 0.030000  Loss: -2.5002  Acc@1: 81.2500 (75.5207)  Acc@5: 100.0000 (94.9171)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:36  Lr: 0.030000  Loss: -2.5623  Acc@1: 81.2500 (75.5361)  Acc@5: 100.0000 (94.9174)  time: 0.3925  data: 0.0007  max mem: 2908
Train: Epoch[1/5]  [2900/3750]  eta: 0:05:32  Lr: 0.030000  Loss: -2.1304  Acc@1: 75.0000 (75.5386)  Acc@5: 93.7500 (94.9091)  time: 0.3934  data: 0.0008  max mem: 2908
Train: Epoch[1/5]  [2910/3750]  eta: 0:05:28  Lr: 0.030000  Loss: -2.8253  Acc@1: 75.0000 (75.5539)  Acc@5: 93.7500 (94.9094)  time: 0.3935  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2920/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -2.8270  Acc@1: 75.0000 (75.5563)  Acc@5: 93.7500 (94.9183)  time: 0.3939  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2930/3750]  eta: 0:05:21  Lr: 0.030000  Loss: -1.7873  Acc@1: 75.0000 (75.5629)  Acc@5: 93.7500 (94.9143)  time: 0.3938  data: 0.0006  max mem: 2908
Train: Epoch[1/5]  [2940/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -2.1309  Acc@1: 75.0000 (75.5440)  Acc@5: 93.7500 (94.9082)  time: 0.3926  data: 0.0006  max mem: 2908
Train: Epoch[1/5]  [2950/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -1.5106  Acc@1: 68.7500 (75.5380)  Acc@5: 100.0000 (94.9212)  time: 0.3930  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2960/3750]  eta: 0:05:09  Lr: 0.030000  Loss: -2.6030  Acc@1: 75.0000 (75.5340)  Acc@5: 100.0000 (94.9173)  time: 0.3929  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [2970/3750]  eta: 0:05:05  Lr: 0.030000  Loss: -2.1509  Acc@1: 81.2500 (75.5575)  Acc@5: 93.7500 (94.9196)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [2980/3750]  eta: 0:05:01  Lr: 0.030000  Loss: -1.9831  Acc@1: 81.2500 (75.5871)  Acc@5: 93.7500 (94.9220)  time: 0.3922  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:57  Lr: 0.030000  Loss: -2.5991  Acc@1: 81.2500 (75.5955)  Acc@5: 100.0000 (94.9244)  time: 0.3931  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -2.9567  Acc@1: 81.2500 (75.6310)  Acc@5: 100.0000 (94.9309)  time: 0.3935  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -3.0928  Acc@1: 81.2500 (75.6476)  Acc@5: 100.0000 (94.9352)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:45  Lr: 0.030000  Loss: -2.6488  Acc@1: 81.2500 (75.6848)  Acc@5: 100.0000 (94.9437)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:41  Lr: 0.030000  Loss: -1.8648  Acc@1: 81.2500 (75.7073)  Acc@5: 100.0000 (94.9419)  time: 0.3936  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:37  Lr: 0.030000  Loss: -1.9507  Acc@1: 81.2500 (75.6988)  Acc@5: 93.7500 (94.9420)  time: 0.3935  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:34  Lr: 0.030000  Loss: -1.8532  Acc@1: 75.0000 (75.6965)  Acc@5: 93.7500 (94.9402)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:30  Lr: 0.030000  Loss: -2.9604  Acc@1: 81.2500 (75.7289)  Acc@5: 93.7500 (94.9465)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3070/3750]  eta: 0:04:26  Lr: 0.030000  Loss: -2.4051  Acc@1: 81.2500 (75.7327)  Acc@5: 100.0000 (94.9487)  time: 0.3916  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [3080/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -2.5539  Acc@1: 81.2500 (75.7445)  Acc@5: 93.7500 (94.9428)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3090/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -2.3373  Acc@1: 75.0000 (75.7502)  Acc@5: 93.7500 (94.9410)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -2.3449  Acc@1: 81.2500 (75.7639)  Acc@5: 93.7500 (94.9492)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3110/3750]  eta: 0:04:10  Lr: 0.030000  Loss: -2.3189  Acc@1: 81.2500 (75.7735)  Acc@5: 100.0000 (94.9494)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3120/3750]  eta: 0:04:06  Lr: 0.030000  Loss: -2.5042  Acc@1: 75.0000 (75.7870)  Acc@5: 100.0000 (94.9515)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3130/3750]  eta: 0:04:02  Lr: 0.030000  Loss: -2.2494  Acc@1: 81.2500 (75.7965)  Acc@5: 100.0000 (94.9597)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:58  Lr: 0.030000  Loss: -2.3530  Acc@1: 81.2500 (75.8118)  Acc@5: 100.0000 (94.9678)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -2.1098  Acc@1: 81.2500 (75.8152)  Acc@5: 100.0000 (94.9738)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -1.6498  Acc@1: 81.2500 (75.8285)  Acc@5: 100.0000 (94.9818)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -2.7331  Acc@1: 81.2500 (75.8377)  Acc@5: 100.0000 (94.9898)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:43  Lr: 0.030000  Loss: -2.5784  Acc@1: 81.2500 (75.8527)  Acc@5: 100.0000 (94.9937)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -2.3664  Acc@1: 75.0000 (75.8540)  Acc@5: 93.7500 (94.9937)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -1.9205  Acc@1: 75.0000 (75.8650)  Acc@5: 93.7500 (94.9957)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -1.7479  Acc@1: 75.0000 (75.8603)  Acc@5: 93.7500 (94.9918)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -2.6361  Acc@1: 75.0000 (75.8790)  Acc@5: 93.7500 (94.9977)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -2.4651  Acc@1: 87.5000 (75.8956)  Acc@5: 100.0000 (95.0054)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3240/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -2.2694  Acc@1: 81.2500 (75.8890)  Acc@5: 100.0000 (95.0054)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3250/3750]  eta: 0:03:15  Lr: 0.030000  Loss: -2.5074  Acc@1: 81.2500 (75.9074)  Acc@5: 93.7500 (95.0054)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3260/3750]  eta: 0:03:11  Lr: 0.030000  Loss: -2.3392  Acc@1: 81.2500 (75.9200)  Acc@5: 100.0000 (95.0149)  time: 0.3902  data: 0.0011  max mem: 2908
Train: Epoch[1/5]  [3270/3750]  eta: 0:03:07  Lr: 0.030000  Loss: -2.3475  Acc@1: 81.2500 (75.9267)  Acc@5: 100.0000 (95.0168)  time: 0.3908  data: 0.0018  max mem: 2908
Train: Epoch[1/5]  [3280/3750]  eta: 0:03:04  Lr: 0.030000  Loss: -3.0038  Acc@1: 75.0000 (75.9467)  Acc@5: 93.7500 (95.0206)  time: 0.3907  data: 0.0012  max mem: 2908
Train: Epoch[1/5]  [3290/3750]  eta: 0:03:00  Lr: 0.030000  Loss: -2.7502  Acc@1: 81.2500 (75.9610)  Acc@5: 100.0000 (95.0281)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -2.1453  Acc@1: 75.0000 (75.9561)  Acc@5: 93.7500 (95.0261)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -2.1444  Acc@1: 75.0000 (75.9740)  Acc@5: 93.7500 (95.0242)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -2.6358  Acc@1: 75.0000 (75.9767)  Acc@5: 93.7500 (95.0279)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -2.4584  Acc@1: 75.0000 (75.9738)  Acc@5: 93.7500 (95.0221)  time: 0.3895  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -2.5560  Acc@1: 81.2500 (75.9915)  Acc@5: 93.7500 (95.0221)  time: 0.3891  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -2.8801  Acc@1: 81.2500 (76.0034)  Acc@5: 93.7500 (95.0183)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:32  Lr: 0.030000  Loss: -2.3692  Acc@1: 81.2500 (75.9986)  Acc@5: 93.7500 (95.0164)  time: 0.3906  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -2.1235  Acc@1: 75.0000 (76.0049)  Acc@5: 93.7500 (95.0163)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -2.1788  Acc@1: 81.2500 (76.0167)  Acc@5: 100.0000 (95.0218)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:20  Lr: 0.030000  Loss: -2.6371  Acc@1: 87.5000 (76.0414)  Acc@5: 100.0000 (95.0254)  time: 0.3922  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -2.2970  Acc@1: 81.2500 (76.0512)  Acc@5: 93.7500 (95.0235)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -2.5261  Acc@1: 81.2500 (76.0591)  Acc@5: 93.7500 (95.0253)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -2.4763  Acc@1: 81.2500 (76.0779)  Acc@5: 93.7500 (95.0252)  time: 0.3892  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -2.6758  Acc@1: 81.2500 (76.0839)  Acc@5: 93.7500 (95.0160)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -1.9016  Acc@1: 75.0000 (76.0807)  Acc@5: 93.7500 (95.0087)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -2.6874  Acc@1: 81.2500 (76.1029)  Acc@5: 100.0000 (95.0177)  time: 0.3900  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -2.6052  Acc@1: 81.2500 (76.1196)  Acc@5: 100.0000 (95.0249)  time: 0.3903  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -2.2668  Acc@1: 75.0000 (76.1272)  Acc@5: 100.0000 (95.0266)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -2.8898  Acc@1: 75.0000 (76.1293)  Acc@5: 93.7500 (95.0266)  time: 0.3895  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:41  Lr: 0.030000  Loss: -2.1754  Acc@1: 81.2500 (76.1315)  Acc@5: 93.7500 (95.0301)  time: 0.3898  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:37  Lr: 0.030000  Loss: -1.7677  Acc@1: 81.2500 (76.1372)  Acc@5: 93.7500 (95.0282)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -2.6003  Acc@1: 81.2500 (76.1571)  Acc@5: 100.0000 (95.0335)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:30  Lr: 0.030000  Loss: -2.6972  Acc@1: 81.2500 (76.1556)  Acc@5: 93.7500 (95.0263)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -2.6016  Acc@1: 75.0000 (76.1611)  Acc@5: 93.7500 (95.0227)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -2.8688  Acc@1: 75.0000 (76.1773)  Acc@5: 100.0000 (95.0297)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -2.7190  Acc@1: 75.0000 (76.1863)  Acc@5: 100.0000 (95.0243)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -2.8542  Acc@1: 75.0000 (76.1917)  Acc@5: 93.7500 (95.0242)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -2.6830  Acc@1: 75.0000 (76.1919)  Acc@5: 93.7500 (95.0242)  time: 0.3928  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -2.4538  Acc@1: 81.2500 (76.2043)  Acc@5: 93.7500 (95.0258)  time: 0.3921  data: 0.0006  max mem: 2908
Train: Epoch[1/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -2.5768  Acc@1: 81.2500 (76.2096)  Acc@5: 93.7500 (95.0275)  time: 0.3915  data: 0.0007  max mem: 2908
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -3.0676  Acc@1: 81.2500 (76.2219)  Acc@5: 100.0000 (95.0361)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -1.7492  Acc@1: 87.5000 (76.2479)  Acc@5: 100.0000 (95.0412)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:50  Lr: 0.030000  Loss: -2.5428  Acc@1: 87.5000 (76.2617)  Acc@5: 100.0000 (95.0428)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:46  Lr: 0.030000  Loss: -2.2081  Acc@1: 81.2500 (76.2789)  Acc@5: 93.7500 (95.0444)  time: 0.3924  data: 0.0005  max mem: 2908
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -1.0846  Acc@1: 81.2500 (76.2823)  Acc@5: 100.0000 (95.0426)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -2.6250  Acc@1: 81.2500 (76.2993)  Acc@5: 93.7500 (95.0407)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -2.6380  Acc@1: 81.2500 (76.3009)  Acc@5: 93.7500 (95.0389)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -2.0698  Acc@1: 87.5000 (76.3331)  Acc@5: 100.0000 (95.0473)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -2.3272  Acc@1: 87.5000 (76.3515)  Acc@5: 100.0000 (95.0472)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -1.7043  Acc@1: 81.2500 (76.3580)  Acc@5: 93.7500 (95.0386)  time: 0.3937  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -2.4290  Acc@1: 81.2500 (76.3729)  Acc@5: 93.7500 (95.0419)  time: 0.3938  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -2.5127  Acc@1: 81.2500 (76.3793)  Acc@5: 100.0000 (95.0519)  time: 0.3929  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -2.1389  Acc@1: 75.0000 (76.3824)  Acc@5: 100.0000 (95.0551)  time: 0.3930  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -2.4998  Acc@1: 81.2500 (76.3904)  Acc@5: 93.7500 (95.0566)  time: 0.3933  data: 0.0003  max mem: 2908
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -1.8969  Acc@1: 81.2500 (76.3950)  Acc@5: 93.7500 (95.0531)  time: 0.3938  data: 0.0004  max mem: 2908
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -2.3120  Acc@1: 81.2500 (76.4133)  Acc@5: 93.7500 (95.0567)  time: 0.3931  data: 0.0010  max mem: 2908
Train: Epoch[1/5] Total time: 0:24:28 (0.3917 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.3120  Acc@1: 81.2500 (76.4133)  Acc@5: 93.7500 (95.0567)
Train: Epoch[2/5]  [   0/3750]  eta: 0:51:53  Lr: 0.030000  Loss: -2.5627  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.8302  data: 0.4343  max mem: 2908
Train: Epoch[2/5]  [  10/3750]  eta: 0:26:58  Lr: 0.030000  Loss: -2.1129  Acc@1: 81.2500 (76.7045)  Acc@5: 93.7500 (96.0227)  time: 0.4328  data: 0.0416  max mem: 2908
Train: Epoch[2/5]  [  20/3750]  eta: 0:25:41  Lr: 0.030000  Loss: -2.4833  Acc@1: 81.2500 (78.2738)  Acc@5: 100.0000 (96.7262)  time: 0.3925  data: 0.0014  max mem: 2908
Train: Epoch[2/5]  [  30/3750]  eta: 0:25:13  Lr: 0.030000  Loss: -1.7788  Acc@1: 81.2500 (78.6290)  Acc@5: 100.0000 (95.9677)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [  40/3750]  eta: 0:24:56  Lr: 0.030000  Loss: -1.9835  Acc@1: 75.0000 (78.5061)  Acc@5: 93.7500 (95.2744)  time: 0.3929  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [  50/3750]  eta: 0:24:43  Lr: 0.030000  Loss: -2.7644  Acc@1: 81.2500 (79.4118)  Acc@5: 93.7500 (95.4657)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [  60/3750]  eta: 0:24:35  Lr: 0.030000  Loss: -2.0534  Acc@1: 81.2500 (78.9959)  Acc@5: 93.7500 (95.3893)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [  70/3750]  eta: 0:24:27  Lr: 0.030000  Loss: -2.2871  Acc@1: 75.0000 (78.6972)  Acc@5: 100.0000 (95.7746)  time: 0.3928  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [  80/3750]  eta: 0:24:21  Lr: 0.030000  Loss: -1.9153  Acc@1: 81.2500 (79.3210)  Acc@5: 100.0000 (95.8333)  time: 0.3932  data: 0.0010  max mem: 2908
Train: Epoch[2/5]  [  90/3750]  eta: 0:24:15  Lr: 0.030000  Loss: -1.7701  Acc@1: 81.2500 (79.4643)  Acc@5: 93.7500 (95.9478)  time: 0.3940  data: 0.0017  max mem: 2908
Train: Epoch[2/5]  [ 100/3750]  eta: 0:24:09  Lr: 0.030000  Loss: -2.5332  Acc@1: 81.2500 (79.3936)  Acc@5: 100.0000 (96.0396)  time: 0.3928  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [ 110/3750]  eta: 0:24:04  Lr: 0.030000  Loss: -1.9764  Acc@1: 75.0000 (78.7725)  Acc@5: 100.0000 (95.7770)  time: 0.3927  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [ 120/3750]  eta: 0:23:59  Lr: 0.030000  Loss: -1.8533  Acc@1: 75.0000 (78.4607)  Acc@5: 93.7500 (95.6612)  time: 0.3940  data: 0.0025  max mem: 2908
Train: Epoch[2/5]  [ 130/3750]  eta: 0:23:55  Lr: 0.030000  Loss: -2.5357  Acc@1: 75.0000 (78.4828)  Acc@5: 93.7500 (95.5153)  time: 0.3948  data: 0.0025  max mem: 2908
Train: Epoch[2/5]  [ 140/3750]  eta: 0:23:50  Lr: 0.030000  Loss: -2.7257  Acc@1: 87.5000 (78.9450)  Acc@5: 93.7500 (95.6117)  time: 0.3934  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [ 150/3750]  eta: 0:23:44  Lr: 0.030000  Loss: -2.3931  Acc@1: 87.5000 (79.0977)  Acc@5: 100.0000 (95.7368)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 160/3750]  eta: 0:23:40  Lr: 0.030000  Loss: -2.3419  Acc@1: 75.0000 (78.9596)  Acc@5: 100.0000 (95.7686)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 170/3750]  eta: 0:23:35  Lr: 0.030000  Loss: -2.7828  Acc@1: 75.0000 (78.9839)  Acc@5: 100.0000 (95.8333)  time: 0.3916  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 180/3750]  eta: 0:23:30  Lr: 0.030000  Loss: -2.0947  Acc@1: 75.0000 (78.8674)  Acc@5: 100.0000 (95.8564)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 190/3750]  eta: 0:23:25  Lr: 0.030000  Loss: -2.1998  Acc@1: 81.2500 (79.0249)  Acc@5: 100.0000 (95.9424)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 200/3750]  eta: 0:23:21  Lr: 0.030000  Loss: -2.6614  Acc@1: 81.2500 (78.8868)  Acc@5: 93.7500 (95.8955)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 210/3750]  eta: 0:23:17  Lr: 0.030000  Loss: -2.8382  Acc@1: 81.2500 (78.9100)  Acc@5: 93.7500 (95.9716)  time: 0.3923  data: 0.0009  max mem: 2908
Train: Epoch[2/5]  [ 220/3750]  eta: 0:23:12  Lr: 0.030000  Loss: -2.8445  Acc@1: 81.2500 (78.9593)  Acc@5: 93.7500 (95.8993)  time: 0.3934  data: 0.0016  max mem: 2908
Train: Epoch[2/5]  [ 230/3750]  eta: 0:23:09  Lr: 0.030000  Loss: -2.2268  Acc@1: 81.2500 (79.0314)  Acc@5: 93.7500 (95.8874)  time: 0.3941  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [ 240/3750]  eta: 0:23:05  Lr: 0.030000  Loss: -2.4361  Acc@1: 81.2500 (79.2531)  Acc@5: 93.7500 (95.8766)  time: 0.3948  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 250/3750]  eta: 0:23:01  Lr: 0.030000  Loss: -2.0717  Acc@1: 81.2500 (78.9841)  Acc@5: 93.7500 (95.6673)  time: 0.3941  data: 0.0007  max mem: 2908
Train: Epoch[2/5]  [ 260/3750]  eta: 0:22:56  Lr: 0.030000  Loss: -2.7540  Acc@1: 75.0000 (79.0709)  Acc@5: 93.7500 (95.7375)  time: 0.3924  data: 0.0008  max mem: 2908
Train: Epoch[2/5]  [ 270/3750]  eta: 0:22:52  Lr: 0.030000  Loss: -2.4844  Acc@1: 81.2500 (79.1744)  Acc@5: 100.0000 (95.8718)  time: 0.3926  data: 0.0013  max mem: 2908
Train: Epoch[2/5]  [ 280/3750]  eta: 0:22:48  Lr: 0.030000  Loss: -2.2288  Acc@1: 81.2500 (79.2927)  Acc@5: 100.0000 (95.9297)  time: 0.3929  data: 0.0012  max mem: 2908
Train: Epoch[2/5]  [ 290/3750]  eta: 0:22:44  Lr: 0.030000  Loss: -2.4229  Acc@1: 81.2500 (79.2955)  Acc@5: 93.7500 (95.8763)  time: 0.3926  data: 0.0012  max mem: 2908
Train: Epoch[2/5]  [ 300/3750]  eta: 0:22:40  Lr: 0.030000  Loss: -1.5156  Acc@1: 81.2500 (79.2359)  Acc@5: 93.7500 (95.8056)  time: 0.3935  data: 0.0019  max mem: 2908
Train: Epoch[2/5]  [ 310/3750]  eta: 0:22:36  Lr: 0.030000  Loss: -1.7635  Acc@1: 81.2500 (79.2002)  Acc@5: 93.7500 (95.7797)  time: 0.3926  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [ 320/3750]  eta: 0:22:32  Lr: 0.030000  Loss: -2.8495  Acc@1: 81.2500 (79.3808)  Acc@5: 100.0000 (95.8917)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 330/3750]  eta: 0:22:27  Lr: 0.030000  Loss: -2.5042  Acc@1: 81.2500 (79.4751)  Acc@5: 100.0000 (95.9026)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 340/3750]  eta: 0:22:23  Lr: 0.030000  Loss: -2.0743  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (95.9494)  time: 0.3895  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 350/3750]  eta: 0:22:18  Lr: 0.030000  Loss: -2.2717  Acc@1: 81.2500 (79.5050)  Acc@5: 100.0000 (95.9580)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 360/3750]  eta: 0:22:14  Lr: 0.030000  Loss: -1.9142  Acc@1: 75.0000 (79.3629)  Acc@5: 93.7500 (95.9314)  time: 0.3920  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [ 370/3750]  eta: 0:22:10  Lr: 0.030000  Loss: -2.3312  Acc@1: 75.0000 (79.3295)  Acc@5: 100.0000 (95.9906)  time: 0.3925  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [ 380/3750]  eta: 0:22:06  Lr: 0.030000  Loss: -2.2239  Acc@1: 81.2500 (79.4127)  Acc@5: 100.0000 (96.0138)  time: 0.3928  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 390/3750]  eta: 0:22:03  Lr: 0.030000  Loss: -2.1445  Acc@1: 81.2500 (79.3638)  Acc@5: 100.0000 (96.0518)  time: 0.3944  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 400/3750]  eta: 0:21:59  Lr: 0.030000  Loss: -2.2223  Acc@1: 81.2500 (79.3641)  Acc@5: 100.0000 (96.0411)  time: 0.3944  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [ 410/3750]  eta: 0:21:55  Lr: 0.030000  Loss: -1.8880  Acc@1: 81.2500 (79.3491)  Acc@5: 93.7500 (96.0006)  time: 0.3937  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [ 420/3750]  eta: 0:21:51  Lr: 0.030000  Loss: -1.9668  Acc@1: 81.2500 (79.4388)  Acc@5: 93.7500 (95.9768)  time: 0.3927  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 430/3750]  eta: 0:21:46  Lr: 0.030000  Loss: -2.6729  Acc@1: 81.2500 (79.5244)  Acc@5: 93.7500 (95.9977)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 440/3750]  eta: 0:21:42  Lr: 0.030000  Loss: -2.6940  Acc@1: 81.2500 (79.4501)  Acc@5: 100.0000 (96.0176)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 450/3750]  eta: 0:21:38  Lr: 0.030000  Loss: -2.7607  Acc@1: 81.2500 (79.4762)  Acc@5: 100.0000 (96.0089)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 460/3750]  eta: 0:21:34  Lr: 0.030000  Loss: -2.5109  Acc@1: 81.2500 (79.5418)  Acc@5: 100.0000 (96.0141)  time: 0.3927  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [ 470/3750]  eta: 0:21:30  Lr: 0.030000  Loss: -2.8004  Acc@1: 81.2500 (79.6975)  Acc@5: 100.0000 (96.0456)  time: 0.3924  data: 0.0006  max mem: 2908
Train: Epoch[2/5]  [ 480/3750]  eta: 0:21:26  Lr: 0.030000  Loss: -2.0201  Acc@1: 81.2500 (79.6648)  Acc@5: 100.0000 (96.0889)  time: 0.3928  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [ 490/3750]  eta: 0:21:22  Lr: 0.030000  Loss: -3.1309  Acc@1: 81.2500 (79.7352)  Acc@5: 100.0000 (96.1303)  time: 0.3930  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 500/3750]  eta: 0:21:18  Lr: 0.030000  Loss: -2.1740  Acc@1: 81.2500 (79.8154)  Acc@5: 100.0000 (96.1577)  time: 0.3926  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 510/3750]  eta: 0:21:14  Lr: 0.030000  Loss: -2.6430  Acc@1: 81.2500 (79.8679)  Acc@5: 100.0000 (96.1595)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 520/3750]  eta: 0:21:10  Lr: 0.030000  Loss: -1.9342  Acc@1: 81.2500 (79.8584)  Acc@5: 100.0000 (96.1732)  time: 0.3926  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 530/3750]  eta: 0:21:06  Lr: 0.030000  Loss: -2.7217  Acc@1: 81.2500 (79.9200)  Acc@5: 93.7500 (96.1629)  time: 0.3920  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [ 540/3750]  eta: 0:21:02  Lr: 0.030000  Loss: -2.6709  Acc@1: 81.2500 (79.8752)  Acc@5: 100.0000 (96.2107)  time: 0.3912  data: 0.0012  max mem: 2908
Train: Epoch[2/5]  [ 550/3750]  eta: 0:20:58  Lr: 0.030000  Loss: -2.3921  Acc@1: 75.0000 (79.8888)  Acc@5: 100.0000 (96.1887)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 560/3750]  eta: 0:20:54  Lr: 0.030000  Loss: -2.2130  Acc@1: 81.2500 (79.9020)  Acc@5: 100.0000 (96.2233)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 570/3750]  eta: 0:20:50  Lr: 0.030000  Loss: -2.4018  Acc@1: 81.2500 (79.8489)  Acc@5: 100.0000 (96.2237)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 580/3750]  eta: 0:20:46  Lr: 0.030000  Loss: -2.7466  Acc@1: 81.2500 (79.8623)  Acc@5: 93.7500 (96.2242)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 590/3750]  eta: 0:20:42  Lr: 0.030000  Loss: -2.9174  Acc@1: 81.2500 (79.9281)  Acc@5: 93.7500 (96.2352)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 600/3750]  eta: 0:20:38  Lr: 0.030000  Loss: -2.4597  Acc@1: 81.2500 (79.8981)  Acc@5: 100.0000 (96.2458)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 610/3750]  eta: 0:20:34  Lr: 0.030000  Loss: -1.9445  Acc@1: 75.0000 (79.8691)  Acc@5: 100.0000 (96.2664)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 620/3750]  eta: 0:20:30  Lr: 0.030000  Loss: -2.3808  Acc@1: 81.2500 (79.8913)  Acc@5: 100.0000 (96.3064)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 630/3750]  eta: 0:20:26  Lr: 0.030000  Loss: -1.9430  Acc@1: 81.2500 (79.8732)  Acc@5: 100.0000 (96.2857)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 640/3750]  eta: 0:20:22  Lr: 0.030000  Loss: -2.4964  Acc@1: 75.0000 (79.8849)  Acc@5: 93.7500 (96.2363)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 650/3750]  eta: 0:20:18  Lr: 0.030000  Loss: -2.2189  Acc@1: 81.2500 (79.8771)  Acc@5: 93.7500 (96.2078)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 660/3750]  eta: 0:20:14  Lr: 0.030000  Loss: -2.5022  Acc@1: 81.2500 (79.8317)  Acc@5: 93.7500 (96.1517)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 670/3750]  eta: 0:20:10  Lr: 0.030000  Loss: -2.5396  Acc@1: 81.2500 (79.8901)  Acc@5: 93.7500 (96.1624)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 680/3750]  eta: 0:20:06  Lr: 0.030000  Loss: -2.4445  Acc@1: 81.2500 (79.8550)  Acc@5: 93.7500 (96.1178)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 690/3750]  eta: 0:20:02  Lr: 0.030000  Loss: -2.6419  Acc@1: 81.2500 (79.8571)  Acc@5: 93.7500 (96.1017)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 700/3750]  eta: 0:19:58  Lr: 0.030000  Loss: -2.2584  Acc@1: 81.2500 (79.8413)  Acc@5: 93.7500 (96.1127)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 710/3750]  eta: 0:19:54  Lr: 0.030000  Loss: -2.2540  Acc@1: 81.2500 (79.8787)  Acc@5: 100.0000 (96.1322)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 720/3750]  eta: 0:19:50  Lr: 0.030000  Loss: -2.2551  Acc@1: 75.0000 (79.7590)  Acc@5: 93.7500 (96.0905)  time: 0.3921  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 730/3750]  eta: 0:19:46  Lr: 0.030000  Loss: -2.6831  Acc@1: 81.2500 (79.8393)  Acc@5: 93.7500 (96.0927)  time: 0.3925  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 740/3750]  eta: 0:19:42  Lr: 0.030000  Loss: -2.3727  Acc@1: 81.2500 (79.8583)  Acc@5: 100.0000 (96.0864)  time: 0.3923  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 750/3750]  eta: 0:19:38  Lr: 0.030000  Loss: -2.8379  Acc@1: 81.2500 (79.9184)  Acc@5: 93.7500 (96.0719)  time: 0.3926  data: 0.0006  max mem: 2908
Train: Epoch[2/5]  [ 760/3750]  eta: 0:19:34  Lr: 0.030000  Loss: -2.7049  Acc@1: 81.2500 (79.9195)  Acc@5: 100.0000 (96.1071)  time: 0.3916  data: 0.0007  max mem: 2908
Train: Epoch[2/5]  [ 770/3750]  eta: 0:19:30  Lr: 0.030000  Loss: -2.3185  Acc@1: 81.2500 (79.9530)  Acc@5: 100.0000 (96.0684)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 780/3750]  eta: 0:19:26  Lr: 0.030000  Loss: -2.1846  Acc@1: 81.2500 (80.0016)  Acc@5: 100.0000 (96.0867)  time: 0.3928  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 790/3750]  eta: 0:19:22  Lr: 0.030000  Loss: -1.9933  Acc@1: 81.2500 (80.0095)  Acc@5: 100.0000 (96.0967)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 800/3750]  eta: 0:19:18  Lr: 0.030000  Loss: -2.6087  Acc@1: 81.2500 (80.0250)  Acc@5: 100.0000 (96.0908)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 810/3750]  eta: 0:19:14  Lr: 0.030000  Loss: -2.3285  Acc@1: 81.2500 (80.0632)  Acc@5: 100.0000 (96.1005)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 820/3750]  eta: 0:19:10  Lr: 0.030000  Loss: -2.4921  Acc@1: 81.2500 (80.1233)  Acc@5: 100.0000 (96.1023)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 830/3750]  eta: 0:19:06  Lr: 0.030000  Loss: -2.3098  Acc@1: 81.2500 (80.1594)  Acc@5: 100.0000 (96.0890)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 840/3750]  eta: 0:19:02  Lr: 0.030000  Loss: -2.5009  Acc@1: 81.2500 (80.1873)  Acc@5: 100.0000 (96.1281)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 850/3750]  eta: 0:18:58  Lr: 0.030000  Loss: -2.7847  Acc@1: 81.2500 (80.1410)  Acc@5: 100.0000 (96.1369)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 860/3750]  eta: 0:18:54  Lr: 0.030000  Loss: -2.1583  Acc@1: 81.2500 (80.1757)  Acc@5: 100.0000 (96.1382)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 870/3750]  eta: 0:18:50  Lr: 0.030000  Loss: -2.1027  Acc@1: 81.2500 (80.1665)  Acc@5: 100.0000 (96.1251)  time: 0.3921  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 880/3750]  eta: 0:18:46  Lr: 0.030000  Loss: -3.0404  Acc@1: 81.2500 (80.1930)  Acc@5: 93.7500 (96.1337)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 890/3750]  eta: 0:18:42  Lr: 0.030000  Loss: -2.0026  Acc@1: 81.2500 (80.1768)  Acc@5: 93.7500 (96.1139)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 900/3750]  eta: 0:18:38  Lr: 0.030000  Loss: -2.6009  Acc@1: 81.2500 (80.1748)  Acc@5: 93.7500 (96.1293)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 910/3750]  eta: 0:18:34  Lr: 0.030000  Loss: -2.2635  Acc@1: 81.2500 (80.1729)  Acc@5: 100.0000 (96.1443)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 920/3750]  eta: 0:18:30  Lr: 0.030000  Loss: -1.9895  Acc@1: 81.2500 (80.2185)  Acc@5: 100.0000 (96.1659)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 930/3750]  eta: 0:18:27  Lr: 0.030000  Loss: -2.4442  Acc@1: 81.2500 (80.2564)  Acc@5: 100.0000 (96.1869)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 940/3750]  eta: 0:18:23  Lr: 0.030000  Loss: -2.5788  Acc@1: 81.2500 (80.2803)  Acc@5: 100.0000 (96.1809)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 950/3750]  eta: 0:18:19  Lr: 0.030000  Loss: -2.4165  Acc@1: 87.5000 (80.3102)  Acc@5: 93.7500 (96.1685)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 960/3750]  eta: 0:18:15  Lr: 0.030000  Loss: -2.4941  Acc@1: 81.2500 (80.3135)  Acc@5: 93.7500 (96.1824)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [ 970/3750]  eta: 0:18:11  Lr: 0.030000  Loss: -2.5473  Acc@1: 75.0000 (80.2652)  Acc@5: 100.0000 (96.1637)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 980/3750]  eta: 0:18:07  Lr: 0.030000  Loss: -2.6073  Acc@1: 81.2500 (80.2752)  Acc@5: 93.7500 (96.1328)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [ 990/3750]  eta: 0:18:03  Lr: 0.030000  Loss: -2.4542  Acc@1: 81.2500 (80.2914)  Acc@5: 93.7500 (96.1150)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1000/3750]  eta: 0:17:59  Lr: 0.030000  Loss: -1.9263  Acc@1: 75.0000 (80.2760)  Acc@5: 93.7500 (96.0914)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1010/3750]  eta: 0:17:55  Lr: 0.030000  Loss: -1.5663  Acc@1: 75.0000 (80.2238)  Acc@5: 100.0000 (96.0930)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1020/3750]  eta: 0:17:51  Lr: 0.030000  Loss: -2.9042  Acc@1: 75.0000 (80.1910)  Acc@5: 100.0000 (96.0884)  time: 0.3902  data: 0.0007  max mem: 2908
Train: Epoch[2/5]  [1030/3750]  eta: 0:17:47  Lr: 0.030000  Loss: -2.4055  Acc@1: 75.0000 (80.1770)  Acc@5: 93.7500 (96.0900)  time: 0.3900  data: 0.0007  max mem: 2908
Train: Epoch[2/5]  [1040/3750]  eta: 0:17:43  Lr: 0.030000  Loss: -2.4065  Acc@1: 75.0000 (80.1753)  Acc@5: 93.7500 (96.0795)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1050/3750]  eta: 0:17:39  Lr: 0.030000  Loss: -2.5588  Acc@1: 81.2500 (80.1736)  Acc@5: 100.0000 (96.0930)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1060/3750]  eta: 0:17:35  Lr: 0.030000  Loss: -2.3676  Acc@1: 81.2500 (80.1956)  Acc@5: 100.0000 (96.1180)  time: 0.3895  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1070/3750]  eta: 0:17:31  Lr: 0.030000  Loss: -2.5314  Acc@1: 81.2500 (80.1996)  Acc@5: 100.0000 (96.1076)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1080/3750]  eta: 0:17:27  Lr: 0.030000  Loss: -2.2187  Acc@1: 81.2500 (80.2151)  Acc@5: 93.7500 (96.1089)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1090/3750]  eta: 0:17:23  Lr: 0.030000  Loss: -1.8686  Acc@1: 75.0000 (80.1501)  Acc@5: 93.7500 (96.1102)  time: 0.3898  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1100/3750]  eta: 0:17:19  Lr: 0.030000  Loss: -2.4082  Acc@1: 75.0000 (80.1771)  Acc@5: 93.7500 (96.1172)  time: 0.3894  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1110/3750]  eta: 0:17:15  Lr: 0.030000  Loss: -2.4259  Acc@1: 87.5000 (80.2036)  Acc@5: 100.0000 (96.1352)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1120/3750]  eta: 0:17:11  Lr: 0.030000  Loss: -2.9782  Acc@1: 81.2500 (80.2353)  Acc@5: 100.0000 (96.1363)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1130/3750]  eta: 0:17:07  Lr: 0.030000  Loss: -2.2171  Acc@1: 81.2500 (80.2553)  Acc@5: 93.7500 (96.1317)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1140/3750]  eta: 0:17:03  Lr: 0.030000  Loss: -2.2264  Acc@1: 81.2500 (80.2202)  Acc@5: 93.7500 (96.1273)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1150/3750]  eta: 0:16:59  Lr: 0.030000  Loss: -2.5293  Acc@1: 75.0000 (80.1803)  Acc@5: 100.0000 (96.1175)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1160/3750]  eta: 0:16:55  Lr: 0.030000  Loss: -2.1962  Acc@1: 81.2500 (80.2003)  Acc@5: 93.7500 (96.1079)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1170/3750]  eta: 0:16:51  Lr: 0.030000  Loss: -2.6997  Acc@1: 87.5000 (80.2412)  Acc@5: 100.0000 (96.1198)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1180/3750]  eta: 0:16:47  Lr: 0.030000  Loss: -2.7281  Acc@1: 81.2500 (80.2710)  Acc@5: 100.0000 (96.1367)  time: 0.3922  data: 0.0011  max mem: 2908
Train: Epoch[2/5]  [1190/3750]  eta: 0:16:43  Lr: 0.030000  Loss: -2.5883  Acc@1: 81.2500 (80.2792)  Acc@5: 100.0000 (96.1272)  time: 0.3935  data: 0.0017  max mem: 2908
Train: Epoch[2/5]  [1200/3750]  eta: 0:16:39  Lr: 0.030000  Loss: -2.5348  Acc@1: 81.2500 (80.2612)  Acc@5: 100.0000 (96.1334)  time: 0.3925  data: 0.0010  max mem: 2908
Train: Epoch[2/5]  [1210/3750]  eta: 0:16:36  Lr: 0.030000  Loss: -1.8956  Acc@1: 75.0000 (80.2126)  Acc@5: 100.0000 (96.1396)  time: 0.3921  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1220/3750]  eta: 0:16:32  Lr: 0.030000  Loss: -1.8327  Acc@1: 75.0000 (80.2058)  Acc@5: 100.0000 (96.1405)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1230/3750]  eta: 0:16:28  Lr: 0.030000  Loss: -2.8375  Acc@1: 81.2500 (80.2244)  Acc@5: 93.7500 (96.1413)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1240/3750]  eta: 0:16:24  Lr: 0.030000  Loss: -2.5602  Acc@1: 87.5000 (80.2579)  Acc@5: 100.0000 (96.1473)  time: 0.3915  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [1250/3750]  eta: 0:16:20  Lr: 0.030000  Loss: -2.4826  Acc@1: 87.5000 (80.2858)  Acc@5: 100.0000 (96.1381)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1260/3750]  eta: 0:16:16  Lr: 0.030000  Loss: -2.5712  Acc@1: 87.5000 (80.3182)  Acc@5: 93.7500 (96.1439)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1270/3750]  eta: 0:16:12  Lr: 0.030000  Loss: -2.7852  Acc@1: 87.5000 (80.3157)  Acc@5: 100.0000 (96.1497)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1280/3750]  eta: 0:16:08  Lr: 0.030000  Loss: -2.6462  Acc@1: 75.0000 (80.2742)  Acc@5: 93.7500 (96.1358)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1290/3750]  eta: 0:16:04  Lr: 0.030000  Loss: -2.9996  Acc@1: 75.0000 (80.2818)  Acc@5: 93.7500 (96.1416)  time: 0.3916  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1300/3750]  eta: 0:16:00  Lr: 0.030000  Loss: -2.5148  Acc@1: 81.2500 (80.2796)  Acc@5: 93.7500 (96.1376)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1310/3750]  eta: 0:15:56  Lr: 0.030000  Loss: -2.3483  Acc@1: 81.2500 (80.2727)  Acc@5: 93.7500 (96.1432)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1320/3750]  eta: 0:15:52  Lr: 0.030000  Loss: -2.0139  Acc@1: 81.2500 (80.2659)  Acc@5: 93.7500 (96.1393)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1330/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -2.6455  Acc@1: 81.2500 (80.3109)  Acc@5: 100.0000 (96.1448)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1340/3750]  eta: 0:15:44  Lr: 0.030000  Loss: -2.2396  Acc@1: 87.5000 (80.3085)  Acc@5: 100.0000 (96.1503)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1350/3750]  eta: 0:15:41  Lr: 0.030000  Loss: -1.8810  Acc@1: 75.0000 (80.2739)  Acc@5: 100.0000 (96.1417)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1360/3750]  eta: 0:15:37  Lr: 0.030000  Loss: -2.4314  Acc@1: 75.0000 (80.2856)  Acc@5: 100.0000 (96.1563)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1370/3750]  eta: 0:15:33  Lr: 0.030000  Loss: -2.1814  Acc@1: 87.5000 (80.3063)  Acc@5: 100.0000 (96.1570)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1380/3750]  eta: 0:15:29  Lr: 0.030000  Loss: -2.1978  Acc@1: 81.2500 (80.3041)  Acc@5: 93.7500 (96.1486)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1390/3750]  eta: 0:15:25  Lr: 0.030000  Loss: -1.5729  Acc@1: 75.0000 (80.2705)  Acc@5: 93.7500 (96.1359)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1400/3750]  eta: 0:15:21  Lr: 0.030000  Loss: -2.3226  Acc@1: 81.2500 (80.2909)  Acc@5: 93.7500 (96.1411)  time: 0.3927  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [1410/3750]  eta: 0:15:17  Lr: 0.030000  Loss: -2.3138  Acc@1: 81.2500 (80.2888)  Acc@5: 100.0000 (96.1419)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1420/3750]  eta: 0:15:13  Lr: 0.030000  Loss: -2.5686  Acc@1: 81.2500 (80.2912)  Acc@5: 100.0000 (96.1427)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1430/3750]  eta: 0:15:09  Lr: 0.030000  Loss: -2.8904  Acc@1: 81.2500 (80.2935)  Acc@5: 93.7500 (96.1478)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1440/3750]  eta: 0:15:05  Lr: 0.030000  Loss: -2.2332  Acc@1: 81.2500 (80.3175)  Acc@5: 93.7500 (96.1268)  time: 0.3928  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1450/3750]  eta: 0:15:01  Lr: 0.030000  Loss: -1.6261  Acc@1: 81.2500 (80.3282)  Acc@5: 93.7500 (96.1320)  time: 0.3927  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1460/3750]  eta: 0:14:57  Lr: 0.030000  Loss: -1.8810  Acc@1: 81.2500 (80.3474)  Acc@5: 100.0000 (96.1285)  time: 0.3930  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1470/3750]  eta: 0:14:53  Lr: 0.030000  Loss: -2.1941  Acc@1: 81.2500 (80.3747)  Acc@5: 100.0000 (96.1293)  time: 0.3926  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1480/3750]  eta: 0:14:50  Lr: 0.030000  Loss: -2.1141  Acc@1: 75.0000 (80.3469)  Acc@5: 93.7500 (96.1344)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1490/3750]  eta: 0:14:46  Lr: 0.030000  Loss: -2.3612  Acc@1: 81.2500 (80.3781)  Acc@5: 100.0000 (96.1435)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1500/3750]  eta: 0:14:42  Lr: 0.030000  Loss: -2.3863  Acc@1: 87.5000 (80.4297)  Acc@5: 100.0000 (96.1567)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1510/3750]  eta: 0:14:38  Lr: 0.030000  Loss: -2.6440  Acc@1: 87.5000 (80.4476)  Acc@5: 100.0000 (96.1532)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1520/3750]  eta: 0:14:34  Lr: 0.030000  Loss: -1.9724  Acc@1: 81.2500 (80.4652)  Acc@5: 93.7500 (96.1497)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1530/3750]  eta: 0:14:30  Lr: 0.030000  Loss: -2.6686  Acc@1: 81.2500 (80.4744)  Acc@5: 100.0000 (96.1586)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1540/3750]  eta: 0:14:26  Lr: 0.030000  Loss: -2.6368  Acc@1: 81.2500 (80.4753)  Acc@5: 93.7500 (96.1389)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1550/3750]  eta: 0:14:22  Lr: 0.030000  Loss: -2.6401  Acc@1: 81.2500 (80.4965)  Acc@5: 93.7500 (96.1396)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1560/3750]  eta: 0:14:18  Lr: 0.030000  Loss: -2.7997  Acc@1: 81.2500 (80.5053)  Acc@5: 100.0000 (96.1483)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1570/3750]  eta: 0:14:14  Lr: 0.030000  Loss: -2.4097  Acc@1: 81.2500 (80.4981)  Acc@5: 93.7500 (96.1410)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1580/3750]  eta: 0:14:10  Lr: 0.030000  Loss: -2.9878  Acc@1: 81.2500 (80.4989)  Acc@5: 93.7500 (96.1496)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1590/3750]  eta: 0:14:06  Lr: 0.030000  Loss: -2.3740  Acc@1: 81.2500 (80.4761)  Acc@5: 100.0000 (96.1541)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1600/3750]  eta: 0:14:02  Lr: 0.030000  Loss: -2.5358  Acc@1: 87.5000 (80.5239)  Acc@5: 100.0000 (96.1587)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1610/3750]  eta: 0:13:58  Lr: 0.030000  Loss: -2.5182  Acc@1: 87.5000 (80.5129)  Acc@5: 100.0000 (96.1592)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1620/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -1.7654  Acc@1: 81.2500 (80.5097)  Acc@5: 100.0000 (96.1598)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1630/3750]  eta: 0:13:51  Lr: 0.030000  Loss: -2.1431  Acc@1: 81.2500 (80.5143)  Acc@5: 100.0000 (96.1565)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1640/3750]  eta: 0:13:47  Lr: 0.030000  Loss: -2.7019  Acc@1: 81.2500 (80.5073)  Acc@5: 100.0000 (96.1533)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1650/3750]  eta: 0:13:43  Lr: 0.030000  Loss: -2.8380  Acc@1: 81.2500 (80.5118)  Acc@5: 93.7500 (96.1538)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1660/3750]  eta: 0:13:39  Lr: 0.030000  Loss: -1.5433  Acc@1: 81.2500 (80.5050)  Acc@5: 93.7500 (96.1507)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1670/3750]  eta: 0:13:35  Lr: 0.030000  Loss: -1.8584  Acc@1: 81.2500 (80.4982)  Acc@5: 93.7500 (96.1513)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1680/3750]  eta: 0:13:31  Lr: 0.030000  Loss: -1.7989  Acc@1: 81.2500 (80.4692)  Acc@5: 100.0000 (96.1630)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1690/3750]  eta: 0:13:27  Lr: 0.030000  Loss: -2.3057  Acc@1: 81.2500 (80.4554)  Acc@5: 100.0000 (96.1598)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1700/3750]  eta: 0:13:23  Lr: 0.030000  Loss: -2.3479  Acc@1: 81.2500 (80.4417)  Acc@5: 93.7500 (96.1493)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1710/3750]  eta: 0:13:19  Lr: 0.030000  Loss: -2.9033  Acc@1: 81.2500 (80.4354)  Acc@5: 93.7500 (96.1353)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1720/3750]  eta: 0:13:15  Lr: 0.030000  Loss: -2.5788  Acc@1: 81.2500 (80.4184)  Acc@5: 93.7500 (96.1360)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1730/3750]  eta: 0:13:11  Lr: 0.030000  Loss: -2.4614  Acc@1: 87.5000 (80.4376)  Acc@5: 93.7500 (96.1330)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1740/3750]  eta: 0:13:07  Lr: 0.030000  Loss: -2.6413  Acc@1: 87.5000 (80.4423)  Acc@5: 93.7500 (96.1337)  time: 0.3918  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [1750/3750]  eta: 0:13:03  Lr: 0.030000  Loss: -2.1411  Acc@1: 75.0000 (80.4326)  Acc@5: 100.0000 (96.1379)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1760/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -2.7831  Acc@1: 75.0000 (80.4089)  Acc@5: 93.7500 (96.1173)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1770/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -2.1286  Acc@1: 81.2500 (80.3854)  Acc@5: 93.7500 (96.1004)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1780/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -2.6935  Acc@1: 81.2500 (80.3902)  Acc@5: 93.7500 (96.0837)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1790/3750]  eta: 0:12:48  Lr: 0.030000  Loss: -2.7784  Acc@1: 81.2500 (80.3985)  Acc@5: 93.7500 (96.0706)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1800/3750]  eta: 0:12:44  Lr: 0.030000  Loss: -2.7134  Acc@1: 81.2500 (80.3894)  Acc@5: 93.7500 (96.0612)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1810/3750]  eta: 0:12:40  Lr: 0.030000  Loss: -1.8996  Acc@1: 68.7500 (80.3458)  Acc@5: 100.0000 (96.0588)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1820/3750]  eta: 0:12:36  Lr: 0.030000  Loss: -2.3171  Acc@1: 75.0000 (80.3611)  Acc@5: 100.0000 (96.0702)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1830/3750]  eta: 0:12:32  Lr: 0.030000  Loss: -2.1109  Acc@1: 75.0000 (80.3454)  Acc@5: 100.0000 (96.0745)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1840/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -2.4376  Acc@1: 75.0000 (80.3402)  Acc@5: 93.7500 (96.0619)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1850/3750]  eta: 0:12:24  Lr: 0.030000  Loss: -2.4538  Acc@1: 81.2500 (80.3586)  Acc@5: 100.0000 (96.0731)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1860/3750]  eta: 0:12:20  Lr: 0.030000  Loss: -2.7731  Acc@1: 81.2500 (80.3701)  Acc@5: 100.0000 (96.0774)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1870/3750]  eta: 0:12:16  Lr: 0.030000  Loss: -2.4929  Acc@1: 81.2500 (80.3781)  Acc@5: 100.0000 (96.0783)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1880/3750]  eta: 0:12:12  Lr: 0.030000  Loss: -2.3243  Acc@1: 81.2500 (80.3761)  Acc@5: 93.7500 (96.0759)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1890/3750]  eta: 0:12:08  Lr: 0.030000  Loss: -2.4179  Acc@1: 75.0000 (80.3642)  Acc@5: 100.0000 (96.0867)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1900/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -2.1926  Acc@1: 75.0000 (80.3557)  Acc@5: 93.7500 (96.0777)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1910/3750]  eta: 0:12:01  Lr: 0.030000  Loss: -1.6687  Acc@1: 81.2500 (80.3702)  Acc@5: 93.7500 (96.0819)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1920/3750]  eta: 0:11:57  Lr: 0.030000  Loss: -2.3786  Acc@1: 81.2500 (80.3650)  Acc@5: 100.0000 (96.0958)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1930/3750]  eta: 0:11:53  Lr: 0.030000  Loss: -2.4262  Acc@1: 81.2500 (80.3599)  Acc@5: 93.7500 (96.0836)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1940/3750]  eta: 0:11:49  Lr: 0.030000  Loss: -3.0047  Acc@1: 81.2500 (80.3420)  Acc@5: 93.7500 (96.0748)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [1950/3750]  eta: 0:11:45  Lr: 0.030000  Loss: -2.8007  Acc@1: 81.2500 (80.3562)  Acc@5: 93.7500 (96.0757)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1960/3750]  eta: 0:11:41  Lr: 0.030000  Loss: -2.7867  Acc@1: 81.2500 (80.3767)  Acc@5: 100.0000 (96.0766)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [1970/3750]  eta: 0:11:37  Lr: 0.030000  Loss: -2.5748  Acc@1: 81.2500 (80.4002)  Acc@5: 93.7500 (96.0775)  time: 0.3931  data: 0.0006  max mem: 2908
Train: Epoch[2/5]  [1980/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -2.4912  Acc@1: 81.2500 (80.4234)  Acc@5: 100.0000 (96.0847)  time: 0.3931  data: 0.0006  max mem: 2908
Train: Epoch[2/5]  [1990/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -2.8626  Acc@1: 81.2500 (80.4401)  Acc@5: 100.0000 (96.0855)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2000/3750]  eta: 0:11:25  Lr: 0.030000  Loss: -2.7954  Acc@1: 81.2500 (80.4504)  Acc@5: 100.0000 (96.0895)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2010/3750]  eta: 0:11:21  Lr: 0.030000  Loss: -2.5111  Acc@1: 81.2500 (80.4730)  Acc@5: 100.0000 (96.0934)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2020/3750]  eta: 0:11:17  Lr: 0.030000  Loss: -2.3073  Acc@1: 81.2500 (80.4923)  Acc@5: 93.7500 (96.0849)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2030/3750]  eta: 0:11:13  Lr: 0.030000  Loss: -1.9360  Acc@1: 81.2500 (80.4684)  Acc@5: 93.7500 (96.0764)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2040/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -2.8514  Acc@1: 81.2500 (80.4936)  Acc@5: 93.7500 (96.0804)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2050/3750]  eta: 0:11:06  Lr: 0.030000  Loss: -2.6506  Acc@1: 81.2500 (80.5034)  Acc@5: 100.0000 (96.0873)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2060/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -2.3191  Acc@1: 81.2500 (80.5101)  Acc@5: 100.0000 (96.0941)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2070/3750]  eta: 0:10:58  Lr: 0.030000  Loss: -2.4966  Acc@1: 81.2500 (80.5046)  Acc@5: 100.0000 (96.0979)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2080/3750]  eta: 0:10:54  Lr: 0.030000  Loss: -2.3478  Acc@1: 81.2500 (80.5082)  Acc@5: 100.0000 (96.0956)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2090/3750]  eta: 0:10:50  Lr: 0.030000  Loss: -2.4653  Acc@1: 81.2500 (80.4968)  Acc@5: 93.7500 (96.0844)  time: 0.3942  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2100/3750]  eta: 0:10:46  Lr: 0.030000  Loss: -2.5801  Acc@1: 81.2500 (80.5093)  Acc@5: 100.0000 (96.0911)  time: 0.3924  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [2110/3750]  eta: 0:10:42  Lr: 0.030000  Loss: -2.7711  Acc@1: 81.2500 (80.5128)  Acc@5: 100.0000 (96.0949)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2120/3750]  eta: 0:10:38  Lr: 0.030000  Loss: -2.7070  Acc@1: 81.2500 (80.5015)  Acc@5: 100.0000 (96.1044)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2130/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -1.6372  Acc@1: 81.2500 (80.5109)  Acc@5: 100.0000 (96.1080)  time: 0.3894  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2140/3750]  eta: 0:10:30  Lr: 0.030000  Loss: -2.1556  Acc@1: 81.2500 (80.5173)  Acc@5: 100.0000 (96.1145)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2150/3750]  eta: 0:10:26  Lr: 0.030000  Loss: -2.5997  Acc@1: 75.0000 (80.4974)  Acc@5: 93.7500 (96.1094)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2160/3750]  eta: 0:10:22  Lr: 0.030000  Loss: -2.7909  Acc@1: 75.0000 (80.4922)  Acc@5: 93.7500 (96.0984)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2170/3750]  eta: 0:10:18  Lr: 0.030000  Loss: -2.7150  Acc@1: 81.2500 (80.5130)  Acc@5: 93.7500 (96.1049)  time: 0.3894  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2180/3750]  eta: 0:10:15  Lr: 0.030000  Loss: -2.9376  Acc@1: 81.2500 (80.5164)  Acc@5: 100.0000 (96.0912)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2190/3750]  eta: 0:10:11  Lr: 0.030000  Loss: -2.3209  Acc@1: 81.2500 (80.5254)  Acc@5: 93.7500 (96.0777)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2200/3750]  eta: 0:10:07  Lr: 0.030000  Loss: -2.3495  Acc@1: 81.2500 (80.5486)  Acc@5: 93.7500 (96.0813)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2210/3750]  eta: 0:10:03  Lr: 0.030000  Loss: -2.5460  Acc@1: 81.2500 (80.5546)  Acc@5: 100.0000 (96.0877)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2220/3750]  eta: 0:09:59  Lr: 0.030000  Loss: -2.3994  Acc@1: 81.2500 (80.5634)  Acc@5: 100.0000 (96.0969)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2230/3750]  eta: 0:09:55  Lr: 0.030000  Loss: -2.0020  Acc@1: 81.2500 (80.5636)  Acc@5: 100.0000 (96.0976)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2240/3750]  eta: 0:09:51  Lr: 0.030000  Loss: -2.6489  Acc@1: 81.2500 (80.5723)  Acc@5: 100.0000 (96.1011)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2250/3750]  eta: 0:09:47  Lr: 0.030000  Loss: -2.2644  Acc@1: 81.2500 (80.5836)  Acc@5: 93.7500 (96.0906)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2260/3750]  eta: 0:09:43  Lr: 0.030000  Loss: -2.2317  Acc@1: 81.2500 (80.5838)  Acc@5: 93.7500 (96.0858)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2270/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -2.8075  Acc@1: 81.2500 (80.5950)  Acc@5: 100.0000 (96.0948)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2280/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -2.7917  Acc@1: 81.2500 (80.5897)  Acc@5: 100.0000 (96.1009)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2290/3750]  eta: 0:09:31  Lr: 0.030000  Loss: -2.5710  Acc@1: 81.2500 (80.5980)  Acc@5: 93.7500 (96.0989)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2300/3750]  eta: 0:09:27  Lr: 0.030000  Loss: -2.2839  Acc@1: 81.2500 (80.6117)  Acc@5: 93.7500 (96.1077)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2310/3750]  eta: 0:09:23  Lr: 0.030000  Loss: -2.5060  Acc@1: 81.2500 (80.6063)  Acc@5: 93.7500 (96.1056)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2320/3750]  eta: 0:09:20  Lr: 0.030000  Loss: -2.1403  Acc@1: 81.2500 (80.6118)  Acc@5: 100.0000 (96.1170)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2330/3750]  eta: 0:09:16  Lr: 0.030000  Loss: -2.3501  Acc@1: 81.2500 (80.6038)  Acc@5: 100.0000 (96.1122)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2340/3750]  eta: 0:09:12  Lr: 0.030000  Loss: -2.2441  Acc@1: 81.2500 (80.6253)  Acc@5: 93.7500 (96.1181)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2350/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -2.4686  Acc@1: 81.2500 (80.5960)  Acc@5: 100.0000 (96.1134)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2360/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -2.8288  Acc@1: 81.2500 (80.5961)  Acc@5: 93.7500 (96.1139)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2370/3750]  eta: 0:09:00  Lr: 0.030000  Loss: -2.6479  Acc@1: 81.2500 (80.6015)  Acc@5: 100.0000 (96.1145)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2380/3750]  eta: 0:08:56  Lr: 0.030000  Loss: -2.6692  Acc@1: 81.2500 (80.6069)  Acc@5: 100.0000 (96.1151)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2390/3750]  eta: 0:08:52  Lr: 0.030000  Loss: -2.6862  Acc@1: 81.2500 (80.6070)  Acc@5: 93.7500 (96.1026)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2400/3750]  eta: 0:08:48  Lr: 0.030000  Loss: -2.8249  Acc@1: 81.2500 (80.6201)  Acc@5: 100.0000 (96.1110)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2410/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -2.6062  Acc@1: 81.2500 (80.6330)  Acc@5: 100.0000 (96.1168)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2420/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -2.3201  Acc@1: 81.2500 (80.6330)  Acc@5: 100.0000 (96.1199)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2430/3750]  eta: 0:08:36  Lr: 0.030000  Loss: -2.3655  Acc@1: 81.2500 (80.6355)  Acc@5: 100.0000 (96.1230)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2440/3750]  eta: 0:08:32  Lr: 0.030000  Loss: -2.4795  Acc@1: 81.2500 (80.6355)  Acc@5: 100.0000 (96.1286)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2450/3750]  eta: 0:08:29  Lr: 0.030000  Loss: -2.5047  Acc@1: 81.2500 (80.6329)  Acc@5: 93.7500 (96.1240)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2460/3750]  eta: 0:08:25  Lr: 0.030000  Loss: -2.7363  Acc@1: 81.2500 (80.6405)  Acc@5: 93.7500 (96.1271)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2470/3750]  eta: 0:08:21  Lr: 0.030000  Loss: -2.3960  Acc@1: 81.2500 (80.6581)  Acc@5: 100.0000 (96.1276)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2480/3750]  eta: 0:08:17  Lr: 0.030000  Loss: -2.5532  Acc@1: 81.2500 (80.6580)  Acc@5: 100.0000 (96.1356)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2490/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -2.5913  Acc@1: 81.2500 (80.6654)  Acc@5: 100.0000 (96.1361)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2500/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -2.4900  Acc@1: 81.2500 (80.6552)  Acc@5: 100.0000 (96.1390)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2510/3750]  eta: 0:08:05  Lr: 0.030000  Loss: -2.4973  Acc@1: 75.0000 (80.6477)  Acc@5: 100.0000 (96.1295)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2520/3750]  eta: 0:08:01  Lr: 0.030000  Loss: -2.0811  Acc@1: 75.0000 (80.6525)  Acc@5: 93.7500 (96.1350)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:57  Lr: 0.030000  Loss: -2.7998  Acc@1: 81.2500 (80.6623)  Acc@5: 93.7500 (96.1330)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:53  Lr: 0.030000  Loss: -2.3386  Acc@1: 75.0000 (80.6277)  Acc@5: 93.7500 (96.1285)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2550/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -2.4588  Acc@1: 75.0000 (80.6130)  Acc@5: 93.7500 (96.1314)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2560/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -2.2010  Acc@1: 75.0000 (80.6033)  Acc@5: 100.0000 (96.1294)  time: 0.3916  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2570/3750]  eta: 0:07:42  Lr: 0.030000  Loss: -2.3769  Acc@1: 81.2500 (80.5936)  Acc@5: 100.0000 (96.1323)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2580/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -2.1732  Acc@1: 81.2500 (80.5938)  Acc@5: 100.0000 (96.1425)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2590/3750]  eta: 0:07:34  Lr: 0.030000  Loss: -2.7060  Acc@1: 81.2500 (80.5987)  Acc@5: 100.0000 (96.1453)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2600/3750]  eta: 0:07:30  Lr: 0.030000  Loss: -2.1130  Acc@1: 81.2500 (80.6012)  Acc@5: 100.0000 (96.1481)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2610/3750]  eta: 0:07:26  Lr: 0.030000  Loss: -3.0294  Acc@1: 81.2500 (80.6109)  Acc@5: 100.0000 (96.1485)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2620/3750]  eta: 0:07:22  Lr: 0.030000  Loss: -2.2546  Acc@1: 81.2500 (80.6205)  Acc@5: 100.0000 (96.1513)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2630/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -2.3505  Acc@1: 81.2500 (80.6181)  Acc@5: 100.0000 (96.1588)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2640/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -2.1566  Acc@1: 81.2500 (80.6252)  Acc@5: 100.0000 (96.1568)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2650/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -2.3311  Acc@1: 81.2500 (80.6488)  Acc@5: 100.0000 (96.1618)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2660/3750]  eta: 0:07:06  Lr: 0.030000  Loss: -2.2633  Acc@1: 87.5000 (80.6534)  Acc@5: 100.0000 (96.1622)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2670/3750]  eta: 0:07:02  Lr: 0.030000  Loss: -2.3133  Acc@1: 81.2500 (80.6486)  Acc@5: 100.0000 (96.1625)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:58  Lr: 0.030000  Loss: -2.0355  Acc@1: 75.0000 (80.6252)  Acc@5: 93.7500 (96.1581)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:55  Lr: 0.030000  Loss: -2.1007  Acc@1: 81.2500 (80.6577)  Acc@5: 93.7500 (96.1655)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:51  Lr: 0.030000  Loss: -2.8715  Acc@1: 87.5000 (80.6646)  Acc@5: 100.0000 (96.1704)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:47  Lr: 0.030000  Loss: -1.8839  Acc@1: 81.2500 (80.6598)  Acc@5: 100.0000 (96.1684)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2720/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -1.9254  Acc@1: 81.2500 (80.6528)  Acc@5: 93.7500 (96.1641)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2730/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -2.4504  Acc@1: 81.2500 (80.6618)  Acc@5: 93.7500 (96.1667)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2740/3750]  eta: 0:06:35  Lr: 0.030000  Loss: -2.4945  Acc@1: 81.2500 (80.6731)  Acc@5: 100.0000 (96.1693)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2750/3750]  eta: 0:06:31  Lr: 0.030000  Loss: -2.5814  Acc@1: 81.2500 (80.6752)  Acc@5: 100.0000 (96.1718)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2760/3750]  eta: 0:06:27  Lr: 0.030000  Loss: -2.3760  Acc@1: 87.5000 (80.7022)  Acc@5: 100.0000 (96.1721)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2770/3750]  eta: 0:06:23  Lr: 0.030000  Loss: -2.2933  Acc@1: 87.5000 (80.7290)  Acc@5: 100.0000 (96.1792)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2780/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -2.8349  Acc@1: 87.5000 (80.7309)  Acc@5: 100.0000 (96.1794)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2790/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -2.1089  Acc@1: 81.2500 (80.7350)  Acc@5: 100.0000 (96.1774)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2800/3750]  eta: 0:06:11  Lr: 0.030000  Loss: -2.6270  Acc@1: 81.2500 (80.7346)  Acc@5: 100.0000 (96.1822)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2810/3750]  eta: 0:06:08  Lr: 0.030000  Loss: -2.4444  Acc@1: 81.2500 (80.7342)  Acc@5: 93.7500 (96.1757)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2820/3750]  eta: 0:06:04  Lr: 0.030000  Loss: -2.7237  Acc@1: 81.2500 (80.7515)  Acc@5: 93.7500 (96.1760)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2830/3750]  eta: 0:06:00  Lr: 0.030000  Loss: -2.8333  Acc@1: 81.2500 (80.7533)  Acc@5: 100.0000 (96.1851)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:56  Lr: 0.030000  Loss: -2.8792  Acc@1: 81.2500 (80.7550)  Acc@5: 100.0000 (96.1831)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:52  Lr: 0.030000  Loss: -2.9566  Acc@1: 81.2500 (80.7502)  Acc@5: 93.7500 (96.1834)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -2.8138  Acc@1: 87.5000 (80.7738)  Acc@5: 93.7500 (96.1836)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -2.7056  Acc@1: 87.5000 (80.7820)  Acc@5: 93.7500 (96.1838)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:40  Lr: 0.030000  Loss: -2.9303  Acc@1: 81.2500 (80.7727)  Acc@5: 100.0000 (96.1906)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:36  Lr: 0.030000  Loss: -1.8942  Acc@1: 81.2500 (80.7657)  Acc@5: 100.0000 (96.1886)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2900/3750]  eta: 0:05:32  Lr: 0.030000  Loss: -2.8535  Acc@1: 81.2500 (80.7782)  Acc@5: 100.0000 (96.1996)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2910/3750]  eta: 0:05:28  Lr: 0.030000  Loss: -2.4940  Acc@1: 81.2500 (80.7669)  Acc@5: 100.0000 (96.2041)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2920/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -1.7753  Acc@1: 81.2500 (80.7579)  Acc@5: 100.0000 (96.2021)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2930/3750]  eta: 0:05:21  Lr: 0.030000  Loss: -2.6710  Acc@1: 81.2500 (80.7660)  Acc@5: 93.7500 (96.2044)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2940/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -2.7987  Acc@1: 81.2500 (80.7591)  Acc@5: 100.0000 (96.2024)  time: 0.3900  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [2950/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -2.0147  Acc@1: 81.2500 (80.7735)  Acc@5: 100.0000 (96.2110)  time: 0.3907  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [2960/3750]  eta: 0:05:09  Lr: 0.030000  Loss: -2.5531  Acc@1: 81.2500 (80.7645)  Acc@5: 100.0000 (96.2091)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2970/3750]  eta: 0:05:05  Lr: 0.030000  Loss: -2.3130  Acc@1: 75.0000 (80.7535)  Acc@5: 93.7500 (96.2113)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [2980/3750]  eta: 0:05:01  Lr: 0.030000  Loss: -2.5593  Acc@1: 75.0000 (80.7468)  Acc@5: 100.0000 (96.2156)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:57  Lr: 0.030000  Loss: -2.3110  Acc@1: 81.2500 (80.7464)  Acc@5: 100.0000 (96.2095)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -2.5576  Acc@1: 81.2500 (80.7543)  Acc@5: 100.0000 (96.2117)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -2.7148  Acc@1: 81.2500 (80.7539)  Acc@5: 100.0000 (96.2160)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:45  Lr: 0.030000  Loss: -2.6503  Acc@1: 81.2500 (80.7555)  Acc@5: 100.0000 (96.2202)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:41  Lr: 0.030000  Loss: -2.0773  Acc@1: 81.2500 (80.7510)  Acc@5: 100.0000 (96.2203)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:37  Lr: 0.030000  Loss: -2.4643  Acc@1: 81.2500 (80.7526)  Acc@5: 93.7500 (96.2142)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:34  Lr: 0.030000  Loss: -2.5356  Acc@1: 81.2500 (80.7666)  Acc@5: 100.0000 (96.2185)  time: 0.3922  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:30  Lr: 0.030000  Loss: -2.6062  Acc@1: 87.5000 (80.7763)  Acc@5: 100.0000 (96.2165)  time: 0.3923  data: 0.0006  max mem: 2908
Train: Epoch[2/5]  [3070/3750]  eta: 0:04:26  Lr: 0.030000  Loss: -2.5897  Acc@1: 81.2500 (80.7799)  Acc@5: 93.7500 (96.2146)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3080/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -2.5052  Acc@1: 81.2500 (80.7875)  Acc@5: 100.0000 (96.2167)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3090/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -2.8070  Acc@1: 81.2500 (80.7930)  Acc@5: 100.0000 (96.2229)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -1.9819  Acc@1: 81.2500 (80.7925)  Acc@5: 100.0000 (96.2270)  time: 0.3918  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3110/3750]  eta: 0:04:10  Lr: 0.030000  Loss: -2.0532  Acc@1: 81.2500 (80.8000)  Acc@5: 100.0000 (96.2231)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3120/3750]  eta: 0:04:06  Lr: 0.030000  Loss: -2.4284  Acc@1: 81.2500 (80.8034)  Acc@5: 93.7500 (96.2212)  time: 0.3923  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3130/3750]  eta: 0:04:02  Lr: 0.030000  Loss: -2.0521  Acc@1: 81.2500 (80.8009)  Acc@5: 93.7500 (96.2113)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:58  Lr: 0.030000  Loss: -2.5783  Acc@1: 81.2500 (80.7963)  Acc@5: 93.7500 (96.2134)  time: 0.3919  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -2.6923  Acc@1: 75.0000 (80.7918)  Acc@5: 100.0000 (96.2195)  time: 0.3923  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:50  Lr: 0.030000  Loss: -2.0783  Acc@1: 75.0000 (80.7834)  Acc@5: 93.7500 (96.2097)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -2.5107  Acc@1: 75.0000 (80.7868)  Acc@5: 93.7500 (96.2118)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:43  Lr: 0.030000  Loss: -2.6958  Acc@1: 81.2500 (80.7981)  Acc@5: 100.0000 (96.2099)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -2.6204  Acc@1: 81.2500 (80.7878)  Acc@5: 100.0000 (96.2179)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -2.8633  Acc@1: 75.0000 (80.7775)  Acc@5: 100.0000 (96.2160)  time: 0.3918  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -2.7340  Acc@1: 81.2500 (80.7712)  Acc@5: 93.7500 (96.2045)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -2.4801  Acc@1: 81.2500 (80.7649)  Acc@5: 100.0000 (96.2143)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -2.7324  Acc@1: 81.2500 (80.7645)  Acc@5: 100.0000 (96.2086)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3240/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -2.1985  Acc@1: 81.2500 (80.7467)  Acc@5: 93.7500 (96.2010)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3250/3750]  eta: 0:03:15  Lr: 0.030000  Loss: -2.2295  Acc@1: 81.2500 (80.7309)  Acc@5: 93.7500 (96.2050)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3260/3750]  eta: 0:03:11  Lr: 0.030000  Loss: -1.8408  Acc@1: 75.0000 (80.7249)  Acc@5: 100.0000 (96.1994)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3270/3750]  eta: 0:03:07  Lr: 0.030000  Loss: -2.1969  Acc@1: 81.2500 (80.7169)  Acc@5: 93.7500 (96.1881)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3280/3750]  eta: 0:03:03  Lr: 0.030000  Loss: -2.6595  Acc@1: 81.2500 (80.7223)  Acc@5: 93.7500 (96.1883)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3290/3750]  eta: 0:03:00  Lr: 0.030000  Loss: -2.7037  Acc@1: 81.2500 (80.7239)  Acc@5: 100.0000 (96.1866)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -2.1448  Acc@1: 81.2500 (80.7161)  Acc@5: 100.0000 (96.1830)  time: 0.3906  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -2.6069  Acc@1: 81.2500 (80.7120)  Acc@5: 100.0000 (96.1832)  time: 0.3911  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -2.2869  Acc@1: 81.2500 (80.7268)  Acc@5: 100.0000 (96.1834)  time: 0.3918  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -2.1622  Acc@1: 87.5000 (80.7284)  Acc@5: 100.0000 (96.1817)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -2.3083  Acc@1: 81.2500 (80.7356)  Acc@5: 93.7500 (96.1782)  time: 0.3939  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -2.6231  Acc@1: 81.2500 (80.7334)  Acc@5: 93.7500 (96.1784)  time: 0.3929  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:32  Lr: 0.030000  Loss: -1.6870  Acc@1: 81.2500 (80.7349)  Acc@5: 100.0000 (96.1860)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -2.6583  Acc@1: 81.2500 (80.7346)  Acc@5: 100.0000 (96.1881)  time: 0.3923  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -2.1594  Acc@1: 81.2500 (80.7416)  Acc@5: 100.0000 (96.1920)  time: 0.3910  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:20  Lr: 0.030000  Loss: -2.6568  Acc@1: 81.2500 (80.7413)  Acc@5: 93.7500 (96.1848)  time: 0.3912  data: 0.0005  max mem: 2908
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -2.3323  Acc@1: 81.2500 (80.7428)  Acc@5: 93.7500 (96.1868)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -2.8617  Acc@1: 81.2500 (80.7406)  Acc@5: 100.0000 (96.1906)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -2.5683  Acc@1: 87.5000 (80.7549)  Acc@5: 100.0000 (96.1908)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -2.3419  Acc@1: 87.5000 (80.7727)  Acc@5: 100.0000 (96.1983)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -2.2811  Acc@1: 81.2500 (80.7650)  Acc@5: 100.0000 (96.1966)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -2.5503  Acc@1: 75.0000 (80.7501)  Acc@5: 100.0000 (96.2022)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -2.2294  Acc@1: 81.2500 (80.7516)  Acc@5: 100.0000 (96.2059)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -2.3632  Acc@1: 81.2500 (80.7584)  Acc@5: 100.0000 (96.2133)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -2.8740  Acc@1: 81.2500 (80.7724)  Acc@5: 100.0000 (96.2188)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:41  Lr: 0.030000  Loss: -2.3968  Acc@1: 81.2500 (80.7702)  Acc@5: 100.0000 (96.2188)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:37  Lr: 0.030000  Loss: -2.4892  Acc@1: 75.0000 (80.7591)  Acc@5: 93.7500 (96.2207)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -2.7915  Acc@1: 81.2500 (80.7658)  Acc@5: 100.0000 (96.2244)  time: 0.3895  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:30  Lr: 0.030000  Loss: -2.6670  Acc@1: 81.2500 (80.7725)  Acc@5: 100.0000 (96.2315)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -2.2728  Acc@1: 81.2500 (80.7703)  Acc@5: 100.0000 (96.2298)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -2.5200  Acc@1: 81.2500 (80.7787)  Acc@5: 100.0000 (96.2369)  time: 0.3898  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -2.2574  Acc@1: 81.2500 (80.7730)  Acc@5: 100.0000 (96.2352)  time: 0.3898  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -2.3999  Acc@1: 75.0000 (80.7638)  Acc@5: 100.0000 (96.2388)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -2.9753  Acc@1: 75.0000 (80.7582)  Acc@5: 93.7500 (96.2300)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -2.6250  Acc@1: 75.0000 (80.7456)  Acc@5: 93.7500 (96.2301)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -2.4026  Acc@1: 75.0000 (80.7383)  Acc@5: 93.7500 (96.2215)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -2.1549  Acc@1: 81.2500 (80.7501)  Acc@5: 93.7500 (96.2215)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -2.6364  Acc@1: 87.5000 (80.7619)  Acc@5: 100.0000 (96.2268)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:50  Lr: 0.030000  Loss: -2.6114  Acc@1: 87.5000 (80.7667)  Acc@5: 100.0000 (96.2286)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:46  Lr: 0.030000  Loss: -2.9798  Acc@1: 87.5000 (80.7732)  Acc@5: 100.0000 (96.2287)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -2.2923  Acc@1: 81.2500 (80.7728)  Acc@5: 93.7500 (96.2287)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -2.6921  Acc@1: 81.2500 (80.7741)  Acc@5: 100.0000 (96.2322)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -2.7501  Acc@1: 81.2500 (80.7874)  Acc@5: 100.0000 (96.2357)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -2.6872  Acc@1: 81.2500 (80.7886)  Acc@5: 100.0000 (96.2374)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -2.5225  Acc@1: 81.2500 (80.7916)  Acc@5: 100.0000 (96.2391)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -2.5719  Acc@1: 81.2500 (80.7911)  Acc@5: 93.7500 (96.2341)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -2.0158  Acc@1: 81.2500 (80.7974)  Acc@5: 93.7500 (96.2392)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -2.0899  Acc@1: 81.2500 (80.7818)  Acc@5: 93.7500 (96.2207)  time: 0.3929  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -2.0238  Acc@1: 75.0000 (80.7814)  Acc@5: 93.7500 (96.2174)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -1.8906  Acc@1: 81.2500 (80.7826)  Acc@5: 100.0000 (96.2225)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -2.3043  Acc@1: 81.2500 (80.7889)  Acc@5: 100.0000 (96.2243)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -1.2327  Acc@1: 81.2500 (80.7867)  Acc@5: 100.0000 (96.2217)  time: 0.3905  data: 0.0007  max mem: 2908
Train: Epoch[2/5] Total time: 0:24:28 (0.3916 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.2327  Acc@1: 81.2500 (80.7867)  Acc@5: 100.0000 (96.2217)
Train: Epoch[3/5]  [   0/3750]  eta: 0:47:02  Lr: 0.030000  Loss: -2.4334  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7528  data: 0.3587  max mem: 2908
Train: Epoch[3/5]  [  10/3750]  eta: 0:26:28  Lr: 0.030000  Loss: -2.8979  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.7273)  time: 0.4249  data: 0.0329  max mem: 2908
Train: Epoch[3/5]  [  20/3750]  eta: 0:25:27  Lr: 0.030000  Loss: -2.8386  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (97.9167)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [  30/3750]  eta: 0:24:59  Lr: 0.030000  Loss: -2.7915  Acc@1: 87.5000 (86.0887)  Acc@5: 100.0000 (97.1774)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [  40/3750]  eta: 0:24:44  Lr: 0.030000  Loss: -2.5797  Acc@1: 81.2500 (85.3659)  Acc@5: 93.7500 (96.4939)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [  50/3750]  eta: 0:24:33  Lr: 0.030000  Loss: -2.5847  Acc@1: 87.5000 (85.7843)  Acc@5: 93.7500 (96.4461)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [  60/3750]  eta: 0:24:24  Lr: 0.030000  Loss: -2.6182  Acc@1: 87.5000 (85.1434)  Acc@5: 93.7500 (96.2090)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [  70/3750]  eta: 0:24:17  Lr: 0.030000  Loss: -2.3959  Acc@1: 81.2500 (85.0352)  Acc@5: 100.0000 (96.3028)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [  80/3750]  eta: 0:24:10  Lr: 0.030000  Loss: -2.4401  Acc@1: 87.5000 (85.1080)  Acc@5: 100.0000 (96.4506)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [  90/3750]  eta: 0:24:04  Lr: 0.030000  Loss: -2.7291  Acc@1: 87.5000 (85.1648)  Acc@5: 100.0000 (96.4973)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 100/3750]  eta: 0:23:59  Lr: 0.030000  Loss: -2.6566  Acc@1: 81.2500 (85.0866)  Acc@5: 93.7500 (96.4109)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 110/3750]  eta: 0:23:53  Lr: 0.030000  Loss: -2.2196  Acc@1: 81.2500 (84.4032)  Acc@5: 93.7500 (96.3401)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 120/3750]  eta: 0:23:48  Lr: 0.030000  Loss: -1.9856  Acc@1: 75.0000 (83.9876)  Acc@5: 93.7500 (96.3326)  time: 0.3898  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 130/3750]  eta: 0:23:43  Lr: 0.030000  Loss: -2.5888  Acc@1: 81.2500 (83.7309)  Acc@5: 100.0000 (96.4695)  time: 0.3905  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [ 140/3750]  eta: 0:23:39  Lr: 0.030000  Loss: -2.8782  Acc@1: 81.2500 (83.5106)  Acc@5: 100.0000 (96.5869)  time: 0.3909  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [ 150/3750]  eta: 0:23:34  Lr: 0.030000  Loss: -2.2978  Acc@1: 81.2500 (83.6507)  Acc@5: 100.0000 (96.5646)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 160/3750]  eta: 0:23:30  Lr: 0.030000  Loss: -2.1423  Acc@1: 81.2500 (83.4239)  Acc@5: 100.0000 (96.5062)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 170/3750]  eta: 0:23:25  Lr: 0.030000  Loss: -1.9667  Acc@1: 81.2500 (83.1140)  Acc@5: 100.0000 (96.5278)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 180/3750]  eta: 0:23:21  Lr: 0.030000  Loss: -2.9479  Acc@1: 87.5000 (83.1837)  Acc@5: 100.0000 (96.6160)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 190/3750]  eta: 0:23:16  Lr: 0.030000  Loss: -1.8611  Acc@1: 81.2500 (82.7880)  Acc@5: 100.0000 (96.4660)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 200/3750]  eta: 0:23:12  Lr: 0.030000  Loss: -2.7791  Acc@1: 81.2500 (82.9602)  Acc@5: 93.7500 (96.4552)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 210/3750]  eta: 0:23:08  Lr: 0.030000  Loss: -2.9946  Acc@1: 87.5000 (82.9976)  Acc@5: 100.0000 (96.5047)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 220/3750]  eta: 0:23:04  Lr: 0.030000  Loss: -2.3338  Acc@1: 81.2500 (82.8620)  Acc@5: 100.0000 (96.4367)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 230/3750]  eta: 0:22:59  Lr: 0.030000  Loss: -2.7778  Acc@1: 81.2500 (83.0898)  Acc@5: 100.0000 (96.4827)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 240/3750]  eta: 0:22:55  Lr: 0.030000  Loss: -3.0059  Acc@1: 87.5000 (83.1172)  Acc@5: 100.0000 (96.4471)  time: 0.3888  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 250/3750]  eta: 0:22:51  Lr: 0.030000  Loss: -2.8865  Acc@1: 81.2500 (83.0677)  Acc@5: 93.7500 (96.3894)  time: 0.3894  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 260/3750]  eta: 0:22:47  Lr: 0.030000  Loss: -2.5916  Acc@1: 81.2500 (83.1418)  Acc@5: 93.7500 (96.3841)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 270/3750]  eta: 0:22:43  Lr: 0.030000  Loss: -2.3118  Acc@1: 87.5000 (83.2103)  Acc@5: 93.7500 (96.4022)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 280/3750]  eta: 0:22:39  Lr: 0.030000  Loss: -2.7568  Acc@1: 87.5000 (83.2295)  Acc@5: 93.7500 (96.4190)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 290/3750]  eta: 0:22:35  Lr: 0.030000  Loss: -2.6138  Acc@1: 87.5000 (83.2904)  Acc@5: 100.0000 (96.4777)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 300/3750]  eta: 0:22:30  Lr: 0.030000  Loss: -2.5123  Acc@1: 81.2500 (83.3264)  Acc@5: 100.0000 (96.4909)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 310/3750]  eta: 0:22:26  Lr: 0.030000  Loss: -2.2328  Acc@1: 81.2500 (83.2998)  Acc@5: 93.7500 (96.4228)  time: 0.3894  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 320/3750]  eta: 0:22:22  Lr: 0.030000  Loss: -2.2195  Acc@1: 81.2500 (82.9829)  Acc@5: 93.7500 (96.3396)  time: 0.3894  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 330/3750]  eta: 0:22:18  Lr: 0.030000  Loss: -2.8649  Acc@1: 81.2500 (83.1382)  Acc@5: 93.7500 (96.3746)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 340/3750]  eta: 0:22:14  Lr: 0.030000  Loss: -2.6570  Acc@1: 87.5000 (83.1928)  Acc@5: 100.0000 (96.3893)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 350/3750]  eta: 0:22:10  Lr: 0.030000  Loss: -2.7031  Acc@1: 81.2500 (83.0128)  Acc@5: 100.0000 (96.4209)  time: 0.3906  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [ 360/3750]  eta: 0:22:06  Lr: 0.030000  Loss: -2.3258  Acc@1: 81.2500 (82.8428)  Acc@5: 93.7500 (96.3470)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 370/3750]  eta: 0:22:02  Lr: 0.030000  Loss: -2.9177  Acc@1: 81.2500 (82.9009)  Acc@5: 100.0000 (96.3780)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 380/3750]  eta: 0:21:58  Lr: 0.030000  Loss: -2.1562  Acc@1: 87.5000 (82.8740)  Acc@5: 100.0000 (96.3911)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 390/3750]  eta: 0:21:54  Lr: 0.030000  Loss: -2.4207  Acc@1: 81.2500 (82.8804)  Acc@5: 100.0000 (96.3875)  time: 0.3914  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [ 400/3750]  eta: 0:21:50  Lr: 0.030000  Loss: -2.4597  Acc@1: 81.2500 (82.8709)  Acc@5: 100.0000 (96.3996)  time: 0.3905  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [ 410/3750]  eta: 0:21:46  Lr: 0.030000  Loss: -2.4552  Acc@1: 81.2500 (82.8315)  Acc@5: 93.7500 (96.3352)  time: 0.3891  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 420/3750]  eta: 0:21:42  Lr: 0.030000  Loss: -2.6047  Acc@1: 81.2500 (82.7791)  Acc@5: 93.7500 (96.3480)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 430/3750]  eta: 0:21:38  Lr: 0.030000  Loss: -2.8576  Acc@1: 81.2500 (82.7581)  Acc@5: 93.7500 (96.3312)  time: 0.3906  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [ 440/3750]  eta: 0:21:34  Lr: 0.030000  Loss: -2.5702  Acc@1: 87.5000 (82.8373)  Acc@5: 93.7500 (96.3435)  time: 0.3913  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [ 450/3750]  eta: 0:21:30  Lr: 0.030000  Loss: -2.5693  Acc@1: 81.2500 (82.7882)  Acc@5: 100.0000 (96.3553)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 460/3750]  eta: 0:21:26  Lr: 0.030000  Loss: -2.9529  Acc@1: 81.2500 (82.8362)  Acc@5: 100.0000 (96.3802)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 470/3750]  eta: 0:21:22  Lr: 0.030000  Loss: -2.6530  Acc@1: 81.2500 (82.7893)  Acc@5: 100.0000 (96.4039)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 480/3750]  eta: 0:21:18  Lr: 0.030000  Loss: -1.5094  Acc@1: 81.2500 (82.7573)  Acc@5: 100.0000 (96.3747)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 490/3750]  eta: 0:21:14  Lr: 0.030000  Loss: -2.3610  Acc@1: 81.2500 (82.7011)  Acc@5: 100.0000 (96.3977)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 500/3750]  eta: 0:21:10  Lr: 0.030000  Loss: -1.7157  Acc@1: 81.2500 (82.6597)  Acc@5: 100.0000 (96.3573)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 510/3750]  eta: 0:21:07  Lr: 0.030000  Loss: -2.3595  Acc@1: 81.2500 (82.6566)  Acc@5: 93.7500 (96.3674)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 520/3750]  eta: 0:21:03  Lr: 0.030000  Loss: -3.0351  Acc@1: 81.2500 (82.6895)  Acc@5: 100.0000 (96.4131)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 530/3750]  eta: 0:20:59  Lr: 0.030000  Loss: -1.5528  Acc@1: 81.2500 (82.6860)  Acc@5: 100.0000 (96.4101)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 540/3750]  eta: 0:20:55  Lr: 0.030000  Loss: -1.9559  Acc@1: 81.2500 (82.6248)  Acc@5: 100.0000 (96.4187)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 550/3750]  eta: 0:20:51  Lr: 0.030000  Loss: -2.4358  Acc@1: 75.0000 (82.5544)  Acc@5: 100.0000 (96.4270)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 560/3750]  eta: 0:20:47  Lr: 0.030000  Loss: -2.8480  Acc@1: 81.2500 (82.5535)  Acc@5: 100.0000 (96.4238)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 570/3750]  eta: 0:20:43  Lr: 0.030000  Loss: -2.5968  Acc@1: 81.2500 (82.5088)  Acc@5: 93.7500 (96.3989)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 580/3750]  eta: 0:20:39  Lr: 0.030000  Loss: -2.8989  Acc@1: 81.2500 (82.5516)  Acc@5: 93.7500 (96.4178)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 590/3750]  eta: 0:20:35  Lr: 0.030000  Loss: -2.6791  Acc@1: 81.2500 (82.5190)  Acc@5: 100.0000 (96.4044)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 600/3750]  eta: 0:20:32  Lr: 0.030000  Loss: -2.6526  Acc@1: 81.2500 (82.4355)  Acc@5: 100.0000 (96.4226)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 610/3750]  eta: 0:20:28  Lr: 0.030000  Loss: -2.8200  Acc@1: 81.2500 (82.4673)  Acc@5: 100.0000 (96.4403)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 620/3750]  eta: 0:20:24  Lr: 0.030000  Loss: -2.9950  Acc@1: 81.2500 (82.4980)  Acc@5: 100.0000 (96.4473)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 630/3750]  eta: 0:20:20  Lr: 0.030000  Loss: -2.4182  Acc@1: 81.2500 (82.5475)  Acc@5: 100.0000 (96.4739)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 640/3750]  eta: 0:20:16  Lr: 0.030000  Loss: -2.6425  Acc@1: 81.2500 (82.4590)  Acc@5: 100.0000 (96.4801)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 650/3750]  eta: 0:20:12  Lr: 0.030000  Loss: -2.6452  Acc@1: 81.2500 (82.4597)  Acc@5: 93.7500 (96.4670)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 660/3750]  eta: 0:20:08  Lr: 0.030000  Loss: -2.4404  Acc@1: 87.5000 (82.4792)  Acc@5: 93.7500 (96.4731)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 670/3750]  eta: 0:20:04  Lr: 0.030000  Loss: -2.2325  Acc@1: 81.2500 (82.4516)  Acc@5: 100.0000 (96.4605)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 680/3750]  eta: 0:20:00  Lr: 0.030000  Loss: -2.3223  Acc@1: 81.2500 (82.3880)  Acc@5: 93.7500 (96.4482)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 690/3750]  eta: 0:19:56  Lr: 0.030000  Loss: -2.7513  Acc@1: 81.2500 (82.4077)  Acc@5: 93.7500 (96.4092)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 700/3750]  eta: 0:19:52  Lr: 0.030000  Loss: -2.2658  Acc@1: 81.2500 (82.4001)  Acc@5: 93.7500 (96.4069)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 710/3750]  eta: 0:19:49  Lr: 0.030000  Loss: -1.1604  Acc@1: 81.2500 (82.4103)  Acc@5: 100.0000 (96.4223)  time: 0.3930  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 720/3750]  eta: 0:19:45  Lr: 0.030000  Loss: -2.8423  Acc@1: 81.2500 (82.4202)  Acc@5: 100.0000 (96.4372)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 730/3750]  eta: 0:19:41  Lr: 0.030000  Loss: -2.7748  Acc@1: 81.2500 (82.4042)  Acc@5: 100.0000 (96.4518)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 740/3750]  eta: 0:19:37  Lr: 0.030000  Loss: -2.5217  Acc@1: 81.2500 (82.3971)  Acc@5: 93.7500 (96.4322)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 750/3750]  eta: 0:19:33  Lr: 0.030000  Loss: -2.6215  Acc@1: 81.2500 (82.3735)  Acc@5: 93.7500 (96.4298)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 760/3750]  eta: 0:19:29  Lr: 0.030000  Loss: -2.2567  Acc@1: 81.2500 (82.3095)  Acc@5: 100.0000 (96.4274)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 770/3750]  eta: 0:19:25  Lr: 0.030000  Loss: -2.7581  Acc@1: 75.0000 (82.2795)  Acc@5: 100.0000 (96.4008)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 780/3750]  eta: 0:19:21  Lr: 0.030000  Loss: -2.5381  Acc@1: 75.0000 (82.1863)  Acc@5: 93.7500 (96.4069)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 790/3750]  eta: 0:19:17  Lr: 0.030000  Loss: -2.3607  Acc@1: 75.0000 (82.1508)  Acc@5: 100.0000 (96.4207)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 800/3750]  eta: 0:19:13  Lr: 0.030000  Loss: -1.7234  Acc@1: 81.2500 (82.1317)  Acc@5: 100.0000 (96.4185)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 810/3750]  eta: 0:19:09  Lr: 0.030000  Loss: -2.0143  Acc@1: 75.0000 (82.0669)  Acc@5: 93.7500 (96.4010)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 820/3750]  eta: 0:19:05  Lr: 0.030000  Loss: -2.5717  Acc@1: 81.2500 (82.0874)  Acc@5: 100.0000 (96.3992)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 830/3750]  eta: 0:19:02  Lr: 0.030000  Loss: -2.1692  Acc@1: 81.2500 (82.0773)  Acc@5: 100.0000 (96.4049)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 840/3750]  eta: 0:18:58  Lr: 0.030000  Loss: -2.4563  Acc@1: 81.2500 (82.0229)  Acc@5: 100.0000 (96.3882)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 850/3750]  eta: 0:18:54  Lr: 0.030000  Loss: -2.3309  Acc@1: 75.0000 (81.9771)  Acc@5: 100.0000 (96.3646)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 860/3750]  eta: 0:18:50  Lr: 0.030000  Loss: -2.6377  Acc@1: 81.2500 (82.0557)  Acc@5: 100.0000 (96.3850)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 870/3750]  eta: 0:18:46  Lr: 0.030000  Loss: -2.5382  Acc@1: 87.5000 (82.0537)  Acc@5: 100.0000 (96.3548)  time: 0.3893  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 880/3750]  eta: 0:18:42  Lr: 0.030000  Loss: -2.3445  Acc@1: 81.2500 (82.0233)  Acc@5: 93.7500 (96.3465)  time: 0.3890  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 890/3750]  eta: 0:18:38  Lr: 0.030000  Loss: -2.1724  Acc@1: 81.2500 (82.0637)  Acc@5: 100.0000 (96.3735)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 900/3750]  eta: 0:18:34  Lr: 0.030000  Loss: -2.6091  Acc@1: 87.5000 (82.1310)  Acc@5: 100.0000 (96.3790)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 910/3750]  eta: 0:18:30  Lr: 0.030000  Loss: -1.6276  Acc@1: 81.2500 (82.0321)  Acc@5: 93.7500 (96.3227)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 920/3750]  eta: 0:18:26  Lr: 0.030000  Loss: -2.5656  Acc@1: 75.0000 (81.9897)  Acc@5: 93.7500 (96.3151)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 930/3750]  eta: 0:18:22  Lr: 0.030000  Loss: -2.2254  Acc@1: 81.2500 (81.9683)  Acc@5: 93.7500 (96.3077)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 940/3750]  eta: 0:18:18  Lr: 0.030000  Loss: -2.5410  Acc@1: 81.2500 (81.8943)  Acc@5: 100.0000 (96.3005)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 950/3750]  eta: 0:18:14  Lr: 0.030000  Loss: -2.5238  Acc@1: 81.2500 (81.9532)  Acc@5: 100.0000 (96.3131)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 960/3750]  eta: 0:18:10  Lr: 0.030000  Loss: -2.5910  Acc@1: 87.5000 (81.9459)  Acc@5: 100.0000 (96.3254)  time: 0.3907  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [ 970/3750]  eta: 0:18:06  Lr: 0.030000  Loss: -2.2047  Acc@1: 81.2500 (81.9258)  Acc@5: 100.0000 (96.3568)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [ 980/3750]  eta: 0:18:02  Lr: 0.030000  Loss: -2.9647  Acc@1: 81.2500 (81.9190)  Acc@5: 100.0000 (96.3685)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [ 990/3750]  eta: 0:17:59  Lr: 0.030000  Loss: -2.2517  Acc@1: 81.2500 (81.9437)  Acc@5: 100.0000 (96.3736)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1000/3750]  eta: 0:17:55  Lr: 0.030000  Loss: -2.9030  Acc@1: 81.2500 (81.9680)  Acc@5: 100.0000 (96.3849)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1010/3750]  eta: 0:17:51  Lr: 0.030000  Loss: -2.5106  Acc@1: 81.2500 (81.9795)  Acc@5: 100.0000 (96.3897)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1020/3750]  eta: 0:17:47  Lr: 0.030000  Loss: -2.2027  Acc@1: 81.2500 (82.0213)  Acc@5: 100.0000 (96.4067)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [1030/3750]  eta: 0:17:43  Lr: 0.030000  Loss: -3.0154  Acc@1: 81.2500 (82.0320)  Acc@5: 100.0000 (96.4173)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1040/3750]  eta: 0:17:39  Lr: 0.030000  Loss: -2.2876  Acc@1: 81.2500 (82.0005)  Acc@5: 100.0000 (96.4277)  time: 0.3918  data: 0.0008  max mem: 2908
Train: Epoch[3/5]  [1050/3750]  eta: 0:17:35  Lr: 0.030000  Loss: -2.1370  Acc@1: 81.2500 (81.9993)  Acc@5: 100.0000 (96.4320)  time: 0.3923  data: 0.0008  max mem: 2908
Train: Epoch[3/5]  [1060/3750]  eta: 0:17:31  Lr: 0.030000  Loss: -2.4163  Acc@1: 81.2500 (82.0217)  Acc@5: 100.0000 (96.4361)  time: 0.3917  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1070/3750]  eta: 0:17:27  Lr: 0.030000  Loss: -1.9523  Acc@1: 81.2500 (82.0145)  Acc@5: 100.0000 (96.4577)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1080/3750]  eta: 0:17:23  Lr: 0.030000  Loss: -2.5808  Acc@1: 81.2500 (82.0074)  Acc@5: 100.0000 (96.4616)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1090/3750]  eta: 0:17:20  Lr: 0.030000  Loss: -2.9013  Acc@1: 81.2500 (81.9833)  Acc@5: 93.7500 (96.4425)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1100/3750]  eta: 0:17:16  Lr: 0.030000  Loss: -3.0760  Acc@1: 81.2500 (81.9993)  Acc@5: 100.0000 (96.4634)  time: 0.3928  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1110/3750]  eta: 0:17:12  Lr: 0.030000  Loss: -2.2999  Acc@1: 81.2500 (81.9813)  Acc@5: 100.0000 (96.4671)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1120/3750]  eta: 0:17:08  Lr: 0.030000  Loss: -1.4538  Acc@1: 81.2500 (81.9860)  Acc@5: 100.0000 (96.4652)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [1130/3750]  eta: 0:17:04  Lr: 0.030000  Loss: -2.0740  Acc@1: 81.2500 (81.9629)  Acc@5: 93.7500 (96.4578)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1140/3750]  eta: 0:17:00  Lr: 0.030000  Loss: -2.1112  Acc@1: 81.2500 (81.9402)  Acc@5: 93.7500 (96.4450)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1150/3750]  eta: 0:16:56  Lr: 0.030000  Loss: -1.9141  Acc@1: 81.2500 (81.8962)  Acc@5: 93.7500 (96.4433)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1160/3750]  eta: 0:16:52  Lr: 0.030000  Loss: -2.0773  Acc@1: 81.2500 (81.8745)  Acc@5: 93.7500 (96.4309)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1170/3750]  eta: 0:16:48  Lr: 0.030000  Loss: -2.4611  Acc@1: 81.2500 (81.8211)  Acc@5: 93.7500 (96.4347)  time: 0.3924  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [1180/3750]  eta: 0:16:44  Lr: 0.030000  Loss: -2.0995  Acc@1: 75.0000 (81.8004)  Acc@5: 93.7500 (96.4225)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1190/3750]  eta: 0:16:41  Lr: 0.030000  Loss: -2.7007  Acc@1: 81.2500 (81.8010)  Acc@5: 93.7500 (96.4106)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1200/3750]  eta: 0:16:37  Lr: 0.030000  Loss: -2.5557  Acc@1: 81.2500 (81.8068)  Acc@5: 100.0000 (96.4249)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1210/3750]  eta: 0:16:33  Lr: 0.030000  Loss: -2.0265  Acc@1: 81.2500 (81.7971)  Acc@5: 100.0000 (96.4286)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1220/3750]  eta: 0:16:29  Lr: 0.030000  Loss: -2.7606  Acc@1: 81.2500 (81.7875)  Acc@5: 93.7500 (96.4169)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1230/3750]  eta: 0:16:25  Lr: 0.030000  Loss: -2.4424  Acc@1: 87.5000 (81.8186)  Acc@5: 93.7500 (96.4206)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1240/3750]  eta: 0:16:21  Lr: 0.030000  Loss: -2.4475  Acc@1: 81.2500 (81.7738)  Acc@5: 93.7500 (96.3991)  time: 0.3942  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1250/3750]  eta: 0:16:17  Lr: 0.030000  Loss: -2.5243  Acc@1: 81.2500 (81.8245)  Acc@5: 100.0000 (96.4079)  time: 0.3925  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [1260/3750]  eta: 0:16:13  Lr: 0.030000  Loss: -2.0734  Acc@1: 81.2500 (81.8101)  Acc@5: 100.0000 (96.4116)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [1270/3750]  eta: 0:16:10  Lr: 0.030000  Loss: -2.2410  Acc@1: 81.2500 (81.7909)  Acc@5: 93.7500 (96.4054)  time: 0.3929  data: 0.0009  max mem: 2908
Train: Epoch[3/5]  [1280/3750]  eta: 0:16:06  Lr: 0.030000  Loss: -2.7930  Acc@1: 81.2500 (81.8111)  Acc@5: 93.7500 (96.4139)  time: 0.3925  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [1290/3750]  eta: 0:16:02  Lr: 0.030000  Loss: -2.5534  Acc@1: 75.0000 (81.7583)  Acc@5: 93.7500 (96.4030)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1300/3750]  eta: 0:15:58  Lr: 0.030000  Loss: -2.4681  Acc@1: 81.2500 (81.7977)  Acc@5: 93.7500 (96.4114)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1310/3750]  eta: 0:15:54  Lr: 0.030000  Loss: -2.8983  Acc@1: 87.5000 (81.8221)  Acc@5: 100.0000 (96.4245)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1320/3750]  eta: 0:15:50  Lr: 0.030000  Loss: -2.0778  Acc@1: 81.2500 (81.8036)  Acc@5: 93.7500 (96.4090)  time: 0.3938  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1330/3750]  eta: 0:15:46  Lr: 0.030000  Loss: -2.0335  Acc@1: 81.2500 (81.7806)  Acc@5: 93.7500 (96.4172)  time: 0.3932  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1340/3750]  eta: 0:15:42  Lr: 0.030000  Loss: -2.7880  Acc@1: 81.2500 (81.7813)  Acc@5: 100.0000 (96.4113)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1350/3750]  eta: 0:15:38  Lr: 0.030000  Loss: -2.5876  Acc@1: 81.2500 (81.7635)  Acc@5: 93.7500 (96.3962)  time: 0.3926  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1360/3750]  eta: 0:15:35  Lr: 0.030000  Loss: -2.3434  Acc@1: 81.2500 (81.7506)  Acc@5: 93.7500 (96.3905)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1370/3750]  eta: 0:15:31  Lr: 0.030000  Loss: -2.2623  Acc@1: 81.2500 (81.7423)  Acc@5: 100.0000 (96.3895)  time: 0.3923  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1380/3750]  eta: 0:15:27  Lr: 0.030000  Loss: -1.8026  Acc@1: 81.2500 (81.6935)  Acc@5: 93.7500 (96.3613)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1390/3750]  eta: 0:15:23  Lr: 0.030000  Loss: -2.5830  Acc@1: 81.2500 (81.6813)  Acc@5: 93.7500 (96.3605)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1400/3750]  eta: 0:15:19  Lr: 0.030000  Loss: -2.8400  Acc@1: 81.2500 (81.6827)  Acc@5: 93.7500 (96.3508)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1410/3750]  eta: 0:15:15  Lr: 0.030000  Loss: -2.1037  Acc@1: 81.2500 (81.6752)  Acc@5: 93.7500 (96.3412)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1420/3750]  eta: 0:15:11  Lr: 0.030000  Loss: -2.8141  Acc@1: 81.2500 (81.6810)  Acc@5: 100.0000 (96.3670)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1430/3750]  eta: 0:15:07  Lr: 0.030000  Loss: -2.9469  Acc@1: 81.2500 (81.6343)  Acc@5: 100.0000 (96.3574)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1440/3750]  eta: 0:15:03  Lr: 0.030000  Loss: -2.3531  Acc@1: 81.2500 (81.6490)  Acc@5: 93.7500 (96.3567)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1450/3750]  eta: 0:14:59  Lr: 0.030000  Loss: -2.6133  Acc@1: 81.2500 (81.6377)  Acc@5: 93.7500 (96.3430)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [1460/3750]  eta: 0:14:55  Lr: 0.030000  Loss: -2.2410  Acc@1: 75.0000 (81.5922)  Acc@5: 93.7500 (96.3167)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1470/3750]  eta: 0:14:51  Lr: 0.030000  Loss: -2.7636  Acc@1: 81.2500 (81.6324)  Acc@5: 100.0000 (96.3290)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [1480/3750]  eta: 0:14:48  Lr: 0.030000  Loss: -2.6196  Acc@1: 87.5000 (81.6509)  Acc@5: 100.0000 (96.3327)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1490/3750]  eta: 0:14:44  Lr: 0.030000  Loss: -2.3768  Acc@1: 87.5000 (81.6859)  Acc@5: 100.0000 (96.3322)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1500/3750]  eta: 0:14:40  Lr: 0.030000  Loss: -2.0897  Acc@1: 81.2500 (81.6789)  Acc@5: 93.7500 (96.3191)  time: 0.3893  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1510/3750]  eta: 0:14:36  Lr: 0.030000  Loss: -3.0053  Acc@1: 81.2500 (81.7091)  Acc@5: 93.7500 (96.3269)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1520/3750]  eta: 0:14:32  Lr: 0.030000  Loss: -2.2017  Acc@1: 81.2500 (81.6815)  Acc@5: 93.7500 (96.3264)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1530/3750]  eta: 0:14:28  Lr: 0.030000  Loss: -2.1949  Acc@1: 75.0000 (81.6909)  Acc@5: 100.0000 (96.3300)  time: 0.3919  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1540/3750]  eta: 0:14:24  Lr: 0.030000  Loss: -2.7185  Acc@1: 81.2500 (81.6759)  Acc@5: 100.0000 (96.3254)  time: 0.3937  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [1550/3750]  eta: 0:14:20  Lr: 0.030000  Loss: -2.0485  Acc@1: 81.2500 (81.6812)  Acc@5: 100.0000 (96.3290)  time: 0.3926  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1560/3750]  eta: 0:14:16  Lr: 0.030000  Loss: -1.8276  Acc@1: 87.5000 (81.6984)  Acc@5: 100.0000 (96.3245)  time: 0.3909  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1570/3750]  eta: 0:14:12  Lr: 0.030000  Loss: -3.0935  Acc@1: 87.5000 (81.7155)  Acc@5: 93.7500 (96.3160)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1580/3750]  eta: 0:14:08  Lr: 0.030000  Loss: -2.4404  Acc@1: 81.2500 (81.7125)  Acc@5: 93.7500 (96.3117)  time: 0.3928  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1590/3750]  eta: 0:14:05  Lr: 0.030000  Loss: -2.9315  Acc@1: 81.2500 (81.7253)  Acc@5: 100.0000 (96.3309)  time: 0.3927  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1600/3750]  eta: 0:14:01  Lr: 0.030000  Loss: -2.8868  Acc@1: 81.2500 (81.7185)  Acc@5: 100.0000 (96.3382)  time: 0.3929  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1610/3750]  eta: 0:13:57  Lr: 0.030000  Loss: -1.9722  Acc@1: 81.2500 (81.7272)  Acc@5: 100.0000 (96.3377)  time: 0.3937  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1620/3750]  eta: 0:13:53  Lr: 0.030000  Loss: -2.8110  Acc@1: 87.5000 (81.7397)  Acc@5: 100.0000 (96.3448)  time: 0.3921  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1630/3750]  eta: 0:13:49  Lr: 0.030000  Loss: -2.4824  Acc@1: 87.5000 (81.7826)  Acc@5: 93.7500 (96.3443)  time: 0.3930  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [1640/3750]  eta: 0:13:45  Lr: 0.030000  Loss: -2.4705  Acc@1: 87.5000 (81.7794)  Acc@5: 93.7500 (96.3437)  time: 0.3934  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [1650/3750]  eta: 0:13:41  Lr: 0.030000  Loss: -1.7124  Acc@1: 75.0000 (81.7573)  Acc@5: 93.7500 (96.3356)  time: 0.3912  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1660/3750]  eta: 0:13:37  Lr: 0.030000  Loss: -2.0686  Acc@1: 81.2500 (81.7617)  Acc@5: 100.0000 (96.3501)  time: 0.3933  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1670/3750]  eta: 0:13:33  Lr: 0.030000  Loss: -2.7353  Acc@1: 81.2500 (81.7774)  Acc@5: 100.0000 (96.3532)  time: 0.3942  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1680/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -1.9796  Acc@1: 81.2500 (81.7742)  Acc@5: 93.7500 (96.3526)  time: 0.3926  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [1690/3750]  eta: 0:13:26  Lr: 0.030000  Loss: -2.8237  Acc@1: 81.2500 (81.7933)  Acc@5: 93.7500 (96.3594)  time: 0.3940  data: 0.0018  max mem: 2908
Train: Epoch[3/5]  [1700/3750]  eta: 0:13:22  Lr: 0.030000  Loss: -2.7596  Acc@1: 81.2500 (81.7864)  Acc@5: 93.7500 (96.3404)  time: 0.3944  data: 0.0013  max mem: 2908
Train: Epoch[3/5]  [1710/3750]  eta: 0:13:18  Lr: 0.030000  Loss: -2.1756  Acc@1: 75.0000 (81.7724)  Acc@5: 93.7500 (96.3326)  time: 0.3930  data: 0.0007  max mem: 2908
Train: Epoch[3/5]  [1720/3750]  eta: 0:13:14  Lr: 0.030000  Loss: -1.8527  Acc@1: 75.0000 (81.7657)  Acc@5: 93.7500 (96.3284)  time: 0.3937  data: 0.0014  max mem: 2908
Train: Epoch[3/5]  [1730/3750]  eta: 0:13:10  Lr: 0.030000  Loss: -2.9087  Acc@1: 87.5000 (81.7772)  Acc@5: 100.0000 (96.3280)  time: 0.3944  data: 0.0014  max mem: 2908
Train: Epoch[3/5]  [1740/3750]  eta: 0:13:06  Lr: 0.030000  Loss: -1.7809  Acc@1: 87.5000 (81.7921)  Acc@5: 100.0000 (96.3240)  time: 0.3937  data: 0.0008  max mem: 2908
Train: Epoch[3/5]  [1750/3750]  eta: 0:13:02  Lr: 0.030000  Loss: -2.3931  Acc@1: 87.5000 (81.7890)  Acc@5: 100.0000 (96.3307)  time: 0.3927  data: 0.0008  max mem: 2908
Train: Epoch[3/5]  [1760/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -1.8805  Acc@1: 81.2500 (81.7824)  Acc@5: 93.7500 (96.3231)  time: 0.3948  data: 0.0007  max mem: 2908
Train: Epoch[3/5]  [1770/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -2.6327  Acc@1: 87.5000 (81.7864)  Acc@5: 93.7500 (96.3227)  time: 0.3960  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [1780/3750]  eta: 0:12:51  Lr: 0.030000  Loss: -2.7580  Acc@1: 87.5000 (81.7974)  Acc@5: 93.7500 (96.3153)  time: 0.3936  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [1790/3750]  eta: 0:12:47  Lr: 0.030000  Loss: -2.7234  Acc@1: 87.5000 (81.7804)  Acc@5: 93.7500 (96.3079)  time: 0.3928  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [1800/3750]  eta: 0:12:43  Lr: 0.030000  Loss: -2.5766  Acc@1: 81.2500 (81.8087)  Acc@5: 93.7500 (96.3111)  time: 0.3938  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1810/3750]  eta: 0:12:39  Lr: 0.030000  Loss: -2.7586  Acc@1: 87.5000 (81.8367)  Acc@5: 93.7500 (96.3107)  time: 0.3948  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1820/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -2.5902  Acc@1: 87.5000 (81.8644)  Acc@5: 100.0000 (96.3173)  time: 0.3943  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [1830/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -2.8764  Acc@1: 87.5000 (81.8576)  Acc@5: 100.0000 (96.3237)  time: 0.3961  data: 0.0020  max mem: 2908
Train: Epoch[3/5]  [1840/3750]  eta: 0:12:27  Lr: 0.030000  Loss: -2.3346  Acc@1: 81.2500 (81.8543)  Acc@5: 100.0000 (96.3267)  time: 0.3957  data: 0.0025  max mem: 2908
Train: Epoch[3/5]  [1850/3750]  eta: 0:12:24  Lr: 0.030000  Loss: -2.5160  Acc@1: 87.5000 (81.8713)  Acc@5: 93.7500 (96.3229)  time: 0.3924  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [1860/3750]  eta: 0:12:20  Lr: 0.030000  Loss: -2.2004  Acc@1: 81.2500 (81.8377)  Acc@5: 93.7500 (96.3057)  time: 0.3912  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [1870/3750]  eta: 0:12:16  Lr: 0.030000  Loss: -2.7396  Acc@1: 81.2500 (81.8246)  Acc@5: 93.7500 (96.3088)  time: 0.3917  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1880/3750]  eta: 0:12:12  Lr: 0.030000  Loss: -2.3688  Acc@1: 81.2500 (81.8149)  Acc@5: 93.7500 (96.3085)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1890/3750]  eta: 0:12:08  Lr: 0.030000  Loss: -2.6773  Acc@1: 81.2500 (81.8185)  Acc@5: 93.7500 (96.3082)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [1900/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -2.2588  Acc@1: 81.2500 (81.8089)  Acc@5: 93.7500 (96.3144)  time: 0.3923  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1910/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -2.6782  Acc@1: 81.2500 (81.7864)  Acc@5: 100.0000 (96.3108)  time: 0.3913  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [1920/3750]  eta: 0:11:56  Lr: 0.030000  Loss: -2.5032  Acc@1: 75.0000 (81.7706)  Acc@5: 93.7500 (96.3073)  time: 0.3913  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [1930/3750]  eta: 0:11:52  Lr: 0.030000  Loss: -2.0289  Acc@1: 81.2500 (81.7743)  Acc@5: 93.7500 (96.3070)  time: 0.3925  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1940/3750]  eta: 0:11:48  Lr: 0.030000  Loss: -2.5391  Acc@1: 87.5000 (81.8006)  Acc@5: 93.7500 (96.3035)  time: 0.3934  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [1950/3750]  eta: 0:11:44  Lr: 0.030000  Loss: -2.7157  Acc@1: 87.5000 (81.8074)  Acc@5: 100.0000 (96.3160)  time: 0.3960  data: 0.0020  max mem: 2908
Train: Epoch[3/5]  [1960/3750]  eta: 0:11:41  Lr: 0.030000  Loss: -2.6327  Acc@1: 81.2500 (81.7950)  Acc@5: 100.0000 (96.3252)  time: 0.3974  data: 0.0021  max mem: 2908
Train: Epoch[3/5]  [1970/3750]  eta: 0:11:37  Lr: 0.030000  Loss: -2.4145  Acc@1: 81.2500 (81.8018)  Acc@5: 100.0000 (96.3312)  time: 0.3950  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1980/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -2.1174  Acc@1: 81.2500 (81.8116)  Acc@5: 100.0000 (96.3371)  time: 0.3925  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [1990/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -2.1718  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (96.3335)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2000/3750]  eta: 0:11:25  Lr: 0.030000  Loss: -2.8203  Acc@1: 87.5000 (81.8528)  Acc@5: 100.0000 (96.3331)  time: 0.3932  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2010/3750]  eta: 0:11:21  Lr: 0.030000  Loss: -2.5245  Acc@1: 81.2500 (81.8312)  Acc@5: 93.7500 (96.3265)  time: 0.3942  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2020/3750]  eta: 0:11:17  Lr: 0.030000  Loss: -2.2672  Acc@1: 75.0000 (81.8159)  Acc@5: 93.7500 (96.3230)  time: 0.3933  data: 0.0007  max mem: 2908
Train: Epoch[3/5]  [2030/3750]  eta: 0:11:13  Lr: 0.030000  Loss: -2.4361  Acc@1: 81.2500 (81.8070)  Acc@5: 93.7500 (96.3134)  time: 0.3924  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2040/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -2.5139  Acc@1: 81.2500 (81.8012)  Acc@5: 100.0000 (96.3192)  time: 0.3924  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2050/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -2.3086  Acc@1: 81.2500 (81.7924)  Acc@5: 100.0000 (96.3280)  time: 0.3928  data: 0.0020  max mem: 2908
Train: Epoch[3/5]  [2060/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -2.5113  Acc@1: 81.2500 (81.8049)  Acc@5: 100.0000 (96.3307)  time: 0.3963  data: 0.0027  max mem: 2908
Train: Epoch[3/5]  [2070/3750]  eta: 0:10:58  Lr: 0.030000  Loss: -2.0903  Acc@1: 81.2500 (81.7872)  Acc@5: 93.7500 (96.3182)  time: 0.3942  data: 0.0019  max mem: 2908
Train: Epoch[3/5]  [2080/3750]  eta: 0:10:54  Lr: 0.030000  Loss: -2.1086  Acc@1: 81.2500 (81.7756)  Acc@5: 93.7500 (96.3179)  time: 0.3913  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2090/3750]  eta: 0:10:50  Lr: 0.030000  Loss: -2.1099  Acc@1: 81.2500 (81.8030)  Acc@5: 100.0000 (96.3176)  time: 0.3921  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2100/3750]  eta: 0:10:46  Lr: 0.030000  Loss: -2.4649  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (96.3262)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2110/3750]  eta: 0:10:42  Lr: 0.030000  Loss: -2.3883  Acc@1: 81.2500 (81.8214)  Acc@5: 100.0000 (96.3228)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2120/3750]  eta: 0:10:38  Lr: 0.030000  Loss: -2.1700  Acc@1: 87.5000 (81.8305)  Acc@5: 100.0000 (96.3343)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2130/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -2.8455  Acc@1: 87.5000 (81.8688)  Acc@5: 100.0000 (96.3427)  time: 0.3914  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2140/3750]  eta: 0:10:30  Lr: 0.030000  Loss: -2.6783  Acc@1: 87.5000 (81.8601)  Acc@5: 100.0000 (96.3510)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2150/3750]  eta: 0:10:26  Lr: 0.030000  Loss: -2.6589  Acc@1: 81.2500 (81.8660)  Acc@5: 100.0000 (96.3593)  time: 0.3923  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [2160/3750]  eta: 0:10:22  Lr: 0.030000  Loss: -2.7565  Acc@1: 81.2500 (81.8574)  Acc@5: 100.0000 (96.3616)  time: 0.3944  data: 0.0017  max mem: 2908
Train: Epoch[3/5]  [2170/3750]  eta: 0:10:18  Lr: 0.030000  Loss: -1.8713  Acc@1: 81.2500 (81.8574)  Acc@5: 100.0000 (96.3640)  time: 0.3926  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2180/3750]  eta: 0:10:15  Lr: 0.030000  Loss: -2.3949  Acc@1: 81.2500 (81.8461)  Acc@5: 100.0000 (96.3635)  time: 0.3926  data: 0.0020  max mem: 2908
Train: Epoch[3/5]  [2190/3750]  eta: 0:10:11  Lr: 0.030000  Loss: -2.7764  Acc@1: 81.2500 (81.8519)  Acc@5: 100.0000 (96.3687)  time: 0.3919  data: 0.0020  max mem: 2908
Train: Epoch[3/5]  [2200/3750]  eta: 0:10:07  Lr: 0.030000  Loss: -2.2787  Acc@1: 81.2500 (81.8492)  Acc@5: 100.0000 (96.3710)  time: 0.3907  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2210/3750]  eta: 0:10:03  Lr: 0.030000  Loss: -2.1207  Acc@1: 75.0000 (81.8097)  Acc@5: 93.7500 (96.3591)  time: 0.3904  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2220/3750]  eta: 0:09:59  Lr: 0.030000  Loss: -2.7935  Acc@1: 81.2500 (81.8241)  Acc@5: 93.7500 (96.3671)  time: 0.3929  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2230/3750]  eta: 0:09:55  Lr: 0.030000  Loss: -2.4452  Acc@1: 87.5000 (81.8271)  Acc@5: 100.0000 (96.3749)  time: 0.3938  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2240/3750]  eta: 0:09:51  Lr: 0.030000  Loss: -2.7118  Acc@1: 81.2500 (81.7938)  Acc@5: 100.0000 (96.3772)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2250/3750]  eta: 0:09:47  Lr: 0.030000  Loss: -2.2317  Acc@1: 75.0000 (81.7831)  Acc@5: 100.0000 (96.3766)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [2260/3750]  eta: 0:09:43  Lr: 0.030000  Loss: -2.6433  Acc@1: 81.2500 (81.7780)  Acc@5: 100.0000 (96.3788)  time: 0.3928  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2270/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -2.3756  Acc@1: 81.2500 (81.7674)  Acc@5: 100.0000 (96.3755)  time: 0.3928  data: 0.0020  max mem: 2908
Train: Epoch[3/5]  [2280/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -2.5728  Acc@1: 81.2500 (81.7733)  Acc@5: 93.7500 (96.3777)  time: 0.3929  data: 0.0017  max mem: 2908
Train: Epoch[3/5]  [2290/3750]  eta: 0:09:32  Lr: 0.030000  Loss: -2.4878  Acc@1: 87.5000 (81.7956)  Acc@5: 100.0000 (96.3799)  time: 0.3975  data: 0.0024  max mem: 2908
Train: Epoch[3/5]  [2300/3750]  eta: 0:09:28  Lr: 0.030000  Loss: -2.5364  Acc@1: 81.2500 (81.7932)  Acc@5: 100.0000 (96.3820)  time: 0.3970  data: 0.0024  max mem: 2908
Train: Epoch[3/5]  [2310/3750]  eta: 0:09:24  Lr: 0.030000  Loss: -2.2896  Acc@1: 81.2500 (81.7882)  Acc@5: 100.0000 (96.3814)  time: 0.3929  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2320/3750]  eta: 0:09:20  Lr: 0.030000  Loss: -2.1447  Acc@1: 81.2500 (81.7886)  Acc@5: 93.7500 (96.3647)  time: 0.3942  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2330/3750]  eta: 0:09:16  Lr: 0.030000  Loss: -2.4391  Acc@1: 81.2500 (81.7916)  Acc@5: 93.7500 (96.3669)  time: 0.3953  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2340/3750]  eta: 0:09:12  Lr: 0.030000  Loss: -2.4896  Acc@1: 81.2500 (81.7973)  Acc@5: 100.0000 (96.3717)  time: 0.3942  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2350/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -2.4276  Acc@1: 81.2500 (81.7950)  Acc@5: 100.0000 (96.3765)  time: 0.3937  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2360/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -2.8697  Acc@1: 81.2500 (81.7953)  Acc@5: 100.0000 (96.3707)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2370/3750]  eta: 0:09:00  Lr: 0.030000  Loss: -2.7486  Acc@1: 81.2500 (81.7851)  Acc@5: 93.7500 (96.3728)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2380/3750]  eta: 0:08:56  Lr: 0.030000  Loss: -2.2513  Acc@1: 81.2500 (81.7881)  Acc@5: 93.7500 (96.3671)  time: 0.3955  data: 0.0013  max mem: 2908
Train: Epoch[3/5]  [2390/3750]  eta: 0:08:53  Lr: 0.030000  Loss: -2.7041  Acc@1: 81.2500 (81.7832)  Acc@5: 93.7500 (96.3744)  time: 0.3965  data: 0.0013  max mem: 2908
Train: Epoch[3/5]  [2400/3750]  eta: 0:08:49  Lr: 0.030000  Loss: -2.1839  Acc@1: 87.5000 (81.8019)  Acc@5: 100.0000 (96.3739)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2410/3750]  eta: 0:08:45  Lr: 0.030000  Loss: -2.3776  Acc@1: 87.5000 (81.8073)  Acc@5: 93.7500 (96.3760)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2420/3750]  eta: 0:08:41  Lr: 0.030000  Loss: -2.4448  Acc@1: 87.5000 (81.8025)  Acc@5: 100.0000 (96.3832)  time: 0.3939  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [2430/3750]  eta: 0:08:37  Lr: 0.030000  Loss: -2.5386  Acc@1: 81.2500 (81.7976)  Acc@5: 100.0000 (96.3929)  time: 0.3937  data: 0.0009  max mem: 2908
Train: Epoch[3/5]  [2440/3750]  eta: 0:08:33  Lr: 0.030000  Loss: -2.5979  Acc@1: 81.2500 (81.7877)  Acc@5: 100.0000 (96.3924)  time: 0.3940  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2450/3750]  eta: 0:08:29  Lr: 0.030000  Loss: -2.6963  Acc@1: 81.2500 (81.7829)  Acc@5: 93.7500 (96.3841)  time: 0.3953  data: 0.0014  max mem: 2908
Train: Epoch[3/5]  [2460/3750]  eta: 0:08:25  Lr: 0.030000  Loss: -2.2407  Acc@1: 75.0000 (81.7503)  Acc@5: 93.7500 (96.3760)  time: 0.3951  data: 0.0019  max mem: 2908
Train: Epoch[3/5]  [2470/3750]  eta: 0:08:21  Lr: 0.030000  Loss: -2.5469  Acc@1: 81.2500 (81.7559)  Acc@5: 93.7500 (96.3780)  time: 0.3949  data: 0.0017  max mem: 2908
Train: Epoch[3/5]  [2480/3750]  eta: 0:08:17  Lr: 0.030000  Loss: -2.6705  Acc@1: 81.2500 (81.7538)  Acc@5: 100.0000 (96.3825)  time: 0.3934  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2490/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -2.9026  Acc@1: 81.2500 (81.7744)  Acc@5: 100.0000 (96.3820)  time: 0.3923  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2500/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -2.6733  Acc@1: 81.2500 (81.7723)  Acc@5: 100.0000 (96.3839)  time: 0.3927  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2510/3750]  eta: 0:08:06  Lr: 0.030000  Loss: -2.4476  Acc@1: 81.2500 (81.7603)  Acc@5: 93.7500 (96.3685)  time: 0.3922  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2520/3750]  eta: 0:08:02  Lr: 0.030000  Loss: -2.6809  Acc@1: 81.2500 (81.7533)  Acc@5: 93.7500 (96.3680)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:58  Lr: 0.030000  Loss: -2.7510  Acc@1: 81.2500 (81.7562)  Acc@5: 100.0000 (96.3700)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:54  Lr: 0.030000  Loss: -2.9613  Acc@1: 87.5000 (81.7616)  Acc@5: 100.0000 (96.3769)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2550/3750]  eta: 0:07:50  Lr: 0.030000  Loss: -2.5096  Acc@1: 87.5000 (81.7621)  Acc@5: 100.0000 (96.3838)  time: 0.3906  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2560/3750]  eta: 0:07:46  Lr: 0.030000  Loss: -2.6789  Acc@1: 81.2500 (81.7479)  Acc@5: 100.0000 (96.3808)  time: 0.3917  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2570/3750]  eta: 0:07:42  Lr: 0.030000  Loss: -2.8112  Acc@1: 81.2500 (81.7386)  Acc@5: 100.0000 (96.3827)  time: 0.3926  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2580/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -2.8897  Acc@1: 81.2500 (81.7319)  Acc@5: 100.0000 (96.3798)  time: 0.3921  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2590/3750]  eta: 0:07:34  Lr: 0.030000  Loss: -2.3294  Acc@1: 81.2500 (81.7180)  Acc@5: 100.0000 (96.3769)  time: 0.3912  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2600/3750]  eta: 0:07:30  Lr: 0.030000  Loss: -2.5079  Acc@1: 81.2500 (81.7330)  Acc@5: 100.0000 (96.3836)  time: 0.3945  data: 0.0040  max mem: 2908
Train: Epoch[3/5]  [2610/3750]  eta: 0:07:26  Lr: 0.030000  Loss: -2.8924  Acc@1: 81.2500 (81.7359)  Acc@5: 100.0000 (96.3807)  time: 0.3945  data: 0.0041  max mem: 2908
Train: Epoch[3/5]  [2620/3750]  eta: 0:07:22  Lr: 0.030000  Loss: -2.8495  Acc@1: 81.2500 (81.7388)  Acc@5: 100.0000 (96.3897)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2630/3750]  eta: 0:07:19  Lr: 0.030000  Loss: -2.4228  Acc@1: 81.2500 (81.7251)  Acc@5: 100.0000 (96.3892)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [2640/3750]  eta: 0:07:15  Lr: 0.030000  Loss: -2.9495  Acc@1: 81.2500 (81.7280)  Acc@5: 100.0000 (96.3934)  time: 0.3907  data: 0.0018  max mem: 2908
Train: Epoch[3/5]  [2650/3750]  eta: 0:07:11  Lr: 0.030000  Loss: -2.7279  Acc@1: 81.2500 (81.7286)  Acc@5: 100.0000 (96.3929)  time: 0.3925  data: 0.0019  max mem: 2908
Train: Epoch[3/5]  [2660/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -2.7610  Acc@1: 87.5000 (81.7432)  Acc@5: 100.0000 (96.3947)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2670/3750]  eta: 0:07:03  Lr: 0.030000  Loss: -2.4767  Acc@1: 81.2500 (81.7390)  Acc@5: 93.7500 (96.3895)  time: 0.3925  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:59  Lr: 0.030000  Loss: -2.7142  Acc@1: 81.2500 (81.7535)  Acc@5: 93.7500 (96.3819)  time: 0.3952  data: 0.0021  max mem: 2908
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:55  Lr: 0.030000  Loss: -2.8159  Acc@1: 87.5000 (81.7517)  Acc@5: 93.7500 (96.3722)  time: 0.3945  data: 0.0013  max mem: 2908
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:51  Lr: 0.030000  Loss: -2.7283  Acc@1: 81.2500 (81.7614)  Acc@5: 100.0000 (96.3810)  time: 0.3944  data: 0.0022  max mem: 2908
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:47  Lr: 0.030000  Loss: -2.2469  Acc@1: 81.2500 (81.7618)  Acc@5: 100.0000 (96.3828)  time: 0.3934  data: 0.0022  max mem: 2908
Train: Epoch[3/5]  [2720/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -2.5137  Acc@1: 81.2500 (81.7691)  Acc@5: 100.0000 (96.3846)  time: 0.3913  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2730/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -2.7858  Acc@1: 81.2500 (81.7672)  Acc@5: 100.0000 (96.3864)  time: 0.3923  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2740/3750]  eta: 0:06:35  Lr: 0.030000  Loss: -1.9384  Acc@1: 81.2500 (81.7699)  Acc@5: 100.0000 (96.3905)  time: 0.3925  data: 0.0009  max mem: 2908
Train: Epoch[3/5]  [2750/3750]  eta: 0:06:32  Lr: 0.030000  Loss: -2.5137  Acc@1: 87.5000 (81.7839)  Acc@5: 100.0000 (96.3899)  time: 0.3923  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [2760/3750]  eta: 0:06:28  Lr: 0.030000  Loss: -2.3980  Acc@1: 81.2500 (81.7616)  Acc@5: 93.7500 (96.3872)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2770/3750]  eta: 0:06:24  Lr: 0.030000  Loss: -2.6106  Acc@1: 81.2500 (81.7665)  Acc@5: 100.0000 (96.3844)  time: 0.3936  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2780/3750]  eta: 0:06:20  Lr: 0.030000  Loss: -2.6608  Acc@1: 81.2500 (81.7624)  Acc@5: 100.0000 (96.3862)  time: 0.3958  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2790/3750]  eta: 0:06:16  Lr: 0.030000  Loss: -1.9300  Acc@1: 75.0000 (81.7427)  Acc@5: 100.0000 (96.3902)  time: 0.3945  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2800/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -2.3279  Acc@1: 75.0000 (81.7230)  Acc@5: 93.7500 (96.3830)  time: 0.3910  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2810/3750]  eta: 0:06:08  Lr: 0.030000  Loss: -2.4833  Acc@1: 81.2500 (81.7147)  Acc@5: 93.7500 (96.3803)  time: 0.3903  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [2820/3750]  eta: 0:06:04  Lr: 0.030000  Loss: -2.6631  Acc@1: 81.2500 (81.7219)  Acc@5: 93.7500 (96.3820)  time: 0.3938  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2830/3750]  eta: 0:06:00  Lr: 0.030000  Loss: -2.3446  Acc@1: 81.2500 (81.7335)  Acc@5: 100.0000 (96.3838)  time: 0.3966  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:56  Lr: 0.030000  Loss: -2.4503  Acc@1: 81.2500 (81.7230)  Acc@5: 93.7500 (96.3833)  time: 0.3957  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:52  Lr: 0.030000  Loss: -2.1526  Acc@1: 81.2500 (81.7235)  Acc@5: 93.7500 (96.3785)  time: 0.3938  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -2.4038  Acc@1: 75.0000 (81.7000)  Acc@5: 93.7500 (96.3802)  time: 0.3953  data: 0.0019  max mem: 2908
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:45  Lr: 0.030000  Loss: -2.8069  Acc@1: 81.2500 (81.7202)  Acc@5: 93.7500 (96.3797)  time: 0.3973  data: 0.0026  max mem: 2908
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -3.0703  Acc@1: 87.5000 (81.7251)  Acc@5: 93.7500 (96.3815)  time: 0.3969  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:37  Lr: 0.030000  Loss: -2.6056  Acc@1: 81.2500 (81.7213)  Acc@5: 100.0000 (96.3875)  time: 0.3940  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2900/3750]  eta: 0:05:33  Lr: 0.030000  Loss: -2.5830  Acc@1: 81.2500 (81.7067)  Acc@5: 100.0000 (96.3849)  time: 0.3930  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2910/3750]  eta: 0:05:29  Lr: 0.030000  Loss: -2.6202  Acc@1: 75.0000 (81.6987)  Acc@5: 93.7500 (96.3758)  time: 0.3927  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2920/3750]  eta: 0:05:25  Lr: 0.030000  Loss: -2.0632  Acc@1: 75.0000 (81.6865)  Acc@5: 93.7500 (96.3711)  time: 0.3933  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2930/3750]  eta: 0:05:21  Lr: 0.030000  Loss: -2.5815  Acc@1: 81.2500 (81.6999)  Acc@5: 100.0000 (96.3750)  time: 0.3939  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2940/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -2.5605  Acc@1: 87.5000 (81.7048)  Acc@5: 100.0000 (96.3788)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [2950/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -2.4528  Acc@1: 81.2500 (81.7032)  Acc@5: 100.0000 (96.3805)  time: 0.3918  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [2960/3750]  eta: 0:05:09  Lr: 0.030000  Loss: -1.7735  Acc@1: 81.2500 (81.6996)  Acc@5: 100.0000 (96.3864)  time: 0.3931  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2970/3750]  eta: 0:05:05  Lr: 0.030000  Loss: -2.2324  Acc@1: 81.2500 (81.6981)  Acc@5: 100.0000 (96.3922)  time: 0.3924  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2980/3750]  eta: 0:05:01  Lr: 0.030000  Loss: -2.0099  Acc@1: 81.2500 (81.7092)  Acc@5: 100.0000 (96.4001)  time: 0.3928  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:58  Lr: 0.030000  Loss: -3.0415  Acc@1: 87.5000 (81.7369)  Acc@5: 100.0000 (96.4059)  time: 0.3932  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:54  Lr: 0.030000  Loss: -3.0350  Acc@1: 87.5000 (81.7498)  Acc@5: 93.7500 (96.3950)  time: 0.3968  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:50  Lr: 0.030000  Loss: -2.9208  Acc@1: 87.5000 (81.7710)  Acc@5: 100.0000 (96.4028)  time: 0.4010  data: 0.0019  max mem: 2908
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -2.4653  Acc@1: 87.5000 (81.7838)  Acc@5: 100.0000 (96.4043)  time: 0.3989  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:42  Lr: 0.030000  Loss: -2.1314  Acc@1: 81.2500 (81.7717)  Acc@5: 100.0000 (96.4038)  time: 0.3956  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:38  Lr: 0.030000  Loss: -2.0861  Acc@1: 75.0000 (81.7761)  Acc@5: 93.7500 (96.4033)  time: 0.3967  data: 0.0014  max mem: 2908
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:34  Lr: 0.030000  Loss: -2.6545  Acc@1: 81.2500 (81.7683)  Acc@5: 93.7500 (96.3987)  time: 0.3982  data: 0.0014  max mem: 2908
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:30  Lr: 0.030000  Loss: -2.3927  Acc@1: 81.2500 (81.7605)  Acc@5: 93.7500 (96.3921)  time: 0.3968  data: 0.0019  max mem: 2908
Train: Epoch[3/5]  [3070/3750]  eta: 0:04:26  Lr: 0.030000  Loss: -2.2266  Acc@1: 81.2500 (81.7669)  Acc@5: 93.7500 (96.3896)  time: 0.3950  data: 0.0020  max mem: 2908
Train: Epoch[3/5]  [3080/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -1.5434  Acc@1: 87.5000 (81.7673)  Acc@5: 100.0000 (96.3851)  time: 0.3948  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [3090/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -2.4704  Acc@1: 81.2500 (81.7555)  Acc@5: 100.0000 (96.3826)  time: 0.3943  data: 0.0013  max mem: 2908
Train: Epoch[3/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -2.4082  Acc@1: 81.2500 (81.7579)  Acc@5: 93.7500 (96.3802)  time: 0.3919  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [3110/3750]  eta: 0:04:11  Lr: 0.030000  Loss: -2.6468  Acc@1: 87.5000 (81.7663)  Acc@5: 100.0000 (96.3818)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3120/3750]  eta: 0:04:07  Lr: 0.030000  Loss: -2.8015  Acc@1: 81.2500 (81.7587)  Acc@5: 100.0000 (96.3834)  time: 0.3915  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [3130/3750]  eta: 0:04:03  Lr: 0.030000  Loss: -2.6474  Acc@1: 87.5000 (81.7690)  Acc@5: 100.0000 (96.3829)  time: 0.3920  data: 0.0013  max mem: 2908
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:59  Lr: 0.030000  Loss: -2.0691  Acc@1: 87.5000 (81.7594)  Acc@5: 93.7500 (96.3766)  time: 0.3919  data: 0.0015  max mem: 2908
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:55  Lr: 0.030000  Loss: -2.9511  Acc@1: 81.2500 (81.7578)  Acc@5: 93.7500 (96.3742)  time: 0.3948  data: 0.0026  max mem: 2908
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -2.3096  Acc@1: 81.2500 (81.7562)  Acc@5: 93.7500 (96.3738)  time: 0.3942  data: 0.0026  max mem: 2908
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -2.5361  Acc@1: 81.2500 (81.7565)  Acc@5: 93.7500 (96.3655)  time: 0.3917  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:43  Lr: 0.030000  Loss: -2.2059  Acc@1: 75.0000 (81.7530)  Acc@5: 93.7500 (96.3573)  time: 0.3911  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -2.3305  Acc@1: 81.2500 (81.7612)  Acc@5: 93.7500 (96.3530)  time: 0.3929  data: 0.0021  max mem: 2908
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -2.3920  Acc@1: 81.2500 (81.7752)  Acc@5: 100.0000 (96.3566)  time: 0.3935  data: 0.0027  max mem: 2908
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -2.5415  Acc@1: 81.2500 (81.7794)  Acc@5: 100.0000 (96.3602)  time: 0.3910  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -1.9920  Acc@1: 81.2500 (81.7778)  Acc@5: 100.0000 (96.3559)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -2.7002  Acc@1: 81.2500 (81.7897)  Acc@5: 100.0000 (96.3576)  time: 0.3904  data: 0.0007  max mem: 2908
Train: Epoch[3/5]  [3240/3750]  eta: 0:03:20  Lr: 0.030000  Loss: -2.2962  Acc@1: 87.5000 (81.8054)  Acc@5: 100.0000 (96.3591)  time: 0.3905  data: 0.0007  max mem: 2908
Train: Epoch[3/5]  [3250/3750]  eta: 0:03:16  Lr: 0.030000  Loss: -2.3448  Acc@1: 81.2500 (81.8133)  Acc@5: 100.0000 (96.3588)  time: 0.3908  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [3260/3750]  eta: 0:03:12  Lr: 0.030000  Loss: -2.4322  Acc@1: 81.2500 (81.8039)  Acc@5: 93.7500 (96.3604)  time: 0.3930  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [3270/3750]  eta: 0:03:08  Lr: 0.030000  Loss: -2.0684  Acc@1: 75.0000 (81.7946)  Acc@5: 93.7500 (96.3581)  time: 0.3938  data: 0.0021  max mem: 2908
Train: Epoch[3/5]  [3280/3750]  eta: 0:03:04  Lr: 0.030000  Loss: -2.7150  Acc@1: 81.2500 (81.7967)  Acc@5: 100.0000 (96.3597)  time: 0.3950  data: 0.0029  max mem: 2908
Train: Epoch[3/5]  [3290/3750]  eta: 0:03:00  Lr: 0.030000  Loss: -2.9304  Acc@1: 81.2500 (81.7837)  Acc@5: 93.7500 (96.3575)  time: 0.3929  data: 0.0018  max mem: 2908
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -2.3886  Acc@1: 81.2500 (81.7820)  Acc@5: 93.7500 (96.3572)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -2.3679  Acc@1: 81.2500 (81.7918)  Acc@5: 100.0000 (96.3587)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -2.4242  Acc@1: 81.2500 (81.7939)  Acc@5: 100.0000 (96.3603)  time: 0.3932  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -2.4933  Acc@1: 81.2500 (81.7829)  Acc@5: 100.0000 (96.3675)  time: 0.3936  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -2.5644  Acc@1: 81.2500 (81.7906)  Acc@5: 100.0000 (96.3708)  time: 0.3918  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -2.3765  Acc@1: 81.2500 (81.7853)  Acc@5: 100.0000 (96.3686)  time: 0.3919  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:33  Lr: 0.030000  Loss: -2.5566  Acc@1: 81.2500 (81.7818)  Acc@5: 100.0000 (96.3720)  time: 0.3932  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:29  Lr: 0.030000  Loss: -2.6599  Acc@1: 81.2500 (81.7895)  Acc@5: 100.0000 (96.3753)  time: 0.3931  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:25  Lr: 0.030000  Loss: -2.5389  Acc@1: 81.2500 (81.7916)  Acc@5: 100.0000 (96.3768)  time: 0.3931  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -2.7115  Acc@1: 81.2500 (81.7900)  Acc@5: 93.7500 (96.3746)  time: 0.3946  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -2.4809  Acc@1: 81.2500 (81.7940)  Acc@5: 93.7500 (96.3761)  time: 0.3935  data: 0.0008  max mem: 2908
Train: Epoch[3/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -2.9263  Acc@1: 87.5000 (81.7997)  Acc@5: 100.0000 (96.3794)  time: 0.3913  data: 0.0008  max mem: 2908
Train: Epoch[3/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -2.5655  Acc@1: 81.2500 (81.8036)  Acc@5: 100.0000 (96.3845)  time: 0.3919  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -1.7856  Acc@1: 81.2500 (81.7928)  Acc@5: 93.7500 (96.3768)  time: 0.3936  data: 0.0006  max mem: 2908
Train: Epoch[3/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -2.7043  Acc@1: 81.2500 (81.8112)  Acc@5: 93.7500 (96.3764)  time: 0.3941  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -2.5752  Acc@1: 87.5000 (81.8187)  Acc@5: 100.0000 (96.3815)  time: 0.3946  data: 0.0019  max mem: 2908
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -2.5113  Acc@1: 81.2500 (81.8188)  Acc@5: 100.0000 (96.3757)  time: 0.3958  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -2.3139  Acc@1: 81.2500 (81.8136)  Acc@5: 93.7500 (96.3789)  time: 0.3948  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -2.3576  Acc@1: 81.2500 (81.8138)  Acc@5: 100.0000 (96.3804)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:42  Lr: 0.030000  Loss: -2.4208  Acc@1: 81.2500 (81.7996)  Acc@5: 93.7500 (96.3800)  time: 0.3929  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:38  Lr: 0.030000  Loss: -2.5077  Acc@1: 75.0000 (81.7927)  Acc@5: 93.7500 (96.3796)  time: 0.3934  data: 0.0005  max mem: 2908
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:34  Lr: 0.030000  Loss: -2.3803  Acc@1: 81.2500 (81.8090)  Acc@5: 100.0000 (96.3881)  time: 0.3928  data: 0.0003  max mem: 2908
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:30  Lr: 0.030000  Loss: -2.0315  Acc@1: 81.2500 (81.8056)  Acc@5: 100.0000 (96.3877)  time: 0.3931  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -2.1433  Acc@1: 81.2500 (81.8093)  Acc@5: 93.7500 (96.3856)  time: 0.3936  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -2.3608  Acc@1: 81.2500 (81.8166)  Acc@5: 93.7500 (96.3870)  time: 0.3958  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -2.2695  Acc@1: 81.2500 (81.8097)  Acc@5: 100.0000 (96.3883)  time: 0.3986  data: 0.0015  max mem: 2908
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -2.6647  Acc@1: 81.2500 (81.8152)  Acc@5: 100.0000 (96.3915)  time: 0.3961  data: 0.0021  max mem: 2908
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -2.1053  Acc@1: 81.2500 (81.8171)  Acc@5: 100.0000 (96.3858)  time: 0.3924  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -2.9935  Acc@1: 81.2500 (81.8102)  Acc@5: 100.0000 (96.3907)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -2.4222  Acc@1: 81.2500 (81.8191)  Acc@5: 100.0000 (96.3938)  time: 0.3927  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -1.9129  Acc@1: 87.5000 (81.8297)  Acc@5: 100.0000 (96.3968)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -2.4124  Acc@1: 81.2500 (81.8333)  Acc@5: 100.0000 (96.4016)  time: 0.3942  data: 0.0011  max mem: 2908
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -2.6281  Acc@1: 81.2500 (81.8403)  Acc@5: 100.0000 (96.4029)  time: 0.3960  data: 0.0020  max mem: 2908
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:47  Lr: 0.030000  Loss: -2.6784  Acc@1: 87.5000 (81.8525)  Acc@5: 100.0000 (96.4042)  time: 0.3940  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -2.1966  Acc@1: 81.2500 (81.8456)  Acc@5: 100.0000 (96.4072)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -2.4493  Acc@1: 81.2500 (81.8457)  Acc@5: 100.0000 (96.4068)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -2.8150  Acc@1: 87.5000 (81.8543)  Acc@5: 100.0000 (96.4081)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -2.0687  Acc@1: 81.2500 (81.8442)  Acc@5: 93.7500 (96.4042)  time: 0.3935  data: 0.0013  max mem: 2908
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -2.3771  Acc@1: 75.0000 (81.8307)  Acc@5: 93.7500 (96.4021)  time: 0.3947  data: 0.0021  max mem: 2908
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -2.3205  Acc@1: 81.2500 (81.8291)  Acc@5: 93.7500 (96.3983)  time: 0.3937  data: 0.0012  max mem: 2908
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -3.1179  Acc@1: 81.2500 (81.8360)  Acc@5: 100.0000 (96.4047)  time: 0.3957  data: 0.0014  max mem: 2908
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -2.7770  Acc@1: 87.5000 (81.8496)  Acc@5: 100.0000 (96.4110)  time: 0.3937  data: 0.0013  max mem: 2908
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -1.8313  Acc@1: 81.2500 (81.8446)  Acc@5: 100.0000 (96.4055)  time: 0.3914  data: 0.0010  max mem: 2908
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -1.9853  Acc@1: 81.2500 (81.8430)  Acc@5: 100.0000 (96.4068)  time: 0.3935  data: 0.0025  max mem: 2908
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -2.5039  Acc@1: 81.2500 (81.8464)  Acc@5: 93.7500 (96.4030)  time: 0.3950  data: 0.0026  max mem: 2908
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -2.6888  Acc@1: 81.2500 (81.8450)  Acc@5: 93.7500 (96.4017)  time: 0.3944  data: 0.0018  max mem: 2908
Train: Epoch[3/5] Total time: 0:24:32 (0.3927 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.6888  Acc@1: 81.2500 (81.8450)  Acc@5: 93.7500 (96.4017)
Train: Epoch[4/5]  [   0/3750]  eta: 0:52:41  Lr: 0.030000  Loss: -2.5171  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.8432  data: 0.4548  max mem: 2908
Train: Epoch[4/5]  [  10/3750]  eta: 0:27:00  Lr: 0.030000  Loss: -1.8742  Acc@1: 75.0000 (76.7045)  Acc@5: 93.7500 (96.5909)  time: 0.4333  data: 0.0417  max mem: 2908
Train: Epoch[4/5]  [  20/3750]  eta: 0:25:46  Lr: 0.030000  Loss: -1.6363  Acc@1: 75.0000 (79.7619)  Acc@5: 93.7500 (96.4286)  time: 0.3932  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [  30/3750]  eta: 0:25:12  Lr: 0.030000  Loss: -2.5278  Acc@1: 81.2500 (80.8468)  Acc@5: 100.0000 (96.7742)  time: 0.3919  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [  40/3750]  eta: 0:24:57  Lr: 0.030000  Loss: -2.3934  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.9512)  time: 0.3921  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [  50/3750]  eta: 0:24:42  Lr: 0.030000  Loss: -1.9344  Acc@1: 81.2500 (81.4951)  Acc@5: 93.7500 (96.4461)  time: 0.3915  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [  60/3750]  eta: 0:24:33  Lr: 0.030000  Loss: -2.3015  Acc@1: 81.2500 (82.1721)  Acc@5: 93.7500 (96.5164)  time: 0.3907  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [  70/3750]  eta: 0:24:26  Lr: 0.030000  Loss: -2.6539  Acc@1: 87.5000 (82.6585)  Acc@5: 100.0000 (96.6549)  time: 0.3927  data: 0.0017  max mem: 2908
Train: Epoch[4/5]  [  80/3750]  eta: 0:24:20  Lr: 0.030000  Loss: -2.2953  Acc@1: 81.2500 (82.7160)  Acc@5: 100.0000 (96.8364)  time: 0.3931  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [  90/3750]  eta: 0:24:13  Lr: 0.030000  Loss: -2.5178  Acc@1: 87.5000 (83.4478)  Acc@5: 100.0000 (96.7720)  time: 0.3927  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 100/3750]  eta: 0:24:08  Lr: 0.030000  Loss: -2.6515  Acc@1: 87.5000 (83.3540)  Acc@5: 93.7500 (96.5965)  time: 0.3926  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 110/3750]  eta: 0:24:04  Lr: 0.030000  Loss: -2.3733  Acc@1: 81.2500 (83.2207)  Acc@5: 93.7500 (96.4527)  time: 0.3950  data: 0.0019  max mem: 2908
Train: Epoch[4/5]  [ 120/3750]  eta: 0:23:58  Lr: 0.030000  Loss: -2.5064  Acc@1: 81.2500 (83.1095)  Acc@5: 100.0000 (96.4360)  time: 0.3943  data: 0.0032  max mem: 2908
Train: Epoch[4/5]  [ 130/3750]  eta: 0:23:54  Lr: 0.030000  Loss: -2.9473  Acc@1: 81.2500 (83.3492)  Acc@5: 100.0000 (96.5172)  time: 0.3933  data: 0.0025  max mem: 2908
Train: Epoch[4/5]  [ 140/3750]  eta: 0:23:49  Lr: 0.030000  Loss: -2.4316  Acc@1: 87.5000 (83.3777)  Acc@5: 100.0000 (96.4539)  time: 0.3928  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [ 150/3750]  eta: 0:23:44  Lr: 0.030000  Loss: -2.7322  Acc@1: 81.2500 (83.1954)  Acc@5: 100.0000 (96.5232)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [ 160/3750]  eta: 0:23:39  Lr: 0.030000  Loss: -2.3360  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (96.5062)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [ 170/3750]  eta: 0:23:34  Lr: 0.030000  Loss: -2.5278  Acc@1: 81.2500 (83.0044)  Acc@5: 93.7500 (96.4181)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [ 180/3750]  eta: 0:23:30  Lr: 0.030000  Loss: -2.6177  Acc@1: 81.2500 (82.9765)  Acc@5: 100.0000 (96.4779)  time: 0.3947  data: 0.0010  max mem: 2908
Train: Epoch[4/5]  [ 190/3750]  eta: 0:23:26  Lr: 0.030000  Loss: -2.2375  Acc@1: 87.5000 (82.9843)  Acc@5: 100.0000 (96.4660)  time: 0.3944  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [ 200/3750]  eta: 0:23:21  Lr: 0.030000  Loss: -2.3770  Acc@1: 81.2500 (83.0846)  Acc@5: 100.0000 (96.4552)  time: 0.3908  data: 0.0006  max mem: 2908
Train: Epoch[4/5]  [ 210/3750]  eta: 0:23:17  Lr: 0.030000  Loss: -2.7698  Acc@1: 81.2500 (83.0569)  Acc@5: 100.0000 (96.5047)  time: 0.3916  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [ 220/3750]  eta: 0:23:13  Lr: 0.030000  Loss: -2.3648  Acc@1: 81.2500 (83.0600)  Acc@5: 100.0000 (96.4932)  time: 0.3935  data: 0.0013  max mem: 2908
Train: Epoch[4/5]  [ 230/3750]  eta: 0:23:08  Lr: 0.030000  Loss: -2.8605  Acc@1: 81.2500 (82.9816)  Acc@5: 100.0000 (96.5097)  time: 0.3933  data: 0.0006  max mem: 2908
Train: Epoch[4/5]  [ 240/3750]  eta: 0:23:05  Lr: 0.030000  Loss: -2.7874  Acc@1: 81.2500 (82.9357)  Acc@5: 93.7500 (96.3693)  time: 0.3955  data: 0.0015  max mem: 2908
Train: Epoch[4/5]  [ 250/3750]  eta: 0:23:01  Lr: 0.030000  Loss: -2.0232  Acc@1: 81.2500 (82.7938)  Acc@5: 93.7500 (96.2649)  time: 0.3969  data: 0.0016  max mem: 2908
Train: Epoch[4/5]  [ 260/3750]  eta: 0:22:57  Lr: 0.030000  Loss: -1.9315  Acc@1: 81.2500 (82.6628)  Acc@5: 93.7500 (96.2883)  time: 0.3951  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [ 270/3750]  eta: 0:22:53  Lr: 0.030000  Loss: -2.5343  Acc@1: 81.2500 (82.7721)  Acc@5: 93.7500 (96.3100)  time: 0.3947  data: 0.0018  max mem: 2908
Train: Epoch[4/5]  [ 280/3750]  eta: 0:22:49  Lr: 0.030000  Loss: -2.5174  Acc@1: 81.2500 (82.6290)  Acc@5: 93.7500 (96.2411)  time: 0.3933  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [ 290/3750]  eta: 0:22:45  Lr: 0.030000  Loss: -2.5701  Acc@1: 87.5000 (82.7964)  Acc@5: 100.0000 (96.3273)  time: 0.3932  data: 0.0006  max mem: 2908
Train: Epoch[4/5]  [ 300/3750]  eta: 0:22:41  Lr: 0.030000  Loss: -2.6733  Acc@1: 87.5000 (82.9319)  Acc@5: 100.0000 (96.3248)  time: 0.3948  data: 0.0008  max mem: 2908
Train: Epoch[4/5]  [ 310/3750]  eta: 0:22:37  Lr: 0.030000  Loss: -2.6423  Acc@1: 81.2500 (82.9381)  Acc@5: 100.0000 (96.4027)  time: 0.3968  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [ 320/3750]  eta: 0:22:34  Lr: 0.030000  Loss: -2.4684  Acc@1: 81.2500 (82.9829)  Acc@5: 100.0000 (96.4564)  time: 0.3965  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [ 330/3750]  eta: 0:22:30  Lr: 0.030000  Loss: -2.3613  Acc@1: 81.2500 (83.0438)  Acc@5: 100.0000 (96.4124)  time: 0.3962  data: 0.0025  max mem: 2908
Train: Epoch[4/5]  [ 340/3750]  eta: 0:22:26  Lr: 0.030000  Loss: -2.3433  Acc@1: 87.5000 (83.1562)  Acc@5: 93.7500 (96.3893)  time: 0.3948  data: 0.0017  max mem: 2908
Train: Epoch[4/5]  [ 350/3750]  eta: 0:22:22  Lr: 0.030000  Loss: -2.6151  Acc@1: 87.5000 (83.1375)  Acc@5: 100.0000 (96.4031)  time: 0.3938  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [ 360/3750]  eta: 0:22:18  Lr: 0.030000  Loss: -2.9855  Acc@1: 87.5000 (83.2583)  Acc@5: 100.0000 (96.4681)  time: 0.3953  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 370/3750]  eta: 0:22:14  Lr: 0.030000  Loss: -2.6439  Acc@1: 87.5000 (83.3053)  Acc@5: 100.0000 (96.5128)  time: 0.3941  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 380/3750]  eta: 0:22:10  Lr: 0.030000  Loss: -2.4838  Acc@1: 81.2500 (83.2349)  Acc@5: 100.0000 (96.4567)  time: 0.3959  data: 0.0020  max mem: 2908
Train: Epoch[4/5]  [ 390/3750]  eta: 0:22:07  Lr: 0.030000  Loss: -3.1192  Acc@1: 87.5000 (83.3440)  Acc@5: 93.7500 (96.4834)  time: 0.3994  data: 0.0025  max mem: 2908
Train: Epoch[4/5]  [ 400/3750]  eta: 0:22:03  Lr: 0.030000  Loss: -2.2500  Acc@1: 87.5000 (83.3541)  Acc@5: 100.0000 (96.4931)  time: 0.3966  data: 0.0010  max mem: 2908
Train: Epoch[4/5]  [ 410/3750]  eta: 0:21:58  Lr: 0.030000  Loss: -2.6237  Acc@1: 81.2500 (83.4550)  Acc@5: 100.0000 (96.5328)  time: 0.3930  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [ 420/3750]  eta: 0:21:55  Lr: 0.030000  Loss: -2.4960  Acc@1: 81.2500 (83.3135)  Acc@5: 100.0000 (96.4816)  time: 0.3950  data: 0.0024  max mem: 2908
Train: Epoch[4/5]  [ 430/3750]  eta: 0:21:51  Lr: 0.030000  Loss: -2.2146  Acc@1: 81.2500 (83.4107)  Acc@5: 93.7500 (96.4762)  time: 0.3983  data: 0.0032  max mem: 2908
Train: Epoch[4/5]  [ 440/3750]  eta: 0:21:47  Lr: 0.030000  Loss: -2.3680  Acc@1: 93.7500 (83.4325)  Acc@5: 100.0000 (96.4853)  time: 0.3952  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [ 450/3750]  eta: 0:21:43  Lr: 0.030000  Loss: -2.6429  Acc@1: 87.5000 (83.4396)  Acc@5: 100.0000 (96.5078)  time: 0.3922  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 460/3750]  eta: 0:21:39  Lr: 0.030000  Loss: -2.5535  Acc@1: 81.2500 (83.4463)  Acc@5: 100.0000 (96.5564)  time: 0.3924  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 470/3750]  eta: 0:21:35  Lr: 0.030000  Loss: -1.9306  Acc@1: 81.2500 (83.3731)  Acc@5: 100.0000 (96.5234)  time: 0.3929  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [ 480/3750]  eta: 0:21:31  Lr: 0.030000  Loss: -2.3420  Acc@1: 81.2500 (83.3420)  Acc@5: 93.7500 (96.5177)  time: 0.3941  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [ 490/3750]  eta: 0:21:27  Lr: 0.030000  Loss: -1.8689  Acc@1: 81.2500 (83.2739)  Acc@5: 93.7500 (96.4995)  time: 0.3936  data: 0.0013  max mem: 2908
Train: Epoch[4/5]  [ 500/3750]  eta: 0:21:23  Lr: 0.030000  Loss: -2.7881  Acc@1: 81.2500 (83.2460)  Acc@5: 100.0000 (96.5070)  time: 0.3945  data: 0.0023  max mem: 2908
Train: Epoch[4/5]  [ 510/3750]  eta: 0:21:19  Lr: 0.030000  Loss: -2.4063  Acc@1: 81.2500 (83.1825)  Acc@5: 93.7500 (96.4897)  time: 0.3947  data: 0.0023  max mem: 2908
Train: Epoch[4/5]  [ 520/3750]  eta: 0:21:15  Lr: 0.030000  Loss: -2.4565  Acc@1: 81.2500 (83.2294)  Acc@5: 100.0000 (96.5211)  time: 0.3933  data: 0.0013  max mem: 2908
Train: Epoch[4/5]  [ 530/3750]  eta: 0:21:11  Lr: 0.030000  Loss: -2.7355  Acc@1: 81.2500 (83.1568)  Acc@5: 100.0000 (96.4925)  time: 0.3958  data: 0.0018  max mem: 2908
Train: Epoch[4/5]  [ 540/3750]  eta: 0:21:07  Lr: 0.030000  Loss: -2.4313  Acc@1: 75.0000 (83.0869)  Acc@5: 93.7500 (96.4649)  time: 0.3947  data: 0.0017  max mem: 2908
Train: Epoch[4/5]  [ 550/3750]  eta: 0:21:03  Lr: 0.030000  Loss: -1.9999  Acc@1: 75.0000 (83.0082)  Acc@5: 93.7500 (96.4270)  time: 0.3933  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [ 560/3750]  eta: 0:20:59  Lr: 0.030000  Loss: -2.0352  Acc@1: 81.2500 (82.9434)  Acc@5: 93.7500 (96.3681)  time: 0.3938  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [ 570/3750]  eta: 0:20:55  Lr: 0.030000  Loss: -2.3758  Acc@1: 81.2500 (82.9685)  Acc@5: 93.7500 (96.3660)  time: 0.3929  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [ 580/3750]  eta: 0:20:51  Lr: 0.030000  Loss: -2.7513  Acc@1: 81.2500 (82.9389)  Acc@5: 100.0000 (96.4071)  time: 0.3947  data: 0.0019  max mem: 2908
Train: Epoch[4/5]  [ 590/3750]  eta: 0:20:47  Lr: 0.030000  Loss: -1.9841  Acc@1: 87.5000 (83.0690)  Acc@5: 100.0000 (96.4150)  time: 0.3951  data: 0.0017  max mem: 2908
Train: Epoch[4/5]  [ 600/3750]  eta: 0:20:43  Lr: 0.030000  Loss: -2.6521  Acc@1: 87.5000 (83.0075)  Acc@5: 100.0000 (96.4434)  time: 0.3937  data: 0.0013  max mem: 2908
Train: Epoch[4/5]  [ 610/3750]  eta: 0:20:39  Lr: 0.030000  Loss: -2.8919  Acc@1: 81.2500 (82.9480)  Acc@5: 100.0000 (96.4300)  time: 0.3924  data: 0.0006  max mem: 2908
Train: Epoch[4/5]  [ 620/3750]  eta: 0:20:35  Lr: 0.030000  Loss: -2.3071  Acc@1: 81.2500 (82.9408)  Acc@5: 100.0000 (96.4473)  time: 0.3934  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [ 630/3750]  eta: 0:20:31  Lr: 0.030000  Loss: -2.0203  Acc@1: 81.2500 (82.9536)  Acc@5: 100.0000 (96.4639)  time: 0.3941  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 640/3750]  eta: 0:20:27  Lr: 0.030000  Loss: -3.0544  Acc@1: 81.2500 (82.9856)  Acc@5: 100.0000 (96.4509)  time: 0.3937  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [ 650/3750]  eta: 0:20:23  Lr: 0.030000  Loss: -2.7750  Acc@1: 81.2500 (82.9493)  Acc@5: 93.7500 (96.4574)  time: 0.3931  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [ 660/3750]  eta: 0:20:19  Lr: 0.030000  Loss: -2.3456  Acc@1: 81.2500 (82.9709)  Acc@5: 93.7500 (96.4259)  time: 0.3922  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [ 670/3750]  eta: 0:20:15  Lr: 0.030000  Loss: -2.5562  Acc@1: 87.5000 (82.9639)  Acc@5: 93.7500 (96.4139)  time: 0.3924  data: 0.0025  max mem: 2908
Train: Epoch[4/5]  [ 680/3750]  eta: 0:20:11  Lr: 0.030000  Loss: -2.3965  Acc@1: 81.2500 (82.9938)  Acc@5: 93.7500 (96.4115)  time: 0.3928  data: 0.0018  max mem: 2908
Train: Epoch[4/5]  [ 690/3750]  eta: 0:20:07  Lr: 0.030000  Loss: -2.7389  Acc@1: 87.5000 (82.9866)  Acc@5: 100.0000 (96.4092)  time: 0.3933  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 700/3750]  eta: 0:20:03  Lr: 0.030000  Loss: -2.6612  Acc@1: 81.2500 (82.9708)  Acc@5: 93.7500 (96.3891)  time: 0.3942  data: 0.0019  max mem: 2908
Train: Epoch[4/5]  [ 710/3750]  eta: 0:19:59  Lr: 0.030000  Loss: -1.6831  Acc@1: 81.2500 (82.9466)  Acc@5: 93.7500 (96.3959)  time: 0.3944  data: 0.0026  max mem: 2908
Train: Epoch[4/5]  [ 720/3750]  eta: 0:19:55  Lr: 0.030000  Loss: -2.3162  Acc@1: 81.2500 (82.9317)  Acc@5: 100.0000 (96.4112)  time: 0.3949  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [ 730/3750]  eta: 0:19:51  Lr: 0.030000  Loss: -2.5056  Acc@1: 81.2500 (82.9771)  Acc@5: 100.0000 (96.4176)  time: 0.3963  data: 0.0020  max mem: 2908
Train: Epoch[4/5]  [ 740/3750]  eta: 0:19:47  Lr: 0.030000  Loss: -2.7136  Acc@1: 81.2500 (82.9622)  Acc@5: 100.0000 (96.4406)  time: 0.3959  data: 0.0018  max mem: 2908
Train: Epoch[4/5]  [ 750/3750]  eta: 0:19:43  Lr: 0.030000  Loss: -2.6582  Acc@1: 81.2500 (82.9727)  Acc@5: 100.0000 (96.4547)  time: 0.3932  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [ 760/3750]  eta: 0:19:39  Lr: 0.030000  Loss: -2.4452  Acc@1: 81.2500 (82.9665)  Acc@5: 100.0000 (96.4602)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [ 770/3750]  eta: 0:19:35  Lr: 0.030000  Loss: -2.4287  Acc@1: 81.2500 (82.9929)  Acc@5: 100.0000 (96.4737)  time: 0.3950  data: 0.0008  max mem: 2908
Train: Epoch[4/5]  [ 780/3750]  eta: 0:19:31  Lr: 0.030000  Loss: -2.6157  Acc@1: 87.5000 (82.9706)  Acc@5: 100.0000 (96.4709)  time: 0.3953  data: 0.0015  max mem: 2908
Train: Epoch[4/5]  [ 790/3750]  eta: 0:19:27  Lr: 0.030000  Loss: -2.7204  Acc@1: 81.2500 (82.9567)  Acc@5: 93.7500 (96.4523)  time: 0.3938  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [ 800/3750]  eta: 0:19:23  Lr: 0.030000  Loss: -2.0616  Acc@1: 81.2500 (82.9198)  Acc@5: 93.7500 (96.4107)  time: 0.3929  data: 0.0006  max mem: 2908
Train: Epoch[4/5]  [ 810/3750]  eta: 0:19:19  Lr: 0.030000  Loss: -2.8300  Acc@1: 81.2500 (82.9377)  Acc@5: 93.7500 (96.4242)  time: 0.3943  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [ 820/3750]  eta: 0:19:15  Lr: 0.030000  Loss: -2.5608  Acc@1: 81.2500 (82.9324)  Acc@5: 93.7500 (96.3916)  time: 0.3960  data: 0.0014  max mem: 2908
Train: Epoch[4/5]  [ 830/3750]  eta: 0:19:11  Lr: 0.030000  Loss: -2.8715  Acc@1: 81.2500 (83.0024)  Acc@5: 93.7500 (96.4125)  time: 0.3940  data: 0.0019  max mem: 2908
Train: Epoch[4/5]  [ 840/3750]  eta: 0:19:07  Lr: 0.030000  Loss: -2.7799  Acc@1: 87.5000 (83.0262)  Acc@5: 100.0000 (96.4180)  time: 0.3936  data: 0.0028  max mem: 2908
Train: Epoch[4/5]  [ 850/3750]  eta: 0:19:04  Lr: 0.030000  Loss: -2.6846  Acc@1: 87.5000 (83.0494)  Acc@5: 100.0000 (96.4307)  time: 0.3954  data: 0.0031  max mem: 2908
Train: Epoch[4/5]  [ 860/3750]  eta: 0:19:00  Lr: 0.030000  Loss: -2.5355  Acc@1: 87.5000 (83.1010)  Acc@5: 100.0000 (96.4358)  time: 0.3955  data: 0.0018  max mem: 2908
Train: Epoch[4/5]  [ 870/3750]  eta: 0:18:56  Lr: 0.030000  Loss: -2.7857  Acc@1: 87.5000 (83.1085)  Acc@5: 100.0000 (96.4480)  time: 0.3945  data: 0.0020  max mem: 2908
Train: Epoch[4/5]  [ 880/3750]  eta: 0:18:52  Lr: 0.030000  Loss: -2.8522  Acc@1: 87.5000 (83.1087)  Acc@5: 100.0000 (96.4742)  time: 0.3940  data: 0.0019  max mem: 2908
Train: Epoch[4/5]  [ 890/3750]  eta: 0:18:48  Lr: 0.030000  Loss: -2.5320  Acc@1: 81.2500 (83.0527)  Acc@5: 100.0000 (96.4927)  time: 0.3938  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [ 900/3750]  eta: 0:18:44  Lr: 0.030000  Loss: -2.5231  Acc@1: 81.2500 (83.0813)  Acc@5: 100.0000 (96.5039)  time: 0.3942  data: 0.0006  max mem: 2908
Train: Epoch[4/5]  [ 910/3750]  eta: 0:18:40  Lr: 0.030000  Loss: -1.9819  Acc@1: 81.2500 (83.0818)  Acc@5: 100.0000 (96.5148)  time: 0.3950  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [ 920/3750]  eta: 0:18:36  Lr: 0.030000  Loss: -2.7087  Acc@1: 81.2500 (83.0347)  Acc@5: 100.0000 (96.5119)  time: 0.3943  data: 0.0010  max mem: 2908
Train: Epoch[4/5]  [ 930/3750]  eta: 0:18:32  Lr: 0.030000  Loss: -2.3573  Acc@1: 81.2500 (83.0626)  Acc@5: 100.0000 (96.5293)  time: 0.3976  data: 0.0043  max mem: 2908
Train: Epoch[4/5]  [ 940/3750]  eta: 0:18:28  Lr: 0.030000  Loss: -2.2517  Acc@1: 81.2500 (83.0167)  Acc@5: 100.0000 (96.5263)  time: 0.4001  data: 0.0044  max mem: 2908
Train: Epoch[4/5]  [ 950/3750]  eta: 0:18:24  Lr: 0.030000  Loss: -2.0347  Acc@1: 81.2500 (83.0573)  Acc@5: 100.0000 (96.5431)  time: 0.3963  data: 0.0020  max mem: 2908
Train: Epoch[4/5]  [ 960/3750]  eta: 0:18:21  Lr: 0.030000  Loss: -2.6000  Acc@1: 87.5000 (83.0905)  Acc@5: 100.0000 (96.5336)  time: 0.3961  data: 0.0027  max mem: 2908
Train: Epoch[4/5]  [ 970/3750]  eta: 0:18:16  Lr: 0.030000  Loss: -2.8965  Acc@1: 81.2500 (83.0458)  Acc@5: 100.0000 (96.5242)  time: 0.3946  data: 0.0018  max mem: 2908
Train: Epoch[4/5]  [ 980/3750]  eta: 0:18:12  Lr: 0.030000  Loss: -2.1384  Acc@1: 81.2500 (82.9893)  Acc@5: 93.7500 (96.4959)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [ 990/3750]  eta: 0:18:08  Lr: 0.030000  Loss: -2.4063  Acc@1: 81.2500 (82.9654)  Acc@5: 93.7500 (96.4745)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1000/3750]  eta: 0:18:04  Lr: 0.030000  Loss: -2.8668  Acc@1: 81.2500 (83.0107)  Acc@5: 100.0000 (96.5097)  time: 0.3932  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1010/3750]  eta: 0:18:00  Lr: 0.030000  Loss: -2.7494  Acc@1: 87.5000 (82.9995)  Acc@5: 100.0000 (96.4948)  time: 0.3931  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1020/3750]  eta: 0:17:56  Lr: 0.030000  Loss: -2.7137  Acc@1: 87.5000 (83.0130)  Acc@5: 93.7500 (96.4985)  time: 0.3922  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1030/3750]  eta: 0:17:52  Lr: 0.030000  Loss: -2.9098  Acc@1: 87.5000 (83.0383)  Acc@5: 100.0000 (96.5264)  time: 0.3910  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [1040/3750]  eta: 0:17:48  Lr: 0.030000  Loss: -2.4113  Acc@1: 81.2500 (82.9971)  Acc@5: 100.0000 (96.5178)  time: 0.3911  data: 0.0014  max mem: 2908
Train: Epoch[4/5]  [1050/3750]  eta: 0:17:44  Lr: 0.030000  Loss: -2.3425  Acc@1: 81.2500 (82.9983)  Acc@5: 93.7500 (96.5093)  time: 0.3912  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1060/3750]  eta: 0:17:40  Lr: 0.030000  Loss: -2.8324  Acc@1: 87.5000 (82.9760)  Acc@5: 93.7500 (96.5127)  time: 0.3900  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [1070/3750]  eta: 0:17:36  Lr: 0.030000  Loss: -2.4631  Acc@1: 87.5000 (83.0124)  Acc@5: 100.0000 (96.5394)  time: 0.3908  data: 0.0009  max mem: 2908
Train: Epoch[4/5]  [1080/3750]  eta: 0:17:32  Lr: 0.030000  Loss: -2.5612  Acc@1: 87.5000 (83.0423)  Acc@5: 100.0000 (96.5599)  time: 0.3921  data: 0.0008  max mem: 2908
Train: Epoch[4/5]  [1090/3750]  eta: 0:17:28  Lr: 0.030000  Loss: -2.9412  Acc@1: 81.2500 (83.0374)  Acc@5: 100.0000 (96.5685)  time: 0.3908  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1100/3750]  eta: 0:17:24  Lr: 0.030000  Loss: -2.6949  Acc@1: 81.2500 (83.0609)  Acc@5: 100.0000 (96.5827)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [1110/3750]  eta: 0:17:20  Lr: 0.030000  Loss: -2.0977  Acc@1: 81.2500 (83.0614)  Acc@5: 100.0000 (96.5965)  time: 0.3920  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1120/3750]  eta: 0:17:16  Lr: 0.030000  Loss: -2.5049  Acc@1: 81.2500 (83.0620)  Acc@5: 100.0000 (96.5934)  time: 0.3916  data: 0.0010  max mem: 2908
Train: Epoch[4/5]  [1130/3750]  eta: 0:17:12  Lr: 0.030000  Loss: -2.4149  Acc@1: 81.2500 (83.0626)  Acc@5: 100.0000 (96.6015)  time: 0.3900  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1140/3750]  eta: 0:17:08  Lr: 0.030000  Loss: -2.3854  Acc@1: 81.2500 (83.0686)  Acc@5: 100.0000 (96.6039)  time: 0.3892  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1150/3750]  eta: 0:17:04  Lr: 0.030000  Loss: -3.0794  Acc@1: 81.2500 (83.0908)  Acc@5: 100.0000 (96.6116)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1160/3750]  eta: 0:17:00  Lr: 0.030000  Loss: -2.5473  Acc@1: 87.5000 (83.1288)  Acc@5: 100.0000 (96.6301)  time: 0.3917  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1170/3750]  eta: 0:16:56  Lr: 0.030000  Loss: -2.8952  Acc@1: 87.5000 (83.1394)  Acc@5: 100.0000 (96.6322)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1180/3750]  eta: 0:16:52  Lr: 0.030000  Loss: -2.7668  Acc@1: 87.5000 (83.1657)  Acc@5: 100.0000 (96.6342)  time: 0.3931  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1190/3750]  eta: 0:16:48  Lr: 0.030000  Loss: -2.3131  Acc@1: 81.2500 (83.1602)  Acc@5: 100.0000 (96.6362)  time: 0.3944  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1200/3750]  eta: 0:16:44  Lr: 0.030000  Loss: -2.2371  Acc@1: 81.2500 (83.1286)  Acc@5: 100.0000 (96.6486)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1210/3750]  eta: 0:16:40  Lr: 0.030000  Loss: -2.4370  Acc@1: 81.2500 (83.1080)  Acc@5: 100.0000 (96.6453)  time: 0.3918  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [1220/3750]  eta: 0:16:36  Lr: 0.030000  Loss: -2.2814  Acc@1: 81.2500 (83.1030)  Acc@5: 100.0000 (96.6319)  time: 0.3942  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [1230/3750]  eta: 0:16:32  Lr: 0.030000  Loss: -2.2202  Acc@1: 81.2500 (83.0676)  Acc@5: 100.0000 (96.6186)  time: 0.3946  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [1240/3750]  eta: 0:16:28  Lr: 0.030000  Loss: -2.7791  Acc@1: 81.2500 (83.0782)  Acc@5: 100.0000 (96.6207)  time: 0.3935  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1250/3750]  eta: 0:16:25  Lr: 0.030000  Loss: -2.5045  Acc@1: 81.2500 (83.0635)  Acc@5: 100.0000 (96.6227)  time: 0.3938  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1260/3750]  eta: 0:16:21  Lr: 0.030000  Loss: -2.4330  Acc@1: 81.2500 (83.0690)  Acc@5: 100.0000 (96.6197)  time: 0.3934  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1270/3750]  eta: 0:16:17  Lr: 0.030000  Loss: -2.7000  Acc@1: 81.2500 (83.0547)  Acc@5: 100.0000 (96.6267)  time: 0.3923  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1280/3750]  eta: 0:16:13  Lr: 0.030000  Loss: -2.4330  Acc@1: 81.2500 (83.0796)  Acc@5: 100.0000 (96.6237)  time: 0.3935  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1290/3750]  eta: 0:16:09  Lr: 0.030000  Loss: -2.8491  Acc@1: 87.5000 (83.1139)  Acc@5: 100.0000 (96.6305)  time: 0.3958  data: 0.0025  max mem: 2908
Train: Epoch[4/5]  [1300/3750]  eta: 0:16:05  Lr: 0.030000  Loss: -2.6634  Acc@1: 87.5000 (83.1043)  Acc@5: 100.0000 (96.6324)  time: 0.3982  data: 0.0027  max mem: 2908
Train: Epoch[4/5]  [1310/3750]  eta: 0:16:01  Lr: 0.030000  Loss: -2.7253  Acc@1: 81.2500 (83.0854)  Acc@5: 100.0000 (96.6247)  time: 0.3996  data: 0.0027  max mem: 2908
Train: Epoch[4/5]  [1320/3750]  eta: 0:15:57  Lr: 0.030000  Loss: -2.3516  Acc@1: 81.2500 (83.0715)  Acc@5: 100.0000 (96.6313)  time: 0.3976  data: 0.0025  max mem: 2908
Train: Epoch[4/5]  [1330/3750]  eta: 0:15:53  Lr: 0.030000  Loss: -2.2648  Acc@1: 81.2500 (83.0579)  Acc@5: 100.0000 (96.6473)  time: 0.3955  data: 0.0019  max mem: 2908
Train: Epoch[4/5]  [1340/3750]  eta: 0:15:49  Lr: 0.030000  Loss: -2.3545  Acc@1: 81.2500 (83.0304)  Acc@5: 100.0000 (96.6583)  time: 0.3950  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [1350/3750]  eta: 0:15:45  Lr: 0.030000  Loss: -2.7216  Acc@1: 81.2500 (83.0450)  Acc@5: 100.0000 (96.6738)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1360/3750]  eta: 0:15:41  Lr: 0.030000  Loss: -2.9523  Acc@1: 81.2500 (83.0410)  Acc@5: 100.0000 (96.6752)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1370/3750]  eta: 0:15:37  Lr: 0.030000  Loss: -2.2504  Acc@1: 81.2500 (83.0461)  Acc@5: 100.0000 (96.6813)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [1380/3750]  eta: 0:15:33  Lr: 0.030000  Loss: -2.2923  Acc@1: 81.2500 (83.0241)  Acc@5: 100.0000 (96.6781)  time: 0.3928  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [1390/3750]  eta: 0:15:29  Lr: 0.030000  Loss: -2.0603  Acc@1: 75.0000 (83.0068)  Acc@5: 100.0000 (96.6885)  time: 0.3945  data: 0.0013  max mem: 2908
Train: Epoch[4/5]  [1400/3750]  eta: 0:15:26  Lr: 0.030000  Loss: -2.4126  Acc@1: 81.2500 (83.0077)  Acc@5: 100.0000 (96.6899)  time: 0.3943  data: 0.0014  max mem: 2908
Train: Epoch[4/5]  [1410/3750]  eta: 0:15:22  Lr: 0.030000  Loss: -1.9056  Acc@1: 81.2500 (82.9908)  Acc@5: 93.7500 (96.6867)  time: 0.3959  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [1420/3750]  eta: 0:15:18  Lr: 0.030000  Loss: -2.2609  Acc@1: 81.2500 (82.9917)  Acc@5: 100.0000 (96.6881)  time: 0.3990  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1430/3750]  eta: 0:15:14  Lr: 0.030000  Loss: -2.6566  Acc@1: 81.2500 (83.0058)  Acc@5: 100.0000 (96.7025)  time: 0.3967  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1440/3750]  eta: 0:15:10  Lr: 0.030000  Loss: -2.0528  Acc@1: 87.5000 (83.0370)  Acc@5: 100.0000 (96.7080)  time: 0.3981  data: 0.0017  max mem: 2908
Train: Epoch[4/5]  [1450/3750]  eta: 0:15:06  Lr: 0.030000  Loss: -2.5801  Acc@1: 87.5000 (83.0720)  Acc@5: 100.0000 (96.7221)  time: 0.3983  data: 0.0017  max mem: 2908
Train: Epoch[4/5]  [1460/3750]  eta: 0:15:02  Lr: 0.030000  Loss: -2.5830  Acc@1: 87.5000 (83.0809)  Acc@5: 100.0000 (96.7274)  time: 0.3961  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1470/3750]  eta: 0:14:58  Lr: 0.030000  Loss: -2.6143  Acc@1: 87.5000 (83.0855)  Acc@5: 100.0000 (96.7029)  time: 0.3982  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1480/3750]  eta: 0:14:54  Lr: 0.030000  Loss: -1.8561  Acc@1: 81.2500 (83.0520)  Acc@5: 93.7500 (96.7083)  time: 0.3967  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [1490/3750]  eta: 0:14:50  Lr: 0.030000  Loss: -2.7319  Acc@1: 81.2500 (83.0734)  Acc@5: 100.0000 (96.7094)  time: 0.3941  data: 0.0008  max mem: 2908
Train: Epoch[4/5]  [1500/3750]  eta: 0:14:46  Lr: 0.030000  Loss: -2.8443  Acc@1: 81.2500 (83.0363)  Acc@5: 100.0000 (96.7064)  time: 0.3919  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1510/3750]  eta: 0:14:42  Lr: 0.030000  Loss: -2.7887  Acc@1: 81.2500 (83.0493)  Acc@5: 100.0000 (96.7116)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [1520/3750]  eta: 0:14:39  Lr: 0.030000  Loss: -2.3609  Acc@1: 87.5000 (83.0621)  Acc@5: 100.0000 (96.7168)  time: 0.3915  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1530/3750]  eta: 0:14:35  Lr: 0.030000  Loss: -2.4163  Acc@1: 87.5000 (83.0830)  Acc@5: 100.0000 (96.7137)  time: 0.3922  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1540/3750]  eta: 0:14:31  Lr: 0.030000  Loss: -1.9787  Acc@1: 81.2500 (83.0346)  Acc@5: 93.7500 (96.7026)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1550/3750]  eta: 0:14:27  Lr: 0.030000  Loss: -2.8416  Acc@1: 81.2500 (83.0351)  Acc@5: 100.0000 (96.7078)  time: 0.3934  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1560/3750]  eta: 0:14:23  Lr: 0.030000  Loss: -2.5443  Acc@1: 81.2500 (83.0597)  Acc@5: 100.0000 (96.7168)  time: 0.3947  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1570/3750]  eta: 0:14:19  Lr: 0.030000  Loss: -2.3745  Acc@1: 87.5000 (83.0602)  Acc@5: 100.0000 (96.7099)  time: 0.3938  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1580/3750]  eta: 0:14:15  Lr: 0.030000  Loss: -2.5680  Acc@1: 87.5000 (83.0527)  Acc@5: 93.7500 (96.7070)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1590/3750]  eta: 0:14:11  Lr: 0.030000  Loss: -2.4477  Acc@1: 87.5000 (83.0688)  Acc@5: 100.0000 (96.7120)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1600/3750]  eta: 0:14:07  Lr: 0.030000  Loss: -2.2426  Acc@1: 81.2500 (83.0340)  Acc@5: 100.0000 (96.7130)  time: 0.3935  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1610/3750]  eta: 0:14:03  Lr: 0.030000  Loss: -2.1007  Acc@1: 81.2500 (83.0307)  Acc@5: 100.0000 (96.7179)  time: 0.3930  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1620/3750]  eta: 0:13:59  Lr: 0.030000  Loss: -2.4205  Acc@1: 81.2500 (83.0043)  Acc@5: 100.0000 (96.7227)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [1630/3750]  eta: 0:13:55  Lr: 0.030000  Loss: -2.7684  Acc@1: 81.2500 (83.0127)  Acc@5: 100.0000 (96.7351)  time: 0.3932  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1640/3750]  eta: 0:13:51  Lr: 0.030000  Loss: -2.3995  Acc@1: 81.2500 (82.9982)  Acc@5: 93.7500 (96.7169)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1650/3750]  eta: 0:13:47  Lr: 0.030000  Loss: -2.1510  Acc@1: 87.5000 (83.0179)  Acc@5: 93.7500 (96.7293)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [1660/3750]  eta: 0:13:43  Lr: 0.030000  Loss: -1.9055  Acc@1: 87.5000 (83.0260)  Acc@5: 100.0000 (96.7377)  time: 0.3926  data: 0.0010  max mem: 2908
Train: Epoch[4/5]  [1670/3750]  eta: 0:13:39  Lr: 0.030000  Loss: -2.4704  Acc@1: 81.2500 (83.0266)  Acc@5: 100.0000 (96.7385)  time: 0.3944  data: 0.0018  max mem: 2908
Train: Epoch[4/5]  [1680/3750]  eta: 0:13:35  Lr: 0.030000  Loss: -2.7807  Acc@1: 81.2500 (83.0198)  Acc@5: 100.0000 (96.7393)  time: 0.3925  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [1690/3750]  eta: 0:13:31  Lr: 0.030000  Loss: -2.8286  Acc@1: 81.2500 (83.0204)  Acc@5: 93.7500 (96.7290)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1700/3750]  eta: 0:13:27  Lr: 0.030000  Loss: -2.4374  Acc@1: 81.2500 (83.0284)  Acc@5: 93.7500 (96.7299)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1710/3750]  eta: 0:13:23  Lr: 0.030000  Loss: -1.8032  Acc@1: 81.2500 (82.9887)  Acc@5: 93.7500 (96.7198)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1720/3750]  eta: 0:13:19  Lr: 0.030000  Loss: -2.4626  Acc@1: 87.5000 (83.0222)  Acc@5: 100.0000 (96.7170)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1730/3750]  eta: 0:13:15  Lr: 0.030000  Loss: -2.1591  Acc@1: 87.5000 (83.0228)  Acc@5: 100.0000 (96.7252)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1740/3750]  eta: 0:13:11  Lr: 0.030000  Loss: -2.3926  Acc@1: 81.2500 (83.0198)  Acc@5: 100.0000 (96.7260)  time: 0.3935  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1750/3750]  eta: 0:13:07  Lr: 0.030000  Loss: -2.3188  Acc@1: 81.2500 (83.0347)  Acc@5: 93.7500 (96.7197)  time: 0.3929  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1760/3750]  eta: 0:13:03  Lr: 0.030000  Loss: -2.6119  Acc@1: 87.5000 (83.0530)  Acc@5: 100.0000 (96.7206)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1770/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -2.5914  Acc@1: 81.2500 (83.0463)  Acc@5: 100.0000 (96.7285)  time: 0.3931  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1780/3750]  eta: 0:12:56  Lr: 0.030000  Loss: -2.8679  Acc@1: 81.2500 (83.0503)  Acc@5: 100.0000 (96.7223)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1790/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -1.8752  Acc@1: 81.2500 (83.0332)  Acc@5: 93.7500 (96.7127)  time: 0.3938  data: 0.0031  max mem: 2908
Train: Epoch[4/5]  [1800/3750]  eta: 0:12:48  Lr: 0.030000  Loss: -2.9783  Acc@1: 81.2500 (83.0407)  Acc@5: 93.7500 (96.7206)  time: 0.3946  data: 0.0031  max mem: 2908
Train: Epoch[4/5]  [1810/3750]  eta: 0:12:44  Lr: 0.030000  Loss: -2.4017  Acc@1: 81.2500 (83.0342)  Acc@5: 100.0000 (96.7214)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1820/3750]  eta: 0:12:40  Lr: 0.030000  Loss: -2.6493  Acc@1: 81.2500 (83.0107)  Acc@5: 93.7500 (96.7120)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1830/3750]  eta: 0:12:36  Lr: 0.030000  Loss: -2.8799  Acc@1: 87.5000 (83.0216)  Acc@5: 100.0000 (96.7163)  time: 0.3909  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1840/3750]  eta: 0:12:32  Lr: 0.030000  Loss: -1.9954  Acc@1: 81.2500 (83.0187)  Acc@5: 93.7500 (96.7070)  time: 0.3929  data: 0.0022  max mem: 2908
Train: Epoch[4/5]  [1850/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -3.1370  Acc@1: 81.2500 (82.9991)  Acc@5: 100.0000 (96.7011)  time: 0.3927  data: 0.0021  max mem: 2908
Train: Epoch[4/5]  [1860/3750]  eta: 0:12:24  Lr: 0.030000  Loss: -1.7040  Acc@1: 81.2500 (82.9930)  Acc@5: 100.0000 (96.6987)  time: 0.3908  data: 0.0011  max mem: 2908
Train: Epoch[4/5]  [1870/3750]  eta: 0:12:20  Lr: 0.030000  Loss: -2.4929  Acc@1: 81.2500 (82.9870)  Acc@5: 100.0000 (96.6996)  time: 0.3912  data: 0.0010  max mem: 2908
Train: Epoch[4/5]  [1880/3750]  eta: 0:12:16  Lr: 0.030000  Loss: -2.3138  Acc@1: 81.2500 (83.0011)  Acc@5: 100.0000 (96.6972)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [1890/3750]  eta: 0:12:12  Lr: 0.030000  Loss: -2.5170  Acc@1: 87.5000 (83.0149)  Acc@5: 100.0000 (96.7081)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1900/3750]  eta: 0:12:08  Lr: 0.030000  Loss: -2.6313  Acc@1: 81.2500 (83.0089)  Acc@5: 100.0000 (96.7188)  time: 0.3924  data: 0.0012  max mem: 2908
Train: Epoch[4/5]  [1910/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -2.4459  Acc@1: 81.2500 (82.9932)  Acc@5: 100.0000 (96.7098)  time: 0.3950  data: 0.0014  max mem: 2908
Train: Epoch[4/5]  [1920/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -2.4149  Acc@1: 81.2500 (82.9971)  Acc@5: 100.0000 (96.7140)  time: 0.3937  data: 0.0006  max mem: 2908
Train: Epoch[4/5]  [1930/3750]  eta: 0:11:56  Lr: 0.030000  Loss: -2.2326  Acc@1: 81.2500 (83.0043)  Acc@5: 100.0000 (96.7180)  time: 0.3926  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1940/3750]  eta: 0:11:52  Lr: 0.030000  Loss: -2.6497  Acc@1: 81.2500 (83.0146)  Acc@5: 100.0000 (96.7221)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1950/3750]  eta: 0:11:48  Lr: 0.030000  Loss: -2.7334  Acc@1: 81.2500 (83.0055)  Acc@5: 100.0000 (96.7132)  time: 0.3894  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [1960/3750]  eta: 0:11:44  Lr: 0.030000  Loss: -2.6900  Acc@1: 81.2500 (82.9997)  Acc@5: 93.7500 (96.7077)  time: 0.3915  data: 0.0014  max mem: 2908
Train: Epoch[4/5]  [1970/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -2.3860  Acc@1: 81.2500 (82.9718)  Acc@5: 93.7500 (96.7117)  time: 0.3918  data: 0.0016  max mem: 2908
Train: Epoch[4/5]  [1980/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -2.1973  Acc@1: 81.2500 (82.9631)  Acc@5: 93.7500 (96.7062)  time: 0.3918  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [1990/3750]  eta: 0:11:32  Lr: 0.030000  Loss: -2.4576  Acc@1: 81.2500 (82.9608)  Acc@5: 93.7500 (96.7039)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2000/3750]  eta: 0:11:28  Lr: 0.030000  Loss: -2.4290  Acc@1: 81.2500 (82.9398)  Acc@5: 100.0000 (96.7048)  time: 0.3909  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [2010/3750]  eta: 0:11:25  Lr: 0.030000  Loss: -2.1075  Acc@1: 81.2500 (82.9376)  Acc@5: 100.0000 (96.7118)  time: 0.3962  data: 0.0014  max mem: 2908
Train: Epoch[4/5]  [2020/3750]  eta: 0:11:21  Lr: 0.030000  Loss: -2.3859  Acc@1: 87.5000 (82.9447)  Acc@5: 100.0000 (96.7065)  time: 0.3966  data: 0.0018  max mem: 2908
Train: Epoch[4/5]  [2030/3750]  eta: 0:11:17  Lr: 0.030000  Loss: -2.7722  Acc@1: 81.2500 (82.9394)  Acc@5: 100.0000 (96.7196)  time: 0.3936  data: 0.0017  max mem: 2908
Train: Epoch[4/5]  [2040/3750]  eta: 0:11:13  Lr: 0.030000  Loss: -2.2309  Acc@1: 75.0000 (82.9281)  Acc@5: 100.0000 (96.7142)  time: 0.3923  data: 0.0009  max mem: 2908
Train: Epoch[4/5]  [2050/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -2.7036  Acc@1: 81.2500 (82.9382)  Acc@5: 93.7500 (96.7150)  time: 0.3934  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2060/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -1.5884  Acc@1: 81.2500 (82.9330)  Acc@5: 93.7500 (96.7128)  time: 0.3936  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2070/3750]  eta: 0:11:01  Lr: 0.030000  Loss: -2.3857  Acc@1: 81.2500 (82.9279)  Acc@5: 100.0000 (96.7196)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2080/3750]  eta: 0:10:57  Lr: 0.030000  Loss: -2.8436  Acc@1: 81.2500 (82.9199)  Acc@5: 93.7500 (96.7143)  time: 0.3935  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [2090/3750]  eta: 0:10:53  Lr: 0.030000  Loss: -2.7565  Acc@1: 81.2500 (82.9119)  Acc@5: 100.0000 (96.7211)  time: 0.3934  data: 0.0007  max mem: 2908
Train: Epoch[4/5]  [2100/3750]  eta: 0:10:49  Lr: 0.030000  Loss: -1.9542  Acc@1: 81.2500 (82.9010)  Acc@5: 100.0000 (96.7218)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2110/3750]  eta: 0:10:45  Lr: 0.030000  Loss: -2.1692  Acc@1: 81.2500 (82.8813)  Acc@5: 93.7500 (96.7136)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2120/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -2.8468  Acc@1: 81.2500 (82.8619)  Acc@5: 93.7500 (96.7085)  time: 0.3928  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2130/3750]  eta: 0:10:37  Lr: 0.030000  Loss: -2.7732  Acc@1: 81.2500 (82.8719)  Acc@5: 93.7500 (96.7064)  time: 0.3935  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2140/3750]  eta: 0:10:33  Lr: 0.030000  Loss: -2.1204  Acc@1: 81.2500 (82.8439)  Acc@5: 93.7500 (96.7042)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2150/3750]  eta: 0:10:29  Lr: 0.030000  Loss: -2.8371  Acc@1: 81.2500 (82.8510)  Acc@5: 100.0000 (96.7137)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2160/3750]  eta: 0:10:25  Lr: 0.030000  Loss: -2.3605  Acc@1: 81.2500 (82.8407)  Acc@5: 100.0000 (96.7058)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2170/3750]  eta: 0:10:21  Lr: 0.030000  Loss: -2.3235  Acc@1: 81.2500 (82.8219)  Acc@5: 93.7500 (96.7008)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2180/3750]  eta: 0:10:18  Lr: 0.030000  Loss: -2.2738  Acc@1: 81.2500 (82.8146)  Acc@5: 100.0000 (96.7016)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2190/3750]  eta: 0:10:14  Lr: 0.030000  Loss: -2.5197  Acc@1: 81.2500 (82.8104)  Acc@5: 100.0000 (96.6996)  time: 0.3924  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2200/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -2.7463  Acc@1: 81.2500 (82.8090)  Acc@5: 100.0000 (96.6975)  time: 0.3931  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2210/3750]  eta: 0:10:06  Lr: 0.030000  Loss: -1.8005  Acc@1: 87.5000 (82.7906)  Acc@5: 100.0000 (96.7040)  time: 0.3926  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2220/3750]  eta: 0:10:02  Lr: 0.030000  Loss: -2.1546  Acc@1: 81.2500 (82.7977)  Acc@5: 100.0000 (96.7048)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2230/3750]  eta: 0:09:58  Lr: 0.030000  Loss: -2.5222  Acc@1: 87.5000 (82.8132)  Acc@5: 100.0000 (96.7055)  time: 0.3912  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2240/3750]  eta: 0:09:54  Lr: 0.030000  Loss: -2.6245  Acc@1: 87.5000 (82.8090)  Acc@5: 100.0000 (96.7091)  time: 0.3913  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2250/3750]  eta: 0:09:50  Lr: 0.030000  Loss: -2.6041  Acc@1: 81.2500 (82.8215)  Acc@5: 100.0000 (96.7153)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2260/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -2.8133  Acc@1: 81.2500 (82.8284)  Acc@5: 100.0000 (96.7133)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2270/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -2.4649  Acc@1: 87.5000 (82.8435)  Acc@5: 100.0000 (96.7195)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2280/3750]  eta: 0:09:38  Lr: 0.030000  Loss: -2.1174  Acc@1: 87.5000 (82.8584)  Acc@5: 100.0000 (96.7257)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2290/3750]  eta: 0:09:34  Lr: 0.030000  Loss: -2.6633  Acc@1: 81.2500 (82.8459)  Acc@5: 100.0000 (96.7127)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2300/3750]  eta: 0:09:30  Lr: 0.030000  Loss: -2.7176  Acc@1: 81.2500 (82.8363)  Acc@5: 93.7500 (96.7107)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2310/3750]  eta: 0:09:26  Lr: 0.030000  Loss: -2.2837  Acc@1: 81.2500 (82.8213)  Acc@5: 93.7500 (96.7033)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2320/3750]  eta: 0:09:22  Lr: 0.030000  Loss: -2.4077  Acc@1: 81.2500 (82.8253)  Acc@5: 93.7500 (96.6932)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2330/3750]  eta: 0:09:18  Lr: 0.030000  Loss: -2.2857  Acc@1: 81.2500 (82.8239)  Acc@5: 93.7500 (96.6913)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2340/3750]  eta: 0:09:14  Lr: 0.030000  Loss: -2.9546  Acc@1: 81.2500 (82.8198)  Acc@5: 93.7500 (96.6788)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2350/3750]  eta: 0:09:10  Lr: 0.030000  Loss: -2.4205  Acc@1: 81.2500 (82.8132)  Acc@5: 93.7500 (96.6743)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2360/3750]  eta: 0:09:06  Lr: 0.030000  Loss: -2.2708  Acc@1: 81.2500 (82.8145)  Acc@5: 93.7500 (96.6672)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2370/3750]  eta: 0:09:02  Lr: 0.030000  Loss: -2.7702  Acc@1: 81.2500 (82.8105)  Acc@5: 100.0000 (96.6733)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2380/3750]  eta: 0:08:59  Lr: 0.030000  Loss: -2.4145  Acc@1: 81.2500 (82.8066)  Acc@5: 100.0000 (96.6768)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2390/3750]  eta: 0:08:55  Lr: 0.030000  Loss: -2.0771  Acc@1: 81.2500 (82.7949)  Acc@5: 100.0000 (96.6829)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2400/3750]  eta: 0:08:51  Lr: 0.030000  Loss: -2.2886  Acc@1: 75.0000 (82.7832)  Acc@5: 100.0000 (96.6837)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2410/3750]  eta: 0:08:47  Lr: 0.030000  Loss: -2.6830  Acc@1: 81.2500 (82.7924)  Acc@5: 100.0000 (96.6819)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2420/3750]  eta: 0:08:43  Lr: 0.030000  Loss: -2.9403  Acc@1: 87.5000 (82.8015)  Acc@5: 100.0000 (96.6853)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2430/3750]  eta: 0:08:39  Lr: 0.030000  Loss: -2.3894  Acc@1: 87.5000 (82.8054)  Acc@5: 100.0000 (96.6860)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2440/3750]  eta: 0:08:35  Lr: 0.030000  Loss: -2.3681  Acc@1: 81.2500 (82.7939)  Acc@5: 100.0000 (96.6868)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2450/3750]  eta: 0:08:31  Lr: 0.030000  Loss: -2.4194  Acc@1: 81.2500 (82.7978)  Acc@5: 100.0000 (96.6850)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2460/3750]  eta: 0:08:27  Lr: 0.030000  Loss: -2.5127  Acc@1: 81.2500 (82.7662)  Acc@5: 100.0000 (96.6782)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2470/3750]  eta: 0:08:23  Lr: 0.030000  Loss: -2.6667  Acc@1: 81.2500 (82.7625)  Acc@5: 93.7500 (96.6689)  time: 0.3895  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2480/3750]  eta: 0:08:19  Lr: 0.030000  Loss: -2.5237  Acc@1: 81.2500 (82.7489)  Acc@5: 100.0000 (96.6747)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2490/3750]  eta: 0:08:15  Lr: 0.030000  Loss: -2.0890  Acc@1: 81.2500 (82.7379)  Acc@5: 100.0000 (96.6730)  time: 0.3893  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2500/3750]  eta: 0:08:11  Lr: 0.030000  Loss: -2.0879  Acc@1: 81.2500 (82.7269)  Acc@5: 93.7500 (96.6538)  time: 0.3889  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2510/3750]  eta: 0:08:07  Lr: 0.030000  Loss: -2.9928  Acc@1: 87.5000 (82.7609)  Acc@5: 100.0000 (96.6622)  time: 0.3894  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2520/3750]  eta: 0:08:03  Lr: 0.030000  Loss: -2.4890  Acc@1: 87.5000 (82.7524)  Acc@5: 93.7500 (96.6482)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:59  Lr: 0.030000  Loss: -2.6120  Acc@1: 81.2500 (82.7415)  Acc@5: 93.7500 (96.6515)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:55  Lr: 0.030000  Loss: -2.0472  Acc@1: 81.2500 (82.7184)  Acc@5: 93.7500 (96.6401)  time: 0.3886  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2550/3750]  eta: 0:07:51  Lr: 0.030000  Loss: -2.6707  Acc@1: 81.2500 (82.7102)  Acc@5: 93.7500 (96.6410)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2560/3750]  eta: 0:07:47  Lr: 0.030000  Loss: -2.9827  Acc@1: 87.5000 (82.7240)  Acc@5: 100.0000 (96.6395)  time: 0.3903  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2570/3750]  eta: 0:07:43  Lr: 0.030000  Loss: -2.6468  Acc@1: 87.5000 (82.7305)  Acc@5: 93.7500 (96.6331)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2580/3750]  eta: 0:07:40  Lr: 0.030000  Loss: -2.5153  Acc@1: 81.2500 (82.7150)  Acc@5: 93.7500 (96.6316)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2590/3750]  eta: 0:07:36  Lr: 0.030000  Loss: -2.2098  Acc@1: 81.2500 (82.7142)  Acc@5: 93.7500 (96.6253)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2600/3750]  eta: 0:07:32  Lr: 0.030000  Loss: -2.2954  Acc@1: 87.5000 (82.7206)  Acc@5: 93.7500 (96.6191)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2610/3750]  eta: 0:07:28  Lr: 0.030000  Loss: -2.0284  Acc@1: 87.5000 (82.7269)  Acc@5: 93.7500 (96.6153)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2620/3750]  eta: 0:07:24  Lr: 0.030000  Loss: -2.7041  Acc@1: 87.5000 (82.7261)  Acc@5: 93.7500 (96.6115)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2630/3750]  eta: 0:07:20  Lr: 0.030000  Loss: -2.5213  Acc@1: 81.2500 (82.7300)  Acc@5: 100.0000 (96.6173)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2640/3750]  eta: 0:07:16  Lr: 0.030000  Loss: -2.8515  Acc@1: 81.2500 (82.7338)  Acc@5: 100.0000 (96.6230)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2650/3750]  eta: 0:07:12  Lr: 0.030000  Loss: -2.8876  Acc@1: 81.2500 (82.7282)  Acc@5: 100.0000 (96.6192)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2660/3750]  eta: 0:07:08  Lr: 0.030000  Loss: -2.6342  Acc@1: 81.2500 (82.7227)  Acc@5: 100.0000 (96.6155)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2670/3750]  eta: 0:07:04  Lr: 0.030000  Loss: -2.3648  Acc@1: 75.0000 (82.7031)  Acc@5: 100.0000 (96.6235)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2680/3750]  eta: 0:07:00  Lr: 0.030000  Loss: -2.0463  Acc@1: 75.0000 (82.6954)  Acc@5: 100.0000 (96.6244)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:56  Lr: 0.030000  Loss: -2.2765  Acc@1: 81.2500 (82.6993)  Acc@5: 100.0000 (96.6184)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:52  Lr: 0.030000  Loss: -2.3559  Acc@1: 81.2500 (82.7032)  Acc@5: 100.0000 (96.6239)  time: 0.3916  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:48  Lr: 0.030000  Loss: -2.0517  Acc@1: 81.2500 (82.6955)  Acc@5: 100.0000 (96.6249)  time: 0.3912  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [2720/3750]  eta: 0:06:44  Lr: 0.030000  Loss: -2.4195  Acc@1: 81.2500 (82.7017)  Acc@5: 100.0000 (96.6327)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2730/3750]  eta: 0:06:40  Lr: 0.030000  Loss: -2.7583  Acc@1: 87.5000 (82.6918)  Acc@5: 100.0000 (96.6267)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2740/3750]  eta: 0:06:36  Lr: 0.030000  Loss: -2.7947  Acc@1: 87.5000 (82.7093)  Acc@5: 100.0000 (96.6322)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2750/3750]  eta: 0:06:33  Lr: 0.030000  Loss: -2.9633  Acc@1: 87.5000 (82.7131)  Acc@5: 100.0000 (96.6308)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2760/3750]  eta: 0:06:29  Lr: 0.030000  Loss: -2.5496  Acc@1: 81.2500 (82.6988)  Acc@5: 93.7500 (96.6249)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2770/3750]  eta: 0:06:25  Lr: 0.030000  Loss: -2.1630  Acc@1: 81.2500 (82.6868)  Acc@5: 93.7500 (96.6145)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2780/3750]  eta: 0:06:21  Lr: 0.030000  Loss: -3.0112  Acc@1: 81.2500 (82.7086)  Acc@5: 100.0000 (96.6222)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2790/3750]  eta: 0:06:17  Lr: 0.030000  Loss: -2.8468  Acc@1: 87.5000 (82.7257)  Acc@5: 100.0000 (96.6298)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2800/3750]  eta: 0:06:13  Lr: 0.030000  Loss: -2.7640  Acc@1: 81.2500 (82.7294)  Acc@5: 100.0000 (96.6284)  time: 0.3891  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2810/3750]  eta: 0:06:09  Lr: 0.030000  Loss: -2.2425  Acc@1: 81.2500 (82.7263)  Acc@5: 93.7500 (96.6249)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2820/3750]  eta: 0:06:05  Lr: 0.030000  Loss: -2.3469  Acc@1: 81.2500 (82.7255)  Acc@5: 100.0000 (96.6258)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2830/3750]  eta: 0:06:01  Lr: 0.030000  Loss: -2.6439  Acc@1: 81.2500 (82.7314)  Acc@5: 100.0000 (96.6244)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:57  Lr: 0.030000  Loss: -2.1795  Acc@1: 81.2500 (82.7218)  Acc@5: 100.0000 (96.6297)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:53  Lr: 0.030000  Loss: -2.3631  Acc@1: 81.2500 (82.7056)  Acc@5: 100.0000 (96.6174)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:49  Lr: 0.030000  Loss: -2.6239  Acc@1: 81.2500 (82.7071)  Acc@5: 93.7500 (96.6227)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:45  Lr: 0.030000  Loss: -1.7261  Acc@1: 81.2500 (82.6955)  Acc@5: 100.0000 (96.6257)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -2.4491  Acc@1: 81.2500 (82.7122)  Acc@5: 100.0000 (96.6331)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2890/3750]  eta: 0:05:37  Lr: 0.030000  Loss: -2.2586  Acc@1: 87.5000 (82.7266)  Acc@5: 100.0000 (96.6361)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2900/3750]  eta: 0:05:33  Lr: 0.030000  Loss: -2.7433  Acc@1: 87.5000 (82.7258)  Acc@5: 100.0000 (96.6391)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2910/3750]  eta: 0:05:30  Lr: 0.030000  Loss: -2.4818  Acc@1: 81.2500 (82.7272)  Acc@5: 100.0000 (96.6442)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2920/3750]  eta: 0:05:26  Lr: 0.030000  Loss: -2.8507  Acc@1: 81.2500 (82.7414)  Acc@5: 100.0000 (96.6450)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2930/3750]  eta: 0:05:22  Lr: 0.030000  Loss: -2.4905  Acc@1: 87.5000 (82.7512)  Acc@5: 100.0000 (96.6436)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2940/3750]  eta: 0:05:18  Lr: 0.030000  Loss: -2.2673  Acc@1: 87.5000 (82.7482)  Acc@5: 93.7500 (96.6380)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2950/3750]  eta: 0:05:14  Lr: 0.030000  Loss: -2.3773  Acc@1: 87.5000 (82.7558)  Acc@5: 93.7500 (96.6389)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2960/3750]  eta: 0:05:10  Lr: 0.030000  Loss: -2.1949  Acc@1: 81.2500 (82.7508)  Acc@5: 100.0000 (96.6375)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2970/3750]  eta: 0:05:06  Lr: 0.030000  Loss: -2.5991  Acc@1: 75.0000 (82.7478)  Acc@5: 100.0000 (96.6404)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [2980/3750]  eta: 0:05:02  Lr: 0.030000  Loss: -2.5561  Acc@1: 81.2500 (82.7596)  Acc@5: 100.0000 (96.6412)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:58  Lr: 0.030000  Loss: -2.0340  Acc@1: 81.2500 (82.7566)  Acc@5: 93.7500 (96.6378)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:54  Lr: 0.030000  Loss: -2.9061  Acc@1: 81.2500 (82.7620)  Acc@5: 100.0000 (96.6449)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:50  Lr: 0.030000  Loss: -2.7532  Acc@1: 81.2500 (82.7632)  Acc@5: 100.0000 (96.6477)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -2.6365  Acc@1: 81.2500 (82.7685)  Acc@5: 100.0000 (96.6526)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:42  Lr: 0.030000  Loss: -2.9319  Acc@1: 81.2500 (82.7594)  Acc@5: 100.0000 (96.6554)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:38  Lr: 0.030000  Loss: -2.5441  Acc@1: 81.2500 (82.7585)  Acc@5: 100.0000 (96.6541)  time: 0.3894  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:34  Lr: 0.030000  Loss: -2.2366  Acc@1: 81.2500 (82.7495)  Acc@5: 100.0000 (96.6486)  time: 0.3893  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:31  Lr: 0.030000  Loss: -2.6162  Acc@1: 81.2500 (82.7405)  Acc@5: 93.7500 (96.6433)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3070/3750]  eta: 0:04:27  Lr: 0.030000  Loss: -2.2623  Acc@1: 81.2500 (82.7357)  Acc@5: 93.7500 (96.6399)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3080/3750]  eta: 0:04:23  Lr: 0.030000  Loss: -2.3333  Acc@1: 81.2500 (82.7227)  Acc@5: 93.7500 (96.6387)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3090/3750]  eta: 0:04:19  Lr: 0.030000  Loss: -2.3779  Acc@1: 81.2500 (82.7180)  Acc@5: 100.0000 (96.6374)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3100/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -2.5640  Acc@1: 81.2500 (82.7173)  Acc@5: 100.0000 (96.6321)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3110/3750]  eta: 0:04:11  Lr: 0.030000  Loss: -1.8474  Acc@1: 81.2500 (82.7146)  Acc@5: 93.7500 (96.6269)  time: 0.3923  data: 0.0010  max mem: 2908
Train: Epoch[4/5]  [3120/3750]  eta: 0:04:07  Lr: 0.030000  Loss: -2.8389  Acc@1: 81.2500 (82.7219)  Acc@5: 93.7500 (96.6217)  time: 0.3915  data: 0.0010  max mem: 2908
Train: Epoch[4/5]  [3130/3750]  eta: 0:04:03  Lr: 0.030000  Loss: -2.6785  Acc@1: 81.2500 (82.7092)  Acc@5: 100.0000 (96.6205)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:59  Lr: 0.030000  Loss: -2.5751  Acc@1: 81.2500 (82.6966)  Acc@5: 100.0000 (96.6253)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:55  Lr: 0.030000  Loss: -2.4621  Acc@1: 81.2500 (82.6999)  Acc@5: 93.7500 (96.6201)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -2.5410  Acc@1: 81.2500 (82.6914)  Acc@5: 93.7500 (96.6249)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -2.3576  Acc@1: 81.2500 (82.6947)  Acc@5: 93.7500 (96.6217)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:43  Lr: 0.030000  Loss: -2.1773  Acc@1: 81.2500 (82.6941)  Acc@5: 100.0000 (96.6284)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -2.4811  Acc@1: 87.5000 (82.7072)  Acc@5: 100.0000 (96.6272)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -2.5896  Acc@1: 87.5000 (82.7066)  Acc@5: 93.7500 (96.6241)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:32  Lr: 0.030000  Loss: -2.6567  Acc@1: 87.5000 (82.7176)  Acc@5: 93.7500 (96.6210)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:28  Lr: 0.030000  Loss: -2.0379  Acc@1: 87.5000 (82.7228)  Acc@5: 100.0000 (96.6237)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:24  Lr: 0.030000  Loss: -2.5082  Acc@1: 81.2500 (82.7143)  Acc@5: 100.0000 (96.6245)  time: 0.3921  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3240/3750]  eta: 0:03:20  Lr: 0.030000  Loss: -2.5117  Acc@1: 81.2500 (82.7060)  Acc@5: 100.0000 (96.6272)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3250/3750]  eta: 0:03:16  Lr: 0.030000  Loss: -2.7349  Acc@1: 81.2500 (82.7207)  Acc@5: 100.0000 (96.6241)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3260/3750]  eta: 0:03:12  Lr: 0.030000  Loss: -2.4809  Acc@1: 87.5000 (82.7181)  Acc@5: 100.0000 (96.6230)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3270/3750]  eta: 0:03:08  Lr: 0.030000  Loss: -2.4695  Acc@1: 81.2500 (82.7174)  Acc@5: 93.7500 (96.6237)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3280/3750]  eta: 0:03:04  Lr: 0.030000  Loss: -2.7213  Acc@1: 81.2500 (82.7168)  Acc@5: 100.0000 (96.6245)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3290/3750]  eta: 0:03:00  Lr: 0.030000  Loss: -2.4410  Acc@1: 81.2500 (82.7180)  Acc@5: 100.0000 (96.6253)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -2.9831  Acc@1: 87.5000 (82.7325)  Acc@5: 100.0000 (96.6317)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -2.3761  Acc@1: 87.5000 (82.7261)  Acc@5: 100.0000 (96.6230)  time: 0.3921  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -2.4144  Acc@1: 81.2500 (82.7236)  Acc@5: 93.7500 (96.6181)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -2.4655  Acc@1: 87.5000 (82.7285)  Acc@5: 93.7500 (96.6095)  time: 0.3921  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -2.9106  Acc@1: 87.5000 (82.7353)  Acc@5: 100.0000 (96.6122)  time: 0.3912  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:37  Lr: 0.030000  Loss: -2.4235  Acc@1: 81.2500 (82.7309)  Acc@5: 100.0000 (96.6130)  time: 0.3918  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:33  Lr: 0.030000  Loss: -2.8097  Acc@1: 81.2500 (82.7191)  Acc@5: 93.7500 (96.6119)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:29  Lr: 0.030000  Loss: -2.5826  Acc@1: 81.2500 (82.7277)  Acc@5: 100.0000 (96.6145)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:25  Lr: 0.030000  Loss: -2.3792  Acc@1: 81.2500 (82.7215)  Acc@5: 100.0000 (96.6153)  time: 0.3934  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -2.3039  Acc@1: 81.2500 (82.7319)  Acc@5: 100.0000 (96.6179)  time: 0.3940  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -2.3039  Acc@1: 87.5000 (82.7349)  Acc@5: 93.7500 (96.6095)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -2.6736  Acc@1: 87.5000 (82.7360)  Acc@5: 93.7500 (96.6066)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -2.6598  Acc@1: 81.2500 (82.7225)  Acc@5: 100.0000 (96.6055)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -2.4817  Acc@1: 81.2500 (82.7109)  Acc@5: 100.0000 (96.6081)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -2.2695  Acc@1: 81.2500 (82.7085)  Acc@5: 100.0000 (96.6053)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -2.8236  Acc@1: 81.2500 (82.7133)  Acc@5: 100.0000 (96.6097)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -2.5014  Acc@1: 81.2500 (82.7127)  Acc@5: 100.0000 (96.6159)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -2.6240  Acc@1: 81.2500 (82.7067)  Acc@5: 100.0000 (96.6184)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -1.3881  Acc@1: 75.0000 (82.6953)  Acc@5: 100.0000 (96.6191)  time: 0.3917  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:42  Lr: 0.030000  Loss: -2.5520  Acc@1: 81.2500 (82.6930)  Acc@5: 100.0000 (96.6181)  time: 0.3928  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:38  Lr: 0.030000  Loss: -2.0536  Acc@1: 81.2500 (82.6907)  Acc@5: 100.0000 (96.6188)  time: 0.3916  data: 0.0005  max mem: 2908
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:34  Lr: 0.030000  Loss: -2.7356  Acc@1: 81.2500 (82.6937)  Acc@5: 100.0000 (96.6249)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:30  Lr: 0.030000  Loss: -2.5983  Acc@1: 87.5000 (82.7002)  Acc@5: 100.0000 (96.6274)  time: 0.3893  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -2.7171  Acc@1: 81.2500 (82.7014)  Acc@5: 100.0000 (96.6316)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -2.3757  Acc@1: 87.5000 (82.7150)  Acc@5: 100.0000 (96.6341)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -2.6632  Acc@1: 87.5000 (82.7161)  Acc@5: 100.0000 (96.6330)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -3.0418  Acc@1: 81.2500 (82.7103)  Acc@5: 93.7500 (96.6319)  time: 0.3889  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -2.9396  Acc@1: 81.2500 (82.7062)  Acc@5: 93.7500 (96.6291)  time: 0.3895  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -2.0724  Acc@1: 81.2500 (82.7143)  Acc@5: 100.0000 (96.6333)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -2.6652  Acc@1: 87.5000 (82.7155)  Acc@5: 100.0000 (96.6374)  time: 0.3894  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -2.1021  Acc@1: 87.5000 (82.7183)  Acc@5: 100.0000 (96.6311)  time: 0.3889  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -2.8352  Acc@1: 87.5000 (82.7264)  Acc@5: 93.7500 (96.6301)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -2.4932  Acc@1: 87.5000 (82.7430)  Acc@5: 100.0000 (96.6377)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:47  Lr: 0.030000  Loss: -1.7059  Acc@1: 87.5000 (82.7441)  Acc@5: 100.0000 (96.6366)  time: 0.3949  data: 0.0014  max mem: 2908
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -2.5199  Acc@1: 87.5000 (82.7331)  Acc@5: 100.0000 (96.6355)  time: 0.3930  data: 0.0013  max mem: 2908
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -2.3842  Acc@1: 81.2500 (82.7136)  Acc@5: 93.7500 (96.6328)  time: 0.3890  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -2.6235  Acc@1: 81.2500 (82.7301)  Acc@5: 100.0000 (96.6386)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -2.7371  Acc@1: 87.5000 (82.7244)  Acc@5: 100.0000 (96.6358)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -2.4859  Acc@1: 81.2500 (82.7153)  Acc@5: 100.0000 (96.6297)  time: 0.3890  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -2.7289  Acc@1: 87.5000 (82.7316)  Acc@5: 100.0000 (96.6337)  time: 0.3886  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -2.6060  Acc@1: 87.5000 (82.7462)  Acc@5: 100.0000 (96.6377)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -2.3857  Acc@1: 87.5000 (82.7523)  Acc@5: 100.0000 (96.6417)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -2.9572  Acc@1: 87.5000 (82.7634)  Acc@5: 93.7500 (96.6356)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -2.4722  Acc@1: 87.5000 (82.7660)  Acc@5: 93.7500 (96.6363)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -2.9324  Acc@1: 81.2500 (82.7653)  Acc@5: 93.7500 (96.6319)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -2.4842  Acc@1: 81.2500 (82.7633)  Acc@5: 93.7500 (96.6300)  time: 0.3902  data: 0.0008  max mem: 2908
Train: Epoch[4/5] Total time: 0:24:32 (0.3926 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.4842  Acc@1: 81.2500 (82.7633)  Acc@5: 93.7500 (96.6300)
Train: Epoch[5/5]  [   0/3750]  eta: 0:46:50  Lr: 0.030000  Loss: -1.9642  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.7496  data: 0.3586  max mem: 2908
Train: Epoch[5/5]  [  10/3750]  eta: 0:26:16  Lr: 0.030000  Loss: -2.6368  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (96.5909)  time: 0.4216  data: 0.0329  max mem: 2908
Train: Epoch[5/5]  [  20/3750]  eta: 0:25:17  Lr: 0.030000  Loss: -2.6081  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (97.3214)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [  30/3750]  eta: 0:24:53  Lr: 0.030000  Loss: -2.6525  Acc@1: 81.2500 (83.4677)  Acc@5: 100.0000 (97.9839)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [  40/3750]  eta: 0:24:39  Lr: 0.030000  Loss: -2.8095  Acc@1: 87.5000 (84.9085)  Acc@5: 100.0000 (98.1707)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [  50/3750]  eta: 0:24:30  Lr: 0.030000  Loss: -3.0565  Acc@1: 87.5000 (84.5588)  Acc@5: 100.0000 (97.9167)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [  60/3750]  eta: 0:24:22  Lr: 0.030000  Loss: -2.3256  Acc@1: 81.2500 (83.7090)  Acc@5: 93.7500 (97.6434)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [  70/3750]  eta: 0:24:15  Lr: 0.030000  Loss: -2.4173  Acc@1: 75.0000 (82.8345)  Acc@5: 93.7500 (97.4472)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [  80/3750]  eta: 0:24:09  Lr: 0.030000  Loss: -2.5507  Acc@1: 75.0000 (82.3302)  Acc@5: 93.7500 (97.2222)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [  90/3750]  eta: 0:24:03  Lr: 0.030000  Loss: -2.0522  Acc@1: 87.5000 (82.8297)  Acc@5: 100.0000 (97.3214)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 100/3750]  eta: 0:23:57  Lr: 0.030000  Loss: -2.7675  Acc@1: 87.5000 (83.0446)  Acc@5: 100.0000 (97.5248)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 110/3750]  eta: 0:23:52  Lr: 0.030000  Loss: -2.6508  Acc@1: 87.5000 (83.1081)  Acc@5: 100.0000 (97.5788)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 120/3750]  eta: 0:23:48  Lr: 0.030000  Loss: -2.5489  Acc@1: 81.2500 (83.1095)  Acc@5: 100.0000 (97.4174)  time: 0.3910  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 130/3750]  eta: 0:23:44  Lr: 0.030000  Loss: -2.9952  Acc@1: 87.5000 (83.2538)  Acc@5: 100.0000 (97.4714)  time: 0.3924  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 140/3750]  eta: 0:23:39  Lr: 0.030000  Loss: -2.6040  Acc@1: 87.5000 (83.2890)  Acc@5: 100.0000 (97.3404)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 150/3750]  eta: 0:23:35  Lr: 0.030000  Loss: -2.3273  Acc@1: 87.5000 (83.2781)  Acc@5: 93.7500 (97.3096)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 160/3750]  eta: 0:23:31  Lr: 0.030000  Loss: -2.1612  Acc@1: 81.2500 (83.2686)  Acc@5: 100.0000 (97.2826)  time: 0.3914  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 170/3750]  eta: 0:23:26  Lr: 0.030000  Loss: -2.2490  Acc@1: 81.2500 (82.9678)  Acc@5: 100.0000 (97.3319)  time: 0.3914  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 180/3750]  eta: 0:23:23  Lr: 0.030000  Loss: -2.6578  Acc@1: 81.2500 (83.1492)  Acc@5: 100.0000 (97.3412)  time: 0.3936  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 190/3750]  eta: 0:23:19  Lr: 0.030000  Loss: -2.6609  Acc@1: 87.5000 (83.2461)  Acc@5: 100.0000 (97.3168)  time: 0.3942  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 200/3750]  eta: 0:23:15  Lr: 0.030000  Loss: -2.6740  Acc@1: 81.2500 (82.9602)  Acc@5: 93.7500 (97.1393)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 210/3750]  eta: 0:23:11  Lr: 0.030000  Loss: -2.6720  Acc@1: 81.2500 (82.8495)  Acc@5: 93.7500 (96.9194)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 220/3750]  eta: 0:23:07  Lr: 0.030000  Loss: -2.0755  Acc@1: 81.2500 (83.1165)  Acc@5: 93.7500 (96.8326)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 230/3750]  eta: 0:23:02  Lr: 0.030000  Loss: -2.9593  Acc@1: 87.5000 (83.0357)  Acc@5: 93.7500 (96.7262)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 240/3750]  eta: 0:22:58  Lr: 0.030000  Loss: -2.2073  Acc@1: 81.2500 (83.1432)  Acc@5: 100.0000 (96.7842)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 250/3750]  eta: 0:22:54  Lr: 0.030000  Loss: -2.4003  Acc@1: 81.2500 (82.9681)  Acc@5: 100.0000 (96.7380)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 260/3750]  eta: 0:22:50  Lr: 0.030000  Loss: -2.2273  Acc@1: 81.2500 (82.9741)  Acc@5: 93.7500 (96.7433)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 270/3750]  eta: 0:22:46  Lr: 0.030000  Loss: -2.1026  Acc@1: 81.2500 (83.0489)  Acc@5: 93.7500 (96.7251)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 280/3750]  eta: 0:22:41  Lr: 0.030000  Loss: -2.4517  Acc@1: 81.2500 (83.0294)  Acc@5: 100.0000 (96.7749)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 290/3750]  eta: 0:22:37  Lr: 0.030000  Loss: -2.4668  Acc@1: 87.5000 (83.1615)  Acc@5: 100.0000 (96.7998)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 300/3750]  eta: 0:22:33  Lr: 0.030000  Loss: -2.8946  Acc@1: 87.5000 (82.9942)  Acc@5: 100.0000 (96.7608)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 310/3750]  eta: 0:22:29  Lr: 0.030000  Loss: -2.2414  Acc@1: 75.0000 (82.7974)  Acc@5: 93.7500 (96.6238)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 320/3750]  eta: 0:22:25  Lr: 0.030000  Loss: -1.9074  Acc@1: 75.0000 (82.8271)  Acc@5: 93.7500 (96.5927)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 330/3750]  eta: 0:22:21  Lr: 0.030000  Loss: -2.8543  Acc@1: 87.5000 (82.8550)  Acc@5: 93.7500 (96.5823)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 340/3750]  eta: 0:22:17  Lr: 0.030000  Loss: -2.1868  Acc@1: 87.5000 (82.9362)  Acc@5: 93.7500 (96.5726)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 350/3750]  eta: 0:22:13  Lr: 0.030000  Loss: -2.6617  Acc@1: 87.5000 (82.9772)  Acc@5: 100.0000 (96.6346)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 360/3750]  eta: 0:22:09  Lr: 0.030000  Loss: -2.5085  Acc@1: 87.5000 (83.0852)  Acc@5: 100.0000 (96.6759)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 370/3750]  eta: 0:22:05  Lr: 0.030000  Loss: -2.4345  Acc@1: 87.5000 (83.2379)  Acc@5: 100.0000 (96.7487)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 380/3750]  eta: 0:22:01  Lr: 0.030000  Loss: -2.6542  Acc@1: 87.5000 (83.3005)  Acc@5: 100.0000 (96.7192)  time: 0.3911  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 390/3750]  eta: 0:21:57  Lr: 0.030000  Loss: -2.2653  Acc@1: 81.2500 (83.2801)  Acc@5: 93.7500 (96.7391)  time: 0.3910  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 400/3750]  eta: 0:21:53  Lr: 0.030000  Loss: -2.6628  Acc@1: 87.5000 (83.3697)  Acc@5: 100.0000 (96.7425)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 410/3750]  eta: 0:21:49  Lr: 0.030000  Loss: -2.2896  Acc@1: 87.5000 (83.3333)  Acc@5: 93.7500 (96.7153)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 420/3750]  eta: 0:21:45  Lr: 0.030000  Loss: -2.3487  Acc@1: 81.2500 (83.3581)  Acc@5: 100.0000 (96.7043)  time: 0.3887  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 430/3750]  eta: 0:21:41  Lr: 0.030000  Loss: -2.6488  Acc@1: 81.2500 (83.3382)  Acc@5: 100.0000 (96.7372)  time: 0.3893  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 440/3750]  eta: 0:21:36  Lr: 0.030000  Loss: -2.3933  Acc@1: 81.2500 (83.3192)  Acc@5: 100.0000 (96.7262)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 450/3750]  eta: 0:21:32  Lr: 0.030000  Loss: -2.1065  Acc@1: 81.2500 (83.2456)  Acc@5: 93.7500 (96.6741)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 460/3750]  eta: 0:21:28  Lr: 0.030000  Loss: -2.6088  Acc@1: 81.2500 (83.2294)  Acc@5: 93.7500 (96.6513)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 470/3750]  eta: 0:21:24  Lr: 0.030000  Loss: -2.6057  Acc@1: 81.2500 (83.2139)  Acc@5: 93.7500 (96.6693)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 480/3750]  eta: 0:21:20  Lr: 0.030000  Loss: -2.4022  Acc@1: 81.2500 (83.2640)  Acc@5: 100.0000 (96.6606)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 490/3750]  eta: 0:21:16  Lr: 0.030000  Loss: -2.4547  Acc@1: 81.2500 (83.1976)  Acc@5: 93.7500 (96.6395)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 500/3750]  eta: 0:21:12  Lr: 0.030000  Loss: -2.6914  Acc@1: 81.2500 (83.2086)  Acc@5: 100.0000 (96.6692)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 510/3750]  eta: 0:21:08  Lr: 0.030000  Loss: -2.2875  Acc@1: 87.5000 (83.2314)  Acc@5: 93.7500 (96.6487)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 520/3750]  eta: 0:21:04  Lr: 0.030000  Loss: -2.4103  Acc@1: 81.2500 (83.2054)  Acc@5: 93.7500 (96.6291)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 530/3750]  eta: 0:21:00  Lr: 0.030000  Loss: -2.4546  Acc@1: 75.0000 (83.0626)  Acc@5: 93.7500 (96.5866)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 540/3750]  eta: 0:20:56  Lr: 0.030000  Loss: -2.3597  Acc@1: 75.0000 (83.0176)  Acc@5: 93.7500 (96.5457)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 550/3750]  eta: 0:20:52  Lr: 0.030000  Loss: -2.6233  Acc@1: 81.2500 (82.9401)  Acc@5: 93.7500 (96.4950)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 560/3750]  eta: 0:20:48  Lr: 0.030000  Loss: -2.3994  Acc@1: 81.2500 (82.9100)  Acc@5: 93.7500 (96.4906)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 570/3750]  eta: 0:20:44  Lr: 0.030000  Loss: -2.6263  Acc@1: 81.2500 (82.9028)  Acc@5: 100.0000 (96.5302)  time: 0.3903  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 580/3750]  eta: 0:20:40  Lr: 0.030000  Loss: -2.3831  Acc@1: 81.2500 (82.8421)  Acc@5: 100.0000 (96.5039)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 590/3750]  eta: 0:20:36  Lr: 0.030000  Loss: -2.2648  Acc@1: 81.2500 (82.8892)  Acc@5: 100.0000 (96.5207)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 600/3750]  eta: 0:20:32  Lr: 0.030000  Loss: -1.9102  Acc@1: 81.2500 (82.8619)  Acc@5: 93.7500 (96.4954)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 610/3750]  eta: 0:20:28  Lr: 0.030000  Loss: -2.6282  Acc@1: 81.2500 (82.8662)  Acc@5: 100.0000 (96.5016)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 620/3750]  eta: 0:20:24  Lr: 0.030000  Loss: -2.2951  Acc@1: 81.2500 (82.9408)  Acc@5: 100.0000 (96.5177)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 630/3750]  eta: 0:20:21  Lr: 0.030000  Loss: -1.9554  Acc@1: 81.2500 (82.9041)  Acc@5: 100.0000 (96.5135)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 640/3750]  eta: 0:20:17  Lr: 0.030000  Loss: -2.3943  Acc@1: 81.2500 (82.9173)  Acc@5: 100.0000 (96.5289)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 650/3750]  eta: 0:20:13  Lr: 0.030000  Loss: -2.3297  Acc@1: 81.2500 (82.8341)  Acc@5: 100.0000 (96.5246)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 660/3750]  eta: 0:20:09  Lr: 0.030000  Loss: -2.4019  Acc@1: 81.2500 (82.9425)  Acc@5: 100.0000 (96.5488)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 670/3750]  eta: 0:20:05  Lr: 0.030000  Loss: -2.5027  Acc@1: 87.5000 (82.8987)  Acc@5: 100.0000 (96.5350)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 680/3750]  eta: 0:20:01  Lr: 0.030000  Loss: -2.8404  Acc@1: 81.2500 (82.8744)  Acc@5: 93.7500 (96.4941)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 690/3750]  eta: 0:19:57  Lr: 0.030000  Loss: -2.1616  Acc@1: 81.2500 (82.8148)  Acc@5: 93.7500 (96.4815)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 700/3750]  eta: 0:19:53  Lr: 0.030000  Loss: -2.7483  Acc@1: 87.5000 (82.8905)  Acc@5: 100.0000 (96.4961)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 710/3750]  eta: 0:19:49  Lr: 0.030000  Loss: -2.1044  Acc@1: 87.5000 (82.8674)  Acc@5: 100.0000 (96.5014)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 720/3750]  eta: 0:19:45  Lr: 0.030000  Loss: -2.3200  Acc@1: 81.2500 (82.8537)  Acc@5: 93.7500 (96.4979)  time: 0.3916  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 730/3750]  eta: 0:19:41  Lr: 0.030000  Loss: -2.4589  Acc@1: 81.2500 (82.8659)  Acc@5: 100.0000 (96.5287)  time: 0.3925  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [ 740/3750]  eta: 0:19:37  Lr: 0.030000  Loss: -2.0855  Acc@1: 81.2500 (82.9032)  Acc@5: 100.0000 (96.5587)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 750/3750]  eta: 0:19:33  Lr: 0.030000  Loss: -2.3432  Acc@1: 81.2500 (82.9144)  Acc@5: 100.0000 (96.5546)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 760/3750]  eta: 0:19:30  Lr: 0.030000  Loss: -2.1628  Acc@1: 81.2500 (82.9336)  Acc@5: 100.0000 (96.5342)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 770/3750]  eta: 0:19:26  Lr: 0.030000  Loss: -2.5832  Acc@1: 87.5000 (82.9037)  Acc@5: 93.7500 (96.5224)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 780/3750]  eta: 0:19:22  Lr: 0.030000  Loss: -2.6408  Acc@1: 87.5000 (82.9465)  Acc@5: 93.7500 (96.5349)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 790/3750]  eta: 0:19:18  Lr: 0.030000  Loss: -2.1477  Acc@1: 87.5000 (82.9093)  Acc@5: 93.7500 (96.5076)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 800/3750]  eta: 0:19:14  Lr: 0.030000  Loss: -2.5594  Acc@1: 87.5000 (82.9666)  Acc@5: 93.7500 (96.5122)  time: 0.3914  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 810/3750]  eta: 0:19:10  Lr: 0.030000  Loss: -2.7299  Acc@1: 87.5000 (83.0148)  Acc@5: 100.0000 (96.5244)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 820/3750]  eta: 0:19:06  Lr: 0.030000  Loss: -2.7637  Acc@1: 87.5000 (83.0390)  Acc@5: 100.0000 (96.5438)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 830/3750]  eta: 0:19:02  Lr: 0.030000  Loss: -2.1426  Acc@1: 87.5000 (83.0851)  Acc@5: 100.0000 (96.5554)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 840/3750]  eta: 0:18:58  Lr: 0.030000  Loss: -2.6044  Acc@1: 87.5000 (83.1228)  Acc@5: 100.0000 (96.5666)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 850/3750]  eta: 0:18:54  Lr: 0.030000  Loss: -2.2696  Acc@1: 87.5000 (83.1228)  Acc@5: 93.7500 (96.5335)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 860/3750]  eta: 0:18:50  Lr: 0.030000  Loss: -2.0808  Acc@1: 87.5000 (83.1228)  Acc@5: 93.7500 (96.5447)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 870/3750]  eta: 0:18:46  Lr: 0.030000  Loss: -2.4858  Acc@1: 87.5000 (83.1515)  Acc@5: 100.0000 (96.5629)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 880/3750]  eta: 0:18:42  Lr: 0.030000  Loss: -2.7117  Acc@1: 87.5000 (83.1583)  Acc@5: 100.0000 (96.5593)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 890/3750]  eta: 0:18:39  Lr: 0.030000  Loss: -2.5189  Acc@1: 87.5000 (83.1720)  Acc@5: 100.0000 (96.5699)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 900/3750]  eta: 0:18:35  Lr: 0.030000  Loss: -2.3505  Acc@1: 81.2500 (83.1368)  Acc@5: 100.0000 (96.5733)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 910/3750]  eta: 0:18:31  Lr: 0.030000  Loss: -2.1154  Acc@1: 81.2500 (83.1298)  Acc@5: 100.0000 (96.5697)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 920/3750]  eta: 0:18:27  Lr: 0.030000  Loss: -2.3875  Acc@1: 87.5000 (83.1773)  Acc@5: 100.0000 (96.6002)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 930/3750]  eta: 0:18:23  Lr: 0.030000  Loss: -2.4843  Acc@1: 81.2500 (83.1700)  Acc@5: 100.0000 (96.5830)  time: 0.3895  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 940/3750]  eta: 0:18:19  Lr: 0.030000  Loss: -2.5332  Acc@1: 81.2500 (83.1828)  Acc@5: 100.0000 (96.6126)  time: 0.3890  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 950/3750]  eta: 0:18:15  Lr: 0.030000  Loss: -2.4305  Acc@1: 81.2500 (83.1822)  Acc@5: 100.0000 (96.6154)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [ 960/3750]  eta: 0:18:11  Lr: 0.030000  Loss: -2.6434  Acc@1: 81.2500 (83.1686)  Acc@5: 100.0000 (96.6246)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 970/3750]  eta: 0:18:07  Lr: 0.030000  Loss: -2.7445  Acc@1: 81.2500 (83.1617)  Acc@5: 100.0000 (96.6272)  time: 0.3883  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 980/3750]  eta: 0:18:03  Lr: 0.030000  Loss: -2.5073  Acc@1: 87.5000 (83.1868)  Acc@5: 100.0000 (96.6361)  time: 0.3894  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [ 990/3750]  eta: 0:17:59  Lr: 0.030000  Loss: -2.6398  Acc@1: 81.2500 (83.1799)  Acc@5: 100.0000 (96.6574)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1000/3750]  eta: 0:17:55  Lr: 0.030000  Loss: -2.5705  Acc@1: 81.2500 (83.1419)  Acc@5: 100.0000 (96.6409)  time: 0.3894  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1010/3750]  eta: 0:17:51  Lr: 0.030000  Loss: -2.4581  Acc@1: 81.2500 (83.1231)  Acc@5: 93.7500 (96.6494)  time: 0.3889  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1020/3750]  eta: 0:17:47  Lr: 0.030000  Loss: -1.8440  Acc@1: 81.2500 (83.0987)  Acc@5: 93.7500 (96.6210)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1030/3750]  eta: 0:17:43  Lr: 0.030000  Loss: -2.2936  Acc@1: 87.5000 (83.1474)  Acc@5: 93.7500 (96.6174)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1040/3750]  eta: 0:17:39  Lr: 0.030000  Loss: -2.7117  Acc@1: 81.2500 (83.1352)  Acc@5: 93.7500 (96.6138)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1050/3750]  eta: 0:17:35  Lr: 0.030000  Loss: -2.2431  Acc@1: 81.2500 (83.0637)  Acc@5: 93.7500 (96.6163)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1060/3750]  eta: 0:17:31  Lr: 0.030000  Loss: -2.3967  Acc@1: 81.2500 (83.0643)  Acc@5: 100.0000 (96.6246)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1070/3750]  eta: 0:17:27  Lr: 0.030000  Loss: -2.6071  Acc@1: 81.2500 (83.0707)  Acc@5: 100.0000 (96.6095)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1080/3750]  eta: 0:17:24  Lr: 0.030000  Loss: -2.2904  Acc@1: 81.2500 (83.0076)  Acc@5: 100.0000 (96.6177)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1090/3750]  eta: 0:17:20  Lr: 0.030000  Loss: -2.3745  Acc@1: 75.0000 (82.9743)  Acc@5: 100.0000 (96.6143)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1100/3750]  eta: 0:17:16  Lr: 0.030000  Loss: -2.1979  Acc@1: 81.2500 (82.9757)  Acc@5: 100.0000 (96.6281)  time: 0.3892  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1110/3750]  eta: 0:17:12  Lr: 0.030000  Loss: -2.5500  Acc@1: 81.2500 (82.9770)  Acc@5: 100.0000 (96.6190)  time: 0.3887  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1120/3750]  eta: 0:17:08  Lr: 0.030000  Loss: -2.3557  Acc@1: 81.2500 (82.9672)  Acc@5: 100.0000 (96.6269)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1130/3750]  eta: 0:17:04  Lr: 0.030000  Loss: -1.9786  Acc@1: 81.2500 (82.9741)  Acc@5: 100.0000 (96.6291)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1140/3750]  eta: 0:17:00  Lr: 0.030000  Loss: -2.6676  Acc@1: 81.2500 (82.9864)  Acc@5: 93.7500 (96.6203)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1150/3750]  eta: 0:16:56  Lr: 0.030000  Loss: -1.7103  Acc@1: 75.0000 (82.9007)  Acc@5: 93.7500 (96.6008)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1160/3750]  eta: 0:16:52  Lr: 0.030000  Loss: -2.3406  Acc@1: 75.0000 (82.8919)  Acc@5: 100.0000 (96.6085)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1170/3750]  eta: 0:16:48  Lr: 0.030000  Loss: -2.2587  Acc@1: 81.2500 (82.8939)  Acc@5: 100.0000 (96.6161)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1180/3750]  eta: 0:16:44  Lr: 0.030000  Loss: -1.7273  Acc@1: 75.0000 (82.8429)  Acc@5: 93.7500 (96.5919)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1190/3750]  eta: 0:16:40  Lr: 0.030000  Loss: -2.9581  Acc@1: 75.0000 (82.7928)  Acc@5: 93.7500 (96.5838)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1200/3750]  eta: 0:16:36  Lr: 0.030000  Loss: -1.6563  Acc@1: 81.2500 (82.7748)  Acc@5: 100.0000 (96.5862)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1210/3750]  eta: 0:16:33  Lr: 0.030000  Loss: -2.3020  Acc@1: 81.2500 (82.7725)  Acc@5: 100.0000 (96.5782)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1220/3750]  eta: 0:16:29  Lr: 0.030000  Loss: -2.1872  Acc@1: 87.5000 (82.8112)  Acc@5: 93.7500 (96.5704)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1230/3750]  eta: 0:16:25  Lr: 0.030000  Loss: -2.9168  Acc@1: 87.5000 (82.8544)  Acc@5: 100.0000 (96.5831)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1240/3750]  eta: 0:16:21  Lr: 0.030000  Loss: -2.7485  Acc@1: 81.2500 (82.8566)  Acc@5: 100.0000 (96.6005)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1250/3750]  eta: 0:16:17  Lr: 0.030000  Loss: -2.5981  Acc@1: 81.2500 (82.8537)  Acc@5: 100.0000 (96.6227)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1260/3750]  eta: 0:16:13  Lr: 0.030000  Loss: -2.4631  Acc@1: 81.2500 (82.8360)  Acc@5: 100.0000 (96.6247)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1270/3750]  eta: 0:16:09  Lr: 0.030000  Loss: -2.3657  Acc@1: 81.2500 (82.8777)  Acc@5: 100.0000 (96.6316)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1280/3750]  eta: 0:16:05  Lr: 0.030000  Loss: -2.2645  Acc@1: 87.5000 (82.8649)  Acc@5: 100.0000 (96.6384)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1290/3750]  eta: 0:16:01  Lr: 0.030000  Loss: -1.6927  Acc@1: 75.0000 (82.8282)  Acc@5: 100.0000 (96.6208)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1300/3750]  eta: 0:15:57  Lr: 0.030000  Loss: -2.1770  Acc@1: 75.0000 (82.7825)  Acc@5: 93.7500 (96.6228)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1310/3750]  eta: 0:15:53  Lr: 0.030000  Loss: -2.5808  Acc@1: 81.2500 (82.7565)  Acc@5: 100.0000 (96.6199)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1320/3750]  eta: 0:15:50  Lr: 0.030000  Loss: -2.7050  Acc@1: 81.2500 (82.7498)  Acc@5: 100.0000 (96.6408)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1330/3750]  eta: 0:15:46  Lr: 0.030000  Loss: -2.7079  Acc@1: 81.2500 (82.7245)  Acc@5: 100.0000 (96.6379)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1340/3750]  eta: 0:15:42  Lr: 0.030000  Loss: -2.5644  Acc@1: 81.2500 (82.7274)  Acc@5: 100.0000 (96.6443)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1350/3750]  eta: 0:15:38  Lr: 0.030000  Loss: -2.9626  Acc@1: 81.2500 (82.7119)  Acc@5: 93.7500 (96.6368)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1360/3750]  eta: 0:15:34  Lr: 0.030000  Loss: -2.2654  Acc@1: 81.2500 (82.6965)  Acc@5: 93.7500 (96.6339)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1370/3750]  eta: 0:15:30  Lr: 0.030000  Loss: -2.3372  Acc@1: 81.2500 (82.6769)  Acc@5: 93.7500 (96.6129)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1380/3750]  eta: 0:15:26  Lr: 0.030000  Loss: -2.2130  Acc@1: 81.2500 (82.6665)  Acc@5: 93.7500 (96.6012)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1390/3750]  eta: 0:15:22  Lr: 0.030000  Loss: -2.5990  Acc@1: 81.2500 (82.6653)  Acc@5: 93.7500 (96.5852)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1400/3750]  eta: 0:15:18  Lr: 0.030000  Loss: -2.6168  Acc@1: 81.2500 (82.6285)  Acc@5: 93.7500 (96.5560)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1410/3750]  eta: 0:15:14  Lr: 0.030000  Loss: -2.0210  Acc@1: 75.0000 (82.6187)  Acc@5: 93.7500 (96.5539)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1420/3750]  eta: 0:15:10  Lr: 0.030000  Loss: -2.6849  Acc@1: 87.5000 (82.6575)  Acc@5: 100.0000 (96.5561)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1430/3750]  eta: 0:15:07  Lr: 0.030000  Loss: -2.2012  Acc@1: 87.5000 (82.6520)  Acc@5: 100.0000 (96.5584)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1440/3750]  eta: 0:15:03  Lr: 0.030000  Loss: -2.0627  Acc@1: 81.2500 (82.6553)  Acc@5: 100.0000 (96.5736)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1450/3750]  eta: 0:14:59  Lr: 0.030000  Loss: -2.2277  Acc@1: 81.2500 (82.6585)  Acc@5: 100.0000 (96.5799)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1460/3750]  eta: 0:14:55  Lr: 0.030000  Loss: -2.8093  Acc@1: 81.2500 (82.6531)  Acc@5: 100.0000 (96.5777)  time: 0.3893  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1470/3750]  eta: 0:14:51  Lr: 0.030000  Loss: -2.2349  Acc@1: 81.2500 (82.6564)  Acc@5: 100.0000 (96.5755)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1480/3750]  eta: 0:14:47  Lr: 0.030000  Loss: -2.6864  Acc@1: 81.2500 (82.6342)  Acc@5: 100.0000 (96.5775)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1490/3750]  eta: 0:14:43  Lr: 0.030000  Loss: -2.4015  Acc@1: 81.2500 (82.6081)  Acc@5: 93.7500 (96.5711)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1500/3750]  eta: 0:14:39  Lr: 0.030000  Loss: -2.5116  Acc@1: 81.2500 (82.6199)  Acc@5: 100.0000 (96.5856)  time: 0.3898  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1510/3750]  eta: 0:14:35  Lr: 0.030000  Loss: -1.9584  Acc@1: 87.5000 (82.6357)  Acc@5: 100.0000 (96.5834)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1520/3750]  eta: 0:14:31  Lr: 0.030000  Loss: -2.2192  Acc@1: 87.5000 (82.6759)  Acc@5: 100.0000 (96.5935)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1530/3750]  eta: 0:14:27  Lr: 0.030000  Loss: -2.7910  Acc@1: 87.5000 (82.7237)  Acc@5: 100.0000 (96.6035)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1540/3750]  eta: 0:14:23  Lr: 0.030000  Loss: -2.6282  Acc@1: 87.5000 (82.7628)  Acc@5: 100.0000 (96.6053)  time: 0.3889  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1550/3750]  eta: 0:14:19  Lr: 0.030000  Loss: -2.4439  Acc@1: 87.5000 (82.7772)  Acc@5: 100.0000 (96.5990)  time: 0.3886  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1560/3750]  eta: 0:14:16  Lr: 0.030000  Loss: -2.8359  Acc@1: 87.5000 (82.7835)  Acc@5: 93.7500 (96.6007)  time: 0.3893  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1570/3750]  eta: 0:14:12  Lr: 0.030000  Loss: -2.6664  Acc@1: 87.5000 (82.7976)  Acc@5: 100.0000 (96.6104)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1580/3750]  eta: 0:14:08  Lr: 0.030000  Loss: -2.7155  Acc@1: 87.5000 (82.8155)  Acc@5: 93.7500 (96.6003)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1590/3750]  eta: 0:14:04  Lr: 0.030000  Loss: -2.5344  Acc@1: 87.5000 (82.8174)  Acc@5: 93.7500 (96.5981)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1600/3750]  eta: 0:14:00  Lr: 0.030000  Loss: -2.7128  Acc@1: 81.2500 (82.8115)  Acc@5: 93.7500 (96.5998)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1610/3750]  eta: 0:13:56  Lr: 0.030000  Loss: -2.4258  Acc@1: 81.2500 (82.7980)  Acc@5: 93.7500 (96.5937)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1620/3750]  eta: 0:13:52  Lr: 0.030000  Loss: -2.6139  Acc@1: 81.2500 (82.7845)  Acc@5: 100.0000 (96.5993)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1630/3750]  eta: 0:13:48  Lr: 0.030000  Loss: -2.6949  Acc@1: 81.2500 (82.8020)  Acc@5: 100.0000 (96.6048)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1640/3750]  eta: 0:13:44  Lr: 0.030000  Loss: -2.7944  Acc@1: 87.5000 (82.8306)  Acc@5: 100.0000 (96.6179)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1650/3750]  eta: 0:13:40  Lr: 0.030000  Loss: -2.3813  Acc@1: 87.5000 (82.8627)  Acc@5: 100.0000 (96.6308)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1660/3750]  eta: 0:13:36  Lr: 0.030000  Loss: -2.5699  Acc@1: 87.5000 (82.8755)  Acc@5: 100.0000 (96.6398)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1670/3750]  eta: 0:13:32  Lr: 0.030000  Loss: -2.3134  Acc@1: 81.2500 (82.8621)  Acc@5: 100.0000 (96.6525)  time: 0.3895  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1680/3750]  eta: 0:13:29  Lr: 0.030000  Loss: -2.5186  Acc@1: 81.2500 (82.8488)  Acc@5: 100.0000 (96.6575)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1690/3750]  eta: 0:13:25  Lr: 0.030000  Loss: -2.5057  Acc@1: 81.2500 (82.8208)  Acc@5: 100.0000 (96.6514)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1700/3750]  eta: 0:13:21  Lr: 0.030000  Loss: -2.4520  Acc@1: 81.2500 (82.8079)  Acc@5: 93.7500 (96.6417)  time: 0.3909  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1710/3750]  eta: 0:13:17  Lr: 0.030000  Loss: -2.2912  Acc@1: 81.2500 (82.8280)  Acc@5: 93.7500 (96.6284)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1720/3750]  eta: 0:13:13  Lr: 0.030000  Loss: -2.4734  Acc@1: 87.5000 (82.8370)  Acc@5: 93.7500 (96.6153)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1730/3750]  eta: 0:13:09  Lr: 0.030000  Loss: -2.9380  Acc@1: 81.2500 (82.8351)  Acc@5: 100.0000 (96.6205)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1740/3750]  eta: 0:13:05  Lr: 0.030000  Loss: -2.6028  Acc@1: 81.2500 (82.8655)  Acc@5: 100.0000 (96.6255)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1750/3750]  eta: 0:13:01  Lr: 0.030000  Loss: -2.4381  Acc@1: 93.7500 (82.8955)  Acc@5: 100.0000 (96.6341)  time: 0.3911  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1760/3750]  eta: 0:12:57  Lr: 0.030000  Loss: -2.7497  Acc@1: 87.5000 (82.8861)  Acc@5: 100.0000 (96.6390)  time: 0.3920  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1770/3750]  eta: 0:12:53  Lr: 0.030000  Loss: -2.4958  Acc@1: 81.2500 (82.8981)  Acc@5: 100.0000 (96.6403)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1780/3750]  eta: 0:12:49  Lr: 0.030000  Loss: -2.2555  Acc@1: 81.2500 (82.8994)  Acc@5: 100.0000 (96.6416)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1790/3750]  eta: 0:12:46  Lr: 0.030000  Loss: -2.5542  Acc@1: 81.2500 (82.9041)  Acc@5: 100.0000 (96.6464)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1800/3750]  eta: 0:12:42  Lr: 0.030000  Loss: -2.8182  Acc@1: 81.2500 (82.9019)  Acc@5: 100.0000 (96.6512)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1810/3750]  eta: 0:12:38  Lr: 0.030000  Loss: -2.3671  Acc@1: 81.2500 (82.8927)  Acc@5: 100.0000 (96.6524)  time: 0.3922  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1820/3750]  eta: 0:12:34  Lr: 0.030000  Loss: -2.0613  Acc@1: 81.2500 (82.8871)  Acc@5: 93.7500 (96.6399)  time: 0.3912  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1830/3750]  eta: 0:12:30  Lr: 0.030000  Loss: -2.1447  Acc@1: 81.2500 (82.8714)  Acc@5: 93.7500 (96.6378)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1840/3750]  eta: 0:12:26  Lr: 0.030000  Loss: -2.4331  Acc@1: 81.2500 (82.8694)  Acc@5: 93.7500 (96.6357)  time: 0.3915  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1850/3750]  eta: 0:12:22  Lr: 0.030000  Loss: -2.5064  Acc@1: 81.2500 (82.8572)  Acc@5: 100.0000 (96.6403)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1860/3750]  eta: 0:12:18  Lr: 0.030000  Loss: -2.5152  Acc@1: 81.2500 (82.8755)  Acc@5: 100.0000 (96.6517)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1870/3750]  eta: 0:12:14  Lr: 0.030000  Loss: -2.4505  Acc@1: 81.2500 (82.8768)  Acc@5: 100.0000 (96.6562)  time: 0.3935  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1880/3750]  eta: 0:12:10  Lr: 0.030000  Loss: -2.7811  Acc@1: 81.2500 (82.8648)  Acc@5: 93.7500 (96.6474)  time: 0.3933  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1890/3750]  eta: 0:12:07  Lr: 0.030000  Loss: -2.7264  Acc@1: 81.2500 (82.8695)  Acc@5: 100.0000 (96.6519)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1900/3750]  eta: 0:12:03  Lr: 0.030000  Loss: -2.5754  Acc@1: 81.2500 (82.8741)  Acc@5: 100.0000 (96.6432)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1910/3750]  eta: 0:11:59  Lr: 0.030000  Loss: -2.3735  Acc@1: 81.2500 (82.8656)  Acc@5: 93.7500 (96.6379)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1920/3750]  eta: 0:11:55  Lr: 0.030000  Loss: -1.7028  Acc@1: 81.2500 (82.8540)  Acc@5: 93.7500 (96.6261)  time: 0.3924  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [1930/3750]  eta: 0:11:51  Lr: 0.030000  Loss: -2.3477  Acc@1: 81.2500 (82.8392)  Acc@5: 93.7500 (96.6112)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1940/3750]  eta: 0:11:47  Lr: 0.030000  Loss: -2.7427  Acc@1: 81.2500 (82.8310)  Acc@5: 93.7500 (96.6126)  time: 0.3910  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [1950/3750]  eta: 0:11:43  Lr: 0.030000  Loss: -2.5720  Acc@1: 81.2500 (82.8197)  Acc@5: 100.0000 (96.6107)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1960/3750]  eta: 0:11:39  Lr: 0.030000  Loss: -2.7488  Acc@1: 81.2500 (82.8245)  Acc@5: 100.0000 (96.6184)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1970/3750]  eta: 0:11:35  Lr: 0.030000  Loss: -2.1387  Acc@1: 87.5000 (82.8418)  Acc@5: 100.0000 (96.6229)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1980/3750]  eta: 0:11:31  Lr: 0.030000  Loss: -2.3671  Acc@1: 87.5000 (82.8306)  Acc@5: 100.0000 (96.6305)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [1990/3750]  eta: 0:11:28  Lr: 0.030000  Loss: -2.5718  Acc@1: 81.2500 (82.8133)  Acc@5: 93.7500 (96.6223)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2000/3750]  eta: 0:11:24  Lr: 0.030000  Loss: -2.9288  Acc@1: 81.2500 (82.8086)  Acc@5: 93.7500 (96.6204)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2010/3750]  eta: 0:11:20  Lr: 0.030000  Loss: -2.7841  Acc@1: 87.5000 (82.7977)  Acc@5: 100.0000 (96.6155)  time: 0.3918  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [2020/3750]  eta: 0:11:16  Lr: 0.030000  Loss: -1.5571  Acc@1: 87.5000 (82.7963)  Acc@5: 100.0000 (96.6106)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2030/3750]  eta: 0:11:12  Lr: 0.030000  Loss: -1.9361  Acc@1: 81.2500 (82.7763)  Acc@5: 100.0000 (96.6119)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2040/3750]  eta: 0:11:08  Lr: 0.030000  Loss: -2.0602  Acc@1: 81.2500 (82.7597)  Acc@5: 100.0000 (96.6132)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2050/3750]  eta: 0:11:04  Lr: 0.030000  Loss: -2.5223  Acc@1: 81.2500 (82.7432)  Acc@5: 93.7500 (96.6084)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2060/3750]  eta: 0:11:00  Lr: 0.030000  Loss: -2.3923  Acc@1: 81.2500 (82.7420)  Acc@5: 93.7500 (96.6036)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2070/3750]  eta: 0:10:56  Lr: 0.030000  Loss: -2.2519  Acc@1: 81.2500 (82.7227)  Acc@5: 93.7500 (96.5958)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2080/3750]  eta: 0:10:52  Lr: 0.030000  Loss: -2.8420  Acc@1: 81.2500 (82.7096)  Acc@5: 93.7500 (96.5972)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2090/3750]  eta: 0:10:48  Lr: 0.030000  Loss: -2.1944  Acc@1: 81.2500 (82.6997)  Acc@5: 100.0000 (96.6045)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2100/3750]  eta: 0:10:44  Lr: 0.030000  Loss: -2.5055  Acc@1: 81.2500 (82.6898)  Acc@5: 100.0000 (96.6117)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2110/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -2.6147  Acc@1: 81.2500 (82.7096)  Acc@5: 100.0000 (96.6100)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2120/3750]  eta: 0:10:37  Lr: 0.030000  Loss: -2.2534  Acc@1: 81.2500 (82.6968)  Acc@5: 93.7500 (96.6054)  time: 0.3894  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2130/3750]  eta: 0:10:33  Lr: 0.030000  Loss: -2.3667  Acc@1: 81.2500 (82.7047)  Acc@5: 100.0000 (96.6066)  time: 0.3883  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2140/3750]  eta: 0:10:29  Lr: 0.030000  Loss: -2.5835  Acc@1: 87.5000 (82.7154)  Acc@5: 100.0000 (96.6050)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2150/3750]  eta: 0:10:25  Lr: 0.030000  Loss: -2.0531  Acc@1: 87.5000 (82.7173)  Acc@5: 100.0000 (96.6091)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2160/3750]  eta: 0:10:21  Lr: 0.030000  Loss: -2.5961  Acc@1: 81.2500 (82.7250)  Acc@5: 100.0000 (96.6161)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2170/3750]  eta: 0:10:17  Lr: 0.030000  Loss: -2.5573  Acc@1: 81.2500 (82.7125)  Acc@5: 100.0000 (96.6087)  time: 0.3897  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2180/3750]  eta: 0:10:13  Lr: 0.030000  Loss: -2.1437  Acc@1: 75.0000 (82.6943)  Acc@5: 93.7500 (96.6071)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2190/3750]  eta: 0:10:09  Lr: 0.030000  Loss: -2.3294  Acc@1: 75.0000 (82.6906)  Acc@5: 93.7500 (96.6083)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2200/3750]  eta: 0:10:05  Lr: 0.030000  Loss: -2.5328  Acc@1: 81.2500 (82.6755)  Acc@5: 93.7500 (96.6010)  time: 0.3898  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2210/3750]  eta: 0:10:01  Lr: 0.030000  Loss: -2.3250  Acc@1: 81.2500 (82.6634)  Acc@5: 93.7500 (96.5966)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2220/3750]  eta: 0:09:58  Lr: 0.030000  Loss: -2.8027  Acc@1: 81.2500 (82.6711)  Acc@5: 100.0000 (96.5978)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2230/3750]  eta: 0:09:54  Lr: 0.030000  Loss: -2.6178  Acc@1: 87.5000 (82.6927)  Acc@5: 100.0000 (96.6047)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2240/3750]  eta: 0:09:50  Lr: 0.030000  Loss: -2.6908  Acc@1: 87.5000 (82.7002)  Acc@5: 100.0000 (96.6059)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2250/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -2.0435  Acc@1: 87.5000 (82.7105)  Acc@5: 100.0000 (96.6126)  time: 0.3892  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2260/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -2.2540  Acc@1: 81.2500 (82.7123)  Acc@5: 100.0000 (96.6165)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2270/3750]  eta: 0:09:38  Lr: 0.030000  Loss: -2.8790  Acc@1: 87.5000 (82.7361)  Acc@5: 100.0000 (96.6232)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2280/3750]  eta: 0:09:34  Lr: 0.030000  Loss: -2.4548  Acc@1: 87.5000 (82.7515)  Acc@5: 100.0000 (96.6298)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2290/3750]  eta: 0:09:30  Lr: 0.030000  Loss: -2.6213  Acc@1: 87.5000 (82.7750)  Acc@5: 100.0000 (96.6281)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2300/3750]  eta: 0:09:26  Lr: 0.030000  Loss: -2.2539  Acc@1: 87.5000 (82.7765)  Acc@5: 93.7500 (96.6292)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2310/3750]  eta: 0:09:22  Lr: 0.030000  Loss: -1.4693  Acc@1: 87.5000 (82.7861)  Acc@5: 100.0000 (96.6357)  time: 0.3924  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2320/3750]  eta: 0:09:18  Lr: 0.030000  Loss: -2.6038  Acc@1: 87.5000 (82.7876)  Acc@5: 100.0000 (96.6367)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2330/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -2.1571  Acc@1: 81.2500 (82.7810)  Acc@5: 93.7500 (96.6323)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2340/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -2.6260  Acc@1: 87.5000 (82.7931)  Acc@5: 93.7500 (96.6254)  time: 0.3907  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2350/3750]  eta: 0:09:07  Lr: 0.030000  Loss: -2.3808  Acc@1: 81.2500 (82.7892)  Acc@5: 93.7500 (96.6264)  time: 0.3920  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [2360/3750]  eta: 0:09:03  Lr: 0.030000  Loss: -2.7846  Acc@1: 87.5000 (82.8224)  Acc@5: 100.0000 (96.6328)  time: 0.3939  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:59  Lr: 0.030000  Loss: -2.8814  Acc@1: 93.7500 (82.8132)  Acc@5: 100.0000 (96.6259)  time: 0.3929  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2380/3750]  eta: 0:08:55  Lr: 0.030000  Loss: -2.7497  Acc@1: 75.0000 (82.8092)  Acc@5: 93.7500 (96.6296)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2390/3750]  eta: 0:08:51  Lr: 0.030000  Loss: -2.0846  Acc@1: 75.0000 (82.8027)  Acc@5: 100.0000 (96.6358)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2400/3750]  eta: 0:08:47  Lr: 0.030000  Loss: -1.8402  Acc@1: 81.2500 (82.7910)  Acc@5: 100.0000 (96.6394)  time: 0.3902  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2410/3750]  eta: 0:08:43  Lr: 0.030000  Loss: -2.2545  Acc@1: 75.0000 (82.7769)  Acc@5: 93.7500 (96.6300)  time: 0.3904  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2420/3750]  eta: 0:08:39  Lr: 0.030000  Loss: -2.5320  Acc@1: 81.2500 (82.7757)  Acc@5: 93.7500 (96.6233)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2430/3750]  eta: 0:08:35  Lr: 0.030000  Loss: -2.0765  Acc@1: 81.2500 (82.7643)  Acc@5: 93.7500 (96.6192)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2440/3750]  eta: 0:08:32  Lr: 0.030000  Loss: -2.2216  Acc@1: 81.2500 (82.7607)  Acc@5: 93.7500 (96.6126)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2450/3750]  eta: 0:08:28  Lr: 0.030000  Loss: -2.5735  Acc@1: 81.2500 (82.7596)  Acc@5: 93.7500 (96.6111)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2460/3750]  eta: 0:08:24  Lr: 0.030000  Loss: -2.4058  Acc@1: 81.2500 (82.7662)  Acc@5: 100.0000 (96.6147)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2470/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -2.5137  Acc@1: 81.2500 (82.7600)  Acc@5: 100.0000 (96.6157)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2480/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -2.2392  Acc@1: 81.2500 (82.7716)  Acc@5: 100.0000 (96.6092)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2490/3750]  eta: 0:08:12  Lr: 0.030000  Loss: -1.7284  Acc@1: 87.5000 (82.7705)  Acc@5: 100.0000 (96.6128)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2500/3750]  eta: 0:08:08  Lr: 0.030000  Loss: -2.3668  Acc@1: 81.2500 (82.7769)  Acc@5: 100.0000 (96.6164)  time: 0.3914  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2510/3750]  eta: 0:08:04  Lr: 0.030000  Loss: -2.7038  Acc@1: 87.5000 (82.7833)  Acc@5: 100.0000 (96.6099)  time: 0.3917  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2520/3750]  eta: 0:08:00  Lr: 0.030000  Loss: -2.5127  Acc@1: 87.5000 (82.8020)  Acc@5: 100.0000 (96.6159)  time: 0.3913  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:56  Lr: 0.030000  Loss: -2.8367  Acc@1: 81.2500 (82.7860)  Acc@5: 100.0000 (96.6046)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:52  Lr: 0.030000  Loss: -2.2727  Acc@1: 81.2500 (82.7799)  Acc@5: 93.7500 (96.6032)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2550/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -2.4068  Acc@1: 81.2500 (82.7788)  Acc@5: 100.0000 (96.6018)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2560/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -2.6600  Acc@1: 81.2500 (82.7753)  Acc@5: 100.0000 (96.6029)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2570/3750]  eta: 0:07:41  Lr: 0.030000  Loss: -2.3409  Acc@1: 81.2500 (82.7888)  Acc@5: 100.0000 (96.6088)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2580/3750]  eta: 0:07:37  Lr: 0.030000  Loss: -1.9511  Acc@1: 81.2500 (82.7877)  Acc@5: 100.0000 (96.6123)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2590/3750]  eta: 0:07:33  Lr: 0.030000  Loss: -2.5495  Acc@1: 81.2500 (82.7962)  Acc@5: 100.0000 (96.6157)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2600/3750]  eta: 0:07:29  Lr: 0.030000  Loss: -2.0795  Acc@1: 81.2500 (82.7783)  Acc@5: 100.0000 (96.6095)  time: 0.3917  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2610/3750]  eta: 0:07:25  Lr: 0.030000  Loss: -2.7044  Acc@1: 75.0000 (82.7676)  Acc@5: 93.7500 (96.6105)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2620/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -2.6374  Acc@1: 81.2500 (82.7642)  Acc@5: 93.7500 (96.6043)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2630/3750]  eta: 0:07:17  Lr: 0.030000  Loss: -2.4061  Acc@1: 81.2500 (82.7775)  Acc@5: 100.0000 (96.6101)  time: 0.3895  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2640/3750]  eta: 0:07:13  Lr: 0.030000  Loss: -2.3925  Acc@1: 87.5000 (82.7882)  Acc@5: 100.0000 (96.6064)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2650/3750]  eta: 0:07:09  Lr: 0.030000  Loss: -2.5055  Acc@1: 81.2500 (82.7801)  Acc@5: 93.7500 (96.6027)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2660/3750]  eta: 0:07:06  Lr: 0.030000  Loss: -2.1351  Acc@1: 81.2500 (82.7861)  Acc@5: 100.0000 (96.6084)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2670/3750]  eta: 0:07:02  Lr: 0.030000  Loss: -2.2194  Acc@1: 81.2500 (82.7756)  Acc@5: 100.0000 (96.6047)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:58  Lr: 0.030000  Loss: -2.0348  Acc@1: 81.2500 (82.7630)  Acc@5: 93.7500 (96.5988)  time: 0.3907  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:54  Lr: 0.030000  Loss: -2.6540  Acc@1: 87.5000 (82.7759)  Acc@5: 93.7500 (96.5998)  time: 0.3896  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -2.4949  Acc@1: 87.5000 (82.7888)  Acc@5: 100.0000 (96.6031)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -2.5409  Acc@1: 87.5000 (82.8131)  Acc@5: 100.0000 (96.6110)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2720/3750]  eta: 0:06:42  Lr: 0.030000  Loss: -2.4827  Acc@1: 87.5000 (82.8165)  Acc@5: 100.0000 (96.6097)  time: 0.3911  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [2730/3750]  eta: 0:06:38  Lr: 0.030000  Loss: -2.5961  Acc@1: 81.2500 (82.8268)  Acc@5: 93.7500 (96.6107)  time: 0.3908  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [2740/3750]  eta: 0:06:34  Lr: 0.030000  Loss: -2.9459  Acc@1: 87.5000 (82.8461)  Acc@5: 100.0000 (96.6116)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2750/3750]  eta: 0:06:30  Lr: 0.030000  Loss: -2.4415  Acc@1: 81.2500 (82.8312)  Acc@5: 100.0000 (96.6149)  time: 0.3909  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [2760/3750]  eta: 0:06:26  Lr: 0.030000  Loss: -2.5243  Acc@1: 81.2500 (82.8482)  Acc@5: 100.0000 (96.6090)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2770/3750]  eta: 0:06:23  Lr: 0.030000  Loss: -2.9632  Acc@1: 87.5000 (82.8717)  Acc@5: 100.0000 (96.6145)  time: 0.3895  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2780/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -2.3790  Acc@1: 87.5000 (82.8771)  Acc@5: 100.0000 (96.6177)  time: 0.3895  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2790/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -2.3982  Acc@1: 87.5000 (82.8825)  Acc@5: 100.0000 (96.6141)  time: 0.3893  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2800/3750]  eta: 0:06:11  Lr: 0.030000  Loss: -2.3566  Acc@1: 87.5000 (82.8878)  Acc@5: 93.7500 (96.6039)  time: 0.3889  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2810/3750]  eta: 0:06:07  Lr: 0.030000  Loss: -2.6834  Acc@1: 87.5000 (82.9064)  Acc@5: 100.0000 (96.6115)  time: 0.3897  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2820/3750]  eta: 0:06:03  Lr: 0.030000  Loss: -2.7216  Acc@1: 87.5000 (82.9116)  Acc@5: 100.0000 (96.6125)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:59  Lr: 0.030000  Loss: -2.4557  Acc@1: 81.2500 (82.9168)  Acc@5: 100.0000 (96.6178)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:55  Lr: 0.030000  Loss: -2.2770  Acc@1: 81.2500 (82.9065)  Acc@5: 100.0000 (96.6209)  time: 0.3894  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:51  Lr: 0.030000  Loss: -2.7190  Acc@1: 81.2500 (82.9117)  Acc@5: 100.0000 (96.6174)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:47  Lr: 0.030000  Loss: -2.8079  Acc@1: 87.5000 (82.9146)  Acc@5: 93.7500 (96.6161)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:43  Lr: 0.030000  Loss: -2.9680  Acc@1: 81.2500 (82.8892)  Acc@5: 93.7500 (96.6083)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:40  Lr: 0.030000  Loss: -2.7550  Acc@1: 81.2500 (82.9052)  Acc@5: 100.0000 (96.6158)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:36  Lr: 0.030000  Loss: -2.7924  Acc@1: 81.2500 (82.8952)  Acc@5: 100.0000 (96.6188)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2900/3750]  eta: 0:05:32  Lr: 0.030000  Loss: -2.7196  Acc@1: 81.2500 (82.9024)  Acc@5: 100.0000 (96.6197)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2910/3750]  eta: 0:05:28  Lr: 0.030000  Loss: -2.5047  Acc@1: 87.5000 (82.8968)  Acc@5: 93.7500 (96.6120)  time: 0.3913  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2920/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -2.4667  Acc@1: 81.2500 (82.8933)  Acc@5: 93.7500 (96.6065)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2930/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -1.9662  Acc@1: 81.2500 (82.8834)  Acc@5: 93.7500 (96.6031)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2940/3750]  eta: 0:05:16  Lr: 0.030000  Loss: -2.4684  Acc@1: 81.2500 (82.8778)  Acc@5: 93.7500 (96.6019)  time: 0.3914  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [2950/3750]  eta: 0:05:12  Lr: 0.030000  Loss: -2.6719  Acc@1: 81.2500 (82.8744)  Acc@5: 100.0000 (96.6050)  time: 0.3924  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [2960/3750]  eta: 0:05:08  Lr: 0.030000  Loss: -2.7684  Acc@1: 81.2500 (82.8690)  Acc@5: 100.0000 (96.6059)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2970/3750]  eta: 0:05:04  Lr: 0.030000  Loss: -2.6927  Acc@1: 87.5000 (82.8909)  Acc@5: 100.0000 (96.6089)  time: 0.3916  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2980/3750]  eta: 0:05:00  Lr: 0.030000  Loss: -3.0081  Acc@1: 87.5000 (82.9063)  Acc@5: 100.0000 (96.6161)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:57  Lr: 0.030000  Loss: -2.3426  Acc@1: 87.5000 (82.9154)  Acc@5: 100.0000 (96.6169)  time: 0.3919  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -2.6804  Acc@1: 87.5000 (82.9203)  Acc@5: 100.0000 (96.6261)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -2.5169  Acc@1: 81.2500 (82.9230)  Acc@5: 100.0000 (96.6228)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:45  Lr: 0.030000  Loss: -2.8767  Acc@1: 81.2500 (82.9216)  Acc@5: 100.0000 (96.6236)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:41  Lr: 0.030000  Loss: -2.7355  Acc@1: 81.2500 (82.9058)  Acc@5: 100.0000 (96.6142)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:37  Lr: 0.030000  Loss: -2.2507  Acc@1: 81.2500 (82.8983)  Acc@5: 93.7500 (96.6109)  time: 0.3903  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:33  Lr: 0.030000  Loss: -2.6363  Acc@1: 81.2500 (82.9052)  Acc@5: 100.0000 (96.6138)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:29  Lr: 0.030000  Loss: -2.9677  Acc@1: 87.5000 (82.9202)  Acc@5: 100.0000 (96.6147)  time: 0.3917  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3070/3750]  eta: 0:04:25  Lr: 0.030000  Loss: -2.6235  Acc@1: 81.2500 (82.9168)  Acc@5: 93.7500 (96.6074)  time: 0.3935  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3080/3750]  eta: 0:04:21  Lr: 0.030000  Loss: -2.9927  Acc@1: 81.2500 (82.9296)  Acc@5: 93.7500 (96.6042)  time: 0.3925  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3090/3750]  eta: 0:04:17  Lr: 0.030000  Loss: -2.7601  Acc@1: 87.5000 (82.9343)  Acc@5: 100.0000 (96.6051)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -2.4434  Acc@1: 81.2500 (82.9410)  Acc@5: 100.0000 (96.6100)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3110/3750]  eta: 0:04:10  Lr: 0.030000  Loss: -2.4565  Acc@1: 87.5000 (82.9536)  Acc@5: 100.0000 (96.6128)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3120/3750]  eta: 0:04:06  Lr: 0.030000  Loss: -2.5568  Acc@1: 81.2500 (82.9482)  Acc@5: 93.7500 (96.6097)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3130/3750]  eta: 0:04:02  Lr: 0.030000  Loss: -2.2925  Acc@1: 81.2500 (82.9308)  Acc@5: 93.7500 (96.6045)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:58  Lr: 0.030000  Loss: -2.8678  Acc@1: 87.5000 (82.9493)  Acc@5: 100.0000 (96.6054)  time: 0.3909  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -2.6992  Acc@1: 87.5000 (82.9598)  Acc@5: 100.0000 (96.6062)  time: 0.3902  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:50  Lr: 0.030000  Loss: -2.0605  Acc@1: 81.2500 (82.9484)  Acc@5: 93.7500 (96.6051)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:46  Lr: 0.030000  Loss: -2.3315  Acc@1: 81.2500 (82.9391)  Acc@5: 100.0000 (96.6119)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:42  Lr: 0.030000  Loss: -1.8275  Acc@1: 81.2500 (82.9378)  Acc@5: 100.0000 (96.6068)  time: 0.3909  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:38  Lr: 0.030000  Loss: -2.4289  Acc@1: 81.2500 (82.9364)  Acc@5: 100.0000 (96.6096)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:34  Lr: 0.030000  Loss: -2.2358  Acc@1: 81.2500 (82.9409)  Acc@5: 100.0000 (96.6143)  time: 0.3909  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -2.6602  Acc@1: 81.2500 (82.9376)  Acc@5: 100.0000 (96.6132)  time: 0.3914  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -1.7440  Acc@1: 87.5000 (82.9381)  Acc@5: 100.0000 (96.6121)  time: 0.3911  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -2.6277  Acc@1: 87.5000 (82.9484)  Acc@5: 100.0000 (96.6110)  time: 0.3919  data: 0.0010  max mem: 2908
Train: Epoch[5/5]  [3240/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -1.8110  Acc@1: 87.5000 (82.9605)  Acc@5: 93.7500 (96.6098)  time: 0.3913  data: 0.0011  max mem: 2908
Train: Epoch[5/5]  [3250/3750]  eta: 0:03:15  Lr: 0.030000  Loss: -2.9246  Acc@1: 87.5000 (82.9725)  Acc@5: 100.0000 (96.6107)  time: 0.3906  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3260/3750]  eta: 0:03:11  Lr: 0.030000  Loss: -2.5243  Acc@1: 87.5000 (82.9711)  Acc@5: 100.0000 (96.6115)  time: 0.3918  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3270/3750]  eta: 0:03:07  Lr: 0.030000  Loss: -1.9354  Acc@1: 81.2500 (82.9697)  Acc@5: 93.7500 (96.6046)  time: 0.3932  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3280/3750]  eta: 0:03:03  Lr: 0.030000  Loss: -2.2710  Acc@1: 81.2500 (82.9644)  Acc@5: 93.7500 (96.6074)  time: 0.3931  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -2.2992  Acc@1: 81.2500 (82.9554)  Acc@5: 100.0000 (96.6063)  time: 0.3918  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -2.3902  Acc@1: 81.2500 (82.9635)  Acc@5: 93.7500 (96.6033)  time: 0.3920  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:51  Lr: 0.030000  Loss: -1.8055  Acc@1: 81.2500 (82.9508)  Acc@5: 93.7500 (96.5966)  time: 0.3922  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -2.4352  Acc@1: 87.5000 (82.9682)  Acc@5: 100.0000 (96.6049)  time: 0.3915  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -2.1869  Acc@1: 87.5000 (82.9612)  Acc@5: 100.0000 (96.6095)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -2.4065  Acc@1: 81.2500 (82.9598)  Acc@5: 100.0000 (96.6122)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -2.3799  Acc@1: 81.2500 (82.9659)  Acc@5: 100.0000 (96.6204)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:32  Lr: 0.030000  Loss: -2.0368  Acc@1: 81.2500 (82.9571)  Acc@5: 100.0000 (96.6175)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -2.2225  Acc@1: 81.2500 (82.9520)  Acc@5: 93.7500 (96.6127)  time: 0.3908  data: 0.0005  max mem: 2908
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -2.5171  Acc@1: 81.2500 (82.9433)  Acc@5: 93.7500 (96.6116)  time: 0.3900  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:20  Lr: 0.030000  Loss: -2.7318  Acc@1: 81.2500 (82.9475)  Acc@5: 100.0000 (96.6142)  time: 0.3898  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:16  Lr: 0.030000  Loss: -2.6222  Acc@1: 87.5000 (82.9499)  Acc@5: 100.0000 (96.6131)  time: 0.3910  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3410/3750]  eta: 0:02:12  Lr: 0.030000  Loss: -2.5309  Acc@1: 81.2500 (82.9449)  Acc@5: 100.0000 (96.6176)  time: 0.3902  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3420/3750]  eta: 0:02:08  Lr: 0.030000  Loss: -2.5690  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (96.6238)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -2.3599  Acc@1: 87.5000 (82.9696)  Acc@5: 100.0000 (96.6245)  time: 0.3905  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -2.9797  Acc@1: 87.5000 (82.9737)  Acc@5: 100.0000 (96.6325)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -1.9191  Acc@1: 87.5000 (82.9759)  Acc@5: 100.0000 (96.6260)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -2.5097  Acc@1: 81.2500 (82.9764)  Acc@5: 93.7500 (96.6267)  time: 0.3923  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -2.7435  Acc@1: 81.2500 (82.9786)  Acc@5: 100.0000 (96.6310)  time: 0.3934  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -2.5713  Acc@1: 81.2500 (82.9826)  Acc@5: 100.0000 (96.6299)  time: 0.3923  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:41  Lr: 0.030000  Loss: -2.8353  Acc@1: 87.5000 (82.9920)  Acc@5: 100.0000 (96.6378)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:37  Lr: 0.030000  Loss: -2.7828  Acc@1: 81.2500 (82.9924)  Acc@5: 100.0000 (96.6331)  time: 0.3901  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -2.6120  Acc@1: 87.5000 (83.0034)  Acc@5: 100.0000 (96.6391)  time: 0.3908  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -2.1744  Acc@1: 81.2500 (82.9984)  Acc@5: 100.0000 (96.6363)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:25  Lr: 0.030000  Loss: -2.1632  Acc@1: 81.2500 (82.9864)  Acc@5: 93.7500 (96.6387)  time: 0.3905  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -2.3762  Acc@1: 81.2500 (82.9974)  Acc@5: 100.0000 (96.6411)  time: 0.3908  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -2.3511  Acc@1: 81.2500 (82.9977)  Acc@5: 100.0000 (96.6453)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -2.6786  Acc@1: 81.2500 (82.9999)  Acc@5: 100.0000 (96.6442)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -2.4746  Acc@1: 87.5000 (83.0177)  Acc@5: 100.0000 (96.6501)  time: 0.3906  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -2.4770  Acc@1: 87.5000 (83.0285)  Acc@5: 100.0000 (96.6525)  time: 0.3919  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -2.2123  Acc@1: 81.2500 (83.0235)  Acc@5: 100.0000 (96.6496)  time: 0.3927  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -2.7945  Acc@1: 81.2500 (83.0238)  Acc@5: 100.0000 (96.6554)  time: 0.3912  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -2.3247  Acc@1: 81.2500 (83.0154)  Acc@5: 100.0000 (96.6509)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:50  Lr: 0.030000  Loss: -2.7732  Acc@1: 75.0000 (83.0037)  Acc@5: 100.0000 (96.6515)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:46  Lr: 0.030000  Loss: -2.4861  Acc@1: 81.2500 (82.9971)  Acc@5: 100.0000 (96.6487)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:42  Lr: 0.030000  Loss: -2.2681  Acc@1: 81.2500 (82.9889)  Acc@5: 100.0000 (96.6510)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -2.3800  Acc@1: 81.2500 (82.9927)  Acc@5: 100.0000 (96.6533)  time: 0.3901  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -2.2522  Acc@1: 87.5000 (83.0050)  Acc@5: 100.0000 (96.6590)  time: 0.3903  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -2.6405  Acc@1: 81.2500 (82.9866)  Acc@5: 100.0000 (96.6596)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -2.6102  Acc@1: 81.2500 (82.9802)  Acc@5: 93.7500 (96.6568)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -1.9065  Acc@1: 81.2500 (82.9738)  Acc@5: 93.7500 (96.6506)  time: 0.3899  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -2.2450  Acc@1: 81.2500 (82.9691)  Acc@5: 100.0000 (96.6546)  time: 0.3900  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -2.9258  Acc@1: 81.2500 (82.9695)  Acc@5: 100.0000 (96.6569)  time: 0.3904  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -2.3531  Acc@1: 81.2500 (82.9733)  Acc@5: 100.0000 (96.6575)  time: 0.3896  data: 0.0003  max mem: 2908
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -2.1793  Acc@1: 81.2500 (82.9687)  Acc@5: 100.0000 (96.6614)  time: 0.3893  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -2.3857  Acc@1: 81.2500 (82.9741)  Acc@5: 100.0000 (96.6637)  time: 0.3899  data: 0.0004  max mem: 2908
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -2.5302  Acc@1: 87.5000 (82.9800)  Acc@5: 100.0000 (96.6650)  time: 0.3906  data: 0.0009  max mem: 2908
Train: Epoch[5/5] Total time: 0:24:26 (0.3910 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.5302  Acc@1: 87.5000 (82.9800)  Acc@5: 100.0000 (96.6650)
Test: [Task 1]  [   0/1627]  eta: 0:23:24  Loss: 1.0398 (1.0398)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8634  data: 0.6202  max mem: 2908
Test: [Task 1]  [  10/1627]  eta: 0:08:05  Loss: 0.7414 (0.6987)  Acc@1: 75.0000 (78.4091)  Acc@5: 100.0000 (96.5909)  time: 0.3000  data: 0.0566  max mem: 2908
Test: [Task 1]  [  20/1627]  eta: 0:07:18  Loss: 0.7077 (0.7290)  Acc@1: 81.2500 (78.5714)  Acc@5: 93.7500 (95.8333)  time: 0.2431  data: 0.0003  max mem: 2908
Test: [Task 1]  [  30/1627]  eta: 0:06:59  Loss: 0.6552 (0.7040)  Acc@1: 81.2500 (79.4355)  Acc@5: 100.0000 (96.5726)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 1]  [  40/1627]  eta: 0:06:49  Loss: 0.7015 (0.7239)  Acc@1: 81.2500 (78.6585)  Acc@5: 100.0000 (96.6463)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 1]  [  50/1627]  eta: 0:06:42  Loss: 0.7015 (0.7163)  Acc@1: 81.2500 (79.0441)  Acc@5: 100.0000 (96.8137)  time: 0.2433  data: 0.0004  max mem: 2908
Test: [Task 1]  [  60/1627]  eta: 0:06:36  Loss: 0.6994 (0.7311)  Acc@1: 75.0000 (78.8934)  Acc@5: 100.0000 (96.7213)  time: 0.2431  data: 0.0004  max mem: 2908
Test: [Task 1]  [  70/1627]  eta: 0:06:31  Loss: 0.6605 (0.7280)  Acc@1: 81.2500 (78.9613)  Acc@5: 100.0000 (96.8310)  time: 0.2420  data: 0.0003  max mem: 2908
Test: [Task 1]  [  80/1627]  eta: 0:06:27  Loss: 0.5737 (0.7197)  Acc@1: 81.2500 (78.7809)  Acc@5: 100.0000 (97.2222)  time: 0.2420  data: 0.0003  max mem: 2908
Test: [Task 1]  [  90/1627]  eta: 0:06:23  Loss: 0.7131 (0.7326)  Acc@1: 75.0000 (78.7088)  Acc@5: 100.0000 (97.0467)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 100/1627]  eta: 0:06:20  Loss: 0.8406 (0.7502)  Acc@1: 75.0000 (78.3416)  Acc@5: 93.7500 (96.7822)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 110/1627]  eta: 0:06:16  Loss: 0.6495 (0.7407)  Acc@1: 75.0000 (78.4910)  Acc@5: 100.0000 (97.0158)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 120/1627]  eta: 0:06:13  Loss: 0.6402 (0.7447)  Acc@1: 81.2500 (78.6157)  Acc@5: 100.0000 (96.9525)  time: 0.2418  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 130/1627]  eta: 0:06:10  Loss: 0.6402 (0.7407)  Acc@1: 81.2500 (78.7691)  Acc@5: 100.0000 (96.9943)  time: 0.2431  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 140/1627]  eta: 0:06:07  Loss: 0.6477 (0.7369)  Acc@1: 75.0000 (78.5018)  Acc@5: 100.0000 (97.0301)  time: 0.2437  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 150/1627]  eta: 0:06:04  Loss: 0.6477 (0.7314)  Acc@1: 75.0000 (78.7666)  Acc@5: 100.0000 (97.0613)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 160/1627]  eta: 0:06:01  Loss: 0.6571 (0.7290)  Acc@1: 81.2500 (78.9208)  Acc@5: 100.0000 (97.0497)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 170/1627]  eta: 0:05:58  Loss: 0.6603 (0.7239)  Acc@1: 81.2500 (78.9474)  Acc@5: 100.0000 (97.1491)  time: 0.2419  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 180/1627]  eta: 0:05:56  Loss: 0.6351 (0.7245)  Acc@1: 81.2500 (79.0055)  Acc@5: 100.0000 (97.1685)  time: 0.2424  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 190/1627]  eta: 0:05:53  Loss: 0.6682 (0.7206)  Acc@1: 81.2500 (79.2539)  Acc@5: 100.0000 (97.1204)  time: 0.2433  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 200/1627]  eta: 0:05:50  Loss: 0.7794 (0.7197)  Acc@1: 81.2500 (79.1978)  Acc@5: 100.0000 (97.1704)  time: 0.2437  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 210/1627]  eta: 0:05:48  Loss: 0.6820 (0.7193)  Acc@1: 75.0000 (79.2062)  Acc@5: 100.0000 (97.1564)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 220/1627]  eta: 0:05:45  Loss: 0.6820 (0.7190)  Acc@1: 75.0000 (79.2138)  Acc@5: 100.0000 (97.1719)  time: 0.2436  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 230/1627]  eta: 0:05:43  Loss: 0.7045 (0.7173)  Acc@1: 81.2500 (79.2478)  Acc@5: 100.0000 (97.1591)  time: 0.2446  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 240/1627]  eta: 0:05:40  Loss: 0.5863 (0.7147)  Acc@1: 81.2500 (79.3050)  Acc@5: 100.0000 (97.2251)  time: 0.2440  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 250/1627]  eta: 0:05:38  Loss: 0.5916 (0.7211)  Acc@1: 81.2500 (79.3078)  Acc@5: 100.0000 (97.1116)  time: 0.2431  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 260/1627]  eta: 0:05:35  Loss: 0.6738 (0.7199)  Acc@1: 81.2500 (79.2864)  Acc@5: 100.0000 (97.1264)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 270/1627]  eta: 0:05:32  Loss: 0.6164 (0.7141)  Acc@1: 81.2500 (79.3819)  Acc@5: 100.0000 (97.2094)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 280/1627]  eta: 0:05:30  Loss: 0.7238 (0.7155)  Acc@1: 81.2500 (79.3817)  Acc@5: 100.0000 (97.1753)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 290/1627]  eta: 0:05:27  Loss: 0.7661 (0.7183)  Acc@1: 81.2500 (79.4244)  Acc@5: 100.0000 (97.2079)  time: 0.2437  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 300/1627]  eta: 0:05:25  Loss: 0.6800 (0.7171)  Acc@1: 81.2500 (79.5473)  Acc@5: 100.0000 (97.1968)  time: 0.2440  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 310/1627]  eta: 0:05:22  Loss: 0.5993 (0.7164)  Acc@1: 81.2500 (79.6021)  Acc@5: 100.0000 (97.2267)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 320/1627]  eta: 0:05:20  Loss: 0.5584 (0.7115)  Acc@1: 81.2500 (79.7118)  Acc@5: 100.0000 (97.2741)  time: 0.2433  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 330/1627]  eta: 0:05:17  Loss: 0.4928 (0.7122)  Acc@1: 81.2500 (79.6450)  Acc@5: 100.0000 (97.2810)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 340/1627]  eta: 0:05:15  Loss: 0.6127 (0.7160)  Acc@1: 75.0000 (79.6004)  Acc@5: 100.0000 (97.2874)  time: 0.2423  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 350/1627]  eta: 0:05:12  Loss: 0.6127 (0.7154)  Acc@1: 81.2500 (79.6118)  Acc@5: 100.0000 (97.2756)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 360/1627]  eta: 0:05:10  Loss: 0.6311 (0.7155)  Acc@1: 81.2500 (79.6399)  Acc@5: 100.0000 (97.2472)  time: 0.2440  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 370/1627]  eta: 0:05:07  Loss: 0.5934 (0.7148)  Acc@1: 81.2500 (79.7507)  Acc@5: 100.0000 (97.2372)  time: 0.2437  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 380/1627]  eta: 0:05:05  Loss: 0.6062 (0.7149)  Acc@1: 87.5000 (79.7572)  Acc@5: 100.0000 (97.2277)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 390/1627]  eta: 0:05:02  Loss: 0.6639 (0.7150)  Acc@1: 75.0000 (79.6675)  Acc@5: 100.0000 (97.2666)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 400/1627]  eta: 0:05:00  Loss: 0.5250 (0.7136)  Acc@1: 75.0000 (79.6602)  Acc@5: 100.0000 (97.3036)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 410/1627]  eta: 0:04:57  Loss: 0.7011 (0.7178)  Acc@1: 81.2500 (79.5925)  Acc@5: 100.0000 (97.2780)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 420/1627]  eta: 0:04:55  Loss: 0.6458 (0.7165)  Acc@1: 81.2500 (79.6615)  Acc@5: 100.0000 (97.2981)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 430/1627]  eta: 0:04:52  Loss: 0.6106 (0.7160)  Acc@1: 75.0000 (79.6114)  Acc@5: 100.0000 (97.3173)  time: 0.2420  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 440/1627]  eta: 0:04:50  Loss: 0.6304 (0.7149)  Acc@1: 75.0000 (79.6060)  Acc@5: 100.0000 (97.3073)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 450/1627]  eta: 0:04:47  Loss: 0.6437 (0.7158)  Acc@1: 75.0000 (79.5593)  Acc@5: 100.0000 (97.2561)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 460/1627]  eta: 0:04:45  Loss: 0.6437 (0.7141)  Acc@1: 81.2500 (79.5960)  Acc@5: 100.0000 (97.2614)  time: 0.2439  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 470/1627]  eta: 0:04:42  Loss: 0.5665 (0.7117)  Acc@1: 81.2500 (79.6046)  Acc@5: 100.0000 (97.2797)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 480/1627]  eta: 0:04:40  Loss: 0.6013 (0.7125)  Acc@1: 81.2500 (79.6258)  Acc@5: 100.0000 (97.2713)  time: 0.2423  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 490/1627]  eta: 0:04:37  Loss: 0.7226 (0.7147)  Acc@1: 75.0000 (79.5825)  Acc@5: 93.7500 (97.2378)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 500/1627]  eta: 0:04:35  Loss: 0.7323 (0.7161)  Acc@1: 75.0000 (79.5534)  Acc@5: 100.0000 (97.2430)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 510/1627]  eta: 0:04:32  Loss: 0.7717 (0.7198)  Acc@1: 81.2500 (79.5988)  Acc@5: 100.0000 (97.1991)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 520/1627]  eta: 0:04:30  Loss: 0.7688 (0.7268)  Acc@1: 81.2500 (79.5825)  Acc@5: 93.7500 (97.1209)  time: 0.2419  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 530/1627]  eta: 0:04:27  Loss: 0.7296 (0.7254)  Acc@1: 75.0000 (79.5669)  Acc@5: 100.0000 (97.1516)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 540/1627]  eta: 0:04:25  Loss: 0.6204 (0.7244)  Acc@1: 81.2500 (79.5749)  Acc@5: 100.0000 (97.1811)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 550/1627]  eta: 0:04:22  Loss: 0.6563 (0.7256)  Acc@1: 81.2500 (79.5259)  Acc@5: 100.0000 (97.2210)  time: 0.2424  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 560/1627]  eta: 0:04:20  Loss: 0.7483 (0.7275)  Acc@1: 75.0000 (79.4675)  Acc@5: 100.0000 (97.2259)  time: 0.2431  data: 0.0004  max mem: 2908
Test: [Task 1]  [ 570/1627]  eta: 0:04:18  Loss: 0.7483 (0.7261)  Acc@1: 81.2500 (79.5534)  Acc@5: 100.0000 (97.2307)  time: 0.2443  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 580/1627]  eta: 0:04:15  Loss: 0.4651 (0.7260)  Acc@1: 81.2500 (79.5396)  Acc@5: 100.0000 (97.2676)  time: 0.2441  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 590/1627]  eta: 0:04:13  Loss: 0.5743 (0.7253)  Acc@1: 81.2500 (79.5685)  Acc@5: 100.0000 (97.2821)  time: 0.2433  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 600/1627]  eta: 0:04:10  Loss: 0.5758 (0.7253)  Acc@1: 81.2500 (79.5341)  Acc@5: 100.0000 (97.2962)  time: 0.2442  data: 0.0004  max mem: 2908
Test: [Task 1]  [ 610/1627]  eta: 0:04:08  Loss: 0.6591 (0.7245)  Acc@1: 81.2500 (79.6031)  Acc@5: 100.0000 (97.2688)  time: 0.2440  data: 0.0004  max mem: 2908
Test: [Task 1]  [ 620/1627]  eta: 0:04:05  Loss: 0.6802 (0.7257)  Acc@1: 81.2500 (79.5491)  Acc@5: 93.7500 (97.2424)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 630/1627]  eta: 0:04:03  Loss: 0.6802 (0.7282)  Acc@1: 75.0000 (79.4572)  Acc@5: 93.7500 (97.2266)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 640/1627]  eta: 0:04:00  Loss: 0.7907 (0.7282)  Acc@1: 75.0000 (79.4364)  Acc@5: 100.0000 (97.2309)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 650/1627]  eta: 0:03:58  Loss: 0.6674 (0.7265)  Acc@1: 81.2500 (79.4547)  Acc@5: 100.0000 (97.2638)  time: 0.2442  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 660/1627]  eta: 0:03:55  Loss: 0.6674 (0.7256)  Acc@1: 75.0000 (79.4535)  Acc@5: 100.0000 (97.2674)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 670/1627]  eta: 0:03:53  Loss: 0.7235 (0.7266)  Acc@1: 75.0000 (79.3778)  Acc@5: 100.0000 (97.2895)  time: 0.2420  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 680/1627]  eta: 0:03:51  Loss: 0.7410 (0.7275)  Acc@1: 75.0000 (79.3686)  Acc@5: 100.0000 (97.2742)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 690/1627]  eta: 0:03:48  Loss: 0.7062 (0.7258)  Acc@1: 81.2500 (79.4410)  Acc@5: 100.0000 (97.2594)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 700/1627]  eta: 0:03:46  Loss: 0.7062 (0.7261)  Acc@1: 81.2500 (79.4490)  Acc@5: 93.7500 (97.2272)  time: 0.2434  data: 0.0004  max mem: 2908
Test: [Task 1]  [ 710/1627]  eta: 0:03:43  Loss: 0.6630 (0.7246)  Acc@1: 81.2500 (79.5183)  Acc@5: 100.0000 (97.2310)  time: 0.2433  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 720/1627]  eta: 0:03:41  Loss: 0.5470 (0.7222)  Acc@1: 87.5000 (79.5943)  Acc@5: 100.0000 (97.2521)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 730/1627]  eta: 0:03:38  Loss: 0.5790 (0.7219)  Acc@1: 87.5000 (79.6341)  Acc@5: 100.0000 (97.2555)  time: 0.2438  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 740/1627]  eta: 0:03:36  Loss: 0.7818 (0.7237)  Acc@1: 81.2500 (79.6053)  Acc@5: 100.0000 (97.2419)  time: 0.2452  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 750/1627]  eta: 0:03:33  Loss: 0.7818 (0.7231)  Acc@1: 81.2500 (79.6272)  Acc@5: 100.0000 (97.2453)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 760/1627]  eta: 0:03:31  Loss: 0.7502 (0.7261)  Acc@1: 75.0000 (79.6239)  Acc@5: 100.0000 (97.2158)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 770/1627]  eta: 0:03:29  Loss: 0.5236 (0.7235)  Acc@1: 81.2500 (79.6774)  Acc@5: 100.0000 (97.2357)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 780/1627]  eta: 0:03:26  Loss: 0.4491 (0.7203)  Acc@1: 81.2500 (79.7855)  Acc@5: 100.0000 (97.2631)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 790/1627]  eta: 0:03:24  Loss: 0.4696 (0.7205)  Acc@1: 81.2500 (79.7961)  Acc@5: 100.0000 (97.2503)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 800/1627]  eta: 0:03:21  Loss: 0.6369 (0.7204)  Acc@1: 81.2500 (79.7753)  Acc@5: 100.0000 (97.2456)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 810/1627]  eta: 0:03:19  Loss: 0.6311 (0.7199)  Acc@1: 81.2500 (79.7781)  Acc@5: 100.0000 (97.2488)  time: 0.2424  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 820/1627]  eta: 0:03:16  Loss: 0.5677 (0.7188)  Acc@1: 81.2500 (79.8036)  Acc@5: 100.0000 (97.2442)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 830/1627]  eta: 0:03:14  Loss: 0.6211 (0.7187)  Acc@1: 81.2500 (79.8060)  Acc@5: 100.0000 (97.2323)  time: 0.2433  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 840/1627]  eta: 0:03:11  Loss: 0.6376 (0.7170)  Acc@1: 81.2500 (79.8529)  Acc@5: 100.0000 (97.2577)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 850/1627]  eta: 0:03:09  Loss: 0.6587 (0.7187)  Acc@1: 75.0000 (79.8179)  Acc@5: 100.0000 (97.2606)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 860/1627]  eta: 0:03:06  Loss: 0.6587 (0.7177)  Acc@1: 81.2500 (79.8708)  Acc@5: 100.0000 (97.2779)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 870/1627]  eta: 0:03:04  Loss: 0.5809 (0.7171)  Acc@1: 87.5000 (79.9225)  Acc@5: 100.0000 (97.2732)  time: 0.2419  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 880/1627]  eta: 0:03:02  Loss: 0.7005 (0.7190)  Acc@1: 81.2500 (79.8453)  Acc@5: 100.0000 (97.2616)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 890/1627]  eta: 0:02:59  Loss: 0.8227 (0.7209)  Acc@1: 75.0000 (79.7980)  Acc@5: 100.0000 (97.2433)  time: 0.2445  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 900/1627]  eta: 0:02:57  Loss: 0.6005 (0.7207)  Acc@1: 75.0000 (79.8210)  Acc@5: 100.0000 (97.2392)  time: 0.2448  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 910/1627]  eta: 0:02:54  Loss: 0.5582 (0.7218)  Acc@1: 81.2500 (79.8367)  Acc@5: 100.0000 (97.2146)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 920/1627]  eta: 0:02:52  Loss: 0.6415 (0.7215)  Acc@1: 81.2500 (79.8588)  Acc@5: 100.0000 (97.2177)  time: 0.2415  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 930/1627]  eta: 0:02:49  Loss: 0.6986 (0.7219)  Acc@1: 81.2500 (79.8738)  Acc@5: 100.0000 (97.2073)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 940/1627]  eta: 0:02:47  Loss: 0.6296 (0.7199)  Acc@1: 81.2500 (79.9548)  Acc@5: 100.0000 (97.2171)  time: 0.2434  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 950/1627]  eta: 0:02:44  Loss: 0.6166 (0.7195)  Acc@1: 81.2500 (79.9422)  Acc@5: 100.0000 (97.2266)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 960/1627]  eta: 0:02:42  Loss: 0.6853 (0.7190)  Acc@1: 81.2500 (79.9558)  Acc@5: 100.0000 (97.2425)  time: 0.2417  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 970/1627]  eta: 0:02:40  Loss: 0.6312 (0.7188)  Acc@1: 81.2500 (79.9176)  Acc@5: 100.0000 (97.2451)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 980/1627]  eta: 0:02:37  Loss: 0.7851 (0.7193)  Acc@1: 81.2500 (79.9185)  Acc@5: 100.0000 (97.2159)  time: 0.2442  data: 0.0003  max mem: 2908
Test: [Task 1]  [ 990/1627]  eta: 0:02:35  Loss: 0.8141 (0.7219)  Acc@1: 81.2500 (79.9004)  Acc@5: 93.7500 (97.2124)  time: 0.2442  data: 0.0003  max mem: 2908
Test: [Task 1]  [1000/1627]  eta: 0:02:32  Loss: 0.7886 (0.7216)  Acc@1: 81.2500 (79.9076)  Acc@5: 100.0000 (97.2153)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [1010/1627]  eta: 0:02:30  Loss: 0.5898 (0.7210)  Acc@1: 81.2500 (79.9518)  Acc@5: 100.0000 (97.2366)  time: 0.2424  data: 0.0003  max mem: 2908
Test: [Task 1]  [1020/1627]  eta: 0:02:27  Loss: 0.6326 (0.7210)  Acc@1: 81.2500 (79.9216)  Acc@5: 100.0000 (97.2392)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 1]  [1030/1627]  eta: 0:02:25  Loss: 0.6326 (0.7194)  Acc@1: 81.2500 (79.9588)  Acc@5: 100.0000 (97.2418)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [1040/1627]  eta: 0:02:23  Loss: 0.5519 (0.7182)  Acc@1: 81.2500 (79.9832)  Acc@5: 100.0000 (97.2562)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [1050/1627]  eta: 0:02:20  Loss: 0.5977 (0.7172)  Acc@1: 81.2500 (80.0190)  Acc@5: 100.0000 (97.2645)  time: 0.2424  data: 0.0003  max mem: 2908
Test: [Task 1]  [1060/1627]  eta: 0:02:18  Loss: 0.6683 (0.7181)  Acc@1: 81.2500 (79.9953)  Acc@5: 100.0000 (97.2491)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 1]  [1070/1627]  eta: 0:02:15  Loss: 0.7410 (0.7191)  Acc@1: 81.2500 (79.9778)  Acc@5: 100.0000 (97.2281)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 1]  [1080/1627]  eta: 0:02:13  Loss: 0.7033 (0.7194)  Acc@1: 75.0000 (79.9318)  Acc@5: 100.0000 (97.2364)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [1090/1627]  eta: 0:02:10  Loss: 0.6826 (0.7188)  Acc@1: 75.0000 (79.9439)  Acc@5: 100.0000 (97.2445)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [1100/1627]  eta: 0:02:08  Loss: 0.6366 (0.7183)  Acc@1: 81.2500 (79.9387)  Acc@5: 100.0000 (97.2468)  time: 0.2440  data: 0.0003  max mem: 2908
Test: [Task 1]  [1110/1627]  eta: 0:02:05  Loss: 0.6709 (0.7179)  Acc@1: 81.2500 (79.9280)  Acc@5: 100.0000 (97.2604)  time: 0.2436  data: 0.0003  max mem: 2908
Test: [Task 1]  [1120/1627]  eta: 0:02:03  Loss: 0.6709 (0.7191)  Acc@1: 81.2500 (79.9063)  Acc@5: 100.0000 (97.2402)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 1]  [1130/1627]  eta: 0:02:01  Loss: 0.7136 (0.7195)  Acc@1: 81.2500 (79.8795)  Acc@5: 100.0000 (97.2314)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [1140/1627]  eta: 0:01:58  Loss: 0.7136 (0.7204)  Acc@1: 75.0000 (79.8313)  Acc@5: 100.0000 (97.2447)  time: 0.2440  data: 0.0004  max mem: 2908
Test: [Task 1]  [1150/1627]  eta: 0:01:56  Loss: 0.7534 (0.7213)  Acc@1: 81.2500 (79.8219)  Acc@5: 100.0000 (97.2252)  time: 0.2435  data: 0.0004  max mem: 2908
Test: [Task 1]  [1160/1627]  eta: 0:01:53  Loss: 0.6756 (0.7211)  Acc@1: 81.2500 (79.8396)  Acc@5: 100.0000 (97.2276)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [1170/1627]  eta: 0:01:51  Loss: 0.4997 (0.7202)  Acc@1: 81.2500 (79.8570)  Acc@5: 100.0000 (97.2353)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [1180/1627]  eta: 0:01:48  Loss: 0.5493 (0.7204)  Acc@1: 81.2500 (79.8635)  Acc@5: 100.0000 (97.2481)  time: 0.2440  data: 0.0003  max mem: 2908
Test: [Task 1]  [1190/1627]  eta: 0:01:46  Loss: 0.7066 (0.7203)  Acc@1: 81.2500 (79.8541)  Acc@5: 100.0000 (97.2555)  time: 0.2446  data: 0.0003  max mem: 2908
Test: [Task 1]  [1200/1627]  eta: 0:01:44  Loss: 0.6324 (0.7201)  Acc@1: 81.2500 (79.8449)  Acc@5: 100.0000 (97.2367)  time: 0.2441  data: 0.0003  max mem: 2908
Test: [Task 1]  [1210/1627]  eta: 0:01:41  Loss: 0.5745 (0.7211)  Acc@1: 81.2500 (79.8049)  Acc@5: 100.0000 (97.2182)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 1]  [1220/1627]  eta: 0:01:39  Loss: 0.5745 (0.7202)  Acc@1: 81.2500 (79.8423)  Acc@5: 100.0000 (97.2359)  time: 0.2431  data: 0.0003  max mem: 2908
Test: [Task 1]  [1230/1627]  eta: 0:01:36  Loss: 0.6128 (0.7209)  Acc@1: 81.2500 (79.8233)  Acc@5: 100.0000 (97.2228)  time: 0.2434  data: 0.0003  max mem: 2908
Test: [Task 1]  [1240/1627]  eta: 0:01:34  Loss: 0.6912 (0.7203)  Acc@1: 81.2500 (79.8298)  Acc@5: 100.0000 (97.2351)  time: 0.2434  data: 0.0003  max mem: 2908
Test: [Task 1]  [1250/1627]  eta: 0:01:31  Loss: 0.7065 (0.7203)  Acc@1: 81.2500 (79.8761)  Acc@5: 100.0000 (97.2322)  time: 0.2437  data: 0.0003  max mem: 2908
Test: [Task 1]  [1260/1627]  eta: 0:01:29  Loss: 0.6410 (0.7202)  Acc@1: 81.2500 (79.9019)  Acc@5: 100.0000 (97.2294)  time: 0.2437  data: 0.0003  max mem: 2908
Test: [Task 1]  [1270/1627]  eta: 0:01:26  Loss: 0.6410 (0.7206)  Acc@1: 81.2500 (79.8830)  Acc@5: 100.0000 (97.2168)  time: 0.2438  data: 0.0003  max mem: 2908
Test: [Task 1]  [1280/1627]  eta: 0:01:24  Loss: 0.6560 (0.7193)  Acc@1: 87.5000 (79.9229)  Acc@5: 100.0000 (97.2287)  time: 0.2436  data: 0.0003  max mem: 2908
Test: [Task 1]  [1290/1627]  eta: 0:01:22  Loss: 0.6403 (0.7189)  Acc@1: 81.2500 (79.9332)  Acc@5: 100.0000 (97.2260)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [1300/1627]  eta: 0:01:19  Loss: 0.6174 (0.7185)  Acc@1: 81.2500 (79.9673)  Acc@5: 100.0000 (97.2329)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [1310/1627]  eta: 0:01:17  Loss: 0.5588 (0.7177)  Acc@1: 87.5000 (79.9914)  Acc@5: 100.0000 (97.2397)  time: 0.2424  data: 0.0002  max mem: 2908
Test: [Task 1]  [1320/1627]  eta: 0:01:14  Loss: 0.5273 (0.7178)  Acc@1: 87.5000 (79.9820)  Acc@5: 100.0000 (97.2369)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 1]  [1330/1627]  eta: 0:01:12  Loss: 0.5139 (0.7170)  Acc@1: 87.5000 (80.0103)  Acc@5: 100.0000 (97.2436)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 1]  [1340/1627]  eta: 0:01:09  Loss: 0.6359 (0.7178)  Acc@1: 81.2500 (79.9916)  Acc@5: 100.0000 (97.2455)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [1350/1627]  eta: 0:01:07  Loss: 0.6760 (0.7172)  Acc@1: 81.2500 (80.0194)  Acc@5: 100.0000 (97.2428)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 1]  [1360/1627]  eta: 0:01:05  Loss: 0.6527 (0.7174)  Acc@1: 81.2500 (79.9871)  Acc@5: 100.0000 (97.2584)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 1]  [1370/1627]  eta: 0:01:02  Loss: 0.6513 (0.7166)  Acc@1: 81.2500 (80.0055)  Acc@5: 100.0000 (97.2693)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [1380/1627]  eta: 0:01:00  Loss: 0.5984 (0.7162)  Acc@1: 81.2500 (80.0145)  Acc@5: 100.0000 (97.2755)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 1]  [1390/1627]  eta: 0:00:57  Loss: 0.7813 (0.7164)  Acc@1: 75.0000 (80.0099)  Acc@5: 100.0000 (97.2771)  time: 0.2420  data: 0.0003  max mem: 2908
Test: [Task 1]  [1400/1627]  eta: 0:00:55  Loss: 0.8265 (0.7165)  Acc@1: 75.0000 (79.9920)  Acc@5: 100.0000 (97.2609)  time: 0.2423  data: 0.0003  max mem: 2908
Test: [Task 1]  [1410/1627]  eta: 0:00:52  Loss: 0.6040 (0.7160)  Acc@1: 81.2500 (80.0142)  Acc@5: 100.0000 (97.2626)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 1]  [1420/1627]  eta: 0:00:50  Loss: 0.6040 (0.7157)  Acc@1: 81.2500 (80.0361)  Acc@5: 100.0000 (97.2599)  time: 0.2433  data: 0.0003  max mem: 2908
Test: [Task 1]  [1430/1627]  eta: 0:00:47  Loss: 0.8024 (0.7177)  Acc@1: 81.2500 (80.0183)  Acc@5: 100.0000 (97.2353)  time: 0.2432  data: 0.0004  max mem: 2908
Test: [Task 1]  [1440/1627]  eta: 0:00:45  Loss: 0.8957 (0.7184)  Acc@1: 81.2500 (79.9922)  Acc@5: 93.7500 (97.2241)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 1]  [1450/1627]  eta: 0:00:43  Loss: 0.8135 (0.7196)  Acc@1: 81.2500 (79.9707)  Acc@5: 93.7500 (97.2174)  time: 0.2434  data: 0.0003  max mem: 2908
Test: [Task 1]  [1460/1627]  eta: 0:00:40  Loss: 0.7011 (0.7189)  Acc@1: 81.2500 (80.0094)  Acc@5: 100.0000 (97.2279)  time: 0.2438  data: 0.0003  max mem: 2908
Test: [Task 1]  [1470/1627]  eta: 0:00:38  Loss: 0.5958 (0.7193)  Acc@1: 81.2500 (80.0008)  Acc@5: 100.0000 (97.2255)  time: 0.2442  data: 0.0003  max mem: 2908
Test: [Task 1]  [1480/1627]  eta: 0:00:35  Loss: 0.6478 (0.7198)  Acc@1: 81.2500 (79.9797)  Acc@5: 100.0000 (97.2274)  time: 0.2454  data: 0.0004  max mem: 2908
Test: [Task 1]  [1490/1627]  eta: 0:00:33  Loss: 0.6478 (0.7204)  Acc@1: 81.2500 (79.9757)  Acc@5: 100.0000 (97.2208)  time: 0.2442  data: 0.0004  max mem: 2908
Test: [Task 1]  [1500/1627]  eta: 0:00:30  Loss: 0.6641 (0.7207)  Acc@1: 81.2500 (79.9509)  Acc@5: 100.0000 (97.2227)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 1]  [1510/1627]  eta: 0:00:28  Loss: 0.6631 (0.7212)  Acc@1: 75.0000 (79.9429)  Acc@5: 100.0000 (97.2245)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 1]  [1520/1627]  eta: 0:00:26  Loss: 0.5431 (0.7201)  Acc@1: 81.2500 (79.9803)  Acc@5: 100.0000 (97.2345)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 1]  [1530/1627]  eta: 0:00:23  Loss: 0.5965 (0.7202)  Acc@1: 81.2500 (79.9763)  Acc@5: 100.0000 (97.2404)  time: 0.2418  data: 0.0003  max mem: 2908
Test: [Task 1]  [1540/1627]  eta: 0:00:21  Loss: 0.6005 (0.7189)  Acc@1: 87.5000 (80.0292)  Acc@5: 100.0000 (97.2542)  time: 0.2418  data: 0.0003  max mem: 2908
Test: [Task 1]  [1550/1627]  eta: 0:00:18  Loss: 0.5700 (0.7189)  Acc@1: 87.5000 (80.0210)  Acc@5: 100.0000 (97.2639)  time: 0.2418  data: 0.0003  max mem: 2908
Test: [Task 1]  [1560/1627]  eta: 0:00:16  Loss: 0.5598 (0.7184)  Acc@1: 81.2500 (80.0328)  Acc@5: 100.0000 (97.2654)  time: 0.2423  data: 0.0003  max mem: 2908
Test: [Task 1]  [1570/1627]  eta: 0:00:13  Loss: 0.5481 (0.7182)  Acc@1: 81.2500 (80.0366)  Acc@5: 100.0000 (97.2669)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 1]  [1580/1627]  eta: 0:00:11  Loss: 0.7110 (0.7178)  Acc@1: 81.2500 (80.0522)  Acc@5: 100.0000 (97.2683)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 1]  [1590/1627]  eta: 0:00:09  Loss: 0.7110 (0.7176)  Acc@1: 81.2500 (80.0401)  Acc@5: 100.0000 (97.2698)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 1]  [1600/1627]  eta: 0:00:06  Loss: 0.7347 (0.7185)  Acc@1: 75.0000 (80.0008)  Acc@5: 93.7500 (97.2517)  time: 0.2416  data: 0.0003  max mem: 2908
Test: [Task 1]  [1610/1627]  eta: 0:00:04  Loss: 0.6052 (0.7177)  Acc@1: 75.0000 (80.0318)  Acc@5: 100.0000 (97.2571)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.6052 (0.7172)  Acc@1: 81.2500 (80.0355)  Acc@5: 100.0000 (97.2702)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.6763 (0.7170)  Acc@1: 81.2500 (80.0515)  Acc@5: 100.0000 (97.2764)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 1] Total time: 0:06:36 (0.2436 s / it)
* Acc@1 80.051 Acc@5 97.276 loss 0.717
Test: [Task 2]  [  0/625]  eta: 0:07:10  Loss: 0.1387 (0.1387)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6884  data: 0.4423  max mem: 2908
Test: [Task 2]  [ 10/625]  eta: 0:02:54  Loss: 0.0677 (0.0944)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (100.0000)  time: 0.2836  data: 0.0405  max mem: 2908
Test: [Task 2]  [ 20/625]  eta: 0:02:39  Loss: 0.0677 (0.1326)  Acc@1: 100.0000 (95.8333)  Acc@5: 100.0000 (100.0000)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 2]  [ 30/625]  eta: 0:02:32  Loss: 0.1524 (0.1661)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (99.7984)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 2]  [ 40/625]  eta: 0:02:28  Loss: 0.1716 (0.1783)  Acc@1: 93.7500 (94.0549)  Acc@5: 100.0000 (99.8476)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 2]  [ 50/625]  eta: 0:02:24  Loss: 0.1465 (0.1799)  Acc@1: 93.7500 (93.9951)  Acc@5: 100.0000 (99.8775)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 2]  [ 60/625]  eta: 0:02:21  Loss: 0.1324 (0.1784)  Acc@1: 93.7500 (94.2623)  Acc@5: 100.0000 (99.7951)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 2]  [ 70/625]  eta: 0:02:18  Loss: 0.1211 (0.1704)  Acc@1: 93.7500 (94.6303)  Acc@5: 100.0000 (99.8239)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 2]  [ 80/625]  eta: 0:02:15  Loss: 0.1211 (0.1666)  Acc@1: 93.7500 (94.8302)  Acc@5: 100.0000 (99.8457)  time: 0.2420  data: 0.0003  max mem: 2908
Test: [Task 2]  [ 90/625]  eta: 0:02:12  Loss: 0.1096 (0.1599)  Acc@1: 93.7500 (94.9176)  Acc@5: 100.0000 (99.8626)  time: 0.2421  data: 0.0003  max mem: 2908
Test: [Task 2]  [100/625]  eta: 0:02:09  Loss: 0.0944 (0.1561)  Acc@1: 93.7500 (95.1733)  Acc@5: 100.0000 (99.8762)  time: 0.2436  data: 0.0003  max mem: 2908
Test: [Task 2]  [110/625]  eta: 0:02:07  Loss: 0.0657 (0.1588)  Acc@1: 100.0000 (95.2140)  Acc@5: 100.0000 (99.8311)  time: 0.2435  data: 0.0003  max mem: 2908
Test: [Task 2]  [120/625]  eta: 0:02:04  Loss: 0.1148 (0.1607)  Acc@1: 93.7500 (95.1446)  Acc@5: 100.0000 (99.7934)  time: 0.2436  data: 0.0004  max mem: 2908
Test: [Task 2]  [130/625]  eta: 0:02:01  Loss: 0.1425 (0.1624)  Acc@1: 93.7500 (94.9905)  Acc@5: 100.0000 (99.8092)  time: 0.2448  data: 0.0004  max mem: 2908
Test: [Task 2]  [140/625]  eta: 0:01:59  Loss: 0.1361 (0.1684)  Acc@1: 93.7500 (94.8582)  Acc@5: 100.0000 (99.7340)  time: 0.2443  data: 0.0005  max mem: 2908
Test: [Task 2]  [150/625]  eta: 0:01:56  Loss: 0.1850 (0.1732)  Acc@1: 93.7500 (94.6606)  Acc@5: 100.0000 (99.6689)  time: 0.2430  data: 0.0004  max mem: 2908
Test: [Task 2]  [160/625]  eta: 0:01:54  Loss: 0.1928 (0.1771)  Acc@1: 93.7500 (94.6429)  Acc@5: 100.0000 (99.6118)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 2]  [170/625]  eta: 0:01:51  Loss: 0.1127 (0.1734)  Acc@1: 100.0000 (94.8830)  Acc@5: 100.0000 (99.5980)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 2]  [180/625]  eta: 0:01:49  Loss: 0.0924 (0.1724)  Acc@1: 100.0000 (94.9240)  Acc@5: 100.0000 (99.6202)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 2]  [190/625]  eta: 0:01:46  Loss: 0.1112 (0.1738)  Acc@1: 93.7500 (94.8298)  Acc@5: 100.0000 (99.5746)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 2]  [200/625]  eta: 0:01:44  Loss: 0.1302 (0.1726)  Acc@1: 93.7500 (94.8383)  Acc@5: 100.0000 (99.5958)  time: 0.2424  data: 0.0003  max mem: 2908
Test: [Task 2]  [210/625]  eta: 0:01:41  Loss: 0.1302 (0.1729)  Acc@1: 93.7500 (94.8460)  Acc@5: 100.0000 (99.6149)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 2]  [220/625]  eta: 0:01:39  Loss: 0.0868 (0.1718)  Acc@1: 100.0000 (94.9095)  Acc@5: 100.0000 (99.6041)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 2]  [230/625]  eta: 0:01:36  Loss: 0.0733 (0.1702)  Acc@1: 93.7500 (94.9675)  Acc@5: 100.0000 (99.6212)  time: 0.2433  data: 0.0003  max mem: 2908
Test: [Task 2]  [240/625]  eta: 0:01:34  Loss: 0.1768 (0.1721)  Acc@1: 93.7500 (94.8392)  Acc@5: 100.0000 (99.6369)  time: 0.2454  data: 0.0003  max mem: 2908
Test: [Task 2]  [250/625]  eta: 0:01:31  Loss: 0.1791 (0.1740)  Acc@1: 93.7500 (94.7460)  Acc@5: 100.0000 (99.6514)  time: 0.2455  data: 0.0004  max mem: 2908
Test: [Task 2]  [260/625]  eta: 0:01:29  Loss: 0.1375 (0.1722)  Acc@1: 93.7500 (94.7557)  Acc@5: 100.0000 (99.6648)  time: 0.2434  data: 0.0004  max mem: 2908
Test: [Task 2]  [270/625]  eta: 0:01:26  Loss: 0.1357 (0.1724)  Acc@1: 93.7500 (94.7417)  Acc@5: 100.0000 (99.6771)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 2]  [280/625]  eta: 0:01:24  Loss: 0.1357 (0.1746)  Acc@1: 93.7500 (94.7286)  Acc@5: 100.0000 (99.6441)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 2]  [290/625]  eta: 0:01:21  Loss: 0.1908 (0.1756)  Acc@1: 93.7500 (94.6521)  Acc@5: 100.0000 (99.6564)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 2]  [300/625]  eta: 0:01:19  Loss: 0.1419 (0.1751)  Acc@1: 93.7500 (94.6429)  Acc@5: 100.0000 (99.6678)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 2]  [310/625]  eta: 0:01:16  Loss: 0.1261 (0.1738)  Acc@1: 93.7500 (94.7146)  Acc@5: 100.0000 (99.6785)  time: 0.2417  data: 0.0003  max mem: 2908
Test: [Task 2]  [320/625]  eta: 0:01:14  Loss: 0.0367 (0.1690)  Acc@1: 100.0000 (94.8793)  Acc@5: 100.0000 (99.6885)  time: 0.2413  data: 0.0003  max mem: 2908
Test: [Task 2]  [330/625]  eta: 0:01:12  Loss: 0.0270 (0.1655)  Acc@1: 100.0000 (94.9962)  Acc@5: 100.0000 (99.6979)  time: 0.2411  data: 0.0003  max mem: 2908
Test: [Task 2]  [340/625]  eta: 0:01:09  Loss: 0.0156 (0.1608)  Acc@1: 100.0000 (95.1430)  Acc@5: 100.0000 (99.7067)  time: 0.2415  data: 0.0004  max mem: 2908
Test: [Task 2]  [350/625]  eta: 0:01:07  Loss: 0.0102 (0.1587)  Acc@1: 100.0000 (95.1923)  Acc@5: 100.0000 (99.7151)  time: 0.2424  data: 0.0004  max mem: 2908
Test: [Task 2]  [360/625]  eta: 0:01:04  Loss: 0.0481 (0.1575)  Acc@1: 100.0000 (95.2043)  Acc@5: 100.0000 (99.7230)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 2]  [370/625]  eta: 0:01:02  Loss: 0.0682 (0.1556)  Acc@1: 100.0000 (95.2662)  Acc@5: 100.0000 (99.7305)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 2]  [380/625]  eta: 0:00:59  Loss: 0.1802 (0.1593)  Acc@1: 93.7500 (95.1772)  Acc@5: 100.0000 (99.7047)  time: 0.2422  data: 0.0003  max mem: 2908
Test: [Task 2]  [390/625]  eta: 0:00:57  Loss: 0.1198 (0.1573)  Acc@1: 93.7500 (95.2366)  Acc@5: 100.0000 (99.7123)  time: 0.2431  data: 0.0003  max mem: 2908
Test: [Task 2]  [400/625]  eta: 0:00:54  Loss: 0.0209 (0.1545)  Acc@1: 100.0000 (95.3398)  Acc@5: 100.0000 (99.7195)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 2]  [410/625]  eta: 0:00:52  Loss: 0.0071 (0.1519)  Acc@1: 100.0000 (95.4227)  Acc@5: 100.0000 (99.7263)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 2]  [420/625]  eta: 0:00:49  Loss: 0.0194 (0.1499)  Acc@1: 100.0000 (95.5018)  Acc@5: 100.0000 (99.7328)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 2]  [430/625]  eta: 0:00:47  Loss: 0.0386 (0.1484)  Acc@1: 100.0000 (95.5626)  Acc@5: 100.0000 (99.7390)  time: 0.2414  data: 0.0003  max mem: 2908
Test: [Task 2]  [440/625]  eta: 0:00:45  Loss: 0.0214 (0.1455)  Acc@1: 100.0000 (95.6633)  Acc@5: 100.0000 (99.7449)  time: 0.2413  data: 0.0003  max mem: 2908
Test: [Task 2]  [450/625]  eta: 0:00:42  Loss: 0.0065 (0.1428)  Acc@1: 100.0000 (95.7456)  Acc@5: 100.0000 (99.7506)  time: 0.2424  data: 0.0003  max mem: 2908
Test: [Task 2]  [460/625]  eta: 0:00:40  Loss: 0.0087 (0.1401)  Acc@1: 100.0000 (95.8243)  Acc@5: 100.0000 (99.7560)  time: 0.2434  data: 0.0004  max mem: 2908
Test: [Task 2]  [470/625]  eta: 0:00:37  Loss: 0.0178 (0.1377)  Acc@1: 100.0000 (95.9130)  Acc@5: 100.0000 (99.7611)  time: 0.2431  data: 0.0003  max mem: 2908
Test: [Task 2]  [480/625]  eta: 0:00:35  Loss: 0.0312 (0.1364)  Acc@1: 100.0000 (95.9589)  Acc@5: 100.0000 (99.7661)  time: 0.2423  data: 0.0003  max mem: 2908
Test: [Task 2]  [490/625]  eta: 0:00:32  Loss: 0.0242 (0.1347)  Acc@1: 100.0000 (96.0031)  Acc@5: 100.0000 (99.7709)  time: 0.2427  data: 0.0003  max mem: 2908
Test: [Task 2]  [500/625]  eta: 0:00:30  Loss: 0.0215 (0.1326)  Acc@1: 100.0000 (96.0704)  Acc@5: 100.0000 (99.7754)  time: 0.2429  data: 0.0003  max mem: 2908
Test: [Task 2]  [510/625]  eta: 0:00:28  Loss: 0.0270 (0.1343)  Acc@1: 100.0000 (96.0250)  Acc@5: 100.0000 (99.7798)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 2]  [520/625]  eta: 0:00:25  Loss: 0.0332 (0.1330)  Acc@1: 100.0000 (96.0653)  Acc@5: 100.0000 (99.7841)  time: 0.2432  data: 0.0003  max mem: 2908
Test: [Task 2]  [530/625]  eta: 0:00:23  Loss: 0.0212 (0.1316)  Acc@1: 100.0000 (96.1040)  Acc@5: 100.0000 (99.7881)  time: 0.2431  data: 0.0003  max mem: 2908
Test: [Task 2]  [540/625]  eta: 0:00:20  Loss: 0.0212 (0.1303)  Acc@1: 100.0000 (96.1414)  Acc@5: 100.0000 (99.7921)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 2]  [550/625]  eta: 0:00:18  Loss: 0.0079 (0.1280)  Acc@1: 100.0000 (96.2114)  Acc@5: 100.0000 (99.7958)  time: 0.2425  data: 0.0003  max mem: 2908
Test: [Task 2]  [560/625]  eta: 0:00:15  Loss: 0.0029 (0.1258)  Acc@1: 100.0000 (96.2790)  Acc@5: 100.0000 (99.7995)  time: 0.2423  data: 0.0003  max mem: 2908
Test: [Task 2]  [570/625]  eta: 0:00:13  Loss: 0.0044 (0.1246)  Acc@1: 100.0000 (96.3113)  Acc@5: 100.0000 (99.8030)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 2]  [580/625]  eta: 0:00:10  Loss: 0.0118 (0.1228)  Acc@1: 100.0000 (96.3640)  Acc@5: 100.0000 (99.8064)  time: 0.2430  data: 0.0003  max mem: 2908
Test: [Task 2]  [590/625]  eta: 0:00:08  Loss: 0.0108 (0.1214)  Acc@1: 100.0000 (96.4044)  Acc@5: 100.0000 (99.8096)  time: 0.2426  data: 0.0003  max mem: 2908
Test: [Task 2]  [600/625]  eta: 0:00:06  Loss: 0.0225 (0.1209)  Acc@1: 100.0000 (96.4122)  Acc@5: 100.0000 (99.8128)  time: 0.2428  data: 0.0003  max mem: 2908
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.1153 (0.1215)  Acc@1: 93.7500 (96.3891)  Acc@5: 100.0000 (99.8159)  time: 0.2438  data: 0.0003  max mem: 2908
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.1153 (0.1220)  Acc@1: 93.7500 (96.3366)  Acc@5: 100.0000 (99.8188)  time: 0.2440  data: 0.0003  max mem: 2908
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.0851 (0.1216)  Acc@1: 93.7500 (96.3500)  Acc@5: 100.0000 (99.8200)  time: 0.2439  data: 0.0002  max mem: 2908
Test: [Task 2] Total time: 0:02:32 (0.2438 s / it)
* Acc@1 96.350 Acc@5 99.820 loss 0.122
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 26032, 5: 26032, 6: 26032, 7: 26032, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 10000, 13: 10000, 14: 10000, 15: 10000, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}}
[Average accuracy till task2]	Acc@1: 88.2007	Acc@5: 98.5482	Loss: 0.4193	Forgetting: 10.4640	Backward: -10.4640
Train: Epoch[1/5]  [   0/3125]  eta: 0:46:38  Lr: 0.030000  Loss: 2.3601  Acc@1: 0.0000 (0.0000)  Acc@5: 31.2500 (31.2500)  time: 0.8955  data: 0.4879  max mem: 2908
Train: Epoch[1/5]  [  10/3125]  eta: 0:22:36  Lr: 0.030000  Loss: 1.0943  Acc@1: 25.0000 (23.8636)  Acc@5: 62.5000 (61.3636)  time: 0.4356  data: 0.0447  max mem: 2912
Train: Epoch[1/5]  [  20/3125]  eta: 0:21:25  Lr: 0.030000  Loss: 0.1895  Acc@1: 31.2500 (32.7381)  Acc@5: 68.7500 (72.0238)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  30/3125]  eta: 0:20:58  Lr: 0.030000  Loss: 0.1752  Acc@1: 50.0000 (39.1129)  Acc@5: 87.5000 (77.4194)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  40/3125]  eta: 0:20:43  Lr: 0.030000  Loss: -0.6053  Acc@1: 56.2500 (45.8841)  Acc@5: 93.7500 (81.8598)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  50/3125]  eta: 0:20:31  Lr: 0.030000  Loss: -0.4229  Acc@1: 68.7500 (50.8578)  Acc@5: 93.7500 (84.0686)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [  60/3125]  eta: 0:20:23  Lr: 0.030000  Loss: -0.7632  Acc@1: 75.0000 (54.0984)  Acc@5: 93.7500 (86.1680)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [  70/3125]  eta: 0:20:16  Lr: 0.030000  Loss: -1.0311  Acc@1: 68.7500 (55.8099)  Acc@5: 93.7500 (87.5000)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [  80/3125]  eta: 0:20:10  Lr: 0.030000  Loss: -1.1797  Acc@1: 68.7500 (57.4074)  Acc@5: 93.7500 (88.4259)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  90/3125]  eta: 0:20:04  Lr: 0.030000  Loss: -1.4004  Acc@1: 75.0000 (59.7527)  Acc@5: 93.7500 (89.3544)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 100/3125]  eta: 0:19:59  Lr: 0.030000  Loss: -1.3558  Acc@1: 75.0000 (60.8911)  Acc@5: 93.7500 (89.9134)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 110/3125]  eta: 0:19:54  Lr: 0.030000  Loss: -1.0333  Acc@1: 68.7500 (61.8243)  Acc@5: 93.7500 (90.3716)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 120/3125]  eta: 0:19:48  Lr: 0.030000  Loss: -1.2495  Acc@1: 75.0000 (62.8616)  Acc@5: 93.7500 (90.9607)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 130/3125]  eta: 0:19:45  Lr: 0.030000  Loss: -1.2747  Acc@1: 75.0000 (63.6927)  Acc@5: 100.0000 (91.2691)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 140/3125]  eta: 0:19:40  Lr: 0.030000  Loss: -0.6362  Acc@1: 75.0000 (64.4504)  Acc@5: 100.0000 (91.6223)  time: 0.3943  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 150/3125]  eta: 0:19:36  Lr: 0.030000  Loss: -1.4817  Acc@1: 75.0000 (65.1490)  Acc@5: 100.0000 (91.8046)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 160/3125]  eta: 0:19:31  Lr: 0.030000  Loss: -1.2191  Acc@1: 75.0000 (65.7609)  Acc@5: 93.7500 (92.0419)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 170/3125]  eta: 0:19:27  Lr: 0.030000  Loss: -0.7177  Acc@1: 68.7500 (66.3012)  Acc@5: 93.7500 (92.3246)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 180/3125]  eta: 0:19:22  Lr: 0.030000  Loss: -0.7261  Acc@1: 68.7500 (66.6091)  Acc@5: 100.0000 (92.5069)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 190/3125]  eta: 0:19:18  Lr: 0.030000  Loss: -0.4981  Acc@1: 68.7500 (67.0812)  Acc@5: 93.7500 (92.6374)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 200/3125]  eta: 0:19:13  Lr: 0.030000  Loss: -1.1339  Acc@1: 75.0000 (67.5062)  Acc@5: 100.0000 (92.8172)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 210/3125]  eta: 0:19:09  Lr: 0.030000  Loss: -0.7019  Acc@1: 75.0000 (68.0391)  Acc@5: 100.0000 (92.9799)  time: 0.3917  data: 0.0006  max mem: 2912
Train: Epoch[1/5]  [ 220/3125]  eta: 0:19:05  Lr: 0.030000  Loss: -0.9083  Acc@1: 75.0000 (68.3258)  Acc@5: 93.7500 (93.0995)  time: 0.3922  data: 0.0006  max mem: 2912
Train: Epoch[1/5]  [ 230/3125]  eta: 0:19:00  Lr: 0.030000  Loss: -1.6311  Acc@1: 75.0000 (68.6959)  Acc@5: 93.7500 (93.1818)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 240/3125]  eta: 0:18:56  Lr: 0.030000  Loss: -1.0388  Acc@1: 68.7500 (68.6722)  Acc@5: 93.7500 (93.2313)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 250/3125]  eta: 0:18:52  Lr: 0.030000  Loss: -1.0687  Acc@1: 68.7500 (69.2231)  Acc@5: 93.7500 (93.3765)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 260/3125]  eta: 0:18:47  Lr: 0.030000  Loss: -1.2420  Acc@1: 75.0000 (69.3966)  Acc@5: 93.7500 (93.3669)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 270/3125]  eta: 0:18:43  Lr: 0.030000  Loss: -1.1051  Acc@1: 75.0000 (69.5341)  Acc@5: 93.7500 (93.5424)  time: 0.3908  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 280/3125]  eta: 0:18:39  Lr: 0.030000  Loss: 0.0324  Acc@1: 75.0000 (69.9956)  Acc@5: 100.0000 (93.5721)  time: 0.3907  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 290/3125]  eta: 0:18:35  Lr: 0.030000  Loss: -1.5331  Acc@1: 81.2500 (70.2320)  Acc@5: 93.7500 (93.6211)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 300/3125]  eta: 0:18:30  Lr: 0.030000  Loss: -0.4709  Acc@1: 75.0000 (70.4111)  Acc@5: 93.7500 (93.7085)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 310/3125]  eta: 0:18:26  Lr: 0.030000  Loss: -0.7858  Acc@1: 81.2500 (70.8400)  Acc@5: 93.7500 (93.7701)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 320/3125]  eta: 0:18:22  Lr: 0.030000  Loss: -1.2205  Acc@1: 81.2500 (71.2617)  Acc@5: 93.7500 (93.8474)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 330/3125]  eta: 0:18:18  Lr: 0.030000  Loss: -1.6911  Acc@1: 81.2500 (71.4690)  Acc@5: 100.0000 (93.9577)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 340/3125]  eta: 0:18:13  Lr: 0.030000  Loss: -0.9022  Acc@1: 81.2500 (71.7192)  Acc@5: 100.0000 (94.0433)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 350/3125]  eta: 0:18:09  Lr: 0.030000  Loss: -1.0361  Acc@1: 81.2500 (72.0442)  Acc@5: 100.0000 (94.1417)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 360/3125]  eta: 0:18:05  Lr: 0.030000  Loss: -1.1880  Acc@1: 81.2500 (72.2819)  Acc@5: 100.0000 (94.1828)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 370/3125]  eta: 0:18:01  Lr: 0.030000  Loss: -1.1998  Acc@1: 75.0000 (72.3551)  Acc@5: 100.0000 (94.2217)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 380/3125]  eta: 0:17:57  Lr: 0.030000  Loss: -0.5755  Acc@1: 75.0000 (72.5066)  Acc@5: 93.7500 (94.2421)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 390/3125]  eta: 0:17:53  Lr: 0.030000  Loss: -0.8260  Acc@1: 75.0000 (72.5064)  Acc@5: 100.0000 (94.3414)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 400/3125]  eta: 0:17:49  Lr: 0.030000  Loss: -1.3376  Acc@1: 75.0000 (72.7868)  Acc@5: 100.0000 (94.3890)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 410/3125]  eta: 0:17:45  Lr: 0.030000  Loss: -1.1868  Acc@1: 81.2500 (72.9167)  Acc@5: 93.7500 (94.4039)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 420/3125]  eta: 0:17:40  Lr: 0.030000  Loss: -0.7753  Acc@1: 75.0000 (72.9513)  Acc@5: 93.7500 (94.4477)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 430/3125]  eta: 0:17:36  Lr: 0.030000  Loss: -0.6629  Acc@1: 75.0000 (73.0858)  Acc@5: 93.7500 (94.4606)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 440/3125]  eta: 0:17:32  Lr: 0.030000  Loss: -0.7559  Acc@1: 75.0000 (73.0726)  Acc@5: 93.7500 (94.4444)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 450/3125]  eta: 0:17:29  Lr: 0.030000  Loss: -0.3990  Acc@1: 75.0000 (73.1707)  Acc@5: 93.7500 (94.4845)  time: 0.3949  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 460/3125]  eta: 0:17:25  Lr: 0.030000  Loss: -0.7924  Acc@1: 75.0000 (73.2511)  Acc@5: 93.7500 (94.5363)  time: 0.3946  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 470/3125]  eta: 0:17:21  Lr: 0.030000  Loss: -1.8483  Acc@1: 81.2500 (73.3944)  Acc@5: 100.0000 (94.5860)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 480/3125]  eta: 0:17:17  Lr: 0.030000  Loss: -0.6872  Acc@1: 81.2500 (73.5317)  Acc@5: 100.0000 (94.6336)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 490/3125]  eta: 0:17:13  Lr: 0.030000  Loss: -1.3216  Acc@1: 81.2500 (73.8035)  Acc@5: 100.0000 (94.7047)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 500/3125]  eta: 0:17:09  Lr: 0.030000  Loss: -1.3683  Acc@1: 81.2500 (73.9770)  Acc@5: 100.0000 (94.7231)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 510/3125]  eta: 0:17:05  Lr: 0.030000  Loss: -0.3478  Acc@1: 75.0000 (73.9848)  Acc@5: 93.7500 (94.6429)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 520/3125]  eta: 0:17:01  Lr: 0.030000  Loss: -1.3332  Acc@1: 75.0000 (73.9683)  Acc@5: 93.7500 (94.6617)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 530/3125]  eta: 0:16:57  Lr: 0.030000  Loss: -1.5365  Acc@1: 75.0000 (74.0702)  Acc@5: 93.7500 (94.7034)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 540/3125]  eta: 0:16:53  Lr: 0.030000  Loss: -1.0199  Acc@1: 81.2500 (74.1682)  Acc@5: 100.0000 (94.7551)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 550/3125]  eta: 0:16:49  Lr: 0.030000  Loss: -0.6638  Acc@1: 81.2500 (74.2627)  Acc@5: 93.7500 (94.7255)  time: 0.3944  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 560/3125]  eta: 0:16:46  Lr: 0.030000  Loss: -0.6631  Acc@1: 75.0000 (74.3204)  Acc@5: 93.7500 (94.7750)  time: 0.3959  data: 0.0014  max mem: 2912
Train: Epoch[1/5]  [ 570/3125]  eta: 0:16:42  Lr: 0.030000  Loss: -0.3973  Acc@1: 81.2500 (74.4965)  Acc@5: 100.0000 (94.8117)  time: 0.3941  data: 0.0014  max mem: 2912
Train: Epoch[1/5]  [ 580/3125]  eta: 0:16:38  Lr: 0.030000  Loss: -1.5842  Acc@1: 81.2500 (74.6450)  Acc@5: 93.7500 (94.8042)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 590/3125]  eta: 0:16:34  Lr: 0.030000  Loss: -0.5868  Acc@1: 81.2500 (74.6722)  Acc@5: 93.7500 (94.7652)  time: 0.3939  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 600/3125]  eta: 0:16:30  Lr: 0.030000  Loss: -0.6691  Acc@1: 81.2500 (74.8128)  Acc@5: 100.0000 (94.8211)  time: 0.3944  data: 0.0006  max mem: 2912
Train: Epoch[1/5]  [ 610/3125]  eta: 0:16:26  Lr: 0.030000  Loss: -1.1310  Acc@1: 81.2500 (74.8875)  Acc@5: 100.0000 (94.8650)  time: 0.3932  data: 0.0006  max mem: 2912
Train: Epoch[1/5]  [ 620/3125]  eta: 0:16:22  Lr: 0.030000  Loss: -1.8253  Acc@1: 75.0000 (74.8893)  Acc@5: 100.0000 (94.8370)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 630/3125]  eta: 0:16:18  Lr: 0.030000  Loss: -0.9672  Acc@1: 75.0000 (74.9406)  Acc@5: 93.7500 (94.8296)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 640/3125]  eta: 0:16:14  Lr: 0.030000  Loss: -1.2996  Acc@1: 75.0000 (75.0293)  Acc@5: 93.7500 (94.8518)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 650/3125]  eta: 0:16:10  Lr: 0.030000  Loss: -1.5151  Acc@1: 75.0000 (75.0384)  Acc@5: 100.0000 (94.9021)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 660/3125]  eta: 0:16:06  Lr: 0.030000  Loss: -0.7770  Acc@1: 81.2500 (75.1229)  Acc@5: 100.0000 (94.9319)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 670/3125]  eta: 0:16:02  Lr: 0.030000  Loss: -1.2407  Acc@1: 81.2500 (75.2701)  Acc@5: 100.0000 (94.9888)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 680/3125]  eta: 0:15:58  Lr: 0.030000  Loss: -0.7920  Acc@1: 81.2500 (75.2662)  Acc@5: 100.0000 (95.0073)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 690/3125]  eta: 0:15:54  Lr: 0.030000  Loss: -0.7373  Acc@1: 75.0000 (75.2804)  Acc@5: 100.0000 (94.9982)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 700/3125]  eta: 0:15:50  Lr: 0.030000  Loss: -1.1670  Acc@1: 75.0000 (75.3031)  Acc@5: 93.7500 (95.0071)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 710/3125]  eta: 0:15:46  Lr: 0.030000  Loss: -1.4518  Acc@1: 75.0000 (75.3604)  Acc@5: 100.0000 (95.0598)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 720/3125]  eta: 0:15:43  Lr: 0.030000  Loss: -1.4113  Acc@1: 81.2500 (75.4334)  Acc@5: 100.0000 (95.1023)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 730/3125]  eta: 0:15:39  Lr: 0.030000  Loss: -1.6854  Acc@1: 81.2500 (75.4873)  Acc@5: 100.0000 (95.1351)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 740/3125]  eta: 0:15:35  Lr: 0.030000  Loss: -1.3792  Acc@1: 75.0000 (75.5314)  Acc@5: 100.0000 (95.1670)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 750/3125]  eta: 0:15:31  Lr: 0.030000  Loss: -0.7942  Acc@1: 75.0000 (75.6075)  Acc@5: 100.0000 (95.1897)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 760/3125]  eta: 0:15:27  Lr: 0.030000  Loss: -1.7995  Acc@1: 81.2500 (75.6817)  Acc@5: 100.0000 (95.2365)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 770/3125]  eta: 0:15:23  Lr: 0.030000  Loss: -1.4914  Acc@1: 81.2500 (75.7053)  Acc@5: 100.0000 (95.2497)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 780/3125]  eta: 0:15:19  Lr: 0.030000  Loss: -1.5224  Acc@1: 81.2500 (75.7843)  Acc@5: 100.0000 (95.2625)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 790/3125]  eta: 0:15:15  Lr: 0.030000  Loss: -1.0705  Acc@1: 81.2500 (75.7822)  Acc@5: 100.0000 (95.2908)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 800/3125]  eta: 0:15:11  Lr: 0.030000  Loss: -1.1578  Acc@1: 81.2500 (75.8427)  Acc@5: 100.0000 (95.2949)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 810/3125]  eta: 0:15:07  Lr: 0.030000  Loss: -1.3616  Acc@1: 81.2500 (75.8863)  Acc@5: 93.7500 (95.2913)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 820/3125]  eta: 0:15:03  Lr: 0.030000  Loss: -1.4434  Acc@1: 81.2500 (75.9440)  Acc@5: 100.0000 (95.3182)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 830/3125]  eta: 0:14:59  Lr: 0.030000  Loss: -1.3140  Acc@1: 81.2500 (76.0680)  Acc@5: 100.0000 (95.3520)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 840/3125]  eta: 0:14:55  Lr: 0.030000  Loss: -1.3198  Acc@1: 81.2500 (76.1296)  Acc@5: 100.0000 (95.3924)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 850/3125]  eta: 0:14:51  Lr: 0.030000  Loss: -0.4541  Acc@1: 81.2500 (76.1604)  Acc@5: 100.0000 (95.4025)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 860/3125]  eta: 0:14:47  Lr: 0.030000  Loss: -0.8314  Acc@1: 75.0000 (76.1542)  Acc@5: 93.7500 (95.3833)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 870/3125]  eta: 0:14:43  Lr: 0.030000  Loss: -1.7779  Acc@1: 81.2500 (76.2270)  Acc@5: 100.0000 (95.4076)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 880/3125]  eta: 0:14:39  Lr: 0.030000  Loss: -0.1356  Acc@1: 81.2500 (76.2841)  Acc@5: 100.0000 (95.4384)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 890/3125]  eta: 0:14:35  Lr: 0.030000  Loss: -1.2044  Acc@1: 81.2500 (76.3678)  Acc@5: 100.0000 (95.4756)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 900/3125]  eta: 0:14:31  Lr: 0.030000  Loss: -1.2595  Acc@1: 87.5000 (76.4706)  Acc@5: 100.0000 (95.5050)  time: 0.3906  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 910/3125]  eta: 0:14:27  Lr: 0.030000  Loss: -0.6547  Acc@1: 81.2500 (76.5025)  Acc@5: 100.0000 (95.5200)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 920/3125]  eta: 0:14:23  Lr: 0.030000  Loss: -1.4548  Acc@1: 75.0000 (76.4862)  Acc@5: 100.0000 (95.5280)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 930/3125]  eta: 0:14:19  Lr: 0.030000  Loss: -1.5155  Acc@1: 81.2500 (76.5373)  Acc@5: 100.0000 (95.5626)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 940/3125]  eta: 0:14:15  Lr: 0.030000  Loss: -1.4091  Acc@1: 81.2500 (76.6140)  Acc@5: 100.0000 (95.5964)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 950/3125]  eta: 0:14:11  Lr: 0.030000  Loss: -1.2277  Acc@1: 75.0000 (76.6036)  Acc@5: 100.0000 (95.6230)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 960/3125]  eta: 0:14:07  Lr: 0.030000  Loss: -1.1856  Acc@1: 75.0000 (76.6389)  Acc@5: 93.7500 (95.6230)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 970/3125]  eta: 0:14:03  Lr: 0.030000  Loss: -1.1257  Acc@1: 81.2500 (76.6864)  Acc@5: 93.7500 (95.6359)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 980/3125]  eta: 0:14:00  Lr: 0.030000  Loss: -1.5186  Acc@1: 81.2500 (76.7011)  Acc@5: 93.7500 (95.6231)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 990/3125]  eta: 0:13:56  Lr: 0.030000  Loss: -1.2213  Acc@1: 75.0000 (76.6965)  Acc@5: 93.7500 (95.6168)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1000/3125]  eta: 0:13:52  Lr: 0.030000  Loss: -0.9237  Acc@1: 75.0000 (76.7233)  Acc@5: 100.0000 (95.6356)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1010/3125]  eta: 0:13:48  Lr: 0.030000  Loss: -1.6526  Acc@1: 81.2500 (76.8051)  Acc@5: 100.0000 (95.6726)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1020/3125]  eta: 0:13:44  Lr: 0.030000  Loss: -1.0534  Acc@1: 87.5000 (76.8732)  Acc@5: 100.0000 (95.7027)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1030/3125]  eta: 0:13:40  Lr: 0.030000  Loss: -1.3984  Acc@1: 87.5000 (76.9399)  Acc@5: 100.0000 (95.7202)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1040/3125]  eta: 0:13:36  Lr: 0.030000  Loss: -1.4746  Acc@1: 81.2500 (76.9933)  Acc@5: 100.0000 (95.7373)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1050/3125]  eta: 0:13:32  Lr: 0.030000  Loss: -0.7548  Acc@1: 81.2500 (77.0338)  Acc@5: 100.0000 (95.7422)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1060/3125]  eta: 0:13:28  Lr: 0.030000  Loss: -1.3523  Acc@1: 81.2500 (77.0794)  Acc@5: 100.0000 (95.7469)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1070/3125]  eta: 0:13:24  Lr: 0.030000  Loss: -1.5837  Acc@1: 81.2500 (77.1008)  Acc@5: 100.0000 (95.7633)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1080/3125]  eta: 0:13:20  Lr: 0.030000  Loss: -1.6460  Acc@1: 81.2500 (77.1161)  Acc@5: 100.0000 (95.7678)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1090/3125]  eta: 0:13:16  Lr: 0.030000  Loss: -0.7497  Acc@1: 75.0000 (77.1311)  Acc@5: 100.0000 (95.7837)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1100/3125]  eta: 0:13:12  Lr: 0.030000  Loss: -0.6192  Acc@1: 81.2500 (77.1571)  Acc@5: 100.0000 (95.8050)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1110/3125]  eta: 0:13:09  Lr: 0.030000  Loss: -1.3178  Acc@1: 81.2500 (77.1883)  Acc@5: 100.0000 (95.8427)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1120/3125]  eta: 0:13:05  Lr: 0.030000  Loss: -1.4846  Acc@1: 81.2500 (77.2748)  Acc@5: 100.0000 (95.8631)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1130/3125]  eta: 0:13:01  Lr: 0.030000  Loss: -1.3307  Acc@1: 81.2500 (77.3265)  Acc@5: 100.0000 (95.8720)  time: 0.3903  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1140/3125]  eta: 0:12:57  Lr: 0.030000  Loss: -0.8372  Acc@1: 81.2500 (77.3663)  Acc@5: 100.0000 (95.8699)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1150/3125]  eta: 0:12:53  Lr: 0.030000  Loss: -1.4636  Acc@1: 87.5000 (77.4490)  Acc@5: 100.0000 (95.8732)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1160/3125]  eta: 0:12:49  Lr: 0.030000  Loss: -1.3988  Acc@1: 81.2500 (77.4817)  Acc@5: 100.0000 (95.8925)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1170/3125]  eta: 0:12:45  Lr: 0.030000  Loss: -0.9053  Acc@1: 81.2500 (77.5085)  Acc@5: 100.0000 (95.8849)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1180/3125]  eta: 0:12:41  Lr: 0.030000  Loss: -1.7041  Acc@1: 81.2500 (77.5508)  Acc@5: 100.0000 (95.9039)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1190/3125]  eta: 0:12:37  Lr: 0.030000  Loss: -0.9967  Acc@1: 81.2500 (77.5871)  Acc@5: 100.0000 (95.9120)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1200/3125]  eta: 0:12:33  Lr: 0.030000  Loss: -1.1969  Acc@1: 75.0000 (77.5812)  Acc@5: 100.0000 (95.9357)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1210/3125]  eta: 0:12:29  Lr: 0.030000  Loss: -1.0627  Acc@1: 81.2500 (77.5908)  Acc@5: 93.7500 (95.9228)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1220/3125]  eta: 0:12:25  Lr: 0.030000  Loss: -1.3840  Acc@1: 81.2500 (77.6515)  Acc@5: 93.7500 (95.9152)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1230/3125]  eta: 0:12:21  Lr: 0.030000  Loss: -1.2940  Acc@1: 81.2500 (77.6249)  Acc@5: 100.0000 (95.9383)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1240/3125]  eta: 0:12:17  Lr: 0.030000  Loss: -1.2859  Acc@1: 81.2500 (77.6491)  Acc@5: 100.0000 (95.9458)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1250/3125]  eta: 0:12:14  Lr: 0.030000  Loss: -1.5839  Acc@1: 87.5000 (77.7028)  Acc@5: 100.0000 (95.9482)  time: 0.3921  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1260/3125]  eta: 0:12:10  Lr: 0.030000  Loss: -1.4391  Acc@1: 81.2500 (77.7409)  Acc@5: 100.0000 (95.9754)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1270/3125]  eta: 0:12:06  Lr: 0.030000  Loss: -1.6874  Acc@1: 81.2500 (77.7931)  Acc@5: 100.0000 (95.9874)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1280/3125]  eta: 0:12:02  Lr: 0.030000  Loss: -1.6085  Acc@1: 87.5000 (77.8689)  Acc@5: 100.0000 (96.0041)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1290/3125]  eta: 0:11:58  Lr: 0.030000  Loss: -1.6192  Acc@1: 87.5000 (77.9096)  Acc@5: 100.0000 (96.0157)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1300/3125]  eta: 0:11:54  Lr: 0.030000  Loss: -1.4480  Acc@1: 81.2500 (77.9689)  Acc@5: 100.0000 (96.0415)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1310/3125]  eta: 0:11:50  Lr: 0.030000  Loss: -1.5772  Acc@1: 81.2500 (77.9987)  Acc@5: 100.0000 (96.0622)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1320/3125]  eta: 0:11:46  Lr: 0.030000  Loss: -1.5848  Acc@1: 81.2500 (78.0185)  Acc@5: 100.0000 (96.0825)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1330/3125]  eta: 0:11:42  Lr: 0.030000  Loss: -1.5762  Acc@1: 81.2500 (78.0334)  Acc@5: 100.0000 (96.0932)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1340/3125]  eta: 0:11:38  Lr: 0.030000  Loss: -0.9138  Acc@1: 81.2500 (78.0574)  Acc@5: 100.0000 (96.0990)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1350/3125]  eta: 0:11:34  Lr: 0.030000  Loss: -0.7488  Acc@1: 81.2500 (78.0949)  Acc@5: 93.7500 (96.0955)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1360/3125]  eta: 0:11:30  Lr: 0.030000  Loss: -1.7683  Acc@1: 87.5000 (78.1548)  Acc@5: 100.0000 (96.1058)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1370/3125]  eta: 0:11:27  Lr: 0.030000  Loss: -1.1428  Acc@1: 87.5000 (78.1911)  Acc@5: 100.0000 (96.1205)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1380/3125]  eta: 0:11:23  Lr: 0.030000  Loss: -1.1791  Acc@1: 87.5000 (78.2314)  Acc@5: 100.0000 (96.1350)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1390/3125]  eta: 0:11:19  Lr: 0.030000  Loss: -1.3315  Acc@1: 87.5000 (78.3205)  Acc@5: 100.0000 (96.1538)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1400/3125]  eta: 0:11:15  Lr: 0.030000  Loss: -1.1762  Acc@1: 87.5000 (78.3503)  Acc@5: 100.0000 (96.1590)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1410/3125]  eta: 0:11:11  Lr: 0.030000  Loss: -1.1508  Acc@1: 81.2500 (78.3753)  Acc@5: 100.0000 (96.1729)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1420/3125]  eta: 0:11:07  Lr: 0.030000  Loss: -1.5007  Acc@1: 87.5000 (78.4483)  Acc@5: 100.0000 (96.1867)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1430/3125]  eta: 0:11:03  Lr: 0.030000  Loss: -1.2222  Acc@1: 87.5000 (78.4766)  Acc@5: 100.0000 (96.2046)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1440/3125]  eta: 0:10:59  Lr: 0.030000  Loss: -1.4905  Acc@1: 81.2500 (78.5175)  Acc@5: 100.0000 (96.2136)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1450/3125]  eta: 0:10:55  Lr: 0.030000  Loss: -1.7776  Acc@1: 81.2500 (78.5536)  Acc@5: 100.0000 (96.2138)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1460/3125]  eta: 0:10:51  Lr: 0.030000  Loss: -0.9913  Acc@1: 81.2500 (78.5806)  Acc@5: 100.0000 (96.2355)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1470/3125]  eta: 0:10:47  Lr: 0.030000  Loss: -1.3688  Acc@1: 87.5000 (78.6115)  Acc@5: 100.0000 (96.2483)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1480/3125]  eta: 0:10:43  Lr: 0.030000  Loss: -1.4716  Acc@1: 81.2500 (78.6377)  Acc@5: 100.0000 (96.2357)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1490/3125]  eta: 0:10:39  Lr: 0.030000  Loss: -1.4884  Acc@1: 81.2500 (78.6720)  Acc@5: 100.0000 (96.2357)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1500/3125]  eta: 0:10:36  Lr: 0.030000  Loss: -1.4086  Acc@1: 81.2500 (78.6767)  Acc@5: 100.0000 (96.2483)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1510/3125]  eta: 0:10:32  Lr: 0.030000  Loss: -1.3168  Acc@1: 81.2500 (78.7103)  Acc@5: 100.0000 (96.2442)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1520/3125]  eta: 0:10:28  Lr: 0.030000  Loss: -1.4781  Acc@1: 87.5000 (78.7558)  Acc@5: 93.7500 (96.2442)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1530/3125]  eta: 0:10:24  Lr: 0.030000  Loss: -1.3567  Acc@1: 81.2500 (78.7884)  Acc@5: 93.7500 (96.2443)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1540/3125]  eta: 0:10:20  Lr: 0.030000  Loss: -0.8438  Acc@1: 81.2500 (78.7841)  Acc@5: 93.7500 (96.2484)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1550/3125]  eta: 0:10:16  Lr: 0.030000  Loss: -1.3547  Acc@1: 81.2500 (78.8000)  Acc@5: 93.7500 (96.2444)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1560/3125]  eta: 0:10:12  Lr: 0.030000  Loss: -1.5736  Acc@1: 81.2500 (78.8437)  Acc@5: 93.7500 (96.2404)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1570/3125]  eta: 0:10:08  Lr: 0.030000  Loss: -0.5691  Acc@1: 81.2500 (78.8590)  Acc@5: 93.7500 (96.2245)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1580/3125]  eta: 0:10:04  Lr: 0.030000  Loss: -1.4476  Acc@1: 87.5000 (78.8899)  Acc@5: 93.7500 (96.2326)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1590/3125]  eta: 0:10:00  Lr: 0.030000  Loss: -1.4392  Acc@1: 87.5000 (78.9008)  Acc@5: 100.0000 (96.2406)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1600/3125]  eta: 0:09:56  Lr: 0.030000  Loss: -0.8610  Acc@1: 81.2500 (78.9233)  Acc@5: 100.0000 (96.2562)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1610/3125]  eta: 0:09:52  Lr: 0.030000  Loss: -1.5643  Acc@1: 81.2500 (78.9610)  Acc@5: 100.0000 (96.2717)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1620/3125]  eta: 0:09:48  Lr: 0.030000  Loss: -0.9001  Acc@1: 87.5000 (79.0099)  Acc@5: 100.0000 (96.2832)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1630/3125]  eta: 0:09:44  Lr: 0.030000  Loss: -1.6921  Acc@1: 81.2500 (78.9853)  Acc@5: 100.0000 (96.2830)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1640/3125]  eta: 0:09:41  Lr: 0.030000  Loss: -1.2096  Acc@1: 81.2500 (78.9915)  Acc@5: 100.0000 (96.2828)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1650/3125]  eta: 0:09:37  Lr: 0.030000  Loss: -1.6423  Acc@1: 81.2500 (79.0089)  Acc@5: 100.0000 (96.2863)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1660/3125]  eta: 0:09:33  Lr: 0.030000  Loss: -1.4809  Acc@1: 81.2500 (79.0300)  Acc@5: 100.0000 (96.3049)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1670/3125]  eta: 0:09:29  Lr: 0.030000  Loss: -1.4641  Acc@1: 81.2500 (79.0507)  Acc@5: 100.0000 (96.3158)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1680/3125]  eta: 0:09:25  Lr: 0.030000  Loss: -1.4184  Acc@1: 81.2500 (79.0675)  Acc@5: 100.0000 (96.3080)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1690/3125]  eta: 0:09:21  Lr: 0.030000  Loss: -1.3673  Acc@1: 87.5000 (79.1137)  Acc@5: 93.7500 (96.3114)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1700/3125]  eta: 0:09:17  Lr: 0.030000  Loss: -1.2744  Acc@1: 87.5000 (79.1262)  Acc@5: 100.0000 (96.3147)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1710/3125]  eta: 0:09:13  Lr: 0.030000  Loss: -1.5424  Acc@1: 81.2500 (79.1460)  Acc@5: 100.0000 (96.3216)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1720/3125]  eta: 0:09:09  Lr: 0.030000  Loss: -1.0017  Acc@1: 87.5000 (79.1872)  Acc@5: 100.0000 (96.3321)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1730/3125]  eta: 0:09:05  Lr: 0.030000  Loss: -1.4728  Acc@1: 87.5000 (79.2353)  Acc@5: 100.0000 (96.3460)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1740/3125]  eta: 0:09:01  Lr: 0.030000  Loss: -0.9634  Acc@1: 81.2500 (79.2253)  Acc@5: 100.0000 (96.3455)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1750/3125]  eta: 0:08:57  Lr: 0.030000  Loss: -1.3078  Acc@1: 81.2500 (79.2511)  Acc@5: 100.0000 (96.3521)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1760/3125]  eta: 0:08:53  Lr: 0.030000  Loss: -1.7423  Acc@1: 87.5000 (79.2767)  Acc@5: 100.0000 (96.3657)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1770/3125]  eta: 0:08:49  Lr: 0.030000  Loss: -0.7669  Acc@1: 87.5000 (79.3196)  Acc@5: 100.0000 (96.3721)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1780/3125]  eta: 0:08:46  Lr: 0.030000  Loss: -1.6182  Acc@1: 87.5000 (79.3445)  Acc@5: 100.0000 (96.3890)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1790/3125]  eta: 0:08:42  Lr: 0.030000  Loss: -0.9379  Acc@1: 81.2500 (79.3307)  Acc@5: 100.0000 (96.3882)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1800/3125]  eta: 0:08:38  Lr: 0.030000  Loss: -1.7438  Acc@1: 81.2500 (79.3795)  Acc@5: 100.0000 (96.3909)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1810/3125]  eta: 0:08:34  Lr: 0.030000  Loss: -1.2435  Acc@1: 87.5000 (79.4071)  Acc@5: 100.0000 (96.4005)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1820/3125]  eta: 0:08:30  Lr: 0.030000  Loss: -1.2127  Acc@1: 87.5000 (79.4550)  Acc@5: 100.0000 (96.4202)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1830/3125]  eta: 0:08:26  Lr: 0.030000  Loss: -1.4874  Acc@1: 87.5000 (79.4648)  Acc@5: 100.0000 (96.4364)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1840/3125]  eta: 0:08:22  Lr: 0.030000  Loss: -1.4803  Acc@1: 81.2500 (79.4745)  Acc@5: 100.0000 (96.4523)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1850/3125]  eta: 0:08:18  Lr: 0.030000  Loss: -0.8146  Acc@1: 81.2500 (79.5043)  Acc@5: 100.0000 (96.4479)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1860/3125]  eta: 0:08:14  Lr: 0.030000  Loss: -1.1275  Acc@1: 81.2500 (79.5003)  Acc@5: 100.0000 (96.4602)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1870/3125]  eta: 0:08:10  Lr: 0.030000  Loss: -1.5428  Acc@1: 81.2500 (79.5196)  Acc@5: 100.0000 (96.4725)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1880/3125]  eta: 0:08:06  Lr: 0.030000  Loss: -1.9072  Acc@1: 87.5000 (79.5754)  Acc@5: 100.0000 (96.4879)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1890/3125]  eta: 0:08:03  Lr: 0.030000  Loss: -1.3819  Acc@1: 87.5000 (79.5941)  Acc@5: 100.0000 (96.4900)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:59  Lr: 0.030000  Loss: -1.0762  Acc@1: 81.2500 (79.6127)  Acc@5: 100.0000 (96.4920)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1910/3125]  eta: 0:07:55  Lr: 0.030000  Loss: -1.6877  Acc@1: 81.2500 (79.6245)  Acc@5: 93.7500 (96.4907)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1920/3125]  eta: 0:07:51  Lr: 0.030000  Loss: -1.1235  Acc@1: 81.2500 (79.6525)  Acc@5: 100.0000 (96.4992)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1930/3125]  eta: 0:07:47  Lr: 0.030000  Loss: -0.9624  Acc@1: 81.2500 (79.6511)  Acc@5: 100.0000 (96.4915)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1940/3125]  eta: 0:07:43  Lr: 0.030000  Loss: -1.2229  Acc@1: 81.2500 (79.6722)  Acc@5: 100.0000 (96.4967)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1950/3125]  eta: 0:07:39  Lr: 0.030000  Loss: -1.2733  Acc@1: 81.2500 (79.6771)  Acc@5: 100.0000 (96.5082)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1960/3125]  eta: 0:07:35  Lr: 0.030000  Loss: -1.1355  Acc@1: 81.2500 (79.7074)  Acc@5: 100.0000 (96.5196)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1970/3125]  eta: 0:07:31  Lr: 0.030000  Loss: -1.6940  Acc@1: 81.2500 (79.7374)  Acc@5: 100.0000 (96.5183)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1980/3125]  eta: 0:07:27  Lr: 0.030000  Loss: -1.4672  Acc@1: 81.2500 (79.7388)  Acc@5: 93.7500 (96.5169)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1990/3125]  eta: 0:07:23  Lr: 0.030000  Loss: -1.5482  Acc@1: 87.5000 (79.7777)  Acc@5: 100.0000 (96.5250)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2000/3125]  eta: 0:07:19  Lr: 0.030000  Loss: -1.5615  Acc@1: 87.5000 (79.7820)  Acc@5: 100.0000 (96.5267)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2010/3125]  eta: 0:07:16  Lr: 0.030000  Loss: -1.3679  Acc@1: 81.2500 (79.7831)  Acc@5: 100.0000 (96.5347)  time: 0.3929  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2020/3125]  eta: 0:07:12  Lr: 0.030000  Loss: -1.4986  Acc@1: 81.2500 (79.7965)  Acc@5: 100.0000 (96.5364)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2030/3125]  eta: 0:07:08  Lr: 0.030000  Loss: -1.8647  Acc@1: 81.2500 (79.8344)  Acc@5: 100.0000 (96.5473)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2040/3125]  eta: 0:07:04  Lr: 0.030000  Loss: -1.1751  Acc@1: 81.2500 (79.8444)  Acc@5: 100.0000 (96.5427)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2050/3125]  eta: 0:07:00  Lr: 0.030000  Loss: -1.0081  Acc@1: 81.2500 (79.8574)  Acc@5: 93.7500 (96.5383)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:56  Lr: 0.030000  Loss: -0.9114  Acc@1: 87.5000 (79.8823)  Acc@5: 100.0000 (96.5520)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:52  Lr: 0.030000  Loss: -1.6822  Acc@1: 87.5000 (79.9101)  Acc@5: 100.0000 (96.5476)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2080/3125]  eta: 0:06:48  Lr: 0.030000  Loss: -1.7278  Acc@1: 87.5000 (79.9285)  Acc@5: 100.0000 (96.5521)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2090/3125]  eta: 0:06:44  Lr: 0.030000  Loss: -1.4857  Acc@1: 81.2500 (79.9408)  Acc@5: 100.0000 (96.5626)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2100/3125]  eta: 0:06:40  Lr: 0.030000  Loss: -1.5813  Acc@1: 87.5000 (79.9798)  Acc@5: 100.0000 (96.5671)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2110/3125]  eta: 0:06:36  Lr: 0.030000  Loss: -1.2705  Acc@1: 87.5000 (79.9828)  Acc@5: 100.0000 (96.5715)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2120/3125]  eta: 0:06:33  Lr: 0.030000  Loss: -1.5011  Acc@1: 81.2500 (79.9888)  Acc@5: 100.0000 (96.5818)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2130/3125]  eta: 0:06:29  Lr: 0.030000  Loss: -1.1622  Acc@1: 87.5000 (80.0182)  Acc@5: 100.0000 (96.5861)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2140/3125]  eta: 0:06:25  Lr: 0.030000  Loss: -1.0360  Acc@1: 87.5000 (80.0473)  Acc@5: 100.0000 (96.5845)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2150/3125]  eta: 0:06:21  Lr: 0.030000  Loss: -1.1703  Acc@1: 87.5000 (80.0761)  Acc@5: 100.0000 (96.5946)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2160/3125]  eta: 0:06:17  Lr: 0.030000  Loss: -1.0475  Acc@1: 87.5000 (80.0845)  Acc@5: 100.0000 (96.5959)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2170/3125]  eta: 0:06:13  Lr: 0.030000  Loss: -1.1862  Acc@1: 81.2500 (80.1157)  Acc@5: 100.0000 (96.6029)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2180/3125]  eta: 0:06:09  Lr: 0.030000  Loss: -1.3218  Acc@1: 87.5000 (80.1267)  Acc@5: 100.0000 (96.6042)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2190/3125]  eta: 0:06:05  Lr: 0.030000  Loss: -1.2754  Acc@1: 87.5000 (80.1546)  Acc@5: 100.0000 (96.6026)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2200/3125]  eta: 0:06:01  Lr: 0.030000  Loss: -1.6206  Acc@1: 87.5000 (80.1823)  Acc@5: 100.0000 (96.6095)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:57  Lr: 0.030000  Loss: -1.5812  Acc@1: 87.5000 (80.2154)  Acc@5: 100.0000 (96.6220)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:53  Lr: 0.030000  Loss: -1.8285  Acc@1: 87.5000 (80.2229)  Acc@5: 100.0000 (96.6316)  time: 0.3897  data: 0.0006  max mem: 2912
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:49  Lr: 0.030000  Loss: -1.4502  Acc@1: 81.2500 (80.1995)  Acc@5: 93.7500 (96.6187)  time: 0.3901  data: 0.0006  max mem: 2912
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:46  Lr: 0.030000  Loss: -1.2090  Acc@1: 81.2500 (80.2209)  Acc@5: 93.7500 (96.6254)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:42  Lr: 0.030000  Loss: -1.1713  Acc@1: 81.2500 (80.2199)  Acc@5: 100.0000 (96.6348)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2260/3125]  eta: 0:05:38  Lr: 0.030000  Loss: -1.2188  Acc@1: 81.2500 (80.2410)  Acc@5: 100.0000 (96.6442)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2270/3125]  eta: 0:05:34  Lr: 0.030000  Loss: -1.6634  Acc@1: 81.2500 (80.2592)  Acc@5: 100.0000 (96.6452)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2280/3125]  eta: 0:05:30  Lr: 0.030000  Loss: -1.3026  Acc@1: 81.2500 (80.2773)  Acc@5: 100.0000 (96.6517)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2290/3125]  eta: 0:05:26  Lr: 0.030000  Loss: -1.7527  Acc@1: 87.5000 (80.3006)  Acc@5: 100.0000 (96.6581)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2300/3125]  eta: 0:05:22  Lr: 0.030000  Loss: -1.6513  Acc@1: 87.5000 (80.3183)  Acc@5: 100.0000 (96.6618)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2310/3125]  eta: 0:05:18  Lr: 0.030000  Loss: -0.7379  Acc@1: 87.5000 (80.3116)  Acc@5: 93.7500 (96.6546)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2320/3125]  eta: 0:05:14  Lr: 0.030000  Loss: -1.5709  Acc@1: 87.5000 (80.3264)  Acc@5: 93.7500 (96.6555)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2330/3125]  eta: 0:05:10  Lr: 0.030000  Loss: -1.2576  Acc@1: 87.5000 (80.3384)  Acc@5: 100.0000 (96.6618)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2340/3125]  eta: 0:05:06  Lr: 0.030000  Loss: -1.4698  Acc@1: 87.5000 (80.3636)  Acc@5: 100.0000 (96.6681)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2350/3125]  eta: 0:05:03  Lr: 0.030000  Loss: -0.6105  Acc@1: 87.5000 (80.3807)  Acc@5: 100.0000 (96.6743)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:59  Lr: 0.030000  Loss: -1.6151  Acc@1: 81.2500 (80.3764)  Acc@5: 100.0000 (96.6672)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:55  Lr: 0.030000  Loss: -1.3665  Acc@1: 81.2500 (80.3801)  Acc@5: 100.0000 (96.6707)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:51  Lr: 0.030000  Loss: -1.1603  Acc@1: 81.2500 (80.4021)  Acc@5: 100.0000 (96.6768)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:47  Lr: 0.030000  Loss: -1.5704  Acc@1: 81.2500 (80.4266)  Acc@5: 100.0000 (96.6750)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:43  Lr: 0.030000  Loss: -1.0841  Acc@1: 81.2500 (80.4300)  Acc@5: 93.7500 (96.6655)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:39  Lr: 0.030000  Loss: -1.2110  Acc@1: 81.2500 (80.4619)  Acc@5: 100.0000 (96.6767)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:35  Lr: 0.030000  Loss: -1.5330  Acc@1: 87.5000 (80.4910)  Acc@5: 100.0000 (96.6801)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2430/3125]  eta: 0:04:31  Lr: 0.030000  Loss: -1.2199  Acc@1: 87.5000 (80.5070)  Acc@5: 100.0000 (96.6912)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2440/3125]  eta: 0:04:27  Lr: 0.030000  Loss: -1.0417  Acc@1: 87.5000 (80.5254)  Acc@5: 100.0000 (96.6919)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2450/3125]  eta: 0:04:23  Lr: 0.030000  Loss: -1.1297  Acc@1: 87.5000 (80.5513)  Acc@5: 100.0000 (96.7029)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2460/3125]  eta: 0:04:19  Lr: 0.030000  Loss: -0.9803  Acc@1: 87.5000 (80.5770)  Acc@5: 100.0000 (96.7163)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2470/3125]  eta: 0:04:16  Lr: 0.030000  Loss: -1.3180  Acc@1: 87.5000 (80.6000)  Acc@5: 100.0000 (96.7220)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2480/3125]  eta: 0:04:12  Lr: 0.030000  Loss: -1.4056  Acc@1: 87.5000 (80.6303)  Acc@5: 100.0000 (96.7251)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2490/3125]  eta: 0:04:08  Lr: 0.030000  Loss: -1.4379  Acc@1: 87.5000 (80.6503)  Acc@5: 100.0000 (96.7332)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2500/3125]  eta: 0:04:04  Lr: 0.030000  Loss: -1.7212  Acc@1: 87.5000 (80.6627)  Acc@5: 100.0000 (96.7363)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2510/3125]  eta: 0:04:00  Lr: 0.030000  Loss: -1.0426  Acc@1: 87.5000 (80.6750)  Acc@5: 100.0000 (96.7418)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:56  Lr: 0.030000  Loss: -1.3651  Acc@1: 81.2500 (80.6649)  Acc@5: 100.0000 (96.7473)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:52  Lr: 0.030000  Loss: -1.3925  Acc@1: 81.2500 (80.6697)  Acc@5: 100.0000 (96.7478)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:48  Lr: 0.030000  Loss: -1.2896  Acc@1: 81.2500 (80.6818)  Acc@5: 93.7500 (96.7409)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:44  Lr: 0.030000  Loss: -1.5634  Acc@1: 87.5000 (80.7208)  Acc@5: 100.0000 (96.7488)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:40  Lr: 0.030000  Loss: -0.8861  Acc@1: 87.5000 (80.7351)  Acc@5: 100.0000 (96.7493)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:37  Lr: 0.030000  Loss: -0.7906  Acc@1: 87.5000 (80.7541)  Acc@5: 100.0000 (96.7571)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:33  Lr: 0.030000  Loss: -1.3097  Acc@1: 87.5000 (80.7657)  Acc@5: 100.0000 (96.7576)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:29  Lr: 0.030000  Loss: -1.4378  Acc@1: 87.5000 (80.7917)  Acc@5: 100.0000 (96.7628)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:25  Lr: 0.030000  Loss: -1.5259  Acc@1: 87.5000 (80.8199)  Acc@5: 100.0000 (96.7633)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2610/3125]  eta: 0:03:21  Lr: 0.030000  Loss: -1.4828  Acc@1: 87.5000 (80.8359)  Acc@5: 100.0000 (96.7709)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2620/3125]  eta: 0:03:17  Lr: 0.030000  Loss: -1.6947  Acc@1: 87.5000 (80.8756)  Acc@5: 100.0000 (96.7808)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2630/3125]  eta: 0:03:13  Lr: 0.030000  Loss: -1.3589  Acc@1: 93.7500 (80.9008)  Acc@5: 100.0000 (96.7883)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2640/3125]  eta: 0:03:09  Lr: 0.030000  Loss: -1.6903  Acc@1: 87.5000 (80.9187)  Acc@5: 100.0000 (96.7981)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2650/3125]  eta: 0:03:05  Lr: 0.030000  Loss: -1.0712  Acc@1: 87.5000 (80.9388)  Acc@5: 100.0000 (96.8078)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2660/3125]  eta: 0:03:01  Lr: 0.030000  Loss: -1.6246  Acc@1: 87.5000 (80.9470)  Acc@5: 100.0000 (96.8151)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:57  Lr: 0.030000  Loss: -0.8131  Acc@1: 87.5000 (80.9622)  Acc@5: 100.0000 (96.8200)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:54  Lr: 0.030000  Loss: -0.7499  Acc@1: 87.5000 (80.9679)  Acc@5: 100.0000 (96.8249)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:50  Lr: 0.030000  Loss: -1.2170  Acc@1: 81.2500 (80.9783)  Acc@5: 100.0000 (96.8227)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:46  Lr: 0.030000  Loss: -0.3699  Acc@1: 81.2500 (80.9700)  Acc@5: 93.7500 (96.8160)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:42  Lr: 0.030000  Loss: -1.3397  Acc@1: 87.5000 (80.9964)  Acc@5: 100.0000 (96.8254)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:38  Lr: 0.030000  Loss: -1.8282  Acc@1: 87.5000 (81.0295)  Acc@5: 100.0000 (96.8348)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:34  Lr: 0.030000  Loss: -1.2325  Acc@1: 81.2500 (81.0372)  Acc@5: 100.0000 (96.8418)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:30  Lr: 0.030000  Loss: -1.4040  Acc@1: 81.2500 (81.0357)  Acc@5: 100.0000 (96.8511)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:26  Lr: 0.030000  Loss: -1.3526  Acc@1: 81.2500 (81.0364)  Acc@5: 100.0000 (96.8534)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:22  Lr: 0.030000  Loss: -1.0863  Acc@1: 87.5000 (81.0599)  Acc@5: 100.0000 (96.8580)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:18  Lr: 0.030000  Loss: -1.7165  Acc@1: 87.5000 (81.0583)  Acc@5: 100.0000 (96.8649)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2780/3125]  eta: 0:02:14  Lr: 0.030000  Loss: -1.7869  Acc@1: 87.5000 (81.0859)  Acc@5: 100.0000 (96.8671)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2790/3125]  eta: 0:02:10  Lr: 0.030000  Loss: -0.9187  Acc@1: 87.5000 (81.0932)  Acc@5: 100.0000 (96.8716)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2800/3125]  eta: 0:02:07  Lr: 0.030000  Loss: -1.6536  Acc@1: 81.2500 (81.0983)  Acc@5: 100.0000 (96.8739)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2810/3125]  eta: 0:02:03  Lr: 0.030000  Loss: -1.5762  Acc@1: 81.2500 (81.1144)  Acc@5: 100.0000 (96.8828)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:59  Lr: 0.030000  Loss: -0.9661  Acc@1: 81.2500 (81.1149)  Acc@5: 100.0000 (96.8916)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:55  Lr: 0.030000  Loss: -1.6895  Acc@1: 81.2500 (81.1242)  Acc@5: 100.0000 (96.8894)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:51  Lr: 0.030000  Loss: -1.4309  Acc@1: 81.2500 (81.1136)  Acc@5: 93.7500 (96.8849)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:47  Lr: 0.030000  Loss: -0.8789  Acc@1: 81.2500 (81.1119)  Acc@5: 100.0000 (96.8914)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:43  Lr: 0.030000  Loss: -1.0284  Acc@1: 81.2500 (81.1146)  Acc@5: 100.0000 (96.8914)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:39  Lr: 0.030000  Loss: -1.6688  Acc@1: 87.5000 (81.1455)  Acc@5: 100.0000 (96.9000)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:35  Lr: 0.030000  Loss: -1.1848  Acc@1: 87.5000 (81.1545)  Acc@5: 100.0000 (96.8956)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:31  Lr: 0.030000  Loss: -1.7581  Acc@1: 87.5000 (81.1743)  Acc@5: 100.0000 (96.9042)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:27  Lr: 0.030000  Loss: -1.4975  Acc@1: 87.5000 (81.1940)  Acc@5: 100.0000 (96.9127)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:24  Lr: 0.030000  Loss: -1.6831  Acc@1: 87.5000 (81.2028)  Acc@5: 100.0000 (96.9190)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:20  Lr: 0.030000  Loss: -1.6612  Acc@1: 87.5000 (81.2200)  Acc@5: 100.0000 (96.9274)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:16  Lr: 0.030000  Loss: -1.5971  Acc@1: 87.5000 (81.2308)  Acc@5: 100.0000 (96.9336)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:12  Lr: 0.030000  Loss: -1.6367  Acc@1: 87.5000 (81.2415)  Acc@5: 100.0000 (96.9398)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:08  Lr: 0.030000  Loss: -1.6136  Acc@1: 87.5000 (81.2542)  Acc@5: 100.0000 (96.9396)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2960/3125]  eta: 0:01:04  Lr: 0.030000  Loss: -1.5201  Acc@1: 87.5000 (81.2859)  Acc@5: 100.0000 (96.9499)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2970/3125]  eta: 0:01:00  Lr: 0.030000  Loss: -1.5513  Acc@1: 87.5000 (81.2858)  Acc@5: 100.0000 (96.9539)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:56  Lr: 0.030000  Loss: -1.4993  Acc@1: 87.5000 (81.3045)  Acc@5: 100.0000 (96.9578)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:52  Lr: 0.030000  Loss: -1.6779  Acc@1: 87.5000 (81.3169)  Acc@5: 100.0000 (96.9575)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:48  Lr: 0.030000  Loss: -1.7684  Acc@1: 87.5000 (81.3437)  Acc@5: 100.0000 (96.9593)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:44  Lr: 0.030000  Loss: -1.0380  Acc@1: 87.5000 (81.3683)  Acc@5: 100.0000 (96.9694)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:41  Lr: 0.030000  Loss: -1.8449  Acc@1: 87.5000 (81.3762)  Acc@5: 100.0000 (96.9712)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:37  Lr: 0.030000  Loss: -0.9510  Acc@1: 81.2500 (81.3882)  Acc@5: 100.0000 (96.9668)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:33  Lr: 0.030000  Loss: -1.1663  Acc@1: 81.2500 (81.3959)  Acc@5: 93.7500 (96.9665)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:29  Lr: 0.030000  Loss: -1.3375  Acc@1: 87.5000 (81.4139)  Acc@5: 100.0000 (96.9662)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:25  Lr: 0.030000  Loss: -1.2237  Acc@1: 87.5000 (81.4236)  Acc@5: 100.0000 (96.9659)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:21  Lr: 0.030000  Loss: -1.4763  Acc@1: 87.5000 (81.4454)  Acc@5: 100.0000 (96.9737)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:17  Lr: 0.030000  Loss: -1.1331  Acc@1: 81.2500 (81.4387)  Acc@5: 100.0000 (96.9774)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:13  Lr: 0.030000  Loss: -1.3922  Acc@1: 81.2500 (81.4401)  Acc@5: 100.0000 (96.9812)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:09  Lr: 0.030000  Loss: -1.1606  Acc@1: 81.2500 (81.4374)  Acc@5: 100.0000 (96.9848)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: -1.2718  Acc@1: 75.0000 (81.4368)  Acc@5: 100.0000 (96.9885)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: -1.4882  Acc@1: 81.2500 (81.4402)  Acc@5: 100.0000 (96.9921)  time: 0.3908  data: 0.0007  max mem: 2912
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: -1.2892  Acc@1: 81.2500 (81.4540)  Acc@5: 100.0000 (96.9960)  time: 0.3904  data: 0.0007  max mem: 2912
Train: Epoch[1/5] Total time: 0:20:22 (0.3911 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.2892  Acc@1: 81.2500 (81.4540)  Acc@5: 100.0000 (96.9960)
Train: Epoch[2/5]  [   0/3125]  eta: 0:51:03  Lr: 0.030000  Loss: -0.3080  Acc@1: 50.0000 (50.0000)  Acc@5: 87.5000 (87.5000)  time: 0.9802  data: 0.5807  max mem: 2912
Train: Epoch[2/5]  [  10/3125]  eta: 0:23:05  Lr: 0.030000  Loss: -1.5058  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (97.7273)  time: 0.4447  data: 0.0531  max mem: 2912
Train: Epoch[2/5]  [  20/3125]  eta: 0:21:43  Lr: 0.030000  Loss: -1.5444  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (98.5119)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [  30/3125]  eta: 0:21:10  Lr: 0.030000  Loss: -1.4754  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (98.3871)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  40/3125]  eta: 0:20:52  Lr: 0.030000  Loss: -0.8615  Acc@1: 81.2500 (82.0122)  Acc@5: 100.0000 (97.8659)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  50/3125]  eta: 0:20:37  Lr: 0.030000  Loss: -1.5573  Acc@1: 87.5000 (83.0882)  Acc@5: 100.0000 (98.1618)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  60/3125]  eta: 0:20:28  Lr: 0.030000  Loss: -1.1973  Acc@1: 81.2500 (82.8893)  Acc@5: 100.0000 (97.8484)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  70/3125]  eta: 0:20:19  Lr: 0.030000  Loss: -1.6274  Acc@1: 81.2500 (83.7148)  Acc@5: 100.0000 (97.8873)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [  80/3125]  eta: 0:20:13  Lr: 0.030000  Loss: -1.3741  Acc@1: 87.5000 (84.0278)  Acc@5: 93.7500 (97.4537)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  90/3125]  eta: 0:20:06  Lr: 0.030000  Loss: -1.6095  Acc@1: 87.5000 (84.4093)  Acc@5: 93.7500 (97.4588)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 100/3125]  eta: 0:20:01  Lr: 0.030000  Loss: -1.1916  Acc@1: 87.5000 (84.1584)  Acc@5: 100.0000 (97.4629)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 110/3125]  eta: 0:19:56  Lr: 0.030000  Loss: -1.5758  Acc@1: 87.5000 (84.1216)  Acc@5: 100.0000 (97.6351)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 120/3125]  eta: 0:19:51  Lr: 0.030000  Loss: -1.2697  Acc@1: 81.2500 (83.6777)  Acc@5: 100.0000 (97.4174)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 130/3125]  eta: 0:19:45  Lr: 0.030000  Loss: -1.1169  Acc@1: 81.2500 (83.6832)  Acc@5: 100.0000 (97.5191)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 140/3125]  eta: 0:19:40  Lr: 0.030000  Loss: -0.9011  Acc@1: 81.2500 (83.5993)  Acc@5: 100.0000 (97.4734)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 150/3125]  eta: 0:19:36  Lr: 0.030000  Loss: -1.7191  Acc@1: 81.2500 (83.5265)  Acc@5: 100.0000 (97.4338)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 160/3125]  eta: 0:19:31  Lr: 0.030000  Loss: -1.3778  Acc@1: 81.2500 (83.5792)  Acc@5: 100.0000 (97.5543)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 170/3125]  eta: 0:19:26  Lr: 0.030000  Loss: -1.4346  Acc@1: 87.5000 (83.8450)  Acc@5: 100.0000 (97.5877)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 180/3125]  eta: 0:19:21  Lr: 0.030000  Loss: -1.6868  Acc@1: 87.5000 (83.9779)  Acc@5: 100.0000 (97.5829)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 190/3125]  eta: 0:19:16  Lr: 0.030000  Loss: -1.4387  Acc@1: 81.2500 (84.0314)  Acc@5: 100.0000 (97.5785)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 200/3125]  eta: 0:19:12  Lr: 0.030000  Loss: -1.4749  Acc@1: 81.2500 (83.9552)  Acc@5: 100.0000 (97.5746)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 210/3125]  eta: 0:19:08  Lr: 0.030000  Loss: -1.2935  Acc@1: 81.2500 (83.7974)  Acc@5: 100.0000 (97.5415)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 220/3125]  eta: 0:19:03  Lr: 0.030000  Loss: -1.5661  Acc@1: 81.2500 (83.8518)  Acc@5: 100.0000 (97.5113)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 230/3125]  eta: 0:18:59  Lr: 0.030000  Loss: -1.6846  Acc@1: 87.5000 (84.0097)  Acc@5: 100.0000 (97.5379)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 240/3125]  eta: 0:18:54  Lr: 0.030000  Loss: -1.5543  Acc@1: 87.5000 (84.2064)  Acc@5: 100.0000 (97.5622)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 250/3125]  eta: 0:18:50  Lr: 0.030000  Loss: -1.5561  Acc@1: 87.5000 (84.2629)  Acc@5: 100.0000 (97.5598)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 260/3125]  eta: 0:18:46  Lr: 0.030000  Loss: -1.6759  Acc@1: 87.5000 (84.3630)  Acc@5: 100.0000 (97.5575)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 270/3125]  eta: 0:18:41  Lr: 0.030000  Loss: -1.4424  Acc@1: 87.5000 (84.4788)  Acc@5: 100.0000 (97.6245)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 280/3125]  eta: 0:18:37  Lr: 0.030000  Loss: -1.7247  Acc@1: 87.5000 (84.4973)  Acc@5: 100.0000 (97.5979)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 290/3125]  eta: 0:18:33  Lr: 0.030000  Loss: -0.9607  Acc@1: 87.5000 (84.3428)  Acc@5: 100.0000 (97.5730)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 300/3125]  eta: 0:18:29  Lr: 0.030000  Loss: -1.5799  Acc@1: 87.5000 (84.4477)  Acc@5: 100.0000 (97.5498)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 310/3125]  eta: 0:18:24  Lr: 0.030000  Loss: -1.1811  Acc@1: 87.5000 (84.4654)  Acc@5: 100.0000 (97.5884)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 320/3125]  eta: 0:18:20  Lr: 0.030000  Loss: -1.7121  Acc@1: 87.5000 (84.5600)  Acc@5: 100.0000 (97.6051)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 330/3125]  eta: 0:18:16  Lr: 0.030000  Loss: -1.6748  Acc@1: 87.5000 (84.7054)  Acc@5: 100.0000 (97.6775)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 340/3125]  eta: 0:18:12  Lr: 0.030000  Loss: -1.0423  Acc@1: 87.5000 (84.6224)  Acc@5: 100.0000 (97.6723)  time: 0.3888  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 350/3125]  eta: 0:18:08  Lr: 0.030000  Loss: -1.1971  Acc@1: 81.2500 (84.5264)  Acc@5: 100.0000 (97.5962)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 360/3125]  eta: 0:18:04  Lr: 0.030000  Loss: -1.4637  Acc@1: 81.2500 (84.5395)  Acc@5: 93.7500 (97.5416)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 370/3125]  eta: 0:18:00  Lr: 0.030000  Loss: -1.9640  Acc@1: 81.2500 (84.6024)  Acc@5: 100.0000 (97.5404)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 380/3125]  eta: 0:17:56  Lr: 0.030000  Loss: -1.4084  Acc@1: 87.5000 (84.5965)  Acc@5: 100.0000 (97.5558)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 390/3125]  eta: 0:17:52  Lr: 0.030000  Loss: -1.5441  Acc@1: 81.2500 (84.5428)  Acc@5: 100.0000 (97.5064)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 400/3125]  eta: 0:17:48  Lr: 0.030000  Loss: -1.5380  Acc@1: 81.2500 (84.6166)  Acc@5: 100.0000 (97.4906)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 410/3125]  eta: 0:17:44  Lr: 0.030000  Loss: -1.4704  Acc@1: 87.5000 (84.7324)  Acc@5: 100.0000 (97.5213)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 420/3125]  eta: 0:17:40  Lr: 0.030000  Loss: -0.9789  Acc@1: 87.5000 (84.7684)  Acc@5: 100.0000 (97.5208)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 430/3125]  eta: 0:17:36  Lr: 0.030000  Loss: -1.4242  Acc@1: 87.5000 (84.8173)  Acc@5: 100.0000 (97.5493)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 440/3125]  eta: 0:17:32  Lr: 0.030000  Loss: -1.0053  Acc@1: 87.5000 (84.7364)  Acc@5: 100.0000 (97.5907)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 450/3125]  eta: 0:17:28  Lr: 0.030000  Loss: -1.3123  Acc@1: 81.2500 (84.7561)  Acc@5: 100.0000 (97.5887)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 460/3125]  eta: 0:17:24  Lr: 0.030000  Loss: -1.7343  Acc@1: 87.5000 (84.7885)  Acc@5: 100.0000 (97.6274)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 470/3125]  eta: 0:17:20  Lr: 0.030000  Loss: -1.3140  Acc@1: 87.5000 (84.9124)  Acc@5: 100.0000 (97.6645)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 480/3125]  eta: 0:17:16  Lr: 0.030000  Loss: -1.8214  Acc@1: 93.7500 (84.9532)  Acc@5: 100.0000 (97.7001)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 490/3125]  eta: 0:17:12  Lr: 0.030000  Loss: -1.6790  Acc@1: 87.5000 (85.0305)  Acc@5: 100.0000 (97.7342)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 500/3125]  eta: 0:17:08  Lr: 0.030000  Loss: -0.9899  Acc@1: 87.5000 (85.0923)  Acc@5: 100.0000 (97.7420)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 510/3125]  eta: 0:17:04  Lr: 0.030000  Loss: -1.0471  Acc@1: 87.5000 (85.1027)  Acc@5: 100.0000 (97.7373)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 520/3125]  eta: 0:17:00  Lr: 0.030000  Loss: -1.5594  Acc@1: 81.2500 (85.1128)  Acc@5: 100.0000 (97.7567)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 530/3125]  eta: 0:16:56  Lr: 0.030000  Loss: -1.3844  Acc@1: 87.5000 (85.1577)  Acc@5: 100.0000 (97.7637)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 540/3125]  eta: 0:16:52  Lr: 0.030000  Loss: -1.6945  Acc@1: 87.5000 (85.1664)  Acc@5: 100.0000 (97.7241)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 550/3125]  eta: 0:16:48  Lr: 0.030000  Loss: -1.1116  Acc@1: 81.2500 (85.0499)  Acc@5: 93.7500 (97.7087)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 560/3125]  eta: 0:16:44  Lr: 0.030000  Loss: -1.3460  Acc@1: 81.2500 (85.0824)  Acc@5: 100.0000 (97.7050)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 570/3125]  eta: 0:16:40  Lr: 0.030000  Loss: -1.1403  Acc@1: 87.5000 (85.0372)  Acc@5: 100.0000 (97.6686)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 580/3125]  eta: 0:16:36  Lr: 0.030000  Loss: -1.7143  Acc@1: 81.2500 (84.9720)  Acc@5: 100.0000 (97.6657)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 590/3125]  eta: 0:16:33  Lr: 0.030000  Loss: -1.4073  Acc@1: 81.2500 (84.9302)  Acc@5: 100.0000 (97.6734)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 600/3125]  eta: 0:16:29  Lr: 0.030000  Loss: -0.9903  Acc@1: 75.0000 (84.8274)  Acc@5: 100.0000 (97.6601)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 610/3125]  eta: 0:16:25  Lr: 0.030000  Loss: -1.7083  Acc@1: 87.5000 (84.8916)  Acc@5: 100.0000 (97.6678)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 620/3125]  eta: 0:16:21  Lr: 0.030000  Loss: -0.8741  Acc@1: 87.5000 (84.8732)  Acc@5: 100.0000 (97.6651)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 630/3125]  eta: 0:16:17  Lr: 0.030000  Loss: -1.6190  Acc@1: 81.2500 (84.8752)  Acc@5: 100.0000 (97.6823)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 640/3125]  eta: 0:16:13  Lr: 0.030000  Loss: -1.7071  Acc@1: 87.5000 (84.9064)  Acc@5: 100.0000 (97.6697)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 650/3125]  eta: 0:16:09  Lr: 0.030000  Loss: -1.6379  Acc@1: 87.5000 (84.9174)  Acc@5: 100.0000 (97.6863)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 660/3125]  eta: 0:16:05  Lr: 0.030000  Loss: -1.5965  Acc@1: 87.5000 (84.8998)  Acc@5: 100.0000 (97.6456)  time: 0.3914  data: 0.0011  max mem: 2912
Train: Epoch[2/5]  [ 670/3125]  eta: 0:16:01  Lr: 0.030000  Loss: -1.2835  Acc@1: 81.2500 (84.9106)  Acc@5: 100.0000 (97.6341)  time: 0.3920  data: 0.0011  max mem: 2912
Train: Epoch[2/5]  [ 680/3125]  eta: 0:15:57  Lr: 0.030000  Loss: -1.7003  Acc@1: 87.5000 (84.9945)  Acc@5: 100.0000 (97.6413)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 690/3125]  eta: 0:15:53  Lr: 0.030000  Loss: -1.6836  Acc@1: 87.5000 (85.0308)  Acc@5: 100.0000 (97.6393)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 700/3125]  eta: 0:15:49  Lr: 0.030000  Loss: -1.7038  Acc@1: 87.5000 (85.0214)  Acc@5: 100.0000 (97.6641)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 710/3125]  eta: 0:15:45  Lr: 0.030000  Loss: 0.2624  Acc@1: 81.2500 (84.9771)  Acc@5: 100.0000 (97.6178)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 720/3125]  eta: 0:15:41  Lr: 0.030000  Loss: -1.2466  Acc@1: 81.2500 (84.9775)  Acc@5: 100.0000 (97.6075)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 730/3125]  eta: 0:15:37  Lr: 0.030000  Loss: -1.3121  Acc@1: 87.5000 (85.0034)  Acc@5: 100.0000 (97.6146)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 740/3125]  eta: 0:15:33  Lr: 0.030000  Loss: -1.7338  Acc@1: 81.2500 (84.9781)  Acc@5: 100.0000 (97.6215)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 750/3125]  eta: 0:15:29  Lr: 0.030000  Loss: -0.8530  Acc@1: 81.2500 (84.9867)  Acc@5: 100.0000 (97.6032)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 760/3125]  eta: 0:15:25  Lr: 0.030000  Loss: -1.5750  Acc@1: 87.5000 (85.0279)  Acc@5: 100.0000 (97.6101)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 770/3125]  eta: 0:15:22  Lr: 0.030000  Loss: -1.3279  Acc@1: 87.5000 (84.9870)  Acc@5: 100.0000 (97.6167)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 780/3125]  eta: 0:15:18  Lr: 0.030000  Loss: -1.5549  Acc@1: 81.2500 (84.9712)  Acc@5: 100.0000 (97.6312)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 790/3125]  eta: 0:15:14  Lr: 0.030000  Loss: -1.4052  Acc@1: 87.5000 (85.0032)  Acc@5: 100.0000 (97.6454)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 800/3125]  eta: 0:15:10  Lr: 0.030000  Loss: -1.5131  Acc@1: 87.5000 (85.0187)  Acc@5: 100.0000 (97.6358)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 810/3125]  eta: 0:15:06  Lr: 0.030000  Loss: -0.7412  Acc@1: 87.5000 (84.9954)  Acc@5: 100.0000 (97.6110)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 820/3125]  eta: 0:15:02  Lr: 0.030000  Loss: -1.1323  Acc@1: 87.5000 (84.9726)  Acc@5: 100.0000 (97.6325)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 830/3125]  eta: 0:14:58  Lr: 0.030000  Loss: -1.4942  Acc@1: 87.5000 (84.9880)  Acc@5: 100.0000 (97.6384)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 840/3125]  eta: 0:14:54  Lr: 0.030000  Loss: -1.5202  Acc@1: 87.5000 (84.9881)  Acc@5: 100.0000 (97.6367)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 850/3125]  eta: 0:14:50  Lr: 0.030000  Loss: -1.6989  Acc@1: 87.5000 (84.9736)  Acc@5: 100.0000 (97.6425)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 860/3125]  eta: 0:14:46  Lr: 0.030000  Loss: -1.2148  Acc@1: 87.5000 (84.9303)  Acc@5: 100.0000 (97.6408)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 870/3125]  eta: 0:14:42  Lr: 0.030000  Loss: -1.9606  Acc@1: 87.5000 (84.9526)  Acc@5: 100.0000 (97.6249)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 880/3125]  eta: 0:14:38  Lr: 0.030000  Loss: -1.3844  Acc@1: 87.5000 (84.9674)  Acc@5: 100.0000 (97.6234)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 890/3125]  eta: 0:14:34  Lr: 0.030000  Loss: -1.0209  Acc@1: 87.5000 (84.9256)  Acc@5: 100.0000 (97.6291)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 900/3125]  eta: 0:14:30  Lr: 0.030000  Loss: -1.3952  Acc@1: 87.5000 (84.9473)  Acc@5: 100.0000 (97.6415)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 910/3125]  eta: 0:14:26  Lr: 0.030000  Loss: -1.0817  Acc@1: 87.5000 (84.9890)  Acc@5: 100.0000 (97.6537)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 920/3125]  eta: 0:14:22  Lr: 0.030000  Loss: -1.7506  Acc@1: 87.5000 (85.0434)  Acc@5: 100.0000 (97.6384)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 930/3125]  eta: 0:14:18  Lr: 0.030000  Loss: -1.6991  Acc@1: 87.5000 (85.0295)  Acc@5: 100.0000 (97.6504)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 940/3125]  eta: 0:14:14  Lr: 0.030000  Loss: -1.3882  Acc@1: 87.5000 (85.0093)  Acc@5: 100.0000 (97.6554)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 950/3125]  eta: 0:14:10  Lr: 0.030000  Loss: -1.6461  Acc@1: 81.2500 (84.9895)  Acc@5: 100.0000 (97.6669)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 960/3125]  eta: 0:14:06  Lr: 0.030000  Loss: -0.4558  Acc@1: 81.2500 (84.9376)  Acc@5: 100.0000 (97.6652)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 970/3125]  eta: 0:14:02  Lr: 0.030000  Loss: -1.4315  Acc@1: 81.2500 (84.9189)  Acc@5: 100.0000 (97.6764)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 980/3125]  eta: 0:13:59  Lr: 0.030000  Loss: -1.3813  Acc@1: 87.5000 (84.9516)  Acc@5: 100.0000 (97.6809)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 990/3125]  eta: 0:13:55  Lr: 0.030000  Loss: -1.6201  Acc@1: 87.5000 (84.9584)  Acc@5: 100.0000 (97.6917)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1000/3125]  eta: 0:13:51  Lr: 0.030000  Loss: -1.1409  Acc@1: 87.5000 (84.9463)  Acc@5: 100.0000 (97.7085)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1010/3125]  eta: 0:13:47  Lr: 0.030000  Loss: -1.7256  Acc@1: 87.5000 (84.9963)  Acc@5: 100.0000 (97.7065)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1020/3125]  eta: 0:13:43  Lr: 0.030000  Loss: -1.5361  Acc@1: 87.5000 (84.9902)  Acc@5: 100.0000 (97.7045)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1030/3125]  eta: 0:13:39  Lr: 0.030000  Loss: -1.5044  Acc@1: 87.5000 (84.9661)  Acc@5: 100.0000 (97.7085)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1040/3125]  eta: 0:13:35  Lr: 0.030000  Loss: -0.8360  Acc@1: 87.5000 (85.0024)  Acc@5: 100.0000 (97.7125)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1050/3125]  eta: 0:13:31  Lr: 0.030000  Loss: -1.2857  Acc@1: 93.7500 (85.0559)  Acc@5: 100.0000 (97.7284)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1060/3125]  eta: 0:13:27  Lr: 0.030000  Loss: -1.8003  Acc@1: 93.7500 (85.1143)  Acc@5: 100.0000 (97.7380)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1070/3125]  eta: 0:13:23  Lr: 0.030000  Loss: -1.1135  Acc@1: 87.5000 (85.1132)  Acc@5: 100.0000 (97.7474)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1080/3125]  eta: 0:13:19  Lr: 0.030000  Loss: -1.6392  Acc@1: 87.5000 (85.1179)  Acc@5: 100.0000 (97.7567)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1090/3125]  eta: 0:13:15  Lr: 0.030000  Loss: -1.3568  Acc@1: 87.5000 (85.1169)  Acc@5: 100.0000 (97.7658)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1100/3125]  eta: 0:13:12  Lr: 0.030000  Loss: -1.5364  Acc@1: 87.5000 (85.1272)  Acc@5: 100.0000 (97.7634)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1110/3125]  eta: 0:13:08  Lr: 0.030000  Loss: -1.6740  Acc@1: 87.5000 (85.1598)  Acc@5: 100.0000 (97.7723)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1120/3125]  eta: 0:13:04  Lr: 0.030000  Loss: -1.8406  Acc@1: 93.7500 (85.2085)  Acc@5: 100.0000 (97.7698)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1130/3125]  eta: 0:13:00  Lr: 0.030000  Loss: -1.4409  Acc@1: 93.7500 (85.2454)  Acc@5: 100.0000 (97.7730)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1140/3125]  eta: 0:12:56  Lr: 0.030000  Loss: -1.7517  Acc@1: 87.5000 (85.2432)  Acc@5: 100.0000 (97.7651)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1150/3125]  eta: 0:12:52  Lr: 0.030000  Loss: -1.1167  Acc@1: 87.5000 (85.2682)  Acc@5: 100.0000 (97.7682)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1160/3125]  eta: 0:12:48  Lr: 0.030000  Loss: -1.5229  Acc@1: 87.5000 (85.2444)  Acc@5: 100.0000 (97.7659)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1170/3125]  eta: 0:12:44  Lr: 0.030000  Loss: -1.6358  Acc@1: 87.5000 (85.2530)  Acc@5: 100.0000 (97.7637)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1180/3125]  eta: 0:12:40  Lr: 0.030000  Loss: -1.3253  Acc@1: 87.5000 (85.2508)  Acc@5: 100.0000 (97.7561)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1190/3125]  eta: 0:12:36  Lr: 0.030000  Loss: -1.5949  Acc@1: 87.5000 (85.2330)  Acc@5: 100.0000 (97.7697)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1200/3125]  eta: 0:12:32  Lr: 0.030000  Loss: -1.4140  Acc@1: 81.2500 (85.1842)  Acc@5: 100.0000 (97.7779)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1210/3125]  eta: 0:12:28  Lr: 0.030000  Loss: -1.1638  Acc@1: 81.2500 (85.1982)  Acc@5: 100.0000 (97.7859)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1220/3125]  eta: 0:12:25  Lr: 0.030000  Loss: -1.3260  Acc@1: 87.5000 (85.2068)  Acc@5: 100.0000 (97.7938)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1230/3125]  eta: 0:12:21  Lr: 0.030000  Loss: -1.3429  Acc@1: 81.2500 (85.2051)  Acc@5: 100.0000 (97.7813)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1240/3125]  eta: 0:12:17  Lr: 0.030000  Loss: -1.6070  Acc@1: 81.2500 (85.1682)  Acc@5: 100.0000 (97.7689)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1250/3125]  eta: 0:12:13  Lr: 0.030000  Loss: -1.1075  Acc@1: 81.2500 (85.1219)  Acc@5: 100.0000 (97.7568)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1260/3125]  eta: 0:12:09  Lr: 0.030000  Loss: -1.5064  Acc@1: 81.2500 (85.1308)  Acc@5: 100.0000 (97.7647)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1270/3125]  eta: 0:12:05  Lr: 0.030000  Loss: -1.6255  Acc@1: 87.5000 (85.1298)  Acc@5: 100.0000 (97.7773)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1280/3125]  eta: 0:12:01  Lr: 0.030000  Loss: -1.0241  Acc@1: 81.2500 (85.0800)  Acc@5: 100.0000 (97.7605)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1290/3125]  eta: 0:11:57  Lr: 0.030000  Loss: -1.1001  Acc@1: 81.2500 (85.0988)  Acc@5: 100.0000 (97.7537)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1300/3125]  eta: 0:11:53  Lr: 0.030000  Loss: -1.6420  Acc@1: 87.5000 (85.1076)  Acc@5: 100.0000 (97.7661)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1310/3125]  eta: 0:11:49  Lr: 0.030000  Loss: -1.5470  Acc@1: 87.5000 (85.1306)  Acc@5: 100.0000 (97.7736)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1320/3125]  eta: 0:11:46  Lr: 0.030000  Loss: -1.3964  Acc@1: 87.5000 (85.1107)  Acc@5: 100.0000 (97.7810)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1330/3125]  eta: 0:11:42  Lr: 0.030000  Loss: -0.5655  Acc@1: 81.2500 (85.0817)  Acc@5: 100.0000 (97.7695)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1340/3125]  eta: 0:11:38  Lr: 0.030000  Loss: -1.2488  Acc@1: 87.5000 (85.1044)  Acc@5: 100.0000 (97.7675)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1350/3125]  eta: 0:11:34  Lr: 0.030000  Loss: -1.2204  Acc@1: 87.5000 (85.0805)  Acc@5: 100.0000 (97.7655)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1360/3125]  eta: 0:11:30  Lr: 0.030000  Loss: -1.4566  Acc@1: 87.5000 (85.1120)  Acc@5: 100.0000 (97.7774)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1370/3125]  eta: 0:11:26  Lr: 0.030000  Loss: -1.7274  Acc@1: 87.5000 (85.1067)  Acc@5: 100.0000 (97.7890)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1380/3125]  eta: 0:11:22  Lr: 0.030000  Loss: -1.6127  Acc@1: 87.5000 (85.1285)  Acc@5: 100.0000 (97.7915)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1390/3125]  eta: 0:11:18  Lr: 0.030000  Loss: -1.4777  Acc@1: 87.5000 (85.1321)  Acc@5: 100.0000 (97.7894)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1400/3125]  eta: 0:11:14  Lr: 0.030000  Loss: -1.5935  Acc@1: 87.5000 (85.1267)  Acc@5: 100.0000 (97.7873)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1410/3125]  eta: 0:11:10  Lr: 0.030000  Loss: -1.6085  Acc@1: 81.2500 (85.1302)  Acc@5: 100.0000 (97.7985)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1420/3125]  eta: 0:11:06  Lr: 0.030000  Loss: -0.8643  Acc@1: 87.5000 (85.1425)  Acc@5: 100.0000 (97.7920)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1430/3125]  eta: 0:11:02  Lr: 0.030000  Loss: -1.8844  Acc@1: 93.7500 (85.1852)  Acc@5: 100.0000 (97.7944)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1440/3125]  eta: 0:10:58  Lr: 0.030000  Loss: -1.5107  Acc@1: 87.5000 (85.1839)  Acc@5: 100.0000 (97.7923)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1450/3125]  eta: 0:10:55  Lr: 0.030000  Loss: -1.3586  Acc@1: 87.5000 (85.2042)  Acc@5: 100.0000 (97.7989)  time: 0.3894  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1460/3125]  eta: 0:10:51  Lr: 0.030000  Loss: -1.3486  Acc@1: 87.5000 (85.2156)  Acc@5: 100.0000 (97.8012)  time: 0.3905  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1470/3125]  eta: 0:10:47  Lr: 0.030000  Loss: -1.4958  Acc@1: 87.5000 (85.2141)  Acc@5: 100.0000 (97.8034)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1480/3125]  eta: 0:10:43  Lr: 0.030000  Loss: -1.4178  Acc@1: 87.5000 (85.2338)  Acc@5: 100.0000 (97.8098)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1490/3125]  eta: 0:10:39  Lr: 0.030000  Loss: -1.8865  Acc@1: 87.5000 (85.2406)  Acc@5: 100.0000 (97.8077)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1500/3125]  eta: 0:10:35  Lr: 0.030000  Loss: -1.5735  Acc@1: 87.5000 (85.2557)  Acc@5: 100.0000 (97.8181)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1510/3125]  eta: 0:10:31  Lr: 0.030000  Loss: -1.3724  Acc@1: 87.5000 (85.2705)  Acc@5: 100.0000 (97.8243)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1520/3125]  eta: 0:10:27  Lr: 0.030000  Loss: -1.7267  Acc@1: 87.5000 (85.2646)  Acc@5: 100.0000 (97.8098)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1530/3125]  eta: 0:10:23  Lr: 0.030000  Loss: -1.7468  Acc@1: 87.5000 (85.2670)  Acc@5: 100.0000 (97.8119)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1540/3125]  eta: 0:10:19  Lr: 0.030000  Loss: -1.3533  Acc@1: 87.5000 (85.2612)  Acc@5: 100.0000 (97.8220)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1550/3125]  eta: 0:10:15  Lr: 0.030000  Loss: -1.4101  Acc@1: 87.5000 (85.2555)  Acc@5: 100.0000 (97.8320)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1560/3125]  eta: 0:10:11  Lr: 0.030000  Loss: -1.0088  Acc@1: 87.5000 (85.2538)  Acc@5: 100.0000 (97.8259)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1570/3125]  eta: 0:10:07  Lr: 0.030000  Loss: -1.2379  Acc@1: 87.5000 (85.2642)  Acc@5: 100.0000 (97.8318)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1580/3125]  eta: 0:10:04  Lr: 0.030000  Loss: -1.2393  Acc@1: 87.5000 (85.2744)  Acc@5: 100.0000 (97.8257)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1590/3125]  eta: 0:10:00  Lr: 0.030000  Loss: -1.5149  Acc@1: 87.5000 (85.2726)  Acc@5: 100.0000 (97.8276)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1600/3125]  eta: 0:09:56  Lr: 0.030000  Loss: -0.7878  Acc@1: 87.5000 (85.2592)  Acc@5: 100.0000 (97.8334)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1610/3125]  eta: 0:09:52  Lr: 0.030000  Loss: -1.2695  Acc@1: 87.5000 (85.2498)  Acc@5: 100.0000 (97.8313)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1620/3125]  eta: 0:09:48  Lr: 0.030000  Loss: -1.0181  Acc@1: 81.2500 (85.2290)  Acc@5: 93.7500 (97.8216)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1630/3125]  eta: 0:09:44  Lr: 0.030000  Loss: -1.9452  Acc@1: 81.2500 (85.2315)  Acc@5: 100.0000 (97.8196)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1640/3125]  eta: 0:09:40  Lr: 0.030000  Loss: -1.5419  Acc@1: 87.5000 (85.2072)  Acc@5: 100.0000 (97.8253)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1650/3125]  eta: 0:09:36  Lr: 0.030000  Loss: -1.3814  Acc@1: 87.5000 (85.2173)  Acc@5: 100.0000 (97.8309)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1660/3125]  eta: 0:09:32  Lr: 0.030000  Loss: -1.3026  Acc@1: 87.5000 (85.2197)  Acc@5: 100.0000 (97.8251)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1670/3125]  eta: 0:09:28  Lr: 0.030000  Loss: -1.6890  Acc@1: 87.5000 (85.2521)  Acc@5: 100.0000 (97.8344)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1680/3125]  eta: 0:09:24  Lr: 0.030000  Loss: -1.5042  Acc@1: 87.5000 (85.2432)  Acc@5: 100.0000 (97.8250)  time: 0.3966  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1690/3125]  eta: 0:09:21  Lr: 0.030000  Loss: -1.4432  Acc@1: 81.2500 (85.2491)  Acc@5: 100.0000 (97.8341)  time: 0.3976  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1700/3125]  eta: 0:09:17  Lr: 0.030000  Loss: -1.7759  Acc@1: 81.2500 (85.2623)  Acc@5: 100.0000 (97.8358)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1710/3125]  eta: 0:09:13  Lr: 0.030000  Loss: -1.5419  Acc@1: 81.2500 (85.2645)  Acc@5: 100.0000 (97.8412)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1720/3125]  eta: 0:09:09  Lr: 0.030000  Loss: -1.3556  Acc@1: 87.5000 (85.2920)  Acc@5: 100.0000 (97.8501)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1730/3125]  eta: 0:09:05  Lr: 0.030000  Loss: -1.6427  Acc@1: 87.5000 (85.3083)  Acc@5: 100.0000 (97.8481)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1740/3125]  eta: 0:09:01  Lr: 0.030000  Loss: -0.8585  Acc@1: 87.5000 (85.3173)  Acc@5: 100.0000 (97.8532)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1750/3125]  eta: 0:08:57  Lr: 0.030000  Loss: -1.2434  Acc@1: 87.5000 (85.3191)  Acc@5: 100.0000 (97.8477)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1760/3125]  eta: 0:08:53  Lr: 0.030000  Loss: -1.6361  Acc@1: 87.5000 (85.3173)  Acc@5: 100.0000 (97.8457)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1770/3125]  eta: 0:08:49  Lr: 0.030000  Loss: -1.8329  Acc@1: 81.2500 (85.3120)  Acc@5: 100.0000 (97.8402)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1780/3125]  eta: 0:08:45  Lr: 0.030000  Loss: -1.8529  Acc@1: 87.5000 (85.3102)  Acc@5: 100.0000 (97.8453)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1790/3125]  eta: 0:08:41  Lr: 0.030000  Loss: -1.7627  Acc@1: 87.5000 (85.3120)  Acc@5: 100.0000 (97.8539)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1800/3125]  eta: 0:08:38  Lr: 0.030000  Loss: -1.7127  Acc@1: 87.5000 (85.3276)  Acc@5: 100.0000 (97.8554)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1810/3125]  eta: 0:08:34  Lr: 0.030000  Loss: -1.5795  Acc@1: 87.5000 (85.3223)  Acc@5: 100.0000 (97.8568)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1820/3125]  eta: 0:08:30  Lr: 0.030000  Loss: -1.5641  Acc@1: 81.2500 (85.3137)  Acc@5: 100.0000 (97.8618)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1830/3125]  eta: 0:08:26  Lr: 0.030000  Loss: -1.4165  Acc@1: 87.5000 (85.3222)  Acc@5: 100.0000 (97.8632)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1840/3125]  eta: 0:08:22  Lr: 0.030000  Loss: -1.0863  Acc@1: 87.5000 (85.3239)  Acc@5: 100.0000 (97.8612)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1850/3125]  eta: 0:08:18  Lr: 0.030000  Loss: -1.7011  Acc@1: 87.5000 (85.3424)  Acc@5: 100.0000 (97.8660)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1860/3125]  eta: 0:08:14  Lr: 0.030000  Loss: -1.4852  Acc@1: 87.5000 (85.3540)  Acc@5: 100.0000 (97.8741)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1870/3125]  eta: 0:08:10  Lr: 0.030000  Loss: -1.5952  Acc@1: 87.5000 (85.3654)  Acc@5: 100.0000 (97.8755)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1880/3125]  eta: 0:08:06  Lr: 0.030000  Loss: -1.4771  Acc@1: 87.5000 (85.3569)  Acc@5: 100.0000 (97.8801)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1890/3125]  eta: 0:08:02  Lr: 0.030000  Loss: -1.4972  Acc@1: 87.5000 (85.3649)  Acc@5: 100.0000 (97.8781)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:58  Lr: 0.030000  Loss: -1.6454  Acc@1: 87.5000 (85.3926)  Acc@5: 100.0000 (97.8860)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1910/3125]  eta: 0:07:55  Lr: 0.030000  Loss: -1.0362  Acc@1: 87.5000 (85.3840)  Acc@5: 100.0000 (97.8872)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1920/3125]  eta: 0:07:51  Lr: 0.030000  Loss: -1.1631  Acc@1: 81.2500 (85.3982)  Acc@5: 100.0000 (97.8852)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1930/3125]  eta: 0:07:47  Lr: 0.030000  Loss: -1.5047  Acc@1: 87.5000 (85.3994)  Acc@5: 100.0000 (97.8703)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1940/3125]  eta: 0:07:43  Lr: 0.030000  Loss: -1.7627  Acc@1: 87.5000 (85.4263)  Acc@5: 100.0000 (97.8812)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1950/3125]  eta: 0:07:39  Lr: 0.030000  Loss: -1.5745  Acc@1: 87.5000 (85.4273)  Acc@5: 100.0000 (97.8761)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1960/3125]  eta: 0:07:35  Lr: 0.030000  Loss: -0.9009  Acc@1: 81.2500 (85.4188)  Acc@5: 93.7500 (97.8646)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1970/3125]  eta: 0:07:31  Lr: 0.030000  Loss: -1.1449  Acc@1: 87.5000 (85.4357)  Acc@5: 100.0000 (97.8628)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1980/3125]  eta: 0:07:27  Lr: 0.030000  Loss: -0.9656  Acc@1: 87.5000 (85.4146)  Acc@5: 100.0000 (97.8578)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1990/3125]  eta: 0:07:23  Lr: 0.030000  Loss: -1.5243  Acc@1: 81.2500 (85.4062)  Acc@5: 100.0000 (97.8560)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2000/3125]  eta: 0:07:19  Lr: 0.030000  Loss: -1.7357  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (97.8667)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2010/3125]  eta: 0:07:15  Lr: 0.030000  Loss: -1.5336  Acc@1: 87.5000 (85.4208)  Acc@5: 100.0000 (97.8680)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2020/3125]  eta: 0:07:12  Lr: 0.030000  Loss: -1.3841  Acc@1: 87.5000 (85.4249)  Acc@5: 100.0000 (97.8692)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2030/3125]  eta: 0:07:08  Lr: 0.030000  Loss: -1.5069  Acc@1: 87.5000 (85.4321)  Acc@5: 100.0000 (97.8736)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2040/3125]  eta: 0:07:04  Lr: 0.030000  Loss: -1.5561  Acc@1: 87.5000 (85.4299)  Acc@5: 100.0000 (97.8718)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2050/3125]  eta: 0:07:00  Lr: 0.030000  Loss: -1.6044  Acc@1: 87.5000 (85.4492)  Acc@5: 100.0000 (97.8760)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:56  Lr: 0.030000  Loss: -1.5738  Acc@1: 87.5000 (85.4591)  Acc@5: 100.0000 (97.8772)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:52  Lr: 0.030000  Loss: -1.6593  Acc@1: 87.5000 (85.4841)  Acc@5: 100.0000 (97.8875)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2080/3125]  eta: 0:06:48  Lr: 0.030000  Loss: -1.5986  Acc@1: 87.5000 (85.4938)  Acc@5: 100.0000 (97.8976)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2090/3125]  eta: 0:06:44  Lr: 0.030000  Loss: -1.6505  Acc@1: 87.5000 (85.5033)  Acc@5: 100.0000 (97.9017)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2100/3125]  eta: 0:06:40  Lr: 0.030000  Loss: -1.6875  Acc@1: 87.5000 (85.5099)  Acc@5: 100.0000 (97.9087)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2110/3125]  eta: 0:06:36  Lr: 0.030000  Loss: -1.4603  Acc@1: 87.5000 (85.5134)  Acc@5: 100.0000 (97.9127)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2120/3125]  eta: 0:06:32  Lr: 0.030000  Loss: -1.3689  Acc@1: 87.5000 (85.5227)  Acc@5: 100.0000 (97.9078)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2130/3125]  eta: 0:06:28  Lr: 0.030000  Loss: -1.2610  Acc@1: 87.5000 (85.5320)  Acc@5: 100.0000 (97.9147)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2140/3125]  eta: 0:06:25  Lr: 0.030000  Loss: -1.6712  Acc@1: 87.5000 (85.5325)  Acc@5: 100.0000 (97.9157)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2150/3125]  eta: 0:06:21  Lr: 0.030000  Loss: -1.5191  Acc@1: 87.5000 (85.5590)  Acc@5: 100.0000 (97.9254)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2160/3125]  eta: 0:06:17  Lr: 0.030000  Loss: -1.4183  Acc@1: 87.5000 (85.5651)  Acc@5: 100.0000 (97.9263)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2170/3125]  eta: 0:06:13  Lr: 0.030000  Loss: -1.6321  Acc@1: 87.5000 (85.5798)  Acc@5: 100.0000 (97.9272)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2180/3125]  eta: 0:06:09  Lr: 0.030000  Loss: -1.3512  Acc@1: 87.5000 (85.5685)  Acc@5: 100.0000 (97.9253)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2190/3125]  eta: 0:06:05  Lr: 0.030000  Loss: -1.5466  Acc@1: 81.2500 (85.5660)  Acc@5: 100.0000 (97.9233)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2200/3125]  eta: 0:06:01  Lr: 0.030000  Loss: -1.4123  Acc@1: 87.5000 (85.5662)  Acc@5: 100.0000 (97.9242)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:57  Lr: 0.030000  Loss: -1.3949  Acc@1: 87.5000 (85.5637)  Acc@5: 100.0000 (97.9195)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:53  Lr: 0.030000  Loss: -1.7511  Acc@1: 81.2500 (85.5442)  Acc@5: 100.0000 (97.9204)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:49  Lr: 0.030000  Loss: -1.4711  Acc@1: 81.2500 (85.5194)  Acc@5: 100.0000 (97.9241)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:45  Lr: 0.030000  Loss: -1.6389  Acc@1: 81.2500 (85.5366)  Acc@5: 100.0000 (97.9278)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:41  Lr: 0.030000  Loss: -1.2397  Acc@1: 87.5000 (85.5481)  Acc@5: 100.0000 (97.9370)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2260/3125]  eta: 0:05:38  Lr: 0.030000  Loss: -1.3213  Acc@1: 87.5000 (85.5678)  Acc@5: 100.0000 (97.9462)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2270/3125]  eta: 0:05:34  Lr: 0.030000  Loss: -1.4902  Acc@1: 87.5000 (85.5680)  Acc@5: 100.0000 (97.9552)  time: 0.3948  data: 0.0012  max mem: 2912
Train: Epoch[2/5]  [2280/3125]  eta: 0:05:30  Lr: 0.030000  Loss: -1.4723  Acc@1: 87.5000 (85.5820)  Acc@5: 100.0000 (97.9587)  time: 0.4000  data: 0.0012  max mem: 2912
Train: Epoch[2/5]  [2290/3125]  eta: 0:05:26  Lr: 0.030000  Loss: -1.8151  Acc@1: 87.5000 (85.5822)  Acc@5: 100.0000 (97.9512)  time: 0.3959  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2300/3125]  eta: 0:05:22  Lr: 0.030000  Loss: -1.7756  Acc@1: 87.5000 (85.5851)  Acc@5: 100.0000 (97.9520)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2310/3125]  eta: 0:05:18  Lr: 0.030000  Loss: -1.5613  Acc@1: 87.5000 (85.6042)  Acc@5: 100.0000 (97.9581)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2320/3125]  eta: 0:05:14  Lr: 0.030000  Loss: -1.2124  Acc@1: 87.5000 (85.6016)  Acc@5: 100.0000 (97.9508)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2330/3125]  eta: 0:05:10  Lr: 0.030000  Loss: -1.2719  Acc@1: 81.2500 (85.6124)  Acc@5: 100.0000 (97.9542)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2340/3125]  eta: 0:05:06  Lr: 0.030000  Loss: -1.6950  Acc@1: 87.5000 (85.6365)  Acc@5: 100.0000 (97.9629)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2350/3125]  eta: 0:05:02  Lr: 0.030000  Loss: -1.0222  Acc@1: 87.5000 (85.6311)  Acc@5: 100.0000 (97.9636)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:59  Lr: 0.030000  Loss: -1.5989  Acc@1: 81.2500 (85.6231)  Acc@5: 100.0000 (97.9643)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:55  Lr: 0.030000  Loss: -1.3290  Acc@1: 81.2500 (85.6100)  Acc@5: 100.0000 (97.9624)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:51  Lr: 0.030000  Loss: -1.6052  Acc@1: 81.2500 (85.6048)  Acc@5: 100.0000 (97.9657)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:47  Lr: 0.030000  Loss: -1.5822  Acc@1: 87.5000 (85.6023)  Acc@5: 100.0000 (97.9663)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:43  Lr: 0.030000  Loss: -1.8829  Acc@1: 87.5000 (85.6050)  Acc@5: 100.0000 (97.9748)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:39  Lr: 0.030000  Loss: -1.8073  Acc@1: 93.7500 (85.6310)  Acc@5: 100.0000 (97.9754)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:35  Lr: 0.030000  Loss: -1.7955  Acc@1: 87.5000 (85.6258)  Acc@5: 100.0000 (97.9786)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2430/3125]  eta: 0:04:31  Lr: 0.030000  Loss: -1.2883  Acc@1: 87.5000 (85.6309)  Acc@5: 100.0000 (97.9844)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2440/3125]  eta: 0:04:27  Lr: 0.030000  Loss: -1.5914  Acc@1: 87.5000 (85.6334)  Acc@5: 100.0000 (97.9798)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2450/3125]  eta: 0:04:23  Lr: 0.030000  Loss: -1.2400  Acc@1: 87.5000 (85.6487)  Acc@5: 100.0000 (97.9804)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2460/3125]  eta: 0:04:19  Lr: 0.030000  Loss: -1.2431  Acc@1: 87.5000 (85.6486)  Acc@5: 100.0000 (97.9810)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2470/3125]  eta: 0:04:16  Lr: 0.030000  Loss: -0.3664  Acc@1: 87.5000 (85.6485)  Acc@5: 100.0000 (97.9765)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2480/3125]  eta: 0:04:12  Lr: 0.030000  Loss: -1.3568  Acc@1: 87.5000 (85.6509)  Acc@5: 100.0000 (97.9746)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2490/3125]  eta: 0:04:08  Lr: 0.030000  Loss: -1.2278  Acc@1: 87.5000 (85.6433)  Acc@5: 100.0000 (97.9752)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2500/3125]  eta: 0:04:04  Lr: 0.030000  Loss: -1.3742  Acc@1: 87.5000 (85.6557)  Acc@5: 100.0000 (97.9733)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2510/3125]  eta: 0:04:00  Lr: 0.030000  Loss: -1.2685  Acc@1: 87.5000 (85.6581)  Acc@5: 100.0000 (97.9789)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:56  Lr: 0.030000  Loss: -1.2232  Acc@1: 81.2500 (85.6505)  Acc@5: 100.0000 (97.9720)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:52  Lr: 0.030000  Loss: -1.6681  Acc@1: 81.2500 (85.6628)  Acc@5: 100.0000 (97.9776)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:48  Lr: 0.030000  Loss: -1.4276  Acc@1: 87.5000 (85.6577)  Acc@5: 100.0000 (97.9782)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:44  Lr: 0.030000  Loss: -1.5559  Acc@1: 87.5000 (85.6698)  Acc@5: 100.0000 (97.9836)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:40  Lr: 0.030000  Loss: -1.5855  Acc@1: 87.5000 (85.6721)  Acc@5: 100.0000 (97.9842)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:36  Lr: 0.030000  Loss: -1.3379  Acc@1: 87.5000 (85.6598)  Acc@5: 100.0000 (97.9872)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:33  Lr: 0.030000  Loss: -1.1371  Acc@1: 87.5000 (85.6669)  Acc@5: 100.0000 (97.9901)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:29  Lr: 0.030000  Loss: -1.6305  Acc@1: 87.5000 (85.6740)  Acc@5: 100.0000 (97.9955)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:25  Lr: 0.030000  Loss: -1.8725  Acc@1: 87.5000 (85.6738)  Acc@5: 100.0000 (97.9888)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2610/3125]  eta: 0:03:21  Lr: 0.030000  Loss: -1.5665  Acc@1: 87.5000 (85.6688)  Acc@5: 100.0000 (97.9869)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2620/3125]  eta: 0:03:17  Lr: 0.030000  Loss: -1.3803  Acc@1: 87.5000 (85.6877)  Acc@5: 100.0000 (97.9922)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2630/3125]  eta: 0:03:13  Lr: 0.030000  Loss: -1.5284  Acc@1: 87.5000 (85.6922)  Acc@5: 100.0000 (97.9879)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2640/3125]  eta: 0:03:09  Lr: 0.030000  Loss: -1.6679  Acc@1: 87.5000 (85.6967)  Acc@5: 100.0000 (97.9908)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2650/3125]  eta: 0:03:05  Lr: 0.030000  Loss: -1.3928  Acc@1: 87.5000 (85.7012)  Acc@5: 100.0000 (97.9866)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2660/3125]  eta: 0:03:01  Lr: 0.030000  Loss: -1.3050  Acc@1: 87.5000 (85.7079)  Acc@5: 100.0000 (97.9871)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:57  Lr: 0.030000  Loss: -1.2700  Acc@1: 87.5000 (85.7053)  Acc@5: 100.0000 (97.9923)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:53  Lr: 0.030000  Loss: -1.4032  Acc@1: 87.5000 (85.6933)  Acc@5: 100.0000 (97.9952)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:50  Lr: 0.030000  Loss: -1.3602  Acc@1: 87.5000 (85.7070)  Acc@5: 100.0000 (98.0026)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:46  Lr: 0.030000  Loss: -1.3929  Acc@1: 87.5000 (85.7067)  Acc@5: 100.0000 (98.0031)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:42  Lr: 0.030000  Loss: -1.6451  Acc@1: 87.5000 (85.6833)  Acc@5: 100.0000 (97.9989)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:38  Lr: 0.030000  Loss: -1.7417  Acc@1: 81.2500 (85.6854)  Acc@5: 100.0000 (97.9994)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:34  Lr: 0.030000  Loss: -1.4936  Acc@1: 87.5000 (85.7012)  Acc@5: 100.0000 (97.9998)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:30  Lr: 0.030000  Loss: -1.7107  Acc@1: 87.5000 (85.6964)  Acc@5: 100.0000 (98.0026)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:26  Lr: 0.030000  Loss: -1.3758  Acc@1: 87.5000 (85.7007)  Acc@5: 100.0000 (98.0007)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:22  Lr: 0.030000  Loss: -1.3662  Acc@1: 87.5000 (85.7208)  Acc@5: 100.0000 (97.9989)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:18  Lr: 0.030000  Loss: -1.5202  Acc@1: 87.5000 (85.7091)  Acc@5: 100.0000 (98.0039)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2780/3125]  eta: 0:02:14  Lr: 0.030000  Loss: -1.6462  Acc@1: 87.5000 (85.6886)  Acc@5: 100.0000 (98.0021)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2790/3125]  eta: 0:02:10  Lr: 0.030000  Loss: -1.3507  Acc@1: 87.5000 (85.6906)  Acc@5: 100.0000 (98.0003)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2800/3125]  eta: 0:02:07  Lr: 0.030000  Loss: -1.6418  Acc@1: 87.5000 (85.6926)  Acc@5: 100.0000 (98.0052)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2810/3125]  eta: 0:02:03  Lr: 0.030000  Loss: -1.6785  Acc@1: 87.5000 (85.7013)  Acc@5: 100.0000 (98.0078)  time: 0.3899  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:59  Lr: 0.030000  Loss: -1.7952  Acc@1: 87.5000 (85.7032)  Acc@5: 100.0000 (98.0105)  time: 0.3893  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:55  Lr: 0.030000  Loss: -1.3094  Acc@1: 81.2500 (85.7118)  Acc@5: 100.0000 (98.0087)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:51  Lr: 0.030000  Loss: -1.5238  Acc@1: 87.5000 (85.7159)  Acc@5: 100.0000 (98.0091)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:47  Lr: 0.030000  Loss: -1.6451  Acc@1: 87.5000 (85.7309)  Acc@5: 100.0000 (98.0095)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:43  Lr: 0.030000  Loss: -1.5039  Acc@1: 87.5000 (85.7218)  Acc@5: 100.0000 (98.0033)  time: 0.3885  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:39  Lr: 0.030000  Loss: -1.4176  Acc@1: 87.5000 (85.7323)  Acc@5: 100.0000 (98.0081)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:35  Lr: 0.030000  Loss: -1.8062  Acc@1: 87.5000 (85.7341)  Acc@5: 100.0000 (98.0128)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:31  Lr: 0.030000  Loss: -1.5659  Acc@1: 87.5000 (85.7510)  Acc@5: 100.0000 (98.0197)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:27  Lr: 0.030000  Loss: -0.5201  Acc@1: 87.5000 (85.7463)  Acc@5: 100.0000 (98.0179)  time: 0.3887  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:24  Lr: 0.030000  Loss: -1.2300  Acc@1: 87.5000 (85.7394)  Acc@5: 100.0000 (98.0183)  time: 0.3901  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:20  Lr: 0.030000  Loss: -1.0356  Acc@1: 87.5000 (85.7412)  Acc@5: 100.0000 (98.0187)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:16  Lr: 0.030000  Loss: -1.4177  Acc@1: 87.5000 (85.7472)  Acc@5: 100.0000 (98.0212)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:12  Lr: 0.030000  Loss: -0.9318  Acc@1: 87.5000 (85.7383)  Acc@5: 100.0000 (98.0215)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:08  Lr: 0.030000  Loss: -1.5441  Acc@1: 87.5000 (85.7485)  Acc@5: 100.0000 (98.0219)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2960/3125]  eta: 0:01:04  Lr: 0.030000  Loss: -1.7730  Acc@1: 87.5000 (85.7396)  Acc@5: 100.0000 (98.0201)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2970/3125]  eta: 0:01:00  Lr: 0.030000  Loss: -1.5352  Acc@1: 87.5000 (85.7434)  Acc@5: 100.0000 (98.0247)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:56  Lr: 0.030000  Loss: -1.8802  Acc@1: 87.5000 (85.7577)  Acc@5: 100.0000 (98.0313)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:52  Lr: 0.030000  Loss: -1.4673  Acc@1: 87.5000 (85.7531)  Acc@5: 100.0000 (98.0337)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:48  Lr: 0.030000  Loss: -1.7247  Acc@1: 87.5000 (85.7527)  Acc@5: 100.0000 (98.0319)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:44  Lr: 0.030000  Loss: -1.5904  Acc@1: 87.5000 (85.7626)  Acc@5: 100.0000 (98.0322)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:41  Lr: 0.030000  Loss: -1.1988  Acc@1: 87.5000 (85.7642)  Acc@5: 100.0000 (98.0346)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:37  Lr: 0.030000  Loss: -1.6760  Acc@1: 87.5000 (85.7679)  Acc@5: 100.0000 (98.0266)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:33  Lr: 0.030000  Loss: -1.6839  Acc@1: 87.5000 (85.7756)  Acc@5: 100.0000 (98.0311)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:29  Lr: 0.030000  Loss: -1.2718  Acc@1: 87.5000 (85.7670)  Acc@5: 100.0000 (98.0334)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:25  Lr: 0.030000  Loss: -1.4218  Acc@1: 81.2500 (85.7706)  Acc@5: 100.0000 (98.0358)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:21  Lr: 0.030000  Loss: -1.7350  Acc@1: 87.5000 (85.7782)  Acc@5: 100.0000 (98.0361)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:17  Lr: 0.030000  Loss: -1.7318  Acc@1: 87.5000 (85.7696)  Acc@5: 100.0000 (98.0364)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:13  Lr: 0.030000  Loss: -1.6321  Acc@1: 87.5000 (85.7651)  Acc@5: 100.0000 (98.0346)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:09  Lr: 0.030000  Loss: -1.3228  Acc@1: 87.5000 (85.7586)  Acc@5: 100.0000 (98.0309)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: -1.1260  Acc@1: 87.5000 (85.7562)  Acc@5: 100.0000 (98.0332)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: -1.5989  Acc@1: 87.5000 (85.7598)  Acc@5: 100.0000 (98.0355)  time: 0.3911  data: 0.0008  max mem: 2912
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: -1.7719  Acc@1: 87.5000 (85.7600)  Acc@5: 100.0000 (98.0380)  time: 0.3907  data: 0.0008  max mem: 2912
Train: Epoch[2/5] Total time: 0:20:21 (0.3910 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.7719  Acc@1: 87.5000 (85.7600)  Acc@5: 100.0000 (98.0380)
Train: Epoch[3/5]  [   0/3125]  eta: 0:38:01  Lr: 0.030000  Loss: -1.3974  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7300  data: 0.3370  max mem: 2912
Train: Epoch[3/5]  [  10/3125]  eta: 0:21:56  Lr: 0.030000  Loss: -1.2440  Acc@1: 81.2500 (80.1136)  Acc@5: 100.0000 (97.7273)  time: 0.4226  data: 0.0310  max mem: 2912
Train: Epoch[3/5]  [  20/3125]  eta: 0:21:03  Lr: 0.030000  Loss: -1.4379  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (98.5119)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  30/3125]  eta: 0:20:44  Lr: 0.030000  Loss: -1.8498  Acc@1: 87.5000 (83.8710)  Acc@5: 100.0000 (98.1855)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [  40/3125]  eta: 0:20:32  Lr: 0.030000  Loss: -1.6986  Acc@1: 87.5000 (84.1463)  Acc@5: 100.0000 (98.1707)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [  50/3125]  eta: 0:20:22  Lr: 0.030000  Loss: -1.5160  Acc@1: 87.5000 (85.0490)  Acc@5: 100.0000 (98.2843)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [  60/3125]  eta: 0:20:15  Lr: 0.030000  Loss: -1.2879  Acc@1: 93.7500 (85.8607)  Acc@5: 100.0000 (98.3607)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [  70/3125]  eta: 0:20:08  Lr: 0.030000  Loss: -1.4259  Acc@1: 93.7500 (86.1796)  Acc@5: 100.0000 (98.4155)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [  80/3125]  eta: 0:20:02  Lr: 0.030000  Loss: -1.3553  Acc@1: 87.5000 (86.1883)  Acc@5: 100.0000 (98.3025)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  90/3125]  eta: 0:19:57  Lr: 0.030000  Loss: -1.5663  Acc@1: 87.5000 (86.2637)  Acc@5: 100.0000 (98.3516)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 100/3125]  eta: 0:19:52  Lr: 0.030000  Loss: -1.9238  Acc@1: 93.7500 (86.6955)  Acc@5: 100.0000 (98.5149)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 110/3125]  eta: 0:19:46  Lr: 0.030000  Loss: -1.2032  Acc@1: 87.5000 (86.3739)  Acc@5: 100.0000 (98.5360)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 120/3125]  eta: 0:19:42  Lr: 0.030000  Loss: -1.5915  Acc@1: 81.2500 (86.0537)  Acc@5: 100.0000 (98.3988)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 130/3125]  eta: 0:19:37  Lr: 0.030000  Loss: -1.8103  Acc@1: 81.2500 (86.2118)  Acc@5: 100.0000 (98.3779)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 140/3125]  eta: 0:19:32  Lr: 0.030000  Loss: -1.1671  Acc@1: 87.5000 (86.1702)  Acc@5: 100.0000 (98.2270)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 150/3125]  eta: 0:19:27  Lr: 0.030000  Loss: -1.6921  Acc@1: 87.5000 (86.0927)  Acc@5: 100.0000 (98.2616)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 160/3125]  eta: 0:19:23  Lr: 0.030000  Loss: -1.6573  Acc@1: 87.5000 (85.9472)  Acc@5: 100.0000 (98.3307)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 170/3125]  eta: 0:19:19  Lr: 0.030000  Loss: -1.1507  Acc@1: 87.5000 (86.0746)  Acc@5: 100.0000 (98.3553)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 180/3125]  eta: 0:19:15  Lr: 0.030000  Loss: -1.2554  Acc@1: 87.5000 (85.8425)  Acc@5: 100.0000 (98.3080)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 190/3125]  eta: 0:19:10  Lr: 0.030000  Loss: -1.2732  Acc@1: 87.5000 (85.9293)  Acc@5: 100.0000 (98.3639)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 200/3125]  eta: 0:19:06  Lr: 0.030000  Loss: -1.4811  Acc@1: 87.5000 (85.8831)  Acc@5: 100.0000 (98.4453)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 210/3125]  eta: 0:19:02  Lr: 0.030000  Loss: -1.5032  Acc@1: 81.2500 (85.7227)  Acc@5: 100.0000 (98.3709)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 220/3125]  eta: 0:18:58  Lr: 0.030000  Loss: -0.6237  Acc@1: 87.5000 (85.6618)  Acc@5: 100.0000 (98.3597)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 230/3125]  eta: 0:18:53  Lr: 0.030000  Loss: -1.4867  Acc@1: 87.5000 (85.6061)  Acc@5: 100.0000 (98.3496)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 240/3125]  eta: 0:18:49  Lr: 0.030000  Loss: -1.0877  Acc@1: 81.2500 (85.3216)  Acc@5: 100.0000 (98.3402)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 250/3125]  eta: 0:18:45  Lr: 0.030000  Loss: -1.6394  Acc@1: 81.2500 (85.3835)  Acc@5: 100.0000 (98.3566)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 260/3125]  eta: 0:18:41  Lr: 0.030000  Loss: -1.7129  Acc@1: 87.5000 (85.5603)  Acc@5: 100.0000 (98.3716)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 270/3125]  eta: 0:18:37  Lr: 0.030000  Loss: -1.4399  Acc@1: 87.5000 (85.5627)  Acc@5: 100.0000 (98.3395)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 280/3125]  eta: 0:18:33  Lr: 0.030000  Loss: -1.9569  Acc@1: 87.5000 (85.6317)  Acc@5: 100.0000 (98.3096)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 290/3125]  eta: 0:18:29  Lr: 0.030000  Loss: -1.6620  Acc@1: 87.5000 (85.6744)  Acc@5: 100.0000 (98.3677)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 300/3125]  eta: 0:18:25  Lr: 0.030000  Loss: -0.9757  Acc@1: 81.2500 (85.5482)  Acc@5: 100.0000 (98.3389)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 310/3125]  eta: 0:18:20  Lr: 0.030000  Loss: -1.2099  Acc@1: 81.2500 (85.5105)  Acc@5: 100.0000 (98.3119)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 320/3125]  eta: 0:18:17  Lr: 0.030000  Loss: -1.9389  Acc@1: 87.5000 (85.6503)  Acc@5: 100.0000 (98.3450)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 330/3125]  eta: 0:18:12  Lr: 0.030000  Loss: -1.4630  Acc@1: 87.5000 (85.7440)  Acc@5: 100.0000 (98.3761)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 340/3125]  eta: 0:18:08  Lr: 0.030000  Loss: -1.5114  Acc@1: 87.5000 (85.8321)  Acc@5: 100.0000 (98.3504)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 350/3125]  eta: 0:18:04  Lr: 0.030000  Loss: -1.5370  Acc@1: 87.5000 (85.8262)  Acc@5: 100.0000 (98.3796)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 360/3125]  eta: 0:18:01  Lr: 0.030000  Loss: -1.7683  Acc@1: 87.5000 (85.7341)  Acc@5: 100.0000 (98.3726)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 370/3125]  eta: 0:17:57  Lr: 0.030000  Loss: -1.4033  Acc@1: 81.2500 (85.5964)  Acc@5: 100.0000 (98.3996)  time: 0.3907  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 380/3125]  eta: 0:17:53  Lr: 0.030000  Loss: -1.3804  Acc@1: 81.2500 (85.4823)  Acc@5: 100.0000 (98.3924)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 390/3125]  eta: 0:17:49  Lr: 0.030000  Loss: -1.6234  Acc@1: 81.2500 (85.5179)  Acc@5: 100.0000 (98.4015)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 400/3125]  eta: 0:17:45  Lr: 0.030000  Loss: -1.2256  Acc@1: 87.5000 (85.5362)  Acc@5: 100.0000 (98.4258)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 410/3125]  eta: 0:17:41  Lr: 0.030000  Loss: -0.7540  Acc@1: 87.5000 (85.5535)  Acc@5: 100.0000 (98.4185)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 420/3125]  eta: 0:17:37  Lr: 0.030000  Loss: -1.6616  Acc@1: 87.5000 (85.6740)  Acc@5: 100.0000 (98.4412)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 430/3125]  eta: 0:17:33  Lr: 0.030000  Loss: -1.7083  Acc@1: 87.5000 (85.7309)  Acc@5: 100.0000 (98.4484)  time: 0.3922  data: 0.0008  max mem: 2912
Train: Epoch[3/5]  [ 440/3125]  eta: 0:17:29  Lr: 0.030000  Loss: -1.7094  Acc@1: 87.5000 (85.7710)  Acc@5: 100.0000 (98.4694)  time: 0.3916  data: 0.0008  max mem: 2912
Train: Epoch[3/5]  [ 450/3125]  eta: 0:17:26  Lr: 0.030000  Loss: -1.5228  Acc@1: 87.5000 (85.6984)  Acc@5: 100.0000 (98.4895)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 460/3125]  eta: 0:17:22  Lr: 0.030000  Loss: -1.5751  Acc@1: 87.5000 (85.7375)  Acc@5: 100.0000 (98.5087)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 470/3125]  eta: 0:17:18  Lr: 0.030000  Loss: -1.8012  Acc@1: 87.5000 (85.7219)  Acc@5: 100.0000 (98.5005)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 480/3125]  eta: 0:17:14  Lr: 0.030000  Loss: -1.7540  Acc@1: 87.5000 (85.7978)  Acc@5: 100.0000 (98.5057)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 490/3125]  eta: 0:17:10  Lr: 0.030000  Loss: -1.3071  Acc@1: 87.5000 (85.8070)  Acc@5: 100.0000 (98.4598)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 500/3125]  eta: 0:17:06  Lr: 0.030000  Loss: -0.9484  Acc@1: 87.5000 (85.7909)  Acc@5: 100.0000 (98.4531)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 510/3125]  eta: 0:17:02  Lr: 0.030000  Loss: -1.6400  Acc@1: 87.5000 (85.8488)  Acc@5: 100.0000 (98.4222)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 520/3125]  eta: 0:16:58  Lr: 0.030000  Loss: -1.2759  Acc@1: 87.5000 (85.8565)  Acc@5: 100.0000 (98.4045)  time: 0.3928  data: 0.0006  max mem: 2912
Train: Epoch[3/5]  [ 530/3125]  eta: 0:16:54  Lr: 0.030000  Loss: -1.5210  Acc@1: 87.5000 (85.8169)  Acc@5: 100.0000 (98.3992)  time: 0.3922  data: 0.0006  max mem: 2912
Train: Epoch[3/5]  [ 540/3125]  eta: 0:16:51  Lr: 0.030000  Loss: -1.7639  Acc@1: 81.2500 (85.8249)  Acc@5: 100.0000 (98.3942)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 550/3125]  eta: 0:16:47  Lr: 0.030000  Loss: -1.7018  Acc@1: 87.5000 (85.8553)  Acc@5: 100.0000 (98.4120)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 560/3125]  eta: 0:16:43  Lr: 0.030000  Loss: -1.4135  Acc@1: 87.5000 (85.9180)  Acc@5: 100.0000 (98.4069)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 570/3125]  eta: 0:16:39  Lr: 0.030000  Loss: -1.9204  Acc@1: 87.5000 (85.9019)  Acc@5: 100.0000 (98.4238)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 580/3125]  eta: 0:16:35  Lr: 0.030000  Loss: -1.5298  Acc@1: 81.2500 (85.8649)  Acc@5: 100.0000 (98.3864)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 590/3125]  eta: 0:16:31  Lr: 0.030000  Loss: -1.3518  Acc@1: 87.5000 (85.8080)  Acc@5: 100.0000 (98.3714)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 600/3125]  eta: 0:16:27  Lr: 0.030000  Loss: -1.6846  Acc@1: 87.5000 (85.7737)  Acc@5: 100.0000 (98.3569)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 610/3125]  eta: 0:16:23  Lr: 0.030000  Loss: -1.7644  Acc@1: 81.2500 (85.7099)  Acc@5: 100.0000 (98.3429)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 620/3125]  eta: 0:16:19  Lr: 0.030000  Loss: -1.6615  Acc@1: 81.2500 (85.7589)  Acc@5: 100.0000 (98.3494)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 630/3125]  eta: 0:16:15  Lr: 0.030000  Loss: -1.1307  Acc@1: 87.5000 (85.7567)  Acc@5: 100.0000 (98.3360)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 640/3125]  eta: 0:16:11  Lr: 0.030000  Loss: -1.5453  Acc@1: 87.5000 (85.7254)  Acc@5: 100.0000 (98.3229)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 650/3125]  eta: 0:16:07  Lr: 0.030000  Loss: -1.5503  Acc@1: 81.2500 (85.6951)  Acc@5: 100.0000 (98.3199)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 660/3125]  eta: 0:16:03  Lr: 0.030000  Loss: -1.6884  Acc@1: 81.2500 (85.6373)  Acc@5: 100.0000 (98.3264)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 670/3125]  eta: 0:15:59  Lr: 0.030000  Loss: -1.3846  Acc@1: 87.5000 (85.6278)  Acc@5: 100.0000 (98.2955)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 680/3125]  eta: 0:15:55  Lr: 0.030000  Loss: -1.5300  Acc@1: 87.5000 (85.6186)  Acc@5: 100.0000 (98.2838)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 690/3125]  eta: 0:15:51  Lr: 0.030000  Loss: -1.6900  Acc@1: 87.5000 (85.6639)  Acc@5: 100.0000 (98.2905)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 700/3125]  eta: 0:15:48  Lr: 0.030000  Loss: -1.3961  Acc@1: 87.5000 (85.6455)  Acc@5: 100.0000 (98.2614)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 710/3125]  eta: 0:15:44  Lr: 0.030000  Loss: -1.4936  Acc@1: 87.5000 (85.7155)  Acc@5: 100.0000 (98.2683)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 720/3125]  eta: 0:15:40  Lr: 0.030000  Loss: -1.0080  Acc@1: 87.5000 (85.6796)  Acc@5: 100.0000 (98.2663)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 730/3125]  eta: 0:15:36  Lr: 0.030000  Loss: -1.3851  Acc@1: 81.2500 (85.6447)  Acc@5: 100.0000 (98.2729)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 740/3125]  eta: 0:15:32  Lr: 0.030000  Loss: -1.9014  Acc@1: 87.5000 (85.6866)  Acc@5: 100.0000 (98.2540)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 750/3125]  eta: 0:15:28  Lr: 0.030000  Loss: -1.5550  Acc@1: 87.5000 (85.6774)  Acc@5: 100.0000 (98.2357)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 760/3125]  eta: 0:15:24  Lr: 0.030000  Loss: -1.2995  Acc@1: 87.5000 (85.6767)  Acc@5: 100.0000 (98.2424)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 770/3125]  eta: 0:15:20  Lr: 0.030000  Loss: -1.7017  Acc@1: 81.2500 (85.6599)  Acc@5: 100.0000 (98.2409)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 780/3125]  eta: 0:15:16  Lr: 0.030000  Loss: -1.2143  Acc@1: 87.5000 (85.6914)  Acc@5: 100.0000 (98.2234)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 790/3125]  eta: 0:15:12  Lr: 0.030000  Loss: -1.5119  Acc@1: 87.5000 (85.7301)  Acc@5: 100.0000 (98.2301)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 800/3125]  eta: 0:15:08  Lr: 0.030000  Loss: -1.6946  Acc@1: 87.5000 (85.7444)  Acc@5: 100.0000 (98.2210)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 810/3125]  eta: 0:15:04  Lr: 0.030000  Loss: -1.2041  Acc@1: 87.5000 (85.7506)  Acc@5: 100.0000 (98.2352)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 820/3125]  eta: 0:15:01  Lr: 0.030000  Loss: -1.6933  Acc@1: 87.5000 (85.7491)  Acc@5: 100.0000 (98.2110)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 830/3125]  eta: 0:14:57  Lr: 0.030000  Loss: -1.5819  Acc@1: 87.5000 (85.7626)  Acc@5: 100.0000 (98.2175)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 840/3125]  eta: 0:14:53  Lr: 0.030000  Loss: -1.0500  Acc@1: 87.5000 (85.7387)  Acc@5: 100.0000 (98.2015)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 850/3125]  eta: 0:14:49  Lr: 0.030000  Loss: -1.6792  Acc@1: 87.5000 (85.7521)  Acc@5: 100.0000 (98.2006)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 860/3125]  eta: 0:14:45  Lr: 0.030000  Loss: -1.6946  Acc@1: 87.5000 (85.7506)  Acc@5: 100.0000 (98.1852)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 870/3125]  eta: 0:14:41  Lr: 0.030000  Loss: -1.4300  Acc@1: 81.2500 (85.7420)  Acc@5: 100.0000 (98.1702)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 880/3125]  eta: 0:14:37  Lr: 0.030000  Loss: -1.7852  Acc@1: 87.5000 (85.7832)  Acc@5: 100.0000 (98.1626)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 890/3125]  eta: 0:14:33  Lr: 0.030000  Loss: -1.6382  Acc@1: 87.5000 (85.8025)  Acc@5: 100.0000 (98.1692)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 900/3125]  eta: 0:14:29  Lr: 0.030000  Loss: -1.5248  Acc@1: 81.2500 (85.7519)  Acc@5: 100.0000 (98.1548)  time: 0.3921  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 910/3125]  eta: 0:14:25  Lr: 0.030000  Loss: -1.5005  Acc@1: 81.2500 (85.7368)  Acc@5: 100.0000 (98.1545)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 920/3125]  eta: 0:14:21  Lr: 0.030000  Loss: -1.1336  Acc@1: 87.5000 (85.7831)  Acc@5: 100.0000 (98.1474)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 930/3125]  eta: 0:14:17  Lr: 0.030000  Loss: -0.8562  Acc@1: 87.5000 (85.8016)  Acc@5: 100.0000 (98.1539)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 940/3125]  eta: 0:14:14  Lr: 0.030000  Loss: -1.5727  Acc@1: 87.5000 (85.8262)  Acc@5: 100.0000 (98.1469)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 950/3125]  eta: 0:14:10  Lr: 0.030000  Loss: -1.5331  Acc@1: 87.5000 (85.8438)  Acc@5: 100.0000 (98.1598)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 960/3125]  eta: 0:14:06  Lr: 0.030000  Loss: -1.4290  Acc@1: 87.5000 (85.8286)  Acc@5: 100.0000 (98.1660)  time: 0.3901  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 970/3125]  eta: 0:14:02  Lr: 0.030000  Loss: -1.4137  Acc@1: 87.5000 (85.8522)  Acc@5: 100.0000 (98.1784)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 980/3125]  eta: 0:13:58  Lr: 0.030000  Loss: -1.6563  Acc@1: 87.5000 (85.8435)  Acc@5: 100.0000 (98.1715)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 990/3125]  eta: 0:13:54  Lr: 0.030000  Loss: -1.4410  Acc@1: 87.5000 (85.8602)  Acc@5: 100.0000 (98.1647)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1000/3125]  eta: 0:13:50  Lr: 0.030000  Loss: -1.3542  Acc@1: 87.5000 (85.8954)  Acc@5: 100.0000 (98.1706)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1010/3125]  eta: 0:13:46  Lr: 0.030000  Loss: -1.7212  Acc@1: 87.5000 (85.8803)  Acc@5: 100.0000 (98.1763)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1020/3125]  eta: 0:13:42  Lr: 0.030000  Loss: -1.4643  Acc@1: 87.5000 (85.9329)  Acc@5: 100.0000 (98.1942)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1030/3125]  eta: 0:13:38  Lr: 0.030000  Loss: -1.5870  Acc@1: 87.5000 (85.9299)  Acc@5: 100.0000 (98.2056)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1040/3125]  eta: 0:13:34  Lr: 0.030000  Loss: -1.5976  Acc@1: 87.5000 (85.9150)  Acc@5: 100.0000 (98.2109)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1050/3125]  eta: 0:13:30  Lr: 0.030000  Loss: -1.6361  Acc@1: 87.5000 (85.9360)  Acc@5: 100.0000 (98.2160)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1060/3125]  eta: 0:13:26  Lr: 0.030000  Loss: -1.7014  Acc@1: 87.5000 (85.9390)  Acc@5: 100.0000 (98.2151)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1070/3125]  eta: 0:13:23  Lr: 0.030000  Loss: -1.7348  Acc@1: 93.7500 (85.9886)  Acc@5: 100.0000 (98.2201)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1080/3125]  eta: 0:13:19  Lr: 0.030000  Loss: -1.7451  Acc@1: 93.7500 (86.0430)  Acc@5: 100.0000 (98.2308)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1090/3125]  eta: 0:13:15  Lr: 0.030000  Loss: -1.3272  Acc@1: 93.7500 (86.0621)  Acc@5: 100.0000 (98.2356)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1100/3125]  eta: 0:13:11  Lr: 0.030000  Loss: -1.8216  Acc@1: 87.5000 (86.0695)  Acc@5: 100.0000 (98.2346)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1110/3125]  eta: 0:13:07  Lr: 0.030000  Loss: -1.2859  Acc@1: 87.5000 (86.1105)  Acc@5: 100.0000 (98.2392)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1120/3125]  eta: 0:13:03  Lr: 0.030000  Loss: -1.6965  Acc@1: 87.5000 (86.0950)  Acc@5: 100.0000 (98.2382)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1130/3125]  eta: 0:12:59  Lr: 0.030000  Loss: -1.7329  Acc@1: 87.5000 (86.1351)  Acc@5: 100.0000 (98.2482)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1140/3125]  eta: 0:12:55  Lr: 0.030000  Loss: -1.7569  Acc@1: 87.5000 (86.1470)  Acc@5: 100.0000 (98.2472)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1150/3125]  eta: 0:12:51  Lr: 0.030000  Loss: -1.0336  Acc@1: 87.5000 (86.1696)  Acc@5: 100.0000 (98.2570)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1160/3125]  eta: 0:12:48  Lr: 0.030000  Loss: -1.0696  Acc@1: 87.5000 (86.1865)  Acc@5: 100.0000 (98.2612)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1170/3125]  eta: 0:12:44  Lr: 0.030000  Loss: -1.1859  Acc@1: 87.5000 (86.2137)  Acc@5: 100.0000 (98.2547)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1180/3125]  eta: 0:12:40  Lr: 0.030000  Loss: -1.1213  Acc@1: 93.7500 (86.2352)  Acc@5: 100.0000 (98.2642)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1190/3125]  eta: 0:12:36  Lr: 0.030000  Loss: -1.3070  Acc@1: 87.5000 (86.2406)  Acc@5: 100.0000 (98.2578)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1200/3125]  eta: 0:12:32  Lr: 0.030000  Loss: -1.3530  Acc@1: 81.2500 (86.2250)  Acc@5: 100.0000 (98.2671)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1210/3125]  eta: 0:12:28  Lr: 0.030000  Loss: -1.4541  Acc@1: 81.2500 (86.2201)  Acc@5: 100.0000 (98.2659)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1220/3125]  eta: 0:12:24  Lr: 0.030000  Loss: -1.6829  Acc@1: 81.2500 (86.2101)  Acc@5: 100.0000 (98.2494)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1230/3125]  eta: 0:12:20  Lr: 0.030000  Loss: -1.0506  Acc@1: 81.2500 (86.2053)  Acc@5: 100.0000 (98.2484)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1240/3125]  eta: 0:12:16  Lr: 0.030000  Loss: -1.7620  Acc@1: 87.5000 (86.2510)  Acc@5: 100.0000 (98.2474)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1250/3125]  eta: 0:12:12  Lr: 0.030000  Loss: -1.0585  Acc@1: 81.2500 (86.1910)  Acc@5: 100.0000 (98.2364)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1260/3125]  eta: 0:12:08  Lr: 0.030000  Loss: -1.3257  Acc@1: 81.2500 (86.1717)  Acc@5: 100.0000 (98.2355)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1270/3125]  eta: 0:12:05  Lr: 0.030000  Loss: -1.8706  Acc@1: 81.2500 (86.1772)  Acc@5: 100.0000 (98.2297)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1280/3125]  eta: 0:12:01  Lr: 0.030000  Loss: -1.4496  Acc@1: 81.2500 (86.1680)  Acc@5: 100.0000 (98.2240)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1290/3125]  eta: 0:11:57  Lr: 0.030000  Loss: -1.8233  Acc@1: 87.5000 (86.2074)  Acc@5: 100.0000 (98.2233)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1300/3125]  eta: 0:11:53  Lr: 0.030000  Loss: -0.9327  Acc@1: 87.5000 (86.2029)  Acc@5: 100.0000 (98.2225)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1310/3125]  eta: 0:11:49  Lr: 0.030000  Loss: -1.5004  Acc@1: 87.5000 (86.1985)  Acc@5: 100.0000 (98.2313)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1320/3125]  eta: 0:11:45  Lr: 0.030000  Loss: -1.3537  Acc@1: 81.2500 (86.1942)  Acc@5: 100.0000 (98.2258)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1330/3125]  eta: 0:11:41  Lr: 0.030000  Loss: -1.0474  Acc@1: 87.5000 (86.2322)  Acc@5: 100.0000 (98.2156)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1340/3125]  eta: 0:11:37  Lr: 0.030000  Loss: -1.5008  Acc@1: 87.5000 (86.2183)  Acc@5: 100.0000 (98.2196)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1350/3125]  eta: 0:11:33  Lr: 0.030000  Loss: -0.9432  Acc@1: 87.5000 (86.2232)  Acc@5: 100.0000 (98.2189)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1360/3125]  eta: 0:11:29  Lr: 0.030000  Loss: -1.4532  Acc@1: 87.5000 (86.2601)  Acc@5: 100.0000 (98.2320)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1370/3125]  eta: 0:11:25  Lr: 0.030000  Loss: -1.2845  Acc@1: 87.5000 (86.2691)  Acc@5: 100.0000 (98.2267)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1380/3125]  eta: 0:11:22  Lr: 0.030000  Loss: -0.6714  Acc@1: 87.5000 (86.2690)  Acc@5: 100.0000 (98.2214)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1390/3125]  eta: 0:11:18  Lr: 0.030000  Loss: -1.7566  Acc@1: 87.5000 (86.2868)  Acc@5: 100.0000 (98.2252)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1400/3125]  eta: 0:11:14  Lr: 0.030000  Loss: -1.5828  Acc@1: 87.5000 (86.2821)  Acc@5: 100.0000 (98.2334)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1410/3125]  eta: 0:11:10  Lr: 0.030000  Loss: -1.4786  Acc@1: 87.5000 (86.2775)  Acc@5: 100.0000 (98.2459)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1420/3125]  eta: 0:11:06  Lr: 0.030000  Loss: -1.2001  Acc@1: 81.2500 (86.2597)  Acc@5: 100.0000 (98.2451)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1430/3125]  eta: 0:11:02  Lr: 0.030000  Loss: -0.7250  Acc@1: 87.5000 (86.2902)  Acc@5: 100.0000 (98.2486)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1440/3125]  eta: 0:10:58  Lr: 0.030000  Loss: -1.3589  Acc@1: 87.5000 (86.3159)  Acc@5: 100.0000 (98.2608)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1450/3125]  eta: 0:10:54  Lr: 0.030000  Loss: -1.7082  Acc@1: 87.5000 (86.3327)  Acc@5: 100.0000 (98.2641)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1460/3125]  eta: 0:10:50  Lr: 0.030000  Loss: -1.2636  Acc@1: 87.5000 (86.3492)  Acc@5: 100.0000 (98.2632)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1470/3125]  eta: 0:10:46  Lr: 0.030000  Loss: -1.5796  Acc@1: 87.5000 (86.3528)  Acc@5: 100.0000 (98.2707)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1480/3125]  eta: 0:10:42  Lr: 0.030000  Loss: -1.2186  Acc@1: 87.5000 (86.3690)  Acc@5: 100.0000 (98.2740)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1490/3125]  eta: 0:10:39  Lr: 0.030000  Loss: -1.7840  Acc@1: 87.5000 (86.3892)  Acc@5: 100.0000 (98.2772)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1500/3125]  eta: 0:10:35  Lr: 0.030000  Loss: -1.6315  Acc@1: 87.5000 (86.4132)  Acc@5: 100.0000 (98.2761)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1510/3125]  eta: 0:10:31  Lr: 0.030000  Loss: -1.6703  Acc@1: 87.5000 (86.3956)  Acc@5: 100.0000 (98.2751)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1520/3125]  eta: 0:10:27  Lr: 0.030000  Loss: -1.7260  Acc@1: 81.2500 (86.3659)  Acc@5: 100.0000 (98.2577)  time: 0.3888  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1530/3125]  eta: 0:10:23  Lr: 0.030000  Loss: -1.7110  Acc@1: 81.2500 (86.3365)  Acc@5: 100.0000 (98.2569)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1540/3125]  eta: 0:10:19  Lr: 0.030000  Loss: -1.3919  Acc@1: 87.5000 (86.3603)  Acc@5: 100.0000 (98.2601)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1550/3125]  eta: 0:10:15  Lr: 0.030000  Loss: -1.6467  Acc@1: 93.7500 (86.3999)  Acc@5: 100.0000 (98.2632)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1560/3125]  eta: 0:10:11  Lr: 0.030000  Loss: -1.6739  Acc@1: 93.7500 (86.4070)  Acc@5: 100.0000 (98.2503)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1570/3125]  eta: 0:10:07  Lr: 0.030000  Loss: -1.3923  Acc@1: 87.5000 (86.4099)  Acc@5: 100.0000 (98.2376)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1580/3125]  eta: 0:10:03  Lr: 0.030000  Loss: -1.7612  Acc@1: 87.5000 (86.4287)  Acc@5: 100.0000 (98.2448)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1590/3125]  eta: 0:09:59  Lr: 0.030000  Loss: -1.6533  Acc@1: 87.5000 (86.4118)  Acc@5: 100.0000 (98.2401)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1600/3125]  eta: 0:09:55  Lr: 0.030000  Loss: -0.8329  Acc@1: 81.2500 (86.4030)  Acc@5: 100.0000 (98.2355)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1610/3125]  eta: 0:09:52  Lr: 0.030000  Loss: -1.1338  Acc@1: 87.5000 (86.4176)  Acc@5: 100.0000 (98.2387)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1620/3125]  eta: 0:09:48  Lr: 0.030000  Loss: -1.7411  Acc@1: 93.7500 (86.4474)  Acc@5: 100.0000 (98.2303)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1630/3125]  eta: 0:09:44  Lr: 0.030000  Loss: -1.0244  Acc@1: 87.5000 (86.4385)  Acc@5: 100.0000 (98.2296)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1640/3125]  eta: 0:09:40  Lr: 0.030000  Loss: -1.4211  Acc@1: 87.5000 (86.4526)  Acc@5: 100.0000 (98.2366)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1650/3125]  eta: 0:09:36  Lr: 0.030000  Loss: -1.7834  Acc@1: 87.5000 (86.4287)  Acc@5: 100.0000 (98.2397)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1660/3125]  eta: 0:09:32  Lr: 0.030000  Loss: -0.2427  Acc@1: 81.2500 (86.4126)  Acc@5: 100.0000 (98.2315)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1670/3125]  eta: 0:09:28  Lr: 0.030000  Loss: -1.6879  Acc@1: 87.5000 (86.4228)  Acc@5: 100.0000 (98.2421)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1680/3125]  eta: 0:09:24  Lr: 0.030000  Loss: -1.8660  Acc@1: 87.5000 (86.4366)  Acc@5: 100.0000 (98.2488)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1690/3125]  eta: 0:09:20  Lr: 0.030000  Loss: -1.3388  Acc@1: 87.5000 (86.4614)  Acc@5: 100.0000 (98.2444)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1700/3125]  eta: 0:09:16  Lr: 0.030000  Loss: -1.2516  Acc@1: 87.5000 (86.4675)  Acc@5: 100.0000 (98.2437)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1710/3125]  eta: 0:09:12  Lr: 0.030000  Loss: -1.5993  Acc@1: 87.5000 (86.5028)  Acc@5: 100.0000 (98.2503)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1720/3125]  eta: 0:09:09  Lr: 0.030000  Loss: -1.4841  Acc@1: 93.7500 (86.5122)  Acc@5: 100.0000 (98.2496)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1730/3125]  eta: 0:09:05  Lr: 0.030000  Loss: -1.6998  Acc@1: 87.5000 (86.5179)  Acc@5: 100.0000 (98.2488)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1740/3125]  eta: 0:09:01  Lr: 0.030000  Loss: -1.5636  Acc@1: 87.5000 (86.5164)  Acc@5: 100.0000 (98.2517)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1750/3125]  eta: 0:08:57  Lr: 0.030000  Loss: -1.9292  Acc@1: 81.2500 (86.5006)  Acc@5: 100.0000 (98.2546)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1760/3125]  eta: 0:08:53  Lr: 0.030000  Loss: -1.6927  Acc@1: 81.2500 (86.5133)  Acc@5: 100.0000 (98.2574)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1770/3125]  eta: 0:08:49  Lr: 0.030000  Loss: -1.3705  Acc@1: 87.5000 (86.5189)  Acc@5: 100.0000 (98.2531)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1780/3125]  eta: 0:08:45  Lr: 0.030000  Loss: -1.4404  Acc@1: 87.5000 (86.5034)  Acc@5: 100.0000 (98.2489)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1790/3125]  eta: 0:08:41  Lr: 0.030000  Loss: -1.4087  Acc@1: 87.5000 (86.5159)  Acc@5: 100.0000 (98.2552)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1800/3125]  eta: 0:08:37  Lr: 0.030000  Loss: -1.6809  Acc@1: 87.5000 (86.5387)  Acc@5: 100.0000 (98.2614)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1810/3125]  eta: 0:08:33  Lr: 0.030000  Loss: -1.5370  Acc@1: 87.5000 (86.5233)  Acc@5: 100.0000 (98.2572)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1820/3125]  eta: 0:08:29  Lr: 0.030000  Loss: -1.5856  Acc@1: 87.5000 (86.5321)  Acc@5: 100.0000 (98.2633)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1830/3125]  eta: 0:08:26  Lr: 0.030000  Loss: -1.0097  Acc@1: 87.5000 (86.5238)  Acc@5: 100.0000 (98.2660)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1840/3125]  eta: 0:08:22  Lr: 0.030000  Loss: -1.5854  Acc@1: 81.2500 (86.5121)  Acc@5: 100.0000 (98.2584)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1850/3125]  eta: 0:08:18  Lr: 0.030000  Loss: -1.7703  Acc@1: 87.5000 (86.5343)  Acc@5: 100.0000 (98.2645)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1860/3125]  eta: 0:08:14  Lr: 0.030000  Loss: -1.4357  Acc@1: 87.5000 (86.5261)  Acc@5: 100.0000 (98.2570)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1870/3125]  eta: 0:08:10  Lr: 0.030000  Loss: -0.9749  Acc@1: 81.2500 (86.5212)  Acc@5: 100.0000 (98.2496)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1880/3125]  eta: 0:08:06  Lr: 0.030000  Loss: -1.3607  Acc@1: 87.5000 (86.5364)  Acc@5: 100.0000 (98.2489)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1890/3125]  eta: 0:08:02  Lr: 0.030000  Loss: -1.4891  Acc@1: 87.5000 (86.5283)  Acc@5: 100.0000 (98.2483)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:58  Lr: 0.030000  Loss: -1.4016  Acc@1: 87.5000 (86.5301)  Acc@5: 100.0000 (98.2509)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1910/3125]  eta: 0:07:54  Lr: 0.030000  Loss: -1.1445  Acc@1: 87.5000 (86.5417)  Acc@5: 100.0000 (98.2535)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1920/3125]  eta: 0:07:50  Lr: 0.030000  Loss: -1.3586  Acc@1: 87.5000 (86.5532)  Acc@5: 100.0000 (98.2496)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1930/3125]  eta: 0:07:46  Lr: 0.030000  Loss: -1.3385  Acc@1: 87.5000 (86.5549)  Acc@5: 100.0000 (98.2490)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1940/3125]  eta: 0:07:43  Lr: 0.030000  Loss: -1.5125  Acc@1: 87.5000 (86.5598)  Acc@5: 100.0000 (98.2387)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1950/3125]  eta: 0:07:39  Lr: 0.030000  Loss: -1.6507  Acc@1: 87.5000 (86.5742)  Acc@5: 100.0000 (98.2381)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1960/3125]  eta: 0:07:35  Lr: 0.030000  Loss: -1.6916  Acc@1: 87.5000 (86.5630)  Acc@5: 100.0000 (98.2407)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1970/3125]  eta: 0:07:31  Lr: 0.030000  Loss: -1.1742  Acc@1: 81.2500 (86.5519)  Acc@5: 100.0000 (98.2464)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1980/3125]  eta: 0:07:27  Lr: 0.030000  Loss: -0.8574  Acc@1: 87.5000 (86.5440)  Acc@5: 100.0000 (98.2427)  time: 0.3888  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1990/3125]  eta: 0:07:23  Lr: 0.030000  Loss: -1.6131  Acc@1: 87.5000 (86.5394)  Acc@5: 100.0000 (98.2421)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2000/3125]  eta: 0:07:19  Lr: 0.030000  Loss: -1.4574  Acc@1: 87.5000 (86.5286)  Acc@5: 100.0000 (98.2353)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2010/3125]  eta: 0:07:15  Lr: 0.030000  Loss: -0.9533  Acc@1: 81.2500 (86.5055)  Acc@5: 100.0000 (98.2378)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2020/3125]  eta: 0:07:11  Lr: 0.030000  Loss: -1.7395  Acc@1: 87.5000 (86.5197)  Acc@5: 100.0000 (98.2465)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2030/3125]  eta: 0:07:07  Lr: 0.030000  Loss: -1.8962  Acc@1: 87.5000 (86.5214)  Acc@5: 100.0000 (98.2490)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2040/3125]  eta: 0:07:03  Lr: 0.030000  Loss: -1.4371  Acc@1: 87.5000 (86.5232)  Acc@5: 100.0000 (98.2515)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:59  Lr: 0.030000  Loss: -1.6077  Acc@1: 81.2500 (86.5157)  Acc@5: 100.0000 (98.2509)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:56  Lr: 0.030000  Loss: -1.5951  Acc@1: 87.5000 (86.5144)  Acc@5: 100.0000 (98.2533)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:52  Lr: 0.030000  Loss: -1.0738  Acc@1: 87.5000 (86.5101)  Acc@5: 100.0000 (98.2527)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2080/3125]  eta: 0:06:48  Lr: 0.030000  Loss: -1.3600  Acc@1: 87.5000 (86.5299)  Acc@5: 100.0000 (98.2550)  time: 0.3884  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2090/3125]  eta: 0:06:44  Lr: 0.030000  Loss: -1.4604  Acc@1: 93.7500 (86.5525)  Acc@5: 100.0000 (98.2544)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2100/3125]  eta: 0:06:40  Lr: 0.030000  Loss: -1.4891  Acc@1: 87.5000 (86.5421)  Acc@5: 100.0000 (98.2598)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2110/3125]  eta: 0:06:36  Lr: 0.030000  Loss: -1.5589  Acc@1: 87.5000 (86.5496)  Acc@5: 100.0000 (98.2621)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2120/3125]  eta: 0:06:32  Lr: 0.030000  Loss: -1.0289  Acc@1: 87.5000 (86.5600)  Acc@5: 100.0000 (98.2673)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2130/3125]  eta: 0:06:28  Lr: 0.030000  Loss: -1.0966  Acc@1: 87.5000 (86.5644)  Acc@5: 100.0000 (98.2725)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2140/3125]  eta: 0:06:24  Lr: 0.030000  Loss: -1.4451  Acc@1: 87.5000 (86.5483)  Acc@5: 100.0000 (98.2718)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2150/3125]  eta: 0:06:20  Lr: 0.030000  Loss: -1.5034  Acc@1: 87.5000 (86.5470)  Acc@5: 100.0000 (98.2741)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2160/3125]  eta: 0:06:16  Lr: 0.030000  Loss: -1.2984  Acc@1: 87.5000 (86.5600)  Acc@5: 100.0000 (98.2763)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2170/3125]  eta: 0:06:13  Lr: 0.030000  Loss: -0.9525  Acc@1: 87.5000 (86.5557)  Acc@5: 100.0000 (98.2698)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2180/3125]  eta: 0:06:09  Lr: 0.030000  Loss: -1.6972  Acc@1: 87.5000 (86.5543)  Acc@5: 100.0000 (98.2548)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2190/3125]  eta: 0:06:05  Lr: 0.030000  Loss: -1.3702  Acc@1: 87.5000 (86.5472)  Acc@5: 100.0000 (98.2542)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2200/3125]  eta: 0:06:01  Lr: 0.030000  Loss: -1.3043  Acc@1: 87.5000 (86.5402)  Acc@5: 100.0000 (98.2565)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:57  Lr: 0.030000  Loss: -1.4792  Acc@1: 87.5000 (86.5191)  Acc@5: 100.0000 (98.2502)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:53  Lr: 0.030000  Loss: -1.4006  Acc@1: 81.2500 (86.5207)  Acc@5: 100.0000 (98.2525)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:49  Lr: 0.030000  Loss: -1.7541  Acc@1: 87.5000 (86.5307)  Acc@5: 100.0000 (98.2547)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:45  Lr: 0.030000  Loss: -1.4399  Acc@1: 87.5000 (86.5322)  Acc@5: 100.0000 (98.2597)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:41  Lr: 0.030000  Loss: -0.8291  Acc@1: 87.5000 (86.5227)  Acc@5: 100.0000 (98.2563)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2260/3125]  eta: 0:05:37  Lr: 0.030000  Loss: -1.6712  Acc@1: 87.5000 (86.5463)  Acc@5: 100.0000 (98.2585)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2270/3125]  eta: 0:05:33  Lr: 0.030000  Loss: -1.4947  Acc@1: 87.5000 (86.5478)  Acc@5: 100.0000 (98.2579)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2280/3125]  eta: 0:05:30  Lr: 0.030000  Loss: -1.4643  Acc@1: 87.5000 (86.5821)  Acc@5: 100.0000 (98.2628)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2290/3125]  eta: 0:05:26  Lr: 0.030000  Loss: -1.4963  Acc@1: 93.7500 (86.6107)  Acc@5: 100.0000 (98.2704)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2300/3125]  eta: 0:05:22  Lr: 0.030000  Loss: -1.5046  Acc@1: 93.7500 (86.5982)  Acc@5: 100.0000 (98.2671)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2310/3125]  eta: 0:05:18  Lr: 0.030000  Loss: -1.1054  Acc@1: 87.5000 (86.5994)  Acc@5: 100.0000 (98.2664)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2320/3125]  eta: 0:05:14  Lr: 0.030000  Loss: -1.5440  Acc@1: 87.5000 (86.5898)  Acc@5: 100.0000 (98.2658)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2330/3125]  eta: 0:05:10  Lr: 0.030000  Loss: -1.5546  Acc@1: 87.5000 (86.5911)  Acc@5: 100.0000 (98.2733)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2340/3125]  eta: 0:05:06  Lr: 0.030000  Loss: -1.4044  Acc@1: 87.5000 (86.5896)  Acc@5: 100.0000 (98.2726)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2350/3125]  eta: 0:05:02  Lr: 0.030000  Loss: -1.3791  Acc@1: 87.5000 (86.6014)  Acc@5: 100.0000 (98.2773)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:58  Lr: 0.030000  Loss: -1.2995  Acc@1: 87.5000 (86.6053)  Acc@5: 100.0000 (98.2793)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:54  Lr: 0.030000  Loss: -1.1523  Acc@1: 87.5000 (86.5985)  Acc@5: 100.0000 (98.2813)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:51  Lr: 0.030000  Loss: -1.3668  Acc@1: 87.5000 (86.6023)  Acc@5: 100.0000 (98.2754)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:47  Lr: 0.030000  Loss: -1.6182  Acc@1: 87.5000 (86.6008)  Acc@5: 93.7500 (98.2669)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:43  Lr: 0.030000  Loss: -1.7246  Acc@1: 87.5000 (86.6097)  Acc@5: 100.0000 (98.2690)  time: 0.3935  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:39  Lr: 0.030000  Loss: -1.5342  Acc@1: 87.5000 (86.6057)  Acc@5: 100.0000 (98.2709)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:35  Lr: 0.030000  Loss: -1.5698  Acc@1: 81.2500 (86.5990)  Acc@5: 100.0000 (98.2626)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2430/3125]  eta: 0:04:31  Lr: 0.030000  Loss: -1.1389  Acc@1: 81.2500 (86.5925)  Acc@5: 100.0000 (98.2620)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2440/3125]  eta: 0:04:27  Lr: 0.030000  Loss: -1.5345  Acc@1: 81.2500 (86.5936)  Acc@5: 100.0000 (98.2640)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2450/3125]  eta: 0:04:23  Lr: 0.030000  Loss: -1.3582  Acc@1: 81.2500 (86.5591)  Acc@5: 100.0000 (98.2533)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2460/3125]  eta: 0:04:19  Lr: 0.030000  Loss: -1.3942  Acc@1: 81.2500 (86.5502)  Acc@5: 100.0000 (98.2527)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2470/3125]  eta: 0:04:15  Lr: 0.030000  Loss: -1.7142  Acc@1: 87.5000 (86.5692)  Acc@5: 100.0000 (98.2548)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2480/3125]  eta: 0:04:11  Lr: 0.030000  Loss: -1.5398  Acc@1: 87.5000 (86.5427)  Acc@5: 100.0000 (98.2517)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2490/3125]  eta: 0:04:08  Lr: 0.030000  Loss: -1.1831  Acc@1: 87.5000 (86.5616)  Acc@5: 100.0000 (98.2537)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2500/3125]  eta: 0:04:04  Lr: 0.030000  Loss: -1.6047  Acc@1: 87.5000 (86.5754)  Acc@5: 100.0000 (98.2482)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2510/3125]  eta: 0:04:00  Lr: 0.030000  Loss: -1.6912  Acc@1: 87.5000 (86.5840)  Acc@5: 100.0000 (98.2552)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:56  Lr: 0.030000  Loss: -1.7331  Acc@1: 87.5000 (86.5901)  Acc@5: 100.0000 (98.2547)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:52  Lr: 0.030000  Loss: -1.5620  Acc@1: 87.5000 (86.5814)  Acc@5: 100.0000 (98.2541)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:48  Lr: 0.030000  Loss: -1.5327  Acc@1: 87.5000 (86.5752)  Acc@5: 100.0000 (98.2561)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:44  Lr: 0.030000  Loss: -1.6190  Acc@1: 87.5000 (86.5910)  Acc@5: 100.0000 (98.2580)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:40  Lr: 0.030000  Loss: -1.4271  Acc@1: 87.5000 (86.5897)  Acc@5: 100.0000 (98.2551)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:36  Lr: 0.030000  Loss: -1.7144  Acc@1: 87.5000 (86.6005)  Acc@5: 100.0000 (98.2619)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:32  Lr: 0.030000  Loss: -1.4712  Acc@1: 87.5000 (86.5992)  Acc@5: 100.0000 (98.2638)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:29  Lr: 0.030000  Loss: -1.6165  Acc@1: 93.7500 (86.6123)  Acc@5: 100.0000 (98.2680)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:25  Lr: 0.030000  Loss: -1.7192  Acc@1: 87.5000 (86.6157)  Acc@5: 100.0000 (98.2723)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2610/3125]  eta: 0:03:21  Lr: 0.030000  Loss: -1.5175  Acc@1: 81.2500 (86.6143)  Acc@5: 100.0000 (98.2765)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2620/3125]  eta: 0:03:17  Lr: 0.030000  Loss: -1.4568  Acc@1: 87.5000 (86.6368)  Acc@5: 100.0000 (98.2783)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2630/3125]  eta: 0:03:13  Lr: 0.030000  Loss: -1.6035  Acc@1: 87.5000 (86.6377)  Acc@5: 100.0000 (98.2754)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2640/3125]  eta: 0:03:09  Lr: 0.030000  Loss: -1.5744  Acc@1: 87.5000 (86.6622)  Acc@5: 100.0000 (98.2772)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2650/3125]  eta: 0:03:05  Lr: 0.030000  Loss: -1.2292  Acc@1: 87.5000 (86.6631)  Acc@5: 100.0000 (98.2790)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2660/3125]  eta: 0:03:01  Lr: 0.030000  Loss: -1.6821  Acc@1: 87.5000 (86.6474)  Acc@5: 100.0000 (98.2784)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:57  Lr: 0.030000  Loss: -1.2943  Acc@1: 81.2500 (86.6389)  Acc@5: 100.0000 (98.2778)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:53  Lr: 0.030000  Loss: -1.2784  Acc@1: 81.2500 (86.6165)  Acc@5: 100.0000 (98.2749)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:49  Lr: 0.030000  Loss: -1.1267  Acc@1: 81.2500 (86.6151)  Acc@5: 100.0000 (98.2767)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:46  Lr: 0.030000  Loss: -1.6469  Acc@1: 87.5000 (86.6114)  Acc@5: 100.0000 (98.2761)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:42  Lr: 0.030000  Loss: -1.4399  Acc@1: 87.5000 (86.6032)  Acc@5: 100.0000 (98.2778)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:38  Lr: 0.030000  Loss: -1.8023  Acc@1: 87.5000 (86.5950)  Acc@5: 100.0000 (98.2773)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:34  Lr: 0.030000  Loss: -1.3104  Acc@1: 87.5000 (86.5937)  Acc@5: 100.0000 (98.2699)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:30  Lr: 0.030000  Loss: -1.8482  Acc@1: 81.2500 (86.5856)  Acc@5: 100.0000 (98.2716)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:26  Lr: 0.030000  Loss: -1.7302  Acc@1: 81.2500 (86.5799)  Acc@5: 100.0000 (98.2756)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:22  Lr: 0.030000  Loss: -1.5949  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.2819)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:18  Lr: 0.030000  Loss: -1.7281  Acc@1: 87.5000 (86.6001)  Acc@5: 100.0000 (98.2813)  time: 0.3885  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2780/3125]  eta: 0:02:14  Lr: 0.030000  Loss: -1.2861  Acc@1: 87.5000 (86.5876)  Acc@5: 100.0000 (98.2762)  time: 0.3888  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2790/3125]  eta: 0:02:10  Lr: 0.030000  Loss: -1.1564  Acc@1: 81.2500 (86.5729)  Acc@5: 100.0000 (98.2712)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2800/3125]  eta: 0:02:06  Lr: 0.030000  Loss: -1.1430  Acc@1: 81.2500 (86.5539)  Acc@5: 100.0000 (98.2618)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2810/3125]  eta: 0:02:03  Lr: 0.030000  Loss: -1.7742  Acc@1: 81.2500 (86.5506)  Acc@5: 100.0000 (98.2680)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:59  Lr: 0.030000  Loss: -1.3582  Acc@1: 87.5000 (86.5540)  Acc@5: 100.0000 (98.2675)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:55  Lr: 0.030000  Loss: -1.5178  Acc@1: 87.5000 (86.5507)  Acc@5: 100.0000 (98.2670)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:51  Lr: 0.030000  Loss: -1.5654  Acc@1: 87.5000 (86.5650)  Acc@5: 100.0000 (98.2709)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:47  Lr: 0.030000  Loss: -1.2988  Acc@1: 93.7500 (86.5749)  Acc@5: 100.0000 (98.2703)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:43  Lr: 0.030000  Loss: -1.1672  Acc@1: 93.7500 (86.5847)  Acc@5: 100.0000 (98.2742)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:39  Lr: 0.030000  Loss: -1.6029  Acc@1: 87.5000 (86.5835)  Acc@5: 100.0000 (98.2759)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:35  Lr: 0.030000  Loss: -1.6565  Acc@1: 87.5000 (86.5780)  Acc@5: 100.0000 (98.2753)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:31  Lr: 0.030000  Loss: -1.5808  Acc@1: 87.5000 (86.5704)  Acc@5: 100.0000 (98.2748)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:27  Lr: 0.030000  Loss: -1.0071  Acc@1: 81.2500 (86.5499)  Acc@5: 100.0000 (98.2721)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:23  Lr: 0.030000  Loss: -1.2578  Acc@1: 81.2500 (86.5575)  Acc@5: 100.0000 (98.2695)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:20  Lr: 0.030000  Loss: -1.7343  Acc@1: 87.5000 (86.5478)  Acc@5: 100.0000 (98.2711)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:16  Lr: 0.030000  Loss: -1.3980  Acc@1: 87.5000 (86.5575)  Acc@5: 100.0000 (98.2728)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:12  Lr: 0.030000  Loss: -1.1795  Acc@1: 87.5000 (86.5479)  Acc@5: 100.0000 (98.2638)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:08  Lr: 0.030000  Loss: -1.4179  Acc@1: 81.2500 (86.5427)  Acc@5: 100.0000 (98.2612)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2960/3125]  eta: 0:01:04  Lr: 0.030000  Loss: -1.4560  Acc@1: 87.5000 (86.5354)  Acc@5: 100.0000 (98.2628)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2970/3125]  eta: 0:01:00  Lr: 0.030000  Loss: -1.5665  Acc@1: 87.5000 (86.5344)  Acc@5: 100.0000 (98.2666)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:56  Lr: 0.030000  Loss: -1.5764  Acc@1: 87.5000 (86.5377)  Acc@5: 100.0000 (98.2682)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:52  Lr: 0.030000  Loss: -1.7332  Acc@1: 87.5000 (86.5388)  Acc@5: 100.0000 (98.2698)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:48  Lr: 0.030000  Loss: -1.8035  Acc@1: 87.5000 (86.5441)  Acc@5: 100.0000 (98.2693)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:44  Lr: 0.030000  Loss: -1.3917  Acc@1: 87.5000 (86.5514)  Acc@5: 100.0000 (98.2626)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:41  Lr: 0.030000  Loss: -1.6176  Acc@1: 87.5000 (86.5628)  Acc@5: 100.0000 (98.2642)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:37  Lr: 0.030000  Loss: -1.6936  Acc@1: 87.5000 (86.5618)  Acc@5: 100.0000 (98.2617)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:33  Lr: 0.030000  Loss: -1.1800  Acc@1: 87.5000 (86.5587)  Acc@5: 100.0000 (98.2633)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:29  Lr: 0.030000  Loss: -1.0330  Acc@1: 87.5000 (86.5556)  Acc@5: 100.0000 (98.2608)  time: 0.3921  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:25  Lr: 0.030000  Loss: -1.4378  Acc@1: 87.5000 (86.5526)  Acc@5: 100.0000 (98.2624)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:21  Lr: 0.030000  Loss: -1.5344  Acc@1: 87.5000 (86.5598)  Acc@5: 100.0000 (98.2640)  time: 0.3921  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:17  Lr: 0.030000  Loss: -1.5964  Acc@1: 87.5000 (86.5669)  Acc@5: 100.0000 (98.2676)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:13  Lr: 0.030000  Loss: -1.5227  Acc@1: 87.5000 (86.5800)  Acc@5: 100.0000 (98.2712)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:09  Lr: 0.030000  Loss: -1.7941  Acc@1: 87.5000 (86.5789)  Acc@5: 100.0000 (98.2707)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: -1.3321  Acc@1: 81.2500 (86.5739)  Acc@5: 100.0000 (98.2703)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: -1.3133  Acc@1: 87.5000 (86.5728)  Acc@5: 100.0000 (98.2658)  time: 0.3929  data: 0.0010  max mem: 2912
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: -1.3685  Acc@1: 87.5000 (86.5680)  Acc@5: 100.0000 (98.2640)  time: 0.3920  data: 0.0010  max mem: 2912
Train: Epoch[3/5] Total time: 0:20:21 (0.3908 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.3685  Acc@1: 87.5000 (86.5680)  Acc@5: 100.0000 (98.2640)
Train: Epoch[4/5]  [   0/3125]  eta: 0:41:12  Lr: 0.030000  Loss: -1.5504  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7912  data: 0.3946  max mem: 2912
Train: Epoch[4/5]  [  10/3125]  eta: 0:22:10  Lr: 0.030000  Loss: -1.4388  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.4273  data: 0.0362  max mem: 2912
Train: Epoch[4/5]  [  20/3125]  eta: 0:21:12  Lr: 0.030000  Loss: -1.5371  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (98.8095)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [  30/3125]  eta: 0:20:46  Lr: 0.030000  Loss: -1.5838  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.5887)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [  40/3125]  eta: 0:20:32  Lr: 0.030000  Loss: -1.3948  Acc@1: 81.2500 (86.7378)  Acc@5: 100.0000 (98.7805)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [  50/3125]  eta: 0:20:24  Lr: 0.030000  Loss: -1.6481  Acc@1: 81.2500 (86.7647)  Acc@5: 100.0000 (98.6520)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  60/3125]  eta: 0:20:16  Lr: 0.030000  Loss: -1.9921  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (98.6680)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  70/3125]  eta: 0:20:09  Lr: 0.030000  Loss: -1.3223  Acc@1: 87.5000 (87.0599)  Acc@5: 100.0000 (98.6796)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [  80/3125]  eta: 0:20:03  Lr: 0.030000  Loss: -1.6718  Acc@1: 87.5000 (87.5772)  Acc@5: 100.0000 (98.7654)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  90/3125]  eta: 0:19:58  Lr: 0.030000  Loss: -1.6872  Acc@1: 93.7500 (87.7747)  Acc@5: 100.0000 (98.9011)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 100/3125]  eta: 0:19:52  Lr: 0.030000  Loss: -1.5715  Acc@1: 87.5000 (87.6856)  Acc@5: 100.0000 (98.7005)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 110/3125]  eta: 0:19:47  Lr: 0.030000  Loss: -1.6973  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7613)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 120/3125]  eta: 0:19:43  Lr: 0.030000  Loss: -1.7644  Acc@1: 87.5000 (87.7583)  Acc@5: 100.0000 (98.8120)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 130/3125]  eta: 0:19:38  Lr: 0.030000  Loss: -1.5234  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7595)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 140/3125]  eta: 0:19:33  Lr: 0.030000  Loss: -1.5233  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8475)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 150/3125]  eta: 0:19:28  Lr: 0.030000  Loss: -1.3724  Acc@1: 87.5000 (87.2517)  Acc@5: 100.0000 (98.7583)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 160/3125]  eta: 0:19:23  Lr: 0.030000  Loss: -1.6676  Acc@1: 87.5000 (87.2283)  Acc@5: 100.0000 (98.7578)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 170/3125]  eta: 0:19:19  Lr: 0.030000  Loss: -1.4842  Acc@1: 87.5000 (87.0614)  Acc@5: 100.0000 (98.7208)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 180/3125]  eta: 0:19:14  Lr: 0.030000  Loss: -1.0004  Acc@1: 87.5000 (86.7749)  Acc@5: 100.0000 (98.6533)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 190/3125]  eta: 0:19:10  Lr: 0.030000  Loss: -1.4881  Acc@1: 87.5000 (86.9110)  Acc@5: 100.0000 (98.6911)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 200/3125]  eta: 0:19:06  Lr: 0.030000  Loss: -1.6137  Acc@1: 87.5000 (86.8159)  Acc@5: 100.0000 (98.7251)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 210/3125]  eta: 0:19:02  Lr: 0.030000  Loss: -0.9399  Acc@1: 87.5000 (86.8483)  Acc@5: 100.0000 (98.6967)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 220/3125]  eta: 0:18:57  Lr: 0.030000  Loss: -1.6298  Acc@1: 87.5000 (86.8778)  Acc@5: 100.0000 (98.7274)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 230/3125]  eta: 0:18:53  Lr: 0.030000  Loss: -0.7421  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.7013)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 240/3125]  eta: 0:18:49  Lr: 0.030000  Loss: -1.7889  Acc@1: 87.5000 (86.9813)  Acc@5: 100.0000 (98.7033)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 250/3125]  eta: 0:18:45  Lr: 0.030000  Loss: -1.5474  Acc@1: 87.5000 (86.9771)  Acc@5: 100.0000 (98.6554)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 260/3125]  eta: 0:18:41  Lr: 0.030000  Loss: -1.6327  Acc@1: 87.5000 (86.9971)  Acc@5: 100.0000 (98.6590)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 270/3125]  eta: 0:18:37  Lr: 0.030000  Loss: -1.1397  Acc@1: 87.5000 (87.0618)  Acc@5: 100.0000 (98.6854)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 280/3125]  eta: 0:18:33  Lr: 0.030000  Loss: -1.7005  Acc@1: 87.5000 (87.0996)  Acc@5: 100.0000 (98.6877)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 290/3125]  eta: 0:18:29  Lr: 0.030000  Loss: -1.2954  Acc@1: 87.5000 (87.0490)  Acc@5: 100.0000 (98.6684)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 300/3125]  eta: 0:18:25  Lr: 0.030000  Loss: -1.5081  Acc@1: 87.5000 (87.0640)  Acc@5: 100.0000 (98.6919)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 310/3125]  eta: 0:18:21  Lr: 0.030000  Loss: -1.3103  Acc@1: 87.5000 (86.8770)  Acc@5: 100.0000 (98.6736)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 320/3125]  eta: 0:18:16  Lr: 0.030000  Loss: -1.3870  Acc@1: 87.5000 (86.9354)  Acc@5: 100.0000 (98.6371)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 330/3125]  eta: 0:18:12  Lr: 0.030000  Loss: -1.5731  Acc@1: 87.5000 (86.9524)  Acc@5: 100.0000 (98.6405)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 340/3125]  eta: 0:18:08  Lr: 0.030000  Loss: -1.3523  Acc@1: 87.5000 (87.0601)  Acc@5: 100.0000 (98.6804)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 350/3125]  eta: 0:18:04  Lr: 0.030000  Loss: -1.3122  Acc@1: 87.5000 (87.0192)  Acc@5: 100.0000 (98.6467)  time: 0.3907  data: 0.0010  max mem: 2912
Train: Epoch[4/5]  [ 360/3125]  eta: 0:18:00  Lr: 0.030000  Loss: -1.1704  Acc@1: 87.5000 (86.9979)  Acc@5: 100.0000 (98.6323)  time: 0.3909  data: 0.0010  max mem: 2912
Train: Epoch[4/5]  [ 370/3125]  eta: 0:17:57  Lr: 0.030000  Loss: -1.3091  Acc@1: 87.5000 (86.9272)  Acc@5: 100.0000 (98.6018)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 380/3125]  eta: 0:17:53  Lr: 0.030000  Loss: -1.5867  Acc@1: 87.5000 (87.0243)  Acc@5: 100.0000 (98.6385)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 390/3125]  eta: 0:17:49  Lr: 0.030000  Loss: -1.9483  Acc@1: 87.5000 (87.1004)  Acc@5: 100.0000 (98.6413)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 400/3125]  eta: 0:17:45  Lr: 0.030000  Loss: -1.7195  Acc@1: 87.5000 (87.1103)  Acc@5: 100.0000 (98.6596)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 410/3125]  eta: 0:17:41  Lr: 0.030000  Loss: -1.3562  Acc@1: 87.5000 (87.1198)  Acc@5: 100.0000 (98.6010)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 420/3125]  eta: 0:17:37  Lr: 0.030000  Loss: -1.2525  Acc@1: 87.5000 (87.1289)  Acc@5: 100.0000 (98.5897)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 430/3125]  eta: 0:17:33  Lr: 0.030000  Loss: -1.7116  Acc@1: 87.5000 (87.1375)  Acc@5: 100.0000 (98.6224)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 440/3125]  eta: 0:17:29  Lr: 0.030000  Loss: -1.5181  Acc@1: 87.5000 (87.0890)  Acc@5: 100.0000 (98.5828)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 450/3125]  eta: 0:17:25  Lr: 0.030000  Loss: -1.8407  Acc@1: 87.5000 (87.1813)  Acc@5: 100.0000 (98.6003)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 460/3125]  eta: 0:17:21  Lr: 0.030000  Loss: -1.4986  Acc@1: 87.5000 (87.0933)  Acc@5: 100.0000 (98.6036)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 470/3125]  eta: 0:17:17  Lr: 0.030000  Loss: -1.6751  Acc@1: 87.5000 (87.1417)  Acc@5: 100.0000 (98.5801)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 480/3125]  eta: 0:17:13  Lr: 0.030000  Loss: -1.4621  Acc@1: 87.5000 (87.1622)  Acc@5: 100.0000 (98.6097)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 490/3125]  eta: 0:17:10  Lr: 0.030000  Loss: -1.5897  Acc@1: 87.5000 (87.2072)  Acc@5: 100.0000 (98.5998)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 500/3125]  eta: 0:17:06  Lr: 0.030000  Loss: -1.6019  Acc@1: 93.7500 (87.2879)  Acc@5: 100.0000 (98.6028)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 510/3125]  eta: 0:17:02  Lr: 0.030000  Loss: -1.4992  Acc@1: 87.5000 (87.3165)  Acc@5: 100.0000 (98.6179)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 520/3125]  eta: 0:16:58  Lr: 0.030000  Loss: -1.5020  Acc@1: 87.5000 (87.2601)  Acc@5: 100.0000 (98.5964)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 530/3125]  eta: 0:16:54  Lr: 0.030000  Loss: -1.4518  Acc@1: 87.5000 (87.2764)  Acc@5: 100.0000 (98.6111)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 540/3125]  eta: 0:16:50  Lr: 0.030000  Loss: -1.1765  Acc@1: 87.5000 (87.3267)  Acc@5: 100.0000 (98.6021)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 550/3125]  eta: 0:16:46  Lr: 0.030000  Loss: -1.6726  Acc@1: 93.7500 (87.3979)  Acc@5: 100.0000 (98.6162)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 560/3125]  eta: 0:16:42  Lr: 0.030000  Loss: -1.1926  Acc@1: 87.5000 (87.3217)  Acc@5: 100.0000 (98.6185)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 570/3125]  eta: 0:16:38  Lr: 0.030000  Loss: -1.5822  Acc@1: 81.2500 (87.2045)  Acc@5: 100.0000 (98.5771)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 580/3125]  eta: 0:16:35  Lr: 0.030000  Loss: -1.4647  Acc@1: 81.2500 (87.1343)  Acc@5: 100.0000 (98.5370)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 590/3125]  eta: 0:16:31  Lr: 0.030000  Loss: -1.7815  Acc@1: 87.5000 (87.1933)  Acc@5: 100.0000 (98.5300)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 600/3125]  eta: 0:16:27  Lr: 0.030000  Loss: -1.6665  Acc@1: 87.5000 (87.1776)  Acc@5: 100.0000 (98.5129)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 610/3125]  eta: 0:16:23  Lr: 0.030000  Loss: -1.1613  Acc@1: 87.5000 (87.1931)  Acc@5: 100.0000 (98.4963)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 620/3125]  eta: 0:16:19  Lr: 0.030000  Loss: -1.7280  Acc@1: 87.5000 (87.2182)  Acc@5: 100.0000 (98.5105)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 630/3125]  eta: 0:16:15  Lr: 0.030000  Loss: -1.4792  Acc@1: 87.5000 (87.2425)  Acc@5: 100.0000 (98.5143)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 640/3125]  eta: 0:16:11  Lr: 0.030000  Loss: -1.3586  Acc@1: 81.2500 (87.1782)  Acc@5: 100.0000 (98.5277)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 650/3125]  eta: 0:16:07  Lr: 0.030000  Loss: -1.2949  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.5311)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 660/3125]  eta: 0:16:03  Lr: 0.030000  Loss: -1.4247  Acc@1: 87.5000 (87.1691)  Acc@5: 100.0000 (98.5344)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 670/3125]  eta: 0:15:59  Lr: 0.030000  Loss: -1.3118  Acc@1: 87.5000 (87.2299)  Acc@5: 100.0000 (98.5563)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 680/3125]  eta: 0:15:56  Lr: 0.030000  Loss: -1.6319  Acc@1: 93.7500 (87.2981)  Acc@5: 100.0000 (98.5591)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 690/3125]  eta: 0:15:52  Lr: 0.030000  Loss: -1.6481  Acc@1: 87.5000 (87.3010)  Acc@5: 100.0000 (98.5619)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 700/3125]  eta: 0:15:48  Lr: 0.030000  Loss: -1.3366  Acc@1: 87.5000 (87.2949)  Acc@5: 100.0000 (98.5646)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 710/3125]  eta: 0:15:44  Lr: 0.030000  Loss: -1.7077  Acc@1: 87.5000 (87.2802)  Acc@5: 100.0000 (98.5584)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 720/3125]  eta: 0:15:40  Lr: 0.030000  Loss: -1.4226  Acc@1: 87.5000 (87.2833)  Acc@5: 100.0000 (98.5610)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 730/3125]  eta: 0:15:36  Lr: 0.030000  Loss: -1.7456  Acc@1: 87.5000 (87.3034)  Acc@5: 100.0000 (98.5380)  time: 0.3904  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 740/3125]  eta: 0:15:32  Lr: 0.030000  Loss: -1.5637  Acc@1: 87.5000 (87.3482)  Acc@5: 100.0000 (98.5493)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 750/3125]  eta: 0:15:28  Lr: 0.030000  Loss: -1.6710  Acc@1: 87.5000 (87.3419)  Acc@5: 100.0000 (98.5436)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 760/3125]  eta: 0:15:24  Lr: 0.030000  Loss: -1.6399  Acc@1: 87.5000 (87.3522)  Acc@5: 100.0000 (98.5545)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 770/3125]  eta: 0:15:20  Lr: 0.030000  Loss: -1.6370  Acc@1: 87.5000 (87.4108)  Acc@5: 100.0000 (98.5652)  time: 0.3896  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 780/3125]  eta: 0:15:16  Lr: 0.030000  Loss: -1.4514  Acc@1: 87.5000 (87.4280)  Acc@5: 100.0000 (98.5835)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 790/3125]  eta: 0:15:12  Lr: 0.030000  Loss: -1.5882  Acc@1: 93.7500 (87.4526)  Acc@5: 100.0000 (98.5777)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 800/3125]  eta: 0:15:08  Lr: 0.030000  Loss: -1.4230  Acc@1: 81.2500 (87.3830)  Acc@5: 100.0000 (98.5799)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 810/3125]  eta: 0:15:04  Lr: 0.030000  Loss: -1.7443  Acc@1: 81.2500 (87.4152)  Acc@5: 100.0000 (98.5820)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 820/3125]  eta: 0:15:00  Lr: 0.030000  Loss: -1.4411  Acc@1: 87.5000 (87.4010)  Acc@5: 100.0000 (98.5688)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 830/3125]  eta: 0:14:56  Lr: 0.030000  Loss: -0.8677  Acc@1: 87.5000 (87.3797)  Acc@5: 100.0000 (98.5785)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 840/3125]  eta: 0:14:52  Lr: 0.030000  Loss: -1.5631  Acc@1: 87.5000 (87.4183)  Acc@5: 100.0000 (98.5954)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 850/3125]  eta: 0:14:49  Lr: 0.030000  Loss: -1.2565  Acc@1: 87.5000 (87.3678)  Acc@5: 100.0000 (98.5972)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 860/3125]  eta: 0:14:45  Lr: 0.030000  Loss: -1.1485  Acc@1: 81.2500 (87.2967)  Acc@5: 100.0000 (98.5918)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 870/3125]  eta: 0:14:41  Lr: 0.030000  Loss: -1.6255  Acc@1: 81.2500 (87.3350)  Acc@5: 100.0000 (98.5577)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 880/3125]  eta: 0:14:37  Lr: 0.030000  Loss: -1.1161  Acc@1: 93.7500 (87.3297)  Acc@5: 93.7500 (98.5315)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 890/3125]  eta: 0:14:33  Lr: 0.030000  Loss: -1.4527  Acc@1: 93.7500 (87.3948)  Acc@5: 100.0000 (98.5410)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 900/3125]  eta: 0:14:29  Lr: 0.030000  Loss: -1.6380  Acc@1: 93.7500 (87.3959)  Acc@5: 100.0000 (98.5363)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 910/3125]  eta: 0:14:25  Lr: 0.030000  Loss: -1.5925  Acc@1: 87.5000 (87.4108)  Acc@5: 100.0000 (98.5387)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 920/3125]  eta: 0:14:21  Lr: 0.030000  Loss: -1.3030  Acc@1: 87.5000 (87.4254)  Acc@5: 100.0000 (98.5546)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 930/3125]  eta: 0:14:17  Lr: 0.030000  Loss: -1.3253  Acc@1: 87.5000 (87.4329)  Acc@5: 100.0000 (98.5164)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 940/3125]  eta: 0:14:13  Lr: 0.030000  Loss: -1.5609  Acc@1: 87.5000 (87.4336)  Acc@5: 100.0000 (98.5255)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 950/3125]  eta: 0:14:09  Lr: 0.030000  Loss: -1.6739  Acc@1: 87.5000 (87.4606)  Acc@5: 100.0000 (98.5410)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 960/3125]  eta: 0:14:05  Lr: 0.030000  Loss: -1.9087  Acc@1: 87.5000 (87.4610)  Acc@5: 100.0000 (98.5432)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 970/3125]  eta: 0:14:01  Lr: 0.030000  Loss: -1.9621  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5389)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 980/3125]  eta: 0:13:58  Lr: 0.030000  Loss: -1.1912  Acc@1: 87.5000 (87.5191)  Acc@5: 100.0000 (98.5538)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 990/3125]  eta: 0:13:54  Lr: 0.030000  Loss: -1.0753  Acc@1: 87.5000 (87.5505)  Acc@5: 100.0000 (98.5621)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1000/3125]  eta: 0:13:50  Lr: 0.030000  Loss: -1.2934  Acc@1: 81.2500 (87.4938)  Acc@5: 100.0000 (98.5702)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1010/3125]  eta: 0:13:46  Lr: 0.030000  Loss: -1.4906  Acc@1: 81.2500 (87.4753)  Acc@5: 100.0000 (98.5720)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1020/3125]  eta: 0:13:42  Lr: 0.030000  Loss: -1.3015  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5798)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1030/3125]  eta: 0:13:38  Lr: 0.030000  Loss: -1.5400  Acc@1: 87.5000 (87.5182)  Acc@5: 100.0000 (98.5936)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1040/3125]  eta: 0:13:34  Lr: 0.030000  Loss: -1.3815  Acc@1: 87.5000 (87.5180)  Acc@5: 100.0000 (98.5891)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1050/3125]  eta: 0:13:30  Lr: 0.030000  Loss: -1.7155  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5906)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1060/3125]  eta: 0:13:26  Lr: 0.030000  Loss: -1.4285  Acc@1: 87.5000 (87.5295)  Acc@5: 100.0000 (98.5803)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1070/3125]  eta: 0:13:22  Lr: 0.030000  Loss: -1.3023  Acc@1: 87.5000 (87.5117)  Acc@5: 100.0000 (98.5819)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1080/3125]  eta: 0:13:19  Lr: 0.030000  Loss: -1.8698  Acc@1: 87.5000 (87.5289)  Acc@5: 100.0000 (98.5835)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1090/3125]  eta: 0:13:15  Lr: 0.030000  Loss: -1.6538  Acc@1: 87.5000 (87.5229)  Acc@5: 100.0000 (98.5850)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1100/3125]  eta: 0:13:11  Lr: 0.030000  Loss: -1.7014  Acc@1: 87.5000 (87.5397)  Acc@5: 100.0000 (98.5979)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1110/3125]  eta: 0:13:07  Lr: 0.030000  Loss: -1.7584  Acc@1: 87.5000 (87.5788)  Acc@5: 100.0000 (98.6049)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1120/3125]  eta: 0:13:03  Lr: 0.030000  Loss: -1.7401  Acc@1: 87.5000 (87.5502)  Acc@5: 100.0000 (98.6006)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1130/3125]  eta: 0:12:59  Lr: 0.030000  Loss: -1.7713  Acc@1: 87.5000 (87.5332)  Acc@5: 100.0000 (98.5964)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1140/3125]  eta: 0:12:55  Lr: 0.030000  Loss: -1.5837  Acc@1: 87.5000 (87.5383)  Acc@5: 100.0000 (98.5868)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1150/3125]  eta: 0:12:51  Lr: 0.030000  Loss: -1.4590  Acc@1: 87.5000 (87.5597)  Acc@5: 100.0000 (98.5719)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1160/3125]  eta: 0:12:47  Lr: 0.030000  Loss: -1.8951  Acc@1: 87.5000 (87.5754)  Acc@5: 100.0000 (98.5734)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1170/3125]  eta: 0:12:43  Lr: 0.030000  Loss: -1.6464  Acc@1: 87.5000 (87.5747)  Acc@5: 100.0000 (98.5589)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1180/3125]  eta: 0:12:39  Lr: 0.030000  Loss: -1.4876  Acc@1: 87.5000 (87.5688)  Acc@5: 100.0000 (98.5658)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1190/3125]  eta: 0:12:36  Lr: 0.030000  Loss: -1.6947  Acc@1: 87.5000 (87.5682)  Acc@5: 100.0000 (98.5779)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1200/3125]  eta: 0:12:32  Lr: 0.030000  Loss: -1.6618  Acc@1: 87.5000 (87.5624)  Acc@5: 100.0000 (98.5741)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1210/3125]  eta: 0:12:28  Lr: 0.030000  Loss: -1.2678  Acc@1: 87.5000 (87.5826)  Acc@5: 100.0000 (98.5704)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1220/3125]  eta: 0:12:24  Lr: 0.030000  Loss: -1.5245  Acc@1: 87.5000 (87.5717)  Acc@5: 100.0000 (98.5719)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1230/3125]  eta: 0:12:20  Lr: 0.030000  Loss: -1.5208  Acc@1: 87.5000 (87.5558)  Acc@5: 100.0000 (98.5581)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1240/3125]  eta: 0:12:16  Lr: 0.030000  Loss: -1.6031  Acc@1: 87.5000 (87.5755)  Acc@5: 100.0000 (98.5596)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1250/3125]  eta: 0:12:12  Lr: 0.030000  Loss: -1.2637  Acc@1: 87.5000 (87.5500)  Acc@5: 100.0000 (98.5462)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1260/3125]  eta: 0:12:08  Lr: 0.030000  Loss: -1.5778  Acc@1: 87.5000 (87.5496)  Acc@5: 100.0000 (98.5428)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1270/3125]  eta: 0:12:04  Lr: 0.030000  Loss: -1.6913  Acc@1: 87.5000 (87.5590)  Acc@5: 100.0000 (98.5445)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1280/3125]  eta: 0:12:00  Lr: 0.030000  Loss: -1.7581  Acc@1: 87.5000 (87.5634)  Acc@5: 100.0000 (98.5509)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1290/3125]  eta: 0:11:56  Lr: 0.030000  Loss: -0.8970  Acc@1: 87.5000 (87.5581)  Acc@5: 100.0000 (98.5380)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1300/3125]  eta: 0:11:53  Lr: 0.030000  Loss: -1.1307  Acc@1: 87.5000 (87.5192)  Acc@5: 100.0000 (98.5300)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1310/3125]  eta: 0:11:49  Lr: 0.030000  Loss: -1.4139  Acc@1: 87.5000 (87.5429)  Acc@5: 100.0000 (98.5412)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1320/3125]  eta: 0:11:45  Lr: 0.030000  Loss: -1.6841  Acc@1: 87.5000 (87.4905)  Acc@5: 100.0000 (98.5475)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1330/3125]  eta: 0:11:41  Lr: 0.030000  Loss: -1.1282  Acc@1: 81.2500 (87.4812)  Acc@5: 100.0000 (98.5490)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1340/3125]  eta: 0:11:37  Lr: 0.030000  Loss: -1.5066  Acc@1: 87.5000 (87.4720)  Acc@5: 100.0000 (98.5505)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1350/3125]  eta: 0:11:33  Lr: 0.030000  Loss: -1.4527  Acc@1: 87.5000 (87.4676)  Acc@5: 100.0000 (98.5474)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1360/3125]  eta: 0:11:29  Lr: 0.030000  Loss: -1.6002  Acc@1: 87.5000 (87.4495)  Acc@5: 100.0000 (98.5535)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1370/3125]  eta: 0:11:25  Lr: 0.030000  Loss: -1.6040  Acc@1: 87.5000 (87.4544)  Acc@5: 100.0000 (98.5594)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1380/3125]  eta: 0:11:21  Lr: 0.030000  Loss: -1.7316  Acc@1: 93.7500 (87.4819)  Acc@5: 100.0000 (98.5563)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1390/3125]  eta: 0:11:17  Lr: 0.030000  Loss: -1.6581  Acc@1: 87.5000 (87.4955)  Acc@5: 100.0000 (98.5622)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1400/3125]  eta: 0:11:13  Lr: 0.030000  Loss: -1.3420  Acc@1: 87.5000 (87.4688)  Acc@5: 100.0000 (98.5457)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1410/3125]  eta: 0:11:09  Lr: 0.030000  Loss: -1.2192  Acc@1: 87.5000 (87.4734)  Acc@5: 100.0000 (98.5383)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1420/3125]  eta: 0:11:06  Lr: 0.030000  Loss: -1.5701  Acc@1: 93.7500 (87.4824)  Acc@5: 100.0000 (98.5442)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1430/3125]  eta: 0:11:02  Lr: 0.030000  Loss: -1.6421  Acc@1: 87.5000 (87.4869)  Acc@5: 100.0000 (98.5500)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1440/3125]  eta: 0:10:58  Lr: 0.030000  Loss: -1.6681  Acc@1: 87.5000 (87.4653)  Acc@5: 100.0000 (98.5514)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1450/3125]  eta: 0:10:54  Lr: 0.030000  Loss: -1.7097  Acc@1: 87.5000 (87.4698)  Acc@5: 100.0000 (98.5484)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1460/3125]  eta: 0:10:50  Lr: 0.030000  Loss: -1.2501  Acc@1: 87.5000 (87.4701)  Acc@5: 100.0000 (98.5498)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1470/3125]  eta: 0:10:46  Lr: 0.030000  Loss: -1.8340  Acc@1: 87.5000 (87.4618)  Acc@5: 100.0000 (98.5384)  time: 0.3905  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1480/3125]  eta: 0:10:42  Lr: 0.030000  Loss: -1.2636  Acc@1: 87.5000 (87.4873)  Acc@5: 100.0000 (98.5441)  time: 0.3907  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1490/3125]  eta: 0:10:38  Lr: 0.030000  Loss: -1.7194  Acc@1: 87.5000 (87.4916)  Acc@5: 100.0000 (98.5412)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1500/3125]  eta: 0:10:34  Lr: 0.030000  Loss: -1.7001  Acc@1: 87.5000 (87.4833)  Acc@5: 100.0000 (98.5426)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1510/3125]  eta: 0:10:30  Lr: 0.030000  Loss: -1.5854  Acc@1: 87.5000 (87.4917)  Acc@5: 100.0000 (98.5481)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1520/3125]  eta: 0:10:26  Lr: 0.030000  Loss: -1.7900  Acc@1: 87.5000 (87.5205)  Acc@5: 100.0000 (98.5577)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1530/3125]  eta: 0:10:22  Lr: 0.030000  Loss: -1.5053  Acc@1: 87.5000 (87.4878)  Acc@5: 100.0000 (98.5467)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1540/3125]  eta: 0:10:19  Lr: 0.030000  Loss: -1.7015  Acc@1: 87.5000 (87.5243)  Acc@5: 100.0000 (98.5561)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1550/3125]  eta: 0:10:15  Lr: 0.030000  Loss: -1.2497  Acc@1: 93.7500 (87.5201)  Acc@5: 100.0000 (98.5574)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1560/3125]  eta: 0:10:11  Lr: 0.030000  Loss: -1.5833  Acc@1: 87.5000 (87.5320)  Acc@5: 100.0000 (98.5546)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1570/3125]  eta: 0:10:07  Lr: 0.030000  Loss: -1.1590  Acc@1: 87.5000 (87.5278)  Acc@5: 100.0000 (98.5559)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1580/3125]  eta: 0:10:03  Lr: 0.030000  Loss: -1.6887  Acc@1: 87.5000 (87.5277)  Acc@5: 100.0000 (98.5610)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1590/3125]  eta: 0:09:59  Lr: 0.030000  Loss: -1.5362  Acc@1: 87.5000 (87.5236)  Acc@5: 100.0000 (98.5622)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1600/3125]  eta: 0:09:55  Lr: 0.030000  Loss: -1.8684  Acc@1: 87.5000 (87.5195)  Acc@5: 100.0000 (98.5595)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1610/3125]  eta: 0:09:51  Lr: 0.030000  Loss: -1.3966  Acc@1: 87.5000 (87.5349)  Acc@5: 100.0000 (98.5607)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1620/3125]  eta: 0:09:47  Lr: 0.030000  Loss: -1.2810  Acc@1: 87.5000 (87.5116)  Acc@5: 100.0000 (98.5580)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1630/3125]  eta: 0:09:44  Lr: 0.030000  Loss: -1.7343  Acc@1: 87.5000 (87.5230)  Acc@5: 100.0000 (98.5630)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1640/3125]  eta: 0:09:40  Lr: 0.030000  Loss: -1.7244  Acc@1: 87.5000 (87.4848)  Acc@5: 100.0000 (98.5603)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1650/3125]  eta: 0:09:36  Lr: 0.030000  Loss: -1.3571  Acc@1: 81.2500 (87.4811)  Acc@5: 100.0000 (98.5615)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1660/3125]  eta: 0:09:32  Lr: 0.030000  Loss: -1.0602  Acc@1: 87.5000 (87.4737)  Acc@5: 100.0000 (98.5626)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1670/3125]  eta: 0:09:28  Lr: 0.030000  Loss: -1.5168  Acc@1: 87.5000 (87.4738)  Acc@5: 100.0000 (98.5637)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1680/3125]  eta: 0:09:24  Lr: 0.030000  Loss: -1.5808  Acc@1: 93.7500 (87.4851)  Acc@5: 100.0000 (98.5574)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1690/3125]  eta: 0:09:20  Lr: 0.030000  Loss: -1.4227  Acc@1: 87.5000 (87.4667)  Acc@5: 100.0000 (98.5548)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1700/3125]  eta: 0:09:16  Lr: 0.030000  Loss: -1.1827  Acc@1: 87.5000 (87.4706)  Acc@5: 100.0000 (98.5560)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1710/3125]  eta: 0:09:12  Lr: 0.030000  Loss: -0.9796  Acc@1: 87.5000 (87.4671)  Acc@5: 100.0000 (98.5535)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1720/3125]  eta: 0:09:08  Lr: 0.030000  Loss: -1.4710  Acc@1: 87.5000 (87.4673)  Acc@5: 100.0000 (98.5546)  time: 0.3915  data: 0.0010  max mem: 2912
Train: Epoch[4/5]  [1730/3125]  eta: 0:09:04  Lr: 0.030000  Loss: -1.7141  Acc@1: 87.5000 (87.4675)  Acc@5: 100.0000 (98.5413)  time: 0.3908  data: 0.0010  max mem: 2912
Train: Epoch[4/5]  [1740/3125]  eta: 0:09:01  Lr: 0.030000  Loss: -1.7004  Acc@1: 87.5000 (87.4928)  Acc@5: 100.0000 (98.5353)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1750/3125]  eta: 0:08:57  Lr: 0.030000  Loss: -1.9033  Acc@1: 93.7500 (87.5036)  Acc@5: 100.0000 (98.5330)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1760/3125]  eta: 0:08:53  Lr: 0.030000  Loss: -1.4185  Acc@1: 87.5000 (87.4929)  Acc@5: 100.0000 (98.5307)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1770/3125]  eta: 0:08:49  Lr: 0.030000  Loss: -1.5798  Acc@1: 81.2500 (87.4612)  Acc@5: 100.0000 (98.5213)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1780/3125]  eta: 0:08:45  Lr: 0.030000  Loss: -1.6665  Acc@1: 87.5000 (87.4614)  Acc@5: 100.0000 (98.5296)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1790/3125]  eta: 0:08:41  Lr: 0.030000  Loss: -1.6855  Acc@1: 87.5000 (87.4581)  Acc@5: 100.0000 (98.5239)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1800/3125]  eta: 0:08:37  Lr: 0.030000  Loss: 0.0837  Acc@1: 87.5000 (87.4549)  Acc@5: 100.0000 (98.5147)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1810/3125]  eta: 0:08:33  Lr: 0.030000  Loss: -1.2622  Acc@1: 87.5000 (87.4620)  Acc@5: 100.0000 (98.5160)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1820/3125]  eta: 0:08:29  Lr: 0.030000  Loss: -1.1201  Acc@1: 87.5000 (87.4519)  Acc@5: 100.0000 (98.5173)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1830/3125]  eta: 0:08:25  Lr: 0.030000  Loss: -1.1384  Acc@1: 87.5000 (87.4454)  Acc@5: 100.0000 (98.5117)  time: 0.3910  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1840/3125]  eta: 0:08:21  Lr: 0.030000  Loss: -1.5809  Acc@1: 87.5000 (87.4559)  Acc@5: 100.0000 (98.5096)  time: 0.3910  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1850/3125]  eta: 0:08:18  Lr: 0.030000  Loss: -1.7894  Acc@1: 93.7500 (87.4730)  Acc@5: 100.0000 (98.5076)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1860/3125]  eta: 0:08:14  Lr: 0.030000  Loss: -1.7545  Acc@1: 87.5000 (87.4563)  Acc@5: 100.0000 (98.4921)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1870/3125]  eta: 0:08:10  Lr: 0.030000  Loss: -1.6018  Acc@1: 87.5000 (87.4699)  Acc@5: 100.0000 (98.4935)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1880/3125]  eta: 0:08:06  Lr: 0.030000  Loss: -1.7233  Acc@1: 87.5000 (87.4535)  Acc@5: 100.0000 (98.4948)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1890/3125]  eta: 0:08:02  Lr: 0.030000  Loss: -1.6447  Acc@1: 87.5000 (87.4736)  Acc@5: 100.0000 (98.4896)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:58  Lr: 0.030000  Loss: -1.3222  Acc@1: 93.7500 (87.4934)  Acc@5: 100.0000 (98.4975)  time: 0.3886  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1910/3125]  eta: 0:07:54  Lr: 0.030000  Loss: -1.4088  Acc@1: 87.5000 (87.4804)  Acc@5: 100.0000 (98.4890)  time: 0.3888  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1920/3125]  eta: 0:07:50  Lr: 0.030000  Loss: -1.5077  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4904)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1930/3125]  eta: 0:07:46  Lr: 0.030000  Loss: -1.6635  Acc@1: 87.5000 (87.4968)  Acc@5: 100.0000 (98.4917)  time: 0.3905  data: 0.0010  max mem: 2912
Train: Epoch[4/5]  [1940/3125]  eta: 0:07:42  Lr: 0.030000  Loss: -1.8760  Acc@1: 87.5000 (87.5032)  Acc@5: 100.0000 (98.4963)  time: 0.3902  data: 0.0010  max mem: 2912
Train: Epoch[4/5]  [1950/3125]  eta: 0:07:38  Lr: 0.030000  Loss: -1.1574  Acc@1: 87.5000 (87.4968)  Acc@5: 100.0000 (98.4912)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1960/3125]  eta: 0:07:35  Lr: 0.030000  Loss: -1.0062  Acc@1: 87.5000 (87.5032)  Acc@5: 100.0000 (98.4893)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1970/3125]  eta: 0:07:31  Lr: 0.030000  Loss: -1.2948  Acc@1: 87.5000 (87.5063)  Acc@5: 100.0000 (98.4874)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1980/3125]  eta: 0:07:27  Lr: 0.030000  Loss: -1.5056  Acc@1: 87.5000 (87.5126)  Acc@5: 100.0000 (98.4919)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1990/3125]  eta: 0:07:23  Lr: 0.030000  Loss: -1.6976  Acc@1: 87.5000 (87.5283)  Acc@5: 100.0000 (98.4932)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2000/3125]  eta: 0:07:19  Lr: 0.030000  Loss: -1.6459  Acc@1: 93.7500 (87.5656)  Acc@5: 100.0000 (98.5007)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2010/3125]  eta: 0:07:15  Lr: 0.030000  Loss: -1.4058  Acc@1: 93.7500 (87.5777)  Acc@5: 100.0000 (98.5020)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2020/3125]  eta: 0:07:11  Lr: 0.030000  Loss: -1.8064  Acc@1: 93.7500 (87.5959)  Acc@5: 100.0000 (98.5032)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2030/3125]  eta: 0:07:07  Lr: 0.030000  Loss: -1.4798  Acc@1: 87.5000 (87.6016)  Acc@5: 100.0000 (98.4983)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2040/3125]  eta: 0:07:03  Lr: 0.030000  Loss: -1.6623  Acc@1: 87.5000 (87.5735)  Acc@5: 100.0000 (98.4903)  time: 0.3886  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:59  Lr: 0.030000  Loss: -1.8239  Acc@1: 81.2500 (87.5457)  Acc@5: 100.0000 (98.4916)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:55  Lr: 0.030000  Loss: -1.5815  Acc@1: 81.2500 (87.5516)  Acc@5: 100.0000 (98.4928)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:51  Lr: 0.030000  Loss: -1.5672  Acc@1: 93.7500 (87.5513)  Acc@5: 100.0000 (98.4880)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:48  Lr: 0.030000  Loss: -1.6655  Acc@1: 87.5000 (87.5601)  Acc@5: 100.0000 (98.4923)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2090/3125]  eta: 0:06:44  Lr: 0.030000  Loss: -1.6071  Acc@1: 87.5000 (87.5628)  Acc@5: 100.0000 (98.4965)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2100/3125]  eta: 0:06:40  Lr: 0.030000  Loss: -1.5001  Acc@1: 87.5000 (87.5684)  Acc@5: 100.0000 (98.4977)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2110/3125]  eta: 0:06:36  Lr: 0.030000  Loss: -1.4863  Acc@1: 87.5000 (87.5681)  Acc@5: 100.0000 (98.4930)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2120/3125]  eta: 0:06:32  Lr: 0.030000  Loss: -1.2903  Acc@1: 87.5000 (87.5471)  Acc@5: 100.0000 (98.4883)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2130/3125]  eta: 0:06:28  Lr: 0.030000  Loss: -1.3950  Acc@1: 81.2500 (87.5293)  Acc@5: 100.0000 (98.4778)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2140/3125]  eta: 0:06:24  Lr: 0.030000  Loss: -1.2407  Acc@1: 81.2500 (87.5058)  Acc@5: 100.0000 (98.4791)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2150/3125]  eta: 0:06:20  Lr: 0.030000  Loss: -1.5860  Acc@1: 81.2500 (87.4884)  Acc@5: 100.0000 (98.4804)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2160/3125]  eta: 0:06:16  Lr: 0.030000  Loss: -1.4281  Acc@1: 81.2500 (87.4682)  Acc@5: 100.0000 (98.4671)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2170/3125]  eta: 0:06:12  Lr: 0.030000  Loss: -1.2449  Acc@1: 87.5000 (87.4798)  Acc@5: 100.0000 (98.4684)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2180/3125]  eta: 0:06:09  Lr: 0.030000  Loss: -1.5395  Acc@1: 93.7500 (87.4799)  Acc@5: 100.0000 (98.4669)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2190/3125]  eta: 0:06:05  Lr: 0.030000  Loss: -1.6646  Acc@1: 87.5000 (87.4857)  Acc@5: 100.0000 (98.4710)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2200/3125]  eta: 0:06:01  Lr: 0.030000  Loss: -1.5648  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4780)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:57  Lr: 0.030000  Loss: -1.2390  Acc@1: 87.5000 (87.4887)  Acc@5: 100.0000 (98.4651)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:53  Lr: 0.030000  Loss: -1.2238  Acc@1: 87.5000 (87.4775)  Acc@5: 100.0000 (98.4663)  time: 0.3924  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:49  Lr: 0.030000  Loss: -1.6864  Acc@1: 87.5000 (87.4860)  Acc@5: 100.0000 (98.4648)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:45  Lr: 0.030000  Loss: -1.2519  Acc@1: 87.5000 (87.4833)  Acc@5: 100.0000 (98.4605)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:41  Lr: 0.030000  Loss: -1.7947  Acc@1: 87.5000 (87.4695)  Acc@5: 100.0000 (98.4507)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2260/3125]  eta: 0:05:37  Lr: 0.030000  Loss: -1.4372  Acc@1: 87.5000 (87.4724)  Acc@5: 100.0000 (98.4492)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2270/3125]  eta: 0:05:33  Lr: 0.030000  Loss: -1.4670  Acc@1: 87.5000 (87.4780)  Acc@5: 100.0000 (98.4451)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2280/3125]  eta: 0:05:30  Lr: 0.030000  Loss: -1.7709  Acc@1: 87.5000 (87.4726)  Acc@5: 100.0000 (98.4464)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2290/3125]  eta: 0:05:26  Lr: 0.030000  Loss: -1.6646  Acc@1: 87.5000 (87.4727)  Acc@5: 100.0000 (98.4368)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2300/3125]  eta: 0:05:22  Lr: 0.030000  Loss: -1.8369  Acc@1: 87.5000 (87.4756)  Acc@5: 100.0000 (98.4382)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2310/3125]  eta: 0:05:18  Lr: 0.030000  Loss: -1.6638  Acc@1: 87.5000 (87.4730)  Acc@5: 100.0000 (98.4368)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2320/3125]  eta: 0:05:14  Lr: 0.030000  Loss: -1.6029  Acc@1: 87.5000 (87.4731)  Acc@5: 100.0000 (98.4382)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2330/3125]  eta: 0:05:10  Lr: 0.030000  Loss: -1.8390  Acc@1: 87.5000 (87.4705)  Acc@5: 100.0000 (98.4341)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2340/3125]  eta: 0:05:06  Lr: 0.030000  Loss: -1.1499  Acc@1: 81.2500 (87.4493)  Acc@5: 100.0000 (98.4275)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2350/3125]  eta: 0:05:02  Lr: 0.030000  Loss: -1.4665  Acc@1: 87.5000 (87.4415)  Acc@5: 100.0000 (98.4235)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:58  Lr: 0.030000  Loss: -1.4687  Acc@1: 87.5000 (87.4418)  Acc@5: 100.0000 (98.4196)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:54  Lr: 0.030000  Loss: -1.6796  Acc@1: 87.5000 (87.4526)  Acc@5: 100.0000 (98.4237)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:50  Lr: 0.030000  Loss: -1.6980  Acc@1: 93.7500 (87.4738)  Acc@5: 100.0000 (98.4224)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:47  Lr: 0.030000  Loss: -1.7234  Acc@1: 93.7500 (87.4739)  Acc@5: 100.0000 (98.4133)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:43  Lr: 0.030000  Loss: -1.5377  Acc@1: 93.7500 (87.4688)  Acc@5: 100.0000 (98.4121)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:39  Lr: 0.030000  Loss: -1.5888  Acc@1: 93.7500 (87.4793)  Acc@5: 100.0000 (98.4135)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:35  Lr: 0.030000  Loss: -1.7453  Acc@1: 93.7500 (87.4845)  Acc@5: 100.0000 (98.4149)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2430/3125]  eta: 0:04:31  Lr: 0.030000  Loss: -1.2477  Acc@1: 87.5000 (87.4769)  Acc@5: 100.0000 (98.4189)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2440/3125]  eta: 0:04:27  Lr: 0.030000  Loss: -1.7777  Acc@1: 87.5000 (87.4872)  Acc@5: 100.0000 (98.4202)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2450/3125]  eta: 0:04:23  Lr: 0.030000  Loss: -1.5220  Acc@1: 87.5000 (87.4771)  Acc@5: 100.0000 (98.4190)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2460/3125]  eta: 0:04:19  Lr: 0.030000  Loss: -1.3731  Acc@1: 87.5000 (87.5025)  Acc@5: 100.0000 (98.4204)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2470/3125]  eta: 0:04:15  Lr: 0.030000  Loss: -1.3920  Acc@1: 87.5000 (87.4823)  Acc@5: 100.0000 (98.4166)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2480/3125]  eta: 0:04:11  Lr: 0.030000  Loss: -1.8827  Acc@1: 81.2500 (87.4647)  Acc@5: 100.0000 (98.4155)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2490/3125]  eta: 0:04:08  Lr: 0.030000  Loss: -1.2922  Acc@1: 81.2500 (87.4674)  Acc@5: 100.0000 (98.4193)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2500/3125]  eta: 0:04:04  Lr: 0.030000  Loss: -1.8519  Acc@1: 93.7500 (87.4825)  Acc@5: 100.0000 (98.4131)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2510/3125]  eta: 0:04:00  Lr: 0.030000  Loss: -1.5296  Acc@1: 93.7500 (87.4900)  Acc@5: 100.0000 (98.4170)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:56  Lr: 0.030000  Loss: -1.8445  Acc@1: 87.5000 (87.4926)  Acc@5: 100.0000 (98.4108)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:52  Lr: 0.030000  Loss: -1.4191  Acc@1: 87.5000 (87.4877)  Acc@5: 100.0000 (98.4147)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:48  Lr: 0.030000  Loss: -1.7681  Acc@1: 87.5000 (87.4828)  Acc@5: 100.0000 (98.4184)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:44  Lr: 0.030000  Loss: -1.6445  Acc@1: 87.5000 (87.4755)  Acc@5: 100.0000 (98.4148)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:40  Lr: 0.030000  Loss: -1.3822  Acc@1: 87.5000 (87.4561)  Acc@5: 100.0000 (98.4186)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:36  Lr: 0.030000  Loss: -1.3272  Acc@1: 87.5000 (87.4611)  Acc@5: 100.0000 (98.4150)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:32  Lr: 0.030000  Loss: -1.1951  Acc@1: 87.5000 (87.4467)  Acc@5: 100.0000 (98.4163)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:28  Lr: 0.030000  Loss: -1.8170  Acc@1: 87.5000 (87.4590)  Acc@5: 100.0000 (98.4224)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:25  Lr: 0.030000  Loss: -1.3650  Acc@1: 93.7500 (87.4495)  Acc@5: 100.0000 (98.4189)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2610/3125]  eta: 0:03:21  Lr: 0.030000  Loss: -1.2332  Acc@1: 87.5000 (87.4449)  Acc@5: 100.0000 (98.4178)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2620/3125]  eta: 0:03:17  Lr: 0.030000  Loss: -1.5378  Acc@1: 87.5000 (87.4547)  Acc@5: 100.0000 (98.4214)  time: 0.3895  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2630/3125]  eta: 0:03:13  Lr: 0.030000  Loss: -1.4784  Acc@1: 87.5000 (87.4406)  Acc@5: 100.0000 (98.4203)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2640/3125]  eta: 0:03:09  Lr: 0.030000  Loss: -1.3868  Acc@1: 81.2500 (87.4337)  Acc@5: 100.0000 (98.4239)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2650/3125]  eta: 0:03:05  Lr: 0.030000  Loss: -1.7740  Acc@1: 87.5000 (87.4387)  Acc@5: 100.0000 (98.4228)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2660/3125]  eta: 0:03:01  Lr: 0.030000  Loss: -1.6786  Acc@1: 87.5000 (87.4389)  Acc@5: 100.0000 (98.4263)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:57  Lr: 0.030000  Loss: -1.3997  Acc@1: 87.5000 (87.4415)  Acc@5: 100.0000 (98.4205)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:53  Lr: 0.030000  Loss: -1.2338  Acc@1: 87.5000 (87.4371)  Acc@5: 100.0000 (98.4218)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:49  Lr: 0.030000  Loss: -1.0674  Acc@1: 87.5000 (87.4396)  Acc@5: 100.0000 (98.4230)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:45  Lr: 0.030000  Loss: -1.5723  Acc@1: 87.5000 (87.4375)  Acc@5: 100.0000 (98.4242)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:42  Lr: 0.030000  Loss: -1.5735  Acc@1: 87.5000 (87.4239)  Acc@5: 100.0000 (98.4231)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:38  Lr: 0.030000  Loss: -1.2719  Acc@1: 87.5000 (87.4311)  Acc@5: 100.0000 (98.4220)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:34  Lr: 0.030000  Loss: -1.4631  Acc@1: 93.7500 (87.4474)  Acc@5: 100.0000 (98.4232)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:30  Lr: 0.030000  Loss: -1.4996  Acc@1: 93.7500 (87.4590)  Acc@5: 100.0000 (98.4244)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:26  Lr: 0.030000  Loss: -1.1803  Acc@1: 87.5000 (87.4477)  Acc@5: 100.0000 (98.4165)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:22  Lr: 0.030000  Loss: -1.7437  Acc@1: 87.5000 (87.4457)  Acc@5: 93.7500 (98.4132)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:18  Lr: 0.030000  Loss: -1.0849  Acc@1: 87.5000 (87.4504)  Acc@5: 100.0000 (98.4144)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2780/3125]  eta: 0:02:14  Lr: 0.030000  Loss: -1.7207  Acc@1: 87.5000 (87.4416)  Acc@5: 100.0000 (98.4133)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2790/3125]  eta: 0:02:10  Lr: 0.030000  Loss: -1.6904  Acc@1: 87.5000 (87.4328)  Acc@5: 100.0000 (98.4168)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2800/3125]  eta: 0:02:06  Lr: 0.030000  Loss: -1.6627  Acc@1: 87.5000 (87.4264)  Acc@5: 100.0000 (98.4157)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2810/3125]  eta: 0:02:03  Lr: 0.030000  Loss: -0.8803  Acc@1: 87.5000 (87.4066)  Acc@5: 100.0000 (98.4169)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:59  Lr: 0.030000  Loss: -1.1085  Acc@1: 87.5000 (87.4092)  Acc@5: 100.0000 (98.4181)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:55  Lr: 0.030000  Loss: -1.4779  Acc@1: 87.5000 (87.4051)  Acc@5: 100.0000 (98.4149)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:51  Lr: 0.030000  Loss: -1.3296  Acc@1: 87.5000 (87.4142)  Acc@5: 100.0000 (98.4051)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:47  Lr: 0.030000  Loss: -1.4941  Acc@1: 93.7500 (87.4233)  Acc@5: 100.0000 (98.4106)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:43  Lr: 0.030000  Loss: -1.4610  Acc@1: 87.5000 (87.4126)  Acc@5: 100.0000 (98.4031)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:39  Lr: 0.030000  Loss: -1.4183  Acc@1: 87.5000 (87.4086)  Acc@5: 100.0000 (98.4087)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:35  Lr: 0.030000  Loss: -1.7316  Acc@1: 87.5000 (87.4241)  Acc@5: 100.0000 (98.4055)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:31  Lr: 0.030000  Loss: -1.9354  Acc@1: 87.5000 (87.4200)  Acc@5: 100.0000 (98.4110)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:27  Lr: 0.030000  Loss: -0.7674  Acc@1: 87.5000 (87.4138)  Acc@5: 100.0000 (98.4122)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:23  Lr: 0.030000  Loss: -1.6852  Acc@1: 87.5000 (87.4206)  Acc@5: 100.0000 (98.4155)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:20  Lr: 0.030000  Loss: -1.3764  Acc@1: 87.5000 (87.4187)  Acc@5: 100.0000 (98.4145)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:16  Lr: 0.030000  Loss: -1.2800  Acc@1: 87.5000 (87.4126)  Acc@5: 100.0000 (98.4135)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:12  Lr: 0.030000  Loss: -1.5174  Acc@1: 87.5000 (87.4086)  Acc@5: 100.0000 (98.4125)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:08  Lr: 0.030000  Loss: -1.8459  Acc@1: 87.5000 (87.4132)  Acc@5: 100.0000 (98.4179)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2960/3125]  eta: 0:01:04  Lr: 0.030000  Loss: -2.0731  Acc@1: 87.5000 (87.4092)  Acc@5: 100.0000 (98.4148)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2970/3125]  eta: 0:01:00  Lr: 0.030000  Loss: -1.4527  Acc@1: 87.5000 (87.4053)  Acc@5: 100.0000 (98.4138)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:56  Lr: 0.030000  Loss: -1.6631  Acc@1: 87.5000 (87.4057)  Acc@5: 100.0000 (98.4129)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:52  Lr: 0.030000  Loss: -1.4146  Acc@1: 87.5000 (87.4143)  Acc@5: 100.0000 (98.4140)  time: 0.3908  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:48  Lr: 0.030000  Loss: -1.7632  Acc@1: 87.5000 (87.4167)  Acc@5: 100.0000 (98.4151)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:44  Lr: 0.030000  Loss: -1.2533  Acc@1: 87.5000 (87.4128)  Acc@5: 100.0000 (98.4183)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:41  Lr: 0.030000  Loss: -1.6727  Acc@1: 87.5000 (87.4048)  Acc@5: 100.0000 (98.4235)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:37  Lr: 0.030000  Loss: -1.3590  Acc@1: 87.5000 (87.4113)  Acc@5: 100.0000 (98.4246)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:33  Lr: 0.030000  Loss: -1.6397  Acc@1: 87.5000 (87.4096)  Acc@5: 100.0000 (98.4216)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:29  Lr: 0.030000  Loss: -1.7227  Acc@1: 87.5000 (87.4140)  Acc@5: 100.0000 (98.4226)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:25  Lr: 0.030000  Loss: -1.5803  Acc@1: 87.5000 (87.4142)  Acc@5: 100.0000 (98.4237)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:21  Lr: 0.030000  Loss: -1.6115  Acc@1: 87.5000 (87.4105)  Acc@5: 100.0000 (98.4248)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:17  Lr: 0.030000  Loss: -1.5635  Acc@1: 87.5000 (87.4209)  Acc@5: 100.0000 (98.4258)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:13  Lr: 0.030000  Loss: -1.8154  Acc@1: 87.5000 (87.4029)  Acc@5: 100.0000 (98.4208)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:09  Lr: 0.030000  Loss: -1.6530  Acc@1: 81.2500 (87.4012)  Acc@5: 100.0000 (98.4219)  time: 0.3896  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: -1.5342  Acc@1: 87.5000 (87.3915)  Acc@5: 100.0000 (98.4189)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: -1.2256  Acc@1: 87.5000 (87.3859)  Acc@5: 100.0000 (98.4200)  time: 0.3918  data: 0.0008  max mem: 2912
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: -1.8034  Acc@1: 87.5000 (87.3840)  Acc@5: 100.0000 (98.4200)  time: 0.3911  data: 0.0008  max mem: 2912
Train: Epoch[4/5] Total time: 0:20:21 (0.3907 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.8034  Acc@1: 87.5000 (87.3840)  Acc@5: 100.0000 (98.4200)
Train: Epoch[5/5]  [   0/3125]  eta: 0:41:02  Lr: 0.030000  Loss: -1.4492  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.7879  data: 0.3947  max mem: 2912
Train: Epoch[5/5]  [  10/3125]  eta: 0:22:05  Lr: 0.030000  Loss: -1.1591  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.4256  data: 0.0362  max mem: 2912
Train: Epoch[5/5]  [  20/3125]  eta: 0:21:09  Lr: 0.030000  Loss: -1.4832  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.8095)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  30/3125]  eta: 0:20:45  Lr: 0.030000  Loss: -1.6322  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (98.5887)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  40/3125]  eta: 0:20:34  Lr: 0.030000  Loss: -1.1980  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (98.4756)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  50/3125]  eta: 0:20:24  Lr: 0.030000  Loss: -1.3333  Acc@1: 87.5000 (88.9706)  Acc@5: 100.0000 (98.6520)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  60/3125]  eta: 0:20:15  Lr: 0.030000  Loss: -1.7224  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (98.4631)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  70/3125]  eta: 0:20:09  Lr: 0.030000  Loss: -1.6490  Acc@1: 87.5000 (88.8204)  Acc@5: 100.0000 (98.2394)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  80/3125]  eta: 0:20:02  Lr: 0.030000  Loss: -1.3530  Acc@1: 87.5000 (88.8889)  Acc@5: 100.0000 (98.1481)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  90/3125]  eta: 0:19:57  Lr: 0.030000  Loss: -1.2848  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.1456)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 100/3125]  eta: 0:19:51  Lr: 0.030000  Loss: -1.6727  Acc@1: 87.5000 (88.6139)  Acc@5: 100.0000 (98.2673)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 110/3125]  eta: 0:19:46  Lr: 0.030000  Loss: -1.2368  Acc@1: 93.7500 (88.5698)  Acc@5: 100.0000 (98.1982)  time: 0.3895  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 120/3125]  eta: 0:19:41  Lr: 0.030000  Loss: -1.6326  Acc@1: 87.5000 (88.4298)  Acc@5: 100.0000 (98.2438)  time: 0.3895  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 130/3125]  eta: 0:19:36  Lr: 0.030000  Loss: -1.4900  Acc@1: 87.5000 (88.3588)  Acc@5: 100.0000 (98.3779)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 140/3125]  eta: 0:19:32  Lr: 0.030000  Loss: -1.8317  Acc@1: 87.5000 (88.2979)  Acc@5: 100.0000 (98.3156)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 150/3125]  eta: 0:19:27  Lr: 0.030000  Loss: -1.3392  Acc@1: 87.5000 (88.2450)  Acc@5: 100.0000 (98.3444)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 160/3125]  eta: 0:19:23  Lr: 0.030000  Loss: -1.6127  Acc@1: 81.2500 (87.8882)  Acc@5: 100.0000 (98.3696)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 170/3125]  eta: 0:19:19  Lr: 0.030000  Loss: -0.5527  Acc@1: 81.2500 (87.8655)  Acc@5: 100.0000 (98.2822)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 180/3125]  eta: 0:19:14  Lr: 0.030000  Loss: -0.9931  Acc@1: 93.7500 (87.9834)  Acc@5: 100.0000 (98.3425)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 190/3125]  eta: 0:19:10  Lr: 0.030000  Loss: -1.1202  Acc@1: 87.5000 (88.0563)  Acc@5: 100.0000 (98.3966)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 200/3125]  eta: 0:19:06  Lr: 0.030000  Loss: -1.3322  Acc@1: 87.5000 (87.9042)  Acc@5: 100.0000 (98.3520)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 210/3125]  eta: 0:19:02  Lr: 0.030000  Loss: -1.7851  Acc@1: 87.5000 (87.9443)  Acc@5: 100.0000 (98.3709)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 220/3125]  eta: 0:18:57  Lr: 0.030000  Loss: -1.5828  Acc@1: 87.5000 (87.8959)  Acc@5: 100.0000 (98.3880)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 230/3125]  eta: 0:18:53  Lr: 0.030000  Loss: -0.9877  Acc@1: 87.5000 (87.8788)  Acc@5: 100.0000 (98.2684)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 240/3125]  eta: 0:18:49  Lr: 0.030000  Loss: -1.7414  Acc@1: 87.5000 (87.9149)  Acc@5: 100.0000 (98.3402)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 250/3125]  eta: 0:18:45  Lr: 0.030000  Loss: -1.5180  Acc@1: 87.5000 (87.8735)  Acc@5: 100.0000 (98.3815)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 260/3125]  eta: 0:18:41  Lr: 0.030000  Loss: -1.3185  Acc@1: 81.2500 (87.5000)  Acc@5: 100.0000 (98.3956)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 270/3125]  eta: 0:18:37  Lr: 0.030000  Loss: -1.7569  Acc@1: 81.2500 (87.5000)  Acc@5: 100.0000 (98.4317)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 280/3125]  eta: 0:18:34  Lr: 0.030000  Loss: -1.5101  Acc@1: 87.5000 (87.4333)  Acc@5: 100.0000 (98.4653)  time: 0.3930  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 290/3125]  eta: 0:18:30  Lr: 0.030000  Loss: -0.6034  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4536)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 300/3125]  eta: 0:18:26  Lr: 0.030000  Loss: -1.8014  Acc@1: 87.5000 (87.5831)  Acc@5: 100.0000 (98.4427)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 310/3125]  eta: 0:18:22  Lr: 0.030000  Loss: -1.8623  Acc@1: 87.5000 (87.6206)  Acc@5: 100.0000 (98.4928)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 320/3125]  eta: 0:18:18  Lr: 0.030000  Loss: -1.2932  Acc@1: 87.5000 (87.5195)  Acc@5: 100.0000 (98.4813)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 330/3125]  eta: 0:18:14  Lr: 0.030000  Loss: -1.6164  Acc@1: 87.5000 (87.5944)  Acc@5: 100.0000 (98.5083)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 340/3125]  eta: 0:18:10  Lr: 0.030000  Loss: -1.5327  Acc@1: 87.5000 (87.5367)  Acc@5: 100.0000 (98.4421)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 350/3125]  eta: 0:18:06  Lr: 0.030000  Loss: -1.2847  Acc@1: 87.5000 (87.5178)  Acc@5: 100.0000 (98.4509)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 360/3125]  eta: 0:18:02  Lr: 0.030000  Loss: -1.6171  Acc@1: 87.5000 (87.5866)  Acc@5: 100.0000 (98.4591)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 370/3125]  eta: 0:17:58  Lr: 0.030000  Loss: -1.7966  Acc@1: 87.5000 (87.5674)  Acc@5: 100.0000 (98.4333)  time: 0.3930  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 380/3125]  eta: 0:17:54  Lr: 0.030000  Loss: -1.3485  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4580)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 390/3125]  eta: 0:17:51  Lr: 0.030000  Loss: -1.7052  Acc@1: 87.5000 (87.4840)  Acc@5: 100.0000 (98.4974)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 400/3125]  eta: 0:17:47  Lr: 0.030000  Loss: -1.8062  Acc@1: 87.5000 (87.5623)  Acc@5: 100.0000 (98.5193)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 410/3125]  eta: 0:17:43  Lr: 0.030000  Loss: -1.5554  Acc@1: 87.5000 (87.5456)  Acc@5: 100.0000 (98.5401)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 420/3125]  eta: 0:17:39  Lr: 0.030000  Loss: -1.7348  Acc@1: 93.7500 (87.6485)  Acc@5: 100.0000 (98.5600)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 430/3125]  eta: 0:17:35  Lr: 0.030000  Loss: -1.6147  Acc@1: 87.5000 (87.6595)  Acc@5: 100.0000 (98.5499)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 440/3125]  eta: 0:17:31  Lr: 0.030000  Loss: -1.5436  Acc@1: 87.5000 (87.7551)  Acc@5: 100.0000 (98.5828)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 450/3125]  eta: 0:17:27  Lr: 0.030000  Loss: -1.5125  Acc@1: 87.5000 (87.6386)  Acc@5: 100.0000 (98.5588)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 460/3125]  eta: 0:17:23  Lr: 0.030000  Loss: -1.5524  Acc@1: 87.5000 (87.6491)  Acc@5: 100.0000 (98.5629)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 470/3125]  eta: 0:17:19  Lr: 0.030000  Loss: -1.3390  Acc@1: 87.5000 (87.6858)  Acc@5: 100.0000 (98.5669)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 480/3125]  eta: 0:17:15  Lr: 0.030000  Loss: -1.4375  Acc@1: 87.5000 (87.6949)  Acc@5: 100.0000 (98.5447)  time: 0.3926  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 490/3125]  eta: 0:17:12  Lr: 0.030000  Loss: -0.9971  Acc@1: 87.5000 (87.6782)  Acc@5: 100.0000 (98.5616)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 500/3125]  eta: 0:17:08  Lr: 0.030000  Loss: -1.6352  Acc@1: 87.5000 (87.6747)  Acc@5: 100.0000 (98.5654)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 510/3125]  eta: 0:17:04  Lr: 0.030000  Loss: -1.1758  Acc@1: 87.5000 (87.5856)  Acc@5: 100.0000 (98.5445)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 520/3125]  eta: 0:17:00  Lr: 0.030000  Loss: -1.5992  Acc@1: 81.2500 (87.5360)  Acc@5: 100.0000 (98.5605)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 530/3125]  eta: 0:16:56  Lr: 0.030000  Loss: -0.9347  Acc@1: 81.2500 (87.5000)  Acc@5: 100.0000 (98.5523)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 540/3125]  eta: 0:16:52  Lr: 0.030000  Loss: -1.6076  Acc@1: 87.5000 (87.4769)  Acc@5: 100.0000 (98.5559)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 550/3125]  eta: 0:16:48  Lr: 0.030000  Loss: -1.9051  Acc@1: 87.5000 (87.4773)  Acc@5: 100.0000 (98.5594)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 560/3125]  eta: 0:16:44  Lr: 0.030000  Loss: -1.2354  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5628)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 570/3125]  eta: 0:16:40  Lr: 0.030000  Loss: -1.4289  Acc@1: 87.5000 (87.5109)  Acc@5: 100.0000 (98.5771)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 580/3125]  eta: 0:16:36  Lr: 0.030000  Loss: -1.5599  Acc@1: 87.5000 (87.4892)  Acc@5: 100.0000 (98.5800)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 590/3125]  eta: 0:16:32  Lr: 0.030000  Loss: -1.5768  Acc@1: 87.5000 (87.4788)  Acc@5: 100.0000 (98.5723)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 600/3125]  eta: 0:16:28  Lr: 0.030000  Loss: -1.7622  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5545)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 610/3125]  eta: 0:16:24  Lr: 0.030000  Loss: -1.2140  Acc@1: 93.7500 (87.5102)  Acc@5: 100.0000 (98.5270)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 620/3125]  eta: 0:16:20  Lr: 0.030000  Loss: -1.5231  Acc@1: 87.5000 (87.4899)  Acc@5: 100.0000 (98.5205)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 630/3125]  eta: 0:16:16  Lr: 0.030000  Loss: -1.6450  Acc@1: 87.5000 (87.4505)  Acc@5: 100.0000 (98.5044)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 640/3125]  eta: 0:16:12  Lr: 0.030000  Loss: -1.5111  Acc@1: 81.2500 (87.4610)  Acc@5: 100.0000 (98.4984)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 650/3125]  eta: 0:16:08  Lr: 0.030000  Loss: -1.3316  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.4927)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 660/3125]  eta: 0:16:04  Lr: 0.030000  Loss: -1.2768  Acc@1: 87.5000 (87.5284)  Acc@5: 100.0000 (98.4966)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 670/3125]  eta: 0:16:00  Lr: 0.030000  Loss: -1.4008  Acc@1: 87.5000 (87.5931)  Acc@5: 100.0000 (98.5097)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 680/3125]  eta: 0:15:56  Lr: 0.030000  Loss: -1.5481  Acc@1: 87.5000 (87.5734)  Acc@5: 100.0000 (98.5040)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 690/3125]  eta: 0:15:52  Lr: 0.030000  Loss: -1.4020  Acc@1: 87.5000 (87.5452)  Acc@5: 100.0000 (98.4895)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 700/3125]  eta: 0:15:49  Lr: 0.030000  Loss: -1.4020  Acc@1: 87.5000 (87.5624)  Acc@5: 100.0000 (98.4843)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 710/3125]  eta: 0:15:45  Lr: 0.030000  Loss: -1.7761  Acc@1: 87.5000 (87.5527)  Acc@5: 100.0000 (98.4968)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 720/3125]  eta: 0:15:41  Lr: 0.030000  Loss: -1.7532  Acc@1: 87.5000 (87.6040)  Acc@5: 100.0000 (98.4917)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 730/3125]  eta: 0:15:37  Lr: 0.030000  Loss: -1.8039  Acc@1: 93.7500 (87.6111)  Acc@5: 100.0000 (98.5123)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 740/3125]  eta: 0:15:33  Lr: 0.030000  Loss: -1.5475  Acc@1: 87.5000 (87.6181)  Acc@5: 100.0000 (98.5155)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 750/3125]  eta: 0:15:29  Lr: 0.030000  Loss: -1.6487  Acc@1: 87.5000 (87.5915)  Acc@5: 100.0000 (98.5103)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 760/3125]  eta: 0:15:25  Lr: 0.030000  Loss: -0.9367  Acc@1: 87.5000 (87.5575)  Acc@5: 100.0000 (98.4806)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 770/3125]  eta: 0:15:21  Lr: 0.030000  Loss: -1.6769  Acc@1: 87.5000 (87.5081)  Acc@5: 100.0000 (98.4841)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 780/3125]  eta: 0:15:17  Lr: 0.030000  Loss: -1.5019  Acc@1: 87.5000 (87.5480)  Acc@5: 100.0000 (98.4875)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 790/3125]  eta: 0:15:13  Lr: 0.030000  Loss: -1.4362  Acc@1: 87.5000 (87.5869)  Acc@5: 100.0000 (98.4829)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 800/3125]  eta: 0:15:09  Lr: 0.030000  Loss: -1.5975  Acc@1: 87.5000 (87.6170)  Acc@5: 100.0000 (98.4941)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 810/3125]  eta: 0:15:05  Lr: 0.030000  Loss: -1.6337  Acc@1: 87.5000 (87.5848)  Acc@5: 100.0000 (98.4741)  time: 0.3900  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 820/3125]  eta: 0:15:01  Lr: 0.030000  Loss: -1.3458  Acc@1: 87.5000 (87.6294)  Acc@5: 100.0000 (98.4851)  time: 0.3901  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 830/3125]  eta: 0:14:57  Lr: 0.030000  Loss: -1.3341  Acc@1: 87.5000 (87.5602)  Acc@5: 100.0000 (98.4807)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 840/3125]  eta: 0:14:53  Lr: 0.030000  Loss: -1.5064  Acc@1: 81.2500 (87.5743)  Acc@5: 100.0000 (98.4914)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 850/3125]  eta: 0:14:49  Lr: 0.030000  Loss: -1.6015  Acc@1: 87.5000 (87.5808)  Acc@5: 100.0000 (98.5018)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 860/3125]  eta: 0:14:45  Lr: 0.030000  Loss: -1.5670  Acc@1: 87.5000 (87.5798)  Acc@5: 100.0000 (98.4974)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 870/3125]  eta: 0:14:41  Lr: 0.030000  Loss: -1.9572  Acc@1: 87.5000 (87.6005)  Acc@5: 100.0000 (98.5003)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 880/3125]  eta: 0:14:37  Lr: 0.030000  Loss: -1.6245  Acc@1: 87.5000 (87.5497)  Acc@5: 100.0000 (98.4889)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 890/3125]  eta: 0:14:33  Lr: 0.030000  Loss: -1.7032  Acc@1: 81.2500 (87.5210)  Acc@5: 100.0000 (98.4848)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 900/3125]  eta: 0:14:29  Lr: 0.030000  Loss: -1.6034  Acc@1: 81.2500 (87.4861)  Acc@5: 100.0000 (98.4878)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 910/3125]  eta: 0:14:26  Lr: 0.030000  Loss: -1.5605  Acc@1: 87.5000 (87.4726)  Acc@5: 100.0000 (98.4838)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 920/3125]  eta: 0:14:22  Lr: 0.030000  Loss: -1.4950  Acc@1: 87.5000 (87.5136)  Acc@5: 100.0000 (98.4935)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 930/3125]  eta: 0:14:18  Lr: 0.030000  Loss: -1.3861  Acc@1: 87.5000 (87.5067)  Acc@5: 100.0000 (98.4828)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 940/3125]  eta: 0:14:14  Lr: 0.030000  Loss: -1.7908  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4923)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 950/3125]  eta: 0:14:10  Lr: 0.030000  Loss: -1.7173  Acc@1: 87.5000 (87.5723)  Acc@5: 100.0000 (98.5081)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 960/3125]  eta: 0:14:06  Lr: 0.030000  Loss: -1.5424  Acc@1: 87.5000 (87.5650)  Acc@5: 100.0000 (98.5172)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 970/3125]  eta: 0:14:02  Lr: 0.030000  Loss: -1.6870  Acc@1: 87.5000 (87.5644)  Acc@5: 100.0000 (98.4938)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 980/3125]  eta: 0:13:58  Lr: 0.030000  Loss: -1.0296  Acc@1: 87.5000 (87.5573)  Acc@5: 100.0000 (98.5028)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 990/3125]  eta: 0:13:54  Lr: 0.030000  Loss: -1.3431  Acc@1: 87.5000 (87.5568)  Acc@5: 100.0000 (98.4990)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1000/3125]  eta: 0:13:50  Lr: 0.030000  Loss: -1.6136  Acc@1: 87.5000 (87.5937)  Acc@5: 100.0000 (98.5140)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1010/3125]  eta: 0:13:46  Lr: 0.030000  Loss: -1.2043  Acc@1: 87.5000 (87.5804)  Acc@5: 100.0000 (98.5101)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1020/3125]  eta: 0:13:43  Lr: 0.030000  Loss: -0.9919  Acc@1: 93.7500 (87.5612)  Acc@5: 100.0000 (98.5125)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1030/3125]  eta: 0:13:39  Lr: 0.030000  Loss: -1.7015  Acc@1: 87.5000 (87.5424)  Acc@5: 100.0000 (98.5087)  time: 0.3917  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [1040/3125]  eta: 0:13:35  Lr: 0.030000  Loss: -1.7154  Acc@1: 87.5000 (87.5600)  Acc@5: 100.0000 (98.4990)  time: 0.3908  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [1050/3125]  eta: 0:13:31  Lr: 0.030000  Loss: -0.8801  Acc@1: 87.5000 (87.5238)  Acc@5: 100.0000 (98.4955)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1060/3125]  eta: 0:13:27  Lr: 0.030000  Loss: -1.1977  Acc@1: 87.5000 (87.5059)  Acc@5: 100.0000 (98.4979)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1070/3125]  eta: 0:13:23  Lr: 0.030000  Loss: -1.6664  Acc@1: 87.5000 (87.5117)  Acc@5: 100.0000 (98.5061)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1080/3125]  eta: 0:13:19  Lr: 0.030000  Loss: -1.7100  Acc@1: 87.5000 (87.4884)  Acc@5: 100.0000 (98.5083)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1090/3125]  eta: 0:13:15  Lr: 0.030000  Loss: -1.1867  Acc@1: 87.5000 (87.4542)  Acc@5: 100.0000 (98.4991)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1100/3125]  eta: 0:13:11  Lr: 0.030000  Loss: -1.1388  Acc@1: 87.5000 (87.4603)  Acc@5: 100.0000 (98.4900)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1110/3125]  eta: 0:13:07  Lr: 0.030000  Loss: -1.4157  Acc@1: 87.5000 (87.4381)  Acc@5: 100.0000 (98.4867)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1120/3125]  eta: 0:13:04  Lr: 0.030000  Loss: -1.3251  Acc@1: 87.5000 (87.4610)  Acc@5: 100.0000 (98.4891)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1130/3125]  eta: 0:13:00  Lr: 0.030000  Loss: -1.1030  Acc@1: 87.5000 (87.4392)  Acc@5: 100.0000 (98.4914)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1140/3125]  eta: 0:12:56  Lr: 0.030000  Loss: -1.3308  Acc@1: 81.2500 (87.4124)  Acc@5: 100.0000 (98.4936)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1150/3125]  eta: 0:12:52  Lr: 0.030000  Loss: -1.5447  Acc@1: 87.5000 (87.3968)  Acc@5: 100.0000 (98.4904)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1160/3125]  eta: 0:12:48  Lr: 0.030000  Loss: -1.7879  Acc@1: 87.5000 (87.3923)  Acc@5: 100.0000 (98.4981)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1170/3125]  eta: 0:12:44  Lr: 0.030000  Loss: -1.6103  Acc@1: 87.5000 (87.4093)  Acc@5: 100.0000 (98.5002)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1180/3125]  eta: 0:12:40  Lr: 0.030000  Loss: -1.5833  Acc@1: 87.5000 (87.4259)  Acc@5: 100.0000 (98.5076)  time: 0.3915  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [1190/3125]  eta: 0:12:36  Lr: 0.030000  Loss: -1.3470  Acc@1: 87.5000 (87.4265)  Acc@5: 100.0000 (98.4992)  time: 0.3915  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [1200/3125]  eta: 0:12:32  Lr: 0.030000  Loss: -1.7641  Acc@1: 87.5000 (87.4636)  Acc@5: 100.0000 (98.5117)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1210/3125]  eta: 0:12:28  Lr: 0.030000  Loss: -1.7208  Acc@1: 87.5000 (87.4484)  Acc@5: 100.0000 (98.5188)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1220/3125]  eta: 0:12:24  Lr: 0.030000  Loss: -1.7335  Acc@1: 87.5000 (87.4846)  Acc@5: 100.0000 (98.5309)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1230/3125]  eta: 0:12:20  Lr: 0.030000  Loss: -1.1593  Acc@1: 93.7500 (87.4848)  Acc@5: 100.0000 (98.5276)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1240/3125]  eta: 0:12:17  Lr: 0.030000  Loss: -1.7653  Acc@1: 87.5000 (87.4748)  Acc@5: 100.0000 (98.5244)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1250/3125]  eta: 0:12:13  Lr: 0.030000  Loss: -1.4877  Acc@1: 87.5000 (87.5150)  Acc@5: 100.0000 (98.5212)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1260/3125]  eta: 0:12:09  Lr: 0.030000  Loss: -1.2250  Acc@1: 93.7500 (87.5248)  Acc@5: 100.0000 (98.5230)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1270/3125]  eta: 0:12:05  Lr: 0.030000  Loss: -1.5238  Acc@1: 93.7500 (87.5492)  Acc@5: 100.0000 (98.5199)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1280/3125]  eta: 0:12:01  Lr: 0.030000  Loss: -1.7328  Acc@1: 93.7500 (87.5634)  Acc@5: 100.0000 (98.5265)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1290/3125]  eta: 0:11:57  Lr: 0.030000  Loss: -1.7241  Acc@1: 93.7500 (87.5968)  Acc@5: 100.0000 (98.5331)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1300/3125]  eta: 0:11:53  Lr: 0.030000  Loss: -1.4182  Acc@1: 93.7500 (87.6009)  Acc@5: 100.0000 (98.5300)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1310/3125]  eta: 0:11:49  Lr: 0.030000  Loss: -1.7957  Acc@1: 87.5000 (87.6001)  Acc@5: 100.0000 (98.5364)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1320/3125]  eta: 0:11:45  Lr: 0.030000  Loss: -1.4104  Acc@1: 93.7500 (87.6467)  Acc@5: 100.0000 (98.5428)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1330/3125]  eta: 0:11:41  Lr: 0.030000  Loss: -1.5131  Acc@1: 87.5000 (87.6503)  Acc@5: 100.0000 (98.5396)  time: 0.3884  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1340/3125]  eta: 0:11:37  Lr: 0.030000  Loss: -0.9575  Acc@1: 87.5000 (87.6585)  Acc@5: 100.0000 (98.5459)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1350/3125]  eta: 0:11:33  Lr: 0.030000  Loss: -1.8322  Acc@1: 87.5000 (87.6249)  Acc@5: 100.0000 (98.5427)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1360/3125]  eta: 0:11:29  Lr: 0.030000  Loss: -1.1390  Acc@1: 87.5000 (87.6148)  Acc@5: 100.0000 (98.5397)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1370/3125]  eta: 0:11:25  Lr: 0.030000  Loss: -1.6042  Acc@1: 87.5000 (87.6231)  Acc@5: 100.0000 (98.5503)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1380/3125]  eta: 0:11:22  Lr: 0.030000  Loss: -1.9304  Acc@1: 87.5000 (87.5996)  Acc@5: 100.0000 (98.5472)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1390/3125]  eta: 0:11:18  Lr: 0.030000  Loss: -1.5424  Acc@1: 87.5000 (87.5899)  Acc@5: 100.0000 (98.5532)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1400/3125]  eta: 0:11:14  Lr: 0.030000  Loss: -1.3437  Acc@1: 87.5000 (87.5758)  Acc@5: 100.0000 (98.5635)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1410/3125]  eta: 0:11:10  Lr: 0.030000  Loss: -1.7865  Acc@1: 87.5000 (87.5842)  Acc@5: 100.0000 (98.5560)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1420/3125]  eta: 0:11:06  Lr: 0.030000  Loss: -1.7846  Acc@1: 87.5000 (87.5924)  Acc@5: 100.0000 (98.5486)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1430/3125]  eta: 0:11:02  Lr: 0.030000  Loss: -1.4394  Acc@1: 87.5000 (87.5742)  Acc@5: 100.0000 (98.5456)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1440/3125]  eta: 0:10:58  Lr: 0.030000  Loss: -1.4904  Acc@1: 87.5000 (87.5607)  Acc@5: 100.0000 (98.5427)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1450/3125]  eta: 0:10:54  Lr: 0.030000  Loss: -1.6368  Acc@1: 87.5000 (87.5560)  Acc@5: 100.0000 (98.5355)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1460/3125]  eta: 0:10:50  Lr: 0.030000  Loss: -1.4587  Acc@1: 87.5000 (87.5684)  Acc@5: 100.0000 (98.5284)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1470/3125]  eta: 0:10:46  Lr: 0.030000  Loss: -1.1555  Acc@1: 87.5000 (87.5765)  Acc@5: 100.0000 (98.5299)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1480/3125]  eta: 0:10:42  Lr: 0.030000  Loss: -1.3324  Acc@1: 87.5000 (87.5802)  Acc@5: 100.0000 (98.5272)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1490/3125]  eta: 0:10:38  Lr: 0.030000  Loss: -1.2529  Acc@1: 87.5000 (87.5964)  Acc@5: 100.0000 (98.5329)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1500/3125]  eta: 0:10:35  Lr: 0.030000  Loss: -1.7592  Acc@1: 87.5000 (87.6124)  Acc@5: 100.0000 (98.5301)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1510/3125]  eta: 0:10:31  Lr: 0.030000  Loss: -1.6113  Acc@1: 87.5000 (87.6324)  Acc@5: 100.0000 (98.5357)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1520/3125]  eta: 0:10:27  Lr: 0.030000  Loss: -1.4867  Acc@1: 87.5000 (87.6479)  Acc@5: 100.0000 (98.5330)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1530/3125]  eta: 0:10:23  Lr: 0.030000  Loss: -1.7991  Acc@1: 87.5000 (87.6633)  Acc@5: 100.0000 (98.5263)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1540/3125]  eta: 0:10:19  Lr: 0.030000  Loss: -1.6353  Acc@1: 93.7500 (87.6744)  Acc@5: 100.0000 (98.5318)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1550/3125]  eta: 0:10:15  Lr: 0.030000  Loss: -1.7484  Acc@1: 93.7500 (87.6773)  Acc@5: 100.0000 (98.5413)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1560/3125]  eta: 0:10:11  Lr: 0.030000  Loss: -0.9388  Acc@1: 87.5000 (87.6722)  Acc@5: 100.0000 (98.5466)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1570/3125]  eta: 0:10:07  Lr: 0.030000  Loss: -1.6120  Acc@1: 87.5000 (87.6591)  Acc@5: 100.0000 (98.5559)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1580/3125]  eta: 0:10:03  Lr: 0.030000  Loss: -1.3238  Acc@1: 87.5000 (87.6384)  Acc@5: 100.0000 (98.5413)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1590/3125]  eta: 0:09:59  Lr: 0.030000  Loss: -1.5676  Acc@1: 87.5000 (87.6493)  Acc@5: 100.0000 (98.5426)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1600/3125]  eta: 0:09:55  Lr: 0.030000  Loss: -1.4975  Acc@1: 87.5000 (87.6288)  Acc@5: 100.0000 (98.5400)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1610/3125]  eta: 0:09:52  Lr: 0.030000  Loss: -1.3252  Acc@1: 87.5000 (87.6358)  Acc@5: 100.0000 (98.5413)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1620/3125]  eta: 0:09:48  Lr: 0.030000  Loss: -1.0994  Acc@1: 87.5000 (87.6157)  Acc@5: 100.0000 (98.5426)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1630/3125]  eta: 0:09:44  Lr: 0.030000  Loss: -1.6022  Acc@1: 87.5000 (87.6303)  Acc@5: 100.0000 (98.5477)  time: 0.3921  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1640/3125]  eta: 0:09:40  Lr: 0.030000  Loss: -1.6833  Acc@1: 87.5000 (87.6333)  Acc@5: 100.0000 (98.5489)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1650/3125]  eta: 0:09:36  Lr: 0.030000  Loss: -0.9236  Acc@1: 87.5000 (87.6439)  Acc@5: 100.0000 (98.5463)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1660/3125]  eta: 0:09:32  Lr: 0.030000  Loss: -1.2151  Acc@1: 87.5000 (87.6317)  Acc@5: 100.0000 (98.5438)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1670/3125]  eta: 0:09:28  Lr: 0.030000  Loss: -1.2901  Acc@1: 87.5000 (87.6085)  Acc@5: 100.0000 (98.5376)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1680/3125]  eta: 0:09:24  Lr: 0.030000  Loss: -1.5195  Acc@1: 87.5000 (87.6338)  Acc@5: 100.0000 (98.5463)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1690/3125]  eta: 0:09:20  Lr: 0.030000  Loss: -1.6090  Acc@1: 87.5000 (87.6183)  Acc@5: 100.0000 (98.5438)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1700/3125]  eta: 0:09:16  Lr: 0.030000  Loss: -1.7537  Acc@1: 87.5000 (87.6249)  Acc@5: 100.0000 (98.5486)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1710/3125]  eta: 0:09:13  Lr: 0.030000  Loss: -1.6496  Acc@1: 87.5000 (87.6352)  Acc@5: 100.0000 (98.5425)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1720/3125]  eta: 0:09:09  Lr: 0.030000  Loss: -1.7730  Acc@1: 87.5000 (87.6198)  Acc@5: 100.0000 (98.5365)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1730/3125]  eta: 0:09:05  Lr: 0.030000  Loss: -1.6587  Acc@1: 87.5000 (87.6408)  Acc@5: 100.0000 (98.5377)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1740/3125]  eta: 0:09:01  Lr: 0.030000  Loss: -1.4483  Acc@1: 87.5000 (87.6256)  Acc@5: 100.0000 (98.5353)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1750/3125]  eta: 0:08:57  Lr: 0.030000  Loss: -1.6920  Acc@1: 87.5000 (87.6178)  Acc@5: 100.0000 (98.5366)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1760/3125]  eta: 0:08:53  Lr: 0.030000  Loss: -1.7377  Acc@1: 87.5000 (87.5923)  Acc@5: 100.0000 (98.5236)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1770/3125]  eta: 0:08:49  Lr: 0.030000  Loss: -1.4238  Acc@1: 87.5000 (87.5847)  Acc@5: 100.0000 (98.5248)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1780/3125]  eta: 0:08:45  Lr: 0.030000  Loss: -1.7511  Acc@1: 87.5000 (87.5807)  Acc@5: 100.0000 (98.5156)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1790/3125]  eta: 0:08:41  Lr: 0.030000  Loss: -1.2222  Acc@1: 87.5000 (87.5768)  Acc@5: 100.0000 (98.5239)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1800/3125]  eta: 0:08:37  Lr: 0.030000  Loss: -1.0657  Acc@1: 87.5000 (87.5937)  Acc@5: 100.0000 (98.5217)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1810/3125]  eta: 0:08:33  Lr: 0.030000  Loss: -1.5307  Acc@1: 93.7500 (87.5966)  Acc@5: 100.0000 (98.5160)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1820/3125]  eta: 0:08:30  Lr: 0.030000  Loss: -1.7227  Acc@1: 87.5000 (87.5927)  Acc@5: 100.0000 (98.5173)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1830/3125]  eta: 0:08:26  Lr: 0.030000  Loss: -1.5303  Acc@1: 87.5000 (87.6058)  Acc@5: 100.0000 (98.5152)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1840/3125]  eta: 0:08:22  Lr: 0.030000  Loss: -1.1245  Acc@1: 87.5000 (87.6290)  Acc@5: 100.0000 (98.5198)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1850/3125]  eta: 0:08:18  Lr: 0.030000  Loss: -1.7115  Acc@1: 87.5000 (87.6351)  Acc@5: 100.0000 (98.5177)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1860/3125]  eta: 0:08:14  Lr: 0.030000  Loss: -1.2659  Acc@1: 87.5000 (87.6310)  Acc@5: 100.0000 (98.5089)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1870/3125]  eta: 0:08:10  Lr: 0.030000  Loss: -1.7520  Acc@1: 87.5000 (87.6470)  Acc@5: 100.0000 (98.5168)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1880/3125]  eta: 0:08:06  Lr: 0.030000  Loss: -1.6070  Acc@1: 93.7500 (87.6528)  Acc@5: 100.0000 (98.5214)  time: 0.3947  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1890/3125]  eta: 0:08:02  Lr: 0.030000  Loss: -1.7438  Acc@1: 87.5000 (87.6454)  Acc@5: 100.0000 (98.5193)  time: 0.3954  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:58  Lr: 0.030000  Loss: -1.7636  Acc@1: 87.5000 (87.6644)  Acc@5: 100.0000 (98.5205)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1910/3125]  eta: 0:07:54  Lr: 0.030000  Loss: -1.5985  Acc@1: 87.5000 (87.6701)  Acc@5: 100.0000 (98.5152)  time: 0.3922  data: 0.0007  max mem: 2912
Train: Epoch[5/5]  [1920/3125]  eta: 0:07:51  Lr: 0.030000  Loss: -1.7285  Acc@1: 87.5000 (87.6562)  Acc@5: 100.0000 (98.5164)  time: 0.3916  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [1930/3125]  eta: 0:07:47  Lr: 0.030000  Loss: -1.6662  Acc@1: 87.5000 (87.6392)  Acc@5: 100.0000 (98.5241)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1940/3125]  eta: 0:07:43  Lr: 0.030000  Loss: -1.3399  Acc@1: 81.2500 (87.6256)  Acc@5: 100.0000 (98.5252)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1950/3125]  eta: 0:07:39  Lr: 0.030000  Loss: -1.6006  Acc@1: 87.5000 (87.6313)  Acc@5: 100.0000 (98.5296)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1960/3125]  eta: 0:07:35  Lr: 0.030000  Loss: -1.6137  Acc@1: 93.7500 (87.6625)  Acc@5: 100.0000 (98.5339)  time: 0.3910  data: 0.0009  max mem: 2912
Train: Epoch[5/5]  [1970/3125]  eta: 0:07:31  Lr: 0.030000  Loss: -1.8192  Acc@1: 93.7500 (87.6681)  Acc@5: 100.0000 (98.5318)  time: 0.3901  data: 0.0009  max mem: 2912
Train: Epoch[5/5]  [1980/3125]  eta: 0:07:27  Lr: 0.030000  Loss: -1.6393  Acc@1: 87.5000 (87.6735)  Acc@5: 100.0000 (98.5329)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1990/3125]  eta: 0:07:23  Lr: 0.030000  Loss: -1.5327  Acc@1: 87.5000 (87.6632)  Acc@5: 100.0000 (98.5309)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2000/3125]  eta: 0:07:19  Lr: 0.030000  Loss: -1.3019  Acc@1: 87.5000 (87.6624)  Acc@5: 100.0000 (98.5289)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2010/3125]  eta: 0:07:15  Lr: 0.030000  Loss: -1.3428  Acc@1: 87.5000 (87.6616)  Acc@5: 100.0000 (98.5269)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2020/3125]  eta: 0:07:11  Lr: 0.030000  Loss: -1.6742  Acc@1: 87.5000 (87.6546)  Acc@5: 100.0000 (98.5310)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2030/3125]  eta: 0:07:07  Lr: 0.030000  Loss: -1.8969  Acc@1: 87.5000 (87.6600)  Acc@5: 100.0000 (98.5383)  time: 0.3885  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2040/3125]  eta: 0:07:04  Lr: 0.030000  Loss: -1.4568  Acc@1: 87.5000 (87.6531)  Acc@5: 100.0000 (98.5393)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2050/3125]  eta: 0:07:00  Lr: 0.030000  Loss: -0.8694  Acc@1: 81.2500 (87.6249)  Acc@5: 100.0000 (98.5403)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:56  Lr: 0.030000  Loss: -1.4682  Acc@1: 81.2500 (87.6031)  Acc@5: 100.0000 (98.5383)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:52  Lr: 0.030000  Loss: -1.4052  Acc@1: 81.2500 (87.5785)  Acc@5: 100.0000 (98.5424)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2080/3125]  eta: 0:06:48  Lr: 0.030000  Loss: -1.1583  Acc@1: 81.2500 (87.5721)  Acc@5: 100.0000 (98.5374)  time: 0.3889  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2090/3125]  eta: 0:06:44  Lr: 0.030000  Loss: -1.4432  Acc@1: 87.5000 (87.5927)  Acc@5: 100.0000 (98.5384)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2100/3125]  eta: 0:06:40  Lr: 0.030000  Loss: -1.4761  Acc@1: 93.7500 (87.6160)  Acc@5: 100.0000 (98.5424)  time: 0.3888  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2110/3125]  eta: 0:06:36  Lr: 0.030000  Loss: -1.6251  Acc@1: 93.7500 (87.6214)  Acc@5: 100.0000 (98.5433)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2120/3125]  eta: 0:06:32  Lr: 0.030000  Loss: -1.7416  Acc@1: 87.5000 (87.6238)  Acc@5: 100.0000 (98.5414)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2130/3125]  eta: 0:06:28  Lr: 0.030000  Loss: -1.6362  Acc@1: 87.5000 (87.6261)  Acc@5: 100.0000 (98.5394)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2140/3125]  eta: 0:06:24  Lr: 0.030000  Loss: -1.8515  Acc@1: 93.7500 (87.6401)  Acc@5: 100.0000 (98.5433)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2150/3125]  eta: 0:06:21  Lr: 0.030000  Loss: -1.4999  Acc@1: 93.7500 (87.6395)  Acc@5: 100.0000 (98.5472)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2160/3125]  eta: 0:06:17  Lr: 0.030000  Loss: -1.8400  Acc@1: 87.5000 (87.6417)  Acc@5: 100.0000 (98.5481)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2170/3125]  eta: 0:06:13  Lr: 0.030000  Loss: -1.5576  Acc@1: 87.5000 (87.6439)  Acc@5: 100.0000 (98.5491)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2180/3125]  eta: 0:06:09  Lr: 0.030000  Loss: -1.9082  Acc@1: 87.5000 (87.6576)  Acc@5: 100.0000 (98.5471)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2190/3125]  eta: 0:06:05  Lr: 0.030000  Loss: -1.3266  Acc@1: 87.5000 (87.6540)  Acc@5: 100.0000 (98.5395)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2200/3125]  eta: 0:06:01  Lr: 0.030000  Loss: -1.7718  Acc@1: 87.5000 (87.6505)  Acc@5: 100.0000 (98.5404)  time: 0.3905  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:57  Lr: 0.030000  Loss: -1.7385  Acc@1: 87.5000 (87.6244)  Acc@5: 100.0000 (98.5386)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:53  Lr: 0.030000  Loss: -1.6830  Acc@1: 87.5000 (87.6210)  Acc@5: 100.0000 (98.5423)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:49  Lr: 0.030000  Loss: -1.1624  Acc@1: 87.5000 (87.6065)  Acc@5: 100.0000 (98.5489)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:45  Lr: 0.030000  Loss: -1.8878  Acc@1: 87.5000 (87.5892)  Acc@5: 100.0000 (98.5414)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:41  Lr: 0.030000  Loss: -1.5235  Acc@1: 87.5000 (87.5722)  Acc@5: 93.7500 (98.5340)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2260/3125]  eta: 0:05:38  Lr: 0.030000  Loss: -1.2736  Acc@1: 87.5000 (87.5719)  Acc@5: 100.0000 (98.5377)  time: 0.3924  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2270/3125]  eta: 0:05:34  Lr: 0.030000  Loss: -1.2048  Acc@1: 87.5000 (87.5826)  Acc@5: 100.0000 (98.5441)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2280/3125]  eta: 0:05:30  Lr: 0.030000  Loss: -1.5698  Acc@1: 93.7500 (87.6014)  Acc@5: 100.0000 (98.5478)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2290/3125]  eta: 0:05:26  Lr: 0.030000  Loss: -1.3830  Acc@1: 93.7500 (87.6228)  Acc@5: 100.0000 (98.5405)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2300/3125]  eta: 0:05:22  Lr: 0.030000  Loss: -1.5581  Acc@1: 93.7500 (87.6249)  Acc@5: 100.0000 (98.5414)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2310/3125]  eta: 0:05:18  Lr: 0.030000  Loss: -1.5444  Acc@1: 87.5000 (87.6325)  Acc@5: 100.0000 (98.5342)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2320/3125]  eta: 0:05:14  Lr: 0.030000  Loss: -1.7615  Acc@1: 87.5000 (87.6239)  Acc@5: 100.0000 (98.5351)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2330/3125]  eta: 0:05:10  Lr: 0.030000  Loss: -1.7355  Acc@1: 87.5000 (87.6233)  Acc@5: 100.0000 (98.5253)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2340/3125]  eta: 0:05:06  Lr: 0.030000  Loss: -1.3702  Acc@1: 87.5000 (87.6121)  Acc@5: 100.0000 (98.5289)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2350/3125]  eta: 0:05:02  Lr: 0.030000  Loss: -1.2855  Acc@1: 87.5000 (87.6223)  Acc@5: 100.0000 (98.5299)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:58  Lr: 0.030000  Loss: -1.5824  Acc@1: 87.5000 (87.6112)  Acc@5: 100.0000 (98.5282)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:55  Lr: 0.030000  Loss: -1.7893  Acc@1: 87.5000 (87.6160)  Acc@5: 100.0000 (98.5212)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:51  Lr: 0.030000  Loss: -1.5507  Acc@1: 87.5000 (87.6129)  Acc@5: 100.0000 (98.5169)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:47  Lr: 0.030000  Loss: -1.7556  Acc@1: 81.2500 (87.6072)  Acc@5: 100.0000 (98.5179)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:43  Lr: 0.030000  Loss: -1.3399  Acc@1: 87.5000 (87.5937)  Acc@5: 100.0000 (98.5136)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:39  Lr: 0.030000  Loss: -1.6906  Acc@1: 87.5000 (87.6011)  Acc@5: 100.0000 (98.5172)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:35  Lr: 0.030000  Loss: -1.2295  Acc@1: 87.5000 (87.5955)  Acc@5: 100.0000 (98.5182)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2430/3125]  eta: 0:04:31  Lr: 0.030000  Loss: -1.7919  Acc@1: 87.5000 (87.6106)  Acc@5: 100.0000 (98.5191)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2440/3125]  eta: 0:04:27  Lr: 0.030000  Loss: -1.6974  Acc@1: 93.7500 (87.6178)  Acc@5: 100.0000 (98.5201)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2450/3125]  eta: 0:04:23  Lr: 0.030000  Loss: -1.7183  Acc@1: 87.5000 (87.6173)  Acc@5: 100.0000 (98.5134)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2460/3125]  eta: 0:04:19  Lr: 0.030000  Loss: -1.3603  Acc@1: 87.5000 (87.6117)  Acc@5: 100.0000 (98.5169)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2470/3125]  eta: 0:04:15  Lr: 0.030000  Loss: -1.6653  Acc@1: 87.5000 (87.6088)  Acc@5: 100.0000 (98.5153)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2480/3125]  eta: 0:04:12  Lr: 0.030000  Loss: -1.6326  Acc@1: 87.5000 (87.6234)  Acc@5: 100.0000 (98.5213)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2490/3125]  eta: 0:04:08  Lr: 0.030000  Loss: -1.3183  Acc@1: 87.5000 (87.6305)  Acc@5: 100.0000 (98.5247)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2500/3125]  eta: 0:04:04  Lr: 0.030000  Loss: -1.8589  Acc@1: 87.5000 (87.6299)  Acc@5: 100.0000 (98.5306)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2510/3125]  eta: 0:04:00  Lr: 0.030000  Loss: -1.9201  Acc@1: 93.7500 (87.6469)  Acc@5: 100.0000 (98.5265)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:56  Lr: 0.030000  Loss: -1.0622  Acc@1: 87.5000 (87.6537)  Acc@5: 100.0000 (98.5274)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:52  Lr: 0.030000  Loss: -1.5729  Acc@1: 87.5000 (87.6482)  Acc@5: 100.0000 (98.5332)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:48  Lr: 0.030000  Loss: -1.6763  Acc@1: 87.5000 (87.6500)  Acc@5: 100.0000 (98.5365)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:44  Lr: 0.030000  Loss: -0.8304  Acc@1: 87.5000 (87.6372)  Acc@5: 100.0000 (98.5373)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:40  Lr: 0.030000  Loss: -1.6239  Acc@1: 87.5000 (87.6269)  Acc@5: 100.0000 (98.5357)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:36  Lr: 0.030000  Loss: -1.2459  Acc@1: 87.5000 (87.6313)  Acc@5: 100.0000 (98.5390)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:32  Lr: 0.030000  Loss: -1.6317  Acc@1: 87.5000 (87.6477)  Acc@5: 100.0000 (98.5447)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:29  Lr: 0.030000  Loss: -1.3091  Acc@1: 93.7500 (87.6544)  Acc@5: 100.0000 (98.5479)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:25  Lr: 0.030000  Loss: -1.6502  Acc@1: 93.7500 (87.6682)  Acc@5: 100.0000 (98.5486)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2610/3125]  eta: 0:03:21  Lr: 0.030000  Loss: -1.2243  Acc@1: 93.7500 (87.6819)  Acc@5: 100.0000 (98.5518)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2620/3125]  eta: 0:03:17  Lr: 0.030000  Loss: -1.7956  Acc@1: 93.7500 (87.6860)  Acc@5: 100.0000 (98.5526)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2630/3125]  eta: 0:03:13  Lr: 0.030000  Loss: -1.7097  Acc@1: 93.7500 (87.6924)  Acc@5: 100.0000 (98.5557)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2640/3125]  eta: 0:03:09  Lr: 0.030000  Loss: -1.8251  Acc@1: 87.5000 (87.6870)  Acc@5: 100.0000 (98.5564)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2650/3125]  eta: 0:03:05  Lr: 0.030000  Loss: -1.7585  Acc@1: 87.5000 (87.6957)  Acc@5: 100.0000 (98.5595)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2660/3125]  eta: 0:03:01  Lr: 0.030000  Loss: -1.5182  Acc@1: 87.5000 (87.6973)  Acc@5: 100.0000 (98.5579)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:57  Lr: 0.030000  Loss: -1.3825  Acc@1: 87.5000 (87.6989)  Acc@5: 100.0000 (98.5516)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:53  Lr: 0.030000  Loss: -1.6911  Acc@1: 87.5000 (87.6935)  Acc@5: 100.0000 (98.5500)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:49  Lr: 0.030000  Loss: -1.4496  Acc@1: 87.5000 (87.6928)  Acc@5: 100.0000 (98.5530)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:46  Lr: 0.030000  Loss: -1.5607  Acc@1: 87.5000 (87.7013)  Acc@5: 100.0000 (98.5491)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:42  Lr: 0.030000  Loss: -1.4641  Acc@1: 93.7500 (87.7098)  Acc@5: 100.0000 (98.5499)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:38  Lr: 0.030000  Loss: -1.3764  Acc@1: 87.5000 (87.7113)  Acc@5: 100.0000 (98.5529)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:34  Lr: 0.030000  Loss: -1.6010  Acc@1: 87.5000 (87.7037)  Acc@5: 100.0000 (98.5582)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:30  Lr: 0.030000  Loss: -1.5993  Acc@1: 87.5000 (87.7029)  Acc@5: 100.0000 (98.5566)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:26  Lr: 0.030000  Loss: -1.4481  Acc@1: 87.5000 (87.6954)  Acc@5: 100.0000 (98.5551)  time: 0.3902  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:22  Lr: 0.030000  Loss: -1.4416  Acc@1: 81.2500 (87.6811)  Acc@5: 100.0000 (98.5535)  time: 0.3910  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:18  Lr: 0.030000  Loss: -1.6730  Acc@1: 87.5000 (87.6850)  Acc@5: 100.0000 (98.5542)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2780/3125]  eta: 0:02:14  Lr: 0.030000  Loss: -1.7563  Acc@1: 87.5000 (87.6798)  Acc@5: 100.0000 (98.5572)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2790/3125]  eta: 0:02:10  Lr: 0.030000  Loss: -1.4480  Acc@1: 87.5000 (87.6680)  Acc@5: 100.0000 (98.5556)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2800/3125]  eta: 0:02:06  Lr: 0.030000  Loss: -1.6191  Acc@1: 87.5000 (87.6696)  Acc@5: 100.0000 (98.5563)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2810/3125]  eta: 0:02:03  Lr: 0.030000  Loss: -1.4339  Acc@1: 87.5000 (87.6779)  Acc@5: 100.0000 (98.5570)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:59  Lr: 0.030000  Loss: -1.7054  Acc@1: 87.5000 (87.6817)  Acc@5: 100.0000 (98.5577)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:55  Lr: 0.030000  Loss: -1.6890  Acc@1: 87.5000 (87.6877)  Acc@5: 100.0000 (98.5628)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:51  Lr: 0.030000  Loss: -1.3701  Acc@1: 87.5000 (87.6826)  Acc@5: 100.0000 (98.5590)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:47  Lr: 0.030000  Loss: -1.4520  Acc@1: 81.2500 (87.6754)  Acc@5: 100.0000 (98.5575)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:43  Lr: 0.030000  Loss: -1.4292  Acc@1: 87.5000 (87.6813)  Acc@5: 100.0000 (98.5604)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:39  Lr: 0.030000  Loss: -1.5421  Acc@1: 87.5000 (87.6720)  Acc@5: 100.0000 (98.5589)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:35  Lr: 0.030000  Loss: -0.9111  Acc@1: 81.2500 (87.6605)  Acc@5: 100.0000 (98.5595)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:31  Lr: 0.030000  Loss: -1.8375  Acc@1: 81.2500 (87.6470)  Acc@5: 100.0000 (98.5559)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:27  Lr: 0.030000  Loss: -1.7162  Acc@1: 87.5000 (87.6508)  Acc@5: 100.0000 (98.5522)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:24  Lr: 0.030000  Loss: -1.5850  Acc@1: 87.5000 (87.6481)  Acc@5: 100.0000 (98.5550)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:20  Lr: 0.030000  Loss: -1.6514  Acc@1: 87.5000 (87.6498)  Acc@5: 100.0000 (98.5514)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:16  Lr: 0.030000  Loss: -1.7015  Acc@1: 93.7500 (87.6557)  Acc@5: 100.0000 (98.5542)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:12  Lr: 0.030000  Loss: -1.2193  Acc@1: 93.7500 (87.6573)  Acc@5: 100.0000 (98.5549)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:08  Lr: 0.030000  Loss: -0.5422  Acc@1: 87.5000 (87.6588)  Acc@5: 100.0000 (98.5513)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2960/3125]  eta: 0:01:04  Lr: 0.030000  Loss: -1.7213  Acc@1: 87.5000 (87.6562)  Acc@5: 100.0000 (98.5478)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2970/3125]  eta: 0:01:00  Lr: 0.030000  Loss: -1.4495  Acc@1: 87.5000 (87.6683)  Acc@5: 100.0000 (98.5485)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:56  Lr: 0.030000  Loss: -1.2988  Acc@1: 87.5000 (87.6593)  Acc@5: 100.0000 (98.5470)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:52  Lr: 0.030000  Loss: -1.5096  Acc@1: 87.5000 (87.6651)  Acc@5: 100.0000 (98.5435)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:48  Lr: 0.030000  Loss: -1.7154  Acc@1: 87.5000 (87.6583)  Acc@5: 100.0000 (98.5463)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:44  Lr: 0.030000  Loss: -1.6239  Acc@1: 87.5000 (87.6578)  Acc@5: 100.0000 (98.5470)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:41  Lr: 0.030000  Loss: -1.7689  Acc@1: 87.5000 (87.6696)  Acc@5: 100.0000 (98.5497)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:37  Lr: 0.030000  Loss: -1.8129  Acc@1: 87.5000 (87.6588)  Acc@5: 100.0000 (98.5483)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:33  Lr: 0.030000  Loss: -1.6658  Acc@1: 87.5000 (87.6583)  Acc@5: 100.0000 (98.5490)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:29  Lr: 0.030000  Loss: -1.5815  Acc@1: 87.5000 (87.6639)  Acc@5: 100.0000 (98.5456)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:25  Lr: 0.030000  Loss: -1.4640  Acc@1: 87.5000 (87.6593)  Acc@5: 100.0000 (98.5462)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:21  Lr: 0.030000  Loss: -1.2619  Acc@1: 87.5000 (87.6587)  Acc@5: 100.0000 (98.5449)  time: 0.3885  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:17  Lr: 0.030000  Loss: -1.4900  Acc@1: 87.5000 (87.6481)  Acc@5: 100.0000 (98.5475)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:13  Lr: 0.030000  Loss: -1.1433  Acc@1: 87.5000 (87.6577)  Acc@5: 100.0000 (98.5502)  time: 0.3904  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:09  Lr: 0.030000  Loss: -1.4145  Acc@1: 93.7500 (87.6612)  Acc@5: 100.0000 (98.5509)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: -1.5684  Acc@1: 87.5000 (87.6527)  Acc@5: 100.0000 (98.5555)  time: 0.3891  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: -1.3250  Acc@1: 87.5000 (87.6622)  Acc@5: 100.0000 (98.5562)  time: 0.3901  data: 0.0008  max mem: 2912
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: -1.8519  Acc@1: 87.5000 (87.6500)  Acc@5: 100.0000 (98.5580)  time: 0.3899  data: 0.0007  max mem: 2912
Train: Epoch[5/5] Total time: 0:20:21 (0.3909 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.8519  Acc@1: 87.5000 (87.6500)  Acc@5: 100.0000 (98.5580)
Test: [Task 1]  [   0/1627]  eta: 0:16:39  Loss: 1.0456 (1.0456)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6144  data: 0.3728  max mem: 2912
Test: [Task 1]  [  10/1627]  eta: 0:07:28  Loss: 0.7422 (0.7038)  Acc@1: 75.0000 (78.4091)  Acc@5: 100.0000 (96.5909)  time: 0.2777  data: 0.0342  max mem: 2912
Test: [Task 1]  [  20/1627]  eta: 0:06:58  Loss: 0.7157 (0.7357)  Acc@1: 81.2500 (78.5714)  Acc@5: 93.7500 (95.8333)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [  30/1627]  eta: 0:06:47  Loss: 0.6739 (0.7109)  Acc@1: 81.2500 (79.4355)  Acc@5: 93.7500 (96.1694)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [  40/1627]  eta: 0:06:39  Loss: 0.7064 (0.7315)  Acc@1: 81.2500 (78.6585)  Acc@5: 100.0000 (96.1890)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [  50/1627]  eta: 0:06:33  Loss: 0.7064 (0.7240)  Acc@1: 81.2500 (79.0441)  Acc@5: 100.0000 (96.3235)  time: 0.2415  data: 0.0003  max mem: 2912
Test: [Task 1]  [  60/1627]  eta: 0:06:28  Loss: 0.7055 (0.7385)  Acc@1: 75.0000 (78.8934)  Acc@5: 93.7500 (96.2090)  time: 0.2414  data: 0.0003  max mem: 2912
Test: [Task 1]  [  70/1627]  eta: 0:06:24  Loss: 0.6700 (0.7356)  Acc@1: 81.2500 (78.9613)  Acc@5: 100.0000 (96.3908)  time: 0.2411  data: 0.0002  max mem: 2912
Test: [Task 1]  [  80/1627]  eta: 0:06:21  Loss: 0.5881 (0.7274)  Acc@1: 81.2500 (78.7809)  Acc@5: 100.0000 (96.8364)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [  90/1627]  eta: 0:06:18  Loss: 0.7202 (0.7403)  Acc@1: 75.0000 (78.7088)  Acc@5: 100.0000 (96.6346)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 100/1627]  eta: 0:06:15  Loss: 0.8517 (0.7577)  Acc@1: 75.0000 (78.3416)  Acc@5: 93.7500 (96.4109)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 110/1627]  eta: 0:06:12  Loss: 0.6612 (0.7483)  Acc@1: 75.0000 (78.4910)  Acc@5: 100.0000 (96.6216)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 120/1627]  eta: 0:06:10  Loss: 0.6500 (0.7520)  Acc@1: 81.2500 (78.6157)  Acc@5: 100.0000 (96.5393)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 130/1627]  eta: 0:06:07  Loss: 0.6500 (0.7481)  Acc@1: 81.2500 (78.7691)  Acc@5: 93.7500 (96.5649)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 140/1627]  eta: 0:06:04  Loss: 0.6499 (0.7442)  Acc@1: 75.0000 (78.5018)  Acc@5: 100.0000 (96.6312)  time: 0.2413  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 150/1627]  eta: 0:06:01  Loss: 0.6454 (0.7385)  Acc@1: 75.0000 (78.7666)  Acc@5: 100.0000 (96.6887)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 160/1627]  eta: 0:05:59  Loss: 0.6601 (0.7363)  Acc@1: 81.2500 (78.9208)  Acc@5: 100.0000 (96.6615)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 170/1627]  eta: 0:05:57  Loss: 0.6808 (0.7312)  Acc@1: 81.2500 (78.9474)  Acc@5: 100.0000 (96.7836)  time: 0.2476  data: 0.0006  max mem: 2912
Test: [Task 1]  [ 180/1627]  eta: 0:05:54  Loss: 0.6381 (0.7318)  Acc@1: 81.2500 (78.9710)  Acc@5: 100.0000 (96.8232)  time: 0.2465  data: 0.0006  max mem: 2912
Test: [Task 1]  [ 190/1627]  eta: 0:05:51  Loss: 0.6765 (0.7277)  Acc@1: 81.2500 (79.2212)  Acc@5: 100.0000 (96.7605)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 200/1627]  eta: 0:05:49  Loss: 0.7814 (0.7270)  Acc@1: 81.2500 (79.1356)  Acc@5: 93.7500 (96.7662)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 210/1627]  eta: 0:05:46  Loss: 0.6900 (0.7265)  Acc@1: 75.0000 (79.1469)  Acc@5: 100.0000 (96.7713)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 220/1627]  eta: 0:05:43  Loss: 0.6900 (0.7262)  Acc@1: 75.0000 (79.1572)  Acc@5: 100.0000 (96.8043)  time: 0.2413  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 230/1627]  eta: 0:05:41  Loss: 0.7064 (0.7245)  Acc@1: 81.2500 (79.1937)  Acc@5: 100.0000 (96.8074)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 240/1627]  eta: 0:05:38  Loss: 0.5933 (0.7217)  Acc@1: 81.2500 (79.2531)  Acc@5: 100.0000 (96.8880)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 250/1627]  eta: 0:05:36  Loss: 0.5863 (0.7281)  Acc@1: 81.2500 (79.2580)  Acc@5: 100.0000 (96.7878)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 260/1627]  eta: 0:05:33  Loss: 0.6793 (0.7268)  Acc@1: 81.2500 (79.2385)  Acc@5: 100.0000 (96.7912)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 270/1627]  eta: 0:05:31  Loss: 0.6252 (0.7211)  Acc@1: 81.2500 (79.3358)  Acc@5: 100.0000 (96.8865)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 280/1627]  eta: 0:05:28  Loss: 0.7263 (0.7224)  Acc@1: 81.2500 (79.3372)  Acc@5: 100.0000 (96.7972)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 290/1627]  eta: 0:05:26  Loss: 0.7671 (0.7252)  Acc@1: 81.2500 (79.3814)  Acc@5: 100.0000 (96.8428)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 300/1627]  eta: 0:05:23  Loss: 0.6815 (0.7240)  Acc@1: 81.2500 (79.4850)  Acc@5: 100.0000 (96.8231)  time: 0.2430  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 310/1627]  eta: 0:05:21  Loss: 0.6114 (0.7233)  Acc@1: 81.2500 (79.5418)  Acc@5: 100.0000 (96.8248)  time: 0.2428  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 320/1627]  eta: 0:05:18  Loss: 0.5683 (0.7183)  Acc@1: 81.2500 (79.6534)  Acc@5: 100.0000 (96.8847)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 330/1627]  eta: 0:05:16  Loss: 0.5054 (0.7190)  Acc@1: 81.2500 (79.5884)  Acc@5: 100.0000 (96.8656)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 340/1627]  eta: 0:05:13  Loss: 0.6130 (0.7227)  Acc@1: 75.0000 (79.5455)  Acc@5: 100.0000 (96.8842)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 350/1627]  eta: 0:05:11  Loss: 0.6130 (0.7221)  Acc@1: 81.2500 (79.5584)  Acc@5: 100.0000 (96.8839)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 360/1627]  eta: 0:05:08  Loss: 0.6382 (0.7222)  Acc@1: 81.2500 (79.5880)  Acc@5: 100.0000 (96.8663)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 370/1627]  eta: 0:05:06  Loss: 0.6023 (0.7216)  Acc@1: 81.2500 (79.7001)  Acc@5: 100.0000 (96.8666)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 380/1627]  eta: 0:05:03  Loss: 0.6167 (0.7216)  Acc@1: 87.5000 (79.7080)  Acc@5: 100.0000 (96.8668)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 390/1627]  eta: 0:05:01  Loss: 0.6696 (0.7217)  Acc@1: 75.0000 (79.6196)  Acc@5: 100.0000 (96.8830)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 400/1627]  eta: 0:04:58  Loss: 0.5269 (0.7203)  Acc@1: 75.0000 (79.6135)  Acc@5: 100.0000 (96.9296)  time: 0.2433  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 410/1627]  eta: 0:04:56  Loss: 0.7033 (0.7244)  Acc@1: 81.2500 (79.5316)  Acc@5: 100.0000 (96.8826)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 420/1627]  eta: 0:04:54  Loss: 0.6741 (0.7231)  Acc@1: 81.2500 (79.5873)  Acc@5: 100.0000 (96.8973)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 430/1627]  eta: 0:04:51  Loss: 0.6158 (0.7226)  Acc@1: 75.0000 (79.5389)  Acc@5: 100.0000 (96.9258)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 440/1627]  eta: 0:04:49  Loss: 0.6368 (0.7215)  Acc@1: 75.0000 (79.5351)  Acc@5: 100.0000 (96.9104)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 450/1627]  eta: 0:04:46  Loss: 0.6482 (0.7225)  Acc@1: 75.0000 (79.4762)  Acc@5: 100.0000 (96.8681)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 460/1627]  eta: 0:04:44  Loss: 0.6590 (0.7207)  Acc@1: 81.2500 (79.5146)  Acc@5: 100.0000 (96.8682)  time: 0.2446  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 470/1627]  eta: 0:04:42  Loss: 0.5701 (0.7183)  Acc@1: 81.2500 (79.5249)  Acc@5: 100.0000 (96.8816)  time: 0.2479  data: 0.0005  max mem: 2912
Test: [Task 1]  [ 480/1627]  eta: 0:04:39  Loss: 0.6143 (0.7191)  Acc@1: 81.2500 (79.5478)  Acc@5: 100.0000 (96.8685)  time: 0.2504  data: 0.0005  max mem: 2912
Test: [Task 1]  [ 490/1627]  eta: 0:04:37  Loss: 0.7268 (0.7213)  Acc@1: 75.0000 (79.5061)  Acc@5: 93.7500 (96.8432)  time: 0.2463  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 500/1627]  eta: 0:04:34  Loss: 0.7310 (0.7227)  Acc@1: 75.0000 (79.4785)  Acc@5: 93.7500 (96.8438)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 510/1627]  eta: 0:04:32  Loss: 0.7777 (0.7263)  Acc@1: 81.2500 (79.5254)  Acc@5: 93.7500 (96.8077)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 520/1627]  eta: 0:04:29  Loss: 0.7693 (0.7333)  Acc@1: 81.2500 (79.5106)  Acc@5: 93.7500 (96.7131)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 530/1627]  eta: 0:04:27  Loss: 0.7356 (0.7319)  Acc@1: 75.0000 (79.4962)  Acc@5: 100.0000 (96.7514)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 540/1627]  eta: 0:04:25  Loss: 0.6279 (0.7309)  Acc@1: 81.2500 (79.5055)  Acc@5: 100.0000 (96.7652)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 550/1627]  eta: 0:04:22  Loss: 0.6602 (0.7321)  Acc@1: 81.2500 (79.4578)  Acc@5: 100.0000 (96.7899)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 560/1627]  eta: 0:04:20  Loss: 0.7713 (0.7341)  Acc@1: 75.0000 (79.3895)  Acc@5: 100.0000 (96.7914)  time: 0.2446  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 570/1627]  eta: 0:04:17  Loss: 0.7713 (0.7328)  Acc@1: 81.2500 (79.4658)  Acc@5: 93.7500 (96.7929)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 580/1627]  eta: 0:04:15  Loss: 0.4636 (0.7326)  Acc@1: 81.2500 (79.4535)  Acc@5: 100.0000 (96.8266)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 590/1627]  eta: 0:04:12  Loss: 0.5803 (0.7319)  Acc@1: 81.2500 (79.4839)  Acc@5: 100.0000 (96.8380)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 600/1627]  eta: 0:04:10  Loss: 0.5827 (0.7319)  Acc@1: 81.2500 (79.4509)  Acc@5: 100.0000 (96.8490)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 610/1627]  eta: 0:04:07  Loss: 0.6558 (0.7312)  Acc@1: 81.2500 (79.5213)  Acc@5: 93.7500 (96.8290)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 620/1627]  eta: 0:04:05  Loss: 0.6870 (0.7323)  Acc@1: 81.2500 (79.4686)  Acc@5: 93.7500 (96.7995)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 630/1627]  eta: 0:04:03  Loss: 0.6870 (0.7348)  Acc@1: 75.0000 (79.3780)  Acc@5: 93.7500 (96.7809)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 640/1627]  eta: 0:04:00  Loss: 0.7926 (0.7348)  Acc@1: 75.0000 (79.3584)  Acc@5: 100.0000 (96.7824)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 650/1627]  eta: 0:03:58  Loss: 0.6726 (0.7331)  Acc@1: 81.2500 (79.3779)  Acc@5: 100.0000 (96.8126)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 660/1627]  eta: 0:03:55  Loss: 0.6726 (0.7322)  Acc@1: 75.0000 (79.3778)  Acc@5: 100.0000 (96.8135)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 670/1627]  eta: 0:03:53  Loss: 0.7487 (0.7332)  Acc@1: 75.0000 (79.2940)  Acc@5: 100.0000 (96.8238)  time: 0.2445  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 680/1627]  eta: 0:03:50  Loss: 0.7498 (0.7341)  Acc@1: 75.0000 (79.2860)  Acc@5: 100.0000 (96.7970)  time: 0.2458  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 690/1627]  eta: 0:03:48  Loss: 0.7285 (0.7324)  Acc@1: 81.2500 (79.3596)  Acc@5: 93.7500 (96.7710)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 700/1627]  eta: 0:03:45  Loss: 0.7285 (0.7328)  Acc@1: 81.2500 (79.3688)  Acc@5: 93.7500 (96.7457)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 710/1627]  eta: 0:03:43  Loss: 0.6861 (0.7313)  Acc@1: 81.2500 (79.4392)  Acc@5: 100.0000 (96.7563)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 720/1627]  eta: 0:03:41  Loss: 0.5569 (0.7288)  Acc@1: 87.5000 (79.5163)  Acc@5: 100.0000 (96.7840)  time: 0.2434  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 730/1627]  eta: 0:03:38  Loss: 0.5894 (0.7286)  Acc@1: 87.5000 (79.5571)  Acc@5: 100.0000 (96.7938)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 740/1627]  eta: 0:03:36  Loss: 0.7799 (0.7304)  Acc@1: 81.2500 (79.5209)  Acc@5: 100.0000 (96.7780)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 750/1627]  eta: 0:03:33  Loss: 0.7799 (0.7298)  Acc@1: 81.2500 (79.5439)  Acc@5: 100.0000 (96.7876)  time: 0.2435  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 760/1627]  eta: 0:03:31  Loss: 0.7751 (0.7328)  Acc@1: 75.0000 (79.5417)  Acc@5: 100.0000 (96.7641)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 770/1627]  eta: 0:03:28  Loss: 0.5391 (0.7302)  Acc@1: 81.2500 (79.5963)  Acc@5: 100.0000 (96.7899)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 780/1627]  eta: 0:03:26  Loss: 0.4520 (0.7270)  Acc@1: 81.2500 (79.7055)  Acc@5: 100.0000 (96.8230)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 790/1627]  eta: 0:03:23  Loss: 0.4925 (0.7271)  Acc@1: 81.2500 (79.7092)  Acc@5: 100.0000 (96.8157)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 800/1627]  eta: 0:03:21  Loss: 0.6433 (0.7271)  Acc@1: 81.2500 (79.6895)  Acc@5: 100.0000 (96.8165)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 810/1627]  eta: 0:03:19  Loss: 0.6355 (0.7265)  Acc@1: 81.2500 (79.6933)  Acc@5: 100.0000 (96.8249)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 820/1627]  eta: 0:03:16  Loss: 0.5741 (0.7254)  Acc@1: 81.2500 (79.7199)  Acc@5: 100.0000 (96.8103)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 830/1627]  eta: 0:03:14  Loss: 0.6287 (0.7254)  Acc@1: 81.2500 (79.7232)  Acc@5: 100.0000 (96.7960)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 840/1627]  eta: 0:03:11  Loss: 0.6508 (0.7237)  Acc@1: 81.2500 (79.7711)  Acc@5: 100.0000 (96.8193)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 850/1627]  eta: 0:03:09  Loss: 0.6653 (0.7254)  Acc@1: 75.0000 (79.7371)  Acc@5: 100.0000 (96.8126)  time: 0.2451  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 860/1627]  eta: 0:03:06  Loss: 0.6653 (0.7243)  Acc@1: 81.2500 (79.7909)  Acc@5: 100.0000 (96.8278)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 870/1627]  eta: 0:03:04  Loss: 0.5864 (0.7237)  Acc@1: 87.5000 (79.8436)  Acc@5: 100.0000 (96.8212)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 880/1627]  eta: 0:03:02  Loss: 0.7115 (0.7256)  Acc@1: 81.2500 (79.7602)  Acc@5: 100.0000 (96.8147)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 890/1627]  eta: 0:02:59  Loss: 0.8375 (0.7276)  Acc@1: 75.0000 (79.7138)  Acc@5: 100.0000 (96.7943)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 900/1627]  eta: 0:02:57  Loss: 0.6068 (0.7274)  Acc@1: 75.0000 (79.7378)  Acc@5: 100.0000 (96.7814)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 910/1627]  eta: 0:02:54  Loss: 0.5641 (0.7284)  Acc@1: 81.2500 (79.7475)  Acc@5: 100.0000 (96.7618)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 920/1627]  eta: 0:02:52  Loss: 0.6477 (0.7282)  Acc@1: 81.2500 (79.7706)  Acc@5: 100.0000 (96.7630)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 930/1627]  eta: 0:02:49  Loss: 0.7033 (0.7286)  Acc@1: 81.2500 (79.7865)  Acc@5: 100.0000 (96.7508)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 940/1627]  eta: 0:02:47  Loss: 0.6303 (0.7265)  Acc@1: 81.2500 (79.8685)  Acc@5: 100.0000 (96.7654)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 950/1627]  eta: 0:02:44  Loss: 0.6246 (0.7261)  Acc@1: 81.2500 (79.8567)  Acc@5: 100.0000 (96.7797)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 960/1627]  eta: 0:02:42  Loss: 0.6821 (0.7256)  Acc@1: 81.2500 (79.8712)  Acc@5: 100.0000 (96.7872)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 970/1627]  eta: 0:02:40  Loss: 0.6375 (0.7254)  Acc@1: 81.2500 (79.8339)  Acc@5: 100.0000 (96.7945)  time: 0.2434  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 980/1627]  eta: 0:02:37  Loss: 0.7823 (0.7259)  Acc@1: 81.2500 (79.8356)  Acc@5: 100.0000 (96.7699)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 990/1627]  eta: 0:02:35  Loss: 0.8203 (0.7286)  Acc@1: 81.2500 (79.8184)  Acc@5: 93.7500 (96.7646)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [1000/1627]  eta: 0:02:32  Loss: 0.7962 (0.7282)  Acc@1: 81.2500 (79.8264)  Acc@5: 100.0000 (96.7720)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [1010/1627]  eta: 0:02:30  Loss: 0.6035 (0.7276)  Acc@1: 81.2500 (79.8714)  Acc@5: 100.0000 (96.7854)  time: 0.2443  data: 0.0003  max mem: 2912
Test: [Task 1]  [1020/1627]  eta: 0:02:27  Loss: 0.6340 (0.7276)  Acc@1: 81.2500 (79.8421)  Acc@5: 100.0000 (96.7924)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 1]  [1030/1627]  eta: 0:02:25  Loss: 0.6340 (0.7260)  Acc@1: 81.2500 (79.8800)  Acc@5: 100.0000 (96.7992)  time: 0.2433  data: 0.0004  max mem: 2912
Test: [Task 1]  [1040/1627]  eta: 0:02:23  Loss: 0.5578 (0.7248)  Acc@1: 81.2500 (79.9051)  Acc@5: 100.0000 (96.8180)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 1]  [1050/1627]  eta: 0:02:20  Loss: 0.6014 (0.7239)  Acc@1: 81.2500 (79.9417)  Acc@5: 100.0000 (96.8304)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1060/1627]  eta: 0:02:18  Loss: 0.6711 (0.7248)  Acc@1: 81.2500 (79.9187)  Acc@5: 100.0000 (96.8131)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [1070/1627]  eta: 0:02:15  Loss: 0.7411 (0.7258)  Acc@1: 81.2500 (79.9020)  Acc@5: 100.0000 (96.7962)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1080/1627]  eta: 0:02:13  Loss: 0.7411 (0.7261)  Acc@1: 75.0000 (79.8566)  Acc@5: 100.0000 (96.8027)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1090/1627]  eta: 0:02:10  Loss: 0.6932 (0.7256)  Acc@1: 75.0000 (79.8694)  Acc@5: 100.0000 (96.8148)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [1100/1627]  eta: 0:02:08  Loss: 0.6441 (0.7251)  Acc@1: 81.2500 (79.8649)  Acc@5: 100.0000 (96.8211)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [1110/1627]  eta: 0:02:05  Loss: 0.6781 (0.7246)  Acc@1: 81.2500 (79.8549)  Acc@5: 100.0000 (96.8384)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1120/1627]  eta: 0:02:03  Loss: 0.6781 (0.7259)  Acc@1: 81.2500 (79.8283)  Acc@5: 100.0000 (96.8220)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1130/1627]  eta: 0:02:01  Loss: 0.7189 (0.7263)  Acc@1: 75.0000 (79.8022)  Acc@5: 100.0000 (96.8170)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1140/1627]  eta: 0:01:58  Loss: 0.7189 (0.7271)  Acc@1: 75.0000 (79.7546)  Acc@5: 100.0000 (96.8284)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1150/1627]  eta: 0:01:56  Loss: 0.7608 (0.7280)  Acc@1: 81.2500 (79.7459)  Acc@5: 100.0000 (96.8126)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1160/1627]  eta: 0:01:53  Loss: 0.6858 (0.7278)  Acc@1: 81.2500 (79.7642)  Acc@5: 100.0000 (96.8131)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [1170/1627]  eta: 0:01:51  Loss: 0.5010 (0.7268)  Acc@1: 81.2500 (79.7822)  Acc@5: 100.0000 (96.8243)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1180/1627]  eta: 0:01:48  Loss: 0.5501 (0.7272)  Acc@1: 81.2500 (79.7894)  Acc@5: 100.0000 (96.8406)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [1190/1627]  eta: 0:01:46  Loss: 0.7158 (0.7270)  Acc@1: 81.2500 (79.7806)  Acc@5: 100.0000 (96.8409)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 1]  [1200/1627]  eta: 0:01:43  Loss: 0.6355 (0.7269)  Acc@1: 81.2500 (79.7721)  Acc@5: 100.0000 (96.8256)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 1]  [1210/1627]  eta: 0:01:41  Loss: 0.5797 (0.7278)  Acc@1: 81.2500 (79.7327)  Acc@5: 93.7500 (96.8002)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 1]  [1220/1627]  eta: 0:01:39  Loss: 0.5797 (0.7270)  Acc@1: 81.2500 (79.7656)  Acc@5: 100.0000 (96.8213)  time: 0.2443  data: 0.0003  max mem: 2912
Test: [Task 1]  [1230/1627]  eta: 0:01:36  Loss: 0.6141 (0.7277)  Acc@1: 81.2500 (79.7472)  Acc@5: 100.0000 (96.8065)  time: 0.2443  data: 0.0003  max mem: 2912
Test: [Task 1]  [1240/1627]  eta: 0:01:34  Loss: 0.6972 (0.7271)  Acc@1: 81.2500 (79.7542)  Acc@5: 100.0000 (96.8171)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1250/1627]  eta: 0:01:31  Loss: 0.7115 (0.7271)  Acc@1: 81.2500 (79.8012)  Acc@5: 100.0000 (96.8026)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1260/1627]  eta: 0:01:29  Loss: 0.6421 (0.7270)  Acc@1: 81.2500 (79.8275)  Acc@5: 100.0000 (96.7932)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1270/1627]  eta: 0:01:26  Loss: 0.6421 (0.7274)  Acc@1: 81.2500 (79.8092)  Acc@5: 100.0000 (96.7840)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [1280/1627]  eta: 0:01:24  Loss: 0.6654 (0.7260)  Acc@1: 87.5000 (79.8497)  Acc@5: 100.0000 (96.7994)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 1]  [1290/1627]  eta: 0:01:22  Loss: 0.6573 (0.7256)  Acc@1: 81.2500 (79.8606)  Acc@5: 100.0000 (96.8000)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1300/1627]  eta: 0:01:19  Loss: 0.6310 (0.7252)  Acc@1: 81.2500 (79.8953)  Acc@5: 100.0000 (96.8101)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [1310/1627]  eta: 0:01:17  Loss: 0.5659 (0.7244)  Acc@1: 87.5000 (79.9199)  Acc@5: 100.0000 (96.8154)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1320/1627]  eta: 0:01:14  Loss: 0.5303 (0.7246)  Acc@1: 87.5000 (79.9063)  Acc@5: 100.0000 (96.8159)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1330/1627]  eta: 0:01:12  Loss: 0.5212 (0.7238)  Acc@1: 87.5000 (79.9352)  Acc@5: 100.0000 (96.8257)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [1340/1627]  eta: 0:01:09  Loss: 0.6344 (0.7245)  Acc@1: 81.2500 (79.9170)  Acc@5: 100.0000 (96.8214)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [1350/1627]  eta: 0:01:07  Loss: 0.6778 (0.7239)  Acc@1: 81.2500 (79.9454)  Acc@5: 100.0000 (96.8218)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 1]  [1360/1627]  eta: 0:01:05  Loss: 0.6583 (0.7241)  Acc@1: 81.2500 (79.9137)  Acc@5: 100.0000 (96.8406)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 1]  [1370/1627]  eta: 0:01:02  Loss: 0.6583 (0.7233)  Acc@1: 81.2500 (79.9325)  Acc@5: 100.0000 (96.8499)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [1380/1627]  eta: 0:01:00  Loss: 0.5972 (0.7229)  Acc@1: 81.2500 (79.9421)  Acc@5: 100.0000 (96.8546)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 1]  [1390/1627]  eta: 0:00:57  Loss: 0.7890 (0.7231)  Acc@1: 75.0000 (79.9335)  Acc@5: 100.0000 (96.8593)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [1400/1627]  eta: 0:00:55  Loss: 0.8399 (0.7232)  Acc@1: 75.0000 (79.9161)  Acc@5: 100.0000 (96.8415)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [1410/1627]  eta: 0:00:52  Loss: 0.6124 (0.7227)  Acc@1: 81.2500 (79.9389)  Acc@5: 100.0000 (96.8462)  time: 0.2447  data: 0.0003  max mem: 2912
Test: [Task 1]  [1420/1627]  eta: 0:00:50  Loss: 0.6124 (0.7224)  Acc@1: 81.2500 (79.9613)  Acc@5: 100.0000 (96.8464)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [1430/1627]  eta: 0:00:47  Loss: 0.8069 (0.7244)  Acc@1: 81.2500 (79.9441)  Acc@5: 93.7500 (96.8204)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [1440/1627]  eta: 0:00:45  Loss: 0.9110 (0.7252)  Acc@1: 81.2500 (79.9141)  Acc@5: 93.7500 (96.8034)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 1]  [1450/1627]  eta: 0:00:43  Loss: 0.8279 (0.7263)  Acc@1: 81.2500 (79.8889)  Acc@5: 93.7500 (96.7867)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 1]  [1460/1627]  eta: 0:00:40  Loss: 0.7021 (0.7257)  Acc@1: 81.2500 (79.9281)  Acc@5: 100.0000 (96.8001)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [1470/1627]  eta: 0:00:38  Loss: 0.5983 (0.7260)  Acc@1: 81.2500 (79.9201)  Acc@5: 100.0000 (96.7964)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [1480/1627]  eta: 0:00:35  Loss: 0.6519 (0.7265)  Acc@1: 81.2500 (79.8996)  Acc@5: 100.0000 (96.8011)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [1490/1627]  eta: 0:00:33  Loss: 0.6519 (0.7271)  Acc@1: 81.2500 (79.8960)  Acc@5: 100.0000 (96.7975)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [1500/1627]  eta: 0:00:30  Loss: 0.6680 (0.7274)  Acc@1: 81.2500 (79.8718)  Acc@5: 100.0000 (96.8021)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 1]  [1510/1627]  eta: 0:00:28  Loss: 0.6635 (0.7279)  Acc@1: 75.0000 (79.8602)  Acc@5: 100.0000 (96.7985)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [1520/1627]  eta: 0:00:26  Loss: 0.5599 (0.7268)  Acc@1: 81.2500 (79.8981)  Acc@5: 100.0000 (96.8072)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1530/1627]  eta: 0:00:23  Loss: 0.5964 (0.7269)  Acc@1: 81.2500 (79.8947)  Acc@5: 100.0000 (96.8076)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1540/1627]  eta: 0:00:21  Loss: 0.6017 (0.7256)  Acc@1: 87.5000 (79.9481)  Acc@5: 100.0000 (96.8243)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1550/1627]  eta: 0:00:18  Loss: 0.5761 (0.7256)  Acc@1: 87.5000 (79.9404)  Acc@5: 100.0000 (96.8367)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 1]  [1560/1627]  eta: 0:00:16  Loss: 0.5559 (0.7250)  Acc@1: 81.2500 (79.9528)  Acc@5: 100.0000 (96.8370)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1570/1627]  eta: 0:00:13  Loss: 0.5484 (0.7249)  Acc@1: 81.2500 (79.9570)  Acc@5: 100.0000 (96.8412)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1580/1627]  eta: 0:00:11  Loss: 0.7119 (0.7245)  Acc@1: 81.2500 (79.9731)  Acc@5: 100.0000 (96.8414)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [1590/1627]  eta: 0:00:09  Loss: 0.7119 (0.7243)  Acc@1: 81.2500 (79.9615)  Acc@5: 100.0000 (96.8455)  time: 0.2446  data: 0.0003  max mem: 2912
Test: [Task 1]  [1600/1627]  eta: 0:00:06  Loss: 0.7402 (0.7251)  Acc@1: 75.0000 (79.9227)  Acc@5: 93.7500 (96.8301)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 1]  [1610/1627]  eta: 0:00:04  Loss: 0.6071 (0.7243)  Acc@1: 75.0000 (79.9542)  Acc@5: 100.0000 (96.8343)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.6071 (0.7239)  Acc@1: 81.2500 (79.9584)  Acc@5: 100.0000 (96.8499)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.6809 (0.7237)  Acc@1: 81.2500 (79.9746)  Acc@5: 100.0000 (96.8500)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1] Total time: 0:06:36 (0.2436 s / it)
* Acc@1 79.975 Acc@5 96.850 loss 0.724
Test: [Task 2]  [  0/625]  eta: 0:05:52  Loss: 0.1402 (0.1402)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5642  data: 0.3209  max mem: 2912
Test: [Task 2]  [ 10/625]  eta: 0:02:48  Loss: 0.0683 (0.0950)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (100.0000)  time: 0.2734  data: 0.0295  max mem: 2912
Test: [Task 2]  [ 20/625]  eta: 0:02:36  Loss: 0.0683 (0.1337)  Acc@1: 100.0000 (95.8333)  Acc@5: 100.0000 (100.0000)  time: 0.2440  data: 0.0007  max mem: 2912
Test: [Task 2]  [ 30/625]  eta: 0:02:31  Loss: 0.1543 (0.1673)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (99.7984)  time: 0.2435  data: 0.0007  max mem: 2912
Test: [Task 2]  [ 40/625]  eta: 0:02:26  Loss: 0.1790 (0.1796)  Acc@1: 93.7500 (94.0549)  Acc@5: 100.0000 (99.8476)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 50/625]  eta: 0:02:23  Loss: 0.1485 (0.1817)  Acc@1: 93.7500 (93.9951)  Acc@5: 100.0000 (99.8775)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 60/625]  eta: 0:02:20  Loss: 0.1326 (0.1800)  Acc@1: 93.7500 (94.2623)  Acc@5: 100.0000 (99.7951)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 70/625]  eta: 0:02:17  Loss: 0.1221 (0.1719)  Acc@1: 93.7500 (94.6303)  Acc@5: 100.0000 (99.8239)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 80/625]  eta: 0:02:14  Loss: 0.1221 (0.1683)  Acc@1: 93.7500 (94.8302)  Acc@5: 100.0000 (99.8457)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 90/625]  eta: 0:02:11  Loss: 0.1118 (0.1618)  Acc@1: 93.7500 (94.9176)  Acc@5: 100.0000 (99.8626)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 2]  [100/625]  eta: 0:02:09  Loss: 0.0946 (0.1579)  Acc@1: 93.7500 (95.1733)  Acc@5: 100.0000 (99.8762)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 2]  [110/625]  eta: 0:02:06  Loss: 0.0709 (0.1608)  Acc@1: 100.0000 (95.2140)  Acc@5: 100.0000 (99.8311)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 2]  [120/625]  eta: 0:02:04  Loss: 0.1186 (0.1627)  Acc@1: 93.7500 (95.1446)  Acc@5: 100.0000 (99.7934)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 2]  [130/625]  eta: 0:02:01  Loss: 0.1429 (0.1643)  Acc@1: 93.7500 (94.9905)  Acc@5: 100.0000 (99.8092)  time: 0.2446  data: 0.0003  max mem: 2912
Test: [Task 2]  [140/625]  eta: 0:01:59  Loss: 0.1383 (0.1704)  Acc@1: 93.7500 (94.8582)  Acc@5: 100.0000 (99.7340)  time: 0.2454  data: 0.0003  max mem: 2912
Test: [Task 2]  [150/625]  eta: 0:01:56  Loss: 0.1857 (0.1752)  Acc@1: 93.7500 (94.6606)  Acc@5: 100.0000 (99.6689)  time: 0.2443  data: 0.0003  max mem: 2912
Test: [Task 2]  [160/625]  eta: 0:01:54  Loss: 0.1949 (0.1791)  Acc@1: 93.7500 (94.6429)  Acc@5: 100.0000 (99.6118)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 2]  [170/625]  eta: 0:01:51  Loss: 0.1176 (0.1755)  Acc@1: 100.0000 (94.8830)  Acc@5: 100.0000 (99.5980)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 2]  [180/625]  eta: 0:01:49  Loss: 0.0956 (0.1745)  Acc@1: 100.0000 (94.9240)  Acc@5: 100.0000 (99.6202)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 2]  [190/625]  eta: 0:01:46  Loss: 0.1128 (0.1759)  Acc@1: 93.7500 (94.8298)  Acc@5: 100.0000 (99.5746)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [200/625]  eta: 0:01:44  Loss: 0.1333 (0.1747)  Acc@1: 93.7500 (94.8383)  Acc@5: 100.0000 (99.5958)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [210/625]  eta: 0:01:41  Loss: 0.1333 (0.1750)  Acc@1: 93.7500 (94.8460)  Acc@5: 100.0000 (99.6149)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 2]  [220/625]  eta: 0:01:39  Loss: 0.0886 (0.1740)  Acc@1: 100.0000 (94.9095)  Acc@5: 100.0000 (99.6041)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 2]  [230/625]  eta: 0:01:36  Loss: 0.0768 (0.1723)  Acc@1: 93.7500 (94.9675)  Acc@5: 100.0000 (99.6212)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [240/625]  eta: 0:01:34  Loss: 0.1793 (0.1743)  Acc@1: 93.7500 (94.8392)  Acc@5: 100.0000 (99.6369)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 2]  [250/625]  eta: 0:01:31  Loss: 0.1827 (0.1762)  Acc@1: 93.7500 (94.7460)  Acc@5: 100.0000 (99.6265)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 2]  [260/625]  eta: 0:01:29  Loss: 0.1391 (0.1743)  Acc@1: 93.7500 (94.7557)  Acc@5: 100.0000 (99.6408)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 2]  [270/625]  eta: 0:01:26  Loss: 0.1374 (0.1746)  Acc@1: 93.7500 (94.7417)  Acc@5: 100.0000 (99.6541)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 2]  [280/625]  eta: 0:01:24  Loss: 0.1374 (0.1769)  Acc@1: 93.7500 (94.7286)  Acc@5: 100.0000 (99.6219)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 2]  [290/625]  eta: 0:01:21  Loss: 0.1981 (0.1779)  Acc@1: 93.7500 (94.6521)  Acc@5: 100.0000 (99.6349)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 2]  [300/625]  eta: 0:01:19  Loss: 0.1420 (0.1773)  Acc@1: 93.7500 (94.6429)  Acc@5: 100.0000 (99.6262)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 2]  [310/625]  eta: 0:01:16  Loss: 0.1270 (0.1760)  Acc@1: 93.7500 (94.7146)  Acc@5: 100.0000 (99.6182)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 2]  [320/625]  eta: 0:01:14  Loss: 0.0368 (0.1711)  Acc@1: 100.0000 (94.8793)  Acc@5: 100.0000 (99.6301)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 2]  [330/625]  eta: 0:01:11  Loss: 0.0274 (0.1676)  Acc@1: 100.0000 (94.9962)  Acc@5: 100.0000 (99.6412)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 2]  [340/625]  eta: 0:01:09  Loss: 0.0159 (0.1629)  Acc@1: 100.0000 (95.1430)  Acc@5: 100.0000 (99.6518)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 2]  [350/625]  eta: 0:01:07  Loss: 0.0102 (0.1607)  Acc@1: 100.0000 (95.1923)  Acc@5: 100.0000 (99.6617)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 2]  [360/625]  eta: 0:01:04  Loss: 0.0504 (0.1595)  Acc@1: 100.0000 (95.2043)  Acc@5: 100.0000 (99.6711)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 2]  [370/625]  eta: 0:01:02  Loss: 0.0683 (0.1576)  Acc@1: 100.0000 (95.2662)  Acc@5: 100.0000 (99.6799)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [380/625]  eta: 0:00:59  Loss: 0.1863 (0.1613)  Acc@1: 93.7500 (95.1772)  Acc@5: 100.0000 (99.6555)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 2]  [390/625]  eta: 0:00:57  Loss: 0.1203 (0.1592)  Acc@1: 93.7500 (95.2366)  Acc@5: 100.0000 (99.6643)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 2]  [400/625]  eta: 0:00:54  Loss: 0.0209 (0.1563)  Acc@1: 100.0000 (95.3398)  Acc@5: 100.0000 (99.6727)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 2]  [410/625]  eta: 0:00:52  Loss: 0.0073 (0.1538)  Acc@1: 100.0000 (95.4227)  Acc@5: 100.0000 (99.6807)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 2]  [420/625]  eta: 0:00:49  Loss: 0.0194 (0.1517)  Acc@1: 100.0000 (95.5018)  Acc@5: 100.0000 (99.6882)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 2]  [430/625]  eta: 0:00:47  Loss: 0.0390 (0.1502)  Acc@1: 100.0000 (95.5626)  Acc@5: 100.0000 (99.6955)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 2]  [440/625]  eta: 0:00:45  Loss: 0.0251 (0.1472)  Acc@1: 100.0000 (95.6633)  Acc@5: 100.0000 (99.7024)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 2]  [450/625]  eta: 0:00:42  Loss: 0.0066 (0.1445)  Acc@1: 100.0000 (95.7456)  Acc@5: 100.0000 (99.7090)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 2]  [460/625]  eta: 0:00:40  Loss: 0.0088 (0.1418)  Acc@1: 100.0000 (95.8243)  Acc@5: 100.0000 (99.7153)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 2]  [470/625]  eta: 0:00:37  Loss: 0.0183 (0.1394)  Acc@1: 100.0000 (95.9130)  Acc@5: 100.0000 (99.7213)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 2]  [480/625]  eta: 0:00:35  Loss: 0.0320 (0.1380)  Acc@1: 100.0000 (95.9589)  Acc@5: 100.0000 (99.7271)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 2]  [490/625]  eta: 0:00:32  Loss: 0.0244 (0.1364)  Acc@1: 100.0000 (96.0031)  Acc@5: 100.0000 (99.7327)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 2]  [500/625]  eta: 0:00:30  Loss: 0.0225 (0.1343)  Acc@1: 100.0000 (96.0704)  Acc@5: 100.0000 (99.7380)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 2]  [510/625]  eta: 0:00:28  Loss: 0.0275 (0.1360)  Acc@1: 100.0000 (96.0250)  Acc@5: 100.0000 (99.7432)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 2]  [520/625]  eta: 0:00:25  Loss: 0.0337 (0.1346)  Acc@1: 100.0000 (96.0653)  Acc@5: 100.0000 (99.7481)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 2]  [530/625]  eta: 0:00:23  Loss: 0.0214 (0.1332)  Acc@1: 100.0000 (96.1040)  Acc@5: 100.0000 (99.7528)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [540/625]  eta: 0:00:20  Loss: 0.0214 (0.1319)  Acc@1: 100.0000 (96.1414)  Acc@5: 100.0000 (99.7574)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 2]  [550/625]  eta: 0:00:18  Loss: 0.0080 (0.1296)  Acc@1: 100.0000 (96.2114)  Acc@5: 100.0000 (99.7618)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 2]  [560/625]  eta: 0:00:15  Loss: 0.0029 (0.1273)  Acc@1: 100.0000 (96.2790)  Acc@5: 100.0000 (99.7660)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 2]  [570/625]  eta: 0:00:13  Loss: 0.0046 (0.1261)  Acc@1: 100.0000 (96.3113)  Acc@5: 100.0000 (99.7701)  time: 0.2442  data: 0.0004  max mem: 2912
Test: [Task 2]  [580/625]  eta: 0:00:10  Loss: 0.0119 (0.1244)  Acc@1: 100.0000 (96.3640)  Acc@5: 100.0000 (99.7741)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 2]  [590/625]  eta: 0:00:08  Loss: 0.0114 (0.1229)  Acc@1: 100.0000 (96.4044)  Acc@5: 100.0000 (99.7779)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [600/625]  eta: 0:00:06  Loss: 0.0229 (0.1223)  Acc@1: 100.0000 (96.4122)  Acc@5: 100.0000 (99.7816)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.1154 (0.1231)  Acc@1: 93.7500 (96.3891)  Acc@5: 100.0000 (99.7852)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.1154 (0.1235)  Acc@1: 93.7500 (96.3366)  Acc@5: 100.0000 (99.7886)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.0852 (0.1231)  Acc@1: 93.7500 (96.3500)  Acc@5: 100.0000 (99.7900)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 2] Total time: 0:02:32 (0.2437 s / it)
* Acc@1 96.350 Acc@5 99.790 loss 0.123
Test: [Task 3]  [  0/625]  eta: 0:05:52  Loss: 0.1230 (0.1230)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5637  data: 0.3211  max mem: 2912
Test: [Task 3]  [ 10/625]  eta: 0:02:48  Loss: 0.1136 (0.1100)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (99.4318)  time: 0.2732  data: 0.0295  max mem: 2912
Test: [Task 3]  [ 20/625]  eta: 0:02:36  Loss: 0.0848 (0.1293)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (99.7024)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 30/625]  eta: 0:02:30  Loss: 0.0790 (0.1280)  Acc@1: 100.0000 (97.5806)  Acc@5: 100.0000 (99.7984)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 40/625]  eta: 0:02:26  Loss: 0.0275 (0.1045)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (99.8476)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 50/625]  eta: 0:02:23  Loss: 0.0317 (0.1006)  Acc@1: 100.0000 (98.0392)  Acc@5: 100.0000 (99.7549)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 60/625]  eta: 0:02:20  Loss: 0.0654 (0.0996)  Acc@1: 100.0000 (97.9508)  Acc@5: 100.0000 (99.7951)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 70/625]  eta: 0:02:17  Loss: 0.0371 (0.0944)  Acc@1: 100.0000 (98.0634)  Acc@5: 100.0000 (99.7359)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 80/625]  eta: 0:02:14  Loss: 0.0424 (0.1009)  Acc@1: 100.0000 (97.7623)  Acc@5: 100.0000 (99.6914)  time: 0.2417  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 90/625]  eta: 0:02:11  Loss: 0.0558 (0.0989)  Acc@1: 100.0000 (97.8022)  Acc@5: 100.0000 (99.6566)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 3]  [100/625]  eta: 0:02:09  Loss: 0.0343 (0.0960)  Acc@1: 100.0000 (97.8960)  Acc@5: 100.0000 (99.6906)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 3]  [110/625]  eta: 0:02:06  Loss: 0.0322 (0.0918)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (99.7185)  time: 0.2430  data: 0.0004  max mem: 2912
Test: [Task 3]  [120/625]  eta: 0:02:03  Loss: 0.0213 (0.0915)  Acc@1: 100.0000 (97.9339)  Acc@5: 100.0000 (99.6901)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 3]  [130/625]  eta: 0:02:01  Loss: 0.0468 (0.0938)  Acc@1: 100.0000 (97.8531)  Acc@5: 100.0000 (99.7137)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 3]  [140/625]  eta: 0:01:58  Loss: 0.0652 (0.0973)  Acc@1: 100.0000 (97.7837)  Acc@5: 100.0000 (99.6454)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [150/625]  eta: 0:01:56  Loss: 0.0914 (0.1102)  Acc@1: 100.0000 (97.7235)  Acc@5: 100.0000 (99.6275)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 3]  [160/625]  eta: 0:01:53  Loss: 0.0916 (0.1118)  Acc@1: 100.0000 (97.7484)  Acc@5: 100.0000 (99.5730)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 3]  [170/625]  eta: 0:01:51  Loss: 0.0713 (0.1117)  Acc@1: 100.0000 (97.6974)  Acc@5: 100.0000 (99.5980)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 3]  [180/625]  eta: 0:01:48  Loss: 0.0713 (0.1138)  Acc@1: 100.0000 (97.6519)  Acc@5: 100.0000 (99.5856)  time: 0.2447  data: 0.0003  max mem: 2912
Test: [Task 3]  [190/625]  eta: 0:01:46  Loss: 0.0436 (0.1122)  Acc@1: 100.0000 (97.6440)  Acc@5: 100.0000 (99.6073)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 3]  [200/625]  eta: 0:01:43  Loss: 0.0672 (0.1129)  Acc@1: 100.0000 (97.6368)  Acc@5: 100.0000 (99.5958)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 3]  [210/625]  eta: 0:01:41  Loss: 0.0772 (0.1147)  Acc@1: 100.0000 (97.5415)  Acc@5: 100.0000 (99.5557)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 3]  [220/625]  eta: 0:01:38  Loss: 0.0380 (0.1141)  Acc@1: 100.0000 (97.5113)  Acc@5: 100.0000 (99.5758)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 3]  [230/625]  eta: 0:01:36  Loss: 0.0446 (0.1146)  Acc@1: 100.0000 (97.5379)  Acc@5: 100.0000 (99.5671)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [240/625]  eta: 0:01:34  Loss: 0.0446 (0.1150)  Acc@1: 100.0000 (97.5363)  Acc@5: 100.0000 (99.5591)  time: 0.2447  data: 0.0003  max mem: 2912
Test: [Task 3]  [250/625]  eta: 0:01:31  Loss: 0.0384 (0.1133)  Acc@1: 100.0000 (97.6096)  Acc@5: 100.0000 (99.5767)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 3]  [260/625]  eta: 0:01:29  Loss: 0.0472 (0.1125)  Acc@1: 100.0000 (97.6293)  Acc@5: 100.0000 (99.5690)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [270/625]  eta: 0:01:26  Loss: 0.0654 (0.1117)  Acc@1: 100.0000 (97.6245)  Acc@5: 100.0000 (99.5849)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 3]  [280/625]  eta: 0:01:24  Loss: 0.0682 (0.1119)  Acc@1: 100.0000 (97.6646)  Acc@5: 100.0000 (99.5996)  time: 0.2454  data: 0.0004  max mem: 2912
Test: [Task 3]  [290/625]  eta: 0:01:21  Loss: 0.0857 (0.1119)  Acc@1: 100.0000 (97.6804)  Acc@5: 100.0000 (99.6134)  time: 0.2455  data: 0.0004  max mem: 2912
Test: [Task 3]  [300/625]  eta: 0:01:19  Loss: 0.1065 (0.1145)  Acc@1: 93.7500 (97.5706)  Acc@5: 100.0000 (99.6055)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 3]  [310/625]  eta: 0:01:16  Loss: 0.1178 (0.1170)  Acc@1: 93.7500 (97.5281)  Acc@5: 100.0000 (99.5780)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 3]  [320/625]  eta: 0:01:14  Loss: 0.0464 (0.1164)  Acc@1: 100.0000 (97.5078)  Acc@5: 100.0000 (99.5911)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 3]  [330/625]  eta: 0:01:12  Loss: 0.0762 (0.1165)  Acc@1: 100.0000 (97.5076)  Acc@5: 100.0000 (99.6035)  time: 0.2446  data: 0.0003  max mem: 2912
Test: [Task 3]  [340/625]  eta: 0:01:09  Loss: 0.0447 (0.1150)  Acc@1: 100.0000 (97.5623)  Acc@5: 100.0000 (99.6151)  time: 0.2445  data: 0.0003  max mem: 2912
Test: [Task 3]  [350/625]  eta: 0:01:07  Loss: 0.0426 (0.1149)  Acc@1: 100.0000 (97.5605)  Acc@5: 100.0000 (99.6083)  time: 0.2430  data: 0.0004  max mem: 2912
Test: [Task 3]  [360/625]  eta: 0:01:04  Loss: 0.0472 (0.1159)  Acc@1: 100.0000 (97.4896)  Acc@5: 100.0000 (99.6018)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [370/625]  eta: 0:01:02  Loss: 0.0472 (0.1165)  Acc@1: 93.7500 (97.4225)  Acc@5: 100.0000 (99.6125)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 3]  [380/625]  eta: 0:00:59  Loss: 0.0285 (0.1147)  Acc@1: 100.0000 (97.4738)  Acc@5: 100.0000 (99.6227)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 3]  [390/625]  eta: 0:00:57  Loss: 0.0350 (0.1142)  Acc@1: 100.0000 (97.4904)  Acc@5: 100.0000 (99.6324)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [400/625]  eta: 0:00:54  Loss: 0.0464 (0.1141)  Acc@1: 100.0000 (97.4595)  Acc@5: 100.0000 (99.6415)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 3]  [410/625]  eta: 0:00:52  Loss: 0.0644 (0.1143)  Acc@1: 100.0000 (97.4909)  Acc@5: 100.0000 (99.6350)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 3]  [420/625]  eta: 0:00:50  Loss: 0.0644 (0.1137)  Acc@1: 100.0000 (97.5059)  Acc@5: 100.0000 (99.6437)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 3]  [430/625]  eta: 0:00:47  Loss: 0.0663 (0.1138)  Acc@1: 100.0000 (97.5058)  Acc@5: 100.0000 (99.6375)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 3]  [440/625]  eta: 0:00:45  Loss: 0.0773 (0.1154)  Acc@1: 100.0000 (97.4632)  Acc@5: 100.0000 (99.6315)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 3]  [450/625]  eta: 0:00:42  Loss: 0.0446 (0.1162)  Acc@1: 100.0000 (97.4363)  Acc@5: 100.0000 (99.6120)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [460/625]  eta: 0:00:40  Loss: 0.0376 (0.1155)  Acc@1: 100.0000 (97.4376)  Acc@5: 100.0000 (99.6204)  time: 0.2447  data: 0.0004  max mem: 2912
Test: [Task 3]  [470/625]  eta: 0:00:37  Loss: 0.0657 (0.1159)  Acc@1: 93.7500 (97.3859)  Acc@5: 100.0000 (99.6152)  time: 0.2451  data: 0.0004  max mem: 2912
Test: [Task 3]  [480/625]  eta: 0:00:35  Loss: 0.0565 (0.1153)  Acc@1: 100.0000 (97.4142)  Acc@5: 100.0000 (99.6102)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 3]  [490/625]  eta: 0:00:32  Loss: 0.0726 (0.1160)  Acc@1: 100.0000 (97.3778)  Acc@5: 100.0000 (99.6054)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [500/625]  eta: 0:00:30  Loss: 0.0726 (0.1150)  Acc@1: 93.7500 (97.3927)  Acc@5: 100.0000 (99.6133)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 3]  [510/625]  eta: 0:00:28  Loss: 0.0211 (0.1143)  Acc@1: 100.0000 (97.3948)  Acc@5: 100.0000 (99.6208)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [520/625]  eta: 0:00:25  Loss: 0.0596 (0.1137)  Acc@1: 100.0000 (97.3968)  Acc@5: 100.0000 (99.6281)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [530/625]  eta: 0:00:23  Loss: 0.0601 (0.1134)  Acc@1: 100.0000 (97.3752)  Acc@5: 100.0000 (99.6351)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 3]  [540/625]  eta: 0:00:20  Loss: 0.0708 (0.1132)  Acc@1: 100.0000 (97.3775)  Acc@5: 100.0000 (99.6419)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 3]  [550/625]  eta: 0:00:18  Loss: 0.0707 (0.1130)  Acc@1: 100.0000 (97.3798)  Acc@5: 100.0000 (99.6484)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 3]  [560/625]  eta: 0:00:15  Loss: 0.0346 (0.1126)  Acc@1: 100.0000 (97.4042)  Acc@5: 100.0000 (99.6435)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 3]  [570/625]  eta: 0:00:13  Loss: 0.0336 (0.1121)  Acc@1: 100.0000 (97.4278)  Acc@5: 100.0000 (99.6497)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 3]  [580/625]  eta: 0:00:10  Loss: 0.0850 (0.1129)  Acc@1: 100.0000 (97.3752)  Acc@5: 100.0000 (99.6343)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [590/625]  eta: 0:00:08  Loss: 0.0695 (0.1120)  Acc@1: 100.0000 (97.3985)  Acc@5: 100.0000 (99.6404)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 3]  [600/625]  eta: 0:00:06  Loss: 0.0523 (0.1121)  Acc@1: 100.0000 (97.3586)  Acc@5: 100.0000 (99.6360)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.0843 (0.1122)  Acc@1: 93.7500 (97.3507)  Acc@5: 100.0000 (99.6420)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.0832 (0.1124)  Acc@1: 100.0000 (97.3631)  Acc@5: 100.0000 (99.6477)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.0616 (0.1119)  Acc@1: 100.0000 (97.3800)  Acc@5: 100.0000 (99.6500)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 3] Total time: 0:02:32 (0.2440 s / it)
* Acc@1 97.380 Acc@5 99.650 loss 0.112
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 26032, 5: 26032, 6: 26032, 7: 26032, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 10000, 13: 10000, 14: 10000, 15: 10000, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000, 20: 10000, 21: 10000, 22: 10000, 23: 10000, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}}
[Average accuracy till task3]	Acc@1: 91.2349	Acc@5: 98.7633	Loss: 0.3196	Forgetting: 5.2704	Backward: -5.2704
Train: Epoch[1/5]  [   0/1142]  eta: 0:14:26  Lr: 0.030000  Loss: 2.2355  Acc@1: 18.7500 (18.7500)  Acc@5: 31.2500 (31.2500)  time: 0.7590  data: 0.3418  max mem: 2912
Train: Epoch[1/5]  [  10/1142]  eta: 0:07:59  Lr: 0.030000  Loss: 0.9321  Acc@1: 37.5000 (36.3636)  Acc@5: 75.0000 (67.0455)  time: 0.4237  data: 0.0314  max mem: 2912
Train: Epoch[1/5]  [  20/1142]  eta: 0:07:37  Lr: 0.030000  Loss: -0.5021  Acc@1: 43.7500 (40.7738)  Acc@5: 75.0000 (73.5119)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  30/1142]  eta: 0:07:26  Lr: 0.030000  Loss: -0.8118  Acc@1: 43.7500 (42.7419)  Acc@5: 87.5000 (78.4274)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  40/1142]  eta: 0:07:19  Lr: 0.030000  Loss: -0.3012  Acc@1: 50.0000 (45.8841)  Acc@5: 87.5000 (81.5549)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  50/1142]  eta: 0:07:14  Lr: 0.030000  Loss: -0.6361  Acc@1: 43.7500 (44.6078)  Acc@5: 87.5000 (81.2500)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  60/1142]  eta: 0:07:08  Lr: 0.030000  Loss: -0.7823  Acc@1: 37.5000 (44.6721)  Acc@5: 81.2500 (81.6598)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  70/1142]  eta: 0:07:04  Lr: 0.030000  Loss: -1.0205  Acc@1: 43.7500 (45.5106)  Acc@5: 87.5000 (83.1866)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [  80/1142]  eta: 0:06:59  Lr: 0.030000  Loss: -1.5101  Acc@1: 56.2500 (46.2963)  Acc@5: 93.7500 (83.9506)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  90/1142]  eta: 0:06:54  Lr: 0.030000  Loss: -1.7792  Acc@1: 56.2500 (46.9780)  Acc@5: 87.5000 (84.3407)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 100/1142]  eta: 0:06:50  Lr: 0.030000  Loss: -0.9392  Acc@1: 50.0000 (46.9678)  Acc@5: 87.5000 (84.7772)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 110/1142]  eta: 0:06:46  Lr: 0.030000  Loss: -1.1586  Acc@1: 50.0000 (47.7477)  Acc@5: 93.7500 (85.2477)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 120/1142]  eta: 0:06:41  Lr: 0.030000  Loss: -1.7017  Acc@1: 50.0000 (48.2955)  Acc@5: 87.5000 (85.5372)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 130/1142]  eta: 0:06:37  Lr: 0.030000  Loss: -1.5529  Acc@1: 56.2500 (48.8550)  Acc@5: 87.5000 (85.6870)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 140/1142]  eta: 0:06:33  Lr: 0.030000  Loss: -1.2373  Acc@1: 50.0000 (49.2465)  Acc@5: 87.5000 (86.2145)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 150/1142]  eta: 0:06:29  Lr: 0.030000  Loss: -1.3078  Acc@1: 50.0000 (49.6689)  Acc@5: 93.7500 (86.5066)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 160/1142]  eta: 0:06:25  Lr: 0.030000  Loss: -1.0984  Acc@1: 56.2500 (50.3494)  Acc@5: 93.7500 (86.8012)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 170/1142]  eta: 0:06:21  Lr: 0.030000  Loss: -1.8441  Acc@1: 56.2500 (50.4386)  Acc@5: 93.7500 (87.0249)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 180/1142]  eta: 0:06:17  Lr: 0.030000  Loss: -1.2878  Acc@1: 56.2500 (50.7597)  Acc@5: 87.5000 (87.1547)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 190/1142]  eta: 0:06:13  Lr: 0.030000  Loss: -1.2229  Acc@1: 56.2500 (51.0798)  Acc@5: 87.5000 (87.3691)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 200/1142]  eta: 0:06:09  Lr: 0.030000  Loss: -1.0987  Acc@1: 50.0000 (51.1194)  Acc@5: 87.5000 (87.3134)  time: 0.3907  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 210/1142]  eta: 0:06:05  Lr: 0.030000  Loss: -1.4554  Acc@1: 50.0000 (51.3033)  Acc@5: 87.5000 (87.3815)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 220/1142]  eta: 0:06:01  Lr: 0.030000  Loss: -0.8361  Acc@1: 56.2500 (51.2161)  Acc@5: 87.5000 (87.4717)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 230/1142]  eta: 0:05:57  Lr: 0.030000  Loss: -1.5856  Acc@1: 56.2500 (51.5422)  Acc@5: 87.5000 (87.5000)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 240/1142]  eta: 0:05:53  Lr: 0.030000  Loss: -1.6581  Acc@1: 56.2500 (51.7635)  Acc@5: 87.5000 (87.5000)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 250/1142]  eta: 0:05:49  Lr: 0.030000  Loss: -1.6976  Acc@1: 56.2500 (52.0916)  Acc@5: 87.5000 (87.6743)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 260/1142]  eta: 0:05:45  Lr: 0.030000  Loss: -1.8706  Acc@1: 62.5000 (52.2989)  Acc@5: 87.5000 (87.6437)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 270/1142]  eta: 0:05:42  Lr: 0.030000  Loss: -0.6585  Acc@1: 56.2500 (52.5830)  Acc@5: 87.5000 (87.7768)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 280/1142]  eta: 0:05:38  Lr: 0.030000  Loss: -1.3750  Acc@1: 56.2500 (52.7580)  Acc@5: 93.7500 (87.8781)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 290/1142]  eta: 0:05:34  Lr: 0.030000  Loss: -1.9947  Acc@1: 62.5000 (52.9424)  Acc@5: 93.7500 (87.9296)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 300/1142]  eta: 0:05:30  Lr: 0.030000  Loss: -0.7985  Acc@1: 62.5000 (53.2807)  Acc@5: 87.5000 (87.9776)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 310/1142]  eta: 0:05:26  Lr: 0.030000  Loss: -1.2648  Acc@1: 62.5000 (53.4767)  Acc@5: 87.5000 (88.1029)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 320/1142]  eta: 0:05:22  Lr: 0.030000  Loss: -1.6484  Acc@1: 56.2500 (53.6799)  Acc@5: 87.5000 (88.1620)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 330/1142]  eta: 0:05:18  Lr: 0.030000  Loss: -2.2061  Acc@1: 50.0000 (53.7009)  Acc@5: 93.7500 (88.1986)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 340/1142]  eta: 0:05:14  Lr: 0.030000  Loss: -1.7351  Acc@1: 50.0000 (53.6657)  Acc@5: 93.7500 (88.1782)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 350/1142]  eta: 0:05:10  Lr: 0.030000  Loss: -0.9672  Acc@1: 50.0000 (53.7215)  Acc@5: 93.7500 (88.3013)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 360/1142]  eta: 0:05:06  Lr: 0.030000  Loss: -1.4515  Acc@1: 50.0000 (53.7396)  Acc@5: 93.7500 (88.4522)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 370/1142]  eta: 0:05:02  Lr: 0.030000  Loss: -0.9317  Acc@1: 56.2500 (53.8073)  Acc@5: 93.7500 (88.5108)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 380/1142]  eta: 0:04:58  Lr: 0.030000  Loss: -2.1303  Acc@1: 56.2500 (53.9534)  Acc@5: 87.5000 (88.6483)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 390/1142]  eta: 0:04:55  Lr: 0.030000  Loss: -1.3742  Acc@1: 56.2500 (53.9962)  Acc@5: 93.7500 (88.7148)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 400/1142]  eta: 0:04:51  Lr: 0.030000  Loss: -1.8360  Acc@1: 56.2500 (54.0835)  Acc@5: 93.7500 (88.8248)  time: 0.3929  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 410/1142]  eta: 0:04:47  Lr: 0.030000  Loss: -2.0311  Acc@1: 62.5000 (54.1971)  Acc@5: 93.7500 (88.7926)  time: 0.3930  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 420/1142]  eta: 0:04:43  Lr: 0.030000  Loss: -1.2188  Acc@1: 56.2500 (54.2904)  Acc@5: 87.5000 (88.7916)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 430/1142]  eta: 0:04:39  Lr: 0.030000  Loss: -1.3106  Acc@1: 56.2500 (54.4229)  Acc@5: 87.5000 (88.8631)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 440/1142]  eta: 0:04:35  Lr: 0.030000  Loss: -1.7608  Acc@1: 56.2500 (54.4926)  Acc@5: 87.5000 (88.9172)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 450/1142]  eta: 0:04:31  Lr: 0.030000  Loss: -1.0382  Acc@1: 56.2500 (54.6425)  Acc@5: 87.5000 (88.9135)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 460/1142]  eta: 0:04:27  Lr: 0.030000  Loss: -1.5580  Acc@1: 56.2500 (54.7180)  Acc@5: 93.7500 (89.0184)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 470/1142]  eta: 0:04:23  Lr: 0.030000  Loss: -1.7600  Acc@1: 56.2500 (54.8301)  Acc@5: 93.7500 (89.1189)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 480/1142]  eta: 0:04:19  Lr: 0.030000  Loss: -2.1683  Acc@1: 56.2500 (54.9376)  Acc@5: 93.7500 (89.1762)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 490/1142]  eta: 0:04:15  Lr: 0.030000  Loss: -1.2053  Acc@1: 62.5000 (55.0662)  Acc@5: 93.7500 (89.1930)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 500/1142]  eta: 0:04:11  Lr: 0.030000  Loss: -1.9011  Acc@1: 62.5000 (55.2270)  Acc@5: 87.5000 (89.2590)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 510/1142]  eta: 0:04:07  Lr: 0.030000  Loss: -1.1900  Acc@1: 62.5000 (55.3327)  Acc@5: 87.5000 (89.3102)  time: 0.3920  data: 0.0011  max mem: 2912
Train: Epoch[1/5]  [ 520/1142]  eta: 0:04:03  Lr: 0.030000  Loss: -1.5882  Acc@1: 62.5000 (55.4702)  Acc@5: 87.5000 (89.2994)  time: 0.3920  data: 0.0018  max mem: 2912
Train: Epoch[1/5]  [ 530/1142]  eta: 0:04:00  Lr: 0.030000  Loss: -1.3041  Acc@1: 56.2500 (55.4025)  Acc@5: 87.5000 (89.3008)  time: 0.3918  data: 0.0011  max mem: 2912
Train: Epoch[1/5]  [ 540/1142]  eta: 0:03:56  Lr: 0.030000  Loss: -1.2975  Acc@1: 56.2500 (55.4875)  Acc@5: 87.5000 (89.2907)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 550/1142]  eta: 0:03:52  Lr: 0.030000  Loss: -1.5541  Acc@1: 56.2500 (55.5921)  Acc@5: 87.5000 (89.3149)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 560/1142]  eta: 0:03:48  Lr: 0.030000  Loss: -1.8234  Acc@1: 56.2500 (55.6038)  Acc@5: 93.7500 (89.3939)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 570/1142]  eta: 0:03:44  Lr: 0.030000  Loss: -1.5785  Acc@1: 56.2500 (55.6370)  Acc@5: 87.5000 (89.3827)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 580/1142]  eta: 0:03:40  Lr: 0.030000  Loss: -1.0272  Acc@1: 56.2500 (55.6691)  Acc@5: 87.5000 (89.3825)  time: 0.3928  data: 0.0011  max mem: 2912
Train: Epoch[1/5]  [ 590/1142]  eta: 0:03:36  Lr: 0.030000  Loss: -1.8643  Acc@1: 68.7500 (55.9327)  Acc@5: 87.5000 (89.4141)  time: 0.3926  data: 0.0011  max mem: 2912
Train: Epoch[1/5]  [ 600/1142]  eta: 0:03:32  Lr: 0.030000  Loss: -1.8390  Acc@1: 68.7500 (56.0940)  Acc@5: 87.5000 (89.4343)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 610/1142]  eta: 0:03:28  Lr: 0.030000  Loss: -1.0326  Acc@1: 62.5000 (56.1477)  Acc@5: 87.5000 (89.4333)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 620/1142]  eta: 0:03:24  Lr: 0.030000  Loss: -2.3292  Acc@1: 62.5000 (56.2198)  Acc@5: 87.5000 (89.4827)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 630/1142]  eta: 0:03:20  Lr: 0.030000  Loss: -1.8430  Acc@1: 50.0000 (56.0717)  Acc@5: 93.7500 (89.4810)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 640/1142]  eta: 0:03:16  Lr: 0.030000  Loss: -1.2497  Acc@1: 56.2500 (56.1720)  Acc@5: 87.5000 (89.4988)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 650/1142]  eta: 0:03:12  Lr: 0.030000  Loss: -1.0892  Acc@1: 62.5000 (56.1636)  Acc@5: 93.7500 (89.5545)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 660/1142]  eta: 0:03:08  Lr: 0.030000  Loss: -2.2720  Acc@1: 56.2500 (56.1460)  Acc@5: 93.7500 (89.5518)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 670/1142]  eta: 0:03:05  Lr: 0.030000  Loss: -1.8317  Acc@1: 56.2500 (56.2686)  Acc@5: 93.7500 (89.6237)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 680/1142]  eta: 0:03:01  Lr: 0.030000  Loss: -1.5916  Acc@1: 62.5000 (56.2867)  Acc@5: 93.7500 (89.6384)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 690/1142]  eta: 0:02:57  Lr: 0.030000  Loss: -1.5224  Acc@1: 56.2500 (56.3224)  Acc@5: 87.5000 (89.6708)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 700/1142]  eta: 0:02:53  Lr: 0.030000  Loss: -1.0922  Acc@1: 56.2500 (56.3570)  Acc@5: 93.7500 (89.7111)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 710/1142]  eta: 0:02:49  Lr: 0.030000  Loss: -1.5329  Acc@1: 62.5000 (56.4346)  Acc@5: 93.7500 (89.7328)  time: 0.3908  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 720/1142]  eta: 0:02:45  Lr: 0.030000  Loss: -1.2696  Acc@1: 62.5000 (56.5361)  Acc@5: 87.5000 (89.7451)  time: 0.3908  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 730/1142]  eta: 0:02:41  Lr: 0.030000  Loss: -1.8324  Acc@1: 62.5000 (56.5920)  Acc@5: 87.5000 (89.7743)  time: 0.3906  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 740/1142]  eta: 0:02:37  Lr: 0.030000  Loss: -1.9565  Acc@1: 62.5000 (56.7308)  Acc@5: 93.7500 (89.8532)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 750/1142]  eta: 0:02:33  Lr: 0.030000  Loss: -1.4426  Acc@1: 62.5000 (56.7826)  Acc@5: 93.7500 (89.8802)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 760/1142]  eta: 0:02:29  Lr: 0.030000  Loss: -2.2668  Acc@1: 62.5000 (56.8988)  Acc@5: 93.7500 (89.9310)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 770/1142]  eta: 0:02:25  Lr: 0.030000  Loss: -1.7721  Acc@1: 62.5000 (56.9715)  Acc@5: 93.7500 (90.0130)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 780/1142]  eta: 0:02:21  Lr: 0.030000  Loss: -1.8783  Acc@1: 62.5000 (57.0102)  Acc@5: 93.7500 (90.0528)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 790/1142]  eta: 0:02:17  Lr: 0.030000  Loss: -0.8707  Acc@1: 62.5000 (57.0480)  Acc@5: 87.5000 (90.0205)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 800/1142]  eta: 0:02:14  Lr: 0.030000  Loss: -1.7390  Acc@1: 56.2500 (57.0225)  Acc@5: 93.7500 (90.0359)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 810/1142]  eta: 0:02:10  Lr: 0.030000  Loss: -1.8330  Acc@1: 56.2500 (57.0977)  Acc@5: 93.7500 (90.0663)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 820/1142]  eta: 0:02:06  Lr: 0.030000  Loss: -1.5611  Acc@1: 62.5000 (57.1864)  Acc@5: 93.7500 (90.0731)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 830/1142]  eta: 0:02:02  Lr: 0.030000  Loss: -1.0915  Acc@1: 62.5000 (57.2578)  Acc@5: 93.7500 (90.1098)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 840/1142]  eta: 0:01:58  Lr: 0.030000  Loss: -2.4173  Acc@1: 62.5000 (57.3499)  Acc@5: 93.7500 (90.1754)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 850/1142]  eta: 0:01:54  Lr: 0.030000  Loss: -1.5371  Acc@1: 62.5000 (57.3810)  Acc@5: 93.7500 (90.2174)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 860/1142]  eta: 0:01:50  Lr: 0.030000  Loss: -0.7441  Acc@1: 62.5000 (57.4042)  Acc@5: 93.7500 (90.2294)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 870/1142]  eta: 0:01:46  Lr: 0.030000  Loss: -1.7697  Acc@1: 56.2500 (57.4125)  Acc@5: 87.5000 (90.1765)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 880/1142]  eta: 0:01:42  Lr: 0.030000  Loss: -1.6581  Acc@1: 62.5000 (57.4844)  Acc@5: 93.7500 (90.2455)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 890/1142]  eta: 0:01:38  Lr: 0.030000  Loss: -1.8179  Acc@1: 62.5000 (57.5687)  Acc@5: 93.7500 (90.2427)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 900/1142]  eta: 0:01:34  Lr: 0.030000  Loss: -2.0106  Acc@1: 62.5000 (57.5749)  Acc@5: 87.5000 (90.2261)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 910/1142]  eta: 0:01:30  Lr: 0.030000  Loss: -1.4720  Acc@1: 62.5000 (57.5810)  Acc@5: 87.5000 (90.2580)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 920/1142]  eta: 0:01:26  Lr: 0.030000  Loss: -2.0358  Acc@1: 62.5000 (57.6412)  Acc@5: 93.7500 (90.2891)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 930/1142]  eta: 0:01:23  Lr: 0.030000  Loss: -1.7118  Acc@1: 62.5000 (57.6933)  Acc@5: 93.7500 (90.2994)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 940/1142]  eta: 0:01:19  Lr: 0.030000  Loss: -2.0548  Acc@1: 62.5000 (57.7643)  Acc@5: 93.7500 (90.3294)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 950/1142]  eta: 0:01:15  Lr: 0.030000  Loss: -1.2935  Acc@1: 62.5000 (57.7879)  Acc@5: 93.7500 (90.3523)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:11  Lr: 0.030000  Loss: -1.2998  Acc@1: 62.5000 (57.8369)  Acc@5: 93.7500 (90.3746)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 970/1142]  eta: 0:01:07  Lr: 0.030000  Loss: -1.5682  Acc@1: 68.7500 (57.9364)  Acc@5: 93.7500 (90.4029)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 980/1142]  eta: 0:01:03  Lr: 0.030000  Loss: -1.7150  Acc@1: 68.7500 (58.0212)  Acc@5: 93.7500 (90.4116)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 990/1142]  eta: 0:00:59  Lr: 0.030000  Loss: -2.1354  Acc@1: 62.5000 (58.0474)  Acc@5: 93.7500 (90.4516)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1000/1142]  eta: 0:00:55  Lr: 0.030000  Loss: -1.7155  Acc@1: 68.7500 (58.1419)  Acc@5: 93.7500 (90.4845)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1010/1142]  eta: 0:00:51  Lr: 0.030000  Loss: -2.1544  Acc@1: 62.5000 (58.1788)  Acc@5: 93.7500 (90.5045)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1020/1142]  eta: 0:00:47  Lr: 0.030000  Loss: -1.6779  Acc@1: 62.5000 (58.2395)  Acc@5: 93.7500 (90.5179)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1030/1142]  eta: 0:00:43  Lr: 0.030000  Loss: -1.6210  Acc@1: 62.5000 (58.2444)  Acc@5: 93.7500 (90.5310)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1040/1142]  eta: 0:00:39  Lr: 0.030000  Loss: -1.7774  Acc@1: 56.2500 (58.2793)  Acc@5: 87.5000 (90.5319)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:36  Lr: 0.030000  Loss: -2.3194  Acc@1: 62.5000 (58.3432)  Acc@5: 93.7500 (90.5745)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:32  Lr: 0.030000  Loss: -1.3602  Acc@1: 62.5000 (58.3942)  Acc@5: 93.7500 (90.5455)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:28  Lr: 0.030000  Loss: -1.8042  Acc@1: 62.5000 (58.4559)  Acc@5: 87.5000 (90.5521)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:24  Lr: 0.030000  Loss: -1.8415  Acc@1: 68.7500 (58.5685)  Acc@5: 93.7500 (90.5701)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:20  Lr: 0.030000  Loss: -1.2931  Acc@1: 68.7500 (58.5988)  Acc@5: 93.7500 (90.5763)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:16  Lr: 0.030000  Loss: -2.2484  Acc@1: 68.7500 (58.6796)  Acc@5: 93.7500 (90.6108)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:12  Lr: 0.030000  Loss: -0.7763  Acc@1: 62.5000 (58.6465)  Acc@5: 93.7500 (90.5884)  time: 0.3925  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:08  Lr: 0.030000  Loss: -1.2633  Acc@1: 56.2500 (58.6530)  Acc@5: 93.7500 (90.6111)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: -1.4160  Acc@1: 68.7500 (58.7533)  Acc@5: 93.7500 (90.6057)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -0.9229  Acc@1: 68.7500 (58.7369)  Acc@5: 93.7500 (90.6277)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -2.1576  Acc@1: 66.6667 (58.7408)  Acc@5: 93.7500 (90.6269)  time: 0.3842  data: 0.0004  max mem: 2912
Train: Epoch[1/5] Total time: 0:07:27 (0.3920 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.1576  Acc@1: 66.6667 (58.7408)  Acc@5: 93.7500 (90.6269)
Train: Epoch[2/5]  [   0/1142]  eta: 0:16:54  Lr: 0.030000  Loss: -1.9340  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.8882  data: 0.4957  max mem: 2912
Train: Epoch[2/5]  [  10/1142]  eta: 0:08:15  Lr: 0.030000  Loss: -2.1528  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.3182)  time: 0.4375  data: 0.0454  max mem: 2912
Train: Epoch[2/5]  [  20/1142]  eta: 0:07:47  Lr: 0.030000  Loss: -1.5901  Acc@1: 62.5000 (65.7738)  Acc@5: 93.7500 (94.3452)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  30/1142]  eta: 0:07:34  Lr: 0.030000  Loss: -1.9533  Acc@1: 62.5000 (65.1210)  Acc@5: 93.7500 (94.3548)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [  40/1142]  eta: 0:07:26  Lr: 0.030000  Loss: -1.8786  Acc@1: 68.7500 (65.0915)  Acc@5: 93.7500 (92.8354)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [  50/1142]  eta: 0:07:19  Lr: 0.030000  Loss: -2.0092  Acc@1: 68.7500 (64.5833)  Acc@5: 87.5000 (92.7696)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  60/1142]  eta: 0:07:13  Lr: 0.030000  Loss: -2.1918  Acc@1: 62.5000 (64.3443)  Acc@5: 93.7500 (92.3156)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  70/1142]  eta: 0:07:07  Lr: 0.030000  Loss: -2.1388  Acc@1: 62.5000 (63.9965)  Acc@5: 93.7500 (92.5176)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  80/1142]  eta: 0:07:02  Lr: 0.030000  Loss: -2.1506  Acc@1: 62.5000 (64.3519)  Acc@5: 93.7500 (92.2068)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:58  Lr: 0.030000  Loss: -1.8399  Acc@1: 62.5000 (63.6676)  Acc@5: 87.5000 (91.9643)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:53  Lr: 0.030000  Loss: -1.8791  Acc@1: 56.2500 (63.1188)  Acc@5: 93.7500 (92.2649)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 110/1142]  eta: 0:06:49  Lr: 0.030000  Loss: -2.4407  Acc@1: 56.2500 (63.1194)  Acc@5: 93.7500 (92.3986)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 120/1142]  eta: 0:06:44  Lr: 0.030000  Loss: -1.8609  Acc@1: 56.2500 (62.4483)  Acc@5: 93.7500 (92.4587)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 130/1142]  eta: 0:06:40  Lr: 0.030000  Loss: -1.8507  Acc@1: 56.2500 (62.6908)  Acc@5: 93.7500 (92.6050)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 140/1142]  eta: 0:06:36  Lr: 0.030000  Loss: -1.4676  Acc@1: 62.5000 (62.8989)  Acc@5: 93.7500 (92.5089)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 150/1142]  eta: 0:06:31  Lr: 0.030000  Loss: -1.7752  Acc@1: 62.5000 (63.0795)  Acc@5: 93.7500 (92.5083)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 160/1142]  eta: 0:06:27  Lr: 0.030000  Loss: -1.6669  Acc@1: 62.5000 (63.2764)  Acc@5: 93.7500 (92.6630)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 170/1142]  eta: 0:06:23  Lr: 0.030000  Loss: -1.4180  Acc@1: 62.5000 (62.9751)  Acc@5: 93.7500 (92.5439)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 180/1142]  eta: 0:06:19  Lr: 0.030000  Loss: -1.6763  Acc@1: 62.5000 (63.0525)  Acc@5: 93.7500 (92.6105)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 190/1142]  eta: 0:06:15  Lr: 0.030000  Loss: -1.7969  Acc@1: 62.5000 (63.1217)  Acc@5: 93.7500 (92.4411)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 200/1142]  eta: 0:06:11  Lr: 0.030000  Loss: -1.4691  Acc@1: 62.5000 (62.9042)  Acc@5: 93.7500 (92.5062)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 210/1142]  eta: 0:06:07  Lr: 0.030000  Loss: -2.0305  Acc@1: 62.5000 (63.0628)  Acc@5: 93.7500 (92.3578)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 220/1142]  eta: 0:06:03  Lr: 0.030000  Loss: -2.1673  Acc@1: 68.7500 (63.2353)  Acc@5: 93.7500 (92.3643)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:59  Lr: 0.030000  Loss: -1.2279  Acc@1: 62.5000 (63.2035)  Acc@5: 93.7500 (92.3701)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:55  Lr: 0.030000  Loss: -0.3864  Acc@1: 62.5000 (63.0446)  Acc@5: 93.7500 (92.2718)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:51  Lr: 0.030000  Loss: -1.2137  Acc@1: 62.5000 (63.0229)  Acc@5: 93.7500 (92.2809)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:47  Lr: 0.030000  Loss: -2.2356  Acc@1: 62.5000 (63.0747)  Acc@5: 93.7500 (92.3372)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:43  Lr: 0.030000  Loss: -1.4987  Acc@1: 62.5000 (63.2149)  Acc@5: 93.7500 (92.3893)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 280/1142]  eta: 0:05:39  Lr: 0.030000  Loss: -1.4817  Acc@1: 62.5000 (63.1450)  Acc@5: 93.7500 (92.2375)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 290/1142]  eta: 0:05:35  Lr: 0.030000  Loss: -2.2082  Acc@1: 62.5000 (63.1014)  Acc@5: 87.5000 (92.1177)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 300/1142]  eta: 0:05:31  Lr: 0.030000  Loss: -2.0441  Acc@1: 56.2500 (62.9153)  Acc@5: 87.5000 (92.0473)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 310/1142]  eta: 0:05:27  Lr: 0.030000  Loss: -2.2020  Acc@1: 62.5000 (63.2034)  Acc@5: 93.7500 (92.1624)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 320/1142]  eta: 0:05:23  Lr: 0.030000  Loss: -1.8651  Acc@1: 62.5000 (63.0452)  Acc@5: 93.7500 (91.9977)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 330/1142]  eta: 0:05:19  Lr: 0.030000  Loss: -1.6830  Acc@1: 56.2500 (63.0287)  Acc@5: 87.5000 (91.9562)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 340/1142]  eta: 0:05:15  Lr: 0.030000  Loss: -1.3849  Acc@1: 62.5000 (62.9399)  Acc@5: 93.7500 (91.9355)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 350/1142]  eta: 0:05:11  Lr: 0.030000  Loss: -2.1997  Acc@1: 62.5000 (63.0342)  Acc@5: 93.7500 (92.0050)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 360/1142]  eta: 0:05:07  Lr: 0.030000  Loss: -1.8132  Acc@1: 62.5000 (62.9501)  Acc@5: 93.7500 (92.0187)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 370/1142]  eta: 0:05:03  Lr: 0.030000  Loss: -1.8022  Acc@1: 56.2500 (62.8538)  Acc@5: 93.7500 (92.0822)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:59  Lr: 0.030000  Loss: -2.1162  Acc@1: 62.5000 (62.9265)  Acc@5: 93.7500 (92.0768)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:55  Lr: 0.030000  Loss: -2.4688  Acc@1: 62.5000 (63.0115)  Acc@5: 93.7500 (92.1515)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:51  Lr: 0.030000  Loss: -1.0962  Acc@1: 62.5000 (62.9676)  Acc@5: 93.7500 (92.1446)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:47  Lr: 0.030000  Loss: -1.3536  Acc@1: 68.7500 (63.0779)  Acc@5: 93.7500 (92.2141)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:43  Lr: 0.030000  Loss: -1.7661  Acc@1: 68.7500 (63.2274)  Acc@5: 93.7500 (92.2061)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:39  Lr: 0.030000  Loss: -1.7920  Acc@1: 62.5000 (63.1961)  Acc@5: 87.5000 (92.0969)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:35  Lr: 0.030000  Loss: -1.6806  Acc@1: 62.5000 (63.4212)  Acc@5: 93.7500 (92.1485)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 450/1142]  eta: 0:04:31  Lr: 0.030000  Loss: -2.2209  Acc@1: 75.0000 (63.6225)  Acc@5: 93.7500 (92.2118)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 460/1142]  eta: 0:04:28  Lr: 0.030000  Loss: -2.2937  Acc@1: 68.7500 (63.6388)  Acc@5: 93.7500 (92.2316)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 470/1142]  eta: 0:04:24  Lr: 0.030000  Loss: -1.7142  Acc@1: 68.7500 (63.7075)  Acc@5: 93.7500 (92.2903)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 480/1142]  eta: 0:04:20  Lr: 0.030000  Loss: -1.1858  Acc@1: 62.5000 (63.6564)  Acc@5: 93.7500 (92.2947)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 490/1142]  eta: 0:04:16  Lr: 0.030000  Loss: -1.2072  Acc@1: 62.5000 (63.7093)  Acc@5: 87.5000 (92.3116)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 500/1142]  eta: 0:04:12  Lr: 0.030000  Loss: -2.0214  Acc@1: 62.5000 (63.7475)  Acc@5: 87.5000 (92.2655)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 510/1142]  eta: 0:04:08  Lr: 0.030000  Loss: -1.2510  Acc@1: 68.7500 (63.8699)  Acc@5: 93.7500 (92.3068)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 520/1142]  eta: 0:04:04  Lr: 0.030000  Loss: -1.6550  Acc@1: 68.7500 (63.9155)  Acc@5: 93.7500 (92.3345)  time: 0.3934  data: 0.0012  max mem: 2912
Train: Epoch[2/5]  [ 530/1142]  eta: 0:04:00  Lr: 0.030000  Loss: -2.1034  Acc@1: 62.5000 (63.8889)  Acc@5: 93.7500 (92.3611)  time: 0.3946  data: 0.0012  max mem: 2912
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:56  Lr: 0.030000  Loss: -1.7983  Acc@1: 62.5000 (63.8632)  Acc@5: 93.7500 (92.3752)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:52  Lr: 0.030000  Loss: -2.2202  Acc@1: 68.7500 (63.9065)  Acc@5: 93.7500 (92.3888)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:48  Lr: 0.030000  Loss: -2.0502  Acc@1: 68.7500 (63.9594)  Acc@5: 93.7500 (92.3797)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:44  Lr: 0.030000  Loss: -1.7890  Acc@1: 68.7500 (63.9996)  Acc@5: 93.7500 (92.4146)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:40  Lr: 0.030000  Loss: -1.6411  Acc@1: 62.5000 (63.9307)  Acc@5: 93.7500 (92.4376)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:36  Lr: 0.030000  Loss: -2.0444  Acc@1: 62.5000 (63.9382)  Acc@5: 93.7500 (92.4387)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:32  Lr: 0.030000  Loss: -2.4219  Acc@1: 62.5000 (63.8415)  Acc@5: 93.7500 (92.4085)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:29  Lr: 0.030000  Loss: -2.1220  Acc@1: 62.5000 (63.8605)  Acc@5: 93.7500 (92.3895)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 620/1142]  eta: 0:03:25  Lr: 0.030000  Loss: -1.6570  Acc@1: 62.5000 (63.7782)  Acc@5: 93.7500 (92.4014)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 630/1142]  eta: 0:03:21  Lr: 0.030000  Loss: -1.5713  Acc@1: 62.5000 (63.7678)  Acc@5: 93.7500 (92.4029)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 640/1142]  eta: 0:03:17  Lr: 0.030000  Loss: -1.4712  Acc@1: 62.5000 (63.6798)  Acc@5: 93.7500 (92.3849)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 650/1142]  eta: 0:03:13  Lr: 0.030000  Loss: -1.7998  Acc@1: 62.5000 (63.6905)  Acc@5: 93.7500 (92.4251)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 660/1142]  eta: 0:03:09  Lr: 0.030000  Loss: -1.6859  Acc@1: 62.5000 (63.6346)  Acc@5: 93.7500 (92.3506)  time: 0.3921  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 670/1142]  eta: 0:03:05  Lr: 0.030000  Loss: -1.4212  Acc@1: 62.5000 (63.6829)  Acc@5: 87.5000 (92.3435)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 680/1142]  eta: 0:03:01  Lr: 0.030000  Loss: -1.7673  Acc@1: 68.7500 (63.7298)  Acc@5: 87.5000 (92.2907)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:57  Lr: 0.030000  Loss: -2.2335  Acc@1: 62.5000 (63.7120)  Acc@5: 87.5000 (92.3119)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:53  Lr: 0.030000  Loss: -1.4376  Acc@1: 62.5000 (63.6591)  Acc@5: 93.7500 (92.2521)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:49  Lr: 0.030000  Loss: -1.5751  Acc@1: 62.5000 (63.6603)  Acc@5: 93.7500 (92.2732)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:45  Lr: 0.030000  Loss: -1.0028  Acc@1: 62.5000 (63.7656)  Acc@5: 93.7500 (92.3024)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:41  Lr: 0.030000  Loss: -1.4003  Acc@1: 62.5000 (63.7568)  Acc@5: 93.7500 (92.3136)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:37  Lr: 0.030000  Loss: -2.1793  Acc@1: 68.7500 (63.8411)  Acc@5: 93.7500 (92.3330)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:33  Lr: 0.030000  Loss: -1.7467  Acc@1: 68.7500 (63.8815)  Acc@5: 93.7500 (92.3352)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:29  Lr: 0.030000  Loss: -1.7603  Acc@1: 62.5000 (63.8551)  Acc@5: 93.7500 (92.3456)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:26  Lr: 0.030000  Loss: -1.9056  Acc@1: 62.5000 (63.8619)  Acc@5: 93.7500 (92.3314)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:22  Lr: 0.030000  Loss: -1.2992  Acc@1: 62.5000 (63.8604)  Acc@5: 93.7500 (92.3576)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:18  Lr: 0.030000  Loss: -1.4116  Acc@1: 62.5000 (63.8353)  Acc@5: 93.7500 (92.3277)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 800/1142]  eta: 0:02:14  Lr: 0.030000  Loss: -2.3948  Acc@1: 62.5000 (63.8577)  Acc@5: 93.7500 (92.3767)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 810/1142]  eta: 0:02:10  Lr: 0.030000  Loss: -1.8940  Acc@1: 68.7500 (63.8486)  Acc@5: 93.7500 (92.3936)  time: 0.3908  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 820/1142]  eta: 0:02:06  Lr: 0.030000  Loss: -1.7674  Acc@1: 56.2500 (63.7865)  Acc@5: 93.7500 (92.3797)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 830/1142]  eta: 0:02:02  Lr: 0.030000  Loss: -0.8481  Acc@1: 56.2500 (63.7410)  Acc@5: 93.7500 (92.3586)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:58  Lr: 0.030000  Loss: -2.2025  Acc@1: 62.5000 (63.7857)  Acc@5: 87.5000 (92.3529)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:54  Lr: 0.030000  Loss: -2.0087  Acc@1: 68.7500 (63.8367)  Acc@5: 87.5000 (92.3252)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:50  Lr: 0.030000  Loss: -1.8861  Acc@1: 62.5000 (63.8211)  Acc@5: 93.7500 (92.3418)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:46  Lr: 0.030000  Loss: -2.0137  Acc@1: 62.5000 (63.7916)  Acc@5: 93.7500 (92.3077)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:42  Lr: 0.030000  Loss: -1.5617  Acc@1: 56.2500 (63.7699)  Acc@5: 87.5000 (92.3170)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:38  Lr: 0.030000  Loss: -1.8128  Acc@1: 62.5000 (63.7837)  Acc@5: 93.7500 (92.3120)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:34  Lr: 0.030000  Loss: -1.7004  Acc@1: 62.5000 (63.7764)  Acc@5: 93.7500 (92.3488)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:31  Lr: 0.030000  Loss: -1.7170  Acc@1: 62.5000 (63.8241)  Acc@5: 93.7500 (92.3573)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:27  Lr: 0.030000  Loss: -1.7144  Acc@1: 62.5000 (63.7894)  Acc@5: 93.7500 (92.3588)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:23  Lr: 0.030000  Loss: -1.9331  Acc@1: 62.5000 (63.7956)  Acc@5: 93.7500 (92.3469)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:19  Lr: 0.030000  Loss: -2.1339  Acc@1: 62.5000 (63.8084)  Acc@5: 93.7500 (92.3751)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:15  Lr: 0.030000  Loss: -1.7647  Acc@1: 62.5000 (63.8210)  Acc@5: 93.7500 (92.4225)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:11  Lr: 0.030000  Loss: -1.6385  Acc@1: 68.7500 (63.8593)  Acc@5: 93.7500 (92.4623)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 970/1142]  eta: 0:01:07  Lr: 0.030000  Loss: -0.8046  Acc@1: 68.7500 (63.8839)  Acc@5: 93.7500 (92.4691)  time: 0.3923  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [ 980/1142]  eta: 0:01:03  Lr: 0.030000  Loss: -2.0904  Acc@1: 62.5000 (63.8252)  Acc@5: 93.7500 (92.4567)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:59  Lr: 0.030000  Loss: -1.1820  Acc@1: 56.2500 (63.7866)  Acc@5: 93.7500 (92.4130)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:55  Lr: 0.030000  Loss: -1.7188  Acc@1: 62.5000 (63.7987)  Acc@5: 93.7500 (92.4201)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:51  Lr: 0.030000  Loss: -1.5539  Acc@1: 68.7500 (63.8786)  Acc@5: 93.7500 (92.4580)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:47  Lr: 0.030000  Loss: -1.4718  Acc@1: 68.7500 (63.9324)  Acc@5: 93.7500 (92.4645)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:43  Lr: 0.030000  Loss: -2.1390  Acc@1: 68.7500 (63.9306)  Acc@5: 93.7500 (92.4648)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:40  Lr: 0.030000  Loss: -1.9290  Acc@1: 62.5000 (63.8869)  Acc@5: 93.7500 (92.4472)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:36  Lr: 0.030000  Loss: -2.1771  Acc@1: 62.5000 (63.9391)  Acc@5: 93.7500 (92.4477)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:32  Lr: 0.030000  Loss: -1.5750  Acc@1: 62.5000 (63.9373)  Acc@5: 93.7500 (92.4717)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:28  Lr: 0.030000  Loss: -2.1702  Acc@1: 68.7500 (63.9939)  Acc@5: 93.7500 (92.4662)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:24  Lr: 0.030000  Loss: -1.7403  Acc@1: 75.0000 (64.0668)  Acc@5: 93.7500 (92.4838)  time: 0.3933  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:20  Lr: 0.030000  Loss: -1.8271  Acc@1: 62.5000 (64.0582)  Acc@5: 93.7500 (92.5011)  time: 0.3940  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:16  Lr: 0.030000  Loss: -2.2921  Acc@1: 62.5000 (64.0838)  Acc@5: 93.7500 (92.5068)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:12  Lr: 0.030000  Loss: -2.2700  Acc@1: 62.5000 (64.1033)  Acc@5: 93.7500 (92.5124)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:08  Lr: 0.030000  Loss: -1.8382  Acc@1: 62.5000 (64.1057)  Acc@5: 93.7500 (92.4900)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: -1.7337  Acc@1: 75.0000 (64.1357)  Acc@5: 93.7500 (92.5011)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -1.2703  Acc@1: 62.5000 (64.1378)  Acc@5: 93.7500 (92.5066)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -2.4250  Acc@1: 62.5000 (64.1500)  Acc@5: 93.7500 (92.5103)  time: 0.3849  data: 0.0004  max mem: 2912
Train: Epoch[2/5] Total time: 0:07:28 (0.3925 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.4250  Acc@1: 62.5000 (64.1500)  Acc@5: 93.7500 (92.5103)
Train: Epoch[3/5]  [   0/1142]  eta: 0:15:56  Lr: 0.030000  Loss: -0.6024  Acc@1: 37.5000 (37.5000)  Acc@5: 93.7500 (93.7500)  time: 0.8377  data: 0.4387  max mem: 2912
Train: Epoch[3/5]  [  10/1142]  eta: 0:08:10  Lr: 0.030000  Loss: -2.1332  Acc@1: 68.7500 (66.4773)  Acc@5: 93.7500 (94.3182)  time: 0.4335  data: 0.0402  max mem: 2912
Train: Epoch[3/5]  [  20/1142]  eta: 0:07:45  Lr: 0.030000  Loss: -1.8420  Acc@1: 62.5000 (64.2857)  Acc@5: 93.7500 (93.7500)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  30/1142]  eta: 0:07:32  Lr: 0.030000  Loss: -2.3975  Acc@1: 62.5000 (64.1129)  Acc@5: 93.7500 (94.3548)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  40/1142]  eta: 0:07:24  Lr: 0.030000  Loss: -2.0835  Acc@1: 62.5000 (64.9390)  Acc@5: 93.7500 (93.4451)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  50/1142]  eta: 0:07:17  Lr: 0.030000  Loss: -2.3243  Acc@1: 62.5000 (64.2157)  Acc@5: 93.7500 (93.6275)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  60/1142]  eta: 0:07:12  Lr: 0.030000  Loss: -2.1663  Acc@1: 62.5000 (64.5492)  Acc@5: 93.7500 (94.0574)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [  70/1142]  eta: 0:07:07  Lr: 0.030000  Loss: -1.2618  Acc@1: 62.5000 (64.7887)  Acc@5: 93.7500 (93.6620)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [  80/1142]  eta: 0:07:02  Lr: 0.030000  Loss: -1.7809  Acc@1: 62.5000 (64.4290)  Acc@5: 93.7500 (93.9043)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:57  Lr: 0.030000  Loss: -1.0899  Acc@1: 62.5000 (64.0110)  Acc@5: 93.7500 (93.4753)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:53  Lr: 0.030000  Loss: -2.2167  Acc@1: 62.5000 (64.3564)  Acc@5: 93.7500 (93.1312)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 110/1142]  eta: 0:06:48  Lr: 0.030000  Loss: -2.1002  Acc@1: 68.7500 (64.4144)  Acc@5: 93.7500 (93.0743)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 120/1142]  eta: 0:06:44  Lr: 0.030000  Loss: -1.8184  Acc@1: 68.7500 (64.5145)  Acc@5: 93.7500 (93.1302)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 130/1142]  eta: 0:06:40  Lr: 0.030000  Loss: -2.1995  Acc@1: 62.5000 (64.3130)  Acc@5: 93.7500 (93.1775)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 140/1142]  eta: 0:06:35  Lr: 0.030000  Loss: -1.9304  Acc@1: 68.7500 (64.7163)  Acc@5: 93.7500 (93.0851)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 150/1142]  eta: 0:06:31  Lr: 0.030000  Loss: -2.0173  Acc@1: 68.7500 (65.1076)  Acc@5: 93.7500 (93.3361)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 160/1142]  eta: 0:06:27  Lr: 0.030000  Loss: -2.0895  Acc@1: 68.7500 (65.2950)  Acc@5: 93.7500 (93.3230)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 170/1142]  eta: 0:06:23  Lr: 0.030000  Loss: -1.4671  Acc@1: 68.7500 (65.2778)  Acc@5: 93.7500 (93.4576)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 180/1142]  eta: 0:06:19  Lr: 0.030000  Loss: -2.3353  Acc@1: 68.7500 (65.5387)  Acc@5: 93.7500 (93.3356)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 190/1142]  eta: 0:06:15  Lr: 0.030000  Loss: -1.9981  Acc@1: 68.7500 (65.6086)  Acc@5: 93.7500 (93.1610)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 200/1142]  eta: 0:06:11  Lr: 0.030000  Loss: -2.3311  Acc@1: 68.7500 (65.7027)  Acc@5: 93.7500 (93.2214)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 210/1142]  eta: 0:06:06  Lr: 0.030000  Loss: -2.5046  Acc@1: 68.7500 (66.0841)  Acc@5: 93.7500 (93.3057)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 220/1142]  eta: 0:06:02  Lr: 0.030000  Loss: -1.2957  Acc@1: 68.7500 (66.0633)  Acc@5: 93.7500 (93.4672)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:58  Lr: 0.030000  Loss: -1.6459  Acc@1: 68.7500 (65.9091)  Acc@5: 93.7500 (93.5335)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:54  Lr: 0.030000  Loss: -1.9376  Acc@1: 62.5000 (65.9232)  Acc@5: 93.7500 (93.4388)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:50  Lr: 0.030000  Loss: -2.4573  Acc@1: 75.0000 (66.2351)  Acc@5: 93.7500 (93.5508)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:46  Lr: 0.030000  Loss: -1.7494  Acc@1: 75.0000 (66.4272)  Acc@5: 100.0000 (93.6303)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:42  Lr: 0.030000  Loss: -1.2759  Acc@1: 68.7500 (66.4437)  Acc@5: 93.7500 (93.5424)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 280/1142]  eta: 0:05:38  Lr: 0.030000  Loss: -1.8236  Acc@1: 68.7500 (66.4368)  Acc@5: 93.7500 (93.5721)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 290/1142]  eta: 0:05:34  Lr: 0.030000  Loss: -1.9339  Acc@1: 62.5000 (66.2801)  Acc@5: 93.7500 (93.4493)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 300/1142]  eta: 0:05:30  Lr: 0.030000  Loss: -0.8852  Acc@1: 62.5000 (66.1960)  Acc@5: 93.7500 (93.3970)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 310/1142]  eta: 0:05:26  Lr: 0.030000  Loss: -2.4695  Acc@1: 68.7500 (66.2982)  Acc@5: 93.7500 (93.4686)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 320/1142]  eta: 0:05:22  Lr: 0.030000  Loss: -1.3208  Acc@1: 68.7500 (66.2773)  Acc@5: 93.7500 (93.3606)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 330/1142]  eta: 0:05:18  Lr: 0.030000  Loss: -1.5568  Acc@1: 68.7500 (66.2953)  Acc@5: 87.5000 (93.2968)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 340/1142]  eta: 0:05:14  Lr: 0.030000  Loss: -1.7608  Acc@1: 68.7500 (66.4406)  Acc@5: 93.7500 (93.3101)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 350/1142]  eta: 0:05:10  Lr: 0.030000  Loss: -1.5624  Acc@1: 62.5000 (66.1859)  Acc@5: 93.7500 (93.2336)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 360/1142]  eta: 0:05:06  Lr: 0.030000  Loss: -1.4838  Acc@1: 62.5000 (66.1357)  Acc@5: 93.7500 (93.1960)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 370/1142]  eta: 0:05:03  Lr: 0.030000  Loss: -1.9548  Acc@1: 68.7500 (66.1725)  Acc@5: 87.5000 (93.1435)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 380/1142]  eta: 0:04:59  Lr: 0.030000  Loss: -1.7616  Acc@1: 68.7500 (66.3550)  Acc@5: 93.7500 (93.1923)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 390/1142]  eta: 0:04:55  Lr: 0.030000  Loss: -1.6945  Acc@1: 75.0000 (66.5281)  Acc@5: 93.7500 (93.2705)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 400/1142]  eta: 0:04:51  Lr: 0.030000  Loss: -1.5627  Acc@1: 75.0000 (66.6459)  Acc@5: 93.7500 (93.3292)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 410/1142]  eta: 0:04:47  Lr: 0.030000  Loss: -1.3960  Acc@1: 68.7500 (66.6515)  Acc@5: 93.7500 (93.3242)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 420/1142]  eta: 0:04:43  Lr: 0.030000  Loss: -1.8591  Acc@1: 68.7500 (66.7310)  Acc@5: 93.7500 (93.3937)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 430/1142]  eta: 0:04:39  Lr: 0.030000  Loss: -2.0718  Acc@1: 68.7500 (66.8358)  Acc@5: 93.7500 (93.4020)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:35  Lr: 0.030000  Loss: -2.1317  Acc@1: 75.0000 (66.9785)  Acc@5: 93.7500 (93.4382)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 450/1142]  eta: 0:04:31  Lr: 0.030000  Loss: -2.4428  Acc@1: 68.7500 (66.9900)  Acc@5: 93.7500 (93.4174)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 460/1142]  eta: 0:04:27  Lr: 0.030000  Loss: -2.0941  Acc@1: 62.5000 (67.0282)  Acc@5: 93.7500 (93.4111)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 470/1142]  eta: 0:04:23  Lr: 0.030000  Loss: -1.6928  Acc@1: 62.5000 (66.8126)  Acc@5: 93.7500 (93.3785)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 480/1142]  eta: 0:04:19  Lr: 0.030000  Loss: -1.6388  Acc@1: 62.5000 (66.8529)  Acc@5: 93.7500 (93.3342)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 490/1142]  eta: 0:04:15  Lr: 0.030000  Loss: -1.8131  Acc@1: 68.7500 (66.8915)  Acc@5: 93.7500 (93.2790)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 500/1142]  eta: 0:04:11  Lr: 0.030000  Loss: -1.7721  Acc@1: 68.7500 (66.7789)  Acc@5: 93.7500 (93.3134)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 510/1142]  eta: 0:04:07  Lr: 0.030000  Loss: -2.2970  Acc@1: 62.5000 (66.7441)  Acc@5: 93.7500 (93.3219)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 520/1142]  eta: 0:04:03  Lr: 0.030000  Loss: -1.9506  Acc@1: 62.5000 (66.7226)  Acc@5: 93.7500 (93.2582)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 530/1142]  eta: 0:04:00  Lr: 0.030000  Loss: -1.7636  Acc@1: 62.5000 (66.7608)  Acc@5: 93.7500 (93.2556)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 540/1142]  eta: 0:03:56  Lr: 0.030000  Loss: -2.1259  Acc@1: 68.7500 (66.7976)  Acc@5: 93.7500 (93.2763)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 550/1142]  eta: 0:03:52  Lr: 0.030000  Loss: -2.3123  Acc@1: 62.5000 (66.7309)  Acc@5: 93.7500 (93.3190)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:48  Lr: 0.030000  Loss: -2.3055  Acc@1: 62.5000 (66.7112)  Acc@5: 93.7500 (93.2821)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:44  Lr: 0.030000  Loss: -1.8168  Acc@1: 68.7500 (66.7579)  Acc@5: 93.7500 (93.3012)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:40  Lr: 0.030000  Loss: -0.8147  Acc@1: 68.7500 (66.7814)  Acc@5: 93.7500 (93.2767)  time: 0.3938  data: 0.0008  max mem: 2912
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:36  Lr: 0.030000  Loss: -2.0647  Acc@1: 62.5000 (66.6244)  Acc@5: 87.5000 (93.2107)  time: 0.3929  data: 0.0007  max mem: 2912
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:32  Lr: 0.030000  Loss: -1.8984  Acc@1: 62.5000 (66.5765)  Acc@5: 93.7500 (93.2300)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:28  Lr: 0.030000  Loss: -2.0280  Acc@1: 62.5000 (66.5610)  Acc@5: 93.7500 (93.2385)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:24  Lr: 0.030000  Loss: -1.4539  Acc@1: 68.7500 (66.5258)  Acc@5: 93.7500 (93.2267)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 630/1142]  eta: 0:03:20  Lr: 0.030000  Loss: -1.4262  Acc@1: 62.5000 (66.4323)  Acc@5: 93.7500 (93.2250)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 640/1142]  eta: 0:03:16  Lr: 0.030000  Loss: -2.1649  Acc@1: 62.5000 (66.4197)  Acc@5: 93.7500 (93.2235)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 650/1142]  eta: 0:03:12  Lr: 0.030000  Loss: -2.1710  Acc@1: 62.5000 (66.5035)  Acc@5: 93.7500 (93.2700)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 660/1142]  eta: 0:03:09  Lr: 0.030000  Loss: -1.3788  Acc@1: 75.0000 (66.6415)  Acc@5: 93.7500 (93.2961)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 670/1142]  eta: 0:03:05  Lr: 0.030000  Loss: -2.2011  Acc@1: 68.7500 (66.5704)  Acc@5: 93.7500 (93.3308)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 680/1142]  eta: 0:03:01  Lr: 0.030000  Loss: -1.3026  Acc@1: 62.5000 (66.5290)  Acc@5: 93.7500 (93.3370)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:57  Lr: 0.030000  Loss: -2.4073  Acc@1: 62.5000 (66.5069)  Acc@5: 93.7500 (93.3430)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:53  Lr: 0.030000  Loss: -1.7177  Acc@1: 62.5000 (66.4765)  Acc@5: 93.7500 (93.3488)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:49  Lr: 0.030000  Loss: -1.4151  Acc@1: 62.5000 (66.4205)  Acc@5: 93.7500 (93.3281)  time: 0.3919  data: 0.0008  max mem: 2912
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:45  Lr: 0.030000  Loss: -0.9257  Acc@1: 56.2500 (66.3835)  Acc@5: 87.5000 (93.2906)  time: 0.3921  data: 0.0008  max mem: 2912
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:41  Lr: 0.030000  Loss: -1.4704  Acc@1: 56.2500 (66.2962)  Acc@5: 93.7500 (93.2712)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:37  Lr: 0.030000  Loss: -1.9292  Acc@1: 62.5000 (66.2618)  Acc@5: 93.7500 (93.3030)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:33  Lr: 0.030000  Loss: -1.9742  Acc@1: 62.5000 (66.2450)  Acc@5: 93.7500 (93.3256)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:29  Lr: 0.030000  Loss: -2.2404  Acc@1: 68.7500 (66.2122)  Acc@5: 93.7500 (93.3804)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:25  Lr: 0.030000  Loss: -2.3498  Acc@1: 68.7500 (66.1560)  Acc@5: 100.0000 (93.4014)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:21  Lr: 0.030000  Loss: -1.9545  Acc@1: 68.7500 (66.1172)  Acc@5: 93.7500 (93.4059)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:18  Lr: 0.030000  Loss: -1.9509  Acc@1: 68.7500 (66.0714)  Acc@5: 93.7500 (93.4260)  time: 0.3907  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 800/1142]  eta: 0:02:14  Lr: 0.030000  Loss: -2.0519  Acc@1: 56.2500 (65.9176)  Acc@5: 93.7500 (93.4301)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 810/1142]  eta: 0:02:10  Lr: 0.030000  Loss: -1.9562  Acc@1: 62.5000 (65.9679)  Acc@5: 93.7500 (93.4340)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 820/1142]  eta: 0:02:06  Lr: 0.030000  Loss: -1.4030  Acc@1: 68.7500 (65.9409)  Acc@5: 93.7500 (93.4150)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 830/1142]  eta: 0:02:02  Lr: 0.030000  Loss: -2.4928  Acc@1: 68.7500 (65.9522)  Acc@5: 93.7500 (93.4116)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:58  Lr: 0.030000  Loss: -1.8644  Acc@1: 68.7500 (66.0226)  Acc@5: 93.7500 (93.4081)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:54  Lr: 0.030000  Loss: -1.7910  Acc@1: 68.7500 (66.0032)  Acc@5: 93.7500 (93.3975)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:50  Lr: 0.030000  Loss: -2.3542  Acc@1: 68.7500 (66.0859)  Acc@5: 93.7500 (93.3798)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:46  Lr: 0.030000  Loss: -1.5009  Acc@1: 68.7500 (66.0950)  Acc@5: 93.7500 (93.3625)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:42  Lr: 0.030000  Loss: -1.8114  Acc@1: 62.5000 (66.1039)  Acc@5: 93.7500 (93.3598)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:38  Lr: 0.030000  Loss: -2.2919  Acc@1: 62.5000 (66.0704)  Acc@5: 93.7500 (93.3361)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:34  Lr: 0.030000  Loss: -1.5206  Acc@1: 68.7500 (66.0585)  Acc@5: 93.7500 (93.3407)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:30  Lr: 0.030000  Loss: -2.3495  Acc@1: 68.7500 (66.0950)  Acc@5: 93.7500 (93.3315)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:27  Lr: 0.030000  Loss: -1.8120  Acc@1: 68.7500 (66.0898)  Acc@5: 93.7500 (93.3157)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:23  Lr: 0.030000  Loss: -1.9412  Acc@1: 62.5000 (66.0916)  Acc@5: 93.7500 (93.3472)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:19  Lr: 0.030000  Loss: -1.4617  Acc@1: 62.5000 (66.0135)  Acc@5: 93.7500 (93.3382)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:15  Lr: 0.030000  Loss: -1.1119  Acc@1: 62.5000 (65.9503)  Acc@5: 87.5000 (93.2965)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:11  Lr: 0.030000  Loss: -1.1735  Acc@1: 68.7500 (65.9925)  Acc@5: 87.5000 (93.2622)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 970/1142]  eta: 0:01:07  Lr: 0.030000  Loss: -2.1997  Acc@1: 68.7500 (66.0080)  Acc@5: 93.7500 (93.2930)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 980/1142]  eta: 0:01:03  Lr: 0.030000  Loss: -1.5785  Acc@1: 68.7500 (66.0232)  Acc@5: 93.7500 (93.3231)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:59  Lr: 0.030000  Loss: -2.2277  Acc@1: 68.7500 (66.0507)  Acc@5: 100.0000 (93.3464)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:55  Lr: 0.030000  Loss: -2.0825  Acc@1: 68.7500 (66.0277)  Acc@5: 93.7500 (93.3379)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:51  Lr: 0.030000  Loss: -1.8948  Acc@1: 62.5000 (65.9743)  Acc@5: 93.7500 (93.3173)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:47  Lr: 0.030000  Loss: -1.9780  Acc@1: 68.7500 (66.0076)  Acc@5: 93.7500 (93.3337)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:43  Lr: 0.030000  Loss: -1.8239  Acc@1: 68.7500 (65.9857)  Acc@5: 93.7500 (93.3560)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:39  Lr: 0.030000  Loss: -2.2674  Acc@1: 68.7500 (65.9942)  Acc@5: 93.7500 (93.3598)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:36  Lr: 0.030000  Loss: -2.1540  Acc@1: 68.7500 (66.0026)  Acc@5: 93.7500 (93.3575)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:32  Lr: 0.030000  Loss: -1.5661  Acc@1: 62.5000 (65.9932)  Acc@5: 93.7500 (93.3671)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:28  Lr: 0.030000  Loss: -1.9921  Acc@1: 62.5000 (65.9664)  Acc@5: 93.7500 (93.3473)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:24  Lr: 0.030000  Loss: -1.6676  Acc@1: 68.7500 (65.9690)  Acc@5: 93.7500 (93.3337)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:20  Lr: 0.030000  Loss: -2.1824  Acc@1: 75.0000 (66.1263)  Acc@5: 93.7500 (93.3547)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:16  Lr: 0.030000  Loss: -2.2074  Acc@1: 75.0000 (66.1104)  Acc@5: 93.7500 (93.3583)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:12  Lr: 0.030000  Loss: -1.2080  Acc@1: 62.5000 (66.1229)  Acc@5: 93.7500 (93.3843)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:08  Lr: 0.030000  Loss: -2.3031  Acc@1: 68.7500 (66.1351)  Acc@5: 93.7500 (93.3876)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: -1.6132  Acc@1: 68.7500 (66.1141)  Acc@5: 93.7500 (93.4019)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -1.7837  Acc@1: 68.7500 (66.1372)  Acc@5: 93.7500 (93.4104)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -1.4496  Acc@1: 68.7500 (66.1265)  Acc@5: 93.7500 (93.4082)  time: 0.3858  data: 0.0004  max mem: 2912
Train: Epoch[3/5] Total time: 0:07:27 (0.3922 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.4496  Acc@1: 68.7500 (66.1265)  Acc@5: 93.7500 (93.4082)
Train: Epoch[4/5]  [   0/1142]  eta: 0:18:08  Lr: 0.030000  Loss: -2.5037  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.9534  data: 0.5601  max mem: 2912
Train: Epoch[4/5]  [  10/1142]  eta: 0:08:19  Lr: 0.030000  Loss: -1.2717  Acc@1: 56.2500 (58.5227)  Acc@5: 93.7500 (93.7500)  time: 0.4417  data: 0.0512  max mem: 2912
Train: Epoch[4/5]  [  20/1142]  eta: 0:07:49  Lr: 0.030000  Loss: -1.8423  Acc@1: 56.2500 (60.4167)  Acc@5: 93.7500 (93.1548)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  30/1142]  eta: 0:07:36  Lr: 0.030000  Loss: -1.8628  Acc@1: 62.5000 (63.5081)  Acc@5: 93.7500 (93.7500)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  40/1142]  eta: 0:07:27  Lr: 0.030000  Loss: -1.1377  Acc@1: 68.7500 (64.4817)  Acc@5: 93.7500 (93.4451)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  50/1142]  eta: 0:07:20  Lr: 0.030000  Loss: -1.7486  Acc@1: 68.7500 (64.3382)  Acc@5: 93.7500 (93.2598)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  60/1142]  eta: 0:07:14  Lr: 0.030000  Loss: -1.9334  Acc@1: 68.7500 (64.7541)  Acc@5: 93.7500 (93.5451)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  70/1142]  eta: 0:07:08  Lr: 0.030000  Loss: -1.8854  Acc@1: 62.5000 (64.3486)  Acc@5: 93.7500 (93.5739)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [  80/1142]  eta: 0:07:04  Lr: 0.030000  Loss: -1.7471  Acc@1: 62.5000 (64.2747)  Acc@5: 93.7500 (93.5185)  time: 0.3935  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:59  Lr: 0.030000  Loss: -1.4990  Acc@1: 62.5000 (64.0110)  Acc@5: 93.7500 (93.4066)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:54  Lr: 0.030000  Loss: -1.9464  Acc@1: 62.5000 (63.6757)  Acc@5: 93.7500 (93.4406)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 110/1142]  eta: 0:06:50  Lr: 0.030000  Loss: -1.5263  Acc@1: 62.5000 (63.7387)  Acc@5: 93.7500 (93.5248)  time: 0.3926  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 120/1142]  eta: 0:06:45  Lr: 0.030000  Loss: -2.2296  Acc@1: 62.5000 (63.5847)  Acc@5: 93.7500 (93.2851)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 130/1142]  eta: 0:06:41  Lr: 0.030000  Loss: -2.0002  Acc@1: 68.7500 (64.3130)  Acc@5: 93.7500 (93.3683)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 140/1142]  eta: 0:06:37  Lr: 0.030000  Loss: -2.2848  Acc@1: 68.7500 (64.4947)  Acc@5: 93.7500 (93.3511)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 150/1142]  eta: 0:06:32  Lr: 0.030000  Loss: -2.2124  Acc@1: 68.7500 (64.9007)  Acc@5: 93.7500 (93.0050)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 160/1142]  eta: 0:06:28  Lr: 0.030000  Loss: -2.5168  Acc@1: 68.7500 (65.1398)  Acc@5: 93.7500 (93.2453)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 170/1142]  eta: 0:06:24  Lr: 0.030000  Loss: -2.4484  Acc@1: 68.7500 (65.3143)  Acc@5: 93.7500 (93.3480)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 180/1142]  eta: 0:06:20  Lr: 0.030000  Loss: -1.8339  Acc@1: 68.7500 (65.4351)  Acc@5: 93.7500 (93.4392)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 190/1142]  eta: 0:06:16  Lr: 0.030000  Loss: -1.7616  Acc@1: 68.7500 (65.3796)  Acc@5: 93.7500 (93.3901)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 200/1142]  eta: 0:06:12  Lr: 0.030000  Loss: -1.3249  Acc@1: 68.7500 (65.4540)  Acc@5: 93.7500 (93.2836)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 210/1142]  eta: 0:06:08  Lr: 0.030000  Loss: -2.2737  Acc@1: 68.7500 (65.5509)  Acc@5: 93.7500 (93.3057)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 220/1142]  eta: 0:06:04  Lr: 0.030000  Loss: -2.3170  Acc@1: 68.7500 (65.6957)  Acc@5: 93.7500 (93.2692)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 230/1142]  eta: 0:06:00  Lr: 0.030000  Loss: -1.0036  Acc@1: 68.7500 (65.9091)  Acc@5: 93.7500 (93.2359)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:56  Lr: 0.030000  Loss: -1.6781  Acc@1: 62.5000 (65.6120)  Acc@5: 93.7500 (93.1017)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:51  Lr: 0.030000  Loss: -1.9594  Acc@1: 68.7500 (65.7620)  Acc@5: 93.7500 (93.2022)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:47  Lr: 0.030000  Loss: -1.6141  Acc@1: 68.7500 (65.6849)  Acc@5: 93.7500 (93.1992)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:43  Lr: 0.030000  Loss: -2.3167  Acc@1: 68.7500 (65.8672)  Acc@5: 93.7500 (93.2426)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 280/1142]  eta: 0:05:39  Lr: 0.030000  Loss: -2.2281  Acc@1: 68.7500 (65.9920)  Acc@5: 93.7500 (93.2829)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 290/1142]  eta: 0:05:35  Lr: 0.030000  Loss: -1.9549  Acc@1: 62.5000 (66.2586)  Acc@5: 93.7500 (93.3634)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 300/1142]  eta: 0:05:31  Lr: 0.030000  Loss: -1.7351  Acc@1: 75.0000 (66.5282)  Acc@5: 93.7500 (93.4801)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 310/1142]  eta: 0:05:27  Lr: 0.030000  Loss: -1.3206  Acc@1: 68.7500 (66.5394)  Acc@5: 93.7500 (93.4686)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 320/1142]  eta: 0:05:23  Lr: 0.030000  Loss: -2.4311  Acc@1: 68.7500 (66.7251)  Acc@5: 93.7500 (93.5358)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 330/1142]  eta: 0:05:19  Lr: 0.030000  Loss: -1.8521  Acc@1: 68.7500 (66.8807)  Acc@5: 93.7500 (93.6178)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 340/1142]  eta: 0:05:15  Lr: 0.030000  Loss: -2.1116  Acc@1: 68.7500 (66.8988)  Acc@5: 93.7500 (93.6584)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 350/1142]  eta: 0:05:11  Lr: 0.030000  Loss: -1.9082  Acc@1: 68.7500 (66.8981)  Acc@5: 93.7500 (93.5897)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 360/1142]  eta: 0:05:07  Lr: 0.030000  Loss: -1.7577  Acc@1: 68.7500 (66.9148)  Acc@5: 93.7500 (93.4903)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 370/1142]  eta: 0:05:03  Lr: 0.030000  Loss: -1.8229  Acc@1: 68.7500 (67.0654)  Acc@5: 93.7500 (93.5310)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:59  Lr: 0.030000  Loss: -2.0223  Acc@1: 75.0000 (67.1916)  Acc@5: 93.7500 (93.5203)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:55  Lr: 0.030000  Loss: -1.8425  Acc@1: 68.7500 (67.2794)  Acc@5: 93.7500 (93.5902)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:51  Lr: 0.030000  Loss: -2.1874  Acc@1: 68.7500 (67.3005)  Acc@5: 93.7500 (93.5630)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:47  Lr: 0.030000  Loss: -1.1689  Acc@1: 68.7500 (67.3206)  Acc@5: 93.7500 (93.6131)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:43  Lr: 0.030000  Loss: -2.6076  Acc@1: 68.7500 (67.4287)  Acc@5: 93.7500 (93.5867)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:39  Lr: 0.030000  Loss: -1.8205  Acc@1: 68.7500 (67.5899)  Acc@5: 93.7500 (93.6630)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:35  Lr: 0.030000  Loss: -2.0363  Acc@1: 68.7500 (67.5595)  Acc@5: 93.7500 (93.6508)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 450/1142]  eta: 0:04:32  Lr: 0.030000  Loss: -2.0535  Acc@1: 68.7500 (67.4889)  Acc@5: 93.7500 (93.5976)  time: 0.3917  data: 0.0006  max mem: 2912
Train: Epoch[4/5]  [ 460/1142]  eta: 0:04:28  Lr: 0.030000  Loss: -1.9811  Acc@1: 68.7500 (67.5298)  Acc@5: 93.7500 (93.6280)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 470/1142]  eta: 0:04:24  Lr: 0.030000  Loss: -1.9682  Acc@1: 68.7500 (67.6088)  Acc@5: 100.0000 (93.7102)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 480/1142]  eta: 0:04:20  Lr: 0.030000  Loss: -1.9918  Acc@1: 68.7500 (67.6195)  Acc@5: 100.0000 (93.7240)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 490/1142]  eta: 0:04:16  Lr: 0.030000  Loss: -2.1292  Acc@1: 68.7500 (67.6935)  Acc@5: 93.7500 (93.7500)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 500/1142]  eta: 0:04:12  Lr: 0.030000  Loss: -2.1553  Acc@1: 75.0000 (67.8767)  Acc@5: 93.7500 (93.7625)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 510/1142]  eta: 0:04:08  Lr: 0.030000  Loss: -1.9816  Acc@1: 75.0000 (67.8694)  Acc@5: 93.7500 (93.7378)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 520/1142]  eta: 0:04:04  Lr: 0.030000  Loss: -2.1884  Acc@1: 68.7500 (67.9583)  Acc@5: 93.7500 (93.7860)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 530/1142]  eta: 0:04:00  Lr: 0.030000  Loss: -1.8840  Acc@1: 68.7500 (67.8437)  Acc@5: 93.7500 (93.7971)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:56  Lr: 0.030000  Loss: -2.1716  Acc@1: 62.5000 (67.8142)  Acc@5: 93.7500 (93.7847)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:52  Lr: 0.030000  Loss: -2.4439  Acc@1: 68.7500 (67.8312)  Acc@5: 93.7500 (93.7613)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:48  Lr: 0.030000  Loss: -1.4236  Acc@1: 68.7500 (67.8365)  Acc@5: 93.7500 (93.7611)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:44  Lr: 0.030000  Loss: -2.2168  Acc@1: 68.7500 (67.7649)  Acc@5: 93.7500 (93.7609)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:40  Lr: 0.030000  Loss: -2.0702  Acc@1: 62.5000 (67.6420)  Acc@5: 93.7500 (93.7285)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:36  Lr: 0.030000  Loss: -1.6939  Acc@1: 56.2500 (67.5444)  Acc@5: 93.7500 (93.7288)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:32  Lr: 0.030000  Loss: -2.2405  Acc@1: 62.5000 (67.5957)  Acc@5: 93.7500 (93.7396)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:28  Lr: 0.030000  Loss: -1.3804  Acc@1: 68.7500 (67.5839)  Acc@5: 93.7500 (93.7705)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:24  Lr: 0.030000  Loss: -2.1162  Acc@1: 62.5000 (67.6127)  Acc@5: 93.7500 (93.7500)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 630/1142]  eta: 0:03:20  Lr: 0.030000  Loss: -1.9983  Acc@1: 68.7500 (67.5416)  Acc@5: 93.7500 (93.7698)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 640/1142]  eta: 0:03:16  Lr: 0.030000  Loss: -1.6959  Acc@1: 68.7500 (67.5410)  Acc@5: 93.7500 (93.8085)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 650/1142]  eta: 0:03:13  Lr: 0.030000  Loss: -1.4931  Acc@1: 68.7500 (67.5691)  Acc@5: 93.7500 (93.8172)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 660/1142]  eta: 0:03:09  Lr: 0.030000  Loss: -2.2035  Acc@1: 68.7500 (67.5681)  Acc@5: 100.0000 (93.8918)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 670/1142]  eta: 0:03:05  Lr: 0.030000  Loss: -0.8808  Acc@1: 62.5000 (67.4553)  Acc@5: 100.0000 (93.8618)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 680/1142]  eta: 0:03:01  Lr: 0.030000  Loss: -2.5395  Acc@1: 62.5000 (67.4009)  Acc@5: 93.7500 (93.8142)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:57  Lr: 0.030000  Loss: -1.9009  Acc@1: 62.5000 (67.4385)  Acc@5: 93.7500 (93.7681)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:53  Lr: 0.030000  Loss: -1.8251  Acc@1: 62.5000 (67.4037)  Acc@5: 93.7500 (93.7411)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:49  Lr: 0.030000  Loss: -2.1022  Acc@1: 62.5000 (67.4139)  Acc@5: 93.7500 (93.7588)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:45  Lr: 0.030000  Loss: -2.2822  Acc@1: 68.7500 (67.4757)  Acc@5: 93.7500 (93.7847)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:41  Lr: 0.030000  Loss: -2.0020  Acc@1: 68.7500 (67.5103)  Acc@5: 100.0000 (93.8184)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:37  Lr: 0.030000  Loss: -1.0986  Acc@1: 68.7500 (67.4764)  Acc@5: 93.7500 (93.8090)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:33  Lr: 0.030000  Loss: -2.6050  Acc@1: 68.7500 (67.4517)  Acc@5: 93.7500 (93.7999)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:29  Lr: 0.030000  Loss: -1.2242  Acc@1: 68.7500 (67.4934)  Acc@5: 100.0000 (93.8321)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:25  Lr: 0.030000  Loss: -2.1131  Acc@1: 68.7500 (67.4692)  Acc@5: 100.0000 (93.8635)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:21  Lr: 0.030000  Loss: -2.2674  Acc@1: 68.7500 (67.5496)  Acc@5: 93.7500 (93.8540)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:18  Lr: 0.030000  Loss: -1.4882  Acc@1: 68.7500 (67.5648)  Acc@5: 93.7500 (93.8527)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 800/1142]  eta: 0:02:14  Lr: 0.030000  Loss: -2.1650  Acc@1: 68.7500 (67.5952)  Acc@5: 93.7500 (93.9061)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 810/1142]  eta: 0:02:10  Lr: 0.030000  Loss: -2.4312  Acc@1: 75.0000 (67.6480)  Acc@5: 100.0000 (93.9118)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 820/1142]  eta: 0:02:06  Lr: 0.030000  Loss: -1.8855  Acc@1: 68.7500 (67.6462)  Acc@5: 93.7500 (93.9023)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 830/1142]  eta: 0:02:02  Lr: 0.030000  Loss: -2.3190  Acc@1: 68.7500 (67.6670)  Acc@5: 93.7500 (93.9155)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:58  Lr: 0.030000  Loss: -2.1195  Acc@1: 62.5000 (67.5981)  Acc@5: 93.7500 (93.9061)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:54  Lr: 0.030000  Loss: -1.9434  Acc@1: 62.5000 (67.6190)  Acc@5: 93.7500 (93.8969)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:50  Lr: 0.030000  Loss: -2.0659  Acc@1: 62.5000 (67.5523)  Acc@5: 87.5000 (93.8734)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:46  Lr: 0.030000  Loss: -1.8459  Acc@1: 68.7500 (67.5373)  Acc@5: 93.7500 (93.8863)  time: 0.3926  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:42  Lr: 0.030000  Loss: -1.7810  Acc@1: 68.7500 (67.5724)  Acc@5: 93.7500 (93.8706)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:38  Lr: 0.030000  Loss: -1.7551  Acc@1: 68.7500 (67.5154)  Acc@5: 93.7500 (93.8622)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:34  Lr: 0.030000  Loss: -1.9722  Acc@1: 68.7500 (67.5916)  Acc@5: 93.7500 (93.9026)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:30  Lr: 0.030000  Loss: -1.9327  Acc@1: 75.0000 (67.6866)  Acc@5: 93.7500 (93.9009)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:27  Lr: 0.030000  Loss: -1.3686  Acc@1: 75.0000 (67.6982)  Acc@5: 93.7500 (93.9129)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:23  Lr: 0.030000  Loss: -1.9991  Acc@1: 68.7500 (67.7229)  Acc@5: 93.7500 (93.9245)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:19  Lr: 0.030000  Loss: -1.8289  Acc@1: 68.7500 (67.7471)  Acc@5: 93.7500 (93.9360)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:15  Lr: 0.030000  Loss: -2.4253  Acc@1: 68.7500 (67.7050)  Acc@5: 93.7500 (93.9274)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:11  Lr: 0.030000  Loss: -1.9005  Acc@1: 68.7500 (67.6769)  Acc@5: 93.7500 (93.9386)  time: 0.3923  data: 0.0006  max mem: 2912
Train: Epoch[4/5]  [ 970/1142]  eta: 0:01:07  Lr: 0.030000  Loss: -1.3234  Acc@1: 68.7500 (67.6622)  Acc@5: 93.7500 (93.9109)  time: 0.3916  data: 0.0007  max mem: 2912
Train: Epoch[4/5]  [ 980/1142]  eta: 0:01:03  Lr: 0.030000  Loss: -2.1281  Acc@1: 62.5000 (67.6606)  Acc@5: 93.7500 (93.9220)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:59  Lr: 0.030000  Loss: -1.7057  Acc@1: 62.5000 (67.6463)  Acc@5: 93.7500 (93.9455)  time: 0.3913  data: 0.0006  max mem: 2912
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:55  Lr: 0.030000  Loss: -2.1691  Acc@1: 68.7500 (67.6823)  Acc@5: 93.7500 (93.9685)  time: 0.3911  data: 0.0006  max mem: 2912
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:51  Lr: 0.030000  Loss: -1.4149  Acc@1: 68.7500 (67.7423)  Acc@5: 93.7500 (93.9664)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:47  Lr: 0.030000  Loss: -1.6588  Acc@1: 68.7500 (67.7032)  Acc@5: 93.7500 (93.9704)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:43  Lr: 0.030000  Loss: -1.8497  Acc@1: 68.7500 (67.7679)  Acc@5: 93.7500 (93.9804)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:39  Lr: 0.030000  Loss: -2.3014  Acc@1: 75.0000 (67.8014)  Acc@5: 100.0000 (94.0082)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:36  Lr: 0.030000  Loss: -1.7847  Acc@1: 68.7500 (67.8045)  Acc@5: 100.0000 (94.0117)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:32  Lr: 0.030000  Loss: -2.0821  Acc@1: 75.0000 (67.8605)  Acc@5: 100.0000 (94.0504)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:28  Lr: 0.030000  Loss: -1.4248  Acc@1: 68.7500 (67.8455)  Acc@5: 93.7500 (94.0243)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:24  Lr: 0.030000  Loss: -2.2277  Acc@1: 68.7500 (67.8943)  Acc@5: 93.7500 (94.0506)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:20  Lr: 0.030000  Loss: -1.7485  Acc@1: 68.7500 (67.8449)  Acc@5: 93.7500 (94.0422)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:16  Lr: 0.030000  Loss: -2.1429  Acc@1: 68.7500 (67.8190)  Acc@5: 93.7500 (94.0282)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:12  Lr: 0.030000  Loss: -1.8426  Acc@1: 68.7500 (67.8499)  Acc@5: 93.7500 (94.0369)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:08  Lr: 0.030000  Loss: -1.2732  Acc@1: 68.7500 (67.8802)  Acc@5: 93.7500 (94.0455)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: -1.1214  Acc@1: 68.7500 (67.8769)  Acc@5: 93.7500 (94.0374)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -2.1078  Acc@1: 62.5000 (67.8078)  Acc@5: 93.7500 (94.0458)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -2.4920  Acc@1: 68.7500 (67.8182)  Acc@5: 93.7500 (94.0487)  time: 0.3836  data: 0.0004  max mem: 2912
Train: Epoch[4/5] Total time: 0:07:27 (0.3921 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -2.4920  Acc@1: 68.7500 (67.8182)  Acc@5: 93.7500 (94.0487)
Train: Epoch[5/5]  [   0/1142]  eta: 0:14:47  Lr: 0.030000  Loss: -1.8541  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.7770  data: 0.3851  max mem: 2912
Train: Epoch[5/5]  [  10/1142]  eta: 0:08:02  Lr: 0.030000  Loss: -1.3719  Acc@1: 62.5000 (63.0682)  Acc@5: 100.0000 (96.5909)  time: 0.4266  data: 0.0355  max mem: 2912
Train: Epoch[5/5]  [  20/1142]  eta: 0:07:39  Lr: 0.030000  Loss: -1.4857  Acc@1: 62.5000 (65.4762)  Acc@5: 93.7500 (95.2381)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [  30/1142]  eta: 0:07:28  Lr: 0.030000  Loss: -2.0275  Acc@1: 68.7500 (66.9355)  Acc@5: 93.7500 (95.1613)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  40/1142]  eta: 0:07:21  Lr: 0.030000  Loss: -1.9863  Acc@1: 68.7500 (67.9878)  Acc@5: 93.7500 (95.1220)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  50/1142]  eta: 0:07:15  Lr: 0.030000  Loss: -2.1992  Acc@1: 68.7500 (67.7696)  Acc@5: 93.7500 (95.2206)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  60/1142]  eta: 0:07:09  Lr: 0.030000  Loss: -2.4215  Acc@1: 68.7500 (68.1352)  Acc@5: 93.7500 (95.0820)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  70/1142]  eta: 0:07:04  Lr: 0.030000  Loss: -1.5921  Acc@1: 62.5000 (67.4296)  Acc@5: 93.7500 (94.8944)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [  80/1142]  eta: 0:07:00  Lr: 0.030000  Loss: -1.6212  Acc@1: 62.5000 (67.3611)  Acc@5: 93.7500 (94.8302)  time: 0.3903  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:55  Lr: 0.030000  Loss: -1.6654  Acc@1: 62.5000 (67.3764)  Acc@5: 93.7500 (94.5742)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:51  Lr: 0.030000  Loss: -2.2300  Acc@1: 68.7500 (67.2649)  Acc@5: 93.7500 (94.5545)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 110/1142]  eta: 0:06:47  Lr: 0.030000  Loss: -2.1551  Acc@1: 68.7500 (67.4550)  Acc@5: 93.7500 (94.5946)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 120/1142]  eta: 0:06:42  Lr: 0.030000  Loss: -2.0826  Acc@1: 68.7500 (67.8202)  Acc@5: 93.7500 (94.5764)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 130/1142]  eta: 0:06:38  Lr: 0.030000  Loss: -2.2656  Acc@1: 68.7500 (67.6527)  Acc@5: 93.7500 (94.4179)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 140/1142]  eta: 0:06:34  Lr: 0.030000  Loss: -2.2675  Acc@1: 68.7500 (67.8635)  Acc@5: 93.7500 (94.4149)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 150/1142]  eta: 0:06:30  Lr: 0.030000  Loss: -2.2177  Acc@1: 68.7500 (67.8394)  Acc@5: 93.7500 (94.3295)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 160/1142]  eta: 0:06:26  Lr: 0.030000  Loss: -1.8283  Acc@1: 68.7500 (67.3525)  Acc@5: 93.7500 (94.1382)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 170/1142]  eta: 0:06:22  Lr: 0.030000  Loss: -1.9439  Acc@1: 62.5000 (67.1053)  Acc@5: 93.7500 (94.1155)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 180/1142]  eta: 0:06:18  Lr: 0.030000  Loss: -2.3244  Acc@1: 68.7500 (67.2652)  Acc@5: 93.7500 (94.1644)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 190/1142]  eta: 0:06:14  Lr: 0.030000  Loss: -1.8764  Acc@1: 68.7500 (67.3429)  Acc@5: 93.7500 (94.2408)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 200/1142]  eta: 0:06:10  Lr: 0.030000  Loss: -1.5085  Acc@1: 68.7500 (67.4129)  Acc@5: 93.7500 (94.2164)  time: 0.3921  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [ 210/1142]  eta: 0:06:06  Lr: 0.030000  Loss: -1.9119  Acc@1: 68.7500 (67.3578)  Acc@5: 100.0000 (94.3720)  time: 0.3921  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [ 220/1142]  eta: 0:06:02  Lr: 0.030000  Loss: -2.1240  Acc@1: 68.7500 (67.4774)  Acc@5: 93.7500 (94.3439)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:58  Lr: 0.030000  Loss: -1.1561  Acc@1: 68.7500 (67.3160)  Acc@5: 93.7500 (94.1288)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:54  Lr: 0.030000  Loss: -1.0463  Acc@1: 62.5000 (67.2199)  Acc@5: 93.7500 (93.9834)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:50  Lr: 0.030000  Loss: -1.7212  Acc@1: 68.7500 (67.2062)  Acc@5: 93.7500 (93.9243)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:46  Lr: 0.030000  Loss: -1.8261  Acc@1: 68.7500 (67.3851)  Acc@5: 93.7500 (93.9176)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:42  Lr: 0.030000  Loss: -1.5778  Acc@1: 68.7500 (67.3893)  Acc@5: 93.7500 (93.8653)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 280/1142]  eta: 0:05:38  Lr: 0.030000  Loss: -1.9561  Acc@1: 68.7500 (67.6157)  Acc@5: 93.7500 (93.8612)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 290/1142]  eta: 0:05:34  Lr: 0.030000  Loss: -1.2123  Acc@1: 75.0000 (67.6117)  Acc@5: 93.7500 (93.8574)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 300/1142]  eta: 0:05:30  Lr: 0.030000  Loss: -1.8421  Acc@1: 68.7500 (67.5872)  Acc@5: 93.7500 (93.9161)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 310/1142]  eta: 0:05:26  Lr: 0.030000  Loss: -1.4258  Acc@1: 75.0000 (67.8055)  Acc@5: 93.7500 (93.8505)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 320/1142]  eta: 0:05:22  Lr: 0.030000  Loss: -1.5436  Acc@1: 75.0000 (67.8544)  Acc@5: 93.7500 (93.8668)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 330/1142]  eta: 0:05:18  Lr: 0.030000  Loss: -1.5065  Acc@1: 68.7500 (68.0136)  Acc@5: 93.7500 (93.9199)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 340/1142]  eta: 0:05:15  Lr: 0.030000  Loss: -1.6220  Acc@1: 75.0000 (68.2551)  Acc@5: 93.7500 (93.9333)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 350/1142]  eta: 0:05:11  Lr: 0.030000  Loss: -1.7584  Acc@1: 68.7500 (68.1090)  Acc@5: 93.7500 (93.9281)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 360/1142]  eta: 0:05:07  Lr: 0.030000  Loss: -1.8111  Acc@1: 68.7500 (68.0575)  Acc@5: 93.7500 (93.8366)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 370/1142]  eta: 0:05:03  Lr: 0.030000  Loss: -1.5739  Acc@1: 68.7500 (68.0088)  Acc@5: 93.7500 (93.8679)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:59  Lr: 0.030000  Loss: -2.2219  Acc@1: 68.7500 (68.0774)  Acc@5: 93.7500 (93.8156)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:55  Lr: 0.030000  Loss: -1.8692  Acc@1: 68.7500 (67.9987)  Acc@5: 93.7500 (93.7980)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:51  Lr: 0.030000  Loss: -1.6065  Acc@1: 68.7500 (68.0019)  Acc@5: 93.7500 (93.8123)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:47  Lr: 0.030000  Loss: -1.4229  Acc@1: 68.7500 (68.1569)  Acc@5: 93.7500 (93.8260)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:43  Lr: 0.030000  Loss: -0.8265  Acc@1: 75.0000 (68.1265)  Acc@5: 93.7500 (93.8242)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:39  Lr: 0.030000  Loss: -1.8540  Acc@1: 62.5000 (68.1265)  Acc@5: 93.7500 (93.8080)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:35  Lr: 0.030000  Loss: -2.1736  Acc@1: 68.7500 (68.2115)  Acc@5: 93.7500 (93.8209)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 450/1142]  eta: 0:04:31  Lr: 0.030000  Loss: -2.1927  Acc@1: 68.7500 (68.1818)  Acc@5: 93.7500 (93.8470)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 460/1142]  eta: 0:04:27  Lr: 0.030000  Loss: -2.0887  Acc@1: 68.7500 (68.2484)  Acc@5: 93.7500 (93.7636)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 470/1142]  eta: 0:04:23  Lr: 0.030000  Loss: -1.8930  Acc@1: 68.7500 (68.2988)  Acc@5: 93.7500 (93.8163)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 480/1142]  eta: 0:04:19  Lr: 0.030000  Loss: -1.6831  Acc@1: 75.0000 (68.3992)  Acc@5: 93.7500 (93.8150)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 490/1142]  eta: 0:04:16  Lr: 0.030000  Loss: -2.0149  Acc@1: 75.0000 (68.4954)  Acc@5: 93.7500 (93.8518)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 500/1142]  eta: 0:04:12  Lr: 0.030000  Loss: -1.2762  Acc@1: 75.0000 (68.5005)  Acc@5: 93.7500 (93.7874)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 510/1142]  eta: 0:04:08  Lr: 0.030000  Loss: -2.0302  Acc@1: 62.5000 (68.3831)  Acc@5: 93.7500 (93.7867)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 520/1142]  eta: 0:04:04  Lr: 0.030000  Loss: -2.5423  Acc@1: 68.7500 (68.4501)  Acc@5: 93.7500 (93.8460)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 530/1142]  eta: 0:04:00  Lr: 0.030000  Loss: -2.0094  Acc@1: 68.7500 (68.5264)  Acc@5: 100.0000 (93.8912)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:56  Lr: 0.030000  Loss: -1.3779  Acc@1: 68.7500 (68.4958)  Acc@5: 93.7500 (93.8424)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:52  Lr: 0.030000  Loss: -2.0150  Acc@1: 68.7500 (68.5912)  Acc@5: 93.7500 (93.8181)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:48  Lr: 0.030000  Loss: -1.4729  Acc@1: 68.7500 (68.4938)  Acc@5: 93.7500 (93.8725)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:44  Lr: 0.030000  Loss: -2.1681  Acc@1: 68.7500 (68.5311)  Acc@5: 100.0000 (93.9251)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:40  Lr: 0.030000  Loss: -1.5316  Acc@1: 75.0000 (68.6639)  Acc@5: 93.7500 (93.9329)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:36  Lr: 0.030000  Loss: -1.5453  Acc@1: 68.7500 (68.6442)  Acc@5: 93.7500 (93.9086)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:32  Lr: 0.030000  Loss: -2.1074  Acc@1: 68.7500 (68.6564)  Acc@5: 93.7500 (93.9268)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:28  Lr: 0.030000  Loss: -1.5328  Acc@1: 68.7500 (68.6170)  Acc@5: 93.7500 (93.9034)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:24  Lr: 0.030000  Loss: -1.9115  Acc@1: 62.5000 (68.4883)  Acc@5: 93.7500 (93.8909)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 630/1142]  eta: 0:03:20  Lr: 0.030000  Loss: -1.7606  Acc@1: 68.7500 (68.5519)  Acc@5: 93.7500 (93.9184)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 640/1142]  eta: 0:03:17  Lr: 0.030000  Loss: -1.6234  Acc@1: 68.7500 (68.4770)  Acc@5: 93.7500 (93.9158)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 650/1142]  eta: 0:03:13  Lr: 0.030000  Loss: -1.9023  Acc@1: 68.7500 (68.3660)  Acc@5: 93.7500 (93.8556)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 660/1142]  eta: 0:03:09  Lr: 0.030000  Loss: -1.8593  Acc@1: 56.2500 (68.2678)  Acc@5: 93.7500 (93.8540)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 670/1142]  eta: 0:03:05  Lr: 0.030000  Loss: -2.1589  Acc@1: 68.7500 (68.3588)  Acc@5: 93.7500 (93.8897)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 680/1142]  eta: 0:03:01  Lr: 0.030000  Loss: -1.2977  Acc@1: 68.7500 (68.2360)  Acc@5: 93.7500 (93.8510)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:57  Lr: 0.030000  Loss: -1.5024  Acc@1: 62.5000 (68.2254)  Acc@5: 93.7500 (93.8676)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:53  Lr: 0.030000  Loss: -2.4513  Acc@1: 62.5000 (68.2061)  Acc@5: 100.0000 (93.8837)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:49  Lr: 0.030000  Loss: -2.0271  Acc@1: 62.5000 (68.1874)  Acc@5: 93.7500 (93.8994)  time: 0.3919  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:45  Lr: 0.030000  Loss: -1.3714  Acc@1: 68.7500 (68.2126)  Acc@5: 100.0000 (93.9494)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:41  Lr: 0.030000  Loss: -2.1914  Acc@1: 75.0000 (68.2285)  Acc@5: 100.0000 (93.9808)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:37  Lr: 0.030000  Loss: -1.9468  Acc@1: 68.7500 (68.2524)  Acc@5: 100.0000 (93.9946)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:33  Lr: 0.030000  Loss: -2.0022  Acc@1: 68.7500 (68.3672)  Acc@5: 100.0000 (94.0330)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:29  Lr: 0.030000  Loss: -1.7698  Acc@1: 68.7500 (68.3394)  Acc@5: 93.7500 (94.0128)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:25  Lr: 0.030000  Loss: -1.6136  Acc@1: 62.5000 (68.3123)  Acc@5: 93.7500 (94.0337)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:22  Lr: 0.030000  Loss: -1.4808  Acc@1: 68.7500 (68.3419)  Acc@5: 93.7500 (94.0301)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:18  Lr: 0.030000  Loss: -1.4091  Acc@1: 62.5000 (68.2759)  Acc@5: 93.7500 (94.0186)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 800/1142]  eta: 0:02:14  Lr: 0.030000  Loss: -1.7360  Acc@1: 62.5000 (68.2740)  Acc@5: 93.7500 (94.0153)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 810/1142]  eta: 0:02:10  Lr: 0.030000  Loss: -2.3180  Acc@1: 68.7500 (68.3801)  Acc@5: 93.7500 (94.0197)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 820/1142]  eta: 0:02:06  Lr: 0.030000  Loss: -2.2404  Acc@1: 68.7500 (68.3770)  Acc@5: 93.7500 (94.0469)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 830/1142]  eta: 0:02:02  Lr: 0.030000  Loss: -1.6393  Acc@1: 68.7500 (68.4040)  Acc@5: 93.7500 (94.0433)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:58  Lr: 0.030000  Loss: -1.8594  Acc@1: 68.7500 (68.4230)  Acc@5: 93.7500 (94.0621)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:54  Lr: 0.030000  Loss: -2.0712  Acc@1: 68.7500 (68.4269)  Acc@5: 93.7500 (94.0585)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:50  Lr: 0.030000  Loss: -2.0059  Acc@1: 68.7500 (68.4161)  Acc@5: 93.7500 (94.0041)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:46  Lr: 0.030000  Loss: -2.0953  Acc@1: 68.7500 (68.4343)  Acc@5: 93.7500 (94.0083)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:42  Lr: 0.030000  Loss: -1.9244  Acc@1: 68.7500 (68.4946)  Acc@5: 93.7500 (93.9912)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:38  Lr: 0.030000  Loss: -2.4765  Acc@1: 75.0000 (68.5536)  Acc@5: 93.7500 (94.0166)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:34  Lr: 0.030000  Loss: -2.0986  Acc@1: 68.7500 (68.5419)  Acc@5: 93.7500 (94.0136)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:30  Lr: 0.030000  Loss: -1.8922  Acc@1: 68.7500 (68.5510)  Acc@5: 93.7500 (93.9833)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:27  Lr: 0.030000  Loss: -1.9162  Acc@1: 75.0000 (68.6143)  Acc@5: 100.0000 (94.0350)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:23  Lr: 0.030000  Loss: -1.7097  Acc@1: 75.0000 (68.6359)  Acc@5: 100.0000 (94.0454)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:19  Lr: 0.030000  Loss: -2.5487  Acc@1: 75.0000 (68.7434)  Acc@5: 93.7500 (94.0688)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:15  Lr: 0.030000  Loss: -0.9669  Acc@1: 75.0000 (68.7500)  Acc@5: 100.0000 (94.0720)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:11  Lr: 0.030000  Loss: -1.8795  Acc@1: 62.5000 (68.6785)  Acc@5: 93.7500 (94.0622)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 970/1142]  eta: 0:01:07  Lr: 0.030000  Loss: -1.8066  Acc@1: 62.5000 (68.6535)  Acc@5: 93.7500 (94.0847)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 980/1142]  eta: 0:01:03  Lr: 0.030000  Loss: -1.7067  Acc@1: 62.5000 (68.6035)  Acc@5: 93.7500 (94.0749)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:59  Lr: 0.030000  Loss: -2.0333  Acc@1: 68.7500 (68.6806)  Acc@5: 93.7500 (94.0843)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:55  Lr: 0.030000  Loss: -1.6490  Acc@1: 75.0000 (68.7000)  Acc@5: 93.7500 (94.0934)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:51  Lr: 0.030000  Loss: -1.5661  Acc@1: 68.7500 (68.6573)  Acc@5: 93.7500 (94.0776)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:47  Lr: 0.030000  Loss: -2.4346  Acc@1: 68.7500 (68.6459)  Acc@5: 93.7500 (94.0744)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:43  Lr: 0.030000  Loss: -0.8505  Acc@1: 68.7500 (68.6348)  Acc@5: 93.7500 (94.0774)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:39  Lr: 0.030000  Loss: -1.5396  Acc@1: 62.5000 (68.5519)  Acc@5: 93.7500 (94.0262)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:36  Lr: 0.030000  Loss: -1.6331  Acc@1: 62.5000 (68.5181)  Acc@5: 93.7500 (94.0414)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:32  Lr: 0.030000  Loss: -1.7796  Acc@1: 68.7500 (68.5556)  Acc@5: 93.7500 (94.0328)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:28  Lr: 0.030000  Loss: -1.6902  Acc@1: 68.7500 (68.5282)  Acc@5: 93.7500 (94.0359)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:24  Lr: 0.030000  Loss: -0.6275  Acc@1: 62.5000 (68.4956)  Acc@5: 93.7500 (94.0275)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:20  Lr: 0.030000  Loss: -1.5064  Acc@1: 62.5000 (68.4922)  Acc@5: 93.7500 (94.0364)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:16  Lr: 0.030000  Loss: -1.4649  Acc@1: 68.7500 (68.5229)  Acc@5: 93.7500 (94.0452)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:12  Lr: 0.030000  Loss: -1.6727  Acc@1: 68.7500 (68.5025)  Acc@5: 93.7500 (94.0369)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:08  Lr: 0.030000  Loss: -1.9743  Acc@1: 62.5000 (68.4935)  Acc@5: 93.7500 (94.0343)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: -2.0384  Acc@1: 68.7500 (68.5400)  Acc@5: 93.7500 (94.0374)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -2.1584  Acc@1: 62.5000 (68.5090)  Acc@5: 93.7500 (94.0239)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -1.9832  Acc@1: 62.5000 (68.5026)  Acc@5: 93.7500 (94.0268)  time: 0.3850  data: 0.0005  max mem: 2912
Train: Epoch[5/5] Total time: 0:07:27 (0.3921 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -1.9832  Acc@1: 62.5000 (68.5026)  Acc@5: 93.7500 (94.0268)
Test: [Task 1]  [   0/1627]  eta: 0:17:41  Loss: 1.0600 (1.0600)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6527  data: 0.4076  max mem: 2912
Test: [Task 1]  [  10/1627]  eta: 0:07:34  Loss: 0.7636 (0.7154)  Acc@1: 75.0000 (78.4091)  Acc@5: 100.0000 (96.0227)  time: 0.2809  data: 0.0373  max mem: 2912
Test: [Task 1]  [  20/1627]  eta: 0:07:05  Loss: 0.7336 (0.7466)  Acc@1: 81.2500 (78.5714)  Acc@5: 93.7500 (95.2381)  time: 0.2451  data: 0.0003  max mem: 2912
Test: [Task 1]  [  30/1627]  eta: 0:06:51  Loss: 0.6805 (0.7222)  Acc@1: 81.2500 (79.4355)  Acc@5: 93.7500 (95.7661)  time: 0.2450  data: 0.0004  max mem: 2912
Test: [Task 1]  [  40/1627]  eta: 0:06:43  Loss: 0.7240 (0.7430)  Acc@1: 81.2500 (78.6585)  Acc@5: 100.0000 (95.7317)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [  50/1627]  eta: 0:06:37  Loss: 0.7240 (0.7355)  Acc@1: 81.2500 (79.0441)  Acc@5: 100.0000 (95.8333)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [  60/1627]  eta: 0:06:33  Loss: 0.7110 (0.7502)  Acc@1: 75.0000 (78.7910)  Acc@5: 93.7500 (95.7992)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [  70/1627]  eta: 0:06:29  Loss: 0.6785 (0.7479)  Acc@1: 81.2500 (78.8732)  Acc@5: 93.7500 (95.9507)  time: 0.2457  data: 0.0004  max mem: 2912
Test: [Task 1]  [  80/1627]  eta: 0:06:26  Loss: 0.6081 (0.7393)  Acc@1: 81.2500 (78.7037)  Acc@5: 100.0000 (96.3735)  time: 0.2459  data: 0.0004  max mem: 2912
Test: [Task 1]  [  90/1627]  eta: 0:06:22  Loss: 0.7413 (0.7523)  Acc@1: 75.0000 (78.6401)  Acc@5: 100.0000 (96.2225)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 100/1627]  eta: 0:06:19  Loss: 0.8702 (0.7702)  Acc@1: 75.0000 (78.2797)  Acc@5: 93.7500 (96.0396)  time: 0.2445  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 110/1627]  eta: 0:06:16  Loss: 0.6729 (0.7605)  Acc@1: 75.0000 (78.4347)  Acc@5: 100.0000 (96.2838)  time: 0.2447  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 120/1627]  eta: 0:06:13  Loss: 0.6553 (0.7645)  Acc@1: 81.2500 (78.5640)  Acc@5: 100.0000 (96.1777)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 130/1627]  eta: 0:06:10  Loss: 0.6563 (0.7607)  Acc@1: 81.2500 (78.7214)  Acc@5: 93.7500 (96.2309)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 140/1627]  eta: 0:06:07  Loss: 0.6563 (0.7567)  Acc@1: 75.0000 (78.4574)  Acc@5: 100.0000 (96.3209)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 150/1627]  eta: 0:06:05  Loss: 0.6500 (0.7506)  Acc@1: 75.0000 (78.7252)  Acc@5: 100.0000 (96.3990)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 160/1627]  eta: 0:06:02  Loss: 0.6653 (0.7482)  Acc@1: 81.2500 (78.8820)  Acc@5: 100.0000 (96.3509)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 170/1627]  eta: 0:05:59  Loss: 0.6901 (0.7429)  Acc@1: 81.2500 (78.9108)  Acc@5: 100.0000 (96.4547)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 180/1627]  eta: 0:05:56  Loss: 0.6508 (0.7438)  Acc@1: 81.2500 (78.9365)  Acc@5: 100.0000 (96.5124)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 190/1627]  eta: 0:05:54  Loss: 0.6846 (0.7396)  Acc@1: 81.2500 (79.1885)  Acc@5: 100.0000 (96.4660)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 200/1627]  eta: 0:05:51  Loss: 0.7969 (0.7389)  Acc@1: 81.2500 (79.1045)  Acc@5: 93.7500 (96.4241)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 210/1627]  eta: 0:05:48  Loss: 0.6964 (0.7384)  Acc@1: 75.0000 (79.1173)  Acc@5: 93.7500 (96.4159)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 220/1627]  eta: 0:05:46  Loss: 0.6964 (0.7381)  Acc@1: 75.0000 (79.1290)  Acc@5: 100.0000 (96.4367)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 230/1627]  eta: 0:05:43  Loss: 0.7254 (0.7364)  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (96.4556)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 240/1627]  eta: 0:05:40  Loss: 0.6016 (0.7336)  Acc@1: 81.2500 (79.2012)  Acc@5: 100.0000 (96.4990)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 250/1627]  eta: 0:05:38  Loss: 0.6019 (0.7399)  Acc@1: 81.2500 (79.2082)  Acc@5: 93.7500 (96.4143)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 260/1627]  eta: 0:05:35  Loss: 0.6921 (0.7388)  Acc@1: 81.2500 (79.1906)  Acc@5: 100.0000 (96.4320)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 270/1627]  eta: 0:05:33  Loss: 0.6442 (0.7330)  Acc@1: 81.2500 (79.2897)  Acc@5: 100.0000 (96.5406)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 280/1627]  eta: 0:05:30  Loss: 0.7318 (0.7344)  Acc@1: 81.2500 (79.2927)  Acc@5: 100.0000 (96.4413)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 290/1627]  eta: 0:05:28  Loss: 0.7812 (0.7372)  Acc@1: 81.2500 (79.3385)  Acc@5: 100.0000 (96.4777)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 300/1627]  eta: 0:05:25  Loss: 0.6923 (0.7360)  Acc@1: 81.2500 (79.4435)  Acc@5: 100.0000 (96.4701)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 310/1627]  eta: 0:05:23  Loss: 0.6283 (0.7354)  Acc@1: 81.2500 (79.5016)  Acc@5: 100.0000 (96.4831)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 320/1627]  eta: 0:05:20  Loss: 0.5987 (0.7304)  Acc@1: 81.2500 (79.6145)  Acc@5: 100.0000 (96.5537)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 330/1627]  eta: 0:05:18  Loss: 0.5114 (0.7311)  Acc@1: 81.2500 (79.5506)  Acc@5: 100.0000 (96.5257)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 340/1627]  eta: 0:05:15  Loss: 0.6367 (0.7348)  Acc@1: 75.0000 (79.5088)  Acc@5: 100.0000 (96.5359)  time: 0.2446  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 350/1627]  eta: 0:05:13  Loss: 0.6367 (0.7342)  Acc@1: 81.2500 (79.5228)  Acc@5: 100.0000 (96.5278)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 360/1627]  eta: 0:05:10  Loss: 0.6487 (0.7343)  Acc@1: 81.2500 (79.5533)  Acc@5: 93.7500 (96.5028)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 370/1627]  eta: 0:05:07  Loss: 0.6109 (0.7337)  Acc@1: 81.2500 (79.6496)  Acc@5: 100.0000 (96.5128)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 380/1627]  eta: 0:05:05  Loss: 0.6284 (0.7337)  Acc@1: 87.5000 (79.6588)  Acc@5: 100.0000 (96.5223)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 390/1627]  eta: 0:05:02  Loss: 0.6819 (0.7338)  Acc@1: 75.0000 (79.5716)  Acc@5: 100.0000 (96.5313)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 400/1627]  eta: 0:05:00  Loss: 0.5393 (0.7324)  Acc@1: 75.0000 (79.5667)  Acc@5: 100.0000 (96.5867)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 410/1627]  eta: 0:04:57  Loss: 0.7083 (0.7364)  Acc@1: 81.2500 (79.4860)  Acc@5: 100.0000 (96.5176)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 420/1627]  eta: 0:04:55  Loss: 0.6796 (0.7352)  Acc@1: 81.2500 (79.5428)  Acc@5: 93.7500 (96.5410)  time: 0.2435  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 430/1627]  eta: 0:04:52  Loss: 0.6322 (0.7346)  Acc@1: 75.0000 (79.4954)  Acc@5: 100.0000 (96.5632)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 440/1627]  eta: 0:04:50  Loss: 0.6466 (0.7335)  Acc@1: 75.0000 (79.4926)  Acc@5: 100.0000 (96.5420)  time: 0.2442  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 450/1627]  eta: 0:04:48  Loss: 0.6610 (0.7346)  Acc@1: 75.0000 (79.4207)  Acc@5: 100.0000 (96.4939)  time: 0.2447  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 460/1627]  eta: 0:04:45  Loss: 0.6667 (0.7328)  Acc@1: 81.2500 (79.4604)  Acc@5: 100.0000 (96.4886)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 470/1627]  eta: 0:04:43  Loss: 0.5792 (0.7304)  Acc@1: 81.2500 (79.4719)  Acc@5: 100.0000 (96.5101)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 480/1627]  eta: 0:04:40  Loss: 0.6305 (0.7313)  Acc@1: 81.2500 (79.4958)  Acc@5: 100.0000 (96.4917)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 490/1627]  eta: 0:04:38  Loss: 0.7376 (0.7335)  Acc@1: 75.0000 (79.4552)  Acc@5: 93.7500 (96.4613)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 500/1627]  eta: 0:04:35  Loss: 0.7409 (0.7349)  Acc@1: 75.0000 (79.4286)  Acc@5: 93.7500 (96.4571)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 510/1627]  eta: 0:04:33  Loss: 0.7825 (0.7385)  Acc@1: 81.2500 (79.4765)  Acc@5: 93.7500 (96.4163)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 520/1627]  eta: 0:04:30  Loss: 0.7817 (0.7455)  Acc@1: 81.2500 (79.4626)  Acc@5: 93.7500 (96.3292)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 530/1627]  eta: 0:04:28  Loss: 0.7413 (0.7440)  Acc@1: 75.0000 (79.4492)  Acc@5: 100.0000 (96.3630)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 540/1627]  eta: 0:04:25  Loss: 0.6333 (0.7429)  Acc@1: 81.2500 (79.4593)  Acc@5: 100.0000 (96.3725)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 550/1627]  eta: 0:04:23  Loss: 0.6799 (0.7442)  Acc@1: 81.2500 (79.4124)  Acc@5: 100.0000 (96.3929)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 560/1627]  eta: 0:04:20  Loss: 0.7794 (0.7462)  Acc@1: 75.0000 (79.3449)  Acc@5: 100.0000 (96.3904)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 570/1627]  eta: 0:04:18  Loss: 0.7794 (0.7448)  Acc@1: 81.2500 (79.4221)  Acc@5: 93.7500 (96.3989)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 580/1627]  eta: 0:04:15  Loss: 0.4698 (0.7446)  Acc@1: 81.2500 (79.4105)  Acc@5: 100.0000 (96.4393)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 590/1627]  eta: 0:04:13  Loss: 0.6046 (0.7440)  Acc@1: 81.2500 (79.4416)  Acc@5: 100.0000 (96.4467)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 600/1627]  eta: 0:04:10  Loss: 0.6024 (0.7440)  Acc@1: 81.2500 (79.4093)  Acc@5: 100.0000 (96.4642)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 610/1627]  eta: 0:04:08  Loss: 0.6777 (0.7433)  Acc@1: 81.2500 (79.4804)  Acc@5: 93.7500 (96.4505)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 620/1627]  eta: 0:04:05  Loss: 0.6965 (0.7444)  Acc@1: 81.2500 (79.4283)  Acc@5: 93.7500 (96.3969)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 630/1627]  eta: 0:04:03  Loss: 0.6965 (0.7469)  Acc@1: 75.0000 (79.3384)  Acc@5: 93.7500 (96.3649)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 640/1627]  eta: 0:04:01  Loss: 0.7980 (0.7469)  Acc@1: 75.0000 (79.3194)  Acc@5: 93.7500 (96.3631)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 650/1627]  eta: 0:03:58  Loss: 0.6917 (0.7452)  Acc@1: 81.2500 (79.3395)  Acc@5: 100.0000 (96.3998)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 660/1627]  eta: 0:03:56  Loss: 0.6853 (0.7442)  Acc@1: 75.0000 (79.3400)  Acc@5: 100.0000 (96.3880)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 670/1627]  eta: 0:03:53  Loss: 0.7559 (0.7452)  Acc@1: 75.0000 (79.2567)  Acc@5: 100.0000 (96.4046)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 680/1627]  eta: 0:03:51  Loss: 0.7659 (0.7461)  Acc@1: 75.0000 (79.2493)  Acc@5: 100.0000 (96.3840)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 690/1627]  eta: 0:03:48  Loss: 0.7388 (0.7444)  Acc@1: 81.2500 (79.3234)  Acc@5: 93.7500 (96.3640)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 700/1627]  eta: 0:03:46  Loss: 0.7387 (0.7448)  Acc@1: 81.2500 (79.3331)  Acc@5: 93.7500 (96.3445)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 710/1627]  eta: 0:03:43  Loss: 0.7076 (0.7433)  Acc@1: 81.2500 (79.4040)  Acc@5: 100.0000 (96.3608)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 720/1627]  eta: 0:03:41  Loss: 0.5736 (0.7408)  Acc@1: 87.5000 (79.4816)  Acc@5: 100.0000 (96.3939)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 730/1627]  eta: 0:03:39  Loss: 0.5992 (0.7405)  Acc@1: 87.5000 (79.5229)  Acc@5: 100.0000 (96.4090)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 740/1627]  eta: 0:03:36  Loss: 0.7920 (0.7423)  Acc@1: 81.2500 (79.4872)  Acc@5: 100.0000 (96.3984)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 750/1627]  eta: 0:03:34  Loss: 0.7920 (0.7417)  Acc@1: 81.2500 (79.5107)  Acc@5: 100.0000 (96.4131)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 760/1627]  eta: 0:03:31  Loss: 0.8009 (0.7447)  Acc@1: 75.0000 (79.5089)  Acc@5: 100.0000 (96.3781)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 770/1627]  eta: 0:03:29  Loss: 0.5501 (0.7421)  Acc@1: 81.2500 (79.5639)  Acc@5: 100.0000 (96.4089)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 780/1627]  eta: 0:03:26  Loss: 0.4653 (0.7389)  Acc@1: 81.2500 (79.6735)  Acc@5: 100.0000 (96.4389)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 790/1627]  eta: 0:03:24  Loss: 0.4993 (0.7391)  Acc@1: 81.2500 (79.6776)  Acc@5: 100.0000 (96.4286)  time: 0.2443  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 800/1627]  eta: 0:03:21  Loss: 0.6517 (0.7391)  Acc@1: 81.2500 (79.6582)  Acc@5: 93.7500 (96.4263)  time: 0.2443  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 810/1627]  eta: 0:03:19  Loss: 0.6418 (0.7385)  Acc@1: 81.2500 (79.6625)  Acc@5: 100.0000 (96.4396)  time: 0.2447  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 820/1627]  eta: 0:03:17  Loss: 0.5803 (0.7374)  Acc@1: 81.2500 (79.6894)  Acc@5: 100.0000 (96.4297)  time: 0.2448  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 830/1627]  eta: 0:03:14  Loss: 0.6441 (0.7374)  Acc@1: 81.2500 (79.6931)  Acc@5: 100.0000 (96.4200)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 840/1627]  eta: 0:03:12  Loss: 0.6571 (0.7357)  Acc@1: 81.2500 (79.7414)  Acc@5: 100.0000 (96.4477)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 850/1627]  eta: 0:03:09  Loss: 0.6802 (0.7375)  Acc@1: 75.0000 (79.7077)  Acc@5: 100.0000 (96.4454)  time: 0.2449  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 860/1627]  eta: 0:03:07  Loss: 0.6802 (0.7365)  Acc@1: 81.2500 (79.7546)  Acc@5: 100.0000 (96.4649)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 870/1627]  eta: 0:03:04  Loss: 0.6000 (0.7358)  Acc@1: 87.5000 (79.8077)  Acc@5: 100.0000 (96.4624)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 880/1627]  eta: 0:03:02  Loss: 0.7284 (0.7377)  Acc@1: 81.2500 (79.7247)  Acc@5: 100.0000 (96.4600)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 890/1627]  eta: 0:02:59  Loss: 0.8572 (0.7397)  Acc@1: 75.0000 (79.6787)  Acc@5: 100.0000 (96.4436)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 900/1627]  eta: 0:02:57  Loss: 0.6158 (0.7395)  Acc@1: 75.0000 (79.6962)  Acc@5: 100.0000 (96.4345)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 910/1627]  eta: 0:02:55  Loss: 0.5733 (0.7406)  Acc@1: 81.2500 (79.7064)  Acc@5: 100.0000 (96.4188)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 920/1627]  eta: 0:02:52  Loss: 0.6631 (0.7404)  Acc@1: 81.2500 (79.7299)  Acc@5: 100.0000 (96.4237)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 930/1627]  eta: 0:02:50  Loss: 0.7109 (0.7407)  Acc@1: 81.2500 (79.7462)  Acc@5: 100.0000 (96.4151)  time: 0.2447  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 940/1627]  eta: 0:02:47  Loss: 0.6488 (0.7387)  Acc@1: 81.2500 (79.8286)  Acc@5: 100.0000 (96.4267)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 950/1627]  eta: 0:02:45  Loss: 0.6398 (0.7383)  Acc@1: 81.2500 (79.8173)  Acc@5: 100.0000 (96.4380)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 960/1627]  eta: 0:02:42  Loss: 0.7002 (0.7377)  Acc@1: 81.2500 (79.8322)  Acc@5: 100.0000 (96.4490)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 970/1627]  eta: 0:02:40  Loss: 0.6430 (0.7376)  Acc@1: 81.2500 (79.7953)  Acc@5: 100.0000 (96.4534)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 980/1627]  eta: 0:02:37  Loss: 0.7944 (0.7380)  Acc@1: 81.2500 (79.7974)  Acc@5: 100.0000 (96.4322)  time: 0.2444  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 990/1627]  eta: 0:02:35  Loss: 0.8377 (0.7407)  Acc@1: 81.2500 (79.7742)  Acc@5: 93.7500 (96.4241)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [1000/1627]  eta: 0:02:33  Loss: 0.8103 (0.7404)  Acc@1: 81.2500 (79.7827)  Acc@5: 93.7500 (96.4286)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 1]  [1010/1627]  eta: 0:02:30  Loss: 0.6304 (0.7399)  Acc@1: 81.2500 (79.8281)  Acc@5: 100.0000 (96.4392)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 1]  [1020/1627]  eta: 0:02:28  Loss: 0.6489 (0.7399)  Acc@1: 81.2500 (79.7992)  Acc@5: 100.0000 (96.4373)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 1]  [1030/1627]  eta: 0:02:25  Loss: 0.6489 (0.7383)  Acc@1: 81.2500 (79.8375)  Acc@5: 100.0000 (96.4476)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 1]  [1040/1627]  eta: 0:02:23  Loss: 0.5701 (0.7370)  Acc@1: 81.2500 (79.8631)  Acc@5: 100.0000 (96.4697)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 1]  [1050/1627]  eta: 0:02:20  Loss: 0.6091 (0.7361)  Acc@1: 81.2500 (79.9001)  Acc@5: 100.0000 (96.4736)  time: 0.2442  data: 0.0004  max mem: 2912
Test: [Task 1]  [1060/1627]  eta: 0:02:18  Loss: 0.6787 (0.7370)  Acc@1: 81.2500 (79.8775)  Acc@5: 93.7500 (96.4538)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [1070/1627]  eta: 0:02:16  Loss: 0.7537 (0.7380)  Acc@1: 81.2500 (79.8611)  Acc@5: 93.7500 (96.4402)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [1080/1627]  eta: 0:02:13  Loss: 0.7457 (0.7383)  Acc@1: 75.0000 (79.8161)  Acc@5: 100.0000 (96.4500)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [1090/1627]  eta: 0:02:11  Loss: 0.7029 (0.7378)  Acc@1: 75.0000 (79.8293)  Acc@5: 100.0000 (96.4654)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1100/1627]  eta: 0:02:08  Loss: 0.6539 (0.7373)  Acc@1: 81.2500 (79.8252)  Acc@5: 100.0000 (96.4748)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1110/1627]  eta: 0:02:06  Loss: 0.6954 (0.7368)  Acc@1: 81.2500 (79.8155)  Acc@5: 100.0000 (96.4953)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [1120/1627]  eta: 0:02:03  Loss: 0.6954 (0.7380)  Acc@1: 81.2500 (79.7893)  Acc@5: 100.0000 (96.4819)  time: 0.2445  data: 0.0003  max mem: 2912
Test: [Task 1]  [1130/1627]  eta: 0:02:01  Loss: 0.7389 (0.7384)  Acc@1: 75.0000 (79.7635)  Acc@5: 93.7500 (96.4688)  time: 0.2447  data: 0.0004  max mem: 2912
Test: [Task 1]  [1140/1627]  eta: 0:01:58  Loss: 0.7389 (0.7393)  Acc@1: 75.0000 (79.7163)  Acc@5: 100.0000 (96.4833)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 1]  [1150/1627]  eta: 0:01:56  Loss: 0.7793 (0.7402)  Acc@1: 81.2500 (79.7079)  Acc@5: 100.0000 (96.4705)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [1160/1627]  eta: 0:01:54  Loss: 0.6960 (0.7399)  Acc@1: 81.2500 (79.7265)  Acc@5: 100.0000 (96.4686)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [1170/1627]  eta: 0:01:51  Loss: 0.5115 (0.7389)  Acc@1: 81.2500 (79.7449)  Acc@5: 100.0000 (96.4720)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 1]  [1180/1627]  eta: 0:01:49  Loss: 0.5681 (0.7393)  Acc@1: 81.2500 (79.7523)  Acc@5: 100.0000 (96.4807)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1190/1627]  eta: 0:01:46  Loss: 0.7355 (0.7391)  Acc@1: 81.2500 (79.7439)  Acc@5: 100.0000 (96.4840)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1200/1627]  eta: 0:01:44  Loss: 0.6506 (0.7390)  Acc@1: 81.2500 (79.7356)  Acc@5: 100.0000 (96.4717)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [1210/1627]  eta: 0:01:41  Loss: 0.5915 (0.7400)  Acc@1: 81.2500 (79.6965)  Acc@5: 93.7500 (96.4492)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1220/1627]  eta: 0:01:39  Loss: 0.5850 (0.7391)  Acc@1: 81.2500 (79.7297)  Acc@5: 100.0000 (96.4732)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 1]  [1230/1627]  eta: 0:01:36  Loss: 0.6283 (0.7398)  Acc@1: 81.2500 (79.7116)  Acc@5: 100.0000 (96.4511)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [1240/1627]  eta: 0:01:34  Loss: 0.7102 (0.7392)  Acc@1: 81.2500 (79.7190)  Acc@5: 100.0000 (96.4645)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1250/1627]  eta: 0:01:32  Loss: 0.7169 (0.7393)  Acc@1: 81.2500 (79.7662)  Acc@5: 100.0000 (96.4528)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [1260/1627]  eta: 0:01:29  Loss: 0.6582 (0.7392)  Acc@1: 81.2500 (79.7879)  Acc@5: 100.0000 (96.4463)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 1]  [1270/1627]  eta: 0:01:27  Loss: 0.6582 (0.7396)  Acc@1: 81.2500 (79.7699)  Acc@5: 93.7500 (96.4349)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1280/1627]  eta: 0:01:24  Loss: 0.6806 (0.7382)  Acc@1: 87.5000 (79.8107)  Acc@5: 100.0000 (96.4530)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [1290/1627]  eta: 0:01:22  Loss: 0.6690 (0.7378)  Acc@1: 81.2500 (79.8218)  Acc@5: 100.0000 (96.4562)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [1300/1627]  eta: 0:01:19  Loss: 0.6600 (0.7374)  Acc@1: 81.2500 (79.8568)  Acc@5: 100.0000 (96.4691)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [1310/1627]  eta: 0:01:17  Loss: 0.5782 (0.7366)  Acc@1: 87.5000 (79.8818)  Acc@5: 100.0000 (96.4769)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [1320/1627]  eta: 0:01:14  Loss: 0.5381 (0.7367)  Acc@1: 87.5000 (79.8685)  Acc@5: 100.0000 (96.4799)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [1330/1627]  eta: 0:01:12  Loss: 0.5302 (0.7359)  Acc@1: 87.5000 (79.8929)  Acc@5: 100.0000 (96.4923)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1340/1627]  eta: 0:01:10  Loss: 0.6591 (0.7366)  Acc@1: 81.2500 (79.8751)  Acc@5: 100.0000 (96.4905)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1350/1627]  eta: 0:01:07  Loss: 0.6920 (0.7360)  Acc@1: 81.2500 (79.9038)  Acc@5: 100.0000 (96.4933)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1360/1627]  eta: 0:01:05  Loss: 0.6692 (0.7362)  Acc@1: 81.2500 (79.8723)  Acc@5: 100.0000 (96.5145)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 1]  [1370/1627]  eta: 0:01:02  Loss: 0.6692 (0.7354)  Acc@1: 81.2500 (79.8915)  Acc@5: 100.0000 (96.5171)  time: 0.2442  data: 0.0004  max mem: 2912
Test: [Task 1]  [1380/1627]  eta: 0:01:00  Loss: 0.6167 (0.7350)  Acc@1: 81.2500 (79.9013)  Acc@5: 100.0000 (96.5243)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [1390/1627]  eta: 0:00:57  Loss: 0.8002 (0.7352)  Acc@1: 75.0000 (79.8931)  Acc@5: 100.0000 (96.5313)  time: 0.2446  data: 0.0004  max mem: 2912
Test: [Task 1]  [1400/1627]  eta: 0:00:55  Loss: 0.8805 (0.7353)  Acc@1: 75.0000 (79.8760)  Acc@5: 100.0000 (96.5159)  time: 0.2442  data: 0.0004  max mem: 2912
Test: [Task 1]  [1410/1627]  eta: 0:00:52  Loss: 0.6439 (0.7349)  Acc@1: 81.2500 (79.8990)  Acc@5: 100.0000 (96.5184)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [1420/1627]  eta: 0:00:50  Loss: 0.6290 (0.7346)  Acc@1: 81.2500 (79.9217)  Acc@5: 100.0000 (96.5209)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 1]  [1430/1627]  eta: 0:00:48  Loss: 0.8316 (0.7366)  Acc@1: 81.2500 (79.9048)  Acc@5: 93.7500 (96.4972)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 1]  [1440/1627]  eta: 0:00:45  Loss: 0.9233 (0.7374)  Acc@1: 81.2500 (79.8751)  Acc@5: 93.7500 (96.4825)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [1450/1627]  eta: 0:00:43  Loss: 0.8370 (0.7385)  Acc@1: 81.2500 (79.8501)  Acc@5: 93.7500 (96.4680)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1460/1627]  eta: 0:00:40  Loss: 0.7222 (0.7379)  Acc@1: 81.2500 (79.8854)  Acc@5: 100.0000 (96.4836)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1470/1627]  eta: 0:00:38  Loss: 0.6229 (0.7383)  Acc@1: 81.2500 (79.8776)  Acc@5: 100.0000 (96.4820)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 1]  [1480/1627]  eta: 0:00:35  Loss: 0.6595 (0.7388)  Acc@1: 81.2500 (79.8574)  Acc@5: 100.0000 (96.4889)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 1]  [1490/1627]  eta: 0:00:33  Loss: 0.6595 (0.7393)  Acc@1: 81.2500 (79.8541)  Acc@5: 100.0000 (96.4873)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [1500/1627]  eta: 0:00:30  Loss: 0.6720 (0.7396)  Acc@1: 81.2500 (79.8301)  Acc@5: 100.0000 (96.4898)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [1510/1627]  eta: 0:00:28  Loss: 0.6717 (0.7401)  Acc@1: 75.0000 (79.8188)  Acc@5: 100.0000 (96.4883)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1520/1627]  eta: 0:00:26  Loss: 0.5696 (0.7390)  Acc@1: 81.2500 (79.8570)  Acc@5: 100.0000 (96.4990)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1530/1627]  eta: 0:00:23  Loss: 0.6097 (0.7391)  Acc@1: 81.2500 (79.8539)  Acc@5: 100.0000 (96.4933)  time: 0.2435  data: 0.0004  max mem: 2912
Test: [Task 1]  [1540/1627]  eta: 0:00:21  Loss: 0.6113 (0.7378)  Acc@1: 87.5000 (79.9075)  Acc@5: 100.0000 (96.5039)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [1550/1627]  eta: 0:00:18  Loss: 0.5844 (0.7378)  Acc@1: 87.5000 (79.9001)  Acc@5: 100.0000 (96.5184)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1560/1627]  eta: 0:00:16  Loss: 0.5705 (0.7372)  Acc@1: 81.2500 (79.9127)  Acc@5: 100.0000 (96.5167)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [1570/1627]  eta: 0:00:13  Loss: 0.5585 (0.7370)  Acc@1: 81.2500 (79.9173)  Acc@5: 100.0000 (96.5189)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1580/1627]  eta: 0:00:11  Loss: 0.7211 (0.7367)  Acc@1: 81.2500 (79.9296)  Acc@5: 100.0000 (96.5212)  time: 0.2428  data: 0.0004  max mem: 2912
Test: [Task 1]  [1590/1627]  eta: 0:00:09  Loss: 0.7211 (0.7365)  Acc@1: 75.0000 (79.9183)  Acc@5: 100.0000 (96.5273)  time: 0.2435  data: 0.0004  max mem: 2912
Test: [Task 1]  [1600/1627]  eta: 0:00:06  Loss: 0.7553 (0.7373)  Acc@1: 75.0000 (79.8798)  Acc@5: 93.7500 (96.5100)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 1]  [1610/1627]  eta: 0:00:04  Loss: 0.6177 (0.7365)  Acc@1: 75.0000 (79.9115)  Acc@5: 100.0000 (96.5123)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.6177 (0.7360)  Acc@1: 81.2500 (79.9159)  Acc@5: 100.0000 (96.5222)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.6854 (0.7358)  Acc@1: 81.2500 (79.9324)  Acc@5: 100.0000 (96.5235)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1] Total time: 0:06:37 (0.2440 s / it)
* Acc@1 79.932 Acc@5 96.524 loss 0.736
Test: [Task 2]  [  0/625]  eta: 0:05:57  Loss: 0.1418 (0.1418)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5720  data: 0.3263  max mem: 2912
Test: [Task 2]  [ 10/625]  eta: 0:02:48  Loss: 0.0691 (0.0962)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  time: 0.2738  data: 0.0300  max mem: 2912
Test: [Task 2]  [ 20/625]  eta: 0:02:37  Loss: 0.0691 (0.1352)  Acc@1: 100.0000 (95.8333)  Acc@5: 100.0000 (99.7024)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 30/625]  eta: 0:02:31  Loss: 0.1557 (0.1689)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (99.5968)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 40/625]  eta: 0:02:27  Loss: 0.1900 (0.1814)  Acc@1: 93.7500 (94.0549)  Acc@5: 100.0000 (99.6951)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 50/625]  eta: 0:02:23  Loss: 0.1497 (0.1834)  Acc@1: 93.7500 (93.9951)  Acc@5: 100.0000 (99.7549)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 60/625]  eta: 0:02:20  Loss: 0.1338 (0.1818)  Acc@1: 93.7500 (94.2623)  Acc@5: 100.0000 (99.6926)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 70/625]  eta: 0:02:17  Loss: 0.1224 (0.1736)  Acc@1: 93.7500 (94.6303)  Acc@5: 100.0000 (99.7359)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 2]  [ 80/625]  eta: 0:02:14  Loss: 0.1224 (0.1700)  Acc@1: 93.7500 (94.8302)  Acc@5: 100.0000 (99.6914)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 2]  [ 90/625]  eta: 0:02:12  Loss: 0.1135 (0.1635)  Acc@1: 93.7500 (94.9176)  Acc@5: 100.0000 (99.7253)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 2]  [100/625]  eta: 0:02:09  Loss: 0.0957 (0.1596)  Acc@1: 93.7500 (95.1733)  Acc@5: 100.0000 (99.7525)  time: 0.2442  data: 0.0004  max mem: 2912
Test: [Task 2]  [110/625]  eta: 0:02:07  Loss: 0.0730 (0.1626)  Acc@1: 100.0000 (95.2140)  Acc@5: 100.0000 (99.7185)  time: 0.2450  data: 0.0003  max mem: 2912
Test: [Task 2]  [120/625]  eta: 0:02:04  Loss: 0.1239 (0.1647)  Acc@1: 93.7500 (95.1446)  Acc@5: 100.0000 (99.6384)  time: 0.2479  data: 0.0003  max mem: 2912
Test: [Task 2]  [130/625]  eta: 0:02:02  Loss: 0.1436 (0.1662)  Acc@1: 93.7500 (94.9905)  Acc@5: 100.0000 (99.6660)  time: 0.2490  data: 0.0004  max mem: 2912
Test: [Task 2]  [140/625]  eta: 0:01:59  Loss: 0.1409 (0.1724)  Acc@1: 93.7500 (94.8582)  Acc@5: 100.0000 (99.6011)  time: 0.2461  data: 0.0004  max mem: 2912
Test: [Task 2]  [150/625]  eta: 0:01:57  Loss: 0.1874 (0.1772)  Acc@1: 93.7500 (94.6606)  Acc@5: 100.0000 (99.5447)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 2]  [160/625]  eta: 0:01:54  Loss: 0.1965 (0.1812)  Acc@1: 93.7500 (94.6429)  Acc@5: 100.0000 (99.4953)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 2]  [170/625]  eta: 0:01:52  Loss: 0.1194 (0.1777)  Acc@1: 100.0000 (94.8830)  Acc@5: 100.0000 (99.4883)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 2]  [180/625]  eta: 0:01:49  Loss: 0.0962 (0.1766)  Acc@1: 100.0000 (94.9240)  Acc@5: 100.0000 (99.5166)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 2]  [190/625]  eta: 0:01:47  Loss: 0.1146 (0.1779)  Acc@1: 93.7500 (94.8298)  Acc@5: 100.0000 (99.4764)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 2]  [200/625]  eta: 0:01:44  Loss: 0.1347 (0.1767)  Acc@1: 93.7500 (94.8383)  Acc@5: 100.0000 (99.5025)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 2]  [210/625]  eta: 0:01:42  Loss: 0.1347 (0.1770)  Acc@1: 93.7500 (94.8460)  Acc@5: 100.0000 (99.5261)  time: 0.2445  data: 0.0003  max mem: 2912
Test: [Task 2]  [220/625]  eta: 0:01:39  Loss: 0.0906 (0.1760)  Acc@1: 100.0000 (94.9095)  Acc@5: 100.0000 (99.5192)  time: 0.2450  data: 0.0003  max mem: 2912
Test: [Task 2]  [230/625]  eta: 0:01:37  Loss: 0.0789 (0.1744)  Acc@1: 93.7500 (94.9675)  Acc@5: 100.0000 (99.5400)  time: 0.2443  data: 0.0003  max mem: 2912
Test: [Task 2]  [240/625]  eta: 0:01:34  Loss: 0.1868 (0.1765)  Acc@1: 93.7500 (94.8392)  Acc@5: 100.0000 (99.5591)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 2]  [250/625]  eta: 0:01:32  Loss: 0.1876 (0.1783)  Acc@1: 93.7500 (94.7460)  Acc@5: 100.0000 (99.5518)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 2]  [260/625]  eta: 0:01:29  Loss: 0.1431 (0.1764)  Acc@1: 93.7500 (94.7557)  Acc@5: 100.0000 (99.5690)  time: 0.2451  data: 0.0005  max mem: 2912
Test: [Task 2]  [270/625]  eta: 0:01:27  Loss: 0.1455 (0.1768)  Acc@1: 93.7500 (94.7417)  Acc@5: 100.0000 (99.5849)  time: 0.2454  data: 0.0004  max mem: 2912
Test: [Task 2]  [280/625]  eta: 0:01:24  Loss: 0.1455 (0.1791)  Acc@1: 93.7500 (94.7286)  Acc@5: 100.0000 (99.5552)  time: 0.2444  data: 0.0003  max mem: 2912
Test: [Task 2]  [290/625]  eta: 0:01:22  Loss: 0.2027 (0.1801)  Acc@1: 93.7500 (94.6521)  Acc@5: 100.0000 (99.5704)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 2]  [300/625]  eta: 0:01:19  Loss: 0.1422 (0.1795)  Acc@1: 93.7500 (94.6429)  Acc@5: 100.0000 (99.5640)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 2]  [310/625]  eta: 0:01:17  Loss: 0.1277 (0.1781)  Acc@1: 93.7500 (94.7146)  Acc@5: 100.0000 (99.5579)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 2]  [320/625]  eta: 0:01:14  Loss: 0.0369 (0.1732)  Acc@1: 100.0000 (94.8793)  Acc@5: 100.0000 (99.5717)  time: 0.2451  data: 0.0003  max mem: 2912
Test: [Task 2]  [330/625]  eta: 0:01:12  Loss: 0.0276 (0.1696)  Acc@1: 100.0000 (94.9962)  Acc@5: 100.0000 (99.5846)  time: 0.2453  data: 0.0003  max mem: 2912
Test: [Task 2]  [340/625]  eta: 0:01:09  Loss: 0.0162 (0.1649)  Acc@1: 100.0000 (95.1430)  Acc@5: 100.0000 (99.5968)  time: 0.2444  data: 0.0003  max mem: 2912
Test: [Task 2]  [350/625]  eta: 0:01:07  Loss: 0.0102 (0.1627)  Acc@1: 100.0000 (95.1923)  Acc@5: 100.0000 (99.6083)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 2]  [360/625]  eta: 0:01:05  Loss: 0.0518 (0.1615)  Acc@1: 100.0000 (95.2043)  Acc@5: 100.0000 (99.6191)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 2]  [370/625]  eta: 0:01:02  Loss: 0.0684 (0.1595)  Acc@1: 100.0000 (95.2662)  Acc@5: 100.0000 (99.6294)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 2]  [380/625]  eta: 0:01:00  Loss: 0.1880 (0.1632)  Acc@1: 93.7500 (95.1772)  Acc@5: 100.0000 (99.6063)  time: 0.2442  data: 0.0004  max mem: 2912
Test: [Task 2]  [390/625]  eta: 0:00:57  Loss: 0.1227 (0.1611)  Acc@1: 93.7500 (95.2366)  Acc@5: 100.0000 (99.6164)  time: 0.2450  data: 0.0003  max mem: 2912
Test: [Task 2]  [400/625]  eta: 0:00:55  Loss: 0.0210 (0.1582)  Acc@1: 100.0000 (95.3398)  Acc@5: 100.0000 (99.6259)  time: 0.2445  data: 0.0003  max mem: 2912
Test: [Task 2]  [410/625]  eta: 0:00:52  Loss: 0.0074 (0.1556)  Acc@1: 100.0000 (95.4227)  Acc@5: 100.0000 (99.6350)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [420/625]  eta: 0:00:50  Loss: 0.0195 (0.1535)  Acc@1: 100.0000 (95.5018)  Acc@5: 100.0000 (99.6437)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 2]  [430/625]  eta: 0:00:47  Loss: 0.0399 (0.1520)  Acc@1: 100.0000 (95.5626)  Acc@5: 100.0000 (99.6520)  time: 0.2446  data: 0.0003  max mem: 2912
Test: [Task 2]  [440/625]  eta: 0:00:45  Loss: 0.0276 (0.1490)  Acc@1: 100.0000 (95.6633)  Acc@5: 100.0000 (99.6599)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 2]  [450/625]  eta: 0:00:42  Loss: 0.0066 (0.1462)  Acc@1: 100.0000 (95.7456)  Acc@5: 100.0000 (99.6674)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 2]  [460/625]  eta: 0:00:40  Loss: 0.0091 (0.1435)  Acc@1: 100.0000 (95.8243)  Acc@5: 100.0000 (99.6746)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 2]  [470/625]  eta: 0:00:37  Loss: 0.0187 (0.1410)  Acc@1: 100.0000 (95.9130)  Acc@5: 100.0000 (99.6815)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 2]  [480/625]  eta: 0:00:35  Loss: 0.0325 (0.1397)  Acc@1: 100.0000 (95.9589)  Acc@5: 100.0000 (99.6881)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 2]  [490/625]  eta: 0:00:33  Loss: 0.0247 (0.1380)  Acc@1: 100.0000 (96.0031)  Acc@5: 100.0000 (99.6945)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 2]  [500/625]  eta: 0:00:30  Loss: 0.0229 (0.1358)  Acc@1: 100.0000 (96.0704)  Acc@5: 100.0000 (99.7006)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 2]  [510/625]  eta: 0:00:28  Loss: 0.0276 (0.1375)  Acc@1: 100.0000 (96.0250)  Acc@5: 100.0000 (99.7065)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 2]  [520/625]  eta: 0:00:25  Loss: 0.0342 (0.1362)  Acc@1: 100.0000 (96.0653)  Acc@5: 100.0000 (99.7121)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 2]  [530/625]  eta: 0:00:23  Loss: 0.0215 (0.1347)  Acc@1: 100.0000 (96.1040)  Acc@5: 100.0000 (99.7175)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 2]  [540/625]  eta: 0:00:20  Loss: 0.0215 (0.1334)  Acc@1: 100.0000 (96.1414)  Acc@5: 100.0000 (99.7227)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 2]  [550/625]  eta: 0:00:18  Loss: 0.0081 (0.1311)  Acc@1: 100.0000 (96.2114)  Acc@5: 100.0000 (99.7278)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 2]  [560/625]  eta: 0:00:15  Loss: 0.0029 (0.1288)  Acc@1: 100.0000 (96.2790)  Acc@5: 100.0000 (99.7326)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 2]  [570/625]  eta: 0:00:13  Loss: 0.0047 (0.1275)  Acc@1: 100.0000 (96.3113)  Acc@5: 100.0000 (99.7373)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 2]  [580/625]  eta: 0:00:11  Loss: 0.0119 (0.1258)  Acc@1: 100.0000 (96.3640)  Acc@5: 100.0000 (99.7418)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 2]  [590/625]  eta: 0:00:08  Loss: 0.0117 (0.1243)  Acc@1: 100.0000 (96.4044)  Acc@5: 100.0000 (99.7462)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 2]  [600/625]  eta: 0:00:06  Loss: 0.0231 (0.1238)  Acc@1: 100.0000 (96.4122)  Acc@5: 100.0000 (99.7400)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.1192 (0.1245)  Acc@1: 93.7500 (96.3891)  Acc@5: 100.0000 (99.7443)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.1192 (0.1250)  Acc@1: 93.7500 (96.3366)  Acc@5: 100.0000 (99.7484)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.0861 (0.1245)  Acc@1: 93.7500 (96.3500)  Acc@5: 100.0000 (99.7500)  time: 0.2445  data: 0.0003  max mem: 2912
Test: [Task 2] Total time: 0:02:33 (0.2449 s / it)
* Acc@1 96.350 Acc@5 99.750 loss 0.125
Test: [Task 3]  [  0/625]  eta: 0:06:09  Loss: 0.1251 (0.1251)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5906  data: 0.3430  max mem: 2912
Test: [Task 3]  [ 10/625]  eta: 0:02:48  Loss: 0.1173 (0.1126)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (99.4318)  time: 0.2738  data: 0.0314  max mem: 2912
Test: [Task 3]  [ 20/625]  eta: 0:02:36  Loss: 0.0884 (0.1319)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (99.7024)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 30/625]  eta: 0:02:30  Loss: 0.0797 (0.1306)  Acc@1: 100.0000 (97.5806)  Acc@5: 100.0000 (99.7984)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 40/625]  eta: 0:02:27  Loss: 0.0300 (0.1067)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (99.8476)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 50/625]  eta: 0:02:23  Loss: 0.0327 (0.1027)  Acc@1: 100.0000 (98.0392)  Acc@5: 100.0000 (99.7549)  time: 0.2446  data: 0.0004  max mem: 2912
Test: [Task 3]  [ 60/625]  eta: 0:02:20  Loss: 0.0680 (0.1016)  Acc@1: 100.0000 (97.9508)  Acc@5: 100.0000 (99.7951)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 3]  [ 70/625]  eta: 0:02:17  Loss: 0.0385 (0.0963)  Acc@1: 100.0000 (98.0634)  Acc@5: 100.0000 (99.7359)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 80/625]  eta: 0:02:14  Loss: 0.0432 (0.1027)  Acc@1: 100.0000 (97.7623)  Acc@5: 100.0000 (99.6914)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 90/625]  eta: 0:02:12  Loss: 0.0565 (0.1006)  Acc@1: 100.0000 (97.8022)  Acc@5: 100.0000 (99.6566)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 3]  [100/625]  eta: 0:02:09  Loss: 0.0351 (0.0977)  Acc@1: 100.0000 (97.8960)  Acc@5: 100.0000 (99.6906)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 3]  [110/625]  eta: 0:02:06  Loss: 0.0353 (0.0935)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (99.7185)  time: 0.2447  data: 0.0004  max mem: 2912
Test: [Task 3]  [120/625]  eta: 0:02:04  Loss: 0.0229 (0.0932)  Acc@1: 100.0000 (97.9339)  Acc@5: 100.0000 (99.6901)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 3]  [130/625]  eta: 0:02:01  Loss: 0.0484 (0.0955)  Acc@1: 100.0000 (97.8531)  Acc@5: 100.0000 (99.7137)  time: 0.2430  data: 0.0004  max mem: 2912
Test: [Task 3]  [140/625]  eta: 0:01:59  Loss: 0.0687 (0.0991)  Acc@1: 100.0000 (97.7837)  Acc@5: 100.0000 (99.6454)  time: 0.2425  data: 0.0004  max mem: 2912
Test: [Task 3]  [150/625]  eta: 0:01:56  Loss: 0.0966 (0.1120)  Acc@1: 100.0000 (97.7235)  Acc@5: 100.0000 (99.6275)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 3]  [160/625]  eta: 0:01:54  Loss: 0.1000 (0.1137)  Acc@1: 100.0000 (97.7484)  Acc@5: 100.0000 (99.5730)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 3]  [170/625]  eta: 0:01:51  Loss: 0.0740 (0.1136)  Acc@1: 100.0000 (97.6974)  Acc@5: 100.0000 (99.5980)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 3]  [180/625]  eta: 0:01:49  Loss: 0.0740 (0.1157)  Acc@1: 100.0000 (97.6519)  Acc@5: 100.0000 (99.5511)  time: 0.2426  data: 0.0004  max mem: 2912
Test: [Task 3]  [190/625]  eta: 0:01:46  Loss: 0.0455 (0.1141)  Acc@1: 100.0000 (97.6440)  Acc@5: 100.0000 (99.5746)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [200/625]  eta: 0:01:44  Loss: 0.0673 (0.1148)  Acc@1: 100.0000 (97.6368)  Acc@5: 100.0000 (99.5647)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 3]  [210/625]  eta: 0:01:41  Loss: 0.0784 (0.1166)  Acc@1: 100.0000 (97.5415)  Acc@5: 100.0000 (99.5261)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 3]  [220/625]  eta: 0:01:39  Loss: 0.0383 (0.1160)  Acc@1: 100.0000 (97.5113)  Acc@5: 100.0000 (99.5475)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 3]  [230/625]  eta: 0:01:36  Loss: 0.0465 (0.1165)  Acc@1: 100.0000 (97.5379)  Acc@5: 100.0000 (99.5400)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 3]  [240/625]  eta: 0:01:34  Loss: 0.0465 (0.1169)  Acc@1: 100.0000 (97.5363)  Acc@5: 100.0000 (99.5332)  time: 0.2433  data: 0.0004  max mem: 2912
Test: [Task 3]  [250/625]  eta: 0:01:31  Loss: 0.0396 (0.1152)  Acc@1: 100.0000 (97.5847)  Acc@5: 100.0000 (99.5518)  time: 0.2433  data: 0.0004  max mem: 2912
Test: [Task 3]  [260/625]  eta: 0:01:29  Loss: 0.0475 (0.1144)  Acc@1: 100.0000 (97.6054)  Acc@5: 100.0000 (99.5450)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [270/625]  eta: 0:01:26  Loss: 0.0676 (0.1136)  Acc@1: 100.0000 (97.6015)  Acc@5: 100.0000 (99.5618)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [280/625]  eta: 0:01:24  Loss: 0.0698 (0.1138)  Acc@1: 100.0000 (97.6423)  Acc@5: 100.0000 (99.5774)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 3]  [290/625]  eta: 0:01:21  Loss: 0.0863 (0.1137)  Acc@1: 100.0000 (97.6589)  Acc@5: 100.0000 (99.5919)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 3]  [300/625]  eta: 0:01:19  Loss: 0.1069 (0.1164)  Acc@1: 93.7500 (97.5498)  Acc@5: 100.0000 (99.5847)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 3]  [310/625]  eta: 0:01:16  Loss: 0.1197 (0.1189)  Acc@1: 93.7500 (97.5080)  Acc@5: 100.0000 (99.5579)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 3]  [320/625]  eta: 0:01:14  Loss: 0.0537 (0.1182)  Acc@1: 100.0000 (97.4883)  Acc@5: 100.0000 (99.5717)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [330/625]  eta: 0:01:12  Loss: 0.0775 (0.1184)  Acc@1: 100.0000 (97.4887)  Acc@5: 100.0000 (99.5846)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 3]  [340/625]  eta: 0:01:09  Loss: 0.0485 (0.1168)  Acc@1: 100.0000 (97.5440)  Acc@5: 100.0000 (99.5968)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 3]  [350/625]  eta: 0:01:07  Loss: 0.0433 (0.1167)  Acc@1: 100.0000 (97.5427)  Acc@5: 100.0000 (99.5905)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [360/625]  eta: 0:01:04  Loss: 0.0481 (0.1178)  Acc@1: 100.0000 (97.4723)  Acc@5: 100.0000 (99.5845)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 3]  [370/625]  eta: 0:01:02  Loss: 0.0481 (0.1184)  Acc@1: 93.7500 (97.4057)  Acc@5: 100.0000 (99.5957)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 3]  [380/625]  eta: 0:00:59  Loss: 0.0289 (0.1165)  Acc@1: 100.0000 (97.4573)  Acc@5: 100.0000 (99.6063)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 3]  [390/625]  eta: 0:00:57  Loss: 0.0379 (0.1160)  Acc@1: 100.0000 (97.4744)  Acc@5: 100.0000 (99.6164)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 3]  [400/625]  eta: 0:00:54  Loss: 0.0472 (0.1159)  Acc@1: 100.0000 (97.4439)  Acc@5: 100.0000 (99.6259)  time: 0.2433  data: 0.0004  max mem: 2912
Test: [Task 3]  [410/625]  eta: 0:00:52  Loss: 0.0653 (0.1161)  Acc@1: 100.0000 (97.4605)  Acc@5: 100.0000 (99.6198)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 3]  [420/625]  eta: 0:00:50  Loss: 0.0653 (0.1155)  Acc@1: 100.0000 (97.4762)  Acc@5: 100.0000 (99.6289)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 3]  [430/625]  eta: 0:00:47  Loss: 0.0679 (0.1156)  Acc@1: 100.0000 (97.4768)  Acc@5: 100.0000 (99.6230)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [440/625]  eta: 0:00:45  Loss: 0.0784 (0.1173)  Acc@1: 100.0000 (97.4348)  Acc@5: 100.0000 (99.6173)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 3]  [450/625]  eta: 0:00:42  Loss: 0.0447 (0.1180)  Acc@1: 100.0000 (97.4085)  Acc@5: 100.0000 (99.5981)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [460/625]  eta: 0:00:40  Loss: 0.0384 (0.1173)  Acc@1: 100.0000 (97.4105)  Acc@5: 100.0000 (99.6068)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 3]  [470/625]  eta: 0:00:37  Loss: 0.0664 (0.1178)  Acc@1: 93.7500 (97.3593)  Acc@5: 100.0000 (99.6019)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 3]  [480/625]  eta: 0:00:35  Loss: 0.0571 (0.1171)  Acc@1: 100.0000 (97.3883)  Acc@5: 100.0000 (99.5972)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 3]  [490/625]  eta: 0:00:32  Loss: 0.0731 (0.1178)  Acc@1: 100.0000 (97.3523)  Acc@5: 100.0000 (99.5927)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 3]  [500/625]  eta: 0:00:30  Loss: 0.0731 (0.1168)  Acc@1: 93.7500 (97.3678)  Acc@5: 100.0000 (99.6008)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [510/625]  eta: 0:00:28  Loss: 0.0221 (0.1161)  Acc@1: 100.0000 (97.3704)  Acc@5: 100.0000 (99.6086)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 3]  [520/625]  eta: 0:00:25  Loss: 0.0605 (0.1155)  Acc@1: 100.0000 (97.3728)  Acc@5: 100.0000 (99.6161)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 3]  [530/625]  eta: 0:00:23  Loss: 0.0610 (0.1152)  Acc@1: 100.0000 (97.3517)  Acc@5: 100.0000 (99.6234)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 3]  [540/625]  eta: 0:00:20  Loss: 0.0718 (0.1151)  Acc@1: 100.0000 (97.3544)  Acc@5: 100.0000 (99.6303)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 3]  [550/625]  eta: 0:00:18  Loss: 0.0713 (0.1149)  Acc@1: 100.0000 (97.3571)  Acc@5: 100.0000 (99.6370)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 3]  [560/625]  eta: 0:00:15  Loss: 0.0363 (0.1144)  Acc@1: 100.0000 (97.3819)  Acc@5: 100.0000 (99.6324)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 3]  [570/625]  eta: 0:00:13  Loss: 0.0357 (0.1139)  Acc@1: 100.0000 (97.4059)  Acc@5: 100.0000 (99.6388)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 3]  [580/625]  eta: 0:00:10  Loss: 0.0854 (0.1148)  Acc@1: 100.0000 (97.3537)  Acc@5: 100.0000 (99.6235)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 3]  [590/625]  eta: 0:00:08  Loss: 0.0706 (0.1139)  Acc@1: 100.0000 (97.3773)  Acc@5: 100.0000 (99.6299)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 3]  [600/625]  eta: 0:00:06  Loss: 0.0533 (0.1140)  Acc@1: 100.0000 (97.3378)  Acc@5: 100.0000 (99.6256)  time: 0.2440  data: 0.0004  max mem: 2912
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.0890 (0.1141)  Acc@1: 93.7500 (97.3302)  Acc@5: 100.0000 (99.6318)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.0866 (0.1143)  Acc@1: 100.0000 (97.3430)  Acc@5: 100.0000 (99.6377)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.0636 (0.1138)  Acc@1: 100.0000 (97.3600)  Acc@5: 100.0000 (99.6400)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 3] Total time: 0:02:32 (0.2441 s / it)
* Acc@1 97.360 Acc@5 99.640 loss 0.114
Test: [Task 4]  [ 0/29]  eta: 0:00:17  Loss: 1.8323 (1.8323)  Acc@1: 56.2500 (56.2500)  Acc@5: 87.5000 (87.5000)  time: 0.6204  data: 0.3782  max mem: 2912
Test: [Task 4]  [10/29]  eta: 0:00:05  Loss: 1.8323 (1.8375)  Acc@1: 50.0000 (46.0227)  Acc@5: 87.5000 (84.6591)  time: 0.2781  data: 0.0347  max mem: 2912
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.6623 (1.7966)  Acc@1: 50.0000 (51.1905)  Acc@5: 81.2500 (81.8452)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.3354 (1.5278)  Acc@1: 68.7500 (59.0414)  Acc@5: 87.5000 (85.1852)  time: 0.2541  data: 0.0003  max mem: 2912
Test: [Task 4] Total time: 0:00:07 (0.2677 s / it)
* Acc@1 59.041 Acc@5 85.185 loss 1.528
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 26032, 5: 26032, 6: 26032, 7: 26032, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 10000, 13: 10000, 14: 10000, 15: 10000, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000, 20: 10000, 21: 10000, 22: 10000, 23: 10000, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 459, 25: 459, 26: 459, 27: 459, 28: 459, 29: 459, 30: 459, 31: 459, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}}
[Average accuracy till task4]	Acc@1: 83.1709	Acc@5: 95.2747	Loss: 0.6255	Forgetting: 3.5344	Backward: -3.5344
Train: Epoch[1/5]  [   0/3750]  eta: 0:52:00  Lr: 0.030000  Loss: 2.2903  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  time: 0.8322  data: 0.4165  max mem: 2912
Train: Epoch[1/5]  [  10/3750]  eta: 0:26:55  Lr: 0.030000  Loss: 0.0275  Acc@1: 43.7500 (44.3182)  Acc@5: 81.2500 (80.1136)  time: 0.4319  data: 0.0382  max mem: 2912
Train: Epoch[1/5]  [  20/3750]  eta: 0:25:40  Lr: 0.030000  Loss: -0.3734  Acc@1: 50.0000 (48.5119)  Acc@5: 93.7500 (86.3095)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  30/3750]  eta: 0:25:11  Lr: 0.030000  Loss: -1.1183  Acc@1: 56.2500 (52.0161)  Acc@5: 93.7500 (88.7097)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  40/3750]  eta: 0:24:55  Lr: 0.030000  Loss: -0.8344  Acc@1: 56.2500 (52.2866)  Acc@5: 93.7500 (89.7866)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  50/3750]  eta: 0:24:42  Lr: 0.030000  Loss: -1.1779  Acc@1: 62.5000 (54.7794)  Acc@5: 93.7500 (90.6863)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  60/3750]  eta: 0:24:33  Lr: 0.030000  Loss: -1.2112  Acc@1: 62.5000 (56.0451)  Acc@5: 93.7500 (90.7787)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  70/3750]  eta: 0:24:26  Lr: 0.030000  Loss: -0.8285  Acc@1: 62.5000 (56.4261)  Acc@5: 93.7500 (91.6373)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  80/3750]  eta: 0:24:19  Lr: 0.030000  Loss: -1.5407  Acc@1: 56.2500 (56.9444)  Acc@5: 93.7500 (91.8981)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [  90/3750]  eta: 0:24:13  Lr: 0.030000  Loss: -1.0528  Acc@1: 62.5000 (57.8297)  Acc@5: 93.7500 (92.1016)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 100/3750]  eta: 0:24:07  Lr: 0.030000  Loss: -0.7492  Acc@1: 68.7500 (58.4777)  Acc@5: 93.7500 (92.4505)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 110/3750]  eta: 0:24:02  Lr: 0.030000  Loss: -0.7904  Acc@1: 68.7500 (58.9527)  Acc@5: 100.0000 (92.7928)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 120/3750]  eta: 0:23:56  Lr: 0.030000  Loss: -1.6605  Acc@1: 62.5000 (59.0909)  Acc@5: 100.0000 (93.1818)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 130/3750]  eta: 0:23:51  Lr: 0.030000  Loss: -1.2709  Acc@1: 62.5000 (59.3511)  Acc@5: 100.0000 (93.5115)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 140/3750]  eta: 0:23:46  Lr: 0.030000  Loss: -1.2365  Acc@1: 56.2500 (58.9982)  Acc@5: 93.7500 (93.2624)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 150/3750]  eta: 0:23:41  Lr: 0.030000  Loss: -0.8057  Acc@1: 62.5000 (59.3129)  Acc@5: 93.7500 (93.4189)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 160/3750]  eta: 0:23:36  Lr: 0.030000  Loss: -1.4377  Acc@1: 62.5000 (59.7438)  Acc@5: 93.7500 (93.5171)  time: 0.3908  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 170/3750]  eta: 0:23:32  Lr: 0.030000  Loss: -1.6100  Acc@1: 62.5000 (59.6491)  Acc@5: 93.7500 (93.6769)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 180/3750]  eta: 0:23:27  Lr: 0.030000  Loss: -1.9908  Acc@1: 62.5000 (60.3246)  Acc@5: 93.7500 (93.7500)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 190/3750]  eta: 0:23:22  Lr: 0.030000  Loss: -1.1539  Acc@1: 68.7500 (60.6348)  Acc@5: 93.7500 (93.6846)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 200/3750]  eta: 0:23:18  Lr: 0.030000  Loss: -1.4889  Acc@1: 68.7500 (61.1318)  Acc@5: 93.7500 (93.9366)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 210/3750]  eta: 0:23:14  Lr: 0.030000  Loss: -0.4871  Acc@1: 68.7500 (61.3448)  Acc@5: 100.0000 (93.9870)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 220/3750]  eta: 0:23:09  Lr: 0.030000  Loss: -1.0708  Acc@1: 68.7500 (61.7647)  Acc@5: 100.0000 (94.1459)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 230/3750]  eta: 0:23:05  Lr: 0.030000  Loss: -1.9675  Acc@1: 75.0000 (62.2024)  Acc@5: 100.0000 (94.2911)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 240/3750]  eta: 0:23:01  Lr: 0.030000  Loss: -1.6752  Acc@1: 62.5000 (62.1888)  Acc@5: 93.7500 (94.3205)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 250/3750]  eta: 0:22:56  Lr: 0.030000  Loss: -1.6135  Acc@1: 62.5000 (62.3506)  Acc@5: 93.7500 (94.2978)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 260/3750]  eta: 0:22:52  Lr: 0.030000  Loss: -1.6198  Acc@1: 75.0000 (62.8352)  Acc@5: 93.7500 (94.4684)  time: 0.3907  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 270/3750]  eta: 0:22:48  Lr: 0.030000  Loss: -1.0929  Acc@1: 68.7500 (63.0304)  Acc@5: 100.0000 (94.6033)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 280/3750]  eta: 0:22:44  Lr: 0.030000  Loss: -1.2466  Acc@1: 68.7500 (63.1450)  Acc@5: 100.0000 (94.6619)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 290/3750]  eta: 0:22:39  Lr: 0.030000  Loss: -1.0979  Acc@1: 62.5000 (63.2302)  Acc@5: 100.0000 (94.8024)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 300/3750]  eta: 0:22:35  Lr: 0.030000  Loss: -1.5852  Acc@1: 68.7500 (63.4967)  Acc@5: 100.0000 (94.8505)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 310/3750]  eta: 0:22:31  Lr: 0.030000  Loss: -1.6931  Acc@1: 68.7500 (63.7058)  Acc@5: 93.7500 (94.9156)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 320/3750]  eta: 0:22:27  Lr: 0.030000  Loss: -1.4670  Acc@1: 68.7500 (63.9213)  Acc@5: 93.7500 (94.9766)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 330/3750]  eta: 0:22:23  Lr: 0.030000  Loss: -1.6673  Acc@1: 68.7500 (63.9728)  Acc@5: 100.0000 (95.0529)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 340/3750]  eta: 0:22:19  Lr: 0.030000  Loss: -1.8614  Acc@1: 68.7500 (64.1679)  Acc@5: 100.0000 (95.1246)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 350/3750]  eta: 0:22:15  Lr: 0.030000  Loss: -1.7866  Acc@1: 75.0000 (64.3875)  Acc@5: 100.0000 (95.1745)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 360/3750]  eta: 0:22:11  Lr: 0.030000  Loss: -1.6498  Acc@1: 75.0000 (64.6122)  Acc@5: 100.0000 (95.2389)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 370/3750]  eta: 0:22:07  Lr: 0.030000  Loss: -2.0955  Acc@1: 68.7500 (64.7574)  Acc@5: 100.0000 (95.2999)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 380/3750]  eta: 0:22:03  Lr: 0.030000  Loss: -1.3122  Acc@1: 68.7500 (64.8294)  Acc@5: 100.0000 (95.3576)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 390/3750]  eta: 0:21:59  Lr: 0.030000  Loss: -1.7390  Acc@1: 68.7500 (65.1055)  Acc@5: 100.0000 (95.4124)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 400/3750]  eta: 0:21:55  Lr: 0.030000  Loss: -1.3877  Acc@1: 68.7500 (65.1029)  Acc@5: 100.0000 (95.5112)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 410/3750]  eta: 0:21:51  Lr: 0.030000  Loss: -1.7503  Acc@1: 68.7500 (65.1308)  Acc@5: 100.0000 (95.5748)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 420/3750]  eta: 0:21:47  Lr: 0.030000  Loss: -1.4546  Acc@1: 68.7500 (65.1722)  Acc@5: 100.0000 (95.6057)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 430/3750]  eta: 0:21:43  Lr: 0.030000  Loss: -1.4100  Acc@1: 75.0000 (65.4292)  Acc@5: 100.0000 (95.6497)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 440/3750]  eta: 0:21:39  Lr: 0.030000  Loss: -1.4637  Acc@1: 75.0000 (65.6037)  Acc@5: 93.7500 (95.6207)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 450/3750]  eta: 0:21:35  Lr: 0.030000  Loss: -1.2784  Acc@1: 75.0000 (65.6735)  Acc@5: 93.7500 (95.6624)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 460/3750]  eta: 0:21:31  Lr: 0.030000  Loss: -1.7685  Acc@1: 68.7500 (65.7131)  Acc@5: 100.0000 (95.7158)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 470/3750]  eta: 0:21:27  Lr: 0.030000  Loss: -1.7198  Acc@1: 68.7500 (65.9501)  Acc@5: 100.0000 (95.7803)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 480/3750]  eta: 0:21:23  Lr: 0.030000  Loss: -1.6523  Acc@1: 68.7500 (66.0213)  Acc@5: 100.0000 (95.8160)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 490/3750]  eta: 0:21:19  Lr: 0.030000  Loss: -2.0668  Acc@1: 68.7500 (66.0132)  Acc@5: 100.0000 (95.7994)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 500/3750]  eta: 0:21:15  Lr: 0.030000  Loss: -0.4434  Acc@1: 68.7500 (66.1801)  Acc@5: 93.7500 (95.8084)  time: 0.3928  data: 0.0011  max mem: 2912
Train: Epoch[1/5]  [ 510/3750]  eta: 0:21:11  Lr: 0.030000  Loss: -2.1239  Acc@1: 75.0000 (66.4139)  Acc@5: 100.0000 (95.8659)  time: 0.3931  data: 0.0011  max mem: 2912
Train: Epoch[1/5]  [ 520/3750]  eta: 0:21:07  Lr: 0.030000  Loss: -1.3125  Acc@1: 68.7500 (66.4827)  Acc@5: 100.0000 (95.9093)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 530/3750]  eta: 0:21:03  Lr: 0.030000  Loss: -1.9778  Acc@1: 68.7500 (66.5960)  Acc@5: 100.0000 (95.9510)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 540/3750]  eta: 0:20:59  Lr: 0.030000  Loss: -1.7458  Acc@1: 75.0000 (66.6474)  Acc@5: 100.0000 (95.9681)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 550/3750]  eta: 0:20:55  Lr: 0.030000  Loss: -2.1426  Acc@1: 68.7500 (66.7763)  Acc@5: 100.0000 (96.0073)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 560/3750]  eta: 0:20:51  Lr: 0.030000  Loss: -1.6218  Acc@1: 68.7500 (66.8672)  Acc@5: 100.0000 (96.0116)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 570/3750]  eta: 0:20:47  Lr: 0.030000  Loss: -0.8606  Acc@1: 75.0000 (66.9658)  Acc@5: 100.0000 (96.0595)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 580/3750]  eta: 0:20:44  Lr: 0.030000  Loss: -1.5048  Acc@1: 68.7500 (67.0181)  Acc@5: 100.0000 (96.0736)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 590/3750]  eta: 0:20:40  Lr: 0.030000  Loss: -1.1666  Acc@1: 75.0000 (67.1954)  Acc@5: 100.0000 (96.0871)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 600/3750]  eta: 0:20:36  Lr: 0.030000  Loss: -1.7040  Acc@1: 68.7500 (67.1589)  Acc@5: 100.0000 (96.1314)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 610/3750]  eta: 0:20:32  Lr: 0.030000  Loss: -1.8937  Acc@1: 68.7500 (67.2770)  Acc@5: 100.0000 (96.1641)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 620/3750]  eta: 0:20:28  Lr: 0.030000  Loss: -1.0910  Acc@1: 68.7500 (67.3611)  Acc@5: 100.0000 (96.2057)  time: 0.3938  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 630/3750]  eta: 0:20:24  Lr: 0.030000  Loss: -1.5640  Acc@1: 68.7500 (67.3831)  Acc@5: 100.0000 (96.1965)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 640/3750]  eta: 0:20:20  Lr: 0.030000  Loss: -1.7171  Acc@1: 68.7500 (67.4044)  Acc@5: 100.0000 (96.2071)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 650/3750]  eta: 0:20:16  Lr: 0.030000  Loss: -2.0228  Acc@1: 75.0000 (67.6075)  Acc@5: 100.0000 (96.2558)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 660/3750]  eta: 0:20:12  Lr: 0.030000  Loss: -1.8871  Acc@1: 75.0000 (67.6910)  Acc@5: 100.0000 (96.2557)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 670/3750]  eta: 0:20:09  Lr: 0.030000  Loss: -1.1788  Acc@1: 75.0000 (67.7347)  Acc@5: 100.0000 (96.2649)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 680/3750]  eta: 0:20:05  Lr: 0.030000  Loss: -2.0794  Acc@1: 68.7500 (67.7680)  Acc@5: 100.0000 (96.2830)  time: 0.3933  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 690/3750]  eta: 0:20:01  Lr: 0.030000  Loss: -1.8558  Acc@1: 75.0000 (67.8726)  Acc@5: 100.0000 (96.2916)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 700/3750]  eta: 0:19:57  Lr: 0.030000  Loss: -1.6533  Acc@1: 75.0000 (67.9743)  Acc@5: 100.0000 (96.3267)  time: 0.3924  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 710/3750]  eta: 0:19:53  Lr: 0.030000  Loss: -1.3290  Acc@1: 68.7500 (68.0468)  Acc@5: 100.0000 (96.3080)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 720/3750]  eta: 0:19:49  Lr: 0.030000  Loss: -1.7281  Acc@1: 68.7500 (68.0999)  Acc@5: 93.7500 (96.2985)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 730/3750]  eta: 0:19:45  Lr: 0.030000  Loss: -1.3213  Acc@1: 75.0000 (68.1772)  Acc@5: 100.0000 (96.2808)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 740/3750]  eta: 0:19:41  Lr: 0.030000  Loss: -1.7652  Acc@1: 62.5000 (68.1005)  Acc@5: 100.0000 (96.2972)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 750/3750]  eta: 0:19:37  Lr: 0.030000  Loss: -1.1026  Acc@1: 68.7500 (68.1092)  Acc@5: 100.0000 (96.2883)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 760/3750]  eta: 0:19:33  Lr: 0.030000  Loss: -1.7889  Acc@1: 75.0000 (68.2737)  Acc@5: 100.0000 (96.3371)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 770/3750]  eta: 0:19:29  Lr: 0.030000  Loss: -1.4489  Acc@1: 75.0000 (68.3042)  Acc@5: 100.0000 (96.3521)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 780/3750]  eta: 0:19:25  Lr: 0.030000  Loss: -1.3607  Acc@1: 68.7500 (68.3339)  Acc@5: 100.0000 (96.3588)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 790/3750]  eta: 0:19:21  Lr: 0.030000  Loss: -1.6632  Acc@1: 68.7500 (68.4023)  Acc@5: 100.0000 (96.3733)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 800/3750]  eta: 0:19:17  Lr: 0.030000  Loss: -1.3294  Acc@1: 68.7500 (68.4301)  Acc@5: 100.0000 (96.4107)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 810/3750]  eta: 0:19:13  Lr: 0.030000  Loss: -1.4692  Acc@1: 68.7500 (68.4572)  Acc@5: 100.0000 (96.4396)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 820/3750]  eta: 0:19:09  Lr: 0.030000  Loss: -1.7476  Acc@1: 68.7500 (68.4074)  Acc@5: 100.0000 (96.4753)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 830/3750]  eta: 0:19:05  Lr: 0.030000  Loss: -1.2579  Acc@1: 68.7500 (68.4868)  Acc@5: 100.0000 (96.5027)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 840/3750]  eta: 0:19:01  Lr: 0.030000  Loss: -0.6013  Acc@1: 75.0000 (68.5493)  Acc@5: 100.0000 (96.4997)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 850/3750]  eta: 0:18:58  Lr: 0.030000  Loss: -1.4260  Acc@1: 75.0000 (68.6105)  Acc@5: 100.0000 (96.5041)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 860/3750]  eta: 0:18:54  Lr: 0.030000  Loss: -1.5857  Acc@1: 68.7500 (68.5976)  Acc@5: 100.0000 (96.5302)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 870/3750]  eta: 0:18:50  Lr: 0.030000  Loss: -2.0259  Acc@1: 68.7500 (68.6495)  Acc@5: 100.0000 (96.5485)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 880/3750]  eta: 0:18:46  Lr: 0.030000  Loss: -1.7967  Acc@1: 75.0000 (68.7145)  Acc@5: 100.0000 (96.5735)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 890/3750]  eta: 0:18:42  Lr: 0.030000  Loss: -1.6767  Acc@1: 75.0000 (68.7781)  Acc@5: 100.0000 (96.5839)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [ 900/3750]  eta: 0:18:38  Lr: 0.030000  Loss: -1.9086  Acc@1: 68.7500 (68.8263)  Acc@5: 100.0000 (96.5941)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 910/3750]  eta: 0:18:34  Lr: 0.030000  Loss: -1.8657  Acc@1: 68.7500 (68.8529)  Acc@5: 100.0000 (96.5834)  time: 0.3901  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 920/3750]  eta: 0:18:30  Lr: 0.030000  Loss: -1.6055  Acc@1: 68.7500 (68.8518)  Acc@5: 100.0000 (96.5866)  time: 0.3905  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 930/3750]  eta: 0:18:26  Lr: 0.030000  Loss: -0.8389  Acc@1: 75.0000 (68.9044)  Acc@5: 100.0000 (96.6031)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 940/3750]  eta: 0:18:22  Lr: 0.030000  Loss: -1.6217  Acc@1: 75.0000 (68.9493)  Acc@5: 100.0000 (96.6392)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 950/3750]  eta: 0:18:18  Lr: 0.030000  Loss: -1.7371  Acc@1: 68.7500 (68.9406)  Acc@5: 100.0000 (96.6680)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 960/3750]  eta: 0:18:14  Lr: 0.030000  Loss: -1.5791  Acc@1: 68.7500 (68.9191)  Acc@5: 100.0000 (96.6831)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 970/3750]  eta: 0:18:10  Lr: 0.030000  Loss: -1.8272  Acc@1: 68.7500 (68.9688)  Acc@5: 100.0000 (96.7044)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [ 980/3750]  eta: 0:18:06  Lr: 0.030000  Loss: -1.8710  Acc@1: 75.0000 (69.0367)  Acc@5: 100.0000 (96.7253)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [ 990/3750]  eta: 0:18:02  Lr: 0.030000  Loss: -0.5767  Acc@1: 75.0000 (69.0716)  Acc@5: 100.0000 (96.7394)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1000/3750]  eta: 0:17:58  Lr: 0.030000  Loss: -1.2888  Acc@1: 75.0000 (69.1558)  Acc@5: 100.0000 (96.7470)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1010/3750]  eta: 0:17:54  Lr: 0.030000  Loss: -1.2277  Acc@1: 81.2500 (69.2631)  Acc@5: 100.0000 (96.7730)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1020/3750]  eta: 0:17:50  Lr: 0.030000  Loss: -1.3885  Acc@1: 81.2500 (69.3254)  Acc@5: 100.0000 (96.7740)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1030/3750]  eta: 0:17:46  Lr: 0.030000  Loss: -1.6947  Acc@1: 68.7500 (69.3380)  Acc@5: 100.0000 (96.7932)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1040/3750]  eta: 0:17:42  Lr: 0.030000  Loss: -1.2747  Acc@1: 68.7500 (69.3984)  Acc@5: 100.0000 (96.8060)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1050/3750]  eta: 0:17:38  Lr: 0.030000  Loss: -1.2191  Acc@1: 75.0000 (69.4279)  Acc@5: 100.0000 (96.8007)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1060/3750]  eta: 0:17:34  Lr: 0.030000  Loss: -1.2898  Acc@1: 68.7500 (69.4746)  Acc@5: 93.7500 (96.7955)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1070/3750]  eta: 0:17:30  Lr: 0.030000  Loss: -1.7165  Acc@1: 75.0000 (69.5203)  Acc@5: 100.0000 (96.8196)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1080/3750]  eta: 0:17:27  Lr: 0.030000  Loss: -1.9204  Acc@1: 81.2500 (69.6115)  Acc@5: 100.0000 (96.8316)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1090/3750]  eta: 0:17:23  Lr: 0.030000  Loss: -1.4817  Acc@1: 75.0000 (69.6322)  Acc@5: 100.0000 (96.8607)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1100/3750]  eta: 0:17:19  Lr: 0.030000  Loss: -1.6880  Acc@1: 68.7500 (69.6583)  Acc@5: 100.0000 (96.8608)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1110/3750]  eta: 0:17:15  Lr: 0.030000  Loss: -1.6086  Acc@1: 68.7500 (69.6782)  Acc@5: 100.0000 (96.8666)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1120/3750]  eta: 0:17:11  Lr: 0.030000  Loss: -1.4051  Acc@1: 68.7500 (69.6811)  Acc@5: 100.0000 (96.8722)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1130/3750]  eta: 0:17:07  Lr: 0.030000  Loss: -1.7776  Acc@1: 75.0000 (69.7447)  Acc@5: 100.0000 (96.8943)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1140/3750]  eta: 0:17:03  Lr: 0.030000  Loss: -1.9101  Acc@1: 75.0000 (69.8072)  Acc@5: 100.0000 (96.9051)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1150/3750]  eta: 0:16:59  Lr: 0.030000  Loss: -1.7018  Acc@1: 75.0000 (69.8523)  Acc@5: 100.0000 (96.9157)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1160/3750]  eta: 0:16:55  Lr: 0.030000  Loss: -1.9652  Acc@1: 75.0000 (69.9074)  Acc@5: 100.0000 (96.9261)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1170/3750]  eta: 0:16:51  Lr: 0.030000  Loss: -1.8448  Acc@1: 75.0000 (69.9562)  Acc@5: 100.0000 (96.9364)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1180/3750]  eta: 0:16:47  Lr: 0.030000  Loss: -1.6358  Acc@1: 68.7500 (69.9513)  Acc@5: 100.0000 (96.9464)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1190/3750]  eta: 0:16:43  Lr: 0.030000  Loss: -1.4512  Acc@1: 75.0000 (69.9780)  Acc@5: 100.0000 (96.9458)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1200/3750]  eta: 0:16:39  Lr: 0.030000  Loss: -1.8260  Acc@1: 75.0000 (69.9781)  Acc@5: 93.7500 (96.9348)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1210/3750]  eta: 0:16:35  Lr: 0.030000  Loss: -1.3545  Acc@1: 75.0000 (70.0093)  Acc@5: 93.7500 (96.9395)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1220/3750]  eta: 0:16:31  Lr: 0.030000  Loss: -1.6696  Acc@1: 68.7500 (70.0041)  Acc@5: 100.0000 (96.9441)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1230/3750]  eta: 0:16:28  Lr: 0.030000  Loss: -1.0738  Acc@1: 68.7500 (70.0244)  Acc@5: 100.0000 (96.9334)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1240/3750]  eta: 0:16:24  Lr: 0.030000  Loss: -1.9179  Acc@1: 68.7500 (70.0191)  Acc@5: 93.7500 (96.9128)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1250/3750]  eta: 0:16:20  Lr: 0.030000  Loss: -1.9241  Acc@1: 75.0000 (70.0739)  Acc@5: 93.7500 (96.9075)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1260/3750]  eta: 0:16:16  Lr: 0.030000  Loss: -1.4403  Acc@1: 75.0000 (70.0684)  Acc@5: 100.0000 (96.9122)  time: 0.3934  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1270/3750]  eta: 0:16:12  Lr: 0.030000  Loss: -1.2642  Acc@1: 68.7500 (70.0531)  Acc@5: 100.0000 (96.9217)  time: 0.3940  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1280/3750]  eta: 0:16:08  Lr: 0.030000  Loss: -1.6399  Acc@1: 68.7500 (70.0527)  Acc@5: 100.0000 (96.9165)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1290/3750]  eta: 0:16:04  Lr: 0.030000  Loss: -1.7105  Acc@1: 75.0000 (70.0959)  Acc@5: 93.7500 (96.9113)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1300/3750]  eta: 0:16:00  Lr: 0.030000  Loss: -2.0378  Acc@1: 75.0000 (70.1528)  Acc@5: 100.0000 (96.9206)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1310/3750]  eta: 0:15:56  Lr: 0.030000  Loss: -1.5588  Acc@1: 75.0000 (70.2088)  Acc@5: 100.0000 (96.9251)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1320/3750]  eta: 0:15:52  Lr: 0.030000  Loss: -1.8025  Acc@1: 75.0000 (70.2356)  Acc@5: 100.0000 (96.9389)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1330/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -1.7389  Acc@1: 68.7500 (70.2573)  Acc@5: 100.0000 (96.9290)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1340/3750]  eta: 0:15:45  Lr: 0.030000  Loss: -1.9071  Acc@1: 75.0000 (70.2927)  Acc@5: 100.0000 (96.9379)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1350/3750]  eta: 0:15:41  Lr: 0.030000  Loss: -1.4128  Acc@1: 75.0000 (70.3137)  Acc@5: 100.0000 (96.9467)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1360/3750]  eta: 0:15:37  Lr: 0.030000  Loss: -1.8648  Acc@1: 68.7500 (70.3435)  Acc@5: 100.0000 (96.9462)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1370/3750]  eta: 0:15:33  Lr: 0.030000  Loss: -1.2705  Acc@1: 75.0000 (70.3911)  Acc@5: 100.0000 (96.9548)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1380/3750]  eta: 0:15:29  Lr: 0.030000  Loss: -1.5038  Acc@1: 75.0000 (70.4155)  Acc@5: 100.0000 (96.9587)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1390/3750]  eta: 0:15:25  Lr: 0.030000  Loss: -2.1723  Acc@1: 68.7500 (70.4035)  Acc@5: 100.0000 (96.9716)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1400/3750]  eta: 0:15:21  Lr: 0.030000  Loss: -2.0514  Acc@1: 75.0000 (70.4408)  Acc@5: 100.0000 (96.9932)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1410/3750]  eta: 0:15:17  Lr: 0.030000  Loss: -1.7403  Acc@1: 75.0000 (70.4908)  Acc@5: 100.0000 (97.0101)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1420/3750]  eta: 0:15:13  Lr: 0.030000  Loss: -1.6120  Acc@1: 75.0000 (70.4961)  Acc@5: 100.0000 (97.0048)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1430/3750]  eta: 0:15:09  Lr: 0.030000  Loss: -1.5130  Acc@1: 75.0000 (70.5451)  Acc@5: 100.0000 (96.9995)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1440/3750]  eta: 0:15:05  Lr: 0.030000  Loss: -1.4372  Acc@1: 75.0000 (70.5586)  Acc@5: 100.0000 (96.9986)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1450/3750]  eta: 0:15:01  Lr: 0.030000  Loss: -1.9416  Acc@1: 75.0000 (70.6065)  Acc@5: 100.0000 (97.0021)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1460/3750]  eta: 0:14:57  Lr: 0.030000  Loss: -1.8746  Acc@1: 75.0000 (70.6665)  Acc@5: 100.0000 (97.0055)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1470/3750]  eta: 0:14:54  Lr: 0.030000  Loss: -1.6334  Acc@1: 75.0000 (70.6917)  Acc@5: 100.0000 (97.0131)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1480/3750]  eta: 0:14:50  Lr: 0.030000  Loss: -1.5201  Acc@1: 81.2500 (70.7292)  Acc@5: 100.0000 (97.0206)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1490/3750]  eta: 0:14:46  Lr: 0.030000  Loss: -1.4949  Acc@1: 75.0000 (70.7537)  Acc@5: 100.0000 (97.0364)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1500/3750]  eta: 0:14:42  Lr: 0.030000  Loss: -1.7383  Acc@1: 75.0000 (70.7695)  Acc@5: 100.0000 (97.0478)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1510/3750]  eta: 0:14:38  Lr: 0.030000  Loss: -1.6072  Acc@1: 75.0000 (70.8099)  Acc@5: 100.0000 (97.0591)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1520/3750]  eta: 0:14:34  Lr: 0.030000  Loss: -1.7535  Acc@1: 75.0000 (70.8292)  Acc@5: 100.0000 (97.0702)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1530/3750]  eta: 0:14:30  Lr: 0.030000  Loss: -1.7376  Acc@1: 68.7500 (70.8442)  Acc@5: 100.0000 (97.0730)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1540/3750]  eta: 0:14:26  Lr: 0.030000  Loss: -1.3828  Acc@1: 68.7500 (70.8144)  Acc@5: 100.0000 (97.0798)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1550/3750]  eta: 0:14:22  Lr: 0.030000  Loss: -0.9763  Acc@1: 68.7500 (70.8092)  Acc@5: 100.0000 (97.0583)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1560/3750]  eta: 0:14:18  Lr: 0.030000  Loss: -2.1175  Acc@1: 75.0000 (70.8480)  Acc@5: 100.0000 (97.0772)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1570/3750]  eta: 0:14:14  Lr: 0.030000  Loss: -1.5293  Acc@1: 68.7500 (70.8227)  Acc@5: 100.0000 (97.0759)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1580/3750]  eta: 0:14:10  Lr: 0.030000  Loss: -1.7361  Acc@1: 68.7500 (70.8254)  Acc@5: 100.0000 (97.0746)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1590/3750]  eta: 0:14:06  Lr: 0.030000  Loss: -1.8568  Acc@1: 75.0000 (70.8477)  Acc@5: 100.0000 (97.0655)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1600/3750]  eta: 0:14:02  Lr: 0.030000  Loss: -1.6637  Acc@1: 75.0000 (70.8776)  Acc@5: 100.0000 (97.0721)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1610/3750]  eta: 0:13:58  Lr: 0.030000  Loss: -1.8906  Acc@1: 81.2500 (70.9303)  Acc@5: 100.0000 (97.0826)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1620/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -1.6141  Acc@1: 75.0000 (70.9362)  Acc@5: 100.0000 (97.0813)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1630/3750]  eta: 0:13:51  Lr: 0.030000  Loss: -1.2029  Acc@1: 68.7500 (70.9496)  Acc@5: 100.0000 (97.0915)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1640/3750]  eta: 0:13:47  Lr: 0.030000  Loss: -1.6712  Acc@1: 68.7500 (70.9438)  Acc@5: 100.0000 (97.0940)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1650/3750]  eta: 0:13:43  Lr: 0.030000  Loss: -1.9709  Acc@1: 68.7500 (70.9797)  Acc@5: 100.0000 (97.1040)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1660/3750]  eta: 0:13:39  Lr: 0.030000  Loss: -1.5946  Acc@1: 68.7500 (70.9512)  Acc@5: 100.0000 (97.0951)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1670/3750]  eta: 0:13:35  Lr: 0.030000  Loss: -1.5215  Acc@1: 68.7500 (70.9867)  Acc@5: 93.7500 (97.0975)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1680/3750]  eta: 0:13:31  Lr: 0.030000  Loss: -1.6687  Acc@1: 68.7500 (71.0068)  Acc@5: 100.0000 (97.1074)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1690/3750]  eta: 0:13:27  Lr: 0.030000  Loss: -1.6660  Acc@1: 68.7500 (70.9898)  Acc@5: 100.0000 (97.1097)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1700/3750]  eta: 0:13:23  Lr: 0.030000  Loss: -1.6325  Acc@1: 68.7500 (71.0060)  Acc@5: 100.0000 (97.1267)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1710/3750]  eta: 0:13:19  Lr: 0.030000  Loss: -1.5145  Acc@1: 75.0000 (71.0075)  Acc@5: 100.0000 (97.1289)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1720/3750]  eta: 0:13:15  Lr: 0.030000  Loss: -1.2069  Acc@1: 75.0000 (71.0270)  Acc@5: 100.0000 (97.1383)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1730/3750]  eta: 0:13:11  Lr: 0.030000  Loss: -1.6162  Acc@1: 75.0000 (71.0716)  Acc@5: 100.0000 (97.1476)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1740/3750]  eta: 0:13:07  Lr: 0.030000  Loss: -1.4749  Acc@1: 75.0000 (71.1014)  Acc@5: 100.0000 (97.1604)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1750/3750]  eta: 0:13:03  Lr: 0.030000  Loss: -1.8275  Acc@1: 75.0000 (71.1094)  Acc@5: 100.0000 (97.1659)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1760/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -1.6517  Acc@1: 68.7500 (71.1279)  Acc@5: 100.0000 (97.1784)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1770/3750]  eta: 0:12:56  Lr: 0.030000  Loss: -1.9465  Acc@1: 75.0000 (71.1745)  Acc@5: 100.0000 (97.1873)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1780/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -1.8182  Acc@1: 75.0000 (71.1960)  Acc@5: 100.0000 (97.1926)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1790/3750]  eta: 0:12:48  Lr: 0.030000  Loss: -1.7282  Acc@1: 75.0000 (71.2312)  Acc@5: 100.0000 (97.2013)  time: 0.3931  data: 0.0012  max mem: 2912
Train: Epoch[1/5]  [1800/3750]  eta: 0:12:44  Lr: 0.030000  Loss: -1.7753  Acc@1: 75.0000 (71.2417)  Acc@5: 100.0000 (97.2064)  time: 0.3929  data: 0.0012  max mem: 2912
Train: Epoch[1/5]  [1810/3750]  eta: 0:12:40  Lr: 0.030000  Loss: -1.5560  Acc@1: 75.0000 (71.2624)  Acc@5: 100.0000 (97.2149)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1820/3750]  eta: 0:12:36  Lr: 0.030000  Loss: -0.8455  Acc@1: 75.0000 (71.2761)  Acc@5: 100.0000 (97.2165)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1830/3750]  eta: 0:12:32  Lr: 0.030000  Loss: -1.7445  Acc@1: 75.0000 (71.3169)  Acc@5: 100.0000 (97.2249)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1840/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -2.2779  Acc@1: 75.0000 (71.3403)  Acc@5: 100.0000 (97.2298)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1850/3750]  eta: 0:12:24  Lr: 0.030000  Loss: -1.0132  Acc@1: 75.0000 (71.3196)  Acc@5: 100.0000 (97.2346)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1860/3750]  eta: 0:12:20  Lr: 0.030000  Loss: -1.5750  Acc@1: 75.0000 (71.3293)  Acc@5: 100.0000 (97.2394)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1870/3750]  eta: 0:12:16  Lr: 0.030000  Loss: -1.7323  Acc@1: 75.0000 (71.3422)  Acc@5: 100.0000 (97.2441)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1880/3750]  eta: 0:12:12  Lr: 0.030000  Loss: -2.2231  Acc@1: 81.2500 (71.4281)  Acc@5: 100.0000 (97.2554)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [1890/3750]  eta: 0:12:09  Lr: 0.030000  Loss: -1.9383  Acc@1: 81.2500 (71.4635)  Acc@5: 100.0000 (97.2567)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1900/3750]  eta: 0:12:05  Lr: 0.030000  Loss: -1.7971  Acc@1: 75.0000 (71.4821)  Acc@5: 100.0000 (97.2613)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1910/3750]  eta: 0:12:01  Lr: 0.030000  Loss: -1.6565  Acc@1: 75.0000 (71.5071)  Acc@5: 100.0000 (97.2724)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1920/3750]  eta: 0:11:57  Lr: 0.030000  Loss: -2.2459  Acc@1: 75.0000 (71.5285)  Acc@5: 100.0000 (97.2833)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1930/3750]  eta: 0:11:53  Lr: 0.030000  Loss: -1.4147  Acc@1: 75.0000 (71.5335)  Acc@5: 100.0000 (97.2844)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1940/3750]  eta: 0:11:49  Lr: 0.030000  Loss: -1.4954  Acc@1: 75.0000 (71.5836)  Acc@5: 100.0000 (97.2888)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1950/3750]  eta: 0:11:45  Lr: 0.030000  Loss: -2.0328  Acc@1: 75.0000 (71.5979)  Acc@5: 100.0000 (97.2931)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [1960/3750]  eta: 0:11:41  Lr: 0.030000  Loss: -1.7997  Acc@1: 75.0000 (71.6312)  Acc@5: 100.0000 (97.2973)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1970/3750]  eta: 0:11:37  Lr: 0.030000  Loss: -1.6135  Acc@1: 75.0000 (71.6229)  Acc@5: 100.0000 (97.2983)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1980/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -1.4804  Acc@1: 75.0000 (71.6526)  Acc@5: 100.0000 (97.3057)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [1990/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -1.9260  Acc@1: 75.0000 (71.6882)  Acc@5: 100.0000 (97.3129)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2000/3750]  eta: 0:11:25  Lr: 0.030000  Loss: -1.1826  Acc@1: 75.0000 (71.7016)  Acc@5: 100.0000 (97.3201)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2010/3750]  eta: 0:11:22  Lr: 0.030000  Loss: -1.4990  Acc@1: 75.0000 (71.7429)  Acc@5: 100.0000 (97.3241)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2020/3750]  eta: 0:11:18  Lr: 0.030000  Loss: -1.2098  Acc@1: 75.0000 (71.7683)  Acc@5: 100.0000 (97.3219)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2030/3750]  eta: 0:11:14  Lr: 0.030000  Loss: -1.9300  Acc@1: 68.7500 (71.7596)  Acc@5: 100.0000 (97.3258)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2040/3750]  eta: 0:11:10  Lr: 0.030000  Loss: -1.6805  Acc@1: 68.7500 (71.7785)  Acc@5: 100.0000 (97.3267)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2050/3750]  eta: 0:11:06  Lr: 0.030000  Loss: -1.4994  Acc@1: 75.0000 (71.7851)  Acc@5: 100.0000 (97.3367)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2060/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -1.6920  Acc@1: 75.0000 (71.8128)  Acc@5: 100.0000 (97.3435)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2070/3750]  eta: 0:10:58  Lr: 0.030000  Loss: -1.7835  Acc@1: 75.0000 (71.8131)  Acc@5: 100.0000 (97.3533)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2080/3750]  eta: 0:10:54  Lr: 0.030000  Loss: -1.9488  Acc@1: 81.2500 (71.8525)  Acc@5: 100.0000 (97.3570)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2090/3750]  eta: 0:10:50  Lr: 0.030000  Loss: -2.1444  Acc@1: 81.2500 (71.8705)  Acc@5: 100.0000 (97.3667)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2100/3750]  eta: 0:10:46  Lr: 0.030000  Loss: -1.8895  Acc@1: 81.2500 (71.9003)  Acc@5: 100.0000 (97.3733)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2110/3750]  eta: 0:10:42  Lr: 0.030000  Loss: -1.9031  Acc@1: 81.2500 (71.9239)  Acc@5: 100.0000 (97.3828)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2120/3750]  eta: 0:10:38  Lr: 0.030000  Loss: -1.9822  Acc@1: 75.0000 (71.9236)  Acc@5: 100.0000 (97.3921)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2130/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -1.9135  Acc@1: 68.7500 (71.9293)  Acc@5: 100.0000 (97.3985)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2140/3750]  eta: 0:10:31  Lr: 0.030000  Loss: -1.9414  Acc@1: 75.0000 (71.9378)  Acc@5: 100.0000 (97.3932)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2150/3750]  eta: 0:10:27  Lr: 0.030000  Loss: -1.6163  Acc@1: 75.0000 (71.9578)  Acc@5: 100.0000 (97.3937)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2160/3750]  eta: 0:10:23  Lr: 0.030000  Loss: -1.7958  Acc@1: 75.0000 (71.9806)  Acc@5: 100.0000 (97.3999)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2170/3750]  eta: 0:10:19  Lr: 0.030000  Loss: -1.4391  Acc@1: 68.7500 (71.9887)  Acc@5: 100.0000 (97.4119)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2180/3750]  eta: 0:10:15  Lr: 0.030000  Loss: -1.8007  Acc@1: 81.2500 (72.0340)  Acc@5: 100.0000 (97.4209)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2190/3750]  eta: 0:10:11  Lr: 0.030000  Loss: -1.3664  Acc@1: 81.2500 (72.0533)  Acc@5: 100.0000 (97.4156)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2200/3750]  eta: 0:10:07  Lr: 0.030000  Loss: -1.6309  Acc@1: 81.2500 (72.1007)  Acc@5: 100.0000 (97.4245)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2210/3750]  eta: 0:10:03  Lr: 0.030000  Loss: -1.5701  Acc@1: 75.0000 (72.1139)  Acc@5: 100.0000 (97.4248)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2220/3750]  eta: 0:09:59  Lr: 0.030000  Loss: -0.9635  Acc@1: 75.0000 (72.1466)  Acc@5: 100.0000 (97.4308)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2230/3750]  eta: 0:09:55  Lr: 0.030000  Loss: -1.5696  Acc@1: 75.0000 (72.1649)  Acc@5: 100.0000 (97.4311)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2240/3750]  eta: 0:09:51  Lr: 0.030000  Loss: -1.6115  Acc@1: 75.0000 (72.1832)  Acc@5: 100.0000 (97.4370)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2250/3750]  eta: 0:09:47  Lr: 0.030000  Loss: -2.0046  Acc@1: 81.2500 (72.2179)  Acc@5: 100.0000 (97.4456)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2260/3750]  eta: 0:09:43  Lr: 0.030000  Loss: -1.7590  Acc@1: 75.0000 (72.2274)  Acc@5: 100.0000 (97.4458)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2270/3750]  eta: 0:09:40  Lr: 0.030000  Loss: -1.1702  Acc@1: 75.0000 (72.2204)  Acc@5: 100.0000 (97.4543)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2280/3750]  eta: 0:09:36  Lr: 0.030000  Loss: -1.8479  Acc@1: 75.0000 (72.2244)  Acc@5: 100.0000 (97.4600)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2290/3750]  eta: 0:09:32  Lr: 0.030000  Loss: -1.9979  Acc@1: 75.0000 (72.2637)  Acc@5: 100.0000 (97.4656)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2300/3750]  eta: 0:09:28  Lr: 0.030000  Loss: -1.6687  Acc@1: 81.2500 (72.2919)  Acc@5: 100.0000 (97.4685)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2310/3750]  eta: 0:09:24  Lr: 0.030000  Loss: -1.9828  Acc@1: 81.2500 (72.3334)  Acc@5: 100.0000 (97.4713)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2320/3750]  eta: 0:09:20  Lr: 0.030000  Loss: -1.3419  Acc@1: 75.0000 (72.3395)  Acc@5: 100.0000 (97.4741)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2330/3750]  eta: 0:09:16  Lr: 0.030000  Loss: -1.3425  Acc@1: 68.7500 (72.3187)  Acc@5: 100.0000 (97.4635)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2340/3750]  eta: 0:09:12  Lr: 0.030000  Loss: -2.0514  Acc@1: 68.7500 (72.3249)  Acc@5: 100.0000 (97.4690)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2350/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -2.1539  Acc@1: 81.2500 (72.3602)  Acc@5: 100.0000 (97.4745)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2360/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -2.1392  Acc@1: 81.2500 (72.3952)  Acc@5: 100.0000 (97.4825)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2370/3750]  eta: 0:09:00  Lr: 0.030000  Loss: -2.1630  Acc@1: 81.2500 (72.4246)  Acc@5: 100.0000 (97.4879)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2380/3750]  eta: 0:08:56  Lr: 0.030000  Loss: -1.7073  Acc@1: 81.2500 (72.4486)  Acc@5: 100.0000 (97.4906)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2390/3750]  eta: 0:08:52  Lr: 0.030000  Loss: -1.8079  Acc@1: 81.2500 (72.4723)  Acc@5: 100.0000 (97.4906)  time: 0.3902  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2400/3750]  eta: 0:08:48  Lr: 0.030000  Loss: -1.8362  Acc@1: 75.0000 (72.4984)  Acc@5: 100.0000 (97.4958)  time: 0.3906  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2410/3750]  eta: 0:08:45  Lr: 0.030000  Loss: -1.2657  Acc@1: 75.0000 (72.4855)  Acc@5: 100.0000 (97.4959)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2420/3750]  eta: 0:08:41  Lr: 0.030000  Loss: -2.2435  Acc@1: 75.0000 (72.5320)  Acc@5: 100.0000 (97.5036)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2430/3750]  eta: 0:08:37  Lr: 0.030000  Loss: -1.9092  Acc@1: 81.2500 (72.5627)  Acc@5: 100.0000 (97.5087)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2440/3750]  eta: 0:08:33  Lr: 0.030000  Loss: -1.6504  Acc@1: 81.2500 (72.5830)  Acc@5: 100.0000 (97.5138)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2450/3750]  eta: 0:08:29  Lr: 0.030000  Loss: -1.6979  Acc@1: 75.0000 (72.5979)  Acc@5: 100.0000 (97.5189)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2460/3750]  eta: 0:08:25  Lr: 0.030000  Loss: -1.2707  Acc@1: 75.0000 (72.5924)  Acc@5: 100.0000 (97.5137)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2470/3750]  eta: 0:08:21  Lr: 0.030000  Loss: -1.4509  Acc@1: 68.7500 (72.5895)  Acc@5: 100.0000 (97.5137)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2480/3750]  eta: 0:08:17  Lr: 0.030000  Loss: -2.0983  Acc@1: 81.2500 (72.6244)  Acc@5: 100.0000 (97.5136)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2490/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -1.8112  Acc@1: 81.2500 (72.6541)  Acc@5: 100.0000 (97.5161)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2500/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -1.5738  Acc@1: 75.0000 (72.6709)  Acc@5: 100.0000 (97.5260)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2510/3750]  eta: 0:08:05  Lr: 0.030000  Loss: -1.7628  Acc@1: 75.0000 (72.6852)  Acc@5: 100.0000 (97.5309)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2520/3750]  eta: 0:08:01  Lr: 0.030000  Loss: -1.6099  Acc@1: 68.7500 (72.6820)  Acc@5: 100.0000 (97.5307)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:57  Lr: 0.030000  Loss: -1.6426  Acc@1: 68.7500 (72.6862)  Acc@5: 100.0000 (97.5257)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:54  Lr: 0.030000  Loss: -1.2308  Acc@1: 75.0000 (72.6855)  Acc@5: 100.0000 (97.5231)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2550/3750]  eta: 0:07:50  Lr: 0.030000  Loss: -1.9957  Acc@1: 75.0000 (72.7092)  Acc@5: 100.0000 (97.5279)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2560/3750]  eta: 0:07:46  Lr: 0.030000  Loss: -1.8302  Acc@1: 75.0000 (72.7060)  Acc@5: 100.0000 (97.5229)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2570/3750]  eta: 0:07:42  Lr: 0.030000  Loss: -1.7503  Acc@1: 68.7500 (72.7125)  Acc@5: 100.0000 (97.5277)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2580/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -1.5923  Acc@1: 75.0000 (72.7116)  Acc@5: 100.0000 (97.5324)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2590/3750]  eta: 0:07:34  Lr: 0.030000  Loss: -1.7454  Acc@1: 75.0000 (72.7229)  Acc@5: 100.0000 (97.5347)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2600/3750]  eta: 0:07:30  Lr: 0.030000  Loss: -1.7694  Acc@1: 75.0000 (72.7244)  Acc@5: 100.0000 (97.5370)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2610/3750]  eta: 0:07:26  Lr: 0.030000  Loss: -1.8774  Acc@1: 75.0000 (72.7379)  Acc@5: 100.0000 (97.5417)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2620/3750]  eta: 0:07:22  Lr: 0.030000  Loss: -2.0898  Acc@1: 75.0000 (72.7490)  Acc@5: 100.0000 (97.5510)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[1/5]  [2630/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -1.7005  Acc@1: 75.0000 (72.7836)  Acc@5: 100.0000 (97.5485)  time: 0.3924  data: 0.0006  max mem: 2912
Train: Epoch[1/5]  [2640/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -1.8408  Acc@1: 81.2500 (72.8204)  Acc@5: 100.0000 (97.5506)  time: 0.3913  data: 0.0006  max mem: 2912
Train: Epoch[1/5]  [2650/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -1.7431  Acc@1: 81.2500 (72.8404)  Acc@5: 100.0000 (97.5552)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2660/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -1.5108  Acc@1: 81.2500 (72.8744)  Acc@5: 100.0000 (97.5550)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2670/3750]  eta: 0:07:03  Lr: 0.030000  Loss: -1.9789  Acc@1: 81.2500 (72.8683)  Acc@5: 100.0000 (97.5524)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:59  Lr: 0.030000  Loss: -2.0744  Acc@1: 75.0000 (72.8809)  Acc@5: 100.0000 (97.5546)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:55  Lr: 0.030000  Loss: -2.0878  Acc@1: 75.0000 (72.9120)  Acc@5: 100.0000 (97.5543)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:51  Lr: 0.030000  Loss: -1.9738  Acc@1: 81.2500 (72.9429)  Acc@5: 100.0000 (97.5588)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:47  Lr: 0.030000  Loss: -1.5939  Acc@1: 75.0000 (72.9505)  Acc@5: 100.0000 (97.5609)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -0.9010  Acc@1: 75.0000 (72.9580)  Acc@5: 100.0000 (97.5629)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2730/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -1.7046  Acc@1: 75.0000 (72.9701)  Acc@5: 100.0000 (97.5627)  time: 0.3933  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2740/3750]  eta: 0:06:35  Lr: 0.030000  Loss: -1.8564  Acc@1: 75.0000 (72.9820)  Acc@5: 100.0000 (97.5670)  time: 0.3935  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2750/3750]  eta: 0:06:31  Lr: 0.030000  Loss: -1.4272  Acc@1: 75.0000 (72.9712)  Acc@5: 100.0000 (97.5645)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2760/3750]  eta: 0:06:27  Lr: 0.030000  Loss: -2.0289  Acc@1: 75.0000 (73.0012)  Acc@5: 100.0000 (97.5688)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2770/3750]  eta: 0:06:23  Lr: 0.030000  Loss: -1.7695  Acc@1: 81.2500 (73.0197)  Acc@5: 100.0000 (97.5708)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2780/3750]  eta: 0:06:20  Lr: 0.030000  Loss: -2.0298  Acc@1: 81.2500 (73.0290)  Acc@5: 100.0000 (97.5751)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2790/3750]  eta: 0:06:16  Lr: 0.030000  Loss: -2.1422  Acc@1: 81.2500 (73.0473)  Acc@5: 100.0000 (97.5815)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2800/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -1.8656  Acc@1: 81.2500 (73.0610)  Acc@5: 100.0000 (97.5857)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2810/3750]  eta: 0:06:08  Lr: 0.030000  Loss: -1.9331  Acc@1: 75.0000 (73.0501)  Acc@5: 100.0000 (97.5809)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2820/3750]  eta: 0:06:04  Lr: 0.030000  Loss: -1.4488  Acc@1: 68.7500 (73.0526)  Acc@5: 100.0000 (97.5829)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2830/3750]  eta: 0:06:00  Lr: 0.030000  Loss: -1.5838  Acc@1: 75.0000 (73.0638)  Acc@5: 100.0000 (97.5848)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:56  Lr: 0.030000  Loss: -1.6103  Acc@1: 75.0000 (73.0707)  Acc@5: 100.0000 (97.5889)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:52  Lr: 0.030000  Loss: -1.4998  Acc@1: 75.0000 (73.0818)  Acc@5: 100.0000 (97.5908)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -1.2486  Acc@1: 75.0000 (73.0841)  Acc@5: 100.0000 (97.5926)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -1.4912  Acc@1: 75.0000 (73.0821)  Acc@5: 100.0000 (97.5945)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:40  Lr: 0.030000  Loss: -1.9047  Acc@1: 75.0000 (73.0844)  Acc@5: 100.0000 (97.5942)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:36  Lr: 0.030000  Loss: -1.8668  Acc@1: 75.0000 (73.0997)  Acc@5: 100.0000 (97.5981)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2900/3750]  eta: 0:05:33  Lr: 0.030000  Loss: -1.8339  Acc@1: 75.0000 (73.1170)  Acc@5: 100.0000 (97.6043)  time: 0.3922  data: 0.0010  max mem: 2912
Train: Epoch[1/5]  [2910/3750]  eta: 0:05:29  Lr: 0.030000  Loss: -1.4784  Acc@1: 75.0000 (73.1278)  Acc@5: 100.0000 (97.6082)  time: 0.3917  data: 0.0011  max mem: 2912
Train: Epoch[1/5]  [2920/3750]  eta: 0:05:25  Lr: 0.030000  Loss: -0.9218  Acc@1: 75.0000 (73.1278)  Acc@5: 100.0000 (97.6036)  time: 0.3910  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [2930/3750]  eta: 0:05:21  Lr: 0.030000  Loss: -1.5722  Acc@1: 75.0000 (73.1342)  Acc@5: 100.0000 (97.6053)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2940/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -1.8099  Acc@1: 75.0000 (73.1363)  Acc@5: 100.0000 (97.6114)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2950/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -1.4849  Acc@1: 75.0000 (73.1362)  Acc@5: 100.0000 (97.6089)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2960/3750]  eta: 0:05:09  Lr: 0.030000  Loss: -1.9904  Acc@1: 75.0000 (73.1742)  Acc@5: 100.0000 (97.6148)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2970/3750]  eta: 0:05:05  Lr: 0.030000  Loss: -1.7032  Acc@1: 81.2500 (73.1951)  Acc@5: 100.0000 (97.6165)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2980/3750]  eta: 0:05:01  Lr: 0.030000  Loss: -1.5875  Acc@1: 81.2500 (73.2200)  Acc@5: 100.0000 (97.6203)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:57  Lr: 0.030000  Loss: -1.7940  Acc@1: 75.0000 (73.2301)  Acc@5: 100.0000 (97.6262)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -1.9177  Acc@1: 75.0000 (73.2506)  Acc@5: 100.0000 (97.6320)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -1.5828  Acc@1: 81.2500 (73.2688)  Acc@5: 100.0000 (97.6337)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -1.2787  Acc@1: 75.0000 (73.2725)  Acc@5: 100.0000 (97.6374)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:42  Lr: 0.030000  Loss: -1.7717  Acc@1: 75.0000 (73.2885)  Acc@5: 100.0000 (97.6452)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:38  Lr: 0.030000  Loss: -2.0696  Acc@1: 81.2500 (73.2921)  Acc@5: 100.0000 (97.6488)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:34  Lr: 0.030000  Loss: -1.6387  Acc@1: 75.0000 (73.3038)  Acc@5: 100.0000 (97.6545)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:30  Lr: 0.030000  Loss: -0.9131  Acc@1: 75.0000 (73.3196)  Acc@5: 100.0000 (97.6601)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3070/3750]  eta: 0:04:26  Lr: 0.030000  Loss: -1.8407  Acc@1: 75.0000 (73.3128)  Acc@5: 100.0000 (97.6616)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3080/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -1.6991  Acc@1: 75.0000 (73.3406)  Acc@5: 100.0000 (97.6631)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3090/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -1.8697  Acc@1: 81.2500 (73.3662)  Acc@5: 100.0000 (97.6666)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -2.0358  Acc@1: 81.2500 (73.3856)  Acc@5: 100.0000 (97.6620)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3110/3750]  eta: 0:04:10  Lr: 0.030000  Loss: -2.2272  Acc@1: 81.2500 (73.4229)  Acc@5: 100.0000 (97.6676)  time: 0.3904  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3120/3750]  eta: 0:04:06  Lr: 0.030000  Loss: -1.5932  Acc@1: 81.2500 (73.4260)  Acc@5: 100.0000 (97.6730)  time: 0.3899  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3130/3750]  eta: 0:04:02  Lr: 0.030000  Loss: -1.2636  Acc@1: 75.0000 (73.4250)  Acc@5: 100.0000 (97.6725)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:58  Lr: 0.030000  Loss: -1.3504  Acc@1: 75.0000 (73.4221)  Acc@5: 100.0000 (97.6719)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:55  Lr: 0.030000  Loss: -2.0235  Acc@1: 75.0000 (73.4211)  Acc@5: 100.0000 (97.6714)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -1.6221  Acc@1: 75.0000 (73.4321)  Acc@5: 100.0000 (97.6748)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -1.6426  Acc@1: 75.0000 (73.4331)  Acc@5: 100.0000 (97.6762)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:43  Lr: 0.030000  Loss: -1.5032  Acc@1: 81.2500 (73.4459)  Acc@5: 100.0000 (97.6815)  time: 0.3911  data: 0.0010  max mem: 2912
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -1.0625  Acc@1: 75.0000 (73.4390)  Acc@5: 100.0000 (97.6810)  time: 0.3908  data: 0.0011  max mem: 2912
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -1.5211  Acc@1: 81.2500 (73.4634)  Acc@5: 100.0000 (97.6804)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -1.2652  Acc@1: 81.2500 (73.4720)  Acc@5: 100.0000 (97.6818)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -1.7650  Acc@1: 75.0000 (73.4923)  Acc@5: 100.0000 (97.6890)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -1.6548  Acc@1: 81.2500 (73.5067)  Acc@5: 100.0000 (97.6903)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3240/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -1.6844  Acc@1: 75.0000 (73.5113)  Acc@5: 100.0000 (97.6898)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3250/3750]  eta: 0:03:15  Lr: 0.030000  Loss: -1.9549  Acc@1: 81.2500 (73.5370)  Acc@5: 100.0000 (97.6949)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3260/3750]  eta: 0:03:11  Lr: 0.030000  Loss: -1.4379  Acc@1: 81.2500 (73.5453)  Acc@5: 100.0000 (97.6963)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3270/3750]  eta: 0:03:08  Lr: 0.030000  Loss: -1.5259  Acc@1: 81.2500 (73.5536)  Acc@5: 100.0000 (97.7014)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3280/3750]  eta: 0:03:04  Lr: 0.030000  Loss: -2.1908  Acc@1: 81.2500 (73.5827)  Acc@5: 100.0000 (97.7065)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3290/3750]  eta: 0:03:00  Lr: 0.030000  Loss: -1.5600  Acc@1: 81.2500 (73.5947)  Acc@5: 100.0000 (97.7097)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -1.8342  Acc@1: 75.0000 (73.6141)  Acc@5: 100.0000 (97.7109)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -0.8055  Acc@1: 81.2500 (73.6201)  Acc@5: 100.0000 (97.7141)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -1.5171  Acc@1: 75.0000 (73.6243)  Acc@5: 100.0000 (97.7134)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -1.5444  Acc@1: 75.0000 (73.6172)  Acc@5: 100.0000 (97.7128)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -1.0117  Acc@1: 75.0000 (73.6157)  Acc@5: 100.0000 (97.7159)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -1.8516  Acc@1: 75.0000 (73.6142)  Acc@5: 100.0000 (97.7190)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:32  Lr: 0.030000  Loss: -1.6331  Acc@1: 75.0000 (73.6314)  Acc@5: 100.0000 (97.7220)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -1.3319  Acc@1: 75.0000 (73.6465)  Acc@5: 100.0000 (97.7251)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -2.1937  Acc@1: 75.0000 (73.6598)  Acc@5: 100.0000 (97.7281)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -1.8631  Acc@1: 75.0000 (73.6693)  Acc@5: 100.0000 (97.7330)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -1.5112  Acc@1: 75.0000 (73.6860)  Acc@5: 100.0000 (97.7360)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -1.7433  Acc@1: 75.0000 (73.6899)  Acc@5: 100.0000 (97.7371)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -1.8031  Acc@1: 68.7500 (73.6791)  Acc@5: 100.0000 (97.7382)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -2.1046  Acc@1: 68.7500 (73.6848)  Acc@5: 100.0000 (97.7357)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -1.8246  Acc@1: 75.0000 (73.6941)  Acc@5: 100.0000 (97.7387)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -1.6741  Acc@1: 81.2500 (73.7105)  Acc@5: 100.0000 (97.7398)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -1.8656  Acc@1: 81.2500 (73.7377)  Acc@5: 100.0000 (97.7373)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -1.7493  Acc@1: 81.2500 (73.7594)  Acc@5: 100.0000 (97.7438)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -1.6909  Acc@1: 81.2500 (73.7755)  Acc@5: 100.0000 (97.7467)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:41  Lr: 0.030000  Loss: -1.8481  Acc@1: 75.0000 (73.7736)  Acc@5: 100.0000 (97.7496)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:37  Lr: 0.030000  Loss: -1.7847  Acc@1: 75.0000 (73.7593)  Acc@5: 100.0000 (97.7542)  time: 0.3939  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:34  Lr: 0.030000  Loss: -1.8857  Acc@1: 75.0000 (73.7539)  Acc@5: 100.0000 (97.7535)  time: 0.3937  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:30  Lr: 0.030000  Loss: -1.4202  Acc@1: 75.0000 (73.7504)  Acc@5: 100.0000 (97.7510)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -2.1574  Acc@1: 75.0000 (73.7450)  Acc@5: 100.0000 (97.7538)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -2.0225  Acc@1: 75.0000 (73.7574)  Acc@5: 100.0000 (97.7549)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -1.9024  Acc@1: 81.2500 (73.7750)  Acc@5: 100.0000 (97.7612)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -1.6072  Acc@1: 75.0000 (73.7644)  Acc@5: 100.0000 (97.7622)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -2.2202  Acc@1: 68.7500 (73.7749)  Acc@5: 100.0000 (97.7632)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -2.1223  Acc@1: 75.0000 (73.7940)  Acc@5: 100.0000 (97.7608)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -1.5419  Acc@1: 75.0000 (73.7886)  Acc@5: 100.0000 (97.7635)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -1.9275  Acc@1: 75.0000 (73.8094)  Acc@5: 100.0000 (97.7662)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -1.6667  Acc@1: 81.2500 (73.8213)  Acc@5: 100.0000 (97.7690)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:50  Lr: 0.030000  Loss: -1.6100  Acc@1: 75.0000 (73.8142)  Acc@5: 100.0000 (97.7682)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:47  Lr: 0.030000  Loss: -1.6819  Acc@1: 75.0000 (73.8226)  Acc@5: 100.0000 (97.7692)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -1.4407  Acc@1: 81.2500 (73.8327)  Acc@5: 100.0000 (97.7736)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -2.0411  Acc@1: 75.0000 (73.8291)  Acc@5: 100.0000 (97.7746)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -1.4762  Acc@1: 81.2500 (73.8545)  Acc@5: 100.0000 (97.7807)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -1.6557  Acc@1: 81.2500 (73.8576)  Acc@5: 100.0000 (97.7816)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -1.8862  Acc@1: 75.0000 (73.8556)  Acc@5: 100.0000 (97.7876)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -1.9735  Acc@1: 75.0000 (73.8570)  Acc@5: 100.0000 (97.7902)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -1.5653  Acc@1: 75.0000 (73.8517)  Acc@5: 100.0000 (97.7928)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -1.7206  Acc@1: 68.7500 (73.8413)  Acc@5: 100.0000 (97.7988)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -1.8016  Acc@1: 75.0000 (73.8478)  Acc@5: 100.0000 (97.8047)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -1.8610  Acc@1: 75.0000 (73.8525)  Acc@5: 100.0000 (97.8055)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -1.9231  Acc@1: 75.0000 (73.8606)  Acc@5: 100.0000 (97.8014)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -2.2070  Acc@1: 75.0000 (73.8767)  Acc@5: 100.0000 (97.8067)  time: 0.3913  data: 0.0008  max mem: 2912
Train: Epoch[1/5] Total time: 0:24:29 (0.3919 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}}
Averaged stats: Lr: 0.030000  Loss: -2.2070  Acc@1: 75.0000 (73.8767)  Acc@5: 100.0000 (97.8067)
Train: Epoch[2/5]  [   0/3750]  eta: 0:47:08  Lr: 0.030000  Loss: -1.8440  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7542  data: 0.3637  max mem: 2912
Train: Epoch[2/5]  [  10/3750]  eta: 0:26:33  Lr: 0.030000  Loss: -1.3288  Acc@1: 75.0000 (78.9773)  Acc@5: 100.0000 (99.4318)  time: 0.4260  data: 0.0334  max mem: 2912
Train: Epoch[2/5]  [  20/3750]  eta: 0:25:25  Lr: 0.030000  Loss: -1.6016  Acc@1: 75.0000 (76.1905)  Acc@5: 100.0000 (99.1071)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [  30/3750]  eta: 0:24:58  Lr: 0.030000  Loss: -2.0815  Acc@1: 81.2500 (79.0323)  Acc@5: 100.0000 (98.7903)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [  40/3750]  eta: 0:24:43  Lr: 0.030000  Loss: -1.5714  Acc@1: 87.5000 (79.2683)  Acc@5: 100.0000 (98.9329)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [  50/3750]  eta: 0:24:31  Lr: 0.030000  Loss: -2.3198  Acc@1: 81.2500 (79.0441)  Acc@5: 100.0000 (99.0196)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [  60/3750]  eta: 0:24:23  Lr: 0.030000  Loss: -1.5130  Acc@1: 75.0000 (78.5861)  Acc@5: 100.0000 (98.9754)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [  70/3750]  eta: 0:24:15  Lr: 0.030000  Loss: -1.9666  Acc@1: 75.0000 (79.0493)  Acc@5: 100.0000 (98.9437)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [  80/3750]  eta: 0:24:10  Lr: 0.030000  Loss: -2.0820  Acc@1: 75.0000 (78.2407)  Acc@5: 100.0000 (98.6111)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [  90/3750]  eta: 0:24:04  Lr: 0.030000  Loss: -1.8795  Acc@1: 75.0000 (77.9533)  Acc@5: 100.0000 (98.6951)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 100/3750]  eta: 0:24:01  Lr: 0.030000  Loss: -0.9975  Acc@1: 75.0000 (77.0421)  Acc@5: 100.0000 (98.2054)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 110/3750]  eta: 0:23:56  Lr: 0.030000  Loss: -1.0609  Acc@1: 75.0000 (76.6892)  Acc@5: 93.7500 (98.0293)  time: 0.3945  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 120/3750]  eta: 0:23:52  Lr: 0.030000  Loss: -1.5781  Acc@1: 75.0000 (76.7562)  Acc@5: 100.0000 (98.0888)  time: 0.3938  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 130/3750]  eta: 0:23:48  Lr: 0.030000  Loss: -1.7810  Acc@1: 75.0000 (76.9561)  Acc@5: 100.0000 (98.1393)  time: 0.3938  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 140/3750]  eta: 0:23:43  Lr: 0.030000  Loss: -1.4015  Acc@1: 75.0000 (76.7730)  Acc@5: 100.0000 (98.2270)  time: 0.3932  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [ 150/3750]  eta: 0:23:39  Lr: 0.030000  Loss: -1.6187  Acc@1: 75.0000 (76.7384)  Acc@5: 100.0000 (98.2202)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 160/3750]  eta: 0:23:34  Lr: 0.030000  Loss: -1.9159  Acc@1: 81.2500 (76.9410)  Acc@5: 100.0000 (98.2919)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 170/3750]  eta: 0:23:31  Lr: 0.030000  Loss: -1.9754  Acc@1: 81.2500 (77.3026)  Acc@5: 100.0000 (98.3553)  time: 0.3940  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 180/3750]  eta: 0:23:26  Lr: 0.030000  Loss: -1.5214  Acc@1: 81.2500 (77.5207)  Acc@5: 100.0000 (98.3425)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 190/3750]  eta: 0:23:22  Lr: 0.030000  Loss: -2.2095  Acc@1: 87.5000 (77.8469)  Acc@5: 100.0000 (98.3639)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 200/3750]  eta: 0:23:17  Lr: 0.030000  Loss: -1.6299  Acc@1: 81.2500 (77.8607)  Acc@5: 100.0000 (98.3520)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 210/3750]  eta: 0:23:13  Lr: 0.030000  Loss: -1.9438  Acc@1: 75.0000 (77.9325)  Acc@5: 100.0000 (98.3709)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 220/3750]  eta: 0:23:09  Lr: 0.030000  Loss: -1.6220  Acc@1: 75.0000 (77.8563)  Acc@5: 100.0000 (98.3597)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 230/3750]  eta: 0:23:04  Lr: 0.030000  Loss: -1.8683  Acc@1: 75.0000 (77.6515)  Acc@5: 100.0000 (98.3766)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 240/3750]  eta: 0:23:00  Lr: 0.030000  Loss: -1.4378  Acc@1: 68.7500 (77.4637)  Acc@5: 100.0000 (98.3921)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 250/3750]  eta: 0:22:55  Lr: 0.030000  Loss: -1.7428  Acc@1: 75.0000 (77.4402)  Acc@5: 100.0000 (98.3815)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 260/3750]  eta: 0:22:51  Lr: 0.030000  Loss: -1.2894  Acc@1: 75.0000 (77.2989)  Acc@5: 100.0000 (98.3477)  time: 0.3907  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 270/3750]  eta: 0:22:47  Lr: 0.030000  Loss: -1.9175  Acc@1: 75.0000 (77.3063)  Acc@5: 100.0000 (98.3625)  time: 0.3922  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [ 280/3750]  eta: 0:22:43  Lr: 0.030000  Loss: -1.3251  Acc@1: 75.0000 (77.2909)  Acc@5: 100.0000 (98.3319)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 290/3750]  eta: 0:22:38  Lr: 0.030000  Loss: -2.2154  Acc@1: 75.0000 (77.2122)  Acc@5: 100.0000 (98.3677)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 300/3750]  eta: 0:22:34  Lr: 0.030000  Loss: -2.0247  Acc@1: 75.0000 (77.1802)  Acc@5: 100.0000 (98.4012)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 310/3750]  eta: 0:22:30  Lr: 0.030000  Loss: -1.9114  Acc@1: 75.0000 (77.2709)  Acc@5: 100.0000 (98.3521)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 320/3750]  eta: 0:22:26  Lr: 0.030000  Loss: -1.1184  Acc@1: 75.0000 (77.2780)  Acc@5: 100.0000 (98.3840)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 330/3750]  eta: 0:22:22  Lr: 0.030000  Loss: -1.7357  Acc@1: 81.2500 (77.2847)  Acc@5: 100.0000 (98.3950)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 340/3750]  eta: 0:22:17  Lr: 0.030000  Loss: -1.7218  Acc@1: 75.0000 (77.0345)  Acc@5: 100.0000 (98.3688)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 350/3750]  eta: 0:22:13  Lr: 0.030000  Loss: -1.9396  Acc@1: 75.0000 (76.9943)  Acc@5: 100.0000 (98.3440)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 360/3750]  eta: 0:22:09  Lr: 0.030000  Loss: -1.7385  Acc@1: 68.7500 (76.7486)  Acc@5: 100.0000 (98.3553)  time: 0.3880  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 370/3750]  eta: 0:22:04  Lr: 0.030000  Loss: -1.4997  Acc@1: 68.7500 (76.6341)  Acc@5: 100.0000 (98.3322)  time: 0.3880  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 380/3750]  eta: 0:22:00  Lr: 0.030000  Loss: -1.5419  Acc@1: 75.0000 (76.5748)  Acc@5: 100.0000 (98.3268)  time: 0.3882  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [ 390/3750]  eta: 0:21:56  Lr: 0.030000  Loss: -1.8590  Acc@1: 75.0000 (76.5185)  Acc@5: 100.0000 (98.3536)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 400/3750]  eta: 0:21:52  Lr: 0.030000  Loss: -1.8129  Acc@1: 75.0000 (76.5898)  Acc@5: 100.0000 (98.3635)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 410/3750]  eta: 0:21:48  Lr: 0.030000  Loss: -1.6051  Acc@1: 75.0000 (76.6575)  Acc@5: 100.0000 (98.3729)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 420/3750]  eta: 0:21:44  Lr: 0.030000  Loss: -1.7704  Acc@1: 75.0000 (76.6479)  Acc@5: 100.0000 (98.3373)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 430/3750]  eta: 0:21:40  Lr: 0.030000  Loss: -1.9551  Acc@1: 75.0000 (76.7546)  Acc@5: 100.0000 (98.3469)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 440/3750]  eta: 0:21:36  Lr: 0.030000  Loss: -1.6991  Acc@1: 81.2500 (76.8141)  Acc@5: 100.0000 (98.3702)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 450/3750]  eta: 0:21:33  Lr: 0.030000  Loss: -2.0853  Acc@1: 81.2500 (76.8570)  Acc@5: 100.0000 (98.3925)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 460/3750]  eta: 0:21:29  Lr: 0.030000  Loss: -1.7963  Acc@1: 75.0000 (76.7896)  Acc@5: 100.0000 (98.3867)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 470/3750]  eta: 0:21:25  Lr: 0.030000  Loss: -1.9039  Acc@1: 68.7500 (76.6852)  Acc@5: 100.0000 (98.3811)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 480/3750]  eta: 0:21:21  Lr: 0.030000  Loss: -1.0613  Acc@1: 75.0000 (76.6892)  Acc@5: 100.0000 (98.3108)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 490/3750]  eta: 0:21:17  Lr: 0.030000  Loss: -1.8587  Acc@1: 81.2500 (76.7693)  Acc@5: 93.7500 (98.3070)  time: 0.3934  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 500/3750]  eta: 0:21:13  Lr: 0.030000  Loss: -1.6445  Acc@1: 75.0000 (76.7091)  Acc@5: 100.0000 (98.3034)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 510/3750]  eta: 0:21:09  Lr: 0.030000  Loss: -1.7070  Acc@1: 75.0000 (76.6879)  Acc@5: 100.0000 (98.2754)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 520/3750]  eta: 0:21:05  Lr: 0.030000  Loss: -1.4976  Acc@1: 75.0000 (76.6915)  Acc@5: 100.0000 (98.2845)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 530/3750]  eta: 0:21:01  Lr: 0.030000  Loss: -1.6653  Acc@1: 75.0000 (76.7302)  Acc@5: 100.0000 (98.3051)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 540/3750]  eta: 0:20:57  Lr: 0.030000  Loss: -1.5895  Acc@1: 81.2500 (76.7560)  Acc@5: 100.0000 (98.3249)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 550/3750]  eta: 0:20:53  Lr: 0.030000  Loss: -2.0420  Acc@1: 81.2500 (76.8603)  Acc@5: 100.0000 (98.3212)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 560/3750]  eta: 0:20:49  Lr: 0.030000  Loss: -1.6633  Acc@1: 81.2500 (76.9385)  Acc@5: 100.0000 (98.2955)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 570/3750]  eta: 0:20:45  Lr: 0.030000  Loss: -2.0070  Acc@1: 75.0000 (76.9374)  Acc@5: 100.0000 (98.3034)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 580/3750]  eta: 0:20:42  Lr: 0.030000  Loss: -1.3813  Acc@1: 75.0000 (76.9256)  Acc@5: 100.0000 (98.3111)  time: 0.3940  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 590/3750]  eta: 0:20:38  Lr: 0.030000  Loss: -1.9651  Acc@1: 81.2500 (76.9987)  Acc@5: 100.0000 (98.3080)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 600/3750]  eta: 0:20:34  Lr: 0.030000  Loss: -1.7785  Acc@1: 81.2500 (76.9655)  Acc@5: 100.0000 (98.2841)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 610/3750]  eta: 0:20:30  Lr: 0.030000  Loss: -1.9059  Acc@1: 81.2500 (77.0765)  Acc@5: 100.0000 (98.3122)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 620/3750]  eta: 0:20:26  Lr: 0.030000  Loss: -1.9831  Acc@1: 81.2500 (77.1337)  Acc@5: 100.0000 (98.3293)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 630/3750]  eta: 0:20:22  Lr: 0.030000  Loss: -1.5565  Acc@1: 81.2500 (77.1395)  Acc@5: 100.0000 (98.3162)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 640/3750]  eta: 0:20:18  Lr: 0.030000  Loss: -1.3634  Acc@1: 81.2500 (77.1743)  Acc@5: 100.0000 (98.3034)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 650/3750]  eta: 0:20:14  Lr: 0.030000  Loss: -2.1247  Acc@1: 81.2500 (77.2369)  Acc@5: 100.0000 (98.3007)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 660/3750]  eta: 0:20:10  Lr: 0.030000  Loss: -2.0618  Acc@1: 81.2500 (77.3449)  Acc@5: 100.0000 (98.3075)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 670/3750]  eta: 0:20:06  Lr: 0.030000  Loss: -1.6708  Acc@1: 87.5000 (77.4404)  Acc@5: 100.0000 (98.3234)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 680/3750]  eta: 0:20:02  Lr: 0.030000  Loss: -2.2591  Acc@1: 81.2500 (77.4229)  Acc@5: 100.0000 (98.3205)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 690/3750]  eta: 0:19:58  Lr: 0.030000  Loss: -1.6209  Acc@1: 75.0000 (77.4692)  Acc@5: 100.0000 (98.3086)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 700/3750]  eta: 0:19:54  Lr: 0.030000  Loss: -1.7193  Acc@1: 75.0000 (77.4786)  Acc@5: 100.0000 (98.3149)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 710/3750]  eta: 0:19:50  Lr: 0.030000  Loss: -1.8201  Acc@1: 75.0000 (77.4965)  Acc@5: 100.0000 (98.3034)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 720/3750]  eta: 0:19:46  Lr: 0.030000  Loss: -1.7142  Acc@1: 81.2500 (77.5312)  Acc@5: 100.0000 (98.3096)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 730/3750]  eta: 0:19:42  Lr: 0.030000  Loss: -1.7022  Acc@1: 81.2500 (77.5650)  Acc@5: 100.0000 (98.3157)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 740/3750]  eta: 0:19:38  Lr: 0.030000  Loss: -2.1093  Acc@1: 81.2500 (77.6231)  Acc@5: 100.0000 (98.2878)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 750/3750]  eta: 0:19:34  Lr: 0.030000  Loss: -1.3506  Acc@1: 81.2500 (77.6381)  Acc@5: 100.0000 (98.2856)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 760/3750]  eta: 0:19:31  Lr: 0.030000  Loss: -2.1587  Acc@1: 81.2500 (77.6199)  Acc@5: 100.0000 (98.2917)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 770/3750]  eta: 0:19:27  Lr: 0.030000  Loss: -1.5839  Acc@1: 81.2500 (77.6670)  Acc@5: 100.0000 (98.2896)  time: 0.3933  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 780/3750]  eta: 0:19:23  Lr: 0.030000  Loss: -2.1189  Acc@1: 75.0000 (77.6969)  Acc@5: 100.0000 (98.2875)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 790/3750]  eta: 0:19:19  Lr: 0.030000  Loss: -1.9553  Acc@1: 81.2500 (77.7734)  Acc@5: 100.0000 (98.3012)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 800/3750]  eta: 0:19:15  Lr: 0.030000  Loss: -2.0776  Acc@1: 81.2500 (77.8246)  Acc@5: 100.0000 (98.2912)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 810/3750]  eta: 0:19:11  Lr: 0.030000  Loss: -2.0498  Acc@1: 81.2500 (77.8591)  Acc@5: 100.0000 (98.3046)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 820/3750]  eta: 0:19:07  Lr: 0.030000  Loss: -1.9752  Acc@1: 81.2500 (77.9080)  Acc@5: 100.0000 (98.3100)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 830/3750]  eta: 0:19:03  Lr: 0.030000  Loss: -2.0413  Acc@1: 81.2500 (77.8655)  Acc@5: 100.0000 (98.3153)  time: 0.3926  data: 0.0012  max mem: 2912
Train: Epoch[2/5]  [ 840/3750]  eta: 0:18:59  Lr: 0.030000  Loss: -1.8629  Acc@1: 81.2500 (77.9132)  Acc@5: 100.0000 (98.3205)  time: 0.3910  data: 0.0011  max mem: 2912
Train: Epoch[2/5]  [ 850/3750]  eta: 0:18:55  Lr: 0.030000  Loss: -1.7523  Acc@1: 81.2500 (77.9083)  Acc@5: 100.0000 (98.3255)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 860/3750]  eta: 0:18:51  Lr: 0.030000  Loss: -1.5960  Acc@1: 81.2500 (77.9762)  Acc@5: 100.0000 (98.3377)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 870/3750]  eta: 0:18:47  Lr: 0.030000  Loss: -1.7531  Acc@1: 81.2500 (77.9707)  Acc@5: 100.0000 (98.3496)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 880/3750]  eta: 0:18:43  Lr: 0.030000  Loss: -1.8696  Acc@1: 75.0000 (78.0221)  Acc@5: 100.0000 (98.3683)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 890/3750]  eta: 0:18:39  Lr: 0.030000  Loss: -1.3598  Acc@1: 75.0000 (77.9672)  Acc@5: 100.0000 (98.3656)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 900/3750]  eta: 0:18:35  Lr: 0.030000  Loss: -1.6904  Acc@1: 75.0000 (77.9828)  Acc@5: 100.0000 (98.3768)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [ 910/3750]  eta: 0:18:32  Lr: 0.030000  Loss: -1.9163  Acc@1: 75.0000 (77.9775)  Acc@5: 100.0000 (98.3603)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [ 920/3750]  eta: 0:18:28  Lr: 0.030000  Loss: -1.6735  Acc@1: 75.0000 (77.9316)  Acc@5: 100.0000 (98.3645)  time: 0.3937  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [ 930/3750]  eta: 0:18:24  Lr: 0.030000  Loss: -2.1931  Acc@1: 75.0000 (77.9404)  Acc@5: 100.0000 (98.3687)  time: 0.3944  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [ 940/3750]  eta: 0:18:20  Lr: 0.030000  Loss: -1.4853  Acc@1: 81.2500 (77.9689)  Acc@5: 100.0000 (98.3794)  time: 0.3947  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 950/3750]  eta: 0:18:16  Lr: 0.030000  Loss: -1.6866  Acc@1: 81.2500 (77.9903)  Acc@5: 100.0000 (98.3964)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 960/3750]  eta: 0:18:12  Lr: 0.030000  Loss: -1.5707  Acc@1: 75.0000 (78.0047)  Acc@5: 100.0000 (98.4001)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 970/3750]  eta: 0:18:08  Lr: 0.030000  Loss: -2.0744  Acc@1: 81.2500 (78.0252)  Acc@5: 100.0000 (98.3973)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 980/3750]  eta: 0:18:05  Lr: 0.030000  Loss: -1.8917  Acc@1: 81.2500 (78.0262)  Acc@5: 100.0000 (98.4009)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [ 990/3750]  eta: 0:18:01  Lr: 0.030000  Loss: -1.5361  Acc@1: 75.0000 (78.0336)  Acc@5: 100.0000 (98.3918)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1000/3750]  eta: 0:17:57  Lr: 0.030000  Loss: -1.9253  Acc@1: 81.2500 (78.0657)  Acc@5: 100.0000 (98.3891)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1010/3750]  eta: 0:17:53  Lr: 0.030000  Loss: -1.8001  Acc@1: 81.2500 (78.0848)  Acc@5: 100.0000 (98.3865)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1020/3750]  eta: 0:17:49  Lr: 0.030000  Loss: -1.6673  Acc@1: 75.0000 (78.0791)  Acc@5: 100.0000 (98.3778)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1030/3750]  eta: 0:17:45  Lr: 0.030000  Loss: -1.6482  Acc@1: 75.0000 (78.0492)  Acc@5: 100.0000 (98.3875)  time: 0.3936  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1040/3750]  eta: 0:17:41  Lr: 0.030000  Loss: -1.9083  Acc@1: 81.2500 (78.1160)  Acc@5: 100.0000 (98.4030)  time: 0.3953  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1050/3750]  eta: 0:17:37  Lr: 0.030000  Loss: -1.9847  Acc@1: 81.2500 (78.1042)  Acc@5: 100.0000 (98.4003)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1060/3750]  eta: 0:17:33  Lr: 0.030000  Loss: -1.7691  Acc@1: 81.2500 (78.1456)  Acc@5: 100.0000 (98.4095)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1070/3750]  eta: 0:17:29  Lr: 0.030000  Loss: -1.8835  Acc@1: 81.2500 (78.1629)  Acc@5: 100.0000 (98.4127)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1080/3750]  eta: 0:17:26  Lr: 0.030000  Loss: -1.7154  Acc@1: 75.0000 (78.1568)  Acc@5: 100.0000 (98.4158)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1090/3750]  eta: 0:17:22  Lr: 0.030000  Loss: -1.9768  Acc@1: 75.0000 (78.1852)  Acc@5: 100.0000 (98.4189)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1100/3750]  eta: 0:17:18  Lr: 0.030000  Loss: -1.7996  Acc@1: 81.2500 (78.1676)  Acc@5: 100.0000 (98.4332)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1110/3750]  eta: 0:17:14  Lr: 0.030000  Loss: -2.2478  Acc@1: 81.2500 (78.2122)  Acc@5: 100.0000 (98.4417)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1120/3750]  eta: 0:17:10  Lr: 0.030000  Loss: -1.8601  Acc@1: 81.2500 (78.1724)  Acc@5: 100.0000 (98.4277)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1130/3750]  eta: 0:17:06  Lr: 0.030000  Loss: -1.6264  Acc@1: 75.0000 (78.1499)  Acc@5: 100.0000 (98.4251)  time: 0.3875  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1140/3750]  eta: 0:17:02  Lr: 0.030000  Loss: -2.0187  Acc@1: 75.0000 (78.1442)  Acc@5: 100.0000 (98.4170)  time: 0.3877  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1150/3750]  eta: 0:16:58  Lr: 0.030000  Loss: -1.5582  Acc@1: 81.2500 (78.1440)  Acc@5: 100.0000 (98.4144)  time: 0.3876  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1160/3750]  eta: 0:16:54  Lr: 0.030000  Loss: -1.6720  Acc@1: 81.2500 (78.1761)  Acc@5: 100.0000 (98.4173)  time: 0.3879  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [1170/3750]  eta: 0:16:50  Lr: 0.030000  Loss: -1.8981  Acc@1: 81.2500 (78.1757)  Acc@5: 100.0000 (98.4095)  time: 0.3879  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [1180/3750]  eta: 0:16:46  Lr: 0.030000  Loss: -1.3196  Acc@1: 75.0000 (78.1224)  Acc@5: 100.0000 (98.4124)  time: 0.3877  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [1190/3750]  eta: 0:16:42  Lr: 0.030000  Loss: -2.0542  Acc@1: 75.0000 (78.1276)  Acc@5: 100.0000 (98.4047)  time: 0.3875  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [1200/3750]  eta: 0:16:38  Lr: 0.030000  Loss: -1.5102  Acc@1: 81.2500 (78.1328)  Acc@5: 100.0000 (98.4024)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1210/3750]  eta: 0:16:34  Lr: 0.030000  Loss: -1.8828  Acc@1: 81.2500 (78.1482)  Acc@5: 100.0000 (98.4001)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1220/3750]  eta: 0:16:30  Lr: 0.030000  Loss: -1.4229  Acc@1: 75.0000 (78.1378)  Acc@5: 100.0000 (98.3927)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1230/3750]  eta: 0:16:26  Lr: 0.030000  Loss: -1.6105  Acc@1: 75.0000 (78.1682)  Acc@5: 100.0000 (98.3905)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1240/3750]  eta: 0:16:22  Lr: 0.030000  Loss: -1.7519  Acc@1: 75.0000 (78.1426)  Acc@5: 100.0000 (98.3934)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1250/3750]  eta: 0:16:18  Lr: 0.030000  Loss: -1.8083  Acc@1: 75.0000 (78.1475)  Acc@5: 100.0000 (98.4013)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1260/3750]  eta: 0:16:14  Lr: 0.030000  Loss: -1.7142  Acc@1: 75.0000 (78.1225)  Acc@5: 100.0000 (98.3842)  time: 0.3922  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [1270/3750]  eta: 0:16:10  Lr: 0.030000  Loss: -2.0176  Acc@1: 75.0000 (78.1570)  Acc@5: 100.0000 (98.3920)  time: 0.3917  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [1280/3750]  eta: 0:16:06  Lr: 0.030000  Loss: -1.3149  Acc@1: 75.0000 (78.1128)  Acc@5: 100.0000 (98.3802)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1290/3750]  eta: 0:16:03  Lr: 0.030000  Loss: -1.6559  Acc@1: 75.0000 (78.1177)  Acc@5: 100.0000 (98.3782)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1300/3750]  eta: 0:15:59  Lr: 0.030000  Loss: -1.2574  Acc@1: 81.2500 (78.1130)  Acc@5: 100.0000 (98.3859)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1310/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -1.2841  Acc@1: 81.2500 (78.0988)  Acc@5: 100.0000 (98.3886)  time: 0.3906  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1320/3750]  eta: 0:15:51  Lr: 0.030000  Loss: -1.7045  Acc@1: 81.2500 (78.1179)  Acc@5: 100.0000 (98.3866)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1330/3750]  eta: 0:15:47  Lr: 0.030000  Loss: -1.8522  Acc@1: 81.2500 (78.1320)  Acc@5: 100.0000 (98.3753)  time: 0.3946  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1340/3750]  eta: 0:15:43  Lr: 0.030000  Loss: -1.5962  Acc@1: 75.0000 (78.1087)  Acc@5: 100.0000 (98.3641)  time: 0.3946  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1350/3750]  eta: 0:15:39  Lr: 0.030000  Loss: -2.2152  Acc@1: 81.2500 (78.1319)  Acc@5: 100.0000 (98.3716)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1360/3750]  eta: 0:15:35  Lr: 0.030000  Loss: -1.5590  Acc@1: 81.2500 (78.1043)  Acc@5: 100.0000 (98.3560)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1370/3750]  eta: 0:15:31  Lr: 0.030000  Loss: -2.1677  Acc@1: 75.0000 (78.1182)  Acc@5: 100.0000 (98.3452)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1380/3750]  eta: 0:15:27  Lr: 0.030000  Loss: -1.6154  Acc@1: 75.0000 (78.0820)  Acc@5: 100.0000 (98.3391)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1390/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -1.9163  Acc@1: 75.0000 (78.0778)  Acc@5: 100.0000 (98.3375)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1400/3750]  eta: 0:15:20  Lr: 0.030000  Loss: -1.6197  Acc@1: 75.0000 (78.0915)  Acc@5: 100.0000 (98.3405)  time: 0.3923  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1410/3750]  eta: 0:15:16  Lr: 0.030000  Loss: -1.7415  Acc@1: 75.0000 (78.0785)  Acc@5: 100.0000 (98.3301)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1420/3750]  eta: 0:15:12  Lr: 0.030000  Loss: -1.4420  Acc@1: 75.0000 (78.0876)  Acc@5: 100.0000 (98.3286)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1430/3750]  eta: 0:15:08  Lr: 0.030000  Loss: -1.9883  Acc@1: 75.0000 (78.0573)  Acc@5: 100.0000 (98.3316)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1440/3750]  eta: 0:15:04  Lr: 0.030000  Loss: -1.8392  Acc@1: 75.0000 (78.0231)  Acc@5: 100.0000 (98.3302)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1450/3750]  eta: 0:15:00  Lr: 0.030000  Loss: -1.6431  Acc@1: 75.0000 (78.0238)  Acc@5: 100.0000 (98.3244)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1460/3750]  eta: 0:14:56  Lr: 0.030000  Loss: -1.6296  Acc@1: 75.0000 (78.0202)  Acc@5: 100.0000 (98.3231)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1470/3750]  eta: 0:14:52  Lr: 0.030000  Loss: -1.6029  Acc@1: 81.2500 (78.0337)  Acc@5: 100.0000 (98.3260)  time: 0.3908  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [1480/3750]  eta: 0:14:48  Lr: 0.030000  Loss: -1.7037  Acc@1: 81.2500 (78.0427)  Acc@5: 100.0000 (98.3288)  time: 0.3916  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [1490/3750]  eta: 0:14:44  Lr: 0.030000  Loss: -1.7263  Acc@1: 81.2500 (78.0684)  Acc@5: 100.0000 (98.3358)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1500/3750]  eta: 0:14:40  Lr: 0.030000  Loss: -1.9874  Acc@1: 75.0000 (78.0563)  Acc@5: 100.0000 (98.3428)  time: 0.3947  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [1510/3750]  eta: 0:14:37  Lr: 0.030000  Loss: -2.1108  Acc@1: 75.0000 (78.0361)  Acc@5: 100.0000 (98.3372)  time: 0.3942  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [1520/3750]  eta: 0:14:33  Lr: 0.030000  Loss: -0.6986  Acc@1: 75.0000 (78.0243)  Acc@5: 100.0000 (98.3317)  time: 0.3917  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [1530/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -1.3878  Acc@1: 75.0000 (78.0250)  Acc@5: 100.0000 (98.3222)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1540/3750]  eta: 0:14:25  Lr: 0.030000  Loss: -1.9656  Acc@1: 81.2500 (78.0054)  Acc@5: 100.0000 (98.3168)  time: 0.3924  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1550/3750]  eta: 0:14:21  Lr: 0.030000  Loss: -2.1624  Acc@1: 81.2500 (78.0585)  Acc@5: 100.0000 (98.3196)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1560/3750]  eta: 0:14:17  Lr: 0.030000  Loss: -1.3120  Acc@1: 81.2500 (78.0549)  Acc@5: 100.0000 (98.3264)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1570/3750]  eta: 0:14:13  Lr: 0.030000  Loss: -1.6056  Acc@1: 81.2500 (78.0594)  Acc@5: 100.0000 (98.3331)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1580/3750]  eta: 0:14:09  Lr: 0.030000  Loss: -1.7309  Acc@1: 81.2500 (78.0954)  Acc@5: 100.0000 (98.3397)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1590/3750]  eta: 0:14:05  Lr: 0.030000  Loss: -1.9075  Acc@1: 81.2500 (78.1505)  Acc@5: 100.0000 (98.3501)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1600/3750]  eta: 0:14:01  Lr: 0.030000  Loss: -2.0046  Acc@1: 81.2500 (78.1621)  Acc@5: 100.0000 (98.3565)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1610/3750]  eta: 0:13:57  Lr: 0.030000  Loss: -1.7985  Acc@1: 81.2500 (78.1696)  Acc@5: 100.0000 (98.3628)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1620/3750]  eta: 0:13:53  Lr: 0.030000  Loss: -2.0537  Acc@1: 81.2500 (78.1732)  Acc@5: 100.0000 (98.3652)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1630/3750]  eta: 0:13:49  Lr: 0.030000  Loss: -1.8655  Acc@1: 75.0000 (78.1499)  Acc@5: 100.0000 (98.3599)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1640/3750]  eta: 0:13:46  Lr: 0.030000  Loss: -2.2396  Acc@1: 75.0000 (78.1574)  Acc@5: 100.0000 (98.3623)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1650/3750]  eta: 0:13:42  Lr: 0.030000  Loss: -1.9987  Acc@1: 81.2500 (78.1534)  Acc@5: 100.0000 (98.3646)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1660/3750]  eta: 0:13:38  Lr: 0.030000  Loss: -2.2277  Acc@1: 81.2500 (78.1570)  Acc@5: 100.0000 (98.3594)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1670/3750]  eta: 0:13:34  Lr: 0.030000  Loss: -1.9465  Acc@1: 81.2500 (78.1643)  Acc@5: 100.0000 (98.3618)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1680/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -1.8092  Acc@1: 81.2500 (78.1640)  Acc@5: 100.0000 (98.3604)  time: 0.3904  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1690/3750]  eta: 0:13:26  Lr: 0.030000  Loss: -1.5865  Acc@1: 75.0000 (78.1416)  Acc@5: 100.0000 (98.3664)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1700/3750]  eta: 0:13:22  Lr: 0.030000  Loss: -1.9479  Acc@1: 75.0000 (78.1305)  Acc@5: 100.0000 (98.3613)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1710/3750]  eta: 0:13:18  Lr: 0.030000  Loss: -1.8651  Acc@1: 75.0000 (78.1232)  Acc@5: 100.0000 (98.3635)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1720/3750]  eta: 0:13:14  Lr: 0.030000  Loss: -1.6114  Acc@1: 75.0000 (78.0723)  Acc@5: 100.0000 (98.3549)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1730/3750]  eta: 0:13:10  Lr: 0.030000  Loss: -1.4405  Acc@1: 75.0000 (78.0474)  Acc@5: 100.0000 (98.3536)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1740/3750]  eta: 0:13:06  Lr: 0.030000  Loss: -1.9648  Acc@1: 75.0000 (78.0514)  Acc@5: 100.0000 (98.3594)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1750/3750]  eta: 0:13:02  Lr: 0.030000  Loss: -1.7791  Acc@1: 75.0000 (78.0304)  Acc@5: 100.0000 (98.3474)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1760/3750]  eta: 0:12:58  Lr: 0.030000  Loss: -1.4182  Acc@1: 75.0000 (78.0061)  Acc@5: 100.0000 (98.3532)  time: 0.3886  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1770/3750]  eta: 0:12:54  Lr: 0.030000  Loss: -1.6371  Acc@1: 75.0000 (78.0068)  Acc@5: 100.0000 (98.3590)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1780/3750]  eta: 0:12:50  Lr: 0.030000  Loss: -1.9782  Acc@1: 75.0000 (77.9829)  Acc@5: 100.0000 (98.3401)  time: 0.3882  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1790/3750]  eta: 0:12:47  Lr: 0.030000  Loss: -1.5369  Acc@1: 75.0000 (77.9662)  Acc@5: 100.0000 (98.3354)  time: 0.3882  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [1800/3750]  eta: 0:12:43  Lr: 0.030000  Loss: -2.2418  Acc@1: 75.0000 (77.9775)  Acc@5: 100.0000 (98.3377)  time: 0.3882  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [1810/3750]  eta: 0:12:39  Lr: 0.030000  Loss: -1.9310  Acc@1: 81.2500 (77.9714)  Acc@5: 100.0000 (98.3366)  time: 0.3890  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1820/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -1.8603  Acc@1: 75.0000 (77.9414)  Acc@5: 100.0000 (98.3388)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1830/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -2.1930  Acc@1: 75.0000 (77.9731)  Acc@5: 100.0000 (98.3445)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1840/3750]  eta: 0:12:27  Lr: 0.030000  Loss: -1.7107  Acc@1: 87.5000 (78.0181)  Acc@5: 100.0000 (98.3501)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1850/3750]  eta: 0:12:23  Lr: 0.030000  Loss: -1.6210  Acc@1: 81.2500 (78.0321)  Acc@5: 100.0000 (98.3556)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1860/3750]  eta: 0:12:19  Lr: 0.030000  Loss: -1.8035  Acc@1: 81.2500 (78.0394)  Acc@5: 100.0000 (98.3611)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1870/3750]  eta: 0:12:15  Lr: 0.030000  Loss: -1.7774  Acc@1: 75.0000 (78.0231)  Acc@5: 100.0000 (98.3465)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1880/3750]  eta: 0:12:11  Lr: 0.030000  Loss: -1.5620  Acc@1: 75.0000 (78.0369)  Acc@5: 100.0000 (98.3553)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1890/3750]  eta: 0:12:07  Lr: 0.030000  Loss: -1.7746  Acc@1: 75.0000 (78.0341)  Acc@5: 100.0000 (98.3640)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1900/3750]  eta: 0:12:03  Lr: 0.030000  Loss: -2.0384  Acc@1: 75.0000 (78.0313)  Acc@5: 100.0000 (98.3627)  time: 0.3903  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1910/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -1.5997  Acc@1: 75.0000 (78.0089)  Acc@5: 100.0000 (98.3582)  time: 0.3906  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [1920/3750]  eta: 0:11:56  Lr: 0.030000  Loss: -1.6400  Acc@1: 75.0000 (77.9835)  Acc@5: 100.0000 (98.3505)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [1930/3750]  eta: 0:11:52  Lr: 0.030000  Loss: -1.9750  Acc@1: 81.2500 (78.0166)  Acc@5: 100.0000 (98.3525)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1940/3750]  eta: 0:11:48  Lr: 0.030000  Loss: -1.4505  Acc@1: 81.2500 (78.0332)  Acc@5: 100.0000 (98.3546)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1950/3750]  eta: 0:11:44  Lr: 0.030000  Loss: -1.9678  Acc@1: 81.2500 (78.0369)  Acc@5: 100.0000 (98.3534)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1960/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -1.7078  Acc@1: 81.2500 (78.0374)  Acc@5: 100.0000 (98.3554)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1970/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -1.6747  Acc@1: 81.2500 (78.0346)  Acc@5: 100.0000 (98.3606)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1980/3750]  eta: 0:11:32  Lr: 0.030000  Loss: -1.5339  Acc@1: 75.0000 (78.0382)  Acc@5: 100.0000 (98.3626)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [1990/3750]  eta: 0:11:28  Lr: 0.030000  Loss: -1.8327  Acc@1: 75.0000 (78.0387)  Acc@5: 100.0000 (98.3677)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2000/3750]  eta: 0:11:24  Lr: 0.030000  Loss: -1.5268  Acc@1: 75.0000 (78.0266)  Acc@5: 100.0000 (98.3758)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2010/3750]  eta: 0:11:20  Lr: 0.030000  Loss: -1.6440  Acc@1: 75.0000 (78.0240)  Acc@5: 100.0000 (98.3746)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2020/3750]  eta: 0:11:16  Lr: 0.030000  Loss: -2.0833  Acc@1: 81.2500 (78.0523)  Acc@5: 100.0000 (98.3795)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2030/3750]  eta: 0:11:12  Lr: 0.030000  Loss: -1.7942  Acc@1: 81.2500 (78.0711)  Acc@5: 100.0000 (98.3875)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2040/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -1.9556  Acc@1: 81.2500 (78.0714)  Acc@5: 100.0000 (98.3923)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2050/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -1.0552  Acc@1: 75.0000 (78.0686)  Acc@5: 100.0000 (98.3880)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2060/3750]  eta: 0:11:01  Lr: 0.030000  Loss: -2.0200  Acc@1: 75.0000 (78.0568)  Acc@5: 100.0000 (98.3837)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2070/3750]  eta: 0:10:57  Lr: 0.030000  Loss: -2.0534  Acc@1: 75.0000 (78.0541)  Acc@5: 100.0000 (98.3915)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2080/3750]  eta: 0:10:53  Lr: 0.030000  Loss: -1.9087  Acc@1: 81.2500 (78.0574)  Acc@5: 100.0000 (98.3992)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2090/3750]  eta: 0:10:49  Lr: 0.030000  Loss: -2.1715  Acc@1: 81.2500 (78.0757)  Acc@5: 100.0000 (98.4039)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2100/3750]  eta: 0:10:45  Lr: 0.030000  Loss: -1.6535  Acc@1: 81.2500 (78.0670)  Acc@5: 100.0000 (98.4055)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2110/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -1.4153  Acc@1: 75.0000 (78.0436)  Acc@5: 100.0000 (98.3923)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2120/3750]  eta: 0:10:37  Lr: 0.030000  Loss: -2.1675  Acc@1: 75.0000 (78.0440)  Acc@5: 100.0000 (98.3911)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2130/3750]  eta: 0:10:33  Lr: 0.030000  Loss: -2.0399  Acc@1: 81.2500 (78.0678)  Acc@5: 100.0000 (98.3898)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2140/3750]  eta: 0:10:29  Lr: 0.030000  Loss: -2.3485  Acc@1: 87.5000 (78.1089)  Acc@5: 100.0000 (98.3974)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2150/3750]  eta: 0:10:25  Lr: 0.030000  Loss: -1.4783  Acc@1: 81.2500 (78.0800)  Acc@5: 100.0000 (98.3874)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2160/3750]  eta: 0:10:22  Lr: 0.030000  Loss: -0.9718  Acc@1: 75.0000 (78.0831)  Acc@5: 100.0000 (98.3833)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2170/3750]  eta: 0:10:18  Lr: 0.030000  Loss: -1.9324  Acc@1: 75.0000 (78.0717)  Acc@5: 100.0000 (98.3907)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2180/3750]  eta: 0:10:14  Lr: 0.030000  Loss: -0.7470  Acc@1: 81.2500 (78.0691)  Acc@5: 100.0000 (98.3924)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2190/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -1.6169  Acc@1: 81.2500 (78.0779)  Acc@5: 100.0000 (98.3940)  time: 0.3954  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2200/3750]  eta: 0:10:06  Lr: 0.030000  Loss: -1.6841  Acc@1: 81.2500 (78.1065)  Acc@5: 100.0000 (98.3956)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2210/3750]  eta: 0:10:02  Lr: 0.030000  Loss: -1.7558  Acc@1: 75.0000 (78.0868)  Acc@5: 100.0000 (98.3916)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2220/3750]  eta: 0:09:58  Lr: 0.030000  Loss: -1.7097  Acc@1: 75.0000 (78.0955)  Acc@5: 100.0000 (98.3988)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2230/3750]  eta: 0:09:54  Lr: 0.030000  Loss: -1.9989  Acc@1: 81.2500 (78.1040)  Acc@5: 100.0000 (98.3976)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2240/3750]  eta: 0:09:50  Lr: 0.030000  Loss: -1.4479  Acc@1: 81.2500 (78.1208)  Acc@5: 100.0000 (98.3992)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2250/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -1.8904  Acc@1: 81.2500 (78.1125)  Acc@5: 100.0000 (98.4007)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2260/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -1.7878  Acc@1: 75.0000 (78.1209)  Acc@5: 100.0000 (98.4050)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2270/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -1.8169  Acc@1: 75.0000 (78.1209)  Acc@5: 100.0000 (98.4065)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2280/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -2.2119  Acc@1: 75.0000 (78.1209)  Acc@5: 100.0000 (98.4080)  time: 0.3888  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [2290/3750]  eta: 0:09:31  Lr: 0.030000  Loss: -2.1623  Acc@1: 75.0000 (78.1318)  Acc@5: 100.0000 (98.4123)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2300/3750]  eta: 0:09:27  Lr: 0.030000  Loss: -1.6426  Acc@1: 75.0000 (78.1454)  Acc@5: 100.0000 (98.4192)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2310/3750]  eta: 0:09:23  Lr: 0.030000  Loss: -1.5841  Acc@1: 87.5000 (78.1777)  Acc@5: 100.0000 (98.4233)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2320/3750]  eta: 0:09:19  Lr: 0.030000  Loss: -1.1471  Acc@1: 81.2500 (78.1910)  Acc@5: 100.0000 (98.4220)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2330/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -2.2361  Acc@1: 81.2500 (78.2014)  Acc@5: 100.0000 (98.4207)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2340/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -1.7828  Acc@1: 81.2500 (78.2038)  Acc@5: 100.0000 (98.4221)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2350/3750]  eta: 0:09:07  Lr: 0.030000  Loss: -1.9863  Acc@1: 81.2500 (78.2300)  Acc@5: 100.0000 (98.4262)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2360/3750]  eta: 0:09:03  Lr: 0.030000  Loss: -1.7769  Acc@1: 81.2500 (78.2428)  Acc@5: 100.0000 (98.4302)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:59  Lr: 0.030000  Loss: -2.0846  Acc@1: 87.5000 (78.2792)  Acc@5: 100.0000 (98.4368)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2380/3750]  eta: 0:08:56  Lr: 0.030000  Loss: -2.0760  Acc@1: 87.5000 (78.2969)  Acc@5: 100.0000 (98.4382)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2390/3750]  eta: 0:08:52  Lr: 0.030000  Loss: -1.6994  Acc@1: 81.2500 (78.3067)  Acc@5: 100.0000 (98.4447)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2400/3750]  eta: 0:08:48  Lr: 0.030000  Loss: -1.4009  Acc@1: 81.2500 (78.3059)  Acc@5: 100.0000 (98.4434)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2410/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -1.4883  Acc@1: 81.2500 (78.2974)  Acc@5: 100.0000 (98.4472)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2420/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -1.9330  Acc@1: 75.0000 (78.2812)  Acc@5: 100.0000 (98.4485)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2430/3750]  eta: 0:08:36  Lr: 0.030000  Loss: -1.9443  Acc@1: 75.0000 (78.2780)  Acc@5: 100.0000 (98.4523)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2440/3750]  eta: 0:08:32  Lr: 0.030000  Loss: -2.0135  Acc@1: 75.0000 (78.2825)  Acc@5: 100.0000 (98.4561)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2450/3750]  eta: 0:08:28  Lr: 0.030000  Loss: -1.9528  Acc@1: 81.2500 (78.2767)  Acc@5: 100.0000 (98.4471)  time: 0.3886  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2460/3750]  eta: 0:08:24  Lr: 0.030000  Loss: -1.9808  Acc@1: 75.0000 (78.2812)  Acc@5: 100.0000 (98.4458)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2470/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -1.6881  Acc@1: 75.0000 (78.2856)  Acc@5: 100.0000 (98.4394)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2480/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -1.5815  Acc@1: 81.2500 (78.3001)  Acc@5: 100.0000 (98.4356)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2490/3750]  eta: 0:08:12  Lr: 0.030000  Loss: -1.6193  Acc@1: 81.2500 (78.3220)  Acc@5: 100.0000 (98.4394)  time: 0.3906  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2500/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -1.9384  Acc@1: 81.2500 (78.3312)  Acc@5: 100.0000 (98.4406)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2510/3750]  eta: 0:08:05  Lr: 0.030000  Loss: -2.1416  Acc@1: 81.2500 (78.3453)  Acc@5: 100.0000 (98.4468)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2520/3750]  eta: 0:08:01  Lr: 0.030000  Loss: -2.2481  Acc@1: 81.2500 (78.3494)  Acc@5: 100.0000 (98.4480)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:57  Lr: 0.030000  Loss: -1.8286  Acc@1: 81.2500 (78.3806)  Acc@5: 100.0000 (98.4468)  time: 0.3923  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:53  Lr: 0.030000  Loss: -1.6604  Acc@1: 81.2500 (78.3820)  Acc@5: 100.0000 (98.4430)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2550/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -1.9820  Acc@1: 81.2500 (78.3957)  Acc@5: 100.0000 (98.4467)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2560/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -2.0703  Acc@1: 81.2500 (78.4069)  Acc@5: 100.0000 (98.4503)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2570/3750]  eta: 0:07:41  Lr: 0.030000  Loss: -1.7109  Acc@1: 81.2500 (78.4131)  Acc@5: 100.0000 (98.4539)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2580/3750]  eta: 0:07:37  Lr: 0.030000  Loss: -1.2448  Acc@1: 81.2500 (78.4168)  Acc@5: 100.0000 (98.4526)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2590/3750]  eta: 0:07:33  Lr: 0.030000  Loss: -1.9105  Acc@1: 75.0000 (78.4012)  Acc@5: 100.0000 (98.4490)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2600/3750]  eta: 0:07:29  Lr: 0.030000  Loss: -1.5199  Acc@1: 75.0000 (78.3857)  Acc@5: 100.0000 (98.4453)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2610/3750]  eta: 0:07:25  Lr: 0.030000  Loss: -1.9948  Acc@1: 75.0000 (78.3823)  Acc@5: 100.0000 (98.4441)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2620/3750]  eta: 0:07:22  Lr: 0.030000  Loss: -1.9764  Acc@1: 75.0000 (78.3718)  Acc@5: 100.0000 (98.4429)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2630/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -2.1962  Acc@1: 81.2500 (78.3922)  Acc@5: 100.0000 (98.4440)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2640/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -1.3377  Acc@1: 81.2500 (78.3912)  Acc@5: 100.0000 (98.4428)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2650/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -1.0465  Acc@1: 75.0000 (78.3832)  Acc@5: 100.0000 (98.4440)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2660/3750]  eta: 0:07:06  Lr: 0.030000  Loss: -1.4272  Acc@1: 75.0000 (78.3728)  Acc@5: 100.0000 (98.4381)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2670/3750]  eta: 0:07:02  Lr: 0.030000  Loss: -1.6631  Acc@1: 81.2500 (78.3812)  Acc@5: 100.0000 (98.4369)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:58  Lr: 0.030000  Loss: -1.8318  Acc@1: 81.2500 (78.3709)  Acc@5: 100.0000 (98.4427)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:54  Lr: 0.030000  Loss: -1.6711  Acc@1: 75.0000 (78.3584)  Acc@5: 100.0000 (98.4462)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -2.0160  Acc@1: 75.0000 (78.3483)  Acc@5: 100.0000 (98.4496)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -1.5051  Acc@1: 75.0000 (78.3359)  Acc@5: 100.0000 (98.4508)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2720/3750]  eta: 0:06:42  Lr: 0.030000  Loss: -1.8781  Acc@1: 81.2500 (78.3581)  Acc@5: 100.0000 (98.4519)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2730/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -1.8540  Acc@1: 81.2500 (78.3573)  Acc@5: 100.0000 (98.4552)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2740/3750]  eta: 0:06:35  Lr: 0.030000  Loss: -2.2598  Acc@1: 81.2500 (78.3656)  Acc@5: 100.0000 (98.4609)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2750/3750]  eta: 0:06:31  Lr: 0.030000  Loss: -1.7179  Acc@1: 81.2500 (78.3579)  Acc@5: 100.0000 (98.4642)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2760/3750]  eta: 0:06:27  Lr: 0.030000  Loss: -2.0080  Acc@1: 81.2500 (78.3683)  Acc@5: 100.0000 (98.4630)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2770/3750]  eta: 0:06:23  Lr: 0.030000  Loss: -1.7202  Acc@1: 81.2500 (78.3675)  Acc@5: 100.0000 (98.4640)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2780/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -2.0552  Acc@1: 81.2500 (78.3868)  Acc@5: 100.0000 (98.4695)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2790/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -1.7896  Acc@1: 81.2500 (78.3635)  Acc@5: 100.0000 (98.4750)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2800/3750]  eta: 0:06:11  Lr: 0.030000  Loss: -1.7863  Acc@1: 81.2500 (78.3894)  Acc@5: 100.0000 (98.4760)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2810/3750]  eta: 0:06:07  Lr: 0.030000  Loss: -1.9771  Acc@1: 81.2500 (78.3929)  Acc@5: 100.0000 (98.4792)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2820/3750]  eta: 0:06:03  Lr: 0.030000  Loss: -1.7894  Acc@1: 81.2500 (78.4030)  Acc@5: 100.0000 (98.4757)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:59  Lr: 0.030000  Loss: -1.9941  Acc@1: 81.2500 (78.4043)  Acc@5: 100.0000 (98.4767)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:55  Lr: 0.030000  Loss: -1.7769  Acc@1: 81.2500 (78.4253)  Acc@5: 100.0000 (98.4776)  time: 0.3900  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:52  Lr: 0.030000  Loss: -2.1958  Acc@1: 87.5000 (78.4440)  Acc@5: 100.0000 (98.4830)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -1.8198  Acc@1: 75.0000 (78.4297)  Acc@5: 100.0000 (98.4817)  time: 0.3943  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -2.1312  Acc@1: 75.0000 (78.4243)  Acc@5: 100.0000 (98.4827)  time: 0.3943  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:40  Lr: 0.030000  Loss: -2.0190  Acc@1: 81.2500 (78.4385)  Acc@5: 100.0000 (98.4858)  time: 0.3936  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:36  Lr: 0.030000  Loss: -1.3713  Acc@1: 81.2500 (78.4396)  Acc@5: 100.0000 (98.4867)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2900/3750]  eta: 0:05:32  Lr: 0.030000  Loss: -2.0927  Acc@1: 81.2500 (78.4622)  Acc@5: 100.0000 (98.4919)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [2910/3750]  eta: 0:05:28  Lr: 0.030000  Loss: -1.9077  Acc@1: 81.2500 (78.4696)  Acc@5: 100.0000 (98.4885)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2920/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -1.0693  Acc@1: 81.2500 (78.4599)  Acc@5: 100.0000 (98.4851)  time: 0.3933  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2930/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -1.7614  Acc@1: 75.0000 (78.4587)  Acc@5: 100.0000 (98.4839)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [2940/3750]  eta: 0:05:16  Lr: 0.030000  Loss: -1.9726  Acc@1: 75.0000 (78.4640)  Acc@5: 100.0000 (98.4848)  time: 0.3935  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2950/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -1.8469  Acc@1: 81.2500 (78.4734)  Acc@5: 100.0000 (98.4857)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2960/3750]  eta: 0:05:09  Lr: 0.030000  Loss: -1.9434  Acc@1: 81.2500 (78.4828)  Acc@5: 100.0000 (98.4887)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2970/3750]  eta: 0:05:05  Lr: 0.030000  Loss: -1.7133  Acc@1: 81.2500 (78.4774)  Acc@5: 100.0000 (98.4896)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [2980/3750]  eta: 0:05:01  Lr: 0.030000  Loss: -1.9016  Acc@1: 81.2500 (78.4888)  Acc@5: 100.0000 (98.4862)  time: 0.3947  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:57  Lr: 0.030000  Loss: -1.7871  Acc@1: 81.2500 (78.5022)  Acc@5: 100.0000 (98.4871)  time: 0.3936  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -1.8540  Acc@1: 81.2500 (78.4822)  Acc@5: 100.0000 (98.4859)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -1.9034  Acc@1: 75.0000 (78.4893)  Acc@5: 100.0000 (98.4868)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:45  Lr: 0.030000  Loss: -2.0880  Acc@1: 81.2500 (78.4902)  Acc@5: 100.0000 (98.4897)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:41  Lr: 0.030000  Loss: -1.7549  Acc@1: 75.0000 (78.4807)  Acc@5: 100.0000 (98.4885)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:37  Lr: 0.030000  Loss: -2.0315  Acc@1: 75.0000 (78.4693)  Acc@5: 100.0000 (98.4894)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:33  Lr: 0.030000  Loss: -1.9634  Acc@1: 81.2500 (78.4538)  Acc@5: 100.0000 (98.4882)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:29  Lr: 0.030000  Loss: -1.5581  Acc@1: 75.0000 (78.4425)  Acc@5: 100.0000 (98.4891)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3070/3750]  eta: 0:04:26  Lr: 0.030000  Loss: -1.5206  Acc@1: 75.0000 (78.4435)  Acc@5: 100.0000 (98.4899)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3080/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -2.0499  Acc@1: 75.0000 (78.4384)  Acc@5: 100.0000 (98.4867)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3090/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -1.8224  Acc@1: 75.0000 (78.4334)  Acc@5: 100.0000 (98.4774)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -1.7186  Acc@1: 75.0000 (78.4263)  Acc@5: 100.0000 (98.4783)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3110/3750]  eta: 0:04:10  Lr: 0.030000  Loss: -1.9052  Acc@1: 75.0000 (78.4213)  Acc@5: 100.0000 (98.4792)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3120/3750]  eta: 0:04:06  Lr: 0.030000  Loss: -2.2082  Acc@1: 75.0000 (78.4224)  Acc@5: 100.0000 (98.4760)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3130/3750]  eta: 0:04:02  Lr: 0.030000  Loss: -1.4468  Acc@1: 75.0000 (78.4134)  Acc@5: 100.0000 (98.4769)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:58  Lr: 0.030000  Loss: -2.1599  Acc@1: 75.0000 (78.4026)  Acc@5: 100.0000 (98.4798)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -1.8798  Acc@1: 75.0000 (78.4037)  Acc@5: 100.0000 (98.4806)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:50  Lr: 0.030000  Loss: -1.7934  Acc@1: 81.2500 (78.4147)  Acc@5: 100.0000 (98.4835)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:46  Lr: 0.030000  Loss: -1.7453  Acc@1: 81.2500 (78.4157)  Acc@5: 100.0000 (98.4843)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:43  Lr: 0.030000  Loss: -1.5509  Acc@1: 75.0000 (78.4011)  Acc@5: 100.0000 (98.4871)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -1.8518  Acc@1: 75.0000 (78.3924)  Acc@5: 100.0000 (98.4840)  time: 0.3939  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -1.7610  Acc@1: 75.0000 (78.3876)  Acc@5: 100.0000 (98.4848)  time: 0.3951  data: 0.0006  max mem: 2912
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -2.1378  Acc@1: 75.0000 (78.3810)  Acc@5: 100.0000 (98.4837)  time: 0.3933  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -1.9223  Acc@1: 75.0000 (78.3608)  Acc@5: 100.0000 (98.4865)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -1.7701  Acc@1: 75.0000 (78.3600)  Acc@5: 100.0000 (98.4912)  time: 0.3944  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3240/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -1.8910  Acc@1: 81.2500 (78.3709)  Acc@5: 100.0000 (98.4939)  time: 0.3943  data: 0.0005  max mem: 2912
Train: Epoch[2/5]  [3250/3750]  eta: 0:03:15  Lr: 0.030000  Loss: -1.9641  Acc@1: 81.2500 (78.3797)  Acc@5: 100.0000 (98.4985)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3260/3750]  eta: 0:03:11  Lr: 0.030000  Loss: -1.9894  Acc@1: 81.2500 (78.3713)  Acc@5: 100.0000 (98.5031)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3270/3750]  eta: 0:03:07  Lr: 0.030000  Loss: -1.6877  Acc@1: 81.2500 (78.3839)  Acc@5: 100.0000 (98.5039)  time: 0.3924  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3280/3750]  eta: 0:03:03  Lr: 0.030000  Loss: -1.5957  Acc@1: 81.2500 (78.3793)  Acc@5: 100.0000 (98.4989)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3290/3750]  eta: 0:03:00  Lr: 0.030000  Loss: -1.8642  Acc@1: 81.2500 (78.3861)  Acc@5: 100.0000 (98.5016)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -2.2207  Acc@1: 81.2500 (78.3986)  Acc@5: 100.0000 (98.4967)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -1.9847  Acc@1: 87.5000 (78.3997)  Acc@5: 100.0000 (98.5012)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -2.0139  Acc@1: 81.2500 (78.4120)  Acc@5: 100.0000 (98.5038)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -2.0208  Acc@1: 81.2500 (78.4111)  Acc@5: 100.0000 (98.5046)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -1.3847  Acc@1: 81.2500 (78.4103)  Acc@5: 100.0000 (98.5034)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -1.7549  Acc@1: 75.0000 (78.4038)  Acc@5: 100.0000 (98.5023)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:32  Lr: 0.030000  Loss: -1.9819  Acc@1: 75.0000 (78.4086)  Acc@5: 100.0000 (98.5049)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -1.4651  Acc@1: 81.2500 (78.4152)  Acc@5: 100.0000 (98.5056)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -1.6467  Acc@1: 81.2500 (78.4180)  Acc@5: 100.0000 (98.5082)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:20  Lr: 0.030000  Loss: -2.0557  Acc@1: 75.0000 (78.4116)  Acc@5: 100.0000 (98.5015)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:16  Lr: 0.030000  Loss: -2.1185  Acc@1: 75.0000 (78.4108)  Acc@5: 100.0000 (98.5041)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -1.6922  Acc@1: 75.0000 (78.4063)  Acc@5: 100.0000 (98.5030)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -1.7953  Acc@1: 75.0000 (78.4109)  Acc@5: 100.0000 (98.5019)  time: 0.3934  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -1.6365  Acc@1: 75.0000 (78.4083)  Acc@5: 100.0000 (98.4990)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -2.0864  Acc@1: 81.2500 (78.4220)  Acc@5: 100.0000 (98.4979)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -1.9712  Acc@1: 87.5000 (78.4374)  Acc@5: 100.0000 (98.4986)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -1.1720  Acc@1: 81.2500 (78.4347)  Acc@5: 100.0000 (98.4975)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -2.0900  Acc@1: 81.2500 (78.4428)  Acc@5: 100.0000 (98.4947)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -1.5423  Acc@1: 81.2500 (78.4563)  Acc@5: 100.0000 (98.4972)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:41  Lr: 0.030000  Loss: -1.8326  Acc@1: 75.0000 (78.4553)  Acc@5: 100.0000 (98.4979)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:37  Lr: 0.030000  Loss: -1.9486  Acc@1: 75.0000 (78.4562)  Acc@5: 100.0000 (98.4986)  time: 0.3889  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -1.9300  Acc@1: 75.0000 (78.4552)  Acc@5: 100.0000 (98.4940)  time: 0.3892  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -1.4109  Acc@1: 81.2500 (78.4702)  Acc@5: 100.0000 (98.4912)  time: 0.3889  data: 0.0002  max mem: 2912
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -1.9552  Acc@1: 81.2500 (78.4764)  Acc@5: 100.0000 (98.4937)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -1.8727  Acc@1: 81.2500 (78.4736)  Acc@5: 100.0000 (98.4980)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -1.9415  Acc@1: 81.2500 (78.4779)  Acc@5: 100.0000 (98.5004)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -2.0606  Acc@1: 75.0000 (78.4769)  Acc@5: 100.0000 (98.5029)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -1.7742  Acc@1: 75.0000 (78.4777)  Acc@5: 100.0000 (98.5071)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -1.7068  Acc@1: 81.2500 (78.4837)  Acc@5: 100.0000 (98.5077)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -1.9794  Acc@1: 81.2500 (78.5070)  Acc@5: 100.0000 (98.5102)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -1.4188  Acc@1: 81.2500 (78.5025)  Acc@5: 100.0000 (98.5108)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -1.3208  Acc@1: 75.0000 (78.4997)  Acc@5: 100.0000 (98.5080)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:50  Lr: 0.030000  Loss: -1.9089  Acc@1: 75.0000 (78.5021)  Acc@5: 100.0000 (98.5087)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:46  Lr: 0.030000  Loss: -1.7811  Acc@1: 81.2500 (78.4959)  Acc@5: 100.0000 (98.5094)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -2.2891  Acc@1: 75.0000 (78.5018)  Acc@5: 100.0000 (98.5135)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -1.4949  Acc@1: 81.2500 (78.5025)  Acc@5: 100.0000 (98.5158)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -1.6707  Acc@1: 75.0000 (78.4997)  Acc@5: 100.0000 (98.5130)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -2.0899  Acc@1: 75.0000 (78.4970)  Acc@5: 100.0000 (98.5171)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -2.0520  Acc@1: 75.0000 (78.4841)  Acc@5: 100.0000 (98.5160)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -1.7407  Acc@1: 75.0000 (78.4848)  Acc@5: 100.0000 (98.5167)  time: 0.3881  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -2.0072  Acc@1: 75.0000 (78.4839)  Acc@5: 100.0000 (98.5139)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -1.6633  Acc@1: 81.2500 (78.5048)  Acc@5: 100.0000 (98.5129)  time: 0.3881  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -0.6344  Acc@1: 81.2500 (78.5038)  Acc@5: 100.0000 (98.5101)  time: 0.3880  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -1.8407  Acc@1: 75.0000 (78.5061)  Acc@5: 100.0000 (98.5125)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -1.6468  Acc@1: 81.2500 (78.5034)  Acc@5: 100.0000 (98.5098)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -1.6774  Acc@1: 75.0000 (78.4950)  Acc@5: 100.0000 (98.5100)  time: 0.3917  data: 0.0007  max mem: 2912
Train: Epoch[2/5] Total time: 0:24:27 (0.3914 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}}
Averaged stats: Lr: 0.030000  Loss: -1.6774  Acc@1: 75.0000 (78.4950)  Acc@5: 100.0000 (98.5100)
Train: Epoch[3/5]  [   0/3750]  eta: 0:57:29  Lr: 0.030000  Loss: -2.1986  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.9198  data: 0.5293  max mem: 2912
Train: Epoch[3/5]  [  10/3750]  eta: 0:27:23  Lr: 0.030000  Loss: -1.7038  Acc@1: 75.0000 (77.2727)  Acc@5: 100.0000 (100.0000)  time: 0.4395  data: 0.0485  max mem: 2912
Train: Epoch[3/5]  [  20/3750]  eta: 0:25:53  Lr: 0.030000  Loss: -2.0497  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (99.4048)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  30/3750]  eta: 0:25:19  Lr: 0.030000  Loss: -1.7635  Acc@1: 81.2500 (81.8548)  Acc@5: 100.0000 (98.9919)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  40/3750]  eta: 0:25:00  Lr: 0.030000  Loss: -1.8325  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (99.2378)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  50/3750]  eta: 0:24:48  Lr: 0.030000  Loss: -1.6945  Acc@1: 81.2500 (81.6176)  Acc@5: 100.0000 (99.1422)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  60/3750]  eta: 0:24:37  Lr: 0.030000  Loss: -1.9408  Acc@1: 81.2500 (81.7623)  Acc@5: 100.0000 (99.2828)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  70/3750]  eta: 0:24:28  Lr: 0.030000  Loss: -1.6230  Acc@1: 81.2500 (81.4261)  Acc@5: 100.0000 (99.2958)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [  80/3750]  eta: 0:24:22  Lr: 0.030000  Loss: -2.4149  Acc@1: 75.0000 (81.3272)  Acc@5: 100.0000 (99.1512)  time: 0.3931  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [  90/3750]  eta: 0:24:18  Lr: 0.030000  Loss: -1.6369  Acc@1: 81.2500 (81.3874)  Acc@5: 100.0000 (99.1071)  time: 0.3966  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 100/3750]  eta: 0:24:12  Lr: 0.030000  Loss: -1.6752  Acc@1: 81.2500 (81.1881)  Acc@5: 100.0000 (99.0718)  time: 0.3957  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 110/3750]  eta: 0:24:06  Lr: 0.030000  Loss: -2.0917  Acc@1: 75.0000 (80.8559)  Acc@5: 100.0000 (98.9302)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 120/3750]  eta: 0:24:01  Lr: 0.030000  Loss: -2.1238  Acc@1: 75.0000 (80.8368)  Acc@5: 100.0000 (98.8636)  time: 0.3921  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 130/3750]  eta: 0:23:55  Lr: 0.030000  Loss: -1.6039  Acc@1: 81.2500 (80.5821)  Acc@5: 100.0000 (98.8550)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 140/3750]  eta: 0:23:50  Lr: 0.030000  Loss: -1.5850  Acc@1: 75.0000 (80.1862)  Acc@5: 100.0000 (98.8475)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 150/3750]  eta: 0:23:44  Lr: 0.030000  Loss: -1.7117  Acc@1: 68.7500 (79.5944)  Acc@5: 100.0000 (98.7583)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 160/3750]  eta: 0:23:39  Lr: 0.030000  Loss: -1.4741  Acc@1: 81.2500 (79.6196)  Acc@5: 100.0000 (98.7189)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 170/3750]  eta: 0:23:34  Lr: 0.030000  Loss: -1.6408  Acc@1: 81.2500 (79.8611)  Acc@5: 100.0000 (98.7573)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 180/3750]  eta: 0:23:29  Lr: 0.030000  Loss: -1.6639  Acc@1: 81.2500 (80.1105)  Acc@5: 100.0000 (98.7914)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 190/3750]  eta: 0:23:25  Lr: 0.030000  Loss: -1.4923  Acc@1: 81.2500 (79.7448)  Acc@5: 100.0000 (98.7893)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 200/3750]  eta: 0:23:21  Lr: 0.030000  Loss: -1.7115  Acc@1: 75.0000 (79.4776)  Acc@5: 100.0000 (98.7873)  time: 0.3936  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 210/3750]  eta: 0:23:16  Lr: 0.030000  Loss: -2.1291  Acc@1: 75.0000 (79.6801)  Acc@5: 100.0000 (98.8152)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 220/3750]  eta: 0:23:12  Lr: 0.030000  Loss: -2.1578  Acc@1: 81.2500 (79.7511)  Acc@5: 100.0000 (98.8405)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 230/3750]  eta: 0:23:08  Lr: 0.030000  Loss: -1.5815  Acc@1: 81.2500 (79.8431)  Acc@5: 100.0000 (98.8636)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 240/3750]  eta: 0:23:03  Lr: 0.030000  Loss: -2.1096  Acc@1: 81.2500 (79.9015)  Acc@5: 100.0000 (98.8849)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 250/3750]  eta: 0:22:59  Lr: 0.030000  Loss: -1.7735  Acc@1: 81.2500 (80.0050)  Acc@5: 100.0000 (98.8795)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 260/3750]  eta: 0:22:55  Lr: 0.030000  Loss: -1.9438  Acc@1: 81.2500 (80.1485)  Acc@5: 100.0000 (98.8506)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 270/3750]  eta: 0:22:50  Lr: 0.030000  Loss: -1.2883  Acc@1: 81.2500 (80.1661)  Acc@5: 100.0000 (98.8699)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 280/3750]  eta: 0:22:46  Lr: 0.030000  Loss: -1.6804  Acc@1: 81.2500 (80.2714)  Acc@5: 100.0000 (98.8657)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 290/3750]  eta: 0:22:42  Lr: 0.030000  Loss: -1.7972  Acc@1: 81.2500 (80.1332)  Acc@5: 100.0000 (98.8617)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 300/3750]  eta: 0:22:37  Lr: 0.030000  Loss: -1.1651  Acc@1: 75.0000 (80.0249)  Acc@5: 100.0000 (98.8372)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 310/3750]  eta: 0:22:33  Lr: 0.030000  Loss: -1.9020  Acc@1: 75.0000 (79.9437)  Acc@5: 100.0000 (98.8545)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 320/3750]  eta: 0:22:28  Lr: 0.030000  Loss: -1.7850  Acc@1: 75.0000 (79.8287)  Acc@5: 100.0000 (98.8318)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 330/3750]  eta: 0:22:24  Lr: 0.030000  Loss: -1.7419  Acc@1: 75.0000 (79.8338)  Acc@5: 100.0000 (98.8482)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 340/3750]  eta: 0:22:20  Lr: 0.030000  Loss: -1.5167  Acc@1: 75.0000 (79.6554)  Acc@5: 100.0000 (98.8453)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 350/3750]  eta: 0:22:16  Lr: 0.030000  Loss: -1.0820  Acc@1: 75.0000 (79.4872)  Acc@5: 100.0000 (98.8248)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 360/3750]  eta: 0:22:11  Lr: 0.030000  Loss: -1.9688  Acc@1: 81.2500 (79.6053)  Acc@5: 100.0000 (98.8227)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 370/3750]  eta: 0:22:07  Lr: 0.030000  Loss: -1.5268  Acc@1: 81.2500 (79.6159)  Acc@5: 100.0000 (98.8376)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 380/3750]  eta: 0:22:03  Lr: 0.030000  Loss: -1.7109  Acc@1: 81.2500 (79.7244)  Acc@5: 100.0000 (98.8517)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 390/3750]  eta: 0:21:59  Lr: 0.030000  Loss: -2.0361  Acc@1: 81.2500 (79.8434)  Acc@5: 100.0000 (98.8811)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 400/3750]  eta: 0:21:55  Lr: 0.030000  Loss: -1.9977  Acc@1: 81.2500 (79.8784)  Acc@5: 100.0000 (98.8778)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 410/3750]  eta: 0:21:51  Lr: 0.030000  Loss: -2.0024  Acc@1: 81.2500 (79.8814)  Acc@5: 100.0000 (98.8899)  time: 0.3910  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 420/3750]  eta: 0:21:47  Lr: 0.030000  Loss: -1.6315  Acc@1: 81.2500 (79.8990)  Acc@5: 100.0000 (98.8717)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 430/3750]  eta: 0:21:43  Lr: 0.030000  Loss: -1.8927  Acc@1: 81.2500 (79.9304)  Acc@5: 100.0000 (98.8689)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 440/3750]  eta: 0:21:39  Lr: 0.030000  Loss: -1.8895  Acc@1: 75.0000 (79.7902)  Acc@5: 100.0000 (98.8804)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 450/3750]  eta: 0:21:35  Lr: 0.030000  Loss: -1.7690  Acc@1: 75.0000 (79.6286)  Acc@5: 100.0000 (98.8636)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 460/3750]  eta: 0:21:31  Lr: 0.030000  Loss: -1.8514  Acc@1: 81.2500 (79.5553)  Acc@5: 100.0000 (98.8747)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 470/3750]  eta: 0:21:27  Lr: 0.030000  Loss: -1.5901  Acc@1: 81.2500 (79.4984)  Acc@5: 100.0000 (98.8455)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 480/3750]  eta: 0:21:23  Lr: 0.030000  Loss: -1.7218  Acc@1: 81.2500 (79.5218)  Acc@5: 100.0000 (98.8695)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 490/3750]  eta: 0:21:19  Lr: 0.030000  Loss: -2.0310  Acc@1: 81.2500 (79.4425)  Acc@5: 100.0000 (98.8671)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 500/3750]  eta: 0:21:16  Lr: 0.030000  Loss: -1.4558  Acc@1: 75.0000 (79.3538)  Acc@5: 100.0000 (98.8648)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 510/3750]  eta: 0:21:11  Lr: 0.030000  Loss: -2.1709  Acc@1: 81.2500 (79.4765)  Acc@5: 100.0000 (98.8748)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 520/3750]  eta: 0:21:07  Lr: 0.030000  Loss: -2.0276  Acc@1: 81.2500 (79.4506)  Acc@5: 100.0000 (98.8604)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 530/3750]  eta: 0:21:03  Lr: 0.030000  Loss: -2.2316  Acc@1: 81.2500 (79.4727)  Acc@5: 100.0000 (98.8583)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 540/3750]  eta: 0:20:59  Lr: 0.030000  Loss: -0.8921  Acc@1: 75.0000 (79.3900)  Acc@5: 100.0000 (98.8447)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 550/3750]  eta: 0:20:55  Lr: 0.030000  Loss: -1.7452  Acc@1: 75.0000 (79.3784)  Acc@5: 100.0000 (98.8430)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 560/3750]  eta: 0:20:51  Lr: 0.030000  Loss: -1.2553  Acc@1: 81.2500 (79.4452)  Acc@5: 100.0000 (98.8525)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 570/3750]  eta: 0:20:47  Lr: 0.030000  Loss: -1.9454  Acc@1: 87.5000 (79.4987)  Acc@5: 100.0000 (98.8726)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 580/3750]  eta: 0:20:43  Lr: 0.030000  Loss: -1.3849  Acc@1: 81.2500 (79.5503)  Acc@5: 100.0000 (98.8920)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 590/3750]  eta: 0:20:39  Lr: 0.030000  Loss: -1.2569  Acc@1: 75.0000 (79.3570)  Acc@5: 100.0000 (98.8684)  time: 0.3886  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 600/3750]  eta: 0:20:35  Lr: 0.030000  Loss: -1.9046  Acc@1: 68.7500 (79.2429)  Acc@5: 100.0000 (98.8769)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 610/3750]  eta: 0:20:31  Lr: 0.030000  Loss: -1.2071  Acc@1: 68.7500 (79.1735)  Acc@5: 100.0000 (98.8441)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 620/3750]  eta: 0:20:27  Lr: 0.030000  Loss: -1.8997  Acc@1: 81.2500 (79.2572)  Acc@5: 100.0000 (98.8426)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 630/3750]  eta: 0:20:23  Lr: 0.030000  Loss: -1.9483  Acc@1: 81.2500 (79.2987)  Acc@5: 100.0000 (98.8510)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 640/3750]  eta: 0:20:19  Lr: 0.030000  Loss: -1.8713  Acc@1: 81.2500 (79.3584)  Acc@5: 100.0000 (98.8592)  time: 0.3931  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 650/3750]  eta: 0:20:15  Lr: 0.030000  Loss: -2.0568  Acc@1: 81.2500 (79.3395)  Acc@5: 100.0000 (98.8671)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 660/3750]  eta: 0:20:11  Lr: 0.030000  Loss: -2.0927  Acc@1: 81.2500 (79.4535)  Acc@5: 100.0000 (98.8843)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 670/3750]  eta: 0:20:07  Lr: 0.030000  Loss: -1.8452  Acc@1: 87.5000 (79.5268)  Acc@5: 100.0000 (98.9009)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 680/3750]  eta: 0:20:03  Lr: 0.030000  Loss: -2.1067  Acc@1: 81.2500 (79.5797)  Acc@5: 100.0000 (98.9170)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 690/3750]  eta: 0:19:59  Lr: 0.030000  Loss: -1.8203  Acc@1: 81.2500 (79.6310)  Acc@5: 100.0000 (98.9327)  time: 0.3925  data: 0.0006  max mem: 2912
Train: Epoch[3/5]  [ 700/3750]  eta: 0:19:55  Lr: 0.030000  Loss: -1.8384  Acc@1: 87.5000 (79.6986)  Acc@5: 100.0000 (98.9301)  time: 0.3919  data: 0.0006  max mem: 2912
Train: Epoch[3/5]  [ 710/3750]  eta: 0:19:51  Lr: 0.030000  Loss: -1.7496  Acc@1: 81.2500 (79.6589)  Acc@5: 100.0000 (98.9188)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 720/3750]  eta: 0:19:47  Lr: 0.030000  Loss: -1.6139  Acc@1: 81.2500 (79.6203)  Acc@5: 100.0000 (98.8731)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 730/3750]  eta: 0:19:43  Lr: 0.030000  Loss: -1.5065  Acc@1: 75.0000 (79.5315)  Acc@5: 100.0000 (98.8714)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 740/3750]  eta: 0:19:39  Lr: 0.030000  Loss: -1.6495  Acc@1: 75.0000 (79.5462)  Acc@5: 100.0000 (98.8866)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 750/3750]  eta: 0:19:35  Lr: 0.030000  Loss: -1.5818  Acc@1: 81.2500 (79.5439)  Acc@5: 100.0000 (98.8931)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 760/3750]  eta: 0:19:32  Lr: 0.030000  Loss: -1.8993  Acc@1: 81.2500 (79.4842)  Acc@5: 100.0000 (98.8748)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 770/3750]  eta: 0:19:28  Lr: 0.030000  Loss: -1.6919  Acc@1: 75.0000 (79.5233)  Acc@5: 100.0000 (98.8651)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 780/3750]  eta: 0:19:24  Lr: 0.030000  Loss: -1.8846  Acc@1: 81.2500 (79.4894)  Acc@5: 100.0000 (98.8716)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 790/3750]  eta: 0:19:20  Lr: 0.030000  Loss: -1.6828  Acc@1: 75.0000 (79.4801)  Acc@5: 100.0000 (98.8859)  time: 0.3936  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 800/3750]  eta: 0:19:16  Lr: 0.030000  Loss: -1.9546  Acc@1: 81.2500 (79.5100)  Acc@5: 100.0000 (98.8842)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 810/3750]  eta: 0:19:12  Lr: 0.030000  Loss: -1.9386  Acc@1: 81.2500 (79.5391)  Acc@5: 100.0000 (98.8903)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [ 820/3750]  eta: 0:19:08  Lr: 0.030000  Loss: -1.8940  Acc@1: 81.2500 (79.5600)  Acc@5: 100.0000 (98.8733)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 830/3750]  eta: 0:19:04  Lr: 0.030000  Loss: -1.9679  Acc@1: 81.2500 (79.5051)  Acc@5: 100.0000 (98.8568)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 840/3750]  eta: 0:19:00  Lr: 0.030000  Loss: -2.1857  Acc@1: 81.2500 (79.5333)  Acc@5: 100.0000 (98.8555)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 850/3750]  eta: 0:18:56  Lr: 0.030000  Loss: -1.7290  Acc@1: 81.2500 (79.5388)  Acc@5: 100.0000 (98.8616)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 860/3750]  eta: 0:18:52  Lr: 0.030000  Loss: -1.7790  Acc@1: 75.0000 (79.5078)  Acc@5: 100.0000 (98.8749)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 870/3750]  eta: 0:18:49  Lr: 0.030000  Loss: -2.2483  Acc@1: 75.0000 (79.5278)  Acc@5: 100.0000 (98.8734)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 880/3750]  eta: 0:18:45  Lr: 0.030000  Loss: -1.6740  Acc@1: 81.2500 (79.5048)  Acc@5: 100.0000 (98.8649)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 890/3750]  eta: 0:18:41  Lr: 0.030000  Loss: -1.4095  Acc@1: 75.0000 (79.4262)  Acc@5: 100.0000 (98.8636)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [ 900/3750]  eta: 0:18:37  Lr: 0.030000  Loss: -2.0190  Acc@1: 75.0000 (79.4534)  Acc@5: 100.0000 (98.8762)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 910/3750]  eta: 0:18:33  Lr: 0.030000  Loss: -1.4699  Acc@1: 81.2500 (79.4731)  Acc@5: 100.0000 (98.8886)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 920/3750]  eta: 0:18:29  Lr: 0.030000  Loss: -2.0006  Acc@1: 81.2500 (79.4924)  Acc@5: 100.0000 (98.9007)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 930/3750]  eta: 0:18:25  Lr: 0.030000  Loss: -1.9705  Acc@1: 81.2500 (79.4576)  Acc@5: 100.0000 (98.8923)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 940/3750]  eta: 0:18:21  Lr: 0.030000  Loss: -2.2475  Acc@1: 75.0000 (79.4700)  Acc@5: 100.0000 (98.9041)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 950/3750]  eta: 0:18:17  Lr: 0.030000  Loss: -1.6924  Acc@1: 81.2500 (79.5018)  Acc@5: 100.0000 (98.9025)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 960/3750]  eta: 0:18:13  Lr: 0.030000  Loss: -1.3349  Acc@1: 81.2500 (79.5395)  Acc@5: 100.0000 (98.9009)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 970/3750]  eta: 0:18:09  Lr: 0.030000  Loss: -2.0169  Acc@1: 81.2500 (79.5507)  Acc@5: 100.0000 (98.8929)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 980/3750]  eta: 0:18:05  Lr: 0.030000  Loss: -1.6483  Acc@1: 81.2500 (79.5935)  Acc@5: 100.0000 (98.9042)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [ 990/3750]  eta: 0:18:01  Lr: 0.030000  Loss: -2.1300  Acc@1: 81.2500 (79.6229)  Acc@5: 100.0000 (98.9152)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1000/3750]  eta: 0:17:57  Lr: 0.030000  Loss: -1.8843  Acc@1: 81.2500 (79.5829)  Acc@5: 100.0000 (98.9198)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1010/3750]  eta: 0:17:53  Lr: 0.030000  Loss: -1.3207  Acc@1: 75.0000 (79.5376)  Acc@5: 100.0000 (98.9305)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1020/3750]  eta: 0:17:49  Lr: 0.030000  Loss: -1.6815  Acc@1: 68.7500 (79.4809)  Acc@5: 100.0000 (98.9287)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1030/3750]  eta: 0:17:45  Lr: 0.030000  Loss: -1.7153  Acc@1: 75.0000 (79.4738)  Acc@5: 100.0000 (98.9391)  time: 0.3940  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1040/3750]  eta: 0:17:41  Lr: 0.030000  Loss: -1.1712  Acc@1: 75.0000 (79.4488)  Acc@5: 100.0000 (98.9253)  time: 0.3943  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1050/3750]  eta: 0:17:37  Lr: 0.030000  Loss: -2.0269  Acc@1: 75.0000 (79.4125)  Acc@5: 100.0000 (98.9236)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1060/3750]  eta: 0:17:33  Lr: 0.030000  Loss: -1.9624  Acc@1: 81.2500 (79.4475)  Acc@5: 100.0000 (98.9338)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1070/3750]  eta: 0:17:29  Lr: 0.030000  Loss: -1.5648  Acc@1: 81.2500 (79.4118)  Acc@5: 100.0000 (98.9321)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1080/3750]  eta: 0:17:26  Lr: 0.030000  Loss: -2.0112  Acc@1: 75.0000 (79.3941)  Acc@5: 100.0000 (98.9130)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1090/3750]  eta: 0:17:22  Lr: 0.030000  Loss: -1.9288  Acc@1: 81.2500 (79.4225)  Acc@5: 100.0000 (98.9173)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1100/3750]  eta: 0:17:18  Lr: 0.030000  Loss: -1.4468  Acc@1: 81.2500 (79.3937)  Acc@5: 100.0000 (98.9158)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1110/3750]  eta: 0:17:14  Lr: 0.030000  Loss: -1.6218  Acc@1: 75.0000 (79.3936)  Acc@5: 100.0000 (98.9199)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1120/3750]  eta: 0:17:10  Lr: 0.030000  Loss: -2.1401  Acc@1: 87.5000 (79.4603)  Acc@5: 100.0000 (98.9240)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1130/3750]  eta: 0:17:06  Lr: 0.030000  Loss: -1.3196  Acc@1: 87.5000 (79.4706)  Acc@5: 100.0000 (98.9114)  time: 0.3939  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1140/3750]  eta: 0:17:02  Lr: 0.030000  Loss: -1.8300  Acc@1: 81.2500 (79.4752)  Acc@5: 100.0000 (98.9154)  time: 0.3944  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1150/3750]  eta: 0:16:58  Lr: 0.030000  Loss: -2.1986  Acc@1: 81.2500 (79.4852)  Acc@5: 100.0000 (98.9248)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1160/3750]  eta: 0:16:55  Lr: 0.030000  Loss: -2.1948  Acc@1: 87.5000 (79.5220)  Acc@5: 100.0000 (98.9180)  time: 0.4000  data: 0.0008  max mem: 2912
Train: Epoch[3/5]  [1170/3750]  eta: 0:16:51  Lr: 0.030000  Loss: -1.9961  Acc@1: 81.2500 (79.4673)  Acc@5: 100.0000 (98.9058)  time: 0.3997  data: 0.0007  max mem: 2912
Train: Epoch[3/5]  [1180/3750]  eta: 0:16:47  Lr: 0.030000  Loss: -2.0553  Acc@1: 81.2500 (79.4771)  Acc@5: 100.0000 (98.8992)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1190/3750]  eta: 0:16:43  Lr: 0.030000  Loss: -2.2516  Acc@1: 81.2500 (79.5288)  Acc@5: 100.0000 (98.8980)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1200/3750]  eta: 0:16:39  Lr: 0.030000  Loss: -1.9150  Acc@1: 81.2500 (79.5223)  Acc@5: 100.0000 (98.8968)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1210/3750]  eta: 0:16:35  Lr: 0.030000  Loss: -1.7316  Acc@1: 81.2500 (79.5159)  Acc@5: 100.0000 (98.8904)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1220/3750]  eta: 0:16:31  Lr: 0.030000  Loss: -1.8912  Acc@1: 81.2500 (79.5147)  Acc@5: 100.0000 (98.8943)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1230/3750]  eta: 0:16:27  Lr: 0.030000  Loss: -1.9932  Acc@1: 81.2500 (79.5695)  Acc@5: 100.0000 (98.9033)  time: 0.3933  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1240/3750]  eta: 0:16:23  Lr: 0.030000  Loss: -1.9926  Acc@1: 81.2500 (79.5981)  Acc@5: 100.0000 (98.9071)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1250/3750]  eta: 0:16:19  Lr: 0.030000  Loss: -1.3488  Acc@1: 75.0000 (79.5663)  Acc@5: 100.0000 (98.9009)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1260/3750]  eta: 0:16:15  Lr: 0.030000  Loss: -1.4225  Acc@1: 75.0000 (79.5747)  Acc@5: 100.0000 (98.9096)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1270/3750]  eta: 0:16:11  Lr: 0.030000  Loss: -1.5901  Acc@1: 81.2500 (79.5879)  Acc@5: 100.0000 (98.8985)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1280/3750]  eta: 0:16:07  Lr: 0.030000  Loss: -1.8118  Acc@1: 81.2500 (79.5667)  Acc@5: 100.0000 (98.9022)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1290/3750]  eta: 0:16:03  Lr: 0.030000  Loss: -1.9162  Acc@1: 81.2500 (79.5701)  Acc@5: 100.0000 (98.9059)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1300/3750]  eta: 0:15:59  Lr: 0.030000  Loss: -2.2208  Acc@1: 81.2500 (79.6118)  Acc@5: 100.0000 (98.8951)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1310/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -1.8494  Acc@1: 81.2500 (79.6243)  Acc@5: 100.0000 (98.8940)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1320/3750]  eta: 0:15:52  Lr: 0.030000  Loss: -1.7873  Acc@1: 81.2500 (79.6556)  Acc@5: 100.0000 (98.8976)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1330/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -1.7530  Acc@1: 81.2500 (79.6769)  Acc@5: 100.0000 (98.8824)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1340/3750]  eta: 0:15:44  Lr: 0.030000  Loss: -1.9564  Acc@1: 81.2500 (79.6933)  Acc@5: 100.0000 (98.8674)  time: 0.3938  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1350/3750]  eta: 0:15:40  Lr: 0.030000  Loss: -1.8479  Acc@1: 81.2500 (79.6817)  Acc@5: 100.0000 (98.8666)  time: 0.3939  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1360/3750]  eta: 0:15:36  Lr: 0.030000  Loss: -1.8655  Acc@1: 81.2500 (79.7070)  Acc@5: 100.0000 (98.8703)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1370/3750]  eta: 0:15:32  Lr: 0.030000  Loss: -1.9936  Acc@1: 81.2500 (79.7319)  Acc@5: 100.0000 (98.8740)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1380/3750]  eta: 0:15:28  Lr: 0.030000  Loss: -1.6999  Acc@1: 81.2500 (79.6886)  Acc@5: 100.0000 (98.8595)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1390/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -1.5559  Acc@1: 75.0000 (79.6954)  Acc@5: 100.0000 (98.8542)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1400/3750]  eta: 0:15:20  Lr: 0.030000  Loss: -1.5709  Acc@1: 81.2500 (79.6931)  Acc@5: 100.0000 (98.8535)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1410/3750]  eta: 0:15:16  Lr: 0.030000  Loss: -1.2374  Acc@1: 75.0000 (79.6421)  Acc@5: 100.0000 (98.8439)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1420/3750]  eta: 0:15:13  Lr: 0.030000  Loss: -2.1476  Acc@1: 75.0000 (79.6182)  Acc@5: 100.0000 (98.8476)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1430/3750]  eta: 0:15:09  Lr: 0.030000  Loss: -1.3434  Acc@1: 75.0000 (79.5772)  Acc@5: 100.0000 (98.8339)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1440/3750]  eta: 0:15:05  Lr: 0.030000  Loss: -2.0796  Acc@1: 75.0000 (79.5932)  Acc@5: 100.0000 (98.8420)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1450/3750]  eta: 0:15:01  Lr: 0.030000  Loss: -1.7012  Acc@1: 75.0000 (79.5615)  Acc@5: 100.0000 (98.8327)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1460/3750]  eta: 0:14:57  Lr: 0.030000  Loss: -1.5580  Acc@1: 75.0000 (79.5560)  Acc@5: 100.0000 (98.8236)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1470/3750]  eta: 0:14:53  Lr: 0.030000  Loss: -1.8119  Acc@1: 75.0000 (79.5250)  Acc@5: 100.0000 (98.8146)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1480/3750]  eta: 0:14:49  Lr: 0.030000  Loss: -2.1639  Acc@1: 81.2500 (79.5366)  Acc@5: 100.0000 (98.8226)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1490/3750]  eta: 0:14:45  Lr: 0.030000  Loss: -2.0122  Acc@1: 81.2500 (79.5272)  Acc@5: 100.0000 (98.8263)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1500/3750]  eta: 0:14:41  Lr: 0.030000  Loss: -1.8146  Acc@1: 75.0000 (79.5261)  Acc@5: 100.0000 (98.8258)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1510/3750]  eta: 0:14:37  Lr: 0.030000  Loss: -1.5059  Acc@1: 87.5000 (79.5665)  Acc@5: 100.0000 (98.8294)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1520/3750]  eta: 0:14:33  Lr: 0.030000  Loss: -1.7139  Acc@1: 81.2500 (79.5488)  Acc@5: 100.0000 (98.8289)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1530/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -1.2631  Acc@1: 81.2500 (79.5599)  Acc@5: 100.0000 (98.8325)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1540/3750]  eta: 0:14:25  Lr: 0.030000  Loss: -2.1602  Acc@1: 75.0000 (79.5547)  Acc@5: 100.0000 (98.8279)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1550/3750]  eta: 0:14:21  Lr: 0.030000  Loss: -1.6542  Acc@1: 81.2500 (79.5817)  Acc@5: 100.0000 (98.8354)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1560/3750]  eta: 0:14:17  Lr: 0.030000  Loss: -1.6612  Acc@1: 81.2500 (79.5884)  Acc@5: 100.0000 (98.8269)  time: 0.3881  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1570/3750]  eta: 0:14:13  Lr: 0.030000  Loss: -1.7414  Acc@1: 81.2500 (79.6030)  Acc@5: 100.0000 (98.8304)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1580/3750]  eta: 0:14:10  Lr: 0.030000  Loss: -2.0589  Acc@1: 81.2500 (79.6292)  Acc@5: 100.0000 (98.8378)  time: 0.3892  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1590/3750]  eta: 0:14:06  Lr: 0.030000  Loss: -1.4316  Acc@1: 81.2500 (79.6315)  Acc@5: 100.0000 (98.8333)  time: 0.3906  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1600/3750]  eta: 0:14:02  Lr: 0.030000  Loss: -1.8388  Acc@1: 81.2500 (79.6026)  Acc@5: 100.0000 (98.8367)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1610/3750]  eta: 0:13:58  Lr: 0.030000  Loss: -2.3498  Acc@1: 81.2500 (79.6361)  Acc@5: 100.0000 (98.8439)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1620/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -1.3240  Acc@1: 81.2500 (79.6114)  Acc@5: 100.0000 (98.8433)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1630/3750]  eta: 0:13:50  Lr: 0.030000  Loss: -1.7885  Acc@1: 75.0000 (79.5946)  Acc@5: 100.0000 (98.8389)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1640/3750]  eta: 0:13:46  Lr: 0.030000  Loss: -1.7624  Acc@1: 75.0000 (79.5742)  Acc@5: 100.0000 (98.8422)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1650/3750]  eta: 0:13:42  Lr: 0.030000  Loss: -1.9101  Acc@1: 75.0000 (79.5919)  Acc@5: 100.0000 (98.8492)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1660/3750]  eta: 0:13:38  Lr: 0.030000  Loss: -1.7984  Acc@1: 81.2500 (79.5944)  Acc@5: 100.0000 (98.8523)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1670/3750]  eta: 0:13:34  Lr: 0.030000  Loss: -1.9882  Acc@1: 81.2500 (79.6043)  Acc@5: 100.0000 (98.8555)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1680/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -1.3870  Acc@1: 75.0000 (79.5843)  Acc@5: 100.0000 (98.8511)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1690/3750]  eta: 0:13:26  Lr: 0.030000  Loss: -1.5681  Acc@1: 81.2500 (79.6053)  Acc@5: 100.0000 (98.8431)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1700/3750]  eta: 0:13:22  Lr: 0.030000  Loss: -2.0675  Acc@1: 87.5000 (79.6590)  Acc@5: 100.0000 (98.8463)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1710/3750]  eta: 0:13:18  Lr: 0.030000  Loss: -1.7680  Acc@1: 81.2500 (79.6756)  Acc@5: 100.0000 (98.8530)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1720/3750]  eta: 0:13:14  Lr: 0.030000  Loss: -1.9470  Acc@1: 81.2500 (79.6303)  Acc@5: 100.0000 (98.8524)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1730/3750]  eta: 0:13:10  Lr: 0.030000  Loss: -2.0265  Acc@1: 81.2500 (79.6505)  Acc@5: 100.0000 (98.8518)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1740/3750]  eta: 0:13:07  Lr: 0.030000  Loss: -1.6688  Acc@1: 81.2500 (79.6525)  Acc@5: 100.0000 (98.8476)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1750/3750]  eta: 0:13:03  Lr: 0.030000  Loss: -1.8856  Acc@1: 81.2500 (79.6688)  Acc@5: 100.0000 (98.8435)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1760/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -1.6509  Acc@1: 81.2500 (79.6884)  Acc@5: 100.0000 (98.8465)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1770/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -2.1794  Acc@1: 81.2500 (79.7184)  Acc@5: 100.0000 (98.8460)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1780/3750]  eta: 0:12:51  Lr: 0.030000  Loss: -2.1505  Acc@1: 81.2500 (79.6919)  Acc@5: 100.0000 (98.8525)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1790/3750]  eta: 0:12:47  Lr: 0.030000  Loss: -1.7584  Acc@1: 81.2500 (79.6971)  Acc@5: 100.0000 (98.8484)  time: 0.3941  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1800/3750]  eta: 0:12:43  Lr: 0.030000  Loss: -1.8010  Acc@1: 81.2500 (79.7057)  Acc@5: 100.0000 (98.8479)  time: 0.3941  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1810/3750]  eta: 0:12:39  Lr: 0.030000  Loss: -1.9112  Acc@1: 81.2500 (79.7108)  Acc@5: 100.0000 (98.8473)  time: 0.3946  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [1820/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -1.2220  Acc@1: 81.2500 (79.7090)  Acc@5: 100.0000 (98.8468)  time: 0.3941  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1830/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -2.1011  Acc@1: 81.2500 (79.7105)  Acc@5: 100.0000 (98.8360)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1840/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -1.8362  Acc@1: 81.2500 (79.7359)  Acc@5: 100.0000 (98.8423)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1850/3750]  eta: 0:12:24  Lr: 0.030000  Loss: -1.9446  Acc@1: 81.2500 (79.7474)  Acc@5: 100.0000 (98.8452)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1860/3750]  eta: 0:12:20  Lr: 0.030000  Loss: -1.5864  Acc@1: 75.0000 (79.7354)  Acc@5: 100.0000 (98.8481)  time: 0.3923  data: 0.0006  max mem: 2912
Train: Epoch[3/5]  [1870/3750]  eta: 0:12:16  Lr: 0.030000  Loss: -1.9048  Acc@1: 75.0000 (79.7134)  Acc@5: 100.0000 (98.8475)  time: 0.3929  data: 0.0006  max mem: 2912
Train: Epoch[3/5]  [1880/3750]  eta: 0:12:12  Lr: 0.030000  Loss: -1.9080  Acc@1: 75.0000 (79.7116)  Acc@5: 100.0000 (98.8537)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1890/3750]  eta: 0:12:08  Lr: 0.030000  Loss: -1.7636  Acc@1: 81.2500 (79.6900)  Acc@5: 100.0000 (98.8564)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1900/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -1.5759  Acc@1: 75.0000 (79.6357)  Acc@5: 100.0000 (98.8493)  time: 0.3942  data: 0.0006  max mem: 2912
Train: Epoch[3/5]  [1910/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -1.5390  Acc@1: 75.0000 (79.6474)  Acc@5: 100.0000 (98.8520)  time: 0.3950  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [1920/3750]  eta: 0:11:56  Lr: 0.030000  Loss: -1.5801  Acc@1: 81.2500 (79.6493)  Acc@5: 100.0000 (98.8417)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1930/3750]  eta: 0:11:52  Lr: 0.030000  Loss: -2.1249  Acc@1: 81.2500 (79.6608)  Acc@5: 100.0000 (98.8380)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1940/3750]  eta: 0:11:48  Lr: 0.030000  Loss: -1.7186  Acc@1: 81.2500 (79.6722)  Acc@5: 100.0000 (98.8408)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1950/3750]  eta: 0:11:45  Lr: 0.030000  Loss: -1.6614  Acc@1: 81.2500 (79.6707)  Acc@5: 100.0000 (98.8403)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1960/3750]  eta: 0:11:41  Lr: 0.030000  Loss: -1.8516  Acc@1: 81.2500 (79.6819)  Acc@5: 100.0000 (98.8431)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1970/3750]  eta: 0:11:37  Lr: 0.030000  Loss: -1.8806  Acc@1: 81.2500 (79.7026)  Acc@5: 100.0000 (98.8458)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1980/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -1.6010  Acc@1: 81.2500 (79.6820)  Acc@5: 100.0000 (98.8516)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [1990/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -2.1288  Acc@1: 75.0000 (79.6930)  Acc@5: 100.0000 (98.8574)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2000/3750]  eta: 0:11:25  Lr: 0.030000  Loss: -1.6661  Acc@1: 87.5000 (79.7226)  Acc@5: 100.0000 (98.8506)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2010/3750]  eta: 0:11:21  Lr: 0.030000  Loss: -1.6708  Acc@1: 87.5000 (79.7271)  Acc@5: 100.0000 (98.8532)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2020/3750]  eta: 0:11:17  Lr: 0.030000  Loss: -2.0363  Acc@1: 81.2500 (79.7378)  Acc@5: 100.0000 (98.8558)  time: 0.3939  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2030/3750]  eta: 0:11:13  Lr: 0.030000  Loss: -2.2973  Acc@1: 81.2500 (79.7514)  Acc@5: 100.0000 (98.8552)  time: 0.3940  data: 0.0006  max mem: 2912
Train: Epoch[3/5]  [2040/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -1.8139  Acc@1: 81.2500 (79.7434)  Acc@5: 100.0000 (98.8455)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2050/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -1.9147  Acc@1: 81.2500 (79.7538)  Acc@5: 100.0000 (98.8481)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2060/3750]  eta: 0:11:01  Lr: 0.030000  Loss: -1.7464  Acc@1: 81.2500 (79.7519)  Acc@5: 100.0000 (98.8476)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2070/3750]  eta: 0:10:57  Lr: 0.030000  Loss: -2.0102  Acc@1: 81.2500 (79.7411)  Acc@5: 100.0000 (98.8502)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2080/3750]  eta: 0:10:54  Lr: 0.030000  Loss: -1.6051  Acc@1: 75.0000 (79.7273)  Acc@5: 100.0000 (98.8497)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2090/3750]  eta: 0:10:50  Lr: 0.030000  Loss: -1.7125  Acc@1: 81.2500 (79.7495)  Acc@5: 100.0000 (98.8552)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2100/3750]  eta: 0:10:46  Lr: 0.030000  Loss: -1.9304  Acc@1: 81.2500 (79.7656)  Acc@5: 100.0000 (98.8517)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2110/3750]  eta: 0:10:42  Lr: 0.030000  Loss: -2.1724  Acc@1: 81.2500 (79.7815)  Acc@5: 100.0000 (98.8483)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2120/3750]  eta: 0:10:38  Lr: 0.030000  Loss: -1.6577  Acc@1: 81.2500 (79.7884)  Acc@5: 100.0000 (98.8537)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2130/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -1.5640  Acc@1: 81.2500 (79.7953)  Acc@5: 100.0000 (98.8532)  time: 0.3944  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2140/3750]  eta: 0:10:30  Lr: 0.030000  Loss: -1.4808  Acc@1: 81.2500 (79.8138)  Acc@5: 100.0000 (98.8557)  time: 0.3938  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2150/3750]  eta: 0:10:26  Lr: 0.030000  Loss: -0.9273  Acc@1: 81.2500 (79.8030)  Acc@5: 100.0000 (98.8436)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2160/3750]  eta: 0:10:22  Lr: 0.030000  Loss: -2.1429  Acc@1: 81.2500 (79.8155)  Acc@5: 100.0000 (98.8431)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2170/3750]  eta: 0:10:18  Lr: 0.030000  Loss: -2.0910  Acc@1: 81.2500 (79.8250)  Acc@5: 100.0000 (98.8485)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2180/3750]  eta: 0:10:14  Lr: 0.030000  Loss: -1.5661  Acc@1: 81.2500 (79.8229)  Acc@5: 100.0000 (98.8480)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2190/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -1.9569  Acc@1: 75.0000 (79.8037)  Acc@5: 100.0000 (98.8504)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2200/3750]  eta: 0:10:07  Lr: 0.030000  Loss: -2.0737  Acc@1: 81.2500 (79.8018)  Acc@5: 100.0000 (98.8500)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2210/3750]  eta: 0:10:03  Lr: 0.030000  Loss: -2.0136  Acc@1: 81.2500 (79.8140)  Acc@5: 100.0000 (98.8523)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2220/3750]  eta: 0:09:59  Lr: 0.030000  Loss: -1.9127  Acc@1: 81.2500 (79.8064)  Acc@5: 100.0000 (98.8547)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2230/3750]  eta: 0:09:55  Lr: 0.030000  Loss: -1.7191  Acc@1: 75.0000 (79.7989)  Acc@5: 100.0000 (98.8570)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2240/3750]  eta: 0:09:51  Lr: 0.030000  Loss: -1.4834  Acc@1: 81.2500 (79.8025)  Acc@5: 100.0000 (98.8537)  time: 0.3956  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2250/3750]  eta: 0:09:47  Lr: 0.030000  Loss: -1.3829  Acc@1: 81.2500 (79.7951)  Acc@5: 100.0000 (98.8588)  time: 0.3952  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2260/3750]  eta: 0:09:43  Lr: 0.030000  Loss: -1.7364  Acc@1: 75.0000 (79.7905)  Acc@5: 100.0000 (98.8556)  time: 0.3942  data: 0.0007  max mem: 2912
Train: Epoch[3/5]  [2270/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -1.7131  Acc@1: 75.0000 (79.7914)  Acc@5: 100.0000 (98.8524)  time: 0.3942  data: 0.0007  max mem: 2912
Train: Epoch[3/5]  [2280/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -2.2552  Acc@1: 81.2500 (79.8170)  Acc@5: 100.0000 (98.8574)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2290/3750]  eta: 0:09:31  Lr: 0.030000  Loss: -1.8884  Acc@1: 87.5000 (79.8205)  Acc@5: 100.0000 (98.8569)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2300/3750]  eta: 0:09:27  Lr: 0.030000  Loss: -1.7439  Acc@1: 81.2500 (79.8321)  Acc@5: 100.0000 (98.8592)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2310/3750]  eta: 0:09:24  Lr: 0.030000  Loss: -1.4786  Acc@1: 81.2500 (79.8545)  Acc@5: 100.0000 (98.8641)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2320/3750]  eta: 0:09:20  Lr: 0.030000  Loss: -2.1050  Acc@1: 87.5000 (79.8794)  Acc@5: 100.0000 (98.8690)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2330/3750]  eta: 0:09:16  Lr: 0.030000  Loss: -1.4124  Acc@1: 81.2500 (79.8584)  Acc@5: 100.0000 (98.8551)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2340/3750]  eta: 0:09:12  Lr: 0.030000  Loss: -2.0477  Acc@1: 81.2500 (79.8697)  Acc@5: 100.0000 (98.8573)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2350/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -1.6725  Acc@1: 81.2500 (79.8676)  Acc@5: 100.0000 (98.8622)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2360/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -2.1181  Acc@1: 75.0000 (79.8549)  Acc@5: 100.0000 (98.8617)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2370/3750]  eta: 0:09:00  Lr: 0.030000  Loss: -1.5521  Acc@1: 81.2500 (79.8608)  Acc@5: 100.0000 (98.8612)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2380/3750]  eta: 0:08:56  Lr: 0.030000  Loss: -1.3182  Acc@1: 81.2500 (79.8562)  Acc@5: 100.0000 (98.8608)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2390/3750]  eta: 0:08:52  Lr: 0.030000  Loss: -1.8353  Acc@1: 75.0000 (79.8411)  Acc@5: 100.0000 (98.8629)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2400/3750]  eta: 0:08:48  Lr: 0.030000  Loss: -1.6945  Acc@1: 81.2500 (79.8600)  Acc@5: 100.0000 (98.8677)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2410/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -1.8656  Acc@1: 81.2500 (79.8502)  Acc@5: 100.0000 (98.8724)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2420/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -1.5331  Acc@1: 81.2500 (79.8508)  Acc@5: 100.0000 (98.8693)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2430/3750]  eta: 0:08:37  Lr: 0.030000  Loss: -1.4845  Acc@1: 81.2500 (79.8437)  Acc@5: 100.0000 (98.8688)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2440/3750]  eta: 0:08:33  Lr: 0.030000  Loss: -2.2037  Acc@1: 81.2500 (79.8546)  Acc@5: 100.0000 (98.8683)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2450/3750]  eta: 0:08:29  Lr: 0.030000  Loss: -1.8983  Acc@1: 81.2500 (79.8399)  Acc@5: 100.0000 (98.8627)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2460/3750]  eta: 0:08:25  Lr: 0.030000  Loss: -1.8961  Acc@1: 81.2500 (79.8405)  Acc@5: 100.0000 (98.8673)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2470/3750]  eta: 0:08:21  Lr: 0.030000  Loss: -1.6357  Acc@1: 81.2500 (79.8336)  Acc@5: 100.0000 (98.8643)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2480/3750]  eta: 0:08:17  Lr: 0.030000  Loss: -1.8253  Acc@1: 81.2500 (79.8292)  Acc@5: 100.0000 (98.8639)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2490/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -1.9792  Acc@1: 75.0000 (79.8224)  Acc@5: 100.0000 (98.8634)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2500/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -2.2139  Acc@1: 75.0000 (79.8256)  Acc@5: 100.0000 (98.8680)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2510/3750]  eta: 0:08:05  Lr: 0.030000  Loss: -1.7994  Acc@1: 81.2500 (79.8337)  Acc@5: 100.0000 (98.8725)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2520/3750]  eta: 0:08:01  Lr: 0.030000  Loss: -1.4824  Acc@1: 81.2500 (79.8270)  Acc@5: 100.0000 (98.8720)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:57  Lr: 0.030000  Loss: -1.4322  Acc@1: 81.2500 (79.8499)  Acc@5: 100.0000 (98.8740)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:53  Lr: 0.030000  Loss: -1.5145  Acc@1: 87.5000 (79.8603)  Acc@5: 100.0000 (98.8735)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2550/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -2.0040  Acc@1: 81.2500 (79.8657)  Acc@5: 100.0000 (98.8705)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2560/3750]  eta: 0:07:46  Lr: 0.030000  Loss: -1.7372  Acc@1: 81.2500 (79.8589)  Acc@5: 100.0000 (98.8701)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2570/3750]  eta: 0:07:42  Lr: 0.030000  Loss: -1.6040  Acc@1: 81.2500 (79.8765)  Acc@5: 100.0000 (98.8745)  time: 0.3935  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2580/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -1.1442  Acc@1: 75.0000 (79.8358)  Acc@5: 100.0000 (98.8740)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2590/3750]  eta: 0:07:34  Lr: 0.030000  Loss: -1.8682  Acc@1: 75.0000 (79.8196)  Acc@5: 100.0000 (98.8735)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2600/3750]  eta: 0:07:30  Lr: 0.030000  Loss: -1.5011  Acc@1: 75.0000 (79.8106)  Acc@5: 100.0000 (98.8658)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2610/3750]  eta: 0:07:26  Lr: 0.030000  Loss: -1.8064  Acc@1: 75.0000 (79.8090)  Acc@5: 100.0000 (98.8654)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2620/3750]  eta: 0:07:22  Lr: 0.030000  Loss: -2.2971  Acc@1: 81.2500 (79.8288)  Acc@5: 100.0000 (98.8673)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2630/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -2.0880  Acc@1: 87.5000 (79.8413)  Acc@5: 100.0000 (98.8645)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2640/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -1.7562  Acc@1: 87.5000 (79.8466)  Acc@5: 100.0000 (98.8617)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2650/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -2.2985  Acc@1: 81.2500 (79.8519)  Acc@5: 100.0000 (98.8636)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2660/3750]  eta: 0:07:06  Lr: 0.030000  Loss: -1.4947  Acc@1: 81.2500 (79.8595)  Acc@5: 100.0000 (98.8609)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2670/3750]  eta: 0:07:02  Lr: 0.030000  Loss: -2.1081  Acc@1: 81.2500 (79.8577)  Acc@5: 100.0000 (98.8581)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:59  Lr: 0.030000  Loss: -1.5147  Acc@1: 81.2500 (79.8513)  Acc@5: 100.0000 (98.8577)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:55  Lr: 0.030000  Loss: -1.8918  Acc@1: 81.2500 (79.8495)  Acc@5: 100.0000 (98.8503)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:51  Lr: 0.030000  Loss: -1.6133  Acc@1: 81.2500 (79.8616)  Acc@5: 100.0000 (98.8453)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:47  Lr: 0.030000  Loss: -1.6770  Acc@1: 81.2500 (79.8621)  Acc@5: 100.0000 (98.8427)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2720/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -2.1487  Acc@1: 81.2500 (79.8764)  Acc@5: 100.0000 (98.8446)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2730/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -1.9774  Acc@1: 87.5000 (79.8952)  Acc@5: 100.0000 (98.8466)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2740/3750]  eta: 0:06:35  Lr: 0.030000  Loss: -1.8914  Acc@1: 81.2500 (79.8887)  Acc@5: 100.0000 (98.8439)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2750/3750]  eta: 0:06:31  Lr: 0.030000  Loss: -1.8213  Acc@1: 81.2500 (79.9005)  Acc@5: 100.0000 (98.8481)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2760/3750]  eta: 0:06:27  Lr: 0.030000  Loss: -1.8747  Acc@1: 81.2500 (79.8895)  Acc@5: 100.0000 (98.8478)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2770/3750]  eta: 0:06:23  Lr: 0.030000  Loss: -1.4049  Acc@1: 81.2500 (79.8990)  Acc@5: 100.0000 (98.8519)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2780/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -1.5274  Acc@1: 81.2500 (79.8993)  Acc@5: 100.0000 (98.8538)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2790/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -1.7526  Acc@1: 75.0000 (79.8862)  Acc@5: 100.0000 (98.8579)  time: 0.3882  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2800/3750]  eta: 0:06:11  Lr: 0.030000  Loss: -1.6533  Acc@1: 81.2500 (79.9000)  Acc@5: 100.0000 (98.8531)  time: 0.3882  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2810/3750]  eta: 0:06:08  Lr: 0.030000  Loss: -2.0707  Acc@1: 81.2500 (79.9026)  Acc@5: 100.0000 (98.8483)  time: 0.3882  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2820/3750]  eta: 0:06:04  Lr: 0.030000  Loss: -2.2259  Acc@1: 81.2500 (79.9074)  Acc@5: 100.0000 (98.8501)  time: 0.3881  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2830/3750]  eta: 0:06:00  Lr: 0.030000  Loss: -1.9567  Acc@1: 81.2500 (79.8945)  Acc@5: 100.0000 (98.8432)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:56  Lr: 0.030000  Loss: -1.9327  Acc@1: 81.2500 (79.8882)  Acc@5: 100.0000 (98.8450)  time: 0.3881  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:52  Lr: 0.030000  Loss: -0.9710  Acc@1: 81.2500 (79.8930)  Acc@5: 100.0000 (98.8381)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -1.7648  Acc@1: 81.2500 (79.9021)  Acc@5: 100.0000 (98.8400)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -1.9797  Acc@1: 81.2500 (79.9068)  Acc@5: 100.0000 (98.8397)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:40  Lr: 0.030000  Loss: -1.9111  Acc@1: 81.2500 (79.9093)  Acc@5: 100.0000 (98.8372)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:36  Lr: 0.030000  Loss: -1.8935  Acc@1: 81.2500 (79.9075)  Acc@5: 100.0000 (98.8391)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2900/3750]  eta: 0:05:32  Lr: 0.030000  Loss: -1.5252  Acc@1: 81.2500 (79.9013)  Acc@5: 100.0000 (98.8345)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2910/3750]  eta: 0:05:28  Lr: 0.030000  Loss: -1.2242  Acc@1: 75.0000 (79.8759)  Acc@5: 100.0000 (98.8320)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2920/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -1.9189  Acc@1: 81.2500 (79.8892)  Acc@5: 100.0000 (98.8317)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2930/3750]  eta: 0:05:21  Lr: 0.030000  Loss: -1.6248  Acc@1: 81.2500 (79.8917)  Acc@5: 100.0000 (98.8336)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2940/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -1.9040  Acc@1: 75.0000 (79.8814)  Acc@5: 100.0000 (98.8333)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2950/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -1.7999  Acc@1: 75.0000 (79.8839)  Acc@5: 100.0000 (98.8288)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2960/3750]  eta: 0:05:09  Lr: 0.030000  Loss: -1.3433  Acc@1: 81.2500 (79.8780)  Acc@5: 100.0000 (98.8285)  time: 0.3904  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2970/3750]  eta: 0:05:05  Lr: 0.030000  Loss: -2.0045  Acc@1: 81.2500 (79.8889)  Acc@5: 100.0000 (98.8283)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [2980/3750]  eta: 0:05:01  Lr: 0.030000  Loss: -2.1279  Acc@1: 81.2500 (79.8830)  Acc@5: 100.0000 (98.8301)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:57  Lr: 0.030000  Loss: -1.8461  Acc@1: 81.2500 (79.9064)  Acc@5: 100.0000 (98.8298)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -1.7067  Acc@1: 87.5000 (79.9254)  Acc@5: 100.0000 (98.8337)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -1.8328  Acc@1: 81.2500 (79.9174)  Acc@5: 100.0000 (98.8376)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:45  Lr: 0.030000  Loss: -1.9423  Acc@1: 81.2500 (79.9156)  Acc@5: 100.0000 (98.8373)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:41  Lr: 0.030000  Loss: -2.1059  Acc@1: 81.2500 (79.9324)  Acc@5: 100.0000 (98.8350)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:37  Lr: 0.030000  Loss: -2.1418  Acc@1: 81.2500 (79.9388)  Acc@5: 100.0000 (98.8367)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:34  Lr: 0.030000  Loss: -1.9397  Acc@1: 81.2500 (79.9512)  Acc@5: 100.0000 (98.8385)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:30  Lr: 0.030000  Loss: -2.0549  Acc@1: 87.5000 (79.9637)  Acc@5: 100.0000 (98.8402)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3070/3750]  eta: 0:04:26  Lr: 0.030000  Loss: -2.0968  Acc@1: 81.2500 (79.9739)  Acc@5: 100.0000 (98.8420)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3080/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -1.6961  Acc@1: 81.2500 (79.9842)  Acc@5: 100.0000 (98.8437)  time: 0.3927  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3090/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -1.4719  Acc@1: 81.2500 (79.9741)  Acc@5: 100.0000 (98.8454)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -2.1203  Acc@1: 81.2500 (79.9762)  Acc@5: 100.0000 (98.8471)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3110/3750]  eta: 0:04:10  Lr: 0.030000  Loss: -1.5978  Acc@1: 75.0000 (79.9723)  Acc@5: 100.0000 (98.8488)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3120/3750]  eta: 0:04:06  Lr: 0.030000  Loss: -1.9379  Acc@1: 75.0000 (79.9824)  Acc@5: 100.0000 (98.8505)  time: 0.3886  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3130/3750]  eta: 0:04:02  Lr: 0.030000  Loss: -1.6429  Acc@1: 81.2500 (79.9864)  Acc@5: 100.0000 (98.8542)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:58  Lr: 0.030000  Loss: -1.6762  Acc@1: 81.2500 (79.9904)  Acc@5: 100.0000 (98.8519)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -1.8745  Acc@1: 75.0000 (79.9687)  Acc@5: 100.0000 (98.8496)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:50  Lr: 0.030000  Loss: -1.7755  Acc@1: 75.0000 (79.9648)  Acc@5: 100.0000 (98.8532)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -2.1430  Acc@1: 81.2500 (79.9728)  Acc@5: 100.0000 (98.8549)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:43  Lr: 0.030000  Loss: -2.0619  Acc@1: 81.2500 (79.9611)  Acc@5: 100.0000 (98.8565)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -1.9514  Acc@1: 75.0000 (79.9553)  Acc@5: 100.0000 (98.8542)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -2.1781  Acc@1: 81.2500 (79.9711)  Acc@5: 100.0000 (98.8558)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -1.6387  Acc@1: 81.2500 (79.9809)  Acc@5: 100.0000 (98.8516)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -1.9896  Acc@1: 81.2500 (79.9732)  Acc@5: 100.0000 (98.8552)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -1.8401  Acc@1: 75.0000 (79.9714)  Acc@5: 100.0000 (98.8529)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3240/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -1.7582  Acc@1: 81.2500 (79.9869)  Acc@5: 100.0000 (98.8526)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3250/3750]  eta: 0:03:15  Lr: 0.030000  Loss: -1.6620  Acc@1: 81.2500 (79.9888)  Acc@5: 100.0000 (98.8523)  time: 0.3907  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3260/3750]  eta: 0:03:11  Lr: 0.030000  Loss: -1.7774  Acc@1: 75.0000 (79.9621)  Acc@5: 100.0000 (98.8520)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3270/3750]  eta: 0:03:07  Lr: 0.030000  Loss: -2.0668  Acc@1: 75.0000 (79.9564)  Acc@5: 100.0000 (98.8555)  time: 0.3937  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3280/3750]  eta: 0:03:03  Lr: 0.030000  Loss: -1.6139  Acc@1: 81.2500 (79.9509)  Acc@5: 100.0000 (98.8590)  time: 0.3943  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3290/3750]  eta: 0:03:00  Lr: 0.030000  Loss: -1.9828  Acc@1: 81.2500 (79.9529)  Acc@5: 100.0000 (98.8624)  time: 0.3936  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -1.2293  Acc@1: 81.2500 (79.9606)  Acc@5: 100.0000 (98.8621)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -1.9562  Acc@1: 81.2500 (79.9607)  Acc@5: 100.0000 (98.8636)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -1.9731  Acc@1: 81.2500 (79.9665)  Acc@5: 100.0000 (98.8614)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -1.9355  Acc@1: 81.2500 (79.9704)  Acc@5: 100.0000 (98.8592)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -1.9502  Acc@1: 81.2500 (79.9742)  Acc@5: 100.0000 (98.8607)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -1.8987  Acc@1: 81.2500 (79.9687)  Acc@5: 100.0000 (98.8604)  time: 0.3940  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:32  Lr: 0.030000  Loss: -1.9119  Acc@1: 81.2500 (79.9669)  Acc@5: 100.0000 (98.8638)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -1.7450  Acc@1: 81.2500 (79.9633)  Acc@5: 100.0000 (98.8635)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -1.5072  Acc@1: 81.2500 (79.9579)  Acc@5: 100.0000 (98.8631)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:20  Lr: 0.030000  Loss: -1.9369  Acc@1: 81.2500 (79.9543)  Acc@5: 100.0000 (98.8610)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -1.8587  Acc@1: 75.0000 (79.9324)  Acc@5: 100.0000 (98.8643)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -2.2026  Acc@1: 81.2500 (79.9491)  Acc@5: 100.0000 (98.8658)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -2.1289  Acc@1: 81.2500 (79.9328)  Acc@5: 100.0000 (98.8600)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -2.1503  Acc@1: 75.0000 (79.9421)  Acc@5: 100.0000 (98.8597)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -1.5561  Acc@1: 75.0000 (79.9477)  Acc@5: 100.0000 (98.8630)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -2.1192  Acc@1: 75.0000 (79.9424)  Acc@5: 100.0000 (98.8590)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -2.1044  Acc@1: 75.0000 (79.9299)  Acc@5: 100.0000 (98.8623)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -1.2227  Acc@1: 81.2500 (79.9265)  Acc@5: 100.0000 (98.8602)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -1.9390  Acc@1: 75.0000 (79.9196)  Acc@5: 100.0000 (98.8581)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:41  Lr: 0.030000  Loss: -1.5434  Acc@1: 75.0000 (79.9162)  Acc@5: 100.0000 (98.8560)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:37  Lr: 0.030000  Loss: -2.1233  Acc@1: 75.0000 (79.9075)  Acc@5: 100.0000 (98.8575)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -1.9254  Acc@1: 75.0000 (79.9114)  Acc@5: 100.0000 (98.8572)  time: 0.3929  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:30  Lr: 0.030000  Loss: -2.1700  Acc@1: 81.2500 (79.9134)  Acc@5: 100.0000 (98.8551)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -1.6486  Acc@1: 81.2500 (79.9172)  Acc@5: 100.0000 (98.8512)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -2.2658  Acc@1: 81.2500 (79.9192)  Acc@5: 100.0000 (98.8545)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -1.7112  Acc@1: 81.2500 (79.9335)  Acc@5: 100.0000 (98.8524)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -1.9651  Acc@1: 87.5000 (79.9407)  Acc@5: 100.0000 (98.8504)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -1.4749  Acc@1: 81.2500 (79.9426)  Acc@5: 100.0000 (98.8484)  time: 0.3880  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -1.9826  Acc@1: 75.0000 (79.9375)  Acc@5: 100.0000 (98.8429)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -1.3983  Acc@1: 75.0000 (79.9377)  Acc@5: 100.0000 (98.8443)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -1.9203  Acc@1: 75.0000 (79.9379)  Acc@5: 100.0000 (98.8423)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -1.9855  Acc@1: 75.0000 (79.9380)  Acc@5: 100.0000 (98.8438)  time: 0.3880  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:50  Lr: 0.030000  Loss: -1.6394  Acc@1: 81.2500 (79.9451)  Acc@5: 100.0000 (98.8436)  time: 0.3882  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:46  Lr: 0.030000  Loss: -1.5385  Acc@1: 81.2500 (79.9453)  Acc@5: 100.0000 (98.8433)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -1.7324  Acc@1: 81.2500 (79.9454)  Acc@5: 100.0000 (98.8448)  time: 0.3899  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -2.0145  Acc@1: 81.2500 (79.9575)  Acc@5: 100.0000 (98.8428)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -2.1357  Acc@1: 87.5000 (79.9696)  Acc@5: 100.0000 (98.8459)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -1.6726  Acc@1: 81.2500 (79.9697)  Acc@5: 100.0000 (98.8474)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -1.7034  Acc@1: 81.2500 (79.9698)  Acc@5: 100.0000 (98.8471)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -1.9226  Acc@1: 81.2500 (79.9800)  Acc@5: 100.0000 (98.8486)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -1.8026  Acc@1: 81.2500 (79.9699)  Acc@5: 100.0000 (98.8466)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -1.5356  Acc@1: 75.0000 (79.9532)  Acc@5: 100.0000 (98.8463)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -2.2797  Acc@1: 81.2500 (79.9617)  Acc@5: 100.0000 (98.8478)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -1.7743  Acc@1: 81.2500 (79.9568)  Acc@5: 100.0000 (98.8441)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -1.8506  Acc@1: 81.2500 (79.9652)  Acc@5: 100.0000 (98.8422)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -2.1515  Acc@1: 81.2500 (79.9683)  Acc@5: 100.0000 (98.8450)  time: 0.3910  data: 0.0010  max mem: 2912
Train: Epoch[3/5] Total time: 0:24:28 (0.3916 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}}
Averaged stats: Lr: 0.030000  Loss: -2.1515  Acc@1: 81.2500 (79.9683)  Acc@5: 100.0000 (98.8450)
Train: Epoch[4/5]  [   0/3750]  eta: 0:56:22  Lr: 0.030000  Loss: -2.0496  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.9020  data: 0.5118  max mem: 2912
Train: Epoch[4/5]  [  10/3750]  eta: 0:27:16  Lr: 0.030000  Loss: -2.1061  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (98.2955)  time: 0.4376  data: 0.0469  max mem: 2912
Train: Epoch[4/5]  [  20/3750]  eta: 0:25:52  Lr: 0.030000  Loss: -2.2340  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (99.1071)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [  30/3750]  eta: 0:25:17  Lr: 0.030000  Loss: -1.7595  Acc@1: 81.2500 (81.6532)  Acc@5: 100.0000 (99.3952)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [  40/3750]  eta: 0:24:59  Lr: 0.030000  Loss: -1.4914  Acc@1: 81.2500 (82.0122)  Acc@5: 100.0000 (99.5427)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [  50/3750]  eta: 0:24:47  Lr: 0.030000  Loss: -2.1469  Acc@1: 81.2500 (81.3725)  Acc@5: 100.0000 (99.6324)  time: 0.3927  data: 0.0006  max mem: 2912
Train: Epoch[4/5]  [  60/3750]  eta: 0:24:35  Lr: 0.030000  Loss: -1.8596  Acc@1: 75.0000 (80.6352)  Acc@5: 100.0000 (99.4877)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [  70/3750]  eta: 0:24:27  Lr: 0.030000  Loss: -1.9295  Acc@1: 81.2500 (80.8099)  Acc@5: 100.0000 (99.2958)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [  80/3750]  eta: 0:24:20  Lr: 0.030000  Loss: -1.8212  Acc@1: 81.2500 (80.5556)  Acc@5: 100.0000 (99.2284)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [  90/3750]  eta: 0:24:13  Lr: 0.030000  Loss: -1.9238  Acc@1: 75.0000 (80.3571)  Acc@5: 100.0000 (99.1071)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 100/3750]  eta: 0:24:06  Lr: 0.030000  Loss: -1.3239  Acc@1: 75.0000 (80.0124)  Acc@5: 100.0000 (99.1337)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 110/3750]  eta: 0:24:01  Lr: 0.030000  Loss: -1.7363  Acc@1: 81.2500 (80.3491)  Acc@5: 100.0000 (99.0991)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 120/3750]  eta: 0:23:55  Lr: 0.030000  Loss: -1.9931  Acc@1: 87.5000 (80.6302)  Acc@5: 100.0000 (99.1736)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 130/3750]  eta: 0:23:49  Lr: 0.030000  Loss: -1.7681  Acc@1: 87.5000 (80.7729)  Acc@5: 100.0000 (99.1412)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 140/3750]  eta: 0:23:44  Lr: 0.030000  Loss: -2.0079  Acc@1: 81.2500 (80.5851)  Acc@5: 100.0000 (99.1578)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 150/3750]  eta: 0:23:39  Lr: 0.030000  Loss: -1.7410  Acc@1: 81.2500 (80.4636)  Acc@5: 100.0000 (99.0480)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 160/3750]  eta: 0:23:35  Lr: 0.030000  Loss: -2.0224  Acc@1: 75.0000 (80.3183)  Acc@5: 100.0000 (99.1071)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 170/3750]  eta: 0:23:30  Lr: 0.030000  Loss: -1.2625  Acc@1: 75.0000 (80.0804)  Acc@5: 100.0000 (99.0863)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 180/3750]  eta: 0:23:25  Lr: 0.030000  Loss: -1.9946  Acc@1: 81.2500 (80.1796)  Acc@5: 100.0000 (99.0677)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 190/3750]  eta: 0:23:21  Lr: 0.030000  Loss: -1.4344  Acc@1: 81.2500 (79.8102)  Acc@5: 100.0000 (99.0510)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 200/3750]  eta: 0:23:17  Lr: 0.030000  Loss: -2.0848  Acc@1: 81.2500 (80.1306)  Acc@5: 100.0000 (98.9739)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 210/3750]  eta: 0:23:12  Lr: 0.030000  Loss: -1.7248  Acc@1: 81.2500 (80.0948)  Acc@5: 100.0000 (98.9633)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 220/3750]  eta: 0:23:08  Lr: 0.030000  Loss: -2.1290  Acc@1: 75.0000 (80.0339)  Acc@5: 100.0000 (98.9536)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 230/3750]  eta: 0:23:03  Lr: 0.030000  Loss: -1.4577  Acc@1: 75.0000 (80.0054)  Acc@5: 100.0000 (98.9448)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 240/3750]  eta: 0:22:59  Lr: 0.030000  Loss: -2.2379  Acc@1: 81.2500 (80.0311)  Acc@5: 100.0000 (98.9886)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 250/3750]  eta: 0:22:55  Lr: 0.030000  Loss: -1.4647  Acc@1: 87.5000 (80.2789)  Acc@5: 100.0000 (99.0289)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 260/3750]  eta: 0:22:50  Lr: 0.030000  Loss: -1.6211  Acc@1: 87.5000 (80.3640)  Acc@5: 100.0000 (99.0182)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 270/3750]  eta: 0:22:46  Lr: 0.030000  Loss: -1.5410  Acc@1: 81.2500 (80.2352)  Acc@5: 100.0000 (98.9391)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 280/3750]  eta: 0:22:42  Lr: 0.030000  Loss: -2.0061  Acc@1: 75.0000 (80.1824)  Acc@5: 100.0000 (98.8657)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 290/3750]  eta: 0:22:38  Lr: 0.030000  Loss: -2.0557  Acc@1: 81.2500 (80.3265)  Acc@5: 100.0000 (98.9046)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 300/3750]  eta: 0:22:34  Lr: 0.030000  Loss: -2.0255  Acc@1: 81.2500 (80.3779)  Acc@5: 100.0000 (98.8787)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 310/3750]  eta: 0:22:30  Lr: 0.030000  Loss: -1.2705  Acc@1: 81.2500 (80.3055)  Acc@5: 100.0000 (98.8143)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 320/3750]  eta: 0:22:26  Lr: 0.030000  Loss: -1.2416  Acc@1: 75.0000 (80.2181)  Acc@5: 100.0000 (98.8123)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 330/3750]  eta: 0:22:22  Lr: 0.030000  Loss: -2.2257  Acc@1: 81.2500 (80.1926)  Acc@5: 100.0000 (98.8293)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 340/3750]  eta: 0:22:18  Lr: 0.030000  Loss: -2.0547  Acc@1: 75.0000 (80.1136)  Acc@5: 100.0000 (98.7353)  time: 0.3905  data: 0.0009  max mem: 2912
Train: Epoch[4/5]  [ 350/3750]  eta: 0:22:13  Lr: 0.030000  Loss: -1.6161  Acc@1: 81.2500 (80.0926)  Acc@5: 100.0000 (98.7179)  time: 0.3906  data: 0.0009  max mem: 2912
Train: Epoch[4/5]  [ 360/3750]  eta: 0:22:09  Lr: 0.030000  Loss: -2.2697  Acc@1: 81.2500 (79.9515)  Acc@5: 100.0000 (98.6669)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 370/3750]  eta: 0:22:05  Lr: 0.030000  Loss: -1.9620  Acc@1: 81.2500 (79.9865)  Acc@5: 100.0000 (98.6354)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 380/3750]  eta: 0:22:01  Lr: 0.030000  Loss: -2.2572  Acc@1: 81.2500 (80.1181)  Acc@5: 100.0000 (98.6385)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 390/3750]  eta: 0:21:57  Lr: 0.030000  Loss: -2.0915  Acc@1: 87.5000 (80.3069)  Acc@5: 100.0000 (98.6573)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 400/3750]  eta: 0:21:53  Lr: 0.030000  Loss: -1.9613  Acc@1: 81.2500 (80.2525)  Acc@5: 100.0000 (98.6752)  time: 0.3882  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 410/3750]  eta: 0:21:49  Lr: 0.030000  Loss: -1.7648  Acc@1: 81.2500 (80.2768)  Acc@5: 100.0000 (98.6770)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 420/3750]  eta: 0:21:44  Lr: 0.030000  Loss: -1.8653  Acc@1: 81.2500 (80.3593)  Acc@5: 100.0000 (98.6787)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 430/3750]  eta: 0:21:40  Lr: 0.030000  Loss: -1.7222  Acc@1: 81.2500 (80.3944)  Acc@5: 100.0000 (98.6804)  time: 0.3881  data: 0.0002  max mem: 2912
Train: Epoch[4/5]  [ 440/3750]  eta: 0:21:36  Lr: 0.030000  Loss: -1.5654  Acc@1: 81.2500 (80.3997)  Acc@5: 100.0000 (98.7103)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 450/3750]  eta: 0:21:32  Lr: 0.030000  Loss: -1.6540  Acc@1: 81.2500 (80.2522)  Acc@5: 100.0000 (98.7251)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 460/3750]  eta: 0:21:28  Lr: 0.030000  Loss: -1.8151  Acc@1: 81.2500 (80.3145)  Acc@5: 100.0000 (98.7527)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 470/3750]  eta: 0:21:24  Lr: 0.030000  Loss: -1.5205  Acc@1: 81.2500 (80.3742)  Acc@5: 100.0000 (98.7659)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 480/3750]  eta: 0:21:20  Lr: 0.030000  Loss: -2.0087  Acc@1: 81.2500 (80.3924)  Acc@5: 100.0000 (98.7656)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 490/3750]  eta: 0:21:16  Lr: 0.030000  Loss: -1.8939  Acc@1: 81.2500 (80.3971)  Acc@5: 100.0000 (98.7780)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 500/3750]  eta: 0:21:12  Lr: 0.030000  Loss: -1.6387  Acc@1: 81.2500 (80.2894)  Acc@5: 100.0000 (98.7525)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 510/3750]  eta: 0:21:09  Lr: 0.030000  Loss: -2.2148  Acc@1: 75.0000 (80.2960)  Acc@5: 100.0000 (98.7769)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 520/3750]  eta: 0:21:04  Lr: 0.030000  Loss: -1.7277  Acc@1: 75.0000 (80.2663)  Acc@5: 100.0000 (98.7644)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 530/3750]  eta: 0:21:01  Lr: 0.030000  Loss: -1.8707  Acc@1: 75.0000 (80.1789)  Acc@5: 100.0000 (98.7406)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 540/3750]  eta: 0:20:57  Lr: 0.030000  Loss: -2.1796  Acc@1: 75.0000 (80.1756)  Acc@5: 100.0000 (98.7523)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 550/3750]  eta: 0:20:53  Lr: 0.030000  Loss: -2.0579  Acc@1: 81.2500 (80.2405)  Acc@5: 100.0000 (98.7523)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 560/3750]  eta: 0:20:49  Lr: 0.030000  Loss: -2.1531  Acc@1: 81.2500 (80.2585)  Acc@5: 100.0000 (98.7522)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 570/3750]  eta: 0:20:45  Lr: 0.030000  Loss: -2.0030  Acc@1: 81.2500 (80.2977)  Acc@5: 100.0000 (98.7741)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 580/3750]  eta: 0:20:41  Lr: 0.030000  Loss: -1.3652  Acc@1: 81.2500 (80.2173)  Acc@5: 100.0000 (98.7737)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 590/3750]  eta: 0:20:37  Lr: 0.030000  Loss: -2.0732  Acc@1: 75.0000 (80.2348)  Acc@5: 100.0000 (98.7733)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 600/3750]  eta: 0:20:33  Lr: 0.030000  Loss: -1.8092  Acc@1: 75.0000 (80.1477)  Acc@5: 100.0000 (98.7313)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 610/3750]  eta: 0:20:29  Lr: 0.030000  Loss: -1.8487  Acc@1: 75.0000 (80.0941)  Acc@5: 100.0000 (98.7520)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 620/3750]  eta: 0:20:25  Lr: 0.030000  Loss: -1.5888  Acc@1: 81.2500 (80.1027)  Acc@5: 100.0000 (98.7520)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 630/3750]  eta: 0:20:21  Lr: 0.030000  Loss: -1.6796  Acc@1: 81.2500 (80.1208)  Acc@5: 100.0000 (98.7619)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 640/3750]  eta: 0:20:17  Lr: 0.030000  Loss: -1.8958  Acc@1: 81.2500 (80.1677)  Acc@5: 100.0000 (98.7715)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 650/3750]  eta: 0:20:13  Lr: 0.030000  Loss: -2.1732  Acc@1: 81.2500 (80.1651)  Acc@5: 100.0000 (98.7519)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 660/3750]  eta: 0:20:09  Lr: 0.030000  Loss: -2.0956  Acc@1: 81.2500 (80.2383)  Acc@5: 100.0000 (98.7613)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 670/3750]  eta: 0:20:05  Lr: 0.030000  Loss: -1.6103  Acc@1: 81.2500 (80.2347)  Acc@5: 100.0000 (98.7705)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 680/3750]  eta: 0:20:01  Lr: 0.030000  Loss: -1.9443  Acc@1: 75.0000 (80.1762)  Acc@5: 100.0000 (98.7794)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 690/3750]  eta: 0:19:57  Lr: 0.030000  Loss: -1.3956  Acc@1: 81.2500 (80.1918)  Acc@5: 100.0000 (98.7789)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 700/3750]  eta: 0:19:53  Lr: 0.030000  Loss: -2.1384  Acc@1: 81.2500 (80.1355)  Acc@5: 100.0000 (98.7785)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 710/3750]  eta: 0:19:49  Lr: 0.030000  Loss: -1.8876  Acc@1: 81.2500 (80.1688)  Acc@5: 100.0000 (98.7781)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 720/3750]  eta: 0:19:45  Lr: 0.030000  Loss: -1.9638  Acc@1: 81.2500 (80.0624)  Acc@5: 100.0000 (98.7864)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 730/3750]  eta: 0:19:41  Lr: 0.030000  Loss: -2.0301  Acc@1: 75.0000 (79.9846)  Acc@5: 100.0000 (98.7859)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 740/3750]  eta: 0:19:37  Lr: 0.030000  Loss: -1.8151  Acc@1: 75.0000 (79.9848)  Acc@5: 100.0000 (98.7770)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 750/3750]  eta: 0:19:33  Lr: 0.030000  Loss: -1.4894  Acc@1: 81.2500 (79.9933)  Acc@5: 100.0000 (98.7766)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 760/3750]  eta: 0:19:29  Lr: 0.030000  Loss: -2.1161  Acc@1: 81.2500 (79.9770)  Acc@5: 100.0000 (98.7845)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 770/3750]  eta: 0:19:26  Lr: 0.030000  Loss: -1.8843  Acc@1: 81.2500 (79.9692)  Acc@5: 100.0000 (98.7759)  time: 0.3941  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 780/3750]  eta: 0:19:22  Lr: 0.030000  Loss: -2.3057  Acc@1: 81.2500 (80.0416)  Acc@5: 100.0000 (98.7756)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 790/3750]  eta: 0:19:18  Lr: 0.030000  Loss: -1.9144  Acc@1: 81.2500 (80.0648)  Acc@5: 100.0000 (98.7753)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 800/3750]  eta: 0:19:14  Lr: 0.030000  Loss: -1.7700  Acc@1: 75.0000 (80.0406)  Acc@5: 100.0000 (98.7906)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 810/3750]  eta: 0:19:10  Lr: 0.030000  Loss: -2.0126  Acc@1: 75.0000 (80.0247)  Acc@5: 100.0000 (98.7901)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 820/3750]  eta: 0:19:06  Lr: 0.030000  Loss: -1.5503  Acc@1: 81.2500 (80.0244)  Acc@5: 100.0000 (98.7820)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 830/3750]  eta: 0:19:02  Lr: 0.030000  Loss: -2.1384  Acc@1: 81.2500 (80.0993)  Acc@5: 100.0000 (98.7966)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 840/3750]  eta: 0:18:58  Lr: 0.030000  Loss: -2.0094  Acc@1: 81.2500 (80.1353)  Acc@5: 100.0000 (98.7961)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 850/3750]  eta: 0:18:54  Lr: 0.030000  Loss: -1.4664  Acc@1: 81.2500 (80.1630)  Acc@5: 100.0000 (98.7955)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 860/3750]  eta: 0:18:50  Lr: 0.030000  Loss: -2.0673  Acc@1: 81.2500 (80.1902)  Acc@5: 100.0000 (98.8023)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 870/3750]  eta: 0:18:46  Lr: 0.030000  Loss: -2.1473  Acc@1: 81.2500 (80.2024)  Acc@5: 100.0000 (98.8088)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 880/3750]  eta: 0:18:42  Lr: 0.030000  Loss: -2.1089  Acc@1: 81.2500 (80.2142)  Acc@5: 100.0000 (98.8153)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 890/3750]  eta: 0:18:39  Lr: 0.030000  Loss: -1.3826  Acc@1: 81.2500 (80.2048)  Acc@5: 100.0000 (98.8215)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 900/3750]  eta: 0:18:35  Lr: 0.030000  Loss: -2.1766  Acc@1: 81.2500 (80.2026)  Acc@5: 100.0000 (98.8346)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 910/3750]  eta: 0:18:31  Lr: 0.030000  Loss: -1.7246  Acc@1: 81.2500 (80.1866)  Acc@5: 100.0000 (98.8474)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 920/3750]  eta: 0:18:27  Lr: 0.030000  Loss: -1.4446  Acc@1: 81.2500 (80.2185)  Acc@5: 100.0000 (98.8464)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [ 930/3750]  eta: 0:18:23  Lr: 0.030000  Loss: -1.6353  Acc@1: 81.2500 (80.2162)  Acc@5: 100.0000 (98.8386)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 940/3750]  eta: 0:18:19  Lr: 0.030000  Loss: -1.3364  Acc@1: 75.0000 (80.1674)  Acc@5: 100.0000 (98.8310)  time: 0.3940  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 950/3750]  eta: 0:18:15  Lr: 0.030000  Loss: -1.9751  Acc@1: 75.0000 (80.1196)  Acc@5: 100.0000 (98.8368)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 960/3750]  eta: 0:18:11  Lr: 0.030000  Loss: -1.9253  Acc@1: 81.2500 (80.1314)  Acc@5: 100.0000 (98.8358)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 970/3750]  eta: 0:18:07  Lr: 0.030000  Loss: -2.2876  Acc@1: 81.2500 (80.1236)  Acc@5: 100.0000 (98.8350)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [ 980/3750]  eta: 0:18:04  Lr: 0.030000  Loss: -2.0074  Acc@1: 75.0000 (80.0714)  Acc@5: 100.0000 (98.8405)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [ 990/3750]  eta: 0:18:00  Lr: 0.030000  Loss: -2.1138  Acc@1: 75.0000 (80.0328)  Acc@5: 100.0000 (98.8459)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1000/3750]  eta: 0:17:56  Lr: 0.030000  Loss: -1.7919  Acc@1: 81.2500 (80.0512)  Acc@5: 100.0000 (98.8449)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1010/3750]  eta: 0:17:52  Lr: 0.030000  Loss: -1.6650  Acc@1: 81.2500 (80.0569)  Acc@5: 100.0000 (98.8378)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1020/3750]  eta: 0:17:48  Lr: 0.030000  Loss: -1.8741  Acc@1: 75.0000 (80.0012)  Acc@5: 100.0000 (98.8308)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1030/3750]  eta: 0:17:44  Lr: 0.030000  Loss: -1.6321  Acc@1: 75.0000 (80.0012)  Acc@5: 100.0000 (98.8361)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1040/3750]  eta: 0:17:40  Lr: 0.030000  Loss: -1.7184  Acc@1: 81.2500 (79.9592)  Acc@5: 100.0000 (98.8293)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1050/3750]  eta: 0:17:36  Lr: 0.030000  Loss: -2.1512  Acc@1: 81.2500 (79.9536)  Acc@5: 100.0000 (98.8225)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1060/3750]  eta: 0:17:32  Lr: 0.030000  Loss: -1.6374  Acc@1: 81.2500 (79.9482)  Acc@5: 100.0000 (98.8219)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1070/3750]  eta: 0:17:28  Lr: 0.030000  Loss: -2.1002  Acc@1: 81.2500 (79.9720)  Acc@5: 100.0000 (98.8270)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1080/3750]  eta: 0:17:24  Lr: 0.030000  Loss: -2.0917  Acc@1: 81.2500 (79.9780)  Acc@5: 100.0000 (98.8379)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1090/3750]  eta: 0:17:20  Lr: 0.030000  Loss: -2.1499  Acc@1: 87.5000 (80.0642)  Acc@5: 100.0000 (98.8485)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1100/3750]  eta: 0:17:16  Lr: 0.030000  Loss: -2.0689  Acc@1: 87.5000 (80.0806)  Acc@5: 100.0000 (98.8533)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1110/3750]  eta: 0:17:13  Lr: 0.030000  Loss: -1.9410  Acc@1: 81.2500 (80.1305)  Acc@5: 100.0000 (98.8580)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1120/3750]  eta: 0:17:09  Lr: 0.030000  Loss: -1.9519  Acc@1: 81.2500 (80.1238)  Acc@5: 100.0000 (98.8570)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1130/3750]  eta: 0:17:05  Lr: 0.030000  Loss: -2.1110  Acc@1: 81.2500 (80.1558)  Acc@5: 100.0000 (98.8672)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1140/3750]  eta: 0:17:01  Lr: 0.030000  Loss: -1.8843  Acc@1: 81.2500 (80.1599)  Acc@5: 100.0000 (98.8771)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1150/3750]  eta: 0:16:57  Lr: 0.030000  Loss: -1.0099  Acc@1: 81.2500 (80.1640)  Acc@5: 100.0000 (98.8651)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1160/3750]  eta: 0:16:53  Lr: 0.030000  Loss: -2.1296  Acc@1: 81.2500 (80.1949)  Acc@5: 100.0000 (98.8641)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1170/3750]  eta: 0:16:49  Lr: 0.030000  Loss: -2.0404  Acc@1: 81.2500 (80.2092)  Acc@5: 100.0000 (98.8738)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1180/3750]  eta: 0:16:45  Lr: 0.030000  Loss: -1.8818  Acc@1: 81.2500 (80.2127)  Acc@5: 100.0000 (98.8834)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1190/3750]  eta: 0:16:41  Lr: 0.030000  Loss: -1.6024  Acc@1: 81.2500 (80.1795)  Acc@5: 100.0000 (98.8717)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1200/3750]  eta: 0:16:37  Lr: 0.030000  Loss: -1.9235  Acc@1: 81.2500 (80.1988)  Acc@5: 100.0000 (98.8707)  time: 0.3910  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1210/3750]  eta: 0:16:33  Lr: 0.030000  Loss: -1.8619  Acc@1: 75.0000 (80.1868)  Acc@5: 100.0000 (98.8646)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1220/3750]  eta: 0:16:29  Lr: 0.030000  Loss: -1.7682  Acc@1: 81.2500 (80.2058)  Acc@5: 100.0000 (98.8636)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1230/3750]  eta: 0:16:25  Lr: 0.030000  Loss: -2.0147  Acc@1: 81.2500 (80.2244)  Acc@5: 100.0000 (98.8678)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1240/3750]  eta: 0:16:22  Lr: 0.030000  Loss: -1.7353  Acc@1: 81.2500 (80.2276)  Acc@5: 100.0000 (98.8668)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1250/3750]  eta: 0:16:18  Lr: 0.030000  Loss: -1.6610  Acc@1: 81.2500 (80.2458)  Acc@5: 100.0000 (98.8759)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1260/3750]  eta: 0:16:14  Lr: 0.030000  Loss: -2.0292  Acc@1: 81.2500 (80.2686)  Acc@5: 100.0000 (98.8848)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1270/3750]  eta: 0:16:10  Lr: 0.030000  Loss: -2.0869  Acc@1: 81.2500 (80.2518)  Acc@5: 100.0000 (98.8788)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1280/3750]  eta: 0:16:06  Lr: 0.030000  Loss: -1.9680  Acc@1: 81.2500 (80.2449)  Acc@5: 100.0000 (98.8876)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1290/3750]  eta: 0:16:02  Lr: 0.030000  Loss: -2.0016  Acc@1: 81.2500 (80.2672)  Acc@5: 100.0000 (98.8865)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1300/3750]  eta: 0:15:58  Lr: 0.030000  Loss: -1.7643  Acc@1: 81.2500 (80.2556)  Acc@5: 100.0000 (98.8951)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1310/3750]  eta: 0:15:54  Lr: 0.030000  Loss: -1.9643  Acc@1: 75.0000 (80.2346)  Acc@5: 100.0000 (98.9035)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1320/3750]  eta: 0:15:50  Lr: 0.030000  Loss: -1.6298  Acc@1: 75.0000 (80.2422)  Acc@5: 100.0000 (98.8929)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1330/3750]  eta: 0:15:46  Lr: 0.030000  Loss: -2.0098  Acc@1: 75.0000 (80.2451)  Acc@5: 100.0000 (98.8965)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1340/3750]  eta: 0:15:42  Lr: 0.030000  Loss: -1.8875  Acc@1: 81.2500 (80.2573)  Acc@5: 100.0000 (98.9001)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1350/3750]  eta: 0:15:38  Lr: 0.030000  Loss: -1.7605  Acc@1: 75.0000 (80.2045)  Acc@5: 100.0000 (98.8990)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1360/3750]  eta: 0:15:35  Lr: 0.030000  Loss: -1.8443  Acc@1: 75.0000 (80.2076)  Acc@5: 100.0000 (98.8933)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1370/3750]  eta: 0:15:31  Lr: 0.030000  Loss: -2.1927  Acc@1: 81.2500 (80.1878)  Acc@5: 100.0000 (98.8968)  time: 0.3944  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1380/3750]  eta: 0:15:27  Lr: 0.030000  Loss: -2.4361  Acc@1: 75.0000 (80.2000)  Acc@5: 100.0000 (98.9048)  time: 0.3952  data: 0.0006  max mem: 2912
Train: Epoch[4/5]  [1390/3750]  eta: 0:15:23  Lr: 0.030000  Loss: -1.7202  Acc@1: 81.2500 (80.1851)  Acc@5: 100.0000 (98.9037)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1400/3750]  eta: 0:15:19  Lr: 0.030000  Loss: -2.0885  Acc@1: 81.2500 (80.1615)  Acc@5: 100.0000 (98.8847)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1410/3750]  eta: 0:15:15  Lr: 0.030000  Loss: -1.8468  Acc@1: 81.2500 (80.1648)  Acc@5: 100.0000 (98.8838)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1420/3750]  eta: 0:15:11  Lr: 0.030000  Loss: -1.8424  Acc@1: 75.0000 (80.1372)  Acc@5: 100.0000 (98.8872)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1430/3750]  eta: 0:15:07  Lr: 0.030000  Loss: -2.0853  Acc@1: 75.0000 (80.1450)  Acc@5: 100.0000 (98.8863)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1440/3750]  eta: 0:15:03  Lr: 0.030000  Loss: -1.8300  Acc@1: 81.2500 (80.1266)  Acc@5: 100.0000 (98.8940)  time: 0.3936  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1450/3750]  eta: 0:15:00  Lr: 0.030000  Loss: -1.8837  Acc@1: 81.2500 (80.1602)  Acc@5: 100.0000 (98.8930)  time: 0.3925  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1460/3750]  eta: 0:14:56  Lr: 0.030000  Loss: -1.3074  Acc@1: 81.2500 (80.1591)  Acc@5: 100.0000 (98.8877)  time: 0.3933  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1470/3750]  eta: 0:14:52  Lr: 0.030000  Loss: -1.9390  Acc@1: 81.2500 (80.1368)  Acc@5: 100.0000 (98.8868)  time: 0.3945  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1480/3750]  eta: 0:14:48  Lr: 0.030000  Loss: -1.8651  Acc@1: 75.0000 (80.0895)  Acc@5: 100.0000 (98.8859)  time: 0.3925  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1490/3750]  eta: 0:14:44  Lr: 0.030000  Loss: -1.6057  Acc@1: 75.0000 (80.1098)  Acc@5: 100.0000 (98.8850)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1500/3750]  eta: 0:14:40  Lr: 0.030000  Loss: -2.0158  Acc@1: 81.2500 (80.1091)  Acc@5: 100.0000 (98.8841)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1510/3750]  eta: 0:14:36  Lr: 0.030000  Loss: -2.0086  Acc@1: 87.5000 (80.1580)  Acc@5: 100.0000 (98.8791)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1520/3750]  eta: 0:14:32  Lr: 0.030000  Loss: -1.8056  Acc@1: 87.5000 (80.1652)  Acc@5: 100.0000 (98.8741)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1530/3750]  eta: 0:14:28  Lr: 0.030000  Loss: -2.0051  Acc@1: 87.5000 (80.2008)  Acc@5: 100.0000 (98.8733)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1540/3750]  eta: 0:14:24  Lr: 0.030000  Loss: -1.6275  Acc@1: 87.5000 (80.2401)  Acc@5: 100.0000 (98.8765)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1550/3750]  eta: 0:14:20  Lr: 0.030000  Loss: -2.2070  Acc@1: 87.5000 (80.2748)  Acc@5: 100.0000 (98.8677)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1560/3750]  eta: 0:14:17  Lr: 0.030000  Loss: -1.9899  Acc@1: 87.5000 (80.3091)  Acc@5: 100.0000 (98.8589)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1570/3750]  eta: 0:14:13  Lr: 0.030000  Loss: -1.8807  Acc@1: 81.2500 (80.3032)  Acc@5: 100.0000 (98.8622)  time: 0.3931  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1580/3750]  eta: 0:14:09  Lr: 0.030000  Loss: -1.9406  Acc@1: 81.2500 (80.3012)  Acc@5: 100.0000 (98.8496)  time: 0.3946  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1590/3750]  eta: 0:14:05  Lr: 0.030000  Loss: -1.3571  Acc@1: 81.2500 (80.2718)  Acc@5: 100.0000 (98.8490)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1600/3750]  eta: 0:14:01  Lr: 0.030000  Loss: -1.7565  Acc@1: 81.2500 (80.3092)  Acc@5: 100.0000 (98.8562)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1610/3750]  eta: 0:13:57  Lr: 0.030000  Loss: -1.3720  Acc@1: 81.2500 (80.3111)  Acc@5: 100.0000 (98.8439)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1620/3750]  eta: 0:13:53  Lr: 0.030000  Loss: -1.7529  Acc@1: 75.0000 (80.2899)  Acc@5: 100.0000 (98.8472)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1630/3750]  eta: 0:13:49  Lr: 0.030000  Loss: -1.8138  Acc@1: 81.2500 (80.2958)  Acc@5: 100.0000 (98.8504)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1640/3750]  eta: 0:13:45  Lr: 0.030000  Loss: -2.0461  Acc@1: 87.5000 (80.3207)  Acc@5: 100.0000 (98.8536)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1650/3750]  eta: 0:13:41  Lr: 0.030000  Loss: -1.4205  Acc@1: 81.2500 (80.3150)  Acc@5: 100.0000 (98.8454)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1660/3750]  eta: 0:13:37  Lr: 0.030000  Loss: -1.9638  Acc@1: 75.0000 (80.2717)  Acc@5: 100.0000 (98.8486)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1670/3750]  eta: 0:13:34  Lr: 0.030000  Loss: -2.0292  Acc@1: 81.2500 (80.2887)  Acc@5: 100.0000 (98.8517)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1680/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -1.8312  Acc@1: 81.2500 (80.2982)  Acc@5: 100.0000 (98.8548)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1690/3750]  eta: 0:13:26  Lr: 0.030000  Loss: -1.4799  Acc@1: 75.0000 (80.2705)  Acc@5: 100.0000 (98.8468)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1700/3750]  eta: 0:13:22  Lr: 0.030000  Loss: -1.7560  Acc@1: 75.0000 (80.2726)  Acc@5: 100.0000 (98.8499)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1710/3750]  eta: 0:13:18  Lr: 0.030000  Loss: -2.0142  Acc@1: 75.0000 (80.2491)  Acc@5: 100.0000 (98.8457)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1720/3750]  eta: 0:13:14  Lr: 0.030000  Loss: -1.3019  Acc@1: 81.2500 (80.2440)  Acc@5: 100.0000 (98.8451)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1730/3750]  eta: 0:13:10  Lr: 0.030000  Loss: -1.5902  Acc@1: 81.2500 (80.2499)  Acc@5: 100.0000 (98.8446)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1740/3750]  eta: 0:13:06  Lr: 0.030000  Loss: -1.6142  Acc@1: 81.2500 (80.2700)  Acc@5: 100.0000 (98.8476)  time: 0.3881  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1750/3750]  eta: 0:13:02  Lr: 0.030000  Loss: -2.0515  Acc@1: 81.2500 (80.2577)  Acc@5: 100.0000 (98.8507)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1760/3750]  eta: 0:12:58  Lr: 0.030000  Loss: -1.7125  Acc@1: 81.2500 (80.2562)  Acc@5: 100.0000 (98.8572)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1770/3750]  eta: 0:12:54  Lr: 0.030000  Loss: -1.9355  Acc@1: 81.2500 (80.2936)  Acc@5: 100.0000 (98.8601)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1780/3750]  eta: 0:12:50  Lr: 0.030000  Loss: -2.1029  Acc@1: 87.5000 (80.3200)  Acc@5: 100.0000 (98.8490)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1790/3750]  eta: 0:12:46  Lr: 0.030000  Loss: -2.1369  Acc@1: 81.2500 (80.3183)  Acc@5: 100.0000 (98.8519)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1800/3750]  eta: 0:12:43  Lr: 0.030000  Loss: -1.8998  Acc@1: 81.2500 (80.3130)  Acc@5: 100.0000 (98.8583)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1810/3750]  eta: 0:12:39  Lr: 0.030000  Loss: -1.9025  Acc@1: 81.2500 (80.3078)  Acc@5: 100.0000 (98.8542)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1820/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -1.9241  Acc@1: 81.2500 (80.2856)  Acc@5: 100.0000 (98.8468)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1830/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -2.1609  Acc@1: 75.0000 (80.2840)  Acc@5: 100.0000 (98.8360)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1840/3750]  eta: 0:12:27  Lr: 0.030000  Loss: -2.1743  Acc@1: 81.2500 (80.2926)  Acc@5: 100.0000 (98.8389)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1850/3750]  eta: 0:12:23  Lr: 0.030000  Loss: -1.3520  Acc@1: 81.2500 (80.2776)  Acc@5: 100.0000 (98.8385)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1860/3750]  eta: 0:12:19  Lr: 0.030000  Loss: -1.9088  Acc@1: 75.0000 (80.2626)  Acc@5: 100.0000 (98.8380)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1870/3750]  eta: 0:12:15  Lr: 0.030000  Loss: -1.7352  Acc@1: 81.2500 (80.2746)  Acc@5: 100.0000 (98.8442)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1880/3750]  eta: 0:12:11  Lr: 0.030000  Loss: -1.7031  Acc@1: 81.2500 (80.2532)  Acc@5: 100.0000 (98.8470)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1890/3750]  eta: 0:12:07  Lr: 0.030000  Loss: -1.6823  Acc@1: 75.0000 (80.2221)  Acc@5: 100.0000 (98.8498)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1900/3750]  eta: 0:12:03  Lr: 0.030000  Loss: -2.1063  Acc@1: 81.2500 (80.2341)  Acc@5: 100.0000 (98.8526)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1910/3750]  eta: 0:11:59  Lr: 0.030000  Loss: -1.9410  Acc@1: 81.2500 (80.2525)  Acc@5: 100.0000 (98.8488)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1920/3750]  eta: 0:11:55  Lr: 0.030000  Loss: -1.9844  Acc@1: 81.2500 (80.2577)  Acc@5: 100.0000 (98.8483)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1930/3750]  eta: 0:11:52  Lr: 0.030000  Loss: -2.0584  Acc@1: 81.2500 (80.2725)  Acc@5: 100.0000 (98.8510)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1940/3750]  eta: 0:11:48  Lr: 0.030000  Loss: -1.5867  Acc@1: 81.2500 (80.2679)  Acc@5: 100.0000 (98.8472)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [1950/3750]  eta: 0:11:44  Lr: 0.030000  Loss: -1.8908  Acc@1: 75.0000 (80.2505)  Acc@5: 100.0000 (98.8371)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1960/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -2.3124  Acc@1: 81.2500 (80.2652)  Acc@5: 100.0000 (98.8335)  time: 0.3938  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1970/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -2.3134  Acc@1: 81.2500 (80.2670)  Acc@5: 100.0000 (98.8331)  time: 0.3946  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [1980/3750]  eta: 0:11:32  Lr: 0.030000  Loss: -1.9943  Acc@1: 81.2500 (80.2593)  Acc@5: 100.0000 (98.8358)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [1990/3750]  eta: 0:11:28  Lr: 0.030000  Loss: -1.7336  Acc@1: 75.0000 (80.2266)  Acc@5: 100.0000 (98.8322)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2000/3750]  eta: 0:11:24  Lr: 0.030000  Loss: -2.0077  Acc@1: 81.2500 (80.2318)  Acc@5: 100.0000 (98.8318)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2010/3750]  eta: 0:11:20  Lr: 0.030000  Loss: -1.7898  Acc@1: 81.2500 (80.2430)  Acc@5: 100.0000 (98.8345)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2020/3750]  eta: 0:11:16  Lr: 0.030000  Loss: -1.9585  Acc@1: 81.2500 (80.2233)  Acc@5: 100.0000 (98.8341)  time: 0.3935  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2030/3750]  eta: 0:11:13  Lr: 0.030000  Loss: -1.9663  Acc@1: 75.0000 (80.2222)  Acc@5: 100.0000 (98.8337)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2040/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -1.5042  Acc@1: 81.2500 (80.2088)  Acc@5: 100.0000 (98.8302)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2050/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -2.0240  Acc@1: 81.2500 (80.2353)  Acc@5: 100.0000 (98.8329)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2060/3750]  eta: 0:11:01  Lr: 0.030000  Loss: -1.6902  Acc@1: 81.2500 (80.2432)  Acc@5: 100.0000 (98.8295)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2070/3750]  eta: 0:10:57  Lr: 0.030000  Loss: -1.5450  Acc@1: 81.2500 (80.2782)  Acc@5: 100.0000 (98.8351)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2080/3750]  eta: 0:10:53  Lr: 0.030000  Loss: -2.1434  Acc@1: 87.5000 (80.2799)  Acc@5: 100.0000 (98.8377)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2090/3750]  eta: 0:10:49  Lr: 0.030000  Loss: -1.7040  Acc@1: 81.2500 (80.2846)  Acc@5: 100.0000 (98.8343)  time: 0.3931  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2100/3750]  eta: 0:10:45  Lr: 0.030000  Loss: -1.3700  Acc@1: 81.2500 (80.2832)  Acc@5: 100.0000 (98.8220)  time: 0.3915  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2110/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -2.1092  Acc@1: 81.2500 (80.2819)  Acc@5: 100.0000 (98.8246)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2120/3750]  eta: 0:10:37  Lr: 0.030000  Loss: -1.7554  Acc@1: 81.2500 (80.2923)  Acc@5: 100.0000 (98.8302)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2130/3750]  eta: 0:10:33  Lr: 0.030000  Loss: -1.9670  Acc@1: 87.5000 (80.3173)  Acc@5: 100.0000 (98.8298)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2140/3750]  eta: 0:10:30  Lr: 0.030000  Loss: -1.8657  Acc@1: 81.2500 (80.3042)  Acc@5: 100.0000 (98.8265)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2150/3750]  eta: 0:10:26  Lr: 0.030000  Loss: -1.6333  Acc@1: 75.0000 (80.2940)  Acc@5: 100.0000 (98.8261)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2160/3750]  eta: 0:10:22  Lr: 0.030000  Loss: -2.1039  Acc@1: 81.2500 (80.3043)  Acc@5: 100.0000 (98.8229)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2170/3750]  eta: 0:10:18  Lr: 0.030000  Loss: -1.9638  Acc@1: 81.2500 (80.3000)  Acc@5: 100.0000 (98.8225)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2180/3750]  eta: 0:10:14  Lr: 0.030000  Loss: -1.6075  Acc@1: 81.2500 (80.2900)  Acc@5: 100.0000 (98.8251)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2190/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -1.4907  Acc@1: 81.2500 (80.2830)  Acc@5: 100.0000 (98.8304)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2200/3750]  eta: 0:10:06  Lr: 0.030000  Loss: -1.8796  Acc@1: 75.0000 (80.2789)  Acc@5: 100.0000 (98.8358)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2210/3750]  eta: 0:10:02  Lr: 0.030000  Loss: -1.3764  Acc@1: 75.0000 (80.2606)  Acc@5: 100.0000 (98.8354)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2220/3750]  eta: 0:09:58  Lr: 0.030000  Loss: -1.5924  Acc@1: 81.2500 (80.2763)  Acc@5: 100.0000 (98.8406)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2230/3750]  eta: 0:09:54  Lr: 0.030000  Loss: -1.8086  Acc@1: 75.0000 (80.2611)  Acc@5: 100.0000 (98.8458)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2240/3750]  eta: 0:09:50  Lr: 0.030000  Loss: -1.7295  Acc@1: 75.0000 (80.2460)  Acc@5: 100.0000 (98.8426)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2250/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -1.3746  Acc@1: 75.0000 (80.2449)  Acc@5: 100.0000 (98.8422)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2260/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -1.7769  Acc@1: 81.2500 (80.2715)  Acc@5: 100.0000 (98.8445)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2270/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -2.1072  Acc@1: 87.5000 (80.2895)  Acc@5: 100.0000 (98.8469)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2280/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -1.8590  Acc@1: 81.2500 (80.2636)  Acc@5: 100.0000 (98.8464)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2290/3750]  eta: 0:09:31  Lr: 0.030000  Loss: -1.6153  Acc@1: 75.0000 (80.2488)  Acc@5: 100.0000 (98.8433)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2300/3750]  eta: 0:09:27  Lr: 0.030000  Loss: -2.2291  Acc@1: 81.2500 (80.2504)  Acc@5: 100.0000 (98.8456)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2310/3750]  eta: 0:09:23  Lr: 0.030000  Loss: -1.6143  Acc@1: 81.2500 (80.2521)  Acc@5: 100.0000 (98.8452)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2320/3750]  eta: 0:09:19  Lr: 0.030000  Loss: -1.5839  Acc@1: 81.2500 (80.2483)  Acc@5: 100.0000 (98.8475)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2330/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -1.2524  Acc@1: 81.2500 (80.2499)  Acc@5: 100.0000 (98.8471)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2340/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -1.6863  Acc@1: 81.2500 (80.2568)  Acc@5: 100.0000 (98.8440)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2350/3750]  eta: 0:09:07  Lr: 0.030000  Loss: -2.2020  Acc@1: 81.2500 (80.2770)  Acc@5: 100.0000 (98.8436)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2360/3750]  eta: 0:09:03  Lr: 0.030000  Loss: -1.8007  Acc@1: 81.2500 (80.2705)  Acc@5: 100.0000 (98.8405)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:59  Lr: 0.030000  Loss: -2.2059  Acc@1: 81.2500 (80.2879)  Acc@5: 100.0000 (98.8428)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2380/3750]  eta: 0:08:55  Lr: 0.030000  Loss: -1.8405  Acc@1: 81.2500 (80.2919)  Acc@5: 100.0000 (98.8424)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2390/3750]  eta: 0:08:52  Lr: 0.030000  Loss: -2.0017  Acc@1: 81.2500 (80.2724)  Acc@5: 100.0000 (98.8368)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2400/3750]  eta: 0:08:48  Lr: 0.030000  Loss: -1.6605  Acc@1: 81.2500 (80.2712)  Acc@5: 100.0000 (98.8364)  time: 0.3882  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2410/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -1.8259  Acc@1: 81.2500 (80.2701)  Acc@5: 100.0000 (98.8335)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2420/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -1.7749  Acc@1: 81.2500 (80.2716)  Acc@5: 100.0000 (98.8331)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2430/3750]  eta: 0:08:36  Lr: 0.030000  Loss: -1.9829  Acc@1: 81.2500 (80.2782)  Acc@5: 100.0000 (98.8276)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2440/3750]  eta: 0:08:32  Lr: 0.030000  Loss: -1.6191  Acc@1: 81.2500 (80.2898)  Acc@5: 100.0000 (98.8248)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2450/3750]  eta: 0:08:28  Lr: 0.030000  Loss: -1.8074  Acc@1: 81.2500 (80.3040)  Acc@5: 100.0000 (98.8245)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2460/3750]  eta: 0:08:24  Lr: 0.030000  Loss: -1.5801  Acc@1: 87.5000 (80.3281)  Acc@5: 100.0000 (98.8292)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2470/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -1.7289  Acc@1: 81.2500 (80.3217)  Acc@5: 100.0000 (98.8289)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2480/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -1.8773  Acc@1: 75.0000 (80.3104)  Acc@5: 100.0000 (98.8311)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2490/3750]  eta: 0:08:12  Lr: 0.030000  Loss: -1.6358  Acc@1: 75.0000 (80.3066)  Acc@5: 100.0000 (98.8333)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2500/3750]  eta: 0:08:08  Lr: 0.030000  Loss: -2.0279  Acc@1: 75.0000 (80.2929)  Acc@5: 100.0000 (98.8330)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2510/3750]  eta: 0:08:05  Lr: 0.030000  Loss: -1.5538  Acc@1: 81.2500 (80.3216)  Acc@5: 100.0000 (98.8351)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2520/3750]  eta: 0:08:01  Lr: 0.030000  Loss: -1.5830  Acc@1: 81.2500 (80.3253)  Acc@5: 100.0000 (98.8373)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:57  Lr: 0.030000  Loss: -2.1548  Acc@1: 81.2500 (80.3314)  Acc@5: 100.0000 (98.8419)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:53  Lr: 0.030000  Loss: -1.4541  Acc@1: 81.2500 (80.3325)  Acc@5: 100.0000 (98.8415)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2550/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -1.5280  Acc@1: 81.2500 (80.3435)  Acc@5: 100.0000 (98.8411)  time: 0.3883  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2560/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -1.9077  Acc@1: 81.2500 (80.3324)  Acc@5: 100.0000 (98.8432)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2570/3750]  eta: 0:07:41  Lr: 0.030000  Loss: -1.4971  Acc@1: 81.2500 (80.3433)  Acc@5: 100.0000 (98.8429)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2580/3750]  eta: 0:07:37  Lr: 0.030000  Loss: -1.6113  Acc@1: 75.0000 (80.3250)  Acc@5: 100.0000 (98.8377)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2590/3750]  eta: 0:07:33  Lr: 0.030000  Loss: -2.2080  Acc@1: 81.2500 (80.3454)  Acc@5: 100.0000 (98.8397)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2600/3750]  eta: 0:07:29  Lr: 0.030000  Loss: -2.0896  Acc@1: 81.2500 (80.3441)  Acc@5: 100.0000 (98.8394)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2610/3750]  eta: 0:07:25  Lr: 0.030000  Loss: -1.9278  Acc@1: 81.2500 (80.3380)  Acc@5: 100.0000 (98.8414)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2620/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -1.9928  Acc@1: 81.2500 (80.3319)  Acc@5: 100.0000 (98.8435)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2630/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -2.1644  Acc@1: 81.2500 (80.3473)  Acc@5: 100.0000 (98.8455)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2640/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -1.5273  Acc@1: 81.2500 (80.3531)  Acc@5: 100.0000 (98.8428)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2650/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -2.0916  Acc@1: 87.5000 (80.3659)  Acc@5: 100.0000 (98.8471)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2660/3750]  eta: 0:07:06  Lr: 0.030000  Loss: -1.9183  Acc@1: 81.2500 (80.3669)  Acc@5: 100.0000 (98.8491)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2670/3750]  eta: 0:07:02  Lr: 0.030000  Loss: -1.3538  Acc@1: 81.2500 (80.3561)  Acc@5: 100.0000 (98.8464)  time: 0.3936  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:58  Lr: 0.030000  Loss: -1.7733  Acc@1: 75.0000 (80.3478)  Acc@5: 100.0000 (98.8414)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:54  Lr: 0.030000  Loss: -1.5449  Acc@1: 75.0000 (80.3419)  Acc@5: 100.0000 (98.8410)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -1.5376  Acc@1: 81.2500 (80.3360)  Acc@5: 100.0000 (98.8407)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -1.7538  Acc@1: 81.2500 (80.3532)  Acc@5: 100.0000 (98.8450)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2720/3750]  eta: 0:06:42  Lr: 0.030000  Loss: -1.9065  Acc@1: 87.5000 (80.3565)  Acc@5: 100.0000 (98.8446)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2730/3750]  eta: 0:06:38  Lr: 0.030000  Loss: -2.0999  Acc@1: 75.0000 (80.3529)  Acc@5: 100.0000 (98.8489)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2740/3750]  eta: 0:06:35  Lr: 0.030000  Loss: -1.8735  Acc@1: 75.0000 (80.3106)  Acc@5: 100.0000 (98.8485)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2750/3750]  eta: 0:06:31  Lr: 0.030000  Loss: -2.0886  Acc@1: 75.0000 (80.3003)  Acc@5: 100.0000 (98.8481)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2760/3750]  eta: 0:06:27  Lr: 0.030000  Loss: -1.6635  Acc@1: 75.0000 (80.2993)  Acc@5: 100.0000 (98.8501)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2770/3750]  eta: 0:06:23  Lr: 0.030000  Loss: -2.0452  Acc@1: 81.2500 (80.3027)  Acc@5: 100.0000 (98.8519)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2780/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -2.0516  Acc@1: 81.2500 (80.2949)  Acc@5: 100.0000 (98.8516)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2790/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -1.4848  Acc@1: 81.2500 (80.2916)  Acc@5: 100.0000 (98.8557)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2800/3750]  eta: 0:06:11  Lr: 0.030000  Loss: -2.1550  Acc@1: 81.2500 (80.2794)  Acc@5: 100.0000 (98.8509)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2810/3750]  eta: 0:06:07  Lr: 0.030000  Loss: -1.8335  Acc@1: 81.2500 (80.2962)  Acc@5: 100.0000 (98.8505)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2820/3750]  eta: 0:06:03  Lr: 0.030000  Loss: -1.7091  Acc@1: 81.2500 (80.2951)  Acc@5: 100.0000 (98.8524)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:59  Lr: 0.030000  Loss: -1.7996  Acc@1: 81.2500 (80.2963)  Acc@5: 100.0000 (98.8542)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:55  Lr: 0.030000  Loss: -1.7490  Acc@1: 81.2500 (80.2842)  Acc@5: 100.0000 (98.8560)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:52  Lr: 0.030000  Loss: -2.0618  Acc@1: 75.0000 (80.2854)  Acc@5: 100.0000 (98.8579)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -1.9658  Acc@1: 75.0000 (80.2648)  Acc@5: 100.0000 (98.8597)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -2.1468  Acc@1: 75.0000 (80.2573)  Acc@5: 100.0000 (98.8593)  time: 0.3939  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:40  Lr: 0.030000  Loss: -1.6871  Acc@1: 81.2500 (80.2629)  Acc@5: 100.0000 (98.8589)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2890/3750]  eta: 0:05:36  Lr: 0.030000  Loss: -1.8182  Acc@1: 81.2500 (80.2512)  Acc@5: 100.0000 (98.8542)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2900/3750]  eta: 0:05:32  Lr: 0.030000  Loss: -1.8595  Acc@1: 81.2500 (80.2590)  Acc@5: 100.0000 (98.8582)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2910/3750]  eta: 0:05:28  Lr: 0.030000  Loss: -2.0963  Acc@1: 81.2500 (80.2581)  Acc@5: 100.0000 (98.8599)  time: 0.3940  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2920/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -1.6678  Acc@1: 81.2500 (80.2572)  Acc@5: 100.0000 (98.8553)  time: 0.3950  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2930/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -1.8860  Acc@1: 75.0000 (80.2414)  Acc@5: 100.0000 (98.8549)  time: 0.3951  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2940/3750]  eta: 0:05:16  Lr: 0.030000  Loss: -1.8896  Acc@1: 75.0000 (80.2384)  Acc@5: 100.0000 (98.8546)  time: 0.3961  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2950/3750]  eta: 0:05:12  Lr: 0.030000  Loss: -1.4713  Acc@1: 81.2500 (80.2355)  Acc@5: 100.0000 (98.8563)  time: 0.3938  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2960/3750]  eta: 0:05:09  Lr: 0.030000  Loss: -1.7235  Acc@1: 81.2500 (80.2368)  Acc@5: 100.0000 (98.8581)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [2970/3750]  eta: 0:05:05  Lr: 0.030000  Loss: -1.8481  Acc@1: 81.2500 (80.2360)  Acc@5: 100.0000 (98.8535)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2980/3750]  eta: 0:05:01  Lr: 0.030000  Loss: -1.9944  Acc@1: 81.2500 (80.2541)  Acc@5: 100.0000 (98.8552)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:57  Lr: 0.030000  Loss: -1.4343  Acc@1: 87.5000 (80.2553)  Acc@5: 100.0000 (98.8549)  time: 0.3936  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -1.9427  Acc@1: 81.2500 (80.2566)  Acc@5: 100.0000 (98.8545)  time: 0.3979  data: 0.0006  max mem: 2912
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -1.9642  Acc@1: 81.2500 (80.2433)  Acc@5: 100.0000 (98.8542)  time: 0.3963  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:45  Lr: 0.030000  Loss: -1.7697  Acc@1: 75.0000 (80.2363)  Acc@5: 100.0000 (98.8559)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:41  Lr: 0.030000  Loss: -1.6532  Acc@1: 81.2500 (80.2520)  Acc@5: 100.0000 (98.8515)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:37  Lr: 0.030000  Loss: -1.9933  Acc@1: 81.2500 (80.2655)  Acc@5: 100.0000 (98.8532)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:33  Lr: 0.030000  Loss: -2.0633  Acc@1: 81.2500 (80.2708)  Acc@5: 100.0000 (98.8508)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:29  Lr: 0.030000  Loss: -2.0772  Acc@1: 81.2500 (80.2720)  Acc@5: 100.0000 (98.8545)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3070/3750]  eta: 0:04:26  Lr: 0.030000  Loss: -1.5929  Acc@1: 81.2500 (80.2772)  Acc@5: 100.0000 (98.8542)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3080/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -1.4464  Acc@1: 81.2500 (80.2661)  Acc@5: 100.0000 (98.8539)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3090/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -1.6922  Acc@1: 81.2500 (80.2875)  Acc@5: 100.0000 (98.8576)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -2.0413  Acc@1: 87.5000 (80.2987)  Acc@5: 100.0000 (98.8572)  time: 0.3880  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3110/3750]  eta: 0:04:10  Lr: 0.030000  Loss: -0.8912  Acc@1: 87.5000 (80.3198)  Acc@5: 100.0000 (98.8589)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3120/3750]  eta: 0:04:06  Lr: 0.030000  Loss: -1.6969  Acc@1: 87.5000 (80.3208)  Acc@5: 100.0000 (98.8585)  time: 0.3878  data: 0.0002  max mem: 2912
Train: Epoch[4/5]  [3130/3750]  eta: 0:04:02  Lr: 0.030000  Loss: -2.2123  Acc@1: 87.5000 (80.3417)  Acc@5: 100.0000 (98.8582)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:58  Lr: 0.030000  Loss: -2.0947  Acc@1: 81.2500 (80.3387)  Acc@5: 100.0000 (98.8559)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -1.5490  Acc@1: 81.2500 (80.3515)  Acc@5: 100.0000 (98.8535)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:50  Lr: 0.030000  Loss: -2.0387  Acc@1: 87.5000 (80.3642)  Acc@5: 100.0000 (98.8552)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:46  Lr: 0.030000  Loss: -1.5865  Acc@1: 81.2500 (80.3532)  Acc@5: 100.0000 (98.8529)  time: 0.3913  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:43  Lr: 0.030000  Loss: -1.5096  Acc@1: 75.0000 (80.3364)  Acc@5: 100.0000 (98.8545)  time: 0.3904  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -2.2367  Acc@1: 75.0000 (80.3608)  Acc@5: 100.0000 (98.8581)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -1.9110  Acc@1: 81.2500 (80.3597)  Acc@5: 100.0000 (98.8558)  time: 0.3946  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -2.0780  Acc@1: 81.2500 (80.3683)  Acc@5: 100.0000 (98.8536)  time: 0.3943  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -1.9751  Acc@1: 81.2500 (80.3632)  Acc@5: 100.0000 (98.8571)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -1.8191  Acc@1: 81.2500 (80.3737)  Acc@5: 100.0000 (98.8529)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3240/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -1.8712  Acc@1: 81.2500 (80.3668)  Acc@5: 100.0000 (98.8526)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3250/3750]  eta: 0:03:15  Lr: 0.030000  Loss: -1.6210  Acc@1: 81.2500 (80.3753)  Acc@5: 100.0000 (98.8542)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3260/3750]  eta: 0:03:11  Lr: 0.030000  Loss: -1.8778  Acc@1: 81.2500 (80.3914)  Acc@5: 100.0000 (98.8539)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3270/3750]  eta: 0:03:07  Lr: 0.030000  Loss: -1.9403  Acc@1: 81.2500 (80.3921)  Acc@5: 100.0000 (98.8517)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3280/3750]  eta: 0:03:03  Lr: 0.030000  Loss: -2.1191  Acc@1: 81.2500 (80.3928)  Acc@5: 100.0000 (98.8532)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -1.8932  Acc@1: 81.2500 (80.4011)  Acc@5: 100.0000 (98.8567)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -1.7230  Acc@1: 81.2500 (80.3828)  Acc@5: 100.0000 (98.8545)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -1.8332  Acc@1: 75.0000 (80.3836)  Acc@5: 100.0000 (98.8542)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -1.5888  Acc@1: 81.2500 (80.3862)  Acc@5: 100.0000 (98.8558)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -1.1911  Acc@1: 81.2500 (80.4000)  Acc@5: 100.0000 (98.8592)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -2.0518  Acc@1: 81.2500 (80.4026)  Acc@5: 100.0000 (98.8589)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -2.0476  Acc@1: 81.2500 (80.4200)  Acc@5: 100.0000 (98.8567)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:32  Lr: 0.030000  Loss: -2.1601  Acc@1: 81.2500 (80.4225)  Acc@5: 100.0000 (98.8545)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -1.9427  Acc@1: 81.2500 (80.4379)  Acc@5: 100.0000 (98.8561)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -1.8613  Acc@1: 81.2500 (80.4366)  Acc@5: 100.0000 (98.8576)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:20  Lr: 0.030000  Loss: -1.9418  Acc@1: 81.2500 (80.4519)  Acc@5: 100.0000 (98.8591)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:16  Lr: 0.030000  Loss: -2.0294  Acc@1: 87.5000 (80.4616)  Acc@5: 100.0000 (98.8625)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -2.1458  Acc@1: 81.2500 (80.4566)  Acc@5: 100.0000 (98.8640)  time: 0.3928  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -1.9500  Acc@1: 87.5000 (80.4717)  Acc@5: 100.0000 (98.8655)  time: 0.3928  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -1.8345  Acc@1: 87.5000 (80.4867)  Acc@5: 100.0000 (98.8651)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -1.7976  Acc@1: 81.2500 (80.4871)  Acc@5: 100.0000 (98.8612)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -1.8848  Acc@1: 81.2500 (80.4785)  Acc@5: 100.0000 (98.8608)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -2.0842  Acc@1: 81.2500 (80.4952)  Acc@5: 100.0000 (98.8641)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -1.8581  Acc@1: 81.2500 (80.4955)  Acc@5: 100.0000 (98.8638)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -2.1705  Acc@1: 81.2500 (80.5067)  Acc@5: 100.0000 (98.8653)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:41  Lr: 0.030000  Loss: -2.0194  Acc@1: 87.5000 (80.5196)  Acc@5: 100.0000 (98.8631)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:37  Lr: 0.030000  Loss: -1.6049  Acc@1: 81.2500 (80.5216)  Acc@5: 100.0000 (98.8646)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -2.0211  Acc@1: 81.2500 (80.5148)  Acc@5: 100.0000 (98.8661)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -1.5110  Acc@1: 81.2500 (80.5187)  Acc@5: 100.0000 (98.8693)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -2.1379  Acc@1: 81.2500 (80.5261)  Acc@5: 100.0000 (98.8707)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -1.7840  Acc@1: 81.2500 (80.5281)  Acc@5: 100.0000 (98.8668)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -2.2250  Acc@1: 81.2500 (80.5407)  Acc@5: 100.0000 (98.8700)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -1.4986  Acc@1: 81.2500 (80.5480)  Acc@5: 100.0000 (98.8732)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -1.7909  Acc@1: 81.2500 (80.5587)  Acc@5: 100.0000 (98.8676)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -1.3993  Acc@1: 81.2500 (80.5519)  Acc@5: 100.0000 (98.8673)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -2.1728  Acc@1: 81.2500 (80.5643)  Acc@5: 100.0000 (98.8652)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -2.0819  Acc@1: 87.5000 (80.5800)  Acc@5: 100.0000 (98.8666)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -1.6671  Acc@1: 87.5000 (80.5871)  Acc@5: 100.0000 (98.8680)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:50  Lr: 0.030000  Loss: -2.1761  Acc@1: 81.2500 (80.5837)  Acc@5: 100.0000 (98.8712)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:46  Lr: 0.030000  Loss: -1.8266  Acc@1: 81.2500 (80.5770)  Acc@5: 100.0000 (98.8726)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -1.7670  Acc@1: 81.2500 (80.5805)  Acc@5: 100.0000 (98.8757)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -1.4432  Acc@1: 81.2500 (80.5772)  Acc@5: 100.0000 (98.8770)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -1.9489  Acc@1: 81.2500 (80.5637)  Acc@5: 100.0000 (98.8784)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -1.4444  Acc@1: 75.0000 (80.5690)  Acc@5: 100.0000 (98.8797)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -1.9742  Acc@1: 81.2500 (80.5691)  Acc@5: 100.0000 (98.8777)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -1.9139  Acc@1: 81.2500 (80.5659)  Acc@5: 100.0000 (98.8773)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -1.7890  Acc@1: 81.2500 (80.5678)  Acc@5: 100.0000 (98.8736)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -2.2279  Acc@1: 87.5000 (80.5763)  Acc@5: 100.0000 (98.8750)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -1.9057  Acc@1: 81.2500 (80.5815)  Acc@5: 100.0000 (98.8746)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -1.9009  Acc@1: 81.2500 (80.5732)  Acc@5: 100.0000 (98.8743)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -1.2027  Acc@1: 81.2500 (80.5767)  Acc@5: 100.0000 (98.8773)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -2.0157  Acc@1: 81.2500 (80.5833)  Acc@5: 100.0000 (98.8750)  time: 0.3907  data: 0.0010  max mem: 2912
Train: Epoch[4/5] Total time: 0:24:27 (0.3914 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}}
Averaged stats: Lr: 0.030000  Loss: -2.0157  Acc@1: 81.2500 (80.5833)  Acc@5: 100.0000 (98.8750)
Train: Epoch[5/5]  [   0/3750]  eta: 0:49:58  Lr: 0.030000  Loss: -1.8877  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7996  data: 0.4075  max mem: 2912
Train: Epoch[5/5]  [  10/3750]  eta: 0:26:50  Lr: 0.030000  Loss: -1.8467  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (99.4318)  time: 0.4306  data: 0.0374  max mem: 2912
Train: Epoch[5/5]  [  20/3750]  eta: 0:25:30  Lr: 0.030000  Loss: -1.9299  Acc@1: 81.2500 (84.2262)  Acc@5: 100.0000 (99.4048)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  30/3750]  eta: 0:24:59  Lr: 0.030000  Loss: -2.1913  Acc@1: 81.2500 (83.2661)  Acc@5: 100.0000 (99.3952)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  40/3750]  eta: 0:24:41  Lr: 0.030000  Loss: -1.1255  Acc@1: 87.5000 (82.9268)  Acc@5: 100.0000 (99.0854)  time: 0.3878  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  50/3750]  eta: 0:24:29  Lr: 0.030000  Loss: -1.8403  Acc@1: 81.2500 (82.5980)  Acc@5: 100.0000 (98.8971)  time: 0.3880  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  60/3750]  eta: 0:24:19  Lr: 0.030000  Loss: -2.0458  Acc@1: 81.2500 (82.8893)  Acc@5: 100.0000 (98.9754)  time: 0.3881  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  70/3750]  eta: 0:24:12  Lr: 0.030000  Loss: -2.2766  Acc@1: 87.5000 (83.0106)  Acc@5: 100.0000 (99.0317)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  80/3750]  eta: 0:24:04  Lr: 0.030000  Loss: -1.6244  Acc@1: 81.2500 (82.7932)  Acc@5: 100.0000 (98.9198)  time: 0.3878  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [  90/3750]  eta: 0:23:58  Lr: 0.030000  Loss: -1.8489  Acc@1: 81.2500 (82.2802)  Acc@5: 100.0000 (98.8324)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 100/3750]  eta: 0:23:54  Lr: 0.030000  Loss: -2.3390  Acc@1: 81.2500 (82.1782)  Acc@5: 100.0000 (98.7624)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 110/3750]  eta: 0:23:50  Lr: 0.030000  Loss: -1.9582  Acc@1: 81.2500 (81.5878)  Acc@5: 100.0000 (98.6486)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 120/3750]  eta: 0:23:46  Lr: 0.030000  Loss: -1.7970  Acc@1: 81.2500 (81.6116)  Acc@5: 100.0000 (98.6570)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 130/3750]  eta: 0:23:41  Lr: 0.030000  Loss: -1.8729  Acc@1: 75.0000 (81.1546)  Acc@5: 100.0000 (98.7595)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 140/3750]  eta: 0:23:37  Lr: 0.030000  Loss: -1.7724  Acc@1: 75.0000 (81.1170)  Acc@5: 100.0000 (98.8032)  time: 0.3911  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 150/3750]  eta: 0:23:32  Lr: 0.030000  Loss: -2.1207  Acc@1: 81.2500 (81.0430)  Acc@5: 100.0000 (98.8411)  time: 0.3898  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 160/3750]  eta: 0:23:28  Lr: 0.030000  Loss: -1.7930  Acc@1: 81.2500 (80.5901)  Acc@5: 100.0000 (98.9130)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 170/3750]  eta: 0:23:24  Lr: 0.030000  Loss: -2.1420  Acc@1: 75.0000 (80.5921)  Acc@5: 100.0000 (98.9401)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 180/3750]  eta: 0:23:20  Lr: 0.030000  Loss: -2.0198  Acc@1: 75.0000 (80.5594)  Acc@5: 100.0000 (98.9296)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 190/3750]  eta: 0:23:16  Lr: 0.030000  Loss: -1.6628  Acc@1: 75.0000 (80.4647)  Acc@5: 100.0000 (98.9529)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 200/3750]  eta: 0:23:12  Lr: 0.030000  Loss: -1.5881  Acc@1: 75.0000 (80.3794)  Acc@5: 100.0000 (98.9428)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 210/3750]  eta: 0:23:09  Lr: 0.030000  Loss: -1.2633  Acc@1: 81.2500 (80.2725)  Acc@5: 100.0000 (98.9040)  time: 0.3939  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 220/3750]  eta: 0:23:05  Lr: 0.030000  Loss: -1.8753  Acc@1: 81.2500 (80.4299)  Acc@5: 100.0000 (98.9536)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 230/3750]  eta: 0:23:01  Lr: 0.030000  Loss: -1.9705  Acc@1: 81.2500 (80.4654)  Acc@5: 100.0000 (98.9177)  time: 0.3943  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 240/3750]  eta: 0:22:59  Lr: 0.030000  Loss: -1.8852  Acc@1: 81.2500 (80.6017)  Acc@5: 100.0000 (98.9108)  time: 0.3977  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 250/3750]  eta: 0:22:54  Lr: 0.030000  Loss: -1.9973  Acc@1: 87.5000 (80.8267)  Acc@5: 100.0000 (98.8546)  time: 0.3952  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 260/3750]  eta: 0:22:50  Lr: 0.030000  Loss: -1.9126  Acc@1: 87.5000 (81.0105)  Acc@5: 100.0000 (98.8745)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 270/3750]  eta: 0:22:46  Lr: 0.030000  Loss: -1.4006  Acc@1: 81.2500 (80.9271)  Acc@5: 100.0000 (98.8007)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 280/3750]  eta: 0:22:42  Lr: 0.030000  Loss: -2.0838  Acc@1: 81.2500 (81.0721)  Acc@5: 100.0000 (98.8212)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 290/3750]  eta: 0:22:37  Lr: 0.030000  Loss: -1.9122  Acc@1: 87.5000 (81.0567)  Acc@5: 100.0000 (98.8187)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 300/3750]  eta: 0:22:34  Lr: 0.030000  Loss: -1.6694  Acc@1: 81.2500 (81.2085)  Acc@5: 100.0000 (98.7957)  time: 0.3917  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [ 310/3750]  eta: 0:22:29  Lr: 0.030000  Loss: -2.0886  Acc@1: 81.2500 (81.1495)  Acc@5: 100.0000 (98.7942)  time: 0.3910  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [ 320/3750]  eta: 0:22:25  Lr: 0.030000  Loss: -1.6097  Acc@1: 81.2500 (81.0942)  Acc@5: 100.0000 (98.7928)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 330/3750]  eta: 0:22:21  Lr: 0.030000  Loss: -2.0607  Acc@1: 81.2500 (81.1556)  Acc@5: 100.0000 (98.7915)  time: 0.3886  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 340/3750]  eta: 0:22:16  Lr: 0.030000  Loss: -2.1555  Acc@1: 81.2500 (81.1584)  Acc@5: 100.0000 (98.7903)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 350/3750]  eta: 0:22:12  Lr: 0.030000  Loss: -1.3275  Acc@1: 81.2500 (81.0897)  Acc@5: 100.0000 (98.7714)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 360/3750]  eta: 0:22:08  Lr: 0.030000  Loss: -1.8578  Acc@1: 81.2500 (81.1634)  Acc@5: 100.0000 (98.7881)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 370/3750]  eta: 0:22:05  Lr: 0.030000  Loss: -1.9935  Acc@1: 81.2500 (81.2332)  Acc@5: 100.0000 (98.7702)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 380/3750]  eta: 0:22:01  Lr: 0.030000  Loss: -1.8702  Acc@1: 81.2500 (81.2828)  Acc@5: 100.0000 (98.7861)  time: 0.3933  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 390/3750]  eta: 0:21:57  Lr: 0.030000  Loss: -2.1205  Acc@1: 81.2500 (81.2820)  Acc@5: 100.0000 (98.7372)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 400/3750]  eta: 0:21:53  Lr: 0.030000  Loss: -1.5782  Acc@1: 81.2500 (81.2968)  Acc@5: 100.0000 (98.7375)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 410/3750]  eta: 0:21:49  Lr: 0.030000  Loss: -1.7747  Acc@1: 81.2500 (81.2652)  Acc@5: 100.0000 (98.7378)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 420/3750]  eta: 0:21:45  Lr: 0.030000  Loss: -2.2972  Acc@1: 75.0000 (81.1015)  Acc@5: 100.0000 (98.7530)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 430/3750]  eta: 0:21:41  Lr: 0.030000  Loss: -1.9738  Acc@1: 81.2500 (81.2210)  Acc@5: 100.0000 (98.7674)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 440/3750]  eta: 0:21:37  Lr: 0.030000  Loss: -2.0657  Acc@1: 87.5000 (81.2358)  Acc@5: 100.0000 (98.7812)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 450/3750]  eta: 0:21:33  Lr: 0.030000  Loss: -1.5536  Acc@1: 81.2500 (81.1669)  Acc@5: 100.0000 (98.7943)  time: 0.3920  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 460/3750]  eta: 0:21:29  Lr: 0.030000  Loss: -2.1981  Acc@1: 81.2500 (81.1144)  Acc@5: 100.0000 (98.7663)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 470/3750]  eta: 0:21:25  Lr: 0.030000  Loss: -2.0854  Acc@1: 75.0000 (81.0244)  Acc@5: 100.0000 (98.7659)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 480/3750]  eta: 0:21:21  Lr: 0.030000  Loss: -1.8801  Acc@1: 81.2500 (81.0551)  Acc@5: 100.0000 (98.7656)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 490/3750]  eta: 0:21:17  Lr: 0.030000  Loss: -1.6368  Acc@1: 81.2500 (81.0209)  Acc@5: 100.0000 (98.7907)  time: 0.3919  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 500/3750]  eta: 0:21:13  Lr: 0.030000  Loss: -1.3787  Acc@1: 81.2500 (81.1128)  Acc@5: 100.0000 (98.8149)  time: 0.3920  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 510/3750]  eta: 0:21:09  Lr: 0.030000  Loss: -1.1648  Acc@1: 81.2500 (81.0665)  Acc@5: 100.0000 (98.8136)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 520/3750]  eta: 0:21:05  Lr: 0.030000  Loss: -1.3431  Acc@1: 81.2500 (81.1060)  Acc@5: 100.0000 (98.8244)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 530/3750]  eta: 0:21:01  Lr: 0.030000  Loss: -2.1089  Acc@1: 81.2500 (81.1323)  Acc@5: 100.0000 (98.8465)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 540/3750]  eta: 0:20:57  Lr: 0.030000  Loss: -2.1664  Acc@1: 81.2500 (81.1229)  Acc@5: 100.0000 (98.8678)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 550/3750]  eta: 0:20:53  Lr: 0.030000  Loss: -1.6744  Acc@1: 81.2500 (81.1593)  Acc@5: 100.0000 (98.8770)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 560/3750]  eta: 0:20:49  Lr: 0.030000  Loss: -1.7791  Acc@1: 81.2500 (81.0829)  Acc@5: 100.0000 (98.8414)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 570/3750]  eta: 0:20:45  Lr: 0.030000  Loss: -2.1671  Acc@1: 81.2500 (81.1296)  Acc@5: 100.0000 (98.7960)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 580/3750]  eta: 0:20:41  Lr: 0.030000  Loss: -2.0361  Acc@1: 87.5000 (81.1962)  Acc@5: 100.0000 (98.7844)  time: 0.3923  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 590/3750]  eta: 0:20:38  Lr: 0.030000  Loss: -2.1869  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (98.8050)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 600/3750]  eta: 0:20:34  Lr: 0.030000  Loss: -2.1140  Acc@1: 87.5000 (81.2812)  Acc@5: 100.0000 (98.7833)  time: 0.3946  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 610/3750]  eta: 0:20:30  Lr: 0.030000  Loss: -2.1777  Acc@1: 87.5000 (81.3421)  Acc@5: 100.0000 (98.8032)  time: 0.3944  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 620/3750]  eta: 0:20:26  Lr: 0.030000  Loss: -1.9003  Acc@1: 87.5000 (81.3808)  Acc@5: 100.0000 (98.7923)  time: 0.3949  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 630/3750]  eta: 0:20:23  Lr: 0.030000  Loss: -1.9215  Acc@1: 81.2500 (81.3590)  Acc@5: 100.0000 (98.7619)  time: 0.3946  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 640/3750]  eta: 0:20:19  Lr: 0.030000  Loss: -1.5066  Acc@1: 75.0000 (81.3085)  Acc@5: 100.0000 (98.7715)  time: 0.3946  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 650/3750]  eta: 0:20:15  Lr: 0.030000  Loss: -1.6369  Acc@1: 81.2500 (81.3556)  Acc@5: 100.0000 (98.7903)  time: 0.3940  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 660/3750]  eta: 0:20:11  Lr: 0.030000  Loss: -1.2015  Acc@1: 81.2500 (81.3446)  Acc@5: 100.0000 (98.7897)  time: 0.3928  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 670/3750]  eta: 0:20:07  Lr: 0.030000  Loss: -2.1402  Acc@1: 81.2500 (81.3525)  Acc@5: 100.0000 (98.7984)  time: 0.3935  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 680/3750]  eta: 0:20:03  Lr: 0.030000  Loss: -1.8691  Acc@1: 81.2500 (81.3785)  Acc@5: 100.0000 (98.7794)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 690/3750]  eta: 0:19:59  Lr: 0.030000  Loss: -2.1017  Acc@1: 81.2500 (81.4038)  Acc@5: 100.0000 (98.7789)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 700/3750]  eta: 0:19:55  Lr: 0.030000  Loss: -1.9361  Acc@1: 81.2500 (81.4105)  Acc@5: 100.0000 (98.7696)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 710/3750]  eta: 0:19:51  Lr: 0.030000  Loss: -2.1501  Acc@1: 87.5000 (81.4961)  Acc@5: 100.0000 (98.7693)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 720/3750]  eta: 0:19:47  Lr: 0.030000  Loss: -1.8851  Acc@1: 87.5000 (81.4580)  Acc@5: 100.0000 (98.7691)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 730/3750]  eta: 0:19:43  Lr: 0.030000  Loss: -1.4572  Acc@1: 81.2500 (81.4210)  Acc@5: 100.0000 (98.7688)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 740/3750]  eta: 0:19:40  Lr: 0.030000  Loss: -2.2017  Acc@1: 81.2500 (81.4862)  Acc@5: 100.0000 (98.7686)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 750/3750]  eta: 0:19:36  Lr: 0.030000  Loss: -1.9659  Acc@1: 81.2500 (81.4747)  Acc@5: 100.0000 (98.7683)  time: 0.3922  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 760/3750]  eta: 0:19:32  Lr: 0.030000  Loss: -1.2061  Acc@1: 81.2500 (81.4225)  Acc@5: 100.0000 (98.7516)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 770/3750]  eta: 0:19:28  Lr: 0.030000  Loss: -1.4038  Acc@1: 81.2500 (81.4040)  Acc@5: 100.0000 (98.7354)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 780/3750]  eta: 0:19:24  Lr: 0.030000  Loss: -2.1185  Acc@1: 87.5000 (81.4741)  Acc@5: 100.0000 (98.7516)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 790/3750]  eta: 0:19:19  Lr: 0.030000  Loss: -1.1798  Acc@1: 87.5000 (81.4791)  Acc@5: 100.0000 (98.7437)  time: 0.3884  data: 0.0002  max mem: 2912
Train: Epoch[5/5]  [ 800/3750]  eta: 0:19:15  Lr: 0.030000  Loss: -1.9972  Acc@1: 87.5000 (81.4919)  Acc@5: 100.0000 (98.7360)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 810/3750]  eta: 0:19:11  Lr: 0.030000  Loss: -1.8499  Acc@1: 87.5000 (81.4581)  Acc@5: 100.0000 (98.7284)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 820/3750]  eta: 0:19:07  Lr: 0.030000  Loss: -1.9986  Acc@1: 81.2500 (81.4327)  Acc@5: 100.0000 (98.7363)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 830/3750]  eta: 0:19:03  Lr: 0.030000  Loss: -1.5595  Acc@1: 75.0000 (81.3703)  Acc@5: 100.0000 (98.7365)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [ 840/3750]  eta: 0:18:59  Lr: 0.030000  Loss: -1.5750  Acc@1: 75.0000 (81.3392)  Acc@5: 100.0000 (98.7441)  time: 0.3894  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 850/3750]  eta: 0:18:55  Lr: 0.030000  Loss: -1.8406  Acc@1: 81.2500 (81.3822)  Acc@5: 100.0000 (98.7441)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 860/3750]  eta: 0:18:52  Lr: 0.030000  Loss: -1.8285  Acc@1: 81.2500 (81.3661)  Acc@5: 100.0000 (98.7224)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 870/3750]  eta: 0:18:48  Lr: 0.030000  Loss: -2.0048  Acc@1: 81.2500 (81.3505)  Acc@5: 100.0000 (98.7371)  time: 0.3909  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [ 880/3750]  eta: 0:18:44  Lr: 0.030000  Loss: -1.9342  Acc@1: 81.2500 (81.3209)  Acc@5: 100.0000 (98.7372)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 890/3750]  eta: 0:18:40  Lr: 0.030000  Loss: -1.9908  Acc@1: 75.0000 (81.2710)  Acc@5: 100.0000 (98.7374)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 900/3750]  eta: 0:18:36  Lr: 0.030000  Loss: -2.1572  Acc@1: 75.0000 (81.2639)  Acc@5: 100.0000 (98.7306)  time: 0.3908  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 910/3750]  eta: 0:18:32  Lr: 0.030000  Loss: -1.9310  Acc@1: 81.2500 (81.2774)  Acc@5: 100.0000 (98.7377)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 920/3750]  eta: 0:18:28  Lr: 0.030000  Loss: -2.0560  Acc@1: 81.2500 (81.2432)  Acc@5: 100.0000 (98.7446)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 930/3750]  eta: 0:18:24  Lr: 0.030000  Loss: -1.9413  Acc@1: 81.2500 (81.2097)  Acc@5: 100.0000 (98.7513)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 940/3750]  eta: 0:18:20  Lr: 0.030000  Loss: -1.7495  Acc@1: 81.2500 (81.2168)  Acc@5: 100.0000 (98.7513)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 950/3750]  eta: 0:18:16  Lr: 0.030000  Loss: -2.1973  Acc@1: 81.2500 (81.2171)  Acc@5: 100.0000 (98.7513)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 960/3750]  eta: 0:18:13  Lr: 0.030000  Loss: -2.0450  Acc@1: 81.2500 (81.2435)  Acc@5: 100.0000 (98.7513)  time: 0.3938  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [ 970/3750]  eta: 0:18:09  Lr: 0.030000  Loss: -1.5035  Acc@1: 81.2500 (81.1985)  Acc@5: 100.0000 (98.7513)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 980/3750]  eta: 0:18:05  Lr: 0.030000  Loss: -2.1412  Acc@1: 75.0000 (81.1735)  Acc@5: 100.0000 (98.7576)  time: 0.3931  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [ 990/3750]  eta: 0:18:01  Lr: 0.030000  Loss: -1.9363  Acc@1: 81.2500 (81.1428)  Acc@5: 100.0000 (98.7513)  time: 0.3952  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [1000/3750]  eta: 0:17:57  Lr: 0.030000  Loss: -1.9233  Acc@1: 75.0000 (81.0939)  Acc@5: 100.0000 (98.7575)  time: 0.3939  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [1010/3750]  eta: 0:17:53  Lr: 0.030000  Loss: -1.6779  Acc@1: 75.0000 (81.0336)  Acc@5: 100.0000 (98.7389)  time: 0.3910  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1020/3750]  eta: 0:17:49  Lr: 0.030000  Loss: -2.0713  Acc@1: 75.0000 (81.0296)  Acc@5: 100.0000 (98.7451)  time: 0.3918  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1030/3750]  eta: 0:17:45  Lr: 0.030000  Loss: -1.5016  Acc@1: 81.2500 (80.9954)  Acc@5: 100.0000 (98.7512)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1040/3750]  eta: 0:17:41  Lr: 0.030000  Loss: -2.1923  Acc@1: 81.2500 (81.0219)  Acc@5: 100.0000 (98.7572)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1050/3750]  eta: 0:17:37  Lr: 0.030000  Loss: -2.2602  Acc@1: 87.5000 (81.0657)  Acc@5: 100.0000 (98.7631)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1060/3750]  eta: 0:17:33  Lr: 0.030000  Loss: -1.8017  Acc@1: 81.2500 (81.0203)  Acc@5: 100.0000 (98.7571)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1070/3750]  eta: 0:17:29  Lr: 0.030000  Loss: -1.9999  Acc@1: 75.0000 (80.9991)  Acc@5: 100.0000 (98.7512)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1080/3750]  eta: 0:17:25  Lr: 0.030000  Loss: -1.5186  Acc@1: 81.2500 (81.0130)  Acc@5: 100.0000 (98.7512)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1090/3750]  eta: 0:17:22  Lr: 0.030000  Loss: -1.2076  Acc@1: 81.2500 (80.9578)  Acc@5: 100.0000 (98.7569)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1100/3750]  eta: 0:17:18  Lr: 0.030000  Loss: -2.0606  Acc@1: 75.0000 (80.9491)  Acc@5: 100.0000 (98.7568)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1110/3750]  eta: 0:17:14  Lr: 0.030000  Loss: -1.8278  Acc@1: 81.2500 (80.9293)  Acc@5: 100.0000 (98.7455)  time: 0.3934  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1120/3750]  eta: 0:17:10  Lr: 0.030000  Loss: -1.1441  Acc@1: 81.2500 (80.8709)  Acc@5: 100.0000 (98.7511)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1130/3750]  eta: 0:17:06  Lr: 0.030000  Loss: -1.6808  Acc@1: 75.0000 (80.8963)  Acc@5: 100.0000 (98.7622)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1140/3750]  eta: 0:17:02  Lr: 0.030000  Loss: -1.6810  Acc@1: 81.2500 (80.9104)  Acc@5: 100.0000 (98.7675)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1150/3750]  eta: 0:16:58  Lr: 0.030000  Loss: -2.1852  Acc@1: 87.5000 (80.9242)  Acc@5: 100.0000 (98.7674)  time: 0.3926  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1160/3750]  eta: 0:16:54  Lr: 0.030000  Loss: -1.4441  Acc@1: 81.2500 (80.9162)  Acc@5: 100.0000 (98.7672)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1170/3750]  eta: 0:16:50  Lr: 0.030000  Loss: -1.9960  Acc@1: 81.2500 (80.9244)  Acc@5: 100.0000 (98.7724)  time: 0.3916  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1180/3750]  eta: 0:16:46  Lr: 0.030000  Loss: -1.7576  Acc@1: 81.2500 (80.9060)  Acc@5: 100.0000 (98.7775)  time: 0.3909  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1190/3750]  eta: 0:16:42  Lr: 0.030000  Loss: -2.0225  Acc@1: 81.2500 (80.9299)  Acc@5: 100.0000 (98.7825)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1200/3750]  eta: 0:16:39  Lr: 0.030000  Loss: -2.1020  Acc@1: 87.5000 (80.9430)  Acc@5: 100.0000 (98.7823)  time: 0.3923  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1210/3750]  eta: 0:16:35  Lr: 0.030000  Loss: -1.4546  Acc@1: 81.2500 (80.9507)  Acc@5: 100.0000 (98.7768)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1220/3750]  eta: 0:16:31  Lr: 0.030000  Loss: -1.9603  Acc@1: 81.2500 (80.9429)  Acc@5: 100.0000 (98.7766)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1230/3750]  eta: 0:16:27  Lr: 0.030000  Loss: -1.4191  Acc@1: 81.2500 (80.9606)  Acc@5: 100.0000 (98.7764)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1240/3750]  eta: 0:16:23  Lr: 0.030000  Loss: -1.9750  Acc@1: 81.2500 (80.9680)  Acc@5: 100.0000 (98.7762)  time: 0.3894  data: 0.0002  max mem: 2912
Train: Epoch[5/5]  [1250/3750]  eta: 0:16:19  Lr: 0.030000  Loss: -1.9931  Acc@1: 81.2500 (80.9802)  Acc@5: 100.0000 (98.7860)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1260/3750]  eta: 0:16:15  Lr: 0.030000  Loss: -1.8605  Acc@1: 81.2500 (80.9526)  Acc@5: 100.0000 (98.7956)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1270/3750]  eta: 0:16:11  Lr: 0.030000  Loss: -1.7606  Acc@1: 75.0000 (80.9156)  Acc@5: 100.0000 (98.8002)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1280/3750]  eta: 0:16:07  Lr: 0.030000  Loss: -2.1567  Acc@1: 75.0000 (80.9377)  Acc@5: 100.0000 (98.7998)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1290/3750]  eta: 0:16:03  Lr: 0.030000  Loss: -1.7099  Acc@1: 81.2500 (80.9208)  Acc@5: 100.0000 (98.7945)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1300/3750]  eta: 0:15:59  Lr: 0.030000  Loss: -1.8215  Acc@1: 81.2500 (80.9281)  Acc@5: 100.0000 (98.7942)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1310/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -1.7954  Acc@1: 87.5000 (80.9735)  Acc@5: 100.0000 (98.7891)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1320/3750]  eta: 0:15:51  Lr: 0.030000  Loss: -1.3156  Acc@1: 81.2500 (80.9614)  Acc@5: 100.0000 (98.7935)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1330/3750]  eta: 0:15:47  Lr: 0.030000  Loss: -1.6811  Acc@1: 75.0000 (80.9636)  Acc@5: 100.0000 (98.7979)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1340/3750]  eta: 0:15:43  Lr: 0.030000  Loss: -1.6491  Acc@1: 81.2500 (80.9610)  Acc@5: 100.0000 (98.8069)  time: 0.3938  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1350/3750]  eta: 0:15:40  Lr: 0.030000  Loss: -1.6166  Acc@1: 75.0000 (80.8938)  Acc@5: 100.0000 (98.7972)  time: 0.3949  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [1360/3750]  eta: 0:15:36  Lr: 0.030000  Loss: -1.6441  Acc@1: 75.0000 (80.9194)  Acc@5: 100.0000 (98.7968)  time: 0.3942  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1370/3750]  eta: 0:15:32  Lr: 0.030000  Loss: -2.1365  Acc@1: 87.5000 (80.9400)  Acc@5: 100.0000 (98.7874)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1380/3750]  eta: 0:15:28  Lr: 0.030000  Loss: -1.6962  Acc@1: 81.2500 (80.9377)  Acc@5: 100.0000 (98.7871)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1390/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -1.8136  Acc@1: 81.2500 (80.9759)  Acc@5: 100.0000 (98.7913)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1400/3750]  eta: 0:15:20  Lr: 0.030000  Loss: -1.5207  Acc@1: 81.2500 (80.9466)  Acc@5: 100.0000 (98.7866)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1410/3750]  eta: 0:15:16  Lr: 0.030000  Loss: -1.6302  Acc@1: 75.0000 (80.9178)  Acc@5: 100.0000 (98.7908)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1420/3750]  eta: 0:15:12  Lr: 0.030000  Loss: -2.3131  Acc@1: 75.0000 (80.9025)  Acc@5: 100.0000 (98.7949)  time: 0.3948  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1430/3750]  eta: 0:15:08  Lr: 0.030000  Loss: -1.7183  Acc@1: 75.0000 (80.9050)  Acc@5: 100.0000 (98.7858)  time: 0.3938  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1440/3750]  eta: 0:15:04  Lr: 0.030000  Loss: -2.1456  Acc@1: 87.5000 (80.9160)  Acc@5: 100.0000 (98.7812)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1450/3750]  eta: 0:15:01  Lr: 0.030000  Loss: -2.1659  Acc@1: 87.5000 (80.9226)  Acc@5: 100.0000 (98.7810)  time: 0.3915  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1460/3750]  eta: 0:14:57  Lr: 0.030000  Loss: -1.9150  Acc@1: 87.5000 (80.9762)  Acc@5: 100.0000 (98.7808)  time: 0.3911  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1470/3750]  eta: 0:14:53  Lr: 0.030000  Loss: -1.8835  Acc@1: 81.2500 (80.9781)  Acc@5: 100.0000 (98.7806)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1480/3750]  eta: 0:14:49  Lr: 0.030000  Loss: -2.1013  Acc@1: 81.2500 (81.0221)  Acc@5: 100.0000 (98.7846)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1490/3750]  eta: 0:14:45  Lr: 0.030000  Loss: -1.9472  Acc@1: 81.2500 (81.0153)  Acc@5: 100.0000 (98.7844)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1500/3750]  eta: 0:14:41  Lr: 0.030000  Loss: -1.8415  Acc@1: 81.2500 (81.0418)  Acc@5: 100.0000 (98.7883)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1510/3750]  eta: 0:14:37  Lr: 0.030000  Loss: -1.6111  Acc@1: 81.2500 (81.0349)  Acc@5: 100.0000 (98.7839)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1520/3750]  eta: 0:14:33  Lr: 0.030000  Loss: -2.1034  Acc@1: 81.2500 (80.9993)  Acc@5: 100.0000 (98.7878)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1530/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -2.0101  Acc@1: 75.0000 (80.9602)  Acc@5: 100.0000 (98.7916)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1540/3750]  eta: 0:14:25  Lr: 0.030000  Loss: -1.7549  Acc@1: 81.2500 (80.9864)  Acc@5: 100.0000 (98.7954)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1550/3750]  eta: 0:14:21  Lr: 0.030000  Loss: -1.6787  Acc@1: 81.2500 (80.9639)  Acc@5: 100.0000 (98.8032)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1560/3750]  eta: 0:14:17  Lr: 0.030000  Loss: -2.0339  Acc@1: 75.0000 (80.9457)  Acc@5: 100.0000 (98.7988)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1570/3750]  eta: 0:14:13  Lr: 0.030000  Loss: -1.6671  Acc@1: 81.2500 (80.9636)  Acc@5: 100.0000 (98.8065)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1580/3750]  eta: 0:14:09  Lr: 0.030000  Loss: -1.8415  Acc@1: 81.2500 (80.9891)  Acc@5: 100.0000 (98.8061)  time: 0.3904  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1590/3750]  eta: 0:14:05  Lr: 0.030000  Loss: -1.9242  Acc@1: 81.2500 (80.9868)  Acc@5: 100.0000 (98.8058)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1600/3750]  eta: 0:14:02  Lr: 0.030000  Loss: -1.1827  Acc@1: 81.2500 (80.9650)  Acc@5: 100.0000 (98.8093)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1610/3750]  eta: 0:13:58  Lr: 0.030000  Loss: -2.0634  Acc@1: 75.0000 (80.9552)  Acc@5: 100.0000 (98.8051)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1620/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -1.4786  Acc@1: 81.2500 (80.9608)  Acc@5: 100.0000 (98.8125)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1630/3750]  eta: 0:13:50  Lr: 0.030000  Loss: -1.6663  Acc@1: 81.2500 (80.9588)  Acc@5: 100.0000 (98.8082)  time: 0.3888  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1640/3750]  eta: 0:13:46  Lr: 0.030000  Loss: -1.9225  Acc@1: 81.2500 (80.9567)  Acc@5: 100.0000 (98.8155)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1650/3750]  eta: 0:13:42  Lr: 0.030000  Loss: -1.9202  Acc@1: 81.2500 (80.9585)  Acc@5: 100.0000 (98.8189)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1660/3750]  eta: 0:13:38  Lr: 0.030000  Loss: -1.4283  Acc@1: 81.2500 (80.9452)  Acc@5: 100.0000 (98.8072)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1670/3750]  eta: 0:13:34  Lr: 0.030000  Loss: -0.9950  Acc@1: 81.2500 (80.9657)  Acc@5: 100.0000 (98.8031)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1680/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -2.1769  Acc@1: 81.2500 (80.9674)  Acc@5: 100.0000 (98.7954)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1690/3750]  eta: 0:13:26  Lr: 0.030000  Loss: -1.7639  Acc@1: 81.2500 (80.9654)  Acc@5: 100.0000 (98.7877)  time: 0.3913  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1700/3750]  eta: 0:13:22  Lr: 0.030000  Loss: -1.2821  Acc@1: 81.2500 (80.9634)  Acc@5: 100.0000 (98.7875)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1710/3750]  eta: 0:13:18  Lr: 0.030000  Loss: -1.9416  Acc@1: 81.2500 (80.9651)  Acc@5: 100.0000 (98.7873)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1720/3750]  eta: 0:13:14  Lr: 0.030000  Loss: -1.2610  Acc@1: 81.2500 (80.9558)  Acc@5: 100.0000 (98.7870)  time: 0.3924  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1730/3750]  eta: 0:13:10  Lr: 0.030000  Loss: -2.2173  Acc@1: 81.2500 (80.9864)  Acc@5: 100.0000 (98.7940)  time: 0.3900  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1740/3750]  eta: 0:13:07  Lr: 0.030000  Loss: -1.9020  Acc@1: 87.5000 (80.9915)  Acc@5: 100.0000 (98.7902)  time: 0.3910  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1750/3750]  eta: 0:13:03  Lr: 0.030000  Loss: -1.9305  Acc@1: 81.2500 (80.9680)  Acc@5: 100.0000 (98.7935)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1760/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -1.9409  Acc@1: 81.2500 (80.9554)  Acc@5: 100.0000 (98.7968)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1770/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -1.6621  Acc@1: 81.2500 (80.9712)  Acc@5: 100.0000 (98.8001)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1780/3750]  eta: 0:12:51  Lr: 0.030000  Loss: -1.5456  Acc@1: 81.2500 (80.9763)  Acc@5: 100.0000 (98.8069)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1790/3750]  eta: 0:12:47  Lr: 0.030000  Loss: -2.1349  Acc@1: 81.2500 (80.9848)  Acc@5: 100.0000 (98.8065)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1800/3750]  eta: 0:12:43  Lr: 0.030000  Loss: -1.2557  Acc@1: 81.2500 (81.0001)  Acc@5: 100.0000 (98.8097)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1810/3750]  eta: 0:12:39  Lr: 0.030000  Loss: -1.9085  Acc@1: 81.2500 (81.0153)  Acc@5: 100.0000 (98.8163)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1820/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -2.0859  Acc@1: 81.2500 (81.0132)  Acc@5: 100.0000 (98.8193)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1830/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -1.3315  Acc@1: 81.2500 (80.9940)  Acc@5: 100.0000 (98.8224)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1840/3750]  eta: 0:12:27  Lr: 0.030000  Loss: -2.0476  Acc@1: 81.2500 (80.9954)  Acc@5: 100.0000 (98.8220)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1850/3750]  eta: 0:12:23  Lr: 0.030000  Loss: -1.8233  Acc@1: 81.2500 (80.9900)  Acc@5: 100.0000 (98.8283)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1860/3750]  eta: 0:12:19  Lr: 0.030000  Loss: -1.9782  Acc@1: 87.5000 (81.0250)  Acc@5: 100.0000 (98.8279)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1870/3750]  eta: 0:12:15  Lr: 0.030000  Loss: -1.5405  Acc@1: 87.5000 (81.0262)  Acc@5: 100.0000 (98.8342)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1880/3750]  eta: 0:12:11  Lr: 0.030000  Loss: -1.6075  Acc@1: 75.0000 (81.0174)  Acc@5: 100.0000 (98.8337)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1890/3750]  eta: 0:12:08  Lr: 0.030000  Loss: -1.9796  Acc@1: 75.0000 (81.0087)  Acc@5: 100.0000 (98.8366)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [1900/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -1.6355  Acc@1: 81.2500 (81.0100)  Acc@5: 100.0000 (98.8394)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1910/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -1.9264  Acc@1: 81.2500 (81.0047)  Acc@5: 100.0000 (98.8390)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1920/3750]  eta: 0:11:56  Lr: 0.030000  Loss: -1.4356  Acc@1: 81.2500 (80.9897)  Acc@5: 100.0000 (98.8352)  time: 0.3921  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1930/3750]  eta: 0:11:52  Lr: 0.030000  Loss: -2.1319  Acc@1: 81.2500 (81.0299)  Acc@5: 100.0000 (98.8413)  time: 0.3908  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1940/3750]  eta: 0:11:48  Lr: 0.030000  Loss: -1.9259  Acc@1: 87.5000 (81.0246)  Acc@5: 100.0000 (98.8408)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1950/3750]  eta: 0:11:44  Lr: 0.030000  Loss: -1.3725  Acc@1: 81.2500 (81.0290)  Acc@5: 100.0000 (98.8339)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [1960/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -2.1418  Acc@1: 81.2500 (81.0237)  Acc@5: 100.0000 (98.8303)  time: 0.3912  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1970/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -2.2305  Acc@1: 81.2500 (81.0439)  Acc@5: 100.0000 (98.8299)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1980/3750]  eta: 0:11:32  Lr: 0.030000  Loss: -1.6464  Acc@1: 81.2500 (81.0418)  Acc@5: 100.0000 (98.8327)  time: 0.3914  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [1990/3750]  eta: 0:11:28  Lr: 0.030000  Loss: -1.6974  Acc@1: 81.2500 (81.0146)  Acc@5: 100.0000 (98.8291)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2000/3750]  eta: 0:11:24  Lr: 0.030000  Loss: -1.6464  Acc@1: 81.2500 (80.9970)  Acc@5: 100.0000 (98.8225)  time: 0.3909  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2010/3750]  eta: 0:11:21  Lr: 0.030000  Loss: -1.7708  Acc@1: 81.2500 (81.0014)  Acc@5: 100.0000 (98.8283)  time: 0.3919  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [2020/3750]  eta: 0:11:17  Lr: 0.030000  Loss: -2.1702  Acc@1: 81.2500 (80.9810)  Acc@5: 100.0000 (98.8248)  time: 0.3937  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2030/3750]  eta: 0:11:13  Lr: 0.030000  Loss: -2.0550  Acc@1: 81.2500 (80.9915)  Acc@5: 100.0000 (98.8275)  time: 0.3935  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2040/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -1.7333  Acc@1: 81.2500 (80.9958)  Acc@5: 100.0000 (98.8272)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2050/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -2.1699  Acc@1: 81.2500 (81.0123)  Acc@5: 100.0000 (98.8268)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2060/3750]  eta: 0:11:01  Lr: 0.030000  Loss: -1.9709  Acc@1: 81.2500 (81.0044)  Acc@5: 100.0000 (98.8204)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2070/3750]  eta: 0:10:57  Lr: 0.030000  Loss: -1.7389  Acc@1: 81.2500 (80.9965)  Acc@5: 100.0000 (98.8230)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2080/3750]  eta: 0:10:53  Lr: 0.030000  Loss: -2.0524  Acc@1: 81.2500 (80.9767)  Acc@5: 100.0000 (98.8287)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2090/3750]  eta: 0:10:49  Lr: 0.030000  Loss: -1.0797  Acc@1: 81.2500 (80.9810)  Acc@5: 100.0000 (98.8283)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2100/3750]  eta: 0:10:45  Lr: 0.030000  Loss: -1.5575  Acc@1: 81.2500 (80.9793)  Acc@5: 100.0000 (98.8309)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2110/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -1.7745  Acc@1: 75.0000 (80.9362)  Acc@5: 100.0000 (98.8157)  time: 0.3914  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2120/3750]  eta: 0:10:38  Lr: 0.030000  Loss: -1.3175  Acc@1: 68.7500 (80.9111)  Acc@5: 100.0000 (98.8125)  time: 0.3926  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2130/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -2.0954  Acc@1: 81.2500 (80.9215)  Acc@5: 100.0000 (98.8151)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2140/3750]  eta: 0:10:30  Lr: 0.030000  Loss: -2.0984  Acc@1: 75.0000 (80.8909)  Acc@5: 100.0000 (98.8206)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2150/3750]  eta: 0:10:26  Lr: 0.030000  Loss: -1.9229  Acc@1: 75.0000 (80.9013)  Acc@5: 100.0000 (98.8232)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2160/3750]  eta: 0:10:22  Lr: 0.030000  Loss: -2.1012  Acc@1: 81.2500 (80.8856)  Acc@5: 100.0000 (98.8200)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2170/3750]  eta: 0:10:18  Lr: 0.030000  Loss: -1.8090  Acc@1: 81.2500 (80.8844)  Acc@5: 100.0000 (98.8254)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2180/3750]  eta: 0:10:14  Lr: 0.030000  Loss: -1.8014  Acc@1: 81.2500 (80.8861)  Acc@5: 100.0000 (98.8193)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2190/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -1.9973  Acc@1: 81.2500 (80.8963)  Acc@5: 100.0000 (98.8247)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2200/3750]  eta: 0:10:06  Lr: 0.030000  Loss: -1.8402  Acc@1: 81.2500 (80.8894)  Acc@5: 100.0000 (98.8272)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2210/3750]  eta: 0:10:02  Lr: 0.030000  Loss: -2.0517  Acc@1: 81.2500 (80.8995)  Acc@5: 100.0000 (98.8325)  time: 0.3895  data: 0.0002  max mem: 2912
Train: Epoch[5/5]  [2220/3750]  eta: 0:09:58  Lr: 0.030000  Loss: -1.9541  Acc@1: 81.2500 (80.8982)  Acc@5: 100.0000 (98.8322)  time: 0.3901  data: 0.0002  max mem: 2912
Train: Epoch[5/5]  [2230/3750]  eta: 0:09:54  Lr: 0.030000  Loss: -2.3214  Acc@1: 81.2500 (80.9194)  Acc@5: 100.0000 (98.8290)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2240/3750]  eta: 0:09:50  Lr: 0.030000  Loss: -1.9069  Acc@1: 81.2500 (80.9265)  Acc@5: 100.0000 (98.8259)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2250/3750]  eta: 0:09:47  Lr: 0.030000  Loss: -2.1404  Acc@1: 87.5000 (80.9446)  Acc@5: 100.0000 (98.8255)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2260/3750]  eta: 0:09:43  Lr: 0.030000  Loss: -1.8368  Acc@1: 87.5000 (80.9432)  Acc@5: 100.0000 (98.8307)  time: 0.3929  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2270/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -1.6514  Acc@1: 81.2500 (80.9500)  Acc@5: 100.0000 (98.8304)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2280/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -1.9775  Acc@1: 81.2500 (80.9541)  Acc@5: 100.0000 (98.8245)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2290/3750]  eta: 0:09:31  Lr: 0.030000  Loss: -2.2052  Acc@1: 81.2500 (80.9417)  Acc@5: 100.0000 (98.8269)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2300/3750]  eta: 0:09:27  Lr: 0.030000  Loss: -1.4547  Acc@1: 81.2500 (80.9458)  Acc@5: 100.0000 (98.8293)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2310/3750]  eta: 0:09:23  Lr: 0.030000  Loss: -2.0452  Acc@1: 87.5000 (80.9633)  Acc@5: 100.0000 (98.8344)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2320/3750]  eta: 0:09:19  Lr: 0.030000  Loss: -2.1049  Acc@1: 87.5000 (80.9673)  Acc@5: 100.0000 (98.8367)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2330/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -1.5069  Acc@1: 87.5000 (80.9685)  Acc@5: 100.0000 (98.8363)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2340/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -1.9543  Acc@1: 81.2500 (80.9537)  Acc@5: 100.0000 (98.8333)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2350/3750]  eta: 0:09:07  Lr: 0.030000  Loss: -1.4072  Acc@1: 81.2500 (80.9416)  Acc@5: 100.0000 (98.8303)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2360/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -2.1558  Acc@1: 75.0000 (80.9350)  Acc@5: 100.0000 (98.8273)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2370/3750]  eta: 0:09:00  Lr: 0.030000  Loss: -1.9000  Acc@1: 75.0000 (80.9100)  Acc@5: 100.0000 (98.8270)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2380/3750]  eta: 0:08:56  Lr: 0.030000  Loss: -1.9244  Acc@1: 81.2500 (80.9403)  Acc@5: 100.0000 (98.8240)  time: 0.3904  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2390/3750]  eta: 0:08:52  Lr: 0.030000  Loss: -1.5486  Acc@1: 87.5000 (80.9389)  Acc@5: 100.0000 (98.8289)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2400/3750]  eta: 0:08:48  Lr: 0.030000  Loss: -1.9480  Acc@1: 81.2500 (80.9246)  Acc@5: 100.0000 (98.8312)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2410/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -2.2262  Acc@1: 75.0000 (80.9078)  Acc@5: 100.0000 (98.8335)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2420/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -1.8067  Acc@1: 75.0000 (80.9015)  Acc@5: 100.0000 (98.8357)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2430/3750]  eta: 0:08:36  Lr: 0.030000  Loss: -1.9872  Acc@1: 81.2500 (80.8978)  Acc@5: 100.0000 (98.8379)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2440/3750]  eta: 0:08:32  Lr: 0.030000  Loss: -2.2109  Acc@1: 81.2500 (80.9171)  Acc@5: 100.0000 (98.8401)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2450/3750]  eta: 0:08:28  Lr: 0.030000  Loss: -1.8469  Acc@1: 81.2500 (80.8854)  Acc@5: 100.0000 (98.8449)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2460/3750]  eta: 0:08:24  Lr: 0.030000  Loss: -1.6903  Acc@1: 81.2500 (80.9097)  Acc@5: 100.0000 (98.8470)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2470/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -2.1180  Acc@1: 87.5000 (80.9313)  Acc@5: 100.0000 (98.8416)  time: 0.3882  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2480/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -2.1438  Acc@1: 87.5000 (80.9225)  Acc@5: 100.0000 (98.8336)  time: 0.3884  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2490/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -1.7034  Acc@1: 81.2500 (80.9263)  Acc@5: 100.0000 (98.8358)  time: 0.3886  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2500/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -1.9037  Acc@1: 81.2500 (80.9301)  Acc@5: 100.0000 (98.8405)  time: 0.3885  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2510/3750]  eta: 0:08:05  Lr: 0.030000  Loss: -1.5992  Acc@1: 81.2500 (80.9239)  Acc@5: 100.0000 (98.8426)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2520/3750]  eta: 0:08:01  Lr: 0.030000  Loss: -1.9321  Acc@1: 81.2500 (80.9153)  Acc@5: 100.0000 (98.8447)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:57  Lr: 0.030000  Loss: -1.9358  Acc@1: 81.2500 (80.9240)  Acc@5: 100.0000 (98.8468)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:53  Lr: 0.030000  Loss: -1.6529  Acc@1: 81.2500 (80.9278)  Acc@5: 100.0000 (98.8464)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2550/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -2.0905  Acc@1: 87.5000 (80.9535)  Acc@5: 100.0000 (98.8436)  time: 0.3902  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2560/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -1.8360  Acc@1: 87.5000 (80.9693)  Acc@5: 100.0000 (98.8408)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2570/3750]  eta: 0:07:41  Lr: 0.030000  Loss: -2.0933  Acc@1: 81.2500 (80.9461)  Acc@5: 100.0000 (98.8429)  time: 0.3905  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2580/3750]  eta: 0:07:37  Lr: 0.030000  Loss: -2.1012  Acc@1: 75.0000 (80.9449)  Acc@5: 100.0000 (98.8425)  time: 0.3896  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2590/3750]  eta: 0:07:33  Lr: 0.030000  Loss: -1.7386  Acc@1: 81.2500 (80.9388)  Acc@5: 100.0000 (98.8421)  time: 0.3897  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2600/3750]  eta: 0:07:29  Lr: 0.030000  Loss: -1.4930  Acc@1: 81.2500 (80.9448)  Acc@5: 100.0000 (98.8442)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2610/3750]  eta: 0:07:26  Lr: 0.030000  Loss: -1.5809  Acc@1: 81.2500 (80.9340)  Acc@5: 100.0000 (98.8414)  time: 0.3910  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2620/3750]  eta: 0:07:22  Lr: 0.030000  Loss: -2.2980  Acc@1: 81.2500 (80.9519)  Acc@5: 100.0000 (98.8435)  time: 0.3901  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2630/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -1.9205  Acc@1: 81.2500 (80.9341)  Acc@5: 100.0000 (98.8479)  time: 0.3897  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2640/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -1.9366  Acc@1: 81.2500 (80.9400)  Acc@5: 100.0000 (98.8499)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2650/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -1.6503  Acc@1: 81.2500 (80.9294)  Acc@5: 100.0000 (98.8495)  time: 0.3912  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2660/3750]  eta: 0:07:06  Lr: 0.030000  Loss: -1.3102  Acc@1: 75.0000 (80.9047)  Acc@5: 100.0000 (98.8444)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2670/3750]  eta: 0:07:02  Lr: 0.030000  Loss: -1.7396  Acc@1: 75.0000 (80.8967)  Acc@5: 100.0000 (98.8464)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:58  Lr: 0.030000  Loss: -1.5010  Acc@1: 81.2500 (80.9003)  Acc@5: 100.0000 (98.8460)  time: 0.3908  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:54  Lr: 0.030000  Loss: -1.8935  Acc@1: 81.2500 (80.8970)  Acc@5: 100.0000 (98.8434)  time: 0.3903  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -1.6422  Acc@1: 81.2500 (80.8844)  Acc@5: 100.0000 (98.8361)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -1.4342  Acc@1: 81.2500 (80.8765)  Acc@5: 100.0000 (98.8381)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2720/3750]  eta: 0:06:42  Lr: 0.030000  Loss: -1.7279  Acc@1: 81.2500 (80.8871)  Acc@5: 100.0000 (98.8354)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2730/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -1.4722  Acc@1: 81.2500 (80.8930)  Acc@5: 100.0000 (98.8328)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2740/3750]  eta: 0:06:35  Lr: 0.030000  Loss: -1.7114  Acc@1: 81.2500 (80.8966)  Acc@5: 100.0000 (98.8348)  time: 0.3895  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2750/3750]  eta: 0:06:31  Lr: 0.030000  Loss: -1.7005  Acc@1: 81.2500 (80.8842)  Acc@5: 100.0000 (98.8391)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2760/3750]  eta: 0:06:27  Lr: 0.030000  Loss: -1.9602  Acc@1: 81.2500 (80.8765)  Acc@5: 100.0000 (98.8410)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2770/3750]  eta: 0:06:23  Lr: 0.030000  Loss: -1.9209  Acc@1: 81.2500 (80.8801)  Acc@5: 100.0000 (98.8452)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2780/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -1.3721  Acc@1: 81.2500 (80.8747)  Acc@5: 100.0000 (98.8493)  time: 0.3929  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2790/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -2.0821  Acc@1: 81.2500 (80.8850)  Acc@5: 100.0000 (98.8490)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2800/3750]  eta: 0:06:11  Lr: 0.030000  Loss: -1.9498  Acc@1: 81.2500 (80.8930)  Acc@5: 100.0000 (98.8509)  time: 0.3934  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2810/3750]  eta: 0:06:07  Lr: 0.030000  Loss: -1.9008  Acc@1: 81.2500 (80.8854)  Acc@5: 100.0000 (98.8483)  time: 0.3936  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2820/3750]  eta: 0:06:03  Lr: 0.030000  Loss: -1.3912  Acc@1: 81.2500 (80.8867)  Acc@5: 100.0000 (98.8501)  time: 0.3930  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:59  Lr: 0.030000  Loss: -1.8015  Acc@1: 81.2500 (80.8813)  Acc@5: 100.0000 (98.8498)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:56  Lr: 0.030000  Loss: -2.3558  Acc@1: 81.2500 (80.8980)  Acc@5: 100.0000 (98.8538)  time: 0.3927  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:52  Lr: 0.030000  Loss: -1.5923  Acc@1: 81.2500 (80.8883)  Acc@5: 100.0000 (98.8535)  time: 0.3927  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -1.0472  Acc@1: 81.2500 (80.8743)  Acc@5: 100.0000 (98.8531)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -2.1780  Acc@1: 81.2500 (80.8908)  Acc@5: 100.0000 (98.8571)  time: 0.3903  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:40  Lr: 0.030000  Loss: -2.0862  Acc@1: 81.2500 (80.8704)  Acc@5: 100.0000 (98.8437)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:36  Lr: 0.030000  Loss: -2.0521  Acc@1: 81.2500 (80.8760)  Acc@5: 100.0000 (98.8477)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2900/3750]  eta: 0:05:32  Lr: 0.030000  Loss: -1.9706  Acc@1: 87.5000 (80.8881)  Acc@5: 100.0000 (98.8495)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2910/3750]  eta: 0:05:28  Lr: 0.030000  Loss: -2.0934  Acc@1: 87.5000 (80.9022)  Acc@5: 100.0000 (98.8513)  time: 0.3928  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2920/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -1.1829  Acc@1: 87.5000 (80.9077)  Acc@5: 100.0000 (98.8510)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [2930/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -1.7071  Acc@1: 81.2500 (80.9110)  Acc@5: 100.0000 (98.8443)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2940/3750]  eta: 0:05:16  Lr: 0.030000  Loss: -1.9570  Acc@1: 81.2500 (80.9185)  Acc@5: 100.0000 (98.8461)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2950/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -1.1541  Acc@1: 81.2500 (80.9175)  Acc@5: 100.0000 (98.8478)  time: 0.3913  data: 0.0008  max mem: 2912
Train: Epoch[5/5]  [2960/3750]  eta: 0:05:09  Lr: 0.030000  Loss: -1.8717  Acc@1: 81.2500 (80.9207)  Acc@5: 100.0000 (98.8496)  time: 0.3907  data: 0.0008  max mem: 2912
Train: Epoch[5/5]  [2970/3750]  eta: 0:05:05  Lr: 0.030000  Loss: -1.8448  Acc@1: 75.0000 (80.9155)  Acc@5: 100.0000 (98.8514)  time: 0.3900  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2980/3750]  eta: 0:05:01  Lr: 0.030000  Loss: -2.1187  Acc@1: 75.0000 (80.9166)  Acc@5: 100.0000 (98.8511)  time: 0.3890  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:57  Lr: 0.030000  Loss: -1.8914  Acc@1: 81.2500 (80.9324)  Acc@5: 100.0000 (98.8549)  time: 0.3877  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -2.0130  Acc@1: 81.2500 (80.9251)  Acc@5: 100.0000 (98.8566)  time: 0.3879  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -2.0661  Acc@1: 81.2500 (80.9262)  Acc@5: 100.0000 (98.8563)  time: 0.3878  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:45  Lr: 0.030000  Loss: -1.6566  Acc@1: 81.2500 (80.9211)  Acc@5: 100.0000 (98.8559)  time: 0.3900  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:41  Lr: 0.030000  Loss: -0.8197  Acc@1: 75.0000 (80.8974)  Acc@5: 100.0000 (98.8556)  time: 0.3910  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:37  Lr: 0.030000  Loss: -1.9816  Acc@1: 75.0000 (80.8780)  Acc@5: 100.0000 (98.8552)  time: 0.3909  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:33  Lr: 0.030000  Loss: -1.6159  Acc@1: 68.7500 (80.8567)  Acc@5: 100.0000 (98.8549)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:29  Lr: 0.030000  Loss: -2.2378  Acc@1: 68.7500 (80.8437)  Acc@5: 100.0000 (98.8586)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3070/3750]  eta: 0:04:26  Lr: 0.030000  Loss: -2.2272  Acc@1: 81.2500 (80.8491)  Acc@5: 100.0000 (98.8603)  time: 0.3901  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3080/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -1.8385  Acc@1: 81.2500 (80.8605)  Acc@5: 100.0000 (98.8599)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3090/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -2.0541  Acc@1: 81.2500 (80.8517)  Acc@5: 100.0000 (98.8636)  time: 0.3891  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3100/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -1.6109  Acc@1: 75.0000 (80.8429)  Acc@5: 100.0000 (98.8653)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3110/3750]  eta: 0:04:10  Lr: 0.030000  Loss: -1.8688  Acc@1: 81.2500 (80.8542)  Acc@5: 100.0000 (98.8649)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3120/3750]  eta: 0:04:06  Lr: 0.030000  Loss: -1.5077  Acc@1: 81.2500 (80.8475)  Acc@5: 100.0000 (98.8645)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3130/3750]  eta: 0:04:02  Lr: 0.030000  Loss: -1.9916  Acc@1: 75.0000 (80.8368)  Acc@5: 100.0000 (98.8602)  time: 0.3883  data: 0.0002  max mem: 2912
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:58  Lr: 0.030000  Loss: -1.7449  Acc@1: 75.0000 (80.7983)  Acc@5: 100.0000 (98.8598)  time: 0.3887  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -1.9396  Acc@1: 75.0000 (80.8216)  Acc@5: 100.0000 (98.8615)  time: 0.3893  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:50  Lr: 0.030000  Loss: -2.2532  Acc@1: 87.5000 (80.8249)  Acc@5: 100.0000 (98.8611)  time: 0.3905  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:46  Lr: 0.030000  Loss: -1.5583  Acc@1: 75.0000 (80.8144)  Acc@5: 100.0000 (98.8608)  time: 0.3919  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:42  Lr: 0.030000  Loss: -1.7144  Acc@1: 81.2500 (80.8177)  Acc@5: 100.0000 (98.8604)  time: 0.3923  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:39  Lr: 0.030000  Loss: -2.0490  Acc@1: 81.2500 (80.8152)  Acc@5: 100.0000 (98.8581)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:35  Lr: 0.030000  Loss: -1.8278  Acc@1: 81.2500 (80.8244)  Acc@5: 100.0000 (98.8617)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:31  Lr: 0.030000  Loss: -1.7113  Acc@1: 81.2500 (80.8023)  Acc@5: 100.0000 (98.8594)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:27  Lr: 0.030000  Loss: -1.8159  Acc@1: 81.2500 (80.8095)  Acc@5: 100.0000 (98.8590)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -2.1325  Acc@1: 81.2500 (80.8206)  Acc@5: 100.0000 (98.8626)  time: 0.3908  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3240/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -1.9990  Acc@1: 81.2500 (80.8257)  Acc@5: 100.0000 (98.8603)  time: 0.3913  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3250/3750]  eta: 0:03:15  Lr: 0.030000  Loss: -2.0708  Acc@1: 81.2500 (80.8213)  Acc@5: 100.0000 (98.8638)  time: 0.3922  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3260/3750]  eta: 0:03:11  Lr: 0.030000  Loss: -1.3875  Acc@1: 81.2500 (80.8245)  Acc@5: 100.0000 (98.8635)  time: 0.3914  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3270/3750]  eta: 0:03:07  Lr: 0.030000  Loss: -1.8389  Acc@1: 81.2500 (80.8201)  Acc@5: 100.0000 (98.8631)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3280/3750]  eta: 0:03:03  Lr: 0.030000  Loss: -2.1732  Acc@1: 81.2500 (80.8271)  Acc@5: 100.0000 (98.8647)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -2.0884  Acc@1: 87.5000 (80.8398)  Acc@5: 100.0000 (98.8662)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:56  Lr: 0.030000  Loss: -1.6323  Acc@1: 75.0000 (80.8164)  Acc@5: 100.0000 (98.8640)  time: 0.3898  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -1.8881  Acc@1: 75.0000 (80.8121)  Acc@5: 100.0000 (98.8655)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -1.6758  Acc@1: 81.2500 (80.7983)  Acc@5: 100.0000 (98.8652)  time: 0.3896  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:44  Lr: 0.030000  Loss: -1.9969  Acc@1: 81.2500 (80.7997)  Acc@5: 100.0000 (98.8648)  time: 0.3917  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:40  Lr: 0.030000  Loss: -1.2397  Acc@1: 81.2500 (80.7973)  Acc@5: 100.0000 (98.8664)  time: 0.3932  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:36  Lr: 0.030000  Loss: -1.8817  Acc@1: 81.2500 (80.8005)  Acc@5: 100.0000 (98.8641)  time: 0.3925  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:32  Lr: 0.030000  Loss: -1.9682  Acc@1: 75.0000 (80.7814)  Acc@5: 100.0000 (98.8601)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -2.0097  Acc@1: 75.0000 (80.7754)  Acc@5: 100.0000 (98.8616)  time: 0.3943  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -1.8200  Acc@1: 81.2500 (80.7731)  Acc@5: 100.0000 (98.8613)  time: 0.3931  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:20  Lr: 0.030000  Loss: -1.7769  Acc@1: 81.2500 (80.7763)  Acc@5: 100.0000 (98.8610)  time: 0.3922  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:16  Lr: 0.030000  Loss: -1.5374  Acc@1: 81.2500 (80.7740)  Acc@5: 100.0000 (98.8588)  time: 0.3934  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3410/3750]  eta: 0:02:13  Lr: 0.030000  Loss: -2.1151  Acc@1: 81.2500 (80.7681)  Acc@5: 100.0000 (98.8603)  time: 0.3940  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3420/3750]  eta: 0:02:09  Lr: 0.030000  Loss: -1.9843  Acc@1: 81.2500 (80.7750)  Acc@5: 100.0000 (98.8563)  time: 0.3936  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3430/3750]  eta: 0:02:05  Lr: 0.030000  Loss: -1.4304  Acc@1: 87.5000 (80.7727)  Acc@5: 100.0000 (98.8597)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3440/3750]  eta: 0:02:01  Lr: 0.030000  Loss: -2.1519  Acc@1: 81.2500 (80.7868)  Acc@5: 100.0000 (98.8575)  time: 0.3917  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -1.9406  Acc@1: 87.5000 (80.7972)  Acc@5: 100.0000 (98.8608)  time: 0.3930  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -1.8588  Acc@1: 87.5000 (80.8022)  Acc@5: 100.0000 (98.8623)  time: 0.3924  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:49  Lr: 0.030000  Loss: -1.9779  Acc@1: 81.2500 (80.7998)  Acc@5: 100.0000 (98.8638)  time: 0.3935  data: 0.0006  max mem: 2912
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:45  Lr: 0.030000  Loss: -1.8060  Acc@1: 87.5000 (80.8119)  Acc@5: 100.0000 (98.8617)  time: 0.3932  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:41  Lr: 0.030000  Loss: -2.1424  Acc@1: 87.5000 (80.8150)  Acc@5: 100.0000 (98.8631)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:37  Lr: 0.030000  Loss: -1.6214  Acc@1: 81.2500 (80.8269)  Acc@5: 100.0000 (98.8646)  time: 0.3902  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -1.4998  Acc@1: 81.2500 (80.8228)  Acc@5: 100.0000 (98.8625)  time: 0.3906  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -1.5162  Acc@1: 81.2500 (80.8116)  Acc@5: 100.0000 (98.8586)  time: 0.3907  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -2.1089  Acc@1: 75.0000 (80.8093)  Acc@5: 100.0000 (98.8601)  time: 0.3905  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -1.6923  Acc@1: 81.2500 (80.8229)  Acc@5: 100.0000 (98.8598)  time: 0.3906  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:18  Lr: 0.030000  Loss: -1.4342  Acc@1: 87.5000 (80.8346)  Acc@5: 100.0000 (98.8595)  time: 0.3899  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:14  Lr: 0.030000  Loss: -2.1209  Acc@1: 81.2500 (80.8393)  Acc@5: 100.0000 (98.8609)  time: 0.3892  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:10  Lr: 0.030000  Loss: -2.0451  Acc@1: 81.2500 (80.8440)  Acc@5: 100.0000 (98.8589)  time: 0.3894  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3580/3750]  eta: 0:01:06  Lr: 0.030000  Loss: -2.1873  Acc@1: 75.0000 (80.8381)  Acc@5: 100.0000 (98.8568)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3590/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -2.1961  Acc@1: 75.0000 (80.8236)  Acc@5: 100.0000 (98.8565)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -2.0661  Acc@1: 75.0000 (80.8282)  Acc@5: 100.0000 (98.8562)  time: 0.3889  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:54  Lr: 0.030000  Loss: -1.7751  Acc@1: 81.2500 (80.8311)  Acc@5: 100.0000 (98.8542)  time: 0.3893  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:50  Lr: 0.030000  Loss: -1.6611  Acc@1: 87.5000 (80.8530)  Acc@5: 100.0000 (98.8574)  time: 0.3907  data: 0.0003  max mem: 2912
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:46  Lr: 0.030000  Loss: -1.9847  Acc@1: 87.5000 (80.8524)  Acc@5: 100.0000 (98.8571)  time: 0.3918  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:43  Lr: 0.030000  Loss: -1.6275  Acc@1: 81.2500 (80.8466)  Acc@5: 100.0000 (98.8585)  time: 0.3920  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:39  Lr: 0.030000  Loss: -2.1499  Acc@1: 75.0000 (80.8460)  Acc@5: 100.0000 (98.8582)  time: 0.3912  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:35  Lr: 0.030000  Loss: -1.4859  Acc@1: 75.0000 (80.8420)  Acc@5: 100.0000 (98.8579)  time: 0.3895  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -1.6325  Acc@1: 75.0000 (80.8363)  Acc@5: 100.0000 (98.8576)  time: 0.3915  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -1.7852  Acc@1: 75.0000 (80.8408)  Acc@5: 100.0000 (98.8607)  time: 0.3921  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:23  Lr: 0.030000  Loss: -1.4904  Acc@1: 81.2500 (80.8402)  Acc@5: 100.0000 (98.8604)  time: 0.3917  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:19  Lr: 0.030000  Loss: -1.8035  Acc@1: 81.2500 (80.8515)  Acc@5: 100.0000 (98.8618)  time: 0.3919  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:15  Lr: 0.030000  Loss: -1.4556  Acc@1: 81.2500 (80.8441)  Acc@5: 100.0000 (98.8632)  time: 0.3911  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:11  Lr: 0.030000  Loss: -1.6945  Acc@1: 75.0000 (80.8402)  Acc@5: 100.0000 (98.8662)  time: 0.3916  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:07  Lr: 0.030000  Loss: -1.7027  Acc@1: 81.2500 (80.8429)  Acc@5: 100.0000 (98.8659)  time: 0.3918  data: 0.0005  max mem: 2912
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -1.8723  Acc@1: 81.2500 (80.8424)  Acc@5: 100.0000 (98.8639)  time: 0.3916  data: 0.0004  max mem: 2912
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -1.3490  Acc@1: 81.2500 (80.8467)  Acc@5: 100.0000 (98.8650)  time: 0.3922  data: 0.0009  max mem: 2912
Train: Epoch[5/5] Total time: 0:24:27 (0.3913 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 20: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 21: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 22: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 23: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 24: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 25: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 26: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 27: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 28: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 29: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 30: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 31: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 32: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 33: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 34: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 35: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 36: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 37: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 38: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 39: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}}
Averaged stats: Lr: 0.030000  Loss: -1.3490  Acc@1: 81.2500 (80.8467)  Acc@5: 100.0000 (98.8650)
Test: [Task 1]  [   0/1627]  eta: 0:16:03  Loss: 1.0815 (1.0815)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5923  data: 0.3480  max mem: 2912
Test: [Task 1]  [  10/1627]  eta: 0:07:24  Loss: 0.7857 (0.7312)  Acc@1: 75.0000 (77.8409)  Acc@5: 93.7500 (94.8864)  time: 0.2748  data: 0.0319  max mem: 2912
Test: [Task 1]  [  20/1627]  eta: 0:06:57  Loss: 0.7453 (0.7618)  Acc@1: 81.2500 (77.9762)  Acc@5: 93.7500 (94.6429)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [  30/1627]  eta: 0:06:46  Loss: 0.6858 (0.7376)  Acc@1: 81.2500 (78.8306)  Acc@5: 93.7500 (95.3629)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [  40/1627]  eta: 0:06:39  Loss: 0.7550 (0.7582)  Acc@1: 81.2500 (78.2012)  Acc@5: 93.7500 (95.1220)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [  50/1627]  eta: 0:06:34  Loss: 0.7550 (0.7501)  Acc@1: 81.2500 (78.6765)  Acc@5: 93.7500 (95.3431)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [  60/1627]  eta: 0:06:29  Loss: 0.7185 (0.7652)  Acc@1: 75.0000 (78.4836)  Acc@5: 93.7500 (95.1844)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [  70/1627]  eta: 0:06:25  Loss: 0.6935 (0.7639)  Acc@1: 81.2500 (78.6092)  Acc@5: 93.7500 (95.1585)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [  80/1627]  eta: 0:06:23  Loss: 0.6354 (0.7552)  Acc@1: 81.2500 (78.4722)  Acc@5: 100.0000 (95.6019)  time: 0.2444  data: 0.0003  max mem: 2912
Test: [Task 1]  [  90/1627]  eta: 0:06:19  Loss: 0.7595 (0.7681)  Acc@1: 75.0000 (78.4341)  Acc@5: 93.7500 (95.3984)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 100/1627]  eta: 0:06:16  Loss: 0.8920 (0.7867)  Acc@1: 75.0000 (78.0322)  Acc@5: 93.7500 (95.2970)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 110/1627]  eta: 0:06:13  Loss: 0.6906 (0.7768)  Acc@1: 75.0000 (78.2095)  Acc@5: 100.0000 (95.5518)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 120/1627]  eta: 0:06:10  Loss: 0.6648 (0.7810)  Acc@1: 81.2500 (78.3574)  Acc@5: 93.7500 (95.5062)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 130/1627]  eta: 0:06:07  Loss: 0.6651 (0.7767)  Acc@1: 81.2500 (78.5305)  Acc@5: 93.7500 (95.6107)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 140/1627]  eta: 0:06:04  Loss: 0.6651 (0.7728)  Acc@1: 75.0000 (78.2801)  Acc@5: 100.0000 (95.7004)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 150/1627]  eta: 0:06:02  Loss: 0.6602 (0.7665)  Acc@1: 75.0000 (78.5182)  Acc@5: 100.0000 (95.7781)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 160/1627]  eta: 0:05:59  Loss: 0.6703 (0.7639)  Acc@1: 81.2500 (78.6879)  Acc@5: 100.0000 (95.7686)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 170/1627]  eta: 0:05:56  Loss: 0.7103 (0.7584)  Acc@1: 81.2500 (78.7281)  Acc@5: 93.7500 (95.8333)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 180/1627]  eta: 0:05:53  Loss: 0.6670 (0.7593)  Acc@1: 75.0000 (78.6948)  Acc@5: 93.7500 (95.8909)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 190/1627]  eta: 0:05:51  Loss: 0.7072 (0.7550)  Acc@1: 81.2500 (78.9594)  Acc@5: 93.7500 (95.8770)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 200/1627]  eta: 0:05:48  Loss: 0.8070 (0.7541)  Acc@1: 81.2500 (78.8868)  Acc@5: 93.7500 (95.8022)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 210/1627]  eta: 0:05:46  Loss: 0.7204 (0.7534)  Acc@1: 75.0000 (78.9100)  Acc@5: 93.7500 (95.8235)  time: 0.2444  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 220/1627]  eta: 0:05:43  Loss: 0.7204 (0.7530)  Acc@1: 75.0000 (78.9027)  Acc@5: 100.0000 (95.8428)  time: 0.2447  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 230/1627]  eta: 0:05:41  Loss: 0.7321 (0.7514)  Acc@1: 81.2500 (78.9502)  Acc@5: 100.0000 (95.8874)  time: 0.2450  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 240/1627]  eta: 0:05:39  Loss: 0.6371 (0.7485)  Acc@1: 81.2500 (78.9938)  Acc@5: 100.0000 (95.9284)  time: 0.2457  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 250/1627]  eta: 0:05:36  Loss: 0.6281 (0.7547)  Acc@1: 81.2500 (79.0090)  Acc@5: 93.7500 (95.8416)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 260/1627]  eta: 0:05:34  Loss: 0.7003 (0.7534)  Acc@1: 81.2500 (78.9990)  Acc@5: 93.7500 (95.8812)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 270/1627]  eta: 0:05:31  Loss: 0.6658 (0.7477)  Acc@1: 75.0000 (79.0821)  Acc@5: 100.0000 (96.0101)  time: 0.2459  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 280/1627]  eta: 0:05:29  Loss: 0.7411 (0.7490)  Acc@1: 75.0000 (79.0925)  Acc@5: 100.0000 (95.9297)  time: 0.2455  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 290/1627]  eta: 0:05:27  Loss: 0.8094 (0.7518)  Acc@1: 81.2500 (79.1022)  Acc@5: 93.7500 (95.9622)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 300/1627]  eta: 0:05:24  Loss: 0.7050 (0.7506)  Acc@1: 81.2500 (79.2151)  Acc@5: 100.0000 (95.9302)  time: 0.2477  data: 0.0005  max mem: 2912
Test: [Task 1]  [ 310/1627]  eta: 0:05:22  Loss: 0.6404 (0.7500)  Acc@1: 81.2500 (79.2805)  Acc@5: 93.7500 (95.9003)  time: 0.2466  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 320/1627]  eta: 0:05:19  Loss: 0.6184 (0.7449)  Acc@1: 81.2500 (79.4003)  Acc@5: 100.0000 (95.9891)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 330/1627]  eta: 0:05:17  Loss: 0.5256 (0.7457)  Acc@1: 81.2500 (79.3429)  Acc@5: 100.0000 (95.9781)  time: 0.2447  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 340/1627]  eta: 0:05:15  Loss: 0.6541 (0.7494)  Acc@1: 75.0000 (79.3072)  Acc@5: 100.0000 (96.0044)  time: 0.2453  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 350/1627]  eta: 0:05:12  Loss: 0.6541 (0.7488)  Acc@1: 81.2500 (79.3091)  Acc@5: 100.0000 (95.9936)  time: 0.2448  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 360/1627]  eta: 0:05:10  Loss: 0.6679 (0.7489)  Acc@1: 81.2500 (79.3456)  Acc@5: 93.7500 (95.9834)  time: 0.2456  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 370/1627]  eta: 0:05:07  Loss: 0.6197 (0.7482)  Acc@1: 81.2500 (79.4474)  Acc@5: 100.0000 (96.0074)  time: 0.2473  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 380/1627]  eta: 0:05:05  Loss: 0.6505 (0.7482)  Acc@1: 87.5000 (79.4619)  Acc@5: 100.0000 (96.0138)  time: 0.2462  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 390/1627]  eta: 0:05:02  Loss: 0.6969 (0.7484)  Acc@1: 75.0000 (79.3798)  Acc@5: 100.0000 (96.0038)  time: 0.2443  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 400/1627]  eta: 0:05:00  Loss: 0.5559 (0.7470)  Acc@1: 75.0000 (79.3797)  Acc@5: 100.0000 (96.0567)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 410/1627]  eta: 0:04:57  Loss: 0.7177 (0.7510)  Acc@1: 81.2500 (79.3035)  Acc@5: 93.7500 (95.9854)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 420/1627]  eta: 0:04:55  Loss: 0.6928 (0.7498)  Acc@1: 81.2500 (79.3349)  Acc@5: 93.7500 (95.9917)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 430/1627]  eta: 0:04:52  Loss: 0.6468 (0.7494)  Acc@1: 75.0000 (79.2778)  Acc@5: 93.7500 (95.9977)  time: 0.2435  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 440/1627]  eta: 0:04:50  Loss: 0.6809 (0.7483)  Acc@1: 75.0000 (79.2800)  Acc@5: 93.7500 (95.9751)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 450/1627]  eta: 0:04:47  Loss: 0.6830 (0.7494)  Acc@1: 75.0000 (79.2129)  Acc@5: 100.0000 (95.9257)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 460/1627]  eta: 0:04:45  Loss: 0.6924 (0.7477)  Acc@1: 81.2500 (79.2570)  Acc@5: 100.0000 (95.9328)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 470/1627]  eta: 0:04:42  Loss: 0.5849 (0.7452)  Acc@1: 81.2500 (79.2728)  Acc@5: 100.0000 (95.9528)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 480/1627]  eta: 0:04:40  Loss: 0.6504 (0.7460)  Acc@1: 81.2500 (79.3009)  Acc@5: 100.0000 (95.9330)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 490/1627]  eta: 0:04:37  Loss: 0.7390 (0.7481)  Acc@1: 75.0000 (79.2643)  Acc@5: 93.7500 (95.9012)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 500/1627]  eta: 0:04:35  Loss: 0.7525 (0.7497)  Acc@1: 75.0000 (79.2415)  Acc@5: 93.7500 (95.8832)  time: 0.2414  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 510/1627]  eta: 0:04:32  Loss: 0.7876 (0.7533)  Acc@1: 81.2500 (79.2931)  Acc@5: 93.7500 (95.8537)  time: 0.2412  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 520/1627]  eta: 0:04:30  Loss: 0.8035 (0.7603)  Acc@1: 81.2500 (79.2706)  Acc@5: 93.7500 (95.7654)  time: 0.2412  data: 0.0002  max mem: 2912
Test: [Task 1]  [ 530/1627]  eta: 0:04:27  Loss: 0.7445 (0.7588)  Acc@1: 75.0000 (79.2608)  Acc@5: 93.7500 (95.7863)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 540/1627]  eta: 0:04:25  Loss: 0.6412 (0.7577)  Acc@1: 81.2500 (79.2745)  Acc@5: 100.0000 (95.7833)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 550/1627]  eta: 0:04:23  Loss: 0.6883 (0.7590)  Acc@1: 81.2500 (79.2309)  Acc@5: 100.0000 (95.8031)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 560/1627]  eta: 0:04:20  Loss: 0.7895 (0.7609)  Acc@1: 75.0000 (79.1667)  Acc@5: 100.0000 (95.7888)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 570/1627]  eta: 0:04:18  Loss: 0.7895 (0.7595)  Acc@1: 81.2500 (79.2469)  Acc@5: 93.7500 (95.8078)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 580/1627]  eta: 0:04:15  Loss: 0.4758 (0.7593)  Acc@1: 81.2500 (79.2384)  Acc@5: 100.0000 (95.8369)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 590/1627]  eta: 0:04:13  Loss: 0.6260 (0.7586)  Acc@1: 81.2500 (79.2724)  Acc@5: 100.0000 (95.8439)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 600/1627]  eta: 0:04:10  Loss: 0.6260 (0.7589)  Acc@1: 81.2500 (79.2429)  Acc@5: 100.0000 (95.8507)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 610/1627]  eta: 0:04:08  Loss: 0.7078 (0.7581)  Acc@1: 81.2500 (79.3065)  Acc@5: 93.7500 (95.8367)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 620/1627]  eta: 0:04:05  Loss: 0.7088 (0.7592)  Acc@1: 81.2500 (79.2572)  Acc@5: 93.7500 (95.7729)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 630/1627]  eta: 0:04:03  Loss: 0.7088 (0.7618)  Acc@1: 75.0000 (79.1700)  Acc@5: 93.7500 (95.7508)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 640/1627]  eta: 0:04:00  Loss: 0.8083 (0.7617)  Acc@1: 75.0000 (79.1537)  Acc@5: 93.7500 (95.7391)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 650/1627]  eta: 0:03:58  Loss: 0.7039 (0.7600)  Acc@1: 81.2500 (79.1763)  Acc@5: 100.0000 (95.7757)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 660/1627]  eta: 0:03:55  Loss: 0.6888 (0.7590)  Acc@1: 75.0000 (79.1793)  Acc@5: 100.0000 (95.7734)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 670/1627]  eta: 0:03:53  Loss: 0.7623 (0.7599)  Acc@1: 75.0000 (79.0984)  Acc@5: 100.0000 (95.7899)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 680/1627]  eta: 0:03:51  Loss: 0.7784 (0.7609)  Acc@1: 75.0000 (79.0841)  Acc@5: 100.0000 (95.7783)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 690/1627]  eta: 0:03:48  Loss: 0.7534 (0.7591)  Acc@1: 81.2500 (79.1606)  Acc@5: 93.7500 (95.7670)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 700/1627]  eta: 0:03:46  Loss: 0.7473 (0.7595)  Acc@1: 81.2500 (79.1726)  Acc@5: 93.7500 (95.7561)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 710/1627]  eta: 0:03:43  Loss: 0.7253 (0.7580)  Acc@1: 81.2500 (79.2458)  Acc@5: 100.0000 (95.7806)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 720/1627]  eta: 0:03:41  Loss: 0.5866 (0.7555)  Acc@1: 87.5000 (79.3256)  Acc@5: 100.0000 (95.8218)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 730/1627]  eta: 0:03:38  Loss: 0.6299 (0.7552)  Acc@1: 87.5000 (79.3690)  Acc@5: 100.0000 (95.8447)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 740/1627]  eta: 0:03:36  Loss: 0.8091 (0.7570)  Acc@1: 81.2500 (79.3269)  Acc@5: 100.0000 (95.8418)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 750/1627]  eta: 0:03:33  Loss: 0.7997 (0.7564)  Acc@1: 75.0000 (79.3525)  Acc@5: 100.0000 (95.8638)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 760/1627]  eta: 0:03:31  Loss: 0.8224 (0.7594)  Acc@1: 75.0000 (79.3528)  Acc@5: 93.7500 (95.8196)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 770/1627]  eta: 0:03:29  Loss: 0.5653 (0.7568)  Acc@1: 81.2500 (79.4018)  Acc@5: 100.0000 (95.8577)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 780/1627]  eta: 0:03:26  Loss: 0.4784 (0.7535)  Acc@1: 81.2500 (79.5134)  Acc@5: 100.0000 (95.8947)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 790/1627]  eta: 0:03:24  Loss: 0.5028 (0.7537)  Acc@1: 81.2500 (79.5196)  Acc@5: 100.0000 (95.8913)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 800/1627]  eta: 0:03:21  Loss: 0.6587 (0.7536)  Acc@1: 81.2500 (79.5022)  Acc@5: 93.7500 (95.8958)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 810/1627]  eta: 0:03:19  Loss: 0.6498 (0.7530)  Acc@1: 81.2500 (79.5083)  Acc@5: 100.0000 (95.9155)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 820/1627]  eta: 0:03:16  Loss: 0.5953 (0.7519)  Acc@1: 81.2500 (79.5295)  Acc@5: 100.0000 (95.9044)  time: 0.2421  data: 0.0002  max mem: 2912
Test: [Task 1]  [ 830/1627]  eta: 0:03:14  Loss: 0.6529 (0.7519)  Acc@1: 81.2500 (79.5352)  Acc@5: 93.7500 (95.9010)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 840/1627]  eta: 0:03:11  Loss: 0.6659 (0.7503)  Acc@1: 81.2500 (79.5853)  Acc@5: 100.0000 (95.9200)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 850/1627]  eta: 0:03:09  Loss: 0.6895 (0.7521)  Acc@1: 75.0000 (79.5461)  Acc@5: 100.0000 (95.9092)  time: 0.2419  data: 0.0002  max mem: 2912
Test: [Task 1]  [ 860/1627]  eta: 0:03:06  Loss: 0.6895 (0.7511)  Acc@1: 81.2500 (79.5877)  Acc@5: 100.0000 (95.9204)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 870/1627]  eta: 0:03:04  Loss: 0.6193 (0.7505)  Acc@1: 87.5000 (79.6355)  Acc@5: 100.0000 (95.9099)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 880/1627]  eta: 0:03:02  Loss: 0.7346 (0.7525)  Acc@1: 81.2500 (79.5474)  Acc@5: 100.0000 (95.9137)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 890/1627]  eta: 0:02:59  Loss: 0.8783 (0.7546)  Acc@1: 75.0000 (79.4964)  Acc@5: 100.0000 (95.9035)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 1]  [ 900/1627]  eta: 0:02:57  Loss: 0.6223 (0.7544)  Acc@1: 75.0000 (79.5089)  Acc@5: 100.0000 (95.9004)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 910/1627]  eta: 0:02:54  Loss: 0.5979 (0.7555)  Acc@1: 81.2500 (79.5211)  Acc@5: 100.0000 (95.8836)  time: 0.2434  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 920/1627]  eta: 0:02:52  Loss: 0.6759 (0.7552)  Acc@1: 81.2500 (79.5467)  Acc@5: 100.0000 (95.8808)  time: 0.2426  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 930/1627]  eta: 0:02:49  Loss: 0.7160 (0.7555)  Acc@1: 81.2500 (79.5650)  Acc@5: 100.0000 (95.8714)  time: 0.2428  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 940/1627]  eta: 0:02:47  Loss: 0.6556 (0.7535)  Acc@1: 81.2500 (79.6493)  Acc@5: 100.0000 (95.8887)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 950/1627]  eta: 0:02:44  Loss: 0.6494 (0.7531)  Acc@1: 81.2500 (79.6333)  Acc@5: 100.0000 (95.9056)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 960/1627]  eta: 0:02:42  Loss: 0.7210 (0.7526)  Acc@1: 81.2500 (79.6436)  Acc@5: 100.0000 (95.9092)  time: 0.2445  data: 0.0004  max mem: 2912
Test: [Task 1]  [ 970/1627]  eta: 0:02:40  Loss: 0.6482 (0.7524)  Acc@1: 81.2500 (79.6022)  Acc@5: 100.0000 (95.9192)  time: 0.2466  data: 0.0005  max mem: 2912
Test: [Task 1]  [ 980/1627]  eta: 0:02:37  Loss: 0.8195 (0.7529)  Acc@1: 81.2500 (79.5935)  Acc@5: 100.0000 (95.9034)  time: 0.2458  data: 0.0005  max mem: 2912
Test: [Task 1]  [ 990/1627]  eta: 0:02:35  Loss: 0.8845 (0.7556)  Acc@1: 81.2500 (79.5724)  Acc@5: 93.7500 (95.8880)  time: 0.2435  data: 0.0004  max mem: 2912
Test: [Task 1]  [1000/1627]  eta: 0:02:32  Loss: 0.8259 (0.7553)  Acc@1: 81.2500 (79.5829)  Acc@5: 93.7500 (95.8916)  time: 0.2436  data: 0.0004  max mem: 2912
Test: [Task 1]  [1010/1627]  eta: 0:02:30  Loss: 0.6647 (0.7548)  Acc@1: 81.2500 (79.6180)  Acc@5: 100.0000 (95.9075)  time: 0.2434  data: 0.0004  max mem: 2912
Test: [Task 1]  [1020/1627]  eta: 0:02:27  Loss: 0.6800 (0.7548)  Acc@1: 81.2500 (79.5911)  Acc@5: 100.0000 (95.8986)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 1]  [1030/1627]  eta: 0:02:25  Loss: 0.6620 (0.7531)  Acc@1: 81.2500 (79.6314)  Acc@5: 100.0000 (95.9142)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 1]  [1040/1627]  eta: 0:02:23  Loss: 0.5773 (0.7519)  Acc@1: 81.2500 (79.6530)  Acc@5: 100.0000 (95.9354)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1050/1627]  eta: 0:02:20  Loss: 0.6140 (0.7509)  Acc@1: 81.2500 (79.6920)  Acc@5: 100.0000 (95.9443)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [1060/1627]  eta: 0:02:18  Loss: 0.6904 (0.7518)  Acc@1: 81.2500 (79.6713)  Acc@5: 93.7500 (95.9237)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 1]  [1070/1627]  eta: 0:02:15  Loss: 0.7796 (0.7528)  Acc@1: 81.2500 (79.6569)  Acc@5: 93.7500 (95.9034)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 1]  [1080/1627]  eta: 0:02:13  Loss: 0.7530 (0.7531)  Acc@1: 75.0000 (79.6138)  Acc@5: 100.0000 (95.9181)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [1090/1627]  eta: 0:02:10  Loss: 0.7090 (0.7526)  Acc@1: 75.0000 (79.6231)  Acc@5: 100.0000 (95.9384)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1100/1627]  eta: 0:02:08  Loss: 0.6672 (0.7520)  Acc@1: 81.2500 (79.6208)  Acc@5: 100.0000 (95.9525)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [1110/1627]  eta: 0:02:05  Loss: 0.7012 (0.7516)  Acc@1: 81.2500 (79.6130)  Acc@5: 100.0000 (95.9665)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1120/1627]  eta: 0:02:03  Loss: 0.7012 (0.7528)  Acc@1: 81.2500 (79.5885)  Acc@5: 100.0000 (95.9579)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [1130/1627]  eta: 0:02:01  Loss: 0.7492 (0.7532)  Acc@1: 75.0000 (79.5645)  Acc@5: 93.7500 (95.9494)  time: 0.2418  data: 0.0002  max mem: 2912
Test: [Task 1]  [1140/1627]  eta: 0:01:58  Loss: 0.7492 (0.7541)  Acc@1: 75.0000 (79.5191)  Acc@5: 100.0000 (95.9684)  time: 0.2419  data: 0.0002  max mem: 2912
Test: [Task 1]  [1150/1627]  eta: 0:01:56  Loss: 0.8006 (0.7550)  Acc@1: 75.0000 (79.5070)  Acc@5: 100.0000 (95.9600)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 1]  [1160/1627]  eta: 0:01:53  Loss: 0.7096 (0.7546)  Acc@1: 81.2500 (79.5273)  Acc@5: 93.7500 (95.9518)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 1]  [1170/1627]  eta: 0:01:51  Loss: 0.5185 (0.7537)  Acc@1: 81.2500 (79.5474)  Acc@5: 100.0000 (95.9596)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1180/1627]  eta: 0:01:48  Loss: 0.5797 (0.7540)  Acc@1: 81.2500 (79.5565)  Acc@5: 100.0000 (95.9727)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 1]  [1190/1627]  eta: 0:01:46  Loss: 0.7481 (0.7539)  Acc@1: 81.2500 (79.5445)  Acc@5: 100.0000 (95.9803)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1200/1627]  eta: 0:01:44  Loss: 0.6786 (0.7537)  Acc@1: 81.2500 (79.5379)  Acc@5: 100.0000 (95.9721)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 1]  [1210/1627]  eta: 0:01:41  Loss: 0.6231 (0.7548)  Acc@1: 81.2500 (79.4953)  Acc@5: 93.7500 (95.9538)  time: 0.2435  data: 0.0004  max mem: 2912
Test: [Task 1]  [1220/1627]  eta: 0:01:39  Loss: 0.5901 (0.7538)  Acc@1: 81.2500 (79.5301)  Acc@5: 100.0000 (95.9715)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 1]  [1230/1627]  eta: 0:01:36  Loss: 0.6396 (0.7546)  Acc@1: 81.2500 (79.5136)  Acc@5: 100.0000 (95.9535)  time: 0.2440  data: 0.0005  max mem: 2912
Test: [Task 1]  [1240/1627]  eta: 0:01:34  Loss: 0.7259 (0.7540)  Acc@1: 81.2500 (79.5175)  Acc@5: 100.0000 (95.9609)  time: 0.2437  data: 0.0005  max mem: 2912
Test: [Task 1]  [1250/1627]  eta: 0:01:31  Loss: 0.7306 (0.7541)  Acc@1: 81.2500 (79.5614)  Acc@5: 100.0000 (95.9532)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 1]  [1260/1627]  eta: 0:01:29  Loss: 0.6663 (0.7540)  Acc@1: 81.2500 (79.5847)  Acc@5: 100.0000 (95.9506)  time: 0.2436  data: 0.0004  max mem: 2912
Test: [Task 1]  [1270/1627]  eta: 0:01:26  Loss: 0.6663 (0.7544)  Acc@1: 81.2500 (79.5683)  Acc@5: 93.7500 (95.9382)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 1]  [1280/1627]  eta: 0:01:24  Loss: 0.6975 (0.7529)  Acc@1: 87.5000 (79.6107)  Acc@5: 93.7500 (95.9504)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1290/1627]  eta: 0:01:22  Loss: 0.6823 (0.7526)  Acc@1: 81.2500 (79.6185)  Acc@5: 100.0000 (95.9527)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1300/1627]  eta: 0:01:19  Loss: 0.6823 (0.7522)  Acc@1: 81.2500 (79.6455)  Acc@5: 100.0000 (95.9694)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1310/1627]  eta: 0:01:17  Loss: 0.5917 (0.7513)  Acc@1: 81.2500 (79.6672)  Acc@5: 100.0000 (95.9811)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1320/1627]  eta: 0:01:14  Loss: 0.5439 (0.7515)  Acc@1: 81.2500 (79.6508)  Acc@5: 100.0000 (95.9879)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1330/1627]  eta: 0:01:12  Loss: 0.5415 (0.7507)  Acc@1: 87.5000 (79.6769)  Acc@5: 100.0000 (95.9946)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1]  [1340/1627]  eta: 0:01:09  Loss: 0.6758 (0.7514)  Acc@1: 81.2500 (79.6560)  Acc@5: 100.0000 (95.9918)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 1]  [1350/1627]  eta: 0:01:07  Loss: 0.7095 (0.7509)  Acc@1: 81.2500 (79.6771)  Acc@5: 100.0000 (95.9983)  time: 0.2415  data: 0.0003  max mem: 2912
Test: [Task 1]  [1360/1627]  eta: 0:01:05  Loss: 0.6773 (0.7511)  Acc@1: 81.2500 (79.6427)  Acc@5: 100.0000 (96.0231)  time: 0.2415  data: 0.0003  max mem: 2912
Test: [Task 1]  [1370/1627]  eta: 0:01:02  Loss: 0.6773 (0.7503)  Acc@1: 81.2500 (79.6636)  Acc@5: 100.0000 (96.0248)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 1]  [1380/1627]  eta: 0:01:00  Loss: 0.6379 (0.7498)  Acc@1: 81.2500 (79.6751)  Acc@5: 100.0000 (96.0310)  time: 0.2417  data: 0.0003  max mem: 2912
Test: [Task 1]  [1390/1627]  eta: 0:00:57  Loss: 0.8166 (0.7500)  Acc@1: 75.0000 (79.6684)  Acc@5: 100.0000 (96.0415)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [1400/1627]  eta: 0:00:55  Loss: 0.9012 (0.7502)  Acc@1: 75.0000 (79.6529)  Acc@5: 100.0000 (96.0252)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [1410/1627]  eta: 0:00:52  Loss: 0.6705 (0.7498)  Acc@1: 81.2500 (79.6775)  Acc@5: 100.0000 (96.0268)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [1420/1627]  eta: 0:00:50  Loss: 0.6577 (0.7495)  Acc@1: 81.2500 (79.6930)  Acc@5: 100.0000 (96.0195)  time: 0.2454  data: 0.0004  max mem: 2912
Test: [Task 1]  [1430/1627]  eta: 0:00:47  Loss: 0.8913 (0.7516)  Acc@1: 81.2500 (79.6689)  Acc@5: 93.7500 (95.9949)  time: 0.2448  data: 0.0004  max mem: 2912
Test: [Task 1]  [1440/1627]  eta: 0:00:45  Loss: 0.9393 (0.7523)  Acc@1: 81.2500 (79.6365)  Acc@5: 93.7500 (95.9837)  time: 0.2455  data: 0.0004  max mem: 2912
Test: [Task 1]  [1450/1627]  eta: 0:00:43  Loss: 0.8462 (0.7535)  Acc@1: 81.2500 (79.6089)  Acc@5: 93.7500 (95.9726)  time: 0.2448  data: 0.0004  max mem: 2912
Test: [Task 1]  [1460/1627]  eta: 0:00:40  Loss: 0.7347 (0.7528)  Acc@1: 81.2500 (79.6458)  Acc@5: 100.0000 (95.9873)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 1]  [1470/1627]  eta: 0:00:38  Loss: 0.6322 (0.7532)  Acc@1: 81.2500 (79.6355)  Acc@5: 100.0000 (95.9806)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 1]  [1480/1627]  eta: 0:00:35  Loss: 0.6702 (0.7537)  Acc@1: 81.2500 (79.6126)  Acc@5: 100.0000 (95.9867)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 1]  [1490/1627]  eta: 0:00:33  Loss: 0.6702 (0.7542)  Acc@1: 81.2500 (79.6110)  Acc@5: 93.7500 (95.9800)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 1]  [1500/1627]  eta: 0:00:30  Loss: 0.6795 (0.7545)  Acc@1: 81.2500 (79.5886)  Acc@5: 93.7500 (95.9818)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 1]  [1510/1627]  eta: 0:00:28  Loss: 0.6795 (0.7550)  Acc@1: 75.0000 (79.5789)  Acc@5: 100.0000 (95.9795)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 1]  [1520/1627]  eta: 0:00:26  Loss: 0.5893 (0.7539)  Acc@1: 81.2500 (79.6146)  Acc@5: 100.0000 (95.9936)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 1]  [1530/1627]  eta: 0:00:23  Loss: 0.6203 (0.7540)  Acc@1: 81.2500 (79.6130)  Acc@5: 100.0000 (95.9871)  time: 0.2421  data: 0.0002  max mem: 2912
Test: [Task 1]  [1540/1627]  eta: 0:00:21  Loss: 0.6326 (0.7526)  Acc@1: 87.5000 (79.6682)  Acc@5: 100.0000 (96.0010)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [1550/1627]  eta: 0:00:18  Loss: 0.5975 (0.7526)  Acc@1: 87.5000 (79.6623)  Acc@5: 100.0000 (96.0106)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 1]  [1560/1627]  eta: 0:00:16  Loss: 0.5802 (0.7520)  Acc@1: 81.2500 (79.6765)  Acc@5: 100.0000 (96.0082)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [1570/1627]  eta: 0:00:13  Loss: 0.5715 (0.7518)  Acc@1: 81.2500 (79.6825)  Acc@5: 100.0000 (96.0137)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 1]  [1580/1627]  eta: 0:00:11  Loss: 0.7328 (0.7514)  Acc@1: 81.2500 (79.6885)  Acc@5: 100.0000 (96.0152)  time: 0.2438  data: 0.0004  max mem: 2912
Test: [Task 1]  [1590/1627]  eta: 0:00:09  Loss: 0.7328 (0.7512)  Acc@1: 75.0000 (79.6787)  Acc@5: 93.7500 (96.0167)  time: 0.2446  data: 0.0004  max mem: 2912
Test: [Task 1]  [1600/1627]  eta: 0:00:06  Loss: 0.7615 (0.7521)  Acc@1: 75.0000 (79.6416)  Acc@5: 93.7500 (96.0025)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1610/1627]  eta: 0:00:04  Loss: 0.6274 (0.7512)  Acc@1: 75.0000 (79.6749)  Acc@5: 93.7500 (96.0040)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.6274 (0.7507)  Acc@1: 81.2500 (79.6808)  Acc@5: 100.0000 (96.0171)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.7057 (0.7505)  Acc@1: 81.2500 (79.6942)  Acc@5: 100.0000 (96.0203)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 1] Total time: 0:06:36 (0.2436 s / it)
* Acc@1 79.694 Acc@5 96.020 loss 0.750
Test: [Task 2]  [  0/625]  eta: 0:06:19  Loss: 0.1448 (0.1448)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6072  data: 0.3624  max mem: 2912
Test: [Task 2]  [ 10/625]  eta: 0:02:49  Loss: 0.0699 (0.0996)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  time: 0.2763  data: 0.0332  max mem: 2912
Test: [Task 2]  [ 20/625]  eta: 0:02:37  Loss: 0.0730 (0.1380)  Acc@1: 100.0000 (95.8333)  Acc@5: 100.0000 (99.7024)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 30/625]  eta: 0:02:32  Loss: 0.1575 (0.1718)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (99.5968)  time: 0.2441  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 40/625]  eta: 0:02:27  Loss: 0.1937 (0.1841)  Acc@1: 93.7500 (94.0549)  Acc@5: 100.0000 (99.6951)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 50/625]  eta: 0:02:23  Loss: 0.1523 (0.1860)  Acc@1: 93.7500 (93.9951)  Acc@5: 100.0000 (99.6324)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 60/625]  eta: 0:02:20  Loss: 0.1480 (0.1847)  Acc@1: 93.7500 (94.2623)  Acc@5: 100.0000 (99.5902)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 2]  [ 70/625]  eta: 0:02:17  Loss: 0.1235 (0.1770)  Acc@1: 93.7500 (94.6303)  Acc@5: 100.0000 (99.6479)  time: 0.2413  data: 0.0002  max mem: 2912
Test: [Task 2]  [ 80/625]  eta: 0:02:14  Loss: 0.1235 (0.1735)  Acc@1: 93.7500 (94.8302)  Acc@5: 100.0000 (99.6142)  time: 0.2415  data: 0.0002  max mem: 2912
Test: [Task 2]  [ 90/625]  eta: 0:02:11  Loss: 0.1136 (0.1672)  Acc@1: 93.7500 (94.9176)  Acc@5: 100.0000 (99.6566)  time: 0.2415  data: 0.0002  max mem: 2912
Test: [Task 2]  [100/625]  eta: 0:02:09  Loss: 0.0968 (0.1634)  Acc@1: 93.7500 (95.1733)  Acc@5: 100.0000 (99.6906)  time: 0.2414  data: 0.0002  max mem: 2912
Test: [Task 2]  [110/625]  eta: 0:02:06  Loss: 0.0820 (0.1667)  Acc@1: 100.0000 (95.1577)  Acc@5: 100.0000 (99.6622)  time: 0.2416  data: 0.0002  max mem: 2912
Test: [Task 2]  [120/625]  eta: 0:02:03  Loss: 0.1267 (0.1687)  Acc@1: 93.7500 (95.0930)  Acc@5: 100.0000 (99.5868)  time: 0.2418  data: 0.0002  max mem: 2912
Test: [Task 2]  [130/625]  eta: 0:02:01  Loss: 0.1450 (0.1705)  Acc@1: 93.7500 (94.8950)  Acc@5: 100.0000 (99.6183)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 2]  [140/625]  eta: 0:01:58  Loss: 0.1450 (0.1765)  Acc@1: 93.7500 (94.7695)  Acc@5: 100.0000 (99.5567)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 2]  [150/625]  eta: 0:01:56  Loss: 0.1889 (0.1814)  Acc@1: 93.7500 (94.5778)  Acc@5: 100.0000 (99.5033)  time: 0.2453  data: 0.0004  max mem: 2912
Test: [Task 2]  [160/625]  eta: 0:01:53  Loss: 0.2038 (0.1854)  Acc@1: 93.7500 (94.5264)  Acc@5: 100.0000 (99.4565)  time: 0.2452  data: 0.0004  max mem: 2912
Test: [Task 2]  [170/625]  eta: 0:01:51  Loss: 0.1241 (0.1818)  Acc@1: 100.0000 (94.7734)  Acc@5: 100.0000 (99.4518)  time: 0.2446  data: 0.0004  max mem: 2912
Test: [Task 2]  [180/625]  eta: 0:01:48  Loss: 0.0970 (0.1806)  Acc@1: 100.0000 (94.8204)  Acc@5: 100.0000 (99.4820)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 2]  [190/625]  eta: 0:01:46  Loss: 0.1166 (0.1818)  Acc@1: 93.7500 (94.7317)  Acc@5: 100.0000 (99.4437)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 2]  [200/625]  eta: 0:01:44  Loss: 0.1365 (0.1805)  Acc@1: 93.7500 (94.7450)  Acc@5: 100.0000 (99.4714)  time: 0.2455  data: 0.0005  max mem: 2912
Test: [Task 2]  [210/625]  eta: 0:01:41  Loss: 0.1365 (0.1808)  Acc@1: 93.7500 (94.7571)  Acc@5: 100.0000 (99.4668)  time: 0.2463  data: 0.0005  max mem: 2912
Test: [Task 2]  [220/625]  eta: 0:01:39  Loss: 0.0910 (0.1799)  Acc@1: 100.0000 (94.8247)  Acc@5: 100.0000 (99.4627)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 2]  [230/625]  eta: 0:01:36  Loss: 0.0814 (0.1784)  Acc@1: 93.7500 (94.8593)  Acc@5: 100.0000 (99.4859)  time: 0.2442  data: 0.0004  max mem: 2912
Test: [Task 2]  [240/625]  eta: 0:01:34  Loss: 0.1896 (0.1804)  Acc@1: 93.7500 (94.7355)  Acc@5: 100.0000 (99.5073)  time: 0.2463  data: 0.0004  max mem: 2912
Test: [Task 2]  [250/625]  eta: 0:01:31  Loss: 0.1924 (0.1822)  Acc@1: 93.7500 (94.6464)  Acc@5: 100.0000 (99.4771)  time: 0.2447  data: 0.0004  max mem: 2912
Test: [Task 2]  [260/625]  eta: 0:01:29  Loss: 0.1462 (0.1803)  Acc@1: 93.7500 (94.6600)  Acc@5: 100.0000 (99.4971)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 2]  [270/625]  eta: 0:01:26  Loss: 0.1487 (0.1806)  Acc@1: 93.7500 (94.6494)  Acc@5: 100.0000 (99.5157)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 2]  [280/625]  eta: 0:01:24  Loss: 0.1487 (0.1829)  Acc@1: 93.7500 (94.6397)  Acc@5: 100.0000 (99.4884)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 2]  [290/625]  eta: 0:01:21  Loss: 0.2062 (0.1838)  Acc@1: 93.7500 (94.5662)  Acc@5: 100.0000 (99.5060)  time: 0.2446  data: 0.0004  max mem: 2912
Test: [Task 2]  [300/625]  eta: 0:01:19  Loss: 0.1424 (0.1832)  Acc@1: 93.7500 (94.5598)  Acc@5: 100.0000 (99.5017)  time: 0.2450  data: 0.0005  max mem: 2912
Test: [Task 2]  [310/625]  eta: 0:01:17  Loss: 0.1308 (0.1819)  Acc@1: 93.7500 (94.6342)  Acc@5: 100.0000 (99.4976)  time: 0.2441  data: 0.0005  max mem: 2912
Test: [Task 2]  [320/625]  eta: 0:01:14  Loss: 0.0374 (0.1769)  Acc@1: 100.0000 (94.8014)  Acc@5: 100.0000 (99.5132)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [330/625]  eta: 0:01:12  Loss: 0.0285 (0.1732)  Acc@1: 100.0000 (94.9207)  Acc@5: 100.0000 (99.5279)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 2]  [340/625]  eta: 0:01:09  Loss: 0.0164 (0.1683)  Acc@1: 100.0000 (95.0696)  Acc@5: 100.0000 (99.5418)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 2]  [350/625]  eta: 0:01:07  Loss: 0.0103 (0.1661)  Acc@1: 100.0000 (95.1211)  Acc@5: 100.0000 (99.5548)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 2]  [360/625]  eta: 0:01:04  Loss: 0.0551 (0.1648)  Acc@1: 100.0000 (95.1350)  Acc@5: 100.0000 (99.5672)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 2]  [370/625]  eta: 0:01:02  Loss: 0.0685 (0.1628)  Acc@1: 100.0000 (95.1988)  Acc@5: 100.0000 (99.5788)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 2]  [380/625]  eta: 0:00:59  Loss: 0.1885 (0.1665)  Acc@1: 93.7500 (95.1115)  Acc@5: 100.0000 (99.5571)  time: 0.2413  data: 0.0003  max mem: 2912
Test: [Task 2]  [390/625]  eta: 0:00:57  Loss: 0.1228 (0.1642)  Acc@1: 93.7500 (95.1726)  Acc@5: 100.0000 (99.5684)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 2]  [400/625]  eta: 0:00:54  Loss: 0.0210 (0.1613)  Acc@1: 100.0000 (95.2774)  Acc@5: 100.0000 (99.5792)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 2]  [410/625]  eta: 0:00:52  Loss: 0.0080 (0.1587)  Acc@1: 100.0000 (95.3619)  Acc@5: 100.0000 (99.5894)  time: 0.2412  data: 0.0003  max mem: 2912
Test: [Task 2]  [420/625]  eta: 0:00:50  Loss: 0.0208 (0.1565)  Acc@1: 100.0000 (95.4424)  Acc@5: 100.0000 (99.5992)  time: 0.2440  data: 0.0004  max mem: 2912
Test: [Task 2]  [430/625]  eta: 0:00:47  Loss: 0.0445 (0.1551)  Acc@1: 100.0000 (95.5046)  Acc@5: 100.0000 (99.6085)  time: 0.2452  data: 0.0005  max mem: 2912
Test: [Task 2]  [440/625]  eta: 0:00:45  Loss: 0.0284 (0.1520)  Acc@1: 100.0000 (95.6066)  Acc@5: 100.0000 (99.6173)  time: 0.2445  data: 0.0005  max mem: 2912
Test: [Task 2]  [450/625]  eta: 0:00:42  Loss: 0.0070 (0.1491)  Acc@1: 100.0000 (95.6901)  Acc@5: 100.0000 (99.6258)  time: 0.2448  data: 0.0005  max mem: 2912
Test: [Task 2]  [460/625]  eta: 0:00:40  Loss: 0.0093 (0.1463)  Acc@1: 100.0000 (95.7701)  Acc@5: 100.0000 (99.6339)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 2]  [470/625]  eta: 0:00:37  Loss: 0.0190 (0.1439)  Acc@1: 100.0000 (95.8599)  Acc@5: 100.0000 (99.6417)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 2]  [480/625]  eta: 0:00:35  Loss: 0.0336 (0.1425)  Acc@1: 100.0000 (95.9070)  Acc@5: 100.0000 (99.6492)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 2]  [490/625]  eta: 0:00:32  Loss: 0.0251 (0.1407)  Acc@1: 100.0000 (95.9521)  Acc@5: 100.0000 (99.6563)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 2]  [500/625]  eta: 0:00:30  Loss: 0.0231 (0.1385)  Acc@1: 100.0000 (96.0205)  Acc@5: 100.0000 (99.6632)  time: 0.2415  data: 0.0003  max mem: 2912
Test: [Task 2]  [510/625]  eta: 0:00:28  Loss: 0.0276 (0.1402)  Acc@1: 100.0000 (95.9760)  Acc@5: 100.0000 (99.6698)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 2]  [520/625]  eta: 0:00:25  Loss: 0.0350 (0.1389)  Acc@1: 100.0000 (96.0173)  Acc@5: 100.0000 (99.6761)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 2]  [530/625]  eta: 0:00:23  Loss: 0.0218 (0.1374)  Acc@1: 100.0000 (96.0570)  Acc@5: 100.0000 (99.6822)  time: 0.2451  data: 0.0005  max mem: 2912
Test: [Task 2]  [540/625]  eta: 0:00:20  Loss: 0.0218 (0.1360)  Acc@1: 100.0000 (96.0952)  Acc@5: 100.0000 (99.6881)  time: 0.2451  data: 0.0005  max mem: 2912
Test: [Task 2]  [550/625]  eta: 0:00:18  Loss: 0.0106 (0.1337)  Acc@1: 100.0000 (96.1661)  Acc@5: 100.0000 (99.6937)  time: 0.2433  data: 0.0004  max mem: 2912
Test: [Task 2]  [560/625]  eta: 0:00:15  Loss: 0.0031 (0.1314)  Acc@1: 100.0000 (96.2344)  Acc@5: 100.0000 (99.6992)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 2]  [570/625]  eta: 0:00:13  Loss: 0.0048 (0.1302)  Acc@1: 100.0000 (96.2675)  Acc@5: 100.0000 (99.7045)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 2]  [580/625]  eta: 0:00:10  Loss: 0.0122 (0.1284)  Acc@1: 100.0000 (96.3210)  Acc@5: 100.0000 (99.7096)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 2]  [590/625]  eta: 0:00:08  Loss: 0.0118 (0.1268)  Acc@1: 100.0000 (96.3621)  Acc@5: 100.0000 (99.7145)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 2]  [600/625]  eta: 0:00:06  Loss: 0.0238 (0.1263)  Acc@1: 100.0000 (96.3706)  Acc@5: 100.0000 (99.7088)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.1237 (0.1271)  Acc@1: 93.7500 (96.3482)  Acc@5: 100.0000 (99.7034)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.1237 (0.1276)  Acc@1: 93.7500 (96.2963)  Acc@5: 100.0000 (99.7081)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.0912 (0.1272)  Acc@1: 93.7500 (96.3100)  Acc@5: 100.0000 (99.7100)  time: 0.2417  data: 0.0002  max mem: 2912
Test: [Task 2] Total time: 0:02:32 (0.2441 s / it)
* Acc@1 96.310 Acc@5 99.710 loss 0.127
Test: [Task 3]  [  0/625]  eta: 0:05:52  Loss: 0.1254 (0.1254)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5642  data: 0.3202  max mem: 2912
Test: [Task 3]  [ 10/625]  eta: 0:02:49  Loss: 0.1210 (0.1163)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (99.4318)  time: 0.2750  data: 0.0296  max mem: 2912
Test: [Task 3]  [ 20/625]  eta: 0:02:37  Loss: 0.0903 (0.1354)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (99.7024)  time: 0.2447  data: 0.0004  max mem: 2912
Test: [Task 3]  [ 30/625]  eta: 0:02:31  Loss: 0.0843 (0.1359)  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (99.7984)  time: 0.2434  data: 0.0004  max mem: 2912
Test: [Task 3]  [ 40/625]  eta: 0:02:27  Loss: 0.0373 (0.1115)  Acc@1: 100.0000 (97.8659)  Acc@5: 100.0000 (99.8476)  time: 0.2447  data: 0.0005  max mem: 2912
Test: [Task 3]  [ 50/625]  eta: 0:02:24  Loss: 0.0373 (0.1070)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (99.7549)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 3]  [ 60/625]  eta: 0:02:20  Loss: 0.0670 (0.1054)  Acc@1: 100.0000 (97.8484)  Acc@5: 100.0000 (99.7951)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 70/625]  eta: 0:02:17  Loss: 0.0411 (0.1000)  Acc@1: 100.0000 (97.9754)  Acc@5: 100.0000 (99.7359)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 80/625]  eta: 0:02:14  Loss: 0.0453 (0.1063)  Acc@1: 100.0000 (97.6852)  Acc@5: 100.0000 (99.6914)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 3]  [ 90/625]  eta: 0:02:12  Loss: 0.0613 (0.1041)  Acc@1: 100.0000 (97.7335)  Acc@5: 100.0000 (99.6566)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [100/625]  eta: 0:02:09  Loss: 0.0398 (0.1010)  Acc@1: 100.0000 (97.8342)  Acc@5: 100.0000 (99.6906)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 3]  [110/625]  eta: 0:02:06  Loss: 0.0374 (0.0966)  Acc@1: 100.0000 (97.8604)  Acc@5: 100.0000 (99.7185)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 3]  [120/625]  eta: 0:02:04  Loss: 0.0228 (0.0963)  Acc@1: 100.0000 (97.8822)  Acc@5: 100.0000 (99.6901)  time: 0.2419  data: 0.0002  max mem: 2912
Test: [Task 3]  [130/625]  eta: 0:02:01  Loss: 0.0496 (0.0987)  Acc@1: 100.0000 (97.7576)  Acc@5: 100.0000 (99.6660)  time: 0.2417  data: 0.0002  max mem: 2912
Test: [Task 3]  [140/625]  eta: 0:01:58  Loss: 0.0686 (0.1021)  Acc@1: 100.0000 (97.6950)  Acc@5: 100.0000 (99.6011)  time: 0.2418  data: 0.0002  max mem: 2912
Test: [Task 3]  [150/625]  eta: 0:01:56  Loss: 0.0977 (0.1151)  Acc@1: 100.0000 (97.6407)  Acc@5: 100.0000 (99.5861)  time: 0.2419  data: 0.0002  max mem: 2912
Test: [Task 3]  [160/625]  eta: 0:01:53  Loss: 0.1021 (0.1167)  Acc@1: 100.0000 (97.6708)  Acc@5: 100.0000 (99.5342)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 3]  [170/625]  eta: 0:01:51  Loss: 0.0772 (0.1165)  Acc@1: 100.0000 (97.6243)  Acc@5: 100.0000 (99.5614)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 3]  [180/625]  eta: 0:01:48  Loss: 0.0772 (0.1186)  Acc@1: 100.0000 (97.5829)  Acc@5: 100.0000 (99.5166)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 3]  [190/625]  eta: 0:01:46  Loss: 0.0476 (0.1170)  Acc@1: 100.0000 (97.5785)  Acc@5: 100.0000 (99.5419)  time: 0.2440  data: 0.0004  max mem: 2912
Test: [Task 3]  [200/625]  eta: 0:01:43  Loss: 0.0692 (0.1178)  Acc@1: 100.0000 (97.5746)  Acc@5: 100.0000 (99.5336)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 3]  [210/625]  eta: 0:01:41  Loss: 0.0842 (0.1197)  Acc@1: 100.0000 (97.4822)  Acc@5: 100.0000 (99.4964)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 3]  [220/625]  eta: 0:01:39  Loss: 0.0391 (0.1191)  Acc@1: 100.0000 (97.4265)  Acc@5: 100.0000 (99.5192)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 3]  [230/625]  eta: 0:01:36  Loss: 0.0502 (0.1195)  Acc@1: 100.0000 (97.4567)  Acc@5: 100.0000 (99.5130)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 3]  [240/625]  eta: 0:01:34  Loss: 0.0502 (0.1201)  Acc@1: 100.0000 (97.4326)  Acc@5: 100.0000 (99.5073)  time: 0.2446  data: 0.0004  max mem: 2912
Test: [Task 3]  [250/625]  eta: 0:01:31  Loss: 0.0394 (0.1183)  Acc@1: 100.0000 (97.4851)  Acc@5: 100.0000 (99.5269)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 3]  [260/625]  eta: 0:01:29  Loss: 0.0483 (0.1175)  Acc@1: 100.0000 (97.5096)  Acc@5: 100.0000 (99.5211)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 3]  [270/625]  eta: 0:01:26  Loss: 0.0693 (0.1167)  Acc@1: 100.0000 (97.5092)  Acc@5: 100.0000 (99.5387)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [280/625]  eta: 0:01:24  Loss: 0.0693 (0.1168)  Acc@1: 100.0000 (97.5534)  Acc@5: 100.0000 (99.5552)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 3]  [290/625]  eta: 0:01:21  Loss: 0.0873 (0.1167)  Acc@1: 100.0000 (97.5730)  Acc@5: 100.0000 (99.5704)  time: 0.2430  data: 0.0003  max mem: 2912
Test: [Task 3]  [300/625]  eta: 0:01:19  Loss: 0.1075 (0.1194)  Acc@1: 93.7500 (97.4668)  Acc@5: 100.0000 (99.5640)  time: 0.2429  data: 0.0003  max mem: 2912
Test: [Task 3]  [310/625]  eta: 0:01:16  Loss: 0.1273 (0.1219)  Acc@1: 93.7500 (97.4277)  Acc@5: 100.0000 (99.5378)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [320/625]  eta: 0:01:14  Loss: 0.0592 (0.1212)  Acc@1: 100.0000 (97.4104)  Acc@5: 100.0000 (99.5522)  time: 0.2435  data: 0.0003  max mem: 2912
Test: [Task 3]  [330/625]  eta: 0:01:12  Loss: 0.0800 (0.1214)  Acc@1: 100.0000 (97.3943)  Acc@5: 100.0000 (99.5657)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 3]  [340/625]  eta: 0:01:09  Loss: 0.0507 (0.1198)  Acc@1: 100.0000 (97.4523)  Acc@5: 100.0000 (99.5784)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 3]  [350/625]  eta: 0:01:07  Loss: 0.0439 (0.1196)  Acc@1: 100.0000 (97.4537)  Acc@5: 100.0000 (99.5726)  time: 0.2421  data: 0.0003  max mem: 2912
Test: [Task 3]  [360/625]  eta: 0:01:04  Loss: 0.0502 (0.1207)  Acc@1: 100.0000 (97.3857)  Acc@5: 100.0000 (99.5499)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 3]  [370/625]  eta: 0:01:02  Loss: 0.0755 (0.1214)  Acc@1: 93.7500 (97.3214)  Acc@5: 100.0000 (99.5451)  time: 0.2422  data: 0.0002  max mem: 2912
Test: [Task 3]  [380/625]  eta: 0:00:59  Loss: 0.0294 (0.1195)  Acc@1: 100.0000 (97.3753)  Acc@5: 100.0000 (99.5571)  time: 0.2423  data: 0.0002  max mem: 2912
Test: [Task 3]  [390/625]  eta: 0:00:57  Loss: 0.0402 (0.1189)  Acc@1: 100.0000 (97.3945)  Acc@5: 100.0000 (99.5524)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 3]  [400/625]  eta: 0:00:54  Loss: 0.0480 (0.1188)  Acc@1: 100.0000 (97.3660)  Acc@5: 100.0000 (99.5480)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 3]  [410/625]  eta: 0:00:52  Loss: 0.0739 (0.1190)  Acc@1: 100.0000 (97.3844)  Acc@5: 100.0000 (99.5438)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 3]  [420/625]  eta: 0:00:49  Loss: 0.0713 (0.1185)  Acc@1: 100.0000 (97.4020)  Acc@5: 100.0000 (99.5546)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 3]  [430/625]  eta: 0:00:47  Loss: 0.0713 (0.1186)  Acc@1: 100.0000 (97.4043)  Acc@5: 100.0000 (99.5505)  time: 0.2436  data: 0.0004  max mem: 2912
Test: [Task 3]  [440/625]  eta: 0:00:45  Loss: 0.0796 (0.1203)  Acc@1: 100.0000 (97.3498)  Acc@5: 100.0000 (99.5465)  time: 0.2434  data: 0.0003  max mem: 2912
Test: [Task 3]  [450/625]  eta: 0:00:42  Loss: 0.0449 (0.1211)  Acc@1: 100.0000 (97.3254)  Acc@5: 100.0000 (99.5288)  time: 0.2451  data: 0.0004  max mem: 2912
Test: [Task 3]  [460/625]  eta: 0:00:40  Loss: 0.0385 (0.1203)  Acc@1: 100.0000 (97.3292)  Acc@5: 100.0000 (99.5390)  time: 0.2443  data: 0.0004  max mem: 2912
Test: [Task 3]  [470/625]  eta: 0:00:37  Loss: 0.0667 (0.1207)  Acc@1: 93.7500 (97.2797)  Acc@5: 100.0000 (99.5356)  time: 0.2450  data: 0.0004  max mem: 2912
Test: [Task 3]  [480/625]  eta: 0:00:35  Loss: 0.0609 (0.1201)  Acc@1: 100.0000 (97.3103)  Acc@5: 100.0000 (99.5322)  time: 0.2464  data: 0.0004  max mem: 2912
Test: [Task 3]  [490/625]  eta: 0:00:32  Loss: 0.0737 (0.1208)  Acc@1: 100.0000 (97.2760)  Acc@5: 100.0000 (99.5290)  time: 0.2440  data: 0.0004  max mem: 2912
Test: [Task 3]  [500/625]  eta: 0:00:30  Loss: 0.0737 (0.1197)  Acc@1: 93.7500 (97.2929)  Acc@5: 100.0000 (99.5384)  time: 0.2423  data: 0.0003  max mem: 2912
Test: [Task 3]  [510/625]  eta: 0:00:28  Loss: 0.0231 (0.1190)  Acc@1: 100.0000 (97.2970)  Acc@5: 100.0000 (99.5475)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 3]  [520/625]  eta: 0:00:25  Loss: 0.0616 (0.1183)  Acc@1: 100.0000 (97.3009)  Acc@5: 100.0000 (99.5561)  time: 0.2432  data: 0.0004  max mem: 2912
Test: [Task 3]  [530/625]  eta: 0:00:23  Loss: 0.0679 (0.1181)  Acc@1: 100.0000 (97.2693)  Acc@5: 100.0000 (99.5645)  time: 0.2448  data: 0.0004  max mem: 2912
Test: [Task 3]  [540/625]  eta: 0:00:20  Loss: 0.0742 (0.1181)  Acc@1: 100.0000 (97.2736)  Acc@5: 100.0000 (99.5494)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 3]  [550/625]  eta: 0:00:18  Loss: 0.0723 (0.1179)  Acc@1: 100.0000 (97.2777)  Acc@5: 100.0000 (99.5576)  time: 0.2431  data: 0.0002  max mem: 2912
Test: [Task 3]  [560/625]  eta: 0:00:15  Loss: 0.0374 (0.1174)  Acc@1: 100.0000 (97.3039)  Acc@5: 100.0000 (99.5544)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [570/625]  eta: 0:00:13  Loss: 0.0359 (0.1168)  Acc@1: 100.0000 (97.3292)  Acc@5: 100.0000 (99.5622)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 3]  [580/625]  eta: 0:00:10  Loss: 0.0860 (0.1177)  Acc@1: 100.0000 (97.2784)  Acc@5: 100.0000 (99.5482)  time: 0.2425  data: 0.0003  max mem: 2912
Test: [Task 3]  [590/625]  eta: 0:00:08  Loss: 0.0712 (0.1168)  Acc@1: 100.0000 (97.3033)  Acc@5: 100.0000 (99.5558)  time: 0.2420  data: 0.0003  max mem: 2912
Test: [Task 3]  [600/625]  eta: 0:00:06  Loss: 0.0558 (0.1169)  Acc@1: 100.0000 (97.2650)  Acc@5: 100.0000 (99.5528)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.0935 (0.1170)  Acc@1: 93.7500 (97.2586)  Acc@5: 100.0000 (99.5601)  time: 0.2415  data: 0.0002  max mem: 2912
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.0912 (0.1173)  Acc@1: 100.0000 (97.2625)  Acc@5: 100.0000 (99.5572)  time: 0.2416  data: 0.0002  max mem: 2912
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.0656 (0.1168)  Acc@1: 100.0000 (97.2800)  Acc@5: 100.0000 (99.5600)  time: 0.2431  data: 0.0002  max mem: 2912
Test: [Task 3] Total time: 0:02:32 (0.2441 s / it)
* Acc@1 97.280 Acc@5 99.560 loss 0.117
Test: [Task 4]  [ 0/29]  eta: 0:00:26  Loss: 1.9255 (1.9255)  Acc@1: 50.0000 (50.0000)  Acc@5: 81.2500 (81.2500)  time: 0.8975  data: 0.6521  max mem: 2912
Test: [Task 4]  [10/29]  eta: 0:00:05  Loss: 1.9255 (1.8722)  Acc@1: 50.0000 (45.4545)  Acc@5: 87.5000 (84.0909)  time: 0.3014  data: 0.0596  max mem: 2912
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.6671 (1.8347)  Acc@1: 50.0000 (50.2976)  Acc@5: 81.2500 (81.2500)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.3829 (1.5630)  Acc@1: 68.7500 (57.9521)  Acc@5: 87.5000 (84.7495)  time: 0.2400  data: 0.0003  max mem: 2912
Test: [Task 4] Total time: 0:00:07 (0.2667 s / it)
* Acc@1 57.952 Acc@5 84.749 loss 1.563
Test: [Task 5]  [  0/625]  eta: 0:05:57  Loss: 0.0306 (0.0306)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5727  data: 0.3266  max mem: 2912
Test: [Task 5]  [ 10/625]  eta: 0:02:47  Loss: 0.2363 (0.3028)  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (99.4318)  time: 0.2716  data: 0.0299  max mem: 2912
Test: [Task 5]  [ 20/625]  eta: 0:02:35  Loss: 0.1964 (0.2630)  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (99.7024)  time: 0.2413  data: 0.0003  max mem: 2912
Test: [Task 5]  [ 30/625]  eta: 0:02:30  Loss: 0.2270 (0.2944)  Acc@1: 93.7500 (91.1290)  Acc@5: 100.0000 (99.3952)  time: 0.2415  data: 0.0003  max mem: 2912
Test: [Task 5]  [ 40/625]  eta: 0:02:26  Loss: 0.3235 (0.2914)  Acc@1: 87.5000 (91.0061)  Acc@5: 100.0000 (99.5427)  time: 0.2417  data: 0.0002  max mem: 2912
Test: [Task 5]  [ 50/625]  eta: 0:02:22  Loss: 0.2984 (0.3038)  Acc@1: 93.7500 (91.4216)  Acc@5: 100.0000 (99.2647)  time: 0.2418  data: 0.0002  max mem: 2912
Test: [Task 5]  [ 60/625]  eta: 0:02:19  Loss: 0.2307 (0.2995)  Acc@1: 93.7500 (91.4959)  Acc@5: 100.0000 (99.1803)  time: 0.2424  data: 0.0003  max mem: 2912
Test: [Task 5]  [ 70/625]  eta: 0:02:16  Loss: 0.2332 (0.3001)  Acc@1: 93.7500 (91.9014)  Acc@5: 100.0000 (99.0317)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 5]  [ 80/625]  eta: 0:02:14  Loss: 0.2950 (0.3082)  Acc@1: 93.7500 (91.5895)  Acc@5: 100.0000 (98.9969)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 5]  [ 90/625]  eta: 0:02:11  Loss: 0.2361 (0.2971)  Acc@1: 87.5000 (91.8956)  Acc@5: 100.0000 (98.9011)  time: 0.2408  data: 0.0003  max mem: 2912
Test: [Task 5]  [100/625]  eta: 0:02:08  Loss: 0.2109 (0.2994)  Acc@1: 93.7500 (91.7079)  Acc@5: 100.0000 (98.8861)  time: 0.2407  data: 0.0003  max mem: 2912
Test: [Task 5]  [110/625]  eta: 0:02:05  Loss: 0.2577 (0.3014)  Acc@1: 87.5000 (91.4977)  Acc@5: 100.0000 (98.9302)  time: 0.2409  data: 0.0003  max mem: 2912
Test: [Task 5]  [120/625]  eta: 0:02:03  Loss: 0.1985 (0.2948)  Acc@1: 93.7500 (91.6839)  Acc@5: 100.0000 (98.9153)  time: 0.2411  data: 0.0003  max mem: 2912
Test: [Task 5]  [130/625]  eta: 0:02:00  Loss: 0.2534 (0.3011)  Acc@1: 87.5000 (91.3168)  Acc@5: 100.0000 (98.9027)  time: 0.2412  data: 0.0003  max mem: 2912
Test: [Task 5]  [140/625]  eta: 0:01:58  Loss: 0.3256 (0.2969)  Acc@1: 87.5000 (91.6223)  Acc@5: 100.0000 (98.9362)  time: 0.2416  data: 0.0003  max mem: 2912
Test: [Task 5]  [150/625]  eta: 0:01:55  Loss: 0.2537 (0.2987)  Acc@1: 93.7500 (91.4735)  Acc@5: 100.0000 (98.9652)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 5]  [160/625]  eta: 0:01:53  Loss: 0.3232 (0.3047)  Acc@1: 87.5000 (91.1102)  Acc@5: 100.0000 (98.9519)  time: 0.2434  data: 0.0004  max mem: 2912
Test: [Task 5]  [170/625]  eta: 0:01:50  Loss: 0.4135 (0.3102)  Acc@1: 87.5000 (91.0088)  Acc@5: 100.0000 (98.9401)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 5]  [180/625]  eta: 0:01:48  Loss: 0.3499 (0.3115)  Acc@1: 87.5000 (90.9530)  Acc@5: 100.0000 (98.9641)  time: 0.2450  data: 0.0004  max mem: 2912
Test: [Task 5]  [190/625]  eta: 0:01:46  Loss: 0.3499 (0.3211)  Acc@1: 87.5000 (90.7068)  Acc@5: 100.0000 (98.8874)  time: 0.2446  data: 0.0004  max mem: 2912
Test: [Task 5]  [200/625]  eta: 0:01:43  Loss: 0.3662 (0.3227)  Acc@1: 87.5000 (90.7027)  Acc@5: 100.0000 (98.9117)  time: 0.2445  data: 0.0005  max mem: 2912
Test: [Task 5]  [210/625]  eta: 0:01:41  Loss: 0.4543 (0.3307)  Acc@1: 87.5000 (90.3732)  Acc@5: 100.0000 (98.8744)  time: 0.2437  data: 0.0004  max mem: 2912
Test: [Task 5]  [220/625]  eta: 0:01:38  Loss: 0.3823 (0.3298)  Acc@1: 87.5000 (90.4412)  Acc@5: 100.0000 (98.8971)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 5]  [230/625]  eta: 0:01:36  Loss: 0.2707 (0.3301)  Acc@1: 93.7500 (90.4491)  Acc@5: 100.0000 (98.8907)  time: 0.2444  data: 0.0004  max mem: 2912
Test: [Task 5]  [240/625]  eta: 0:01:33  Loss: 0.3265 (0.3310)  Acc@1: 87.5000 (90.3786)  Acc@5: 100.0000 (98.9108)  time: 0.2440  data: 0.0004  max mem: 2912
Test: [Task 5]  [250/625]  eta: 0:01:31  Loss: 0.3134 (0.3317)  Acc@1: 87.5000 (90.3137)  Acc@5: 100.0000 (98.9044)  time: 0.2435  data: 0.0004  max mem: 2912
Test: [Task 5]  [260/625]  eta: 0:01:29  Loss: 0.3112 (0.3326)  Acc@1: 87.5000 (90.2538)  Acc@5: 100.0000 (98.8745)  time: 0.2453  data: 0.0004  max mem: 2912
Test: [Task 5]  [270/625]  eta: 0:01:26  Loss: 0.3112 (0.3300)  Acc@1: 87.5000 (90.3137)  Acc@5: 100.0000 (98.8469)  time: 0.2456  data: 0.0004  max mem: 2912
Test: [Task 5]  [280/625]  eta: 0:01:24  Loss: 0.1819 (0.3272)  Acc@1: 93.7500 (90.3247)  Acc@5: 100.0000 (98.8879)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 5]  [290/625]  eta: 0:01:21  Loss: 0.1754 (0.3254)  Acc@1: 93.7500 (90.3780)  Acc@5: 100.0000 (98.9046)  time: 0.2432  data: 0.0003  max mem: 2912
Test: [Task 5]  [300/625]  eta: 0:01:19  Loss: 0.3050 (0.3260)  Acc@1: 87.5000 (90.2409)  Acc@5: 100.0000 (98.9203)  time: 0.2431  data: 0.0003  max mem: 2912
Test: [Task 5]  [310/625]  eta: 0:01:16  Loss: 0.3069 (0.3262)  Acc@1: 87.5000 (90.1929)  Acc@5: 100.0000 (98.9148)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 5]  [320/625]  eta: 0:01:14  Loss: 0.2966 (0.3260)  Acc@1: 93.7500 (90.2453)  Acc@5: 100.0000 (98.9291)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 5]  [330/625]  eta: 0:01:11  Loss: 0.2983 (0.3273)  Acc@1: 93.7500 (90.1624)  Acc@5: 100.0000 (98.9237)  time: 0.2427  data: 0.0003  max mem: 2912
Test: [Task 5]  [340/625]  eta: 0:01:09  Loss: 0.2402 (0.3247)  Acc@1: 93.7500 (90.2126)  Acc@5: 100.0000 (98.9370)  time: 0.2428  data: 0.0003  max mem: 2912
Test: [Task 5]  [350/625]  eta: 0:01:07  Loss: 0.2872 (0.3286)  Acc@1: 93.7500 (90.1353)  Acc@5: 100.0000 (98.9316)  time: 0.2426  data: 0.0003  max mem: 2912
Test: [Task 5]  [360/625]  eta: 0:01:04  Loss: 0.3274 (0.3257)  Acc@1: 93.7500 (90.2528)  Acc@5: 100.0000 (98.9612)  time: 0.2436  data: 0.0003  max mem: 2912
Test: [Task 5]  [370/625]  eta: 0:01:02  Loss: 0.1909 (0.3241)  Acc@1: 93.7500 (90.2796)  Acc@5: 100.0000 (98.9555)  time: 0.2433  data: 0.0003  max mem: 2912
Test: [Task 5]  [380/625]  eta: 0:00:59  Loss: 0.2603 (0.3272)  Acc@1: 87.5000 (90.1903)  Acc@5: 100.0000 (98.9009)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 5]  [390/625]  eta: 0:00:57  Loss: 0.3055 (0.3273)  Acc@1: 87.5000 (90.1375)  Acc@5: 100.0000 (98.9130)  time: 0.2418  data: 0.0003  max mem: 2912
Test: [Task 5]  [400/625]  eta: 0:00:54  Loss: 0.2379 (0.3253)  Acc@1: 87.5000 (90.2431)  Acc@5: 100.0000 (98.9246)  time: 0.2416  data: 0.0002  max mem: 2912
Test: [Task 5]  [410/625]  eta: 0:00:52  Loss: 0.2779 (0.3251)  Acc@1: 93.7500 (90.2524)  Acc@5: 100.0000 (98.9051)  time: 0.2419  data: 0.0002  max mem: 2912
Test: [Task 5]  [420/625]  eta: 0:00:49  Loss: 0.3245 (0.3254)  Acc@1: 87.5000 (90.1871)  Acc@5: 100.0000 (98.9163)  time: 0.2422  data: 0.0003  max mem: 2912
Test: [Task 5]  [430/625]  eta: 0:00:47  Loss: 0.3060 (0.3243)  Acc@1: 87.5000 (90.2262)  Acc@5: 100.0000 (98.9414)  time: 0.2419  data: 0.0003  max mem: 2912
Test: [Task 5]  [440/625]  eta: 0:00:45  Loss: 0.2364 (0.3233)  Acc@1: 93.7500 (90.2353)  Acc@5: 100.0000 (98.9512)  time: 0.2440  data: 0.0003  max mem: 2912
Test: [Task 5]  [450/625]  eta: 0:00:42  Loss: 0.2558 (0.3224)  Acc@1: 87.5000 (90.2162)  Acc@5: 100.0000 (98.9745)  time: 0.2454  data: 0.0003  max mem: 2912
Test: [Task 5]  [460/625]  eta: 0:00:40  Loss: 0.2767 (0.3211)  Acc@1: 87.5000 (90.2251)  Acc@5: 100.0000 (98.9967)  time: 0.2454  data: 0.0003  max mem: 2912
Test: [Task 5]  [470/625]  eta: 0:00:37  Loss: 0.2104 (0.3176)  Acc@1: 93.7500 (90.3397)  Acc@5: 100.0000 (99.0180)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 5]  [480/625]  eta: 0:00:35  Loss: 0.1478 (0.3158)  Acc@1: 93.7500 (90.3976)  Acc@5: 100.0000 (99.0255)  time: 0.2441  data: 0.0004  max mem: 2912
Test: [Task 5]  [490/625]  eta: 0:00:32  Loss: 0.2396 (0.3148)  Acc@1: 93.7500 (90.4404)  Acc@5: 100.0000 (99.0199)  time: 0.2449  data: 0.0004  max mem: 2912
Test: [Task 5]  [500/625]  eta: 0:00:30  Loss: 0.3214 (0.3154)  Acc@1: 87.5000 (90.4192)  Acc@5: 100.0000 (98.9895)  time: 0.2439  data: 0.0004  max mem: 2912
Test: [Task 5]  [510/625]  eta: 0:00:28  Loss: 0.3214 (0.3151)  Acc@1: 93.7500 (90.4354)  Acc@5: 100.0000 (98.9971)  time: 0.2461  data: 0.0005  max mem: 2912
Test: [Task 5]  [520/625]  eta: 0:00:25  Loss: 0.2672 (0.3135)  Acc@1: 93.7500 (90.4511)  Acc@5: 100.0000 (99.0163)  time: 0.2451  data: 0.0005  max mem: 2912
Test: [Task 5]  [530/625]  eta: 0:00:23  Loss: 0.2013 (0.3110)  Acc@1: 93.7500 (90.5603)  Acc@5: 100.0000 (99.0231)  time: 0.2431  data: 0.0004  max mem: 2912
Test: [Task 5]  [540/625]  eta: 0:00:20  Loss: 0.2176 (0.3110)  Acc@1: 93.7500 (90.5730)  Acc@5: 100.0000 (99.0296)  time: 0.2442  data: 0.0003  max mem: 2912
Test: [Task 5]  [550/625]  eta: 0:00:18  Loss: 0.2720 (0.3116)  Acc@1: 93.7500 (90.5626)  Acc@5: 100.0000 (99.0358)  time: 0.2457  data: 0.0004  max mem: 2912
Test: [Task 5]  [560/625]  eta: 0:00:15  Loss: 0.2720 (0.3131)  Acc@1: 87.5000 (90.5414)  Acc@5: 100.0000 (99.0085)  time: 0.2452  data: 0.0004  max mem: 2912
Test: [Task 5]  [570/625]  eta: 0:00:13  Loss: 0.2888 (0.3134)  Acc@1: 87.5000 (90.5429)  Acc@5: 100.0000 (99.0149)  time: 0.2436  data: 0.0004  max mem: 2912
Test: [Task 5]  [580/625]  eta: 0:00:10  Loss: 0.3091 (0.3147)  Acc@1: 87.5000 (90.5336)  Acc@5: 100.0000 (98.9996)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 5]  [590/625]  eta: 0:00:08  Loss: 0.3455 (0.3141)  Acc@1: 87.5000 (90.5457)  Acc@5: 100.0000 (98.9848)  time: 0.2439  data: 0.0003  max mem: 2912
Test: [Task 5]  [600/625]  eta: 0:00:06  Loss: 0.3455 (0.3137)  Acc@1: 93.7500 (90.5886)  Acc@5: 100.0000 (98.9809)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.2511 (0.3127)  Acc@1: 93.7500 (90.5994)  Acc@5: 100.0000 (98.9771)  time: 0.2438  data: 0.0003  max mem: 2912
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.1989 (0.3108)  Acc@1: 93.7500 (90.6703)  Acc@5: 100.0000 (98.9734)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.2511 (0.3118)  Acc@1: 93.7500 (90.6400)  Acc@5: 100.0000 (98.9700)  time: 0.2437  data: 0.0003  max mem: 2912
Test: [Task 5] Total time: 0:02:32 (0.2441 s / it)
* Acc@1 90.640 Acc@5 98.970 loss 0.312
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 26032, 5: 26032, 6: 26032, 7: 26032, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 10000, 13: 10000, 14: 10000, 15: 10000, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000, 20: 10000, 21: 10000, 22: 10000, 23: 10000, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 459, 25: 459, 26: 459, 27: 459, 28: 459, 29: 459, 30: 459, 31: 459, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 10000, 33: 10000, 34: 10000, 35: 10000, 36: 10000, 37: 10000, 38: 10000, 39: 10000}}
[Average accuracy till task5]	Acc@1: 84.3753	Acc@5: 95.8019	Loss: 0.5739	Forgetting: 3.0127	Backward: -3.0127
Total training time: 9:47:59
