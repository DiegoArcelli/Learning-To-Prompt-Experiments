/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=1, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./test_dir', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint='False', pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=False, train_type='l2p', eval_task_id=False, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=True, prompts_per_task=4, prompts_per_class=1)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 207410
Start training for 1 epochs
Train: Epoch[1/1]  [   0/4579]  eta: 2:31:09  Lr: 0.001875  Loss: 0.9925  Acc@1: 12.5000 (12.5000)  Acc@5: 68.7500 (68.7500)  time: 1.9806  data: 0.4112  max mem: 2497
Train: Epoch[1/1]  [  10/4579]  eta: 0:37:34  Lr: 0.001875  Loss: 1.0045  Acc@1: 18.7500 (15.9091)  Acc@5: 50.0000 (57.3864)  time: 0.4935  data: 0.0377  max mem: 2500
Train: Epoch[1/1]  [  20/4579]  eta: 0:32:08  Lr: 0.001875  Loss: 1.3641  Acc@1: 12.5000 (14.8810)  Acc@5: 56.2500 (60.4167)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [  30/4579]  eta: 0:30:11  Lr: 0.001875  Loss: 0.6091  Acc@1: 18.7500 (17.9435)  Acc@5: 62.5000 (61.0887)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [  40/4579]  eta: 0:29:07  Lr: 0.001875  Loss: 0.7373  Acc@1: 25.0000 (19.2073)  Acc@5: 68.7500 (63.4146)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [  50/4579]  eta: 0:28:29  Lr: 0.001875  Loss: 0.6680  Acc@1: 25.0000 (20.5882)  Acc@5: 68.7500 (63.6029)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [  60/4579]  eta: 0:28:01  Lr: 0.001875  Loss: 0.9832  Acc@1: 25.0000 (21.9262)  Acc@5: 68.7500 (64.7541)  time: 0.3458  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [  70/4579]  eta: 0:27:40  Lr: 0.001875  Loss: 0.8714  Acc@1: 25.0000 (22.5352)  Acc@5: 75.0000 (65.8451)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [  80/4579]  eta: 0:27:24  Lr: 0.001875  Loss: 0.6316  Acc@1: 31.2500 (24.1512)  Acc@5: 75.0000 (67.2068)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [  90/4579]  eta: 0:27:10  Lr: 0.001875  Loss: 0.7356  Acc@1: 31.2500 (24.7253)  Acc@5: 75.0000 (68.1319)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 100/4579]  eta: 0:26:58  Lr: 0.001875  Loss: 0.7814  Acc@1: 31.2500 (25.4332)  Acc@5: 75.0000 (68.5025)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 110/4579]  eta: 0:26:48  Lr: 0.001875  Loss: 0.5710  Acc@1: 31.2500 (26.3514)  Acc@5: 75.0000 (69.1441)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 120/4579]  eta: 0:26:40  Lr: 0.001875  Loss: 0.6651  Acc@1: 31.2500 (26.5496)  Acc@5: 75.0000 (69.5764)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 130/4579]  eta: 0:26:33  Lr: 0.001875  Loss: 0.5410  Acc@1: 31.2500 (26.7176)  Acc@5: 75.0000 (69.9427)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 140/4579]  eta: 0:26:27  Lr: 0.001875  Loss: 0.8369  Acc@1: 31.2500 (26.9947)  Acc@5: 75.0000 (70.4344)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 150/4579]  eta: 0:26:21  Lr: 0.001875  Loss: 0.3324  Acc@1: 31.2500 (27.2351)  Acc@5: 75.0000 (71.1507)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 160/4579]  eta: 0:26:14  Lr: 0.001875  Loss: 0.6214  Acc@1: 37.5000 (27.7562)  Acc@5: 81.2500 (71.6615)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 170/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 0.8627  Acc@1: 37.5000 (28.1067)  Acc@5: 81.2500 (72.1857)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 180/4579]  eta: 0:26:03  Lr: 0.001875  Loss: 0.6204  Acc@1: 37.5000 (28.5912)  Acc@5: 81.2500 (72.6519)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [ 190/4579]  eta: 0:25:57  Lr: 0.001875  Loss: 0.5705  Acc@1: 37.5000 (29.2539)  Acc@5: 81.2500 (73.3312)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [ 200/4579]  eta: 0:25:52  Lr: 0.001875  Loss: 0.7916  Acc@1: 37.5000 (29.5709)  Acc@5: 81.2500 (73.3520)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 210/4579]  eta: 0:25:48  Lr: 0.001875  Loss: 0.6601  Acc@1: 37.5000 (29.7986)  Acc@5: 75.0000 (73.4301)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [ 220/4579]  eta: 0:25:43  Lr: 0.001875  Loss: 0.5687  Acc@1: 37.5000 (30.0057)  Acc@5: 81.2500 (73.7557)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [ 230/4579]  eta: 0:25:38  Lr: 0.001875  Loss: 0.4809  Acc@1: 31.2500 (30.1948)  Acc@5: 81.2500 (74.1342)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [ 240/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 0.9214  Acc@1: 31.2500 (30.2127)  Acc@5: 75.0000 (74.0923)  time: 0.3481  data: 0.0014  max mem: 2500
Train: Epoch[1/1]  [ 250/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 0.6364  Acc@1: 37.5000 (30.4034)  Acc@5: 75.0000 (74.3526)  time: 0.3480  data: 0.0019  max mem: 2500
Train: Epoch[1/1]  [ 260/4579]  eta: 0:25:24  Lr: 0.001875  Loss: 0.7305  Acc@1: 37.5000 (30.4837)  Acc@5: 81.2500 (74.6887)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[1/1]  [ 270/4579]  eta: 0:25:20  Lr: 0.001875  Loss: 0.4642  Acc@1: 31.2500 (30.5581)  Acc@5: 81.2500 (74.7232)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 280/4579]  eta: 0:25:15  Lr: 0.001875  Loss: 0.5570  Acc@1: 37.5000 (30.9386)  Acc@5: 75.0000 (74.7553)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 290/4579]  eta: 0:25:11  Lr: 0.001875  Loss: 0.5910  Acc@1: 37.5000 (31.2930)  Acc@5: 81.2500 (75.0215)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 300/4579]  eta: 0:25:07  Lr: 0.001875  Loss: 0.5028  Acc@1: 31.2500 (31.3953)  Acc@5: 87.5000 (75.3530)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 310/4579]  eta: 0:25:03  Lr: 0.001875  Loss: 0.6322  Acc@1: 37.5000 (31.7323)  Acc@5: 87.5000 (75.6029)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 320/4579]  eta: 0:24:59  Lr: 0.001875  Loss: 0.3970  Acc@1: 37.5000 (31.8925)  Acc@5: 87.5000 (75.9540)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 330/4579]  eta: 0:24:55  Lr: 0.001875  Loss: 0.1911  Acc@1: 37.5000 (32.1375)  Acc@5: 81.2500 (76.1140)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 340/4579]  eta: 0:24:51  Lr: 0.001875  Loss: 0.4648  Acc@1: 37.5000 (32.3680)  Acc@5: 87.5000 (76.4479)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 350/4579]  eta: 0:24:47  Lr: 0.001875  Loss: 0.0002  Acc@1: 37.5000 (32.4964)  Acc@5: 87.5000 (76.6204)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 360/4579]  eta: 0:24:43  Lr: 0.001875  Loss: 0.8327  Acc@1: 37.5000 (32.6697)  Acc@5: 81.2500 (76.8179)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 370/4579]  eta: 0:24:40  Lr: 0.001875  Loss: 0.6638  Acc@1: 37.5000 (32.8673)  Acc@5: 81.2500 (76.9542)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 380/4579]  eta: 0:24:36  Lr: 0.001875  Loss: 0.7233  Acc@1: 37.5000 (33.0709)  Acc@5: 81.2500 (77.0669)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 390/4579]  eta: 0:24:32  Lr: 0.001875  Loss: 0.0340  Acc@1: 37.5000 (33.3600)  Acc@5: 81.2500 (77.1899)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 400/4579]  eta: 0:24:28  Lr: 0.001875  Loss: 0.0611  Acc@1: 43.7500 (33.6814)  Acc@5: 81.2500 (77.3379)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 410/4579]  eta: 0:24:25  Lr: 0.001875  Loss: 0.2443  Acc@1: 43.7500 (33.8200)  Acc@5: 87.5000 (77.5547)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 420/4579]  eta: 0:24:21  Lr: 0.001875  Loss: 0.4984  Acc@1: 37.5000 (33.9816)  Acc@5: 81.2500 (77.5980)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 430/4579]  eta: 0:24:17  Lr: 0.001875  Loss: 0.4503  Acc@1: 43.7500 (34.2662)  Acc@5: 81.2500 (77.8132)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 440/4579]  eta: 0:24:14  Lr: 0.001875  Loss: -0.1543  Acc@1: 43.7500 (34.5947)  Acc@5: 87.5000 (78.0754)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 450/4579]  eta: 0:24:10  Lr: 0.001875  Loss: 0.1850  Acc@1: 43.7500 (34.9224)  Acc@5: 87.5000 (78.3398)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 460/4579]  eta: 0:24:06  Lr: 0.001875  Loss: 0.2882  Acc@1: 50.0000 (35.1546)  Acc@5: 87.5000 (78.5385)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 470/4579]  eta: 0:24:03  Lr: 0.001875  Loss: 0.4569  Acc@1: 43.7500 (35.2972)  Acc@5: 87.5000 (78.7155)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 480/4579]  eta: 0:23:59  Lr: 0.001875  Loss: 0.4520  Acc@1: 43.7500 (35.4340)  Acc@5: 81.2500 (78.7942)  time: 0.3498  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 490/4579]  eta: 0:23:55  Lr: 0.001875  Loss: 0.5755  Acc@1: 43.7500 (35.6670)  Acc@5: 81.2500 (78.8315)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 500/4579]  eta: 0:23:52  Lr: 0.001875  Loss: 0.4851  Acc@1: 43.7500 (35.7909)  Acc@5: 81.2500 (78.8922)  time: 0.3506  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 510/4579]  eta: 0:23:48  Lr: 0.001875  Loss: 0.4303  Acc@1: 50.0000 (36.1179)  Acc@5: 81.2500 (79.0117)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 520/4579]  eta: 0:23:45  Lr: 0.001875  Loss: -0.2223  Acc@1: 50.0000 (36.3844)  Acc@5: 87.5000 (79.1867)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 530/4579]  eta: 0:23:41  Lr: 0.001875  Loss: 0.2062  Acc@1: 43.7500 (36.4878)  Acc@5: 87.5000 (79.2491)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 540/4579]  eta: 0:23:38  Lr: 0.001875  Loss: 0.3627  Acc@1: 43.7500 (36.6913)  Acc@5: 87.5000 (79.3785)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 550/4579]  eta: 0:23:34  Lr: 0.001875  Loss: 0.5663  Acc@1: 43.7500 (36.8194)  Acc@5: 87.5000 (79.4011)  time: 0.3526  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 560/4579]  eta: 0:23:31  Lr: 0.001875  Loss: 0.4710  Acc@1: 37.5000 (36.9095)  Acc@5: 87.5000 (79.5566)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 570/4579]  eta: 0:23:27  Lr: 0.001875  Loss: 0.3378  Acc@1: 50.0000 (37.1497)  Acc@5: 87.5000 (79.7067)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 580/4579]  eta: 0:23:24  Lr: 0.001875  Loss: 0.3870  Acc@1: 50.0000 (37.2096)  Acc@5: 87.5000 (79.8731)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 590/4579]  eta: 0:23:20  Lr: 0.001875  Loss: 0.4253  Acc@1: 37.5000 (37.3731)  Acc@5: 87.5000 (79.9704)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 600/4579]  eta: 0:23:17  Lr: 0.001875  Loss: 0.1141  Acc@1: 50.0000 (37.6456)  Acc@5: 87.5000 (80.0853)  time: 0.3505  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 610/4579]  eta: 0:23:13  Lr: 0.001875  Loss: 0.0790  Acc@1: 50.0000 (37.7455)  Acc@5: 81.2500 (80.0941)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 620/4579]  eta: 0:23:09  Lr: 0.001875  Loss: 0.5994  Acc@1: 43.7500 (37.8623)  Acc@5: 81.2500 (80.2134)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 630/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 0.5126  Acc@1: 37.5000 (37.9259)  Acc@5: 87.5000 (80.2100)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 640/4579]  eta: 0:23:02  Lr: 0.001875  Loss: -0.2035  Acc@1: 37.5000 (38.0460)  Acc@5: 87.5000 (80.3725)  time: 0.3512  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 650/4579]  eta: 0:22:59  Lr: 0.001875  Loss: 0.4043  Acc@1: 43.7500 (38.1432)  Acc@5: 87.5000 (80.4531)  time: 0.3503  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 660/4579]  eta: 0:22:55  Lr: 0.001875  Loss: 0.6964  Acc@1: 43.7500 (38.2281)  Acc@5: 87.5000 (80.4841)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 670/4579]  eta: 0:22:52  Lr: 0.001875  Loss: 0.5646  Acc@1: 43.7500 (38.2638)  Acc@5: 81.2500 (80.5607)  time: 0.3522  data: 0.0011  max mem: 2500
Train: Epoch[1/1]  [ 680/4579]  eta: 0:22:49  Lr: 0.001875  Loss: 0.4381  Acc@1: 50.0000 (38.4453)  Acc@5: 87.5000 (80.6810)  time: 0.3519  data: 0.0012  max mem: 2500
Train: Epoch[1/1]  [ 690/4579]  eta: 0:22:45  Lr: 0.001875  Loss: 0.2618  Acc@1: 50.0000 (38.5854)  Acc@5: 87.5000 (80.7706)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [ 700/4579]  eta: 0:22:42  Lr: 0.001875  Loss: 0.3563  Acc@1: 50.0000 (38.6769)  Acc@5: 87.5000 (80.8755)  time: 0.3520  data: 0.0014  max mem: 2500
Train: Epoch[1/1]  [ 710/4579]  eta: 0:22:38  Lr: 0.001875  Loss: 0.2785  Acc@1: 43.7500 (38.6691)  Acc@5: 87.5000 (80.9072)  time: 0.3532  data: 0.0021  max mem: 2500
Train: Epoch[1/1]  [ 720/4579]  eta: 0:22:35  Lr: 0.001875  Loss: 0.4199  Acc@1: 43.7500 (38.8089)  Acc@5: 81.2500 (80.9639)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[1/1]  [ 730/4579]  eta: 0:22:31  Lr: 0.001875  Loss: 0.2392  Acc@1: 50.0000 (38.9022)  Acc@5: 87.5000 (81.0363)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 740/4579]  eta: 0:22:28  Lr: 0.001875  Loss: 0.2599  Acc@1: 50.0000 (39.1026)  Acc@5: 87.5000 (81.1066)  time: 0.3513  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 750/4579]  eta: 0:22:24  Lr: 0.001875  Loss: 0.4830  Acc@1: 50.0000 (39.1977)  Acc@5: 87.5000 (81.1751)  time: 0.3515  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 760/4579]  eta: 0:22:21  Lr: 0.001875  Loss: 0.0404  Acc@1: 50.0000 (39.3479)  Acc@5: 87.5000 (81.2911)  time: 0.3508  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 770/4579]  eta: 0:22:17  Lr: 0.001875  Loss: 0.4092  Acc@1: 43.7500 (39.4131)  Acc@5: 87.5000 (81.3473)  time: 0.3506  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 780/4579]  eta: 0:22:14  Lr: 0.001875  Loss: 0.7021  Acc@1: 43.7500 (39.5567)  Acc@5: 81.2500 (81.3540)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 790/4579]  eta: 0:22:10  Lr: 0.001875  Loss: 0.0137  Acc@1: 50.0000 (39.6255)  Acc@5: 87.5000 (81.4238)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 800/4579]  eta: 0:22:07  Lr: 0.001875  Loss: 0.5268  Acc@1: 50.0000 (39.7862)  Acc@5: 87.5000 (81.5153)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 810/4579]  eta: 0:22:03  Lr: 0.001875  Loss: 0.1450  Acc@1: 50.0000 (39.8505)  Acc@5: 87.5000 (81.6199)  time: 0.3519  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 820/4579]  eta: 0:22:00  Lr: 0.001875  Loss: -0.0149  Acc@1: 50.0000 (40.0350)  Acc@5: 87.5000 (81.6839)  time: 0.3533  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 830/4579]  eta: 0:21:56  Lr: 0.001875  Loss: -0.1374  Acc@1: 56.2500 (40.1324)  Acc@5: 87.5000 (81.7840)  time: 0.3529  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 840/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 0.7000  Acc@1: 56.2500 (40.2497)  Acc@5: 87.5000 (81.8445)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 850/4579]  eta: 0:21:49  Lr: 0.001875  Loss: 0.3133  Acc@1: 50.0000 (40.3202)  Acc@5: 87.5000 (81.8816)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 860/4579]  eta: 0:21:46  Lr: 0.001875  Loss: 0.2633  Acc@1: 50.0000 (40.4399)  Acc@5: 81.2500 (81.9178)  time: 0.3514  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 870/4579]  eta: 0:21:42  Lr: 0.001875  Loss: 0.0394  Acc@1: 50.0000 (40.4779)  Acc@5: 87.5000 (81.9891)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [ 880/4579]  eta: 0:21:39  Lr: 0.001875  Loss: 0.6150  Acc@1: 43.7500 (40.5647)  Acc@5: 87.5000 (82.0375)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [ 890/4579]  eta: 0:21:36  Lr: 0.001875  Loss: 0.4190  Acc@1: 50.0000 (40.6425)  Acc@5: 87.5000 (82.1268)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 900/4579]  eta: 0:21:32  Lr: 0.001875  Loss: 0.2894  Acc@1: 50.0000 (40.7950)  Acc@5: 87.5000 (82.1379)  time: 0.3534  data: 0.0011  max mem: 2500
Train: Epoch[1/1]  [ 910/4579]  eta: 0:21:29  Lr: 0.001875  Loss: 0.2563  Acc@1: 50.0000 (40.8548)  Acc@5: 81.2500 (82.1830)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[1/1]  [ 920/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 0.6181  Acc@1: 43.7500 (40.8455)  Acc@5: 81.2500 (82.2068)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 930/4579]  eta: 0:21:22  Lr: 0.001875  Loss: 0.5288  Acc@1: 37.5000 (40.8633)  Acc@5: 81.2500 (82.2771)  time: 0.3529  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 940/4579]  eta: 0:21:18  Lr: 0.001875  Loss: -0.1432  Acc@1: 43.7500 (40.9338)  Acc@5: 87.5000 (82.3459)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [ 950/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.0216  Acc@1: 43.7500 (40.9109)  Acc@5: 87.5000 (82.3672)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [ 960/4579]  eta: 0:21:11  Lr: 0.001875  Loss: 0.0275  Acc@1: 43.7500 (40.9990)  Acc@5: 87.5000 (82.4272)  time: 0.3516  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 970/4579]  eta: 0:21:08  Lr: 0.001875  Loss: 0.0603  Acc@1: 50.0000 (41.0852)  Acc@5: 87.5000 (82.4601)  time: 0.3540  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [ 980/4579]  eta: 0:21:04  Lr: 0.001875  Loss: 0.2209  Acc@1: 50.0000 (41.1634)  Acc@5: 87.5000 (82.5115)  time: 0.3539  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [ 990/4579]  eta: 0:21:01  Lr: 0.001875  Loss: 0.6785  Acc@1: 50.0000 (41.2462)  Acc@5: 87.5000 (82.5492)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1000/4579]  eta: 0:20:57  Lr: 0.001875  Loss: -0.1481  Acc@1: 50.0000 (41.3711)  Acc@5: 87.5000 (82.5924)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [1010/4579]  eta: 0:20:54  Lr: 0.001875  Loss: 0.0491  Acc@1: 50.0000 (41.4318)  Acc@5: 87.5000 (82.6286)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1020/4579]  eta: 0:20:50  Lr: 0.001875  Loss: 0.3868  Acc@1: 50.0000 (41.5891)  Acc@5: 87.5000 (82.6824)  time: 0.3514  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1030/4579]  eta: 0:20:47  Lr: 0.001875  Loss: 0.7531  Acc@1: 56.2500 (41.6768)  Acc@5: 87.5000 (82.6988)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1040/4579]  eta: 0:20:43  Lr: 0.001875  Loss: 0.8132  Acc@1: 56.2500 (41.7927)  Acc@5: 87.5000 (82.7750)  time: 0.3529  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [1050/4579]  eta: 0:20:40  Lr: 0.001875  Loss: 0.1296  Acc@1: 50.0000 (41.8471)  Acc@5: 93.7500 (82.8378)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [1060/4579]  eta: 0:20:36  Lr: 0.001875  Loss: -0.2311  Acc@1: 50.0000 (41.9180)  Acc@5: 93.7500 (82.8876)  time: 0.3524  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1070/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.0665  Acc@1: 50.0000 (42.0110)  Acc@5: 93.7500 (82.9540)  time: 0.3524  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1080/4579]  eta: 0:20:29  Lr: 0.001875  Loss: 0.0162  Acc@1: 56.2500 (42.1311)  Acc@5: 93.7500 (83.0076)  time: 0.3517  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1090/4579]  eta: 0:20:26  Lr: 0.001875  Loss: 0.0903  Acc@1: 50.0000 (42.1975)  Acc@5: 87.5000 (83.0259)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1100/4579]  eta: 0:20:22  Lr: 0.001875  Loss: 0.4031  Acc@1: 50.0000 (42.2854)  Acc@5: 87.5000 (83.0665)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1110/4579]  eta: 0:20:19  Lr: 0.001875  Loss: -0.0260  Acc@1: 50.0000 (42.3886)  Acc@5: 87.5000 (83.0896)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1120/4579]  eta: 0:20:15  Lr: 0.001875  Loss: 0.0242  Acc@1: 56.2500 (42.4900)  Acc@5: 87.5000 (83.1456)  time: 0.3524  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1130/4579]  eta: 0:20:12  Lr: 0.001875  Loss: 0.0265  Acc@1: 50.0000 (42.5287)  Acc@5: 87.5000 (83.2118)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1140/4579]  eta: 0:20:08  Lr: 0.001875  Loss: -0.0617  Acc@1: 43.7500 (42.5613)  Acc@5: 87.5000 (83.2439)  time: 0.3533  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1150/4579]  eta: 0:20:05  Lr: 0.001875  Loss: 0.2246  Acc@1: 50.0000 (42.6423)  Acc@5: 87.5000 (83.2591)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1160/4579]  eta: 0:20:01  Lr: 0.001875  Loss: -0.3698  Acc@1: 56.2500 (42.7756)  Acc@5: 87.5000 (83.3226)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1170/4579]  eta: 0:19:58  Lr: 0.001875  Loss: -0.0041  Acc@1: 56.2500 (42.8213)  Acc@5: 87.5000 (83.3422)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1180/4579]  eta: 0:19:54  Lr: 0.001875  Loss: 0.5824  Acc@1: 50.0000 (42.8927)  Acc@5: 87.5000 (83.3774)  time: 0.3509  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1190/4579]  eta: 0:19:51  Lr: 0.001875  Loss: -0.1065  Acc@1: 43.7500 (42.9209)  Acc@5: 87.5000 (83.4016)  time: 0.3515  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1200/4579]  eta: 0:19:47  Lr: 0.001875  Loss: 0.6917  Acc@1: 50.0000 (43.0058)  Acc@5: 87.5000 (83.4305)  time: 0.3512  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1210/4579]  eta: 0:19:44  Lr: 0.001875  Loss: 0.0701  Acc@1: 56.2500 (43.1307)  Acc@5: 87.5000 (83.5002)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1220/4579]  eta: 0:19:40  Lr: 0.001875  Loss: 0.1748  Acc@1: 56.2500 (43.2637)  Acc@5: 93.7500 (83.5534)  time: 0.3504  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1230/4579]  eta: 0:19:37  Lr: 0.001875  Loss: -0.0665  Acc@1: 56.2500 (43.3489)  Acc@5: 93.7500 (83.6210)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1240/4579]  eta: 0:19:33  Lr: 0.001875  Loss: 0.2865  Acc@1: 56.2500 (43.4529)  Acc@5: 93.7500 (83.6573)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1250/4579]  eta: 0:19:30  Lr: 0.001875  Loss: 0.2990  Acc@1: 50.0000 (43.5002)  Acc@5: 87.5000 (83.6880)  time: 0.3505  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1260/4579]  eta: 0:19:26  Lr: 0.001875  Loss: 0.1016  Acc@1: 50.0000 (43.5319)  Acc@5: 87.5000 (83.6985)  time: 0.3507  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1270/4579]  eta: 0:19:23  Lr: 0.001875  Loss: 0.1658  Acc@1: 50.0000 (43.6369)  Acc@5: 87.5000 (83.7480)  time: 0.3509  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1280/4579]  eta: 0:19:19  Lr: 0.001875  Loss: 0.1353  Acc@1: 56.2500 (43.7207)  Acc@5: 87.5000 (83.7822)  time: 0.3514  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1290/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.1397  Acc@1: 56.2500 (43.8033)  Acc@5: 87.5000 (83.8207)  time: 0.3515  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1300/4579]  eta: 0:19:12  Lr: 0.001875  Loss: -0.3097  Acc@1: 50.0000 (43.8269)  Acc@5: 93.7500 (83.8682)  time: 0.3536  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1310/4579]  eta: 0:19:09  Lr: 0.001875  Loss: -0.0790  Acc@1: 50.0000 (43.9359)  Acc@5: 87.5000 (83.8863)  time: 0.3530  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1320/4579]  eta: 0:19:05  Lr: 0.001875  Loss: -0.1074  Acc@1: 50.0000 (43.9960)  Acc@5: 87.5000 (83.9232)  time: 0.3518  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1330/4579]  eta: 0:19:02  Lr: 0.001875  Loss: -0.4964  Acc@1: 50.0000 (44.1022)  Acc@5: 93.7500 (83.9735)  time: 0.3523  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1340/4579]  eta: 0:18:58  Lr: 0.001875  Loss: 0.1738  Acc@1: 50.0000 (44.1508)  Acc@5: 93.7500 (84.0371)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1350/4579]  eta: 0:18:55  Lr: 0.001875  Loss: 0.1830  Acc@1: 50.0000 (44.1849)  Acc@5: 93.7500 (84.0489)  time: 0.3519  data: 0.0010  max mem: 2500
Train: Epoch[1/1]  [1360/4579]  eta: 0:18:51  Lr: 0.001875  Loss: 0.4545  Acc@1: 50.0000 (44.2506)  Acc@5: 87.5000 (84.0834)  time: 0.3527  data: 0.0010  max mem: 2500
Train: Epoch[1/1]  [1370/4579]  eta: 0:18:48  Lr: 0.001875  Loss: -0.1253  Acc@1: 50.0000 (44.3107)  Acc@5: 87.5000 (84.1129)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1380/4579]  eta: 0:18:44  Lr: 0.001875  Loss: -0.1872  Acc@1: 56.2500 (44.3927)  Acc@5: 87.5000 (84.1465)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1390/4579]  eta: 0:18:41  Lr: 0.001875  Loss: 0.1688  Acc@1: 50.0000 (44.4105)  Acc@5: 93.7500 (84.2110)  time: 0.3509  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1400/4579]  eta: 0:18:37  Lr: 0.001875  Loss: 0.1080  Acc@1: 50.0000 (44.4593)  Acc@5: 93.7500 (84.2523)  time: 0.3520  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1410/4579]  eta: 0:18:34  Lr: 0.001875  Loss: -0.1319  Acc@1: 50.0000 (44.4809)  Acc@5: 87.5000 (84.2576)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1420/4579]  eta: 0:18:30  Lr: 0.001875  Loss: 0.2126  Acc@1: 50.0000 (44.5417)  Acc@5: 87.5000 (84.3024)  time: 0.3517  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1430/4579]  eta: 0:18:27  Lr: 0.001875  Loss: 0.2546  Acc@1: 50.0000 (44.5798)  Acc@5: 87.5000 (84.3204)  time: 0.3512  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1440/4579]  eta: 0:18:23  Lr: 0.001875  Loss: -0.1063  Acc@1: 50.0000 (44.6695)  Acc@5: 87.5000 (84.3468)  time: 0.3519  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1450/4579]  eta: 0:18:19  Lr: 0.001875  Loss: -0.1531  Acc@1: 56.2500 (44.7665)  Acc@5: 87.5000 (84.3556)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1460/4579]  eta: 0:18:16  Lr: 0.001875  Loss: -0.0291  Acc@1: 50.0000 (44.7810)  Acc@5: 81.2500 (84.3557)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1470/4579]  eta: 0:18:13  Lr: 0.001875  Loss: -0.3100  Acc@1: 50.0000 (44.8674)  Acc@5: 87.5000 (84.4154)  time: 0.3532  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1480/4579]  eta: 0:18:09  Lr: 0.001875  Loss: 0.0319  Acc@1: 56.2500 (44.9485)  Acc@5: 87.5000 (84.4151)  time: 0.3535  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1490/4579]  eta: 0:18:06  Lr: 0.001875  Loss: -0.1676  Acc@1: 56.2500 (44.9908)  Acc@5: 87.5000 (84.4442)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1500/4579]  eta: 0:18:02  Lr: 0.001875  Loss: 0.1702  Acc@1: 56.2500 (45.0408)  Acc@5: 87.5000 (84.4520)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1510/4579]  eta: 0:17:59  Lr: 0.001875  Loss: -0.1260  Acc@1: 56.2500 (45.1191)  Acc@5: 87.5000 (84.5012)  time: 0.3537  data: 0.0011  max mem: 2500
Train: Epoch[1/1]  [1520/4579]  eta: 0:17:55  Lr: 0.001875  Loss: 0.0105  Acc@1: 56.2500 (45.1923)  Acc@5: 93.7500 (84.5455)  time: 0.3536  data: 0.0010  max mem: 2500
Train: Epoch[1/1]  [1530/4579]  eta: 0:17:52  Lr: 0.001875  Loss: 0.1331  Acc@1: 50.0000 (45.2155)  Acc@5: 93.7500 (84.5648)  time: 0.3513  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1540/4579]  eta: 0:17:48  Lr: 0.001875  Loss: -0.2359  Acc@1: 50.0000 (45.2304)  Acc@5: 87.5000 (84.6001)  time: 0.3509  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1550/4579]  eta: 0:17:44  Lr: 0.001875  Loss: -0.1730  Acc@1: 56.2500 (45.3216)  Acc@5: 87.5000 (84.6389)  time: 0.3512  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1560/4579]  eta: 0:17:41  Lr: 0.001875  Loss: 0.1657  Acc@1: 56.2500 (45.4196)  Acc@5: 93.7500 (84.6853)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1570/4579]  eta: 0:17:37  Lr: 0.001875  Loss: 0.4604  Acc@1: 56.2500 (45.4328)  Acc@5: 93.7500 (84.7231)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1580/4579]  eta: 0:17:34  Lr: 0.001875  Loss: -0.2615  Acc@1: 50.0000 (45.4973)  Acc@5: 87.5000 (84.7367)  time: 0.3519  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1590/4579]  eta: 0:17:30  Lr: 0.001875  Loss: -0.0859  Acc@1: 50.0000 (45.4981)  Acc@5: 87.5000 (84.7541)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [1600/4579]  eta: 0:17:27  Lr: 0.001875  Loss: 0.0647  Acc@1: 50.0000 (45.5809)  Acc@5: 87.5000 (84.7751)  time: 0.3545  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [1610/4579]  eta: 0:17:24  Lr: 0.001875  Loss: 0.4208  Acc@1: 56.2500 (45.6510)  Acc@5: 87.5000 (84.7843)  time: 0.3541  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1620/4579]  eta: 0:17:20  Lr: 0.001875  Loss: 0.3456  Acc@1: 56.2500 (45.6971)  Acc@5: 87.5000 (84.8088)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1630/4579]  eta: 0:17:17  Lr: 0.001875  Loss: 0.0321  Acc@1: 56.2500 (45.7733)  Acc@5: 87.5000 (84.8483)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1640/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 0.0187  Acc@1: 56.2500 (45.8371)  Acc@5: 93.7500 (84.9025)  time: 0.3537  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1650/4579]  eta: 0:17:10  Lr: 0.001875  Loss: -0.3350  Acc@1: 50.0000 (45.8889)  Acc@5: 93.7500 (84.9334)  time: 0.3543  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1660/4579]  eta: 0:17:06  Lr: 0.001875  Loss: 0.2608  Acc@1: 50.0000 (45.9211)  Acc@5: 87.5000 (84.9714)  time: 0.3526  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1670/4579]  eta: 0:17:03  Lr: 0.001875  Loss: -0.3361  Acc@1: 56.2500 (46.0016)  Acc@5: 87.5000 (84.9828)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1680/4579]  eta: 0:16:59  Lr: 0.001875  Loss: 0.1560  Acc@1: 50.0000 (46.0068)  Acc@5: 87.5000 (84.9755)  time: 0.3547  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1690/4579]  eta: 0:16:56  Lr: 0.001875  Loss: -0.1753  Acc@1: 50.0000 (46.0674)  Acc@5: 87.5000 (84.9830)  time: 0.3543  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1700/4579]  eta: 0:16:52  Lr: 0.001875  Loss: 0.0761  Acc@1: 56.2500 (46.1567)  Acc@5: 87.5000 (85.0088)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1710/4579]  eta: 0:16:49  Lr: 0.001875  Loss: 0.8073  Acc@1: 43.7500 (46.1499)  Acc@5: 87.5000 (85.0197)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [1720/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.4110  Acc@1: 43.7500 (46.2231)  Acc@5: 87.5000 (85.0414)  time: 0.3548  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1730/4579]  eta: 0:16:42  Lr: 0.001875  Loss: 0.0121  Acc@1: 56.2500 (46.2594)  Acc@5: 87.5000 (85.0737)  time: 0.3536  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1740/4579]  eta: 0:16:38  Lr: 0.001875  Loss: 0.2556  Acc@1: 56.2500 (46.2952)  Acc@5: 87.5000 (85.1055)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1750/4579]  eta: 0:16:35  Lr: 0.001875  Loss: 0.6602  Acc@1: 56.2500 (46.3985)  Acc@5: 93.7500 (85.1478)  time: 0.3523  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1760/4579]  eta: 0:16:31  Lr: 0.001875  Loss: 0.1191  Acc@1: 56.2500 (46.4757)  Acc@5: 93.7500 (85.1718)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1770/4579]  eta: 0:16:28  Lr: 0.001875  Loss: -0.0923  Acc@1: 62.5000 (46.5697)  Acc@5: 93.7500 (85.2096)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1780/4579]  eta: 0:16:24  Lr: 0.001875  Loss: -0.0772  Acc@1: 62.5000 (46.6311)  Acc@5: 93.7500 (85.2330)  time: 0.3528  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1790/4579]  eta: 0:16:21  Lr: 0.001875  Loss: 0.3386  Acc@1: 56.2500 (46.6883)  Acc@5: 87.5000 (85.2282)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1800/4579]  eta: 0:16:17  Lr: 0.001875  Loss: 0.2320  Acc@1: 56.2500 (46.7310)  Acc@5: 87.5000 (85.2651)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1810/4579]  eta: 0:16:13  Lr: 0.001875  Loss: 0.4416  Acc@1: 56.2500 (46.7663)  Acc@5: 93.7500 (85.2947)  time: 0.3501  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1820/4579]  eta: 0:16:10  Lr: 0.001875  Loss: -0.2336  Acc@1: 50.0000 (46.7875)  Acc@5: 87.5000 (85.3240)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1830/4579]  eta: 0:16:06  Lr: 0.001875  Loss: -0.0596  Acc@1: 56.2500 (46.8460)  Acc@5: 87.5000 (85.3427)  time: 0.3497  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1840/4579]  eta: 0:16:03  Lr: 0.001875  Loss: 0.2080  Acc@1: 56.2500 (46.9073)  Acc@5: 93.7500 (85.3850)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1850/4579]  eta: 0:15:59  Lr: 0.001875  Loss: 0.3012  Acc@1: 56.2500 (46.9476)  Acc@5: 93.7500 (85.4032)  time: 0.3494  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1860/4579]  eta: 0:15:56  Lr: 0.001875  Loss: 0.1169  Acc@1: 56.2500 (46.9774)  Acc@5: 87.5000 (85.4144)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1870/4579]  eta: 0:15:52  Lr: 0.001875  Loss: -0.3601  Acc@1: 56.2500 (47.0804)  Acc@5: 87.5000 (85.4389)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1880/4579]  eta: 0:15:49  Lr: 0.001875  Loss: -0.3289  Acc@1: 62.5000 (47.1192)  Acc@5: 93.7500 (85.4499)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1890/4579]  eta: 0:15:45  Lr: 0.001875  Loss: -0.3068  Acc@1: 56.2500 (47.1906)  Acc@5: 87.5000 (85.4673)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [1900/4579]  eta: 0:15:42  Lr: 0.001875  Loss: 0.2099  Acc@1: 56.2500 (47.2383)  Acc@5: 87.5000 (85.4748)  time: 0.3536  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1910/4579]  eta: 0:15:38  Lr: 0.001875  Loss: 0.4689  Acc@1: 50.0000 (47.2789)  Acc@5: 87.5000 (85.4755)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1920/4579]  eta: 0:15:35  Lr: 0.001875  Loss: -0.0375  Acc@1: 56.2500 (47.3126)  Acc@5: 87.5000 (85.4828)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1930/4579]  eta: 0:15:31  Lr: 0.001875  Loss: -0.1687  Acc@1: 56.2500 (47.3556)  Acc@5: 87.5000 (85.5062)  time: 0.3520  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [1940/4579]  eta: 0:15:28  Lr: 0.001875  Loss: 0.1407  Acc@1: 56.2500 (47.4143)  Acc@5: 93.7500 (85.5294)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1950/4579]  eta: 0:15:24  Lr: 0.001875  Loss: 0.2899  Acc@1: 56.2500 (47.4660)  Acc@5: 87.5000 (85.5459)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1960/4579]  eta: 0:15:21  Lr: 0.001875  Loss: -0.1740  Acc@1: 56.2500 (47.5108)  Acc@5: 87.5000 (85.5622)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1970/4579]  eta: 0:15:17  Lr: 0.001875  Loss: 0.2109  Acc@1: 50.0000 (47.5425)  Acc@5: 87.5000 (85.5720)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1980/4579]  eta: 0:15:13  Lr: 0.001875  Loss: 0.3259  Acc@1: 56.2500 (47.6148)  Acc@5: 87.5000 (85.5912)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [1990/4579]  eta: 0:15:10  Lr: 0.001875  Loss: -0.1356  Acc@1: 56.2500 (47.6394)  Acc@5: 93.7500 (85.6102)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2000/4579]  eta: 0:15:06  Lr: 0.001875  Loss: -0.0317  Acc@1: 56.2500 (47.7011)  Acc@5: 93.7500 (85.6416)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2010/4579]  eta: 0:15:03  Lr: 0.001875  Loss: -0.0566  Acc@1: 56.2500 (47.7250)  Acc@5: 93.7500 (85.6508)  time: 0.3537  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2020/4579]  eta: 0:14:59  Lr: 0.001875  Loss: 0.7245  Acc@1: 50.0000 (47.7363)  Acc@5: 87.5000 (85.6599)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2030/4579]  eta: 0:14:56  Lr: 0.001875  Loss: 0.0820  Acc@1: 50.0000 (47.7936)  Acc@5: 87.5000 (85.6875)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2040/4579]  eta: 0:14:52  Lr: 0.001875  Loss: 0.4098  Acc@1: 56.2500 (47.8289)  Acc@5: 87.5000 (85.6749)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2050/4579]  eta: 0:14:49  Lr: 0.001875  Loss: 0.0564  Acc@1: 56.2500 (47.8882)  Acc@5: 87.5000 (85.7082)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2060/4579]  eta: 0:14:45  Lr: 0.001875  Loss: 0.2203  Acc@1: 56.2500 (47.9470)  Acc@5: 93.7500 (85.7351)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2070/4579]  eta: 0:14:42  Lr: 0.001875  Loss: -0.3996  Acc@1: 56.2500 (47.9780)  Acc@5: 87.5000 (85.7527)  time: 0.3532  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2080/4579]  eta: 0:14:38  Lr: 0.001875  Loss: 0.2624  Acc@1: 50.0000 (48.0028)  Acc@5: 93.7500 (85.7821)  time: 0.3534  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2090/4579]  eta: 0:14:35  Lr: 0.001875  Loss: 0.3623  Acc@1: 50.0000 (48.0213)  Acc@5: 93.7500 (85.7813)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2100/4579]  eta: 0:14:31  Lr: 0.001875  Loss: 0.4616  Acc@1: 50.0000 (48.0664)  Acc@5: 87.5000 (85.7836)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2110/4579]  eta: 0:14:28  Lr: 0.001875  Loss: 0.4218  Acc@1: 56.2500 (48.1229)  Acc@5: 87.5000 (85.7946)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2120/4579]  eta: 0:14:24  Lr: 0.001875  Loss: 0.0477  Acc@1: 56.2500 (48.1377)  Acc@5: 87.5000 (85.8174)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2130/4579]  eta: 0:14:21  Lr: 0.001875  Loss: 0.0211  Acc@1: 50.0000 (48.1728)  Acc@5: 87.5000 (85.8282)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2140/4579]  eta: 0:14:17  Lr: 0.001875  Loss: 0.3595  Acc@1: 56.2500 (48.1901)  Acc@5: 87.5000 (85.8507)  time: 0.3512  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2150/4579]  eta: 0:14:14  Lr: 0.001875  Loss: -0.1165  Acc@1: 56.2500 (48.2624)  Acc@5: 93.7500 (85.8787)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2160/4579]  eta: 0:14:10  Lr: 0.001875  Loss: 0.1412  Acc@1: 62.5000 (48.3168)  Acc@5: 93.7500 (85.9151)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2170/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.0527  Acc@1: 56.2500 (48.3533)  Acc@5: 93.7500 (85.9224)  time: 0.3529  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2180/4579]  eta: 0:14:03  Lr: 0.001875  Loss: 0.0155  Acc@1: 56.2500 (48.4010)  Acc@5: 87.5000 (85.9325)  time: 0.3524  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2190/4579]  eta: 0:14:00  Lr: 0.001875  Loss: -0.2857  Acc@1: 56.2500 (48.4453)  Acc@5: 87.5000 (85.9396)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2200/4579]  eta: 0:13:56  Lr: 0.001875  Loss: -0.2896  Acc@1: 56.2500 (48.5007)  Acc@5: 87.5000 (85.9666)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2210/4579]  eta: 0:13:53  Lr: 0.001875  Loss: 0.2963  Acc@1: 56.2500 (48.5188)  Acc@5: 87.5000 (85.9566)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2220/4579]  eta: 0:13:49  Lr: 0.001875  Loss: 0.1381  Acc@1: 56.2500 (48.5564)  Acc@5: 81.2500 (85.9551)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2230/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.3104  Acc@1: 56.2500 (48.5825)  Acc@5: 87.5000 (85.9816)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2240/4579]  eta: 0:13:42  Lr: 0.001875  Loss: 0.1064  Acc@1: 56.2500 (48.6195)  Acc@5: 87.5000 (85.9884)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2250/4579]  eta: 0:13:39  Lr: 0.001875  Loss: -0.3096  Acc@1: 56.2500 (48.6562)  Acc@5: 87.5000 (86.0145)  time: 0.3510  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2260/4579]  eta: 0:13:35  Lr: 0.001875  Loss: 0.1436  Acc@1: 56.2500 (48.6732)  Acc@5: 87.5000 (86.0294)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2270/4579]  eta: 0:13:32  Lr: 0.001875  Loss: -0.0646  Acc@1: 56.2500 (48.7038)  Acc@5: 87.5000 (86.0304)  time: 0.3526  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2280/4579]  eta: 0:13:28  Lr: 0.001875  Loss: 0.4568  Acc@1: 56.2500 (48.7204)  Acc@5: 87.5000 (86.0313)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2290/4579]  eta: 0:13:25  Lr: 0.001875  Loss: 0.2531  Acc@1: 50.0000 (48.7342)  Acc@5: 87.5000 (86.0432)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2300/4579]  eta: 0:13:21  Lr: 0.001875  Loss: -0.0940  Acc@1: 56.2500 (48.7641)  Acc@5: 87.5000 (86.0550)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2310/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.5548  Acc@1: 56.2500 (48.7884)  Acc@5: 87.5000 (86.0829)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2320/4579]  eta: 0:13:14  Lr: 0.001875  Loss: 0.2355  Acc@1: 56.2500 (48.8017)  Acc@5: 87.5000 (86.0809)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2330/4579]  eta: 0:13:10  Lr: 0.001875  Loss: 0.2979  Acc@1: 50.0000 (48.8122)  Acc@5: 87.5000 (86.0870)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2340/4579]  eta: 0:13:07  Lr: 0.001875  Loss: 0.0202  Acc@1: 56.2500 (48.8653)  Acc@5: 93.7500 (86.1170)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2350/4579]  eta: 0:13:03  Lr: 0.001875  Loss: 0.0190  Acc@1: 56.2500 (48.8967)  Acc@5: 93.7500 (86.1442)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2360/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.1168  Acc@1: 56.2500 (48.9385)  Acc@5: 93.7500 (86.1764)  time: 0.3550  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2370/4579]  eta: 0:12:56  Lr: 0.001875  Loss: 0.1824  Acc@1: 62.5000 (48.9746)  Acc@5: 93.7500 (86.1794)  time: 0.3546  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2380/4579]  eta: 0:12:53  Lr: 0.001875  Loss: -0.6342  Acc@1: 62.5000 (49.0340)  Acc@5: 87.5000 (86.2007)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2390/4579]  eta: 0:12:49  Lr: 0.001875  Loss: 0.0207  Acc@1: 62.5000 (49.0590)  Acc@5: 87.5000 (86.2061)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2400/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.4997  Acc@1: 62.5000 (49.1254)  Acc@5: 93.7500 (86.2531)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2410/4579]  eta: 0:12:42  Lr: 0.001875  Loss: 0.0919  Acc@1: 56.2500 (49.1497)  Acc@5: 93.7500 (86.2609)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [2420/4579]  eta: 0:12:39  Lr: 0.001875  Loss: -0.3707  Acc@1: 56.2500 (49.1920)  Acc@5: 87.5000 (86.2763)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [2430/4579]  eta: 0:12:35  Lr: 0.001875  Loss: 0.7216  Acc@1: 56.2500 (49.2056)  Acc@5: 87.5000 (86.2916)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2440/4579]  eta: 0:12:32  Lr: 0.001875  Loss: 0.1511  Acc@1: 56.2500 (49.2319)  Acc@5: 87.5000 (86.2992)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2450/4579]  eta: 0:12:28  Lr: 0.001875  Loss: -0.2359  Acc@1: 62.5000 (49.2962)  Acc@5: 93.7500 (86.3219)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2460/4579]  eta: 0:12:25  Lr: 0.001875  Loss: 0.1078  Acc@1: 56.2500 (49.3041)  Acc@5: 93.7500 (86.3292)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2470/4579]  eta: 0:12:21  Lr: 0.001875  Loss: -0.3359  Acc@1: 56.2500 (49.3373)  Acc@5: 87.5000 (86.3264)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [2480/4579]  eta: 0:12:18  Lr: 0.001875  Loss: -0.1901  Acc@1: 56.2500 (49.3727)  Acc@5: 87.5000 (86.3387)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [2490/4579]  eta: 0:12:14  Lr: 0.001875  Loss: -0.2505  Acc@1: 56.2500 (49.4154)  Acc@5: 93.7500 (86.3709)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2500/4579]  eta: 0:12:11  Lr: 0.001875  Loss: 0.0324  Acc@1: 56.2500 (49.4502)  Acc@5: 93.7500 (86.3854)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2510/4579]  eta: 0:12:07  Lr: 0.001875  Loss: -0.0309  Acc@1: 56.2500 (49.4947)  Acc@5: 87.5000 (86.4023)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2520/4579]  eta: 0:12:04  Lr: 0.001875  Loss: -0.1721  Acc@1: 62.5000 (49.5414)  Acc@5: 93.7500 (86.4191)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2530/4579]  eta: 0:12:00  Lr: 0.001875  Loss: -0.3453  Acc@1: 62.5000 (49.6024)  Acc@5: 93.7500 (86.4456)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2540/4579]  eta: 0:11:57  Lr: 0.001875  Loss: 0.2216  Acc@1: 56.2500 (49.6286)  Acc@5: 93.7500 (86.4645)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2550/4579]  eta: 0:11:53  Lr: 0.001875  Loss: -0.3520  Acc@1: 56.2500 (49.6741)  Acc@5: 93.7500 (86.4808)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2560/4579]  eta: 0:11:50  Lr: 0.001875  Loss: 0.6096  Acc@1: 56.2500 (49.7120)  Acc@5: 93.7500 (86.4848)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2570/4579]  eta: 0:11:46  Lr: 0.001875  Loss: -0.2084  Acc@1: 56.2500 (49.7277)  Acc@5: 87.5000 (86.4912)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2580/4579]  eta: 0:11:43  Lr: 0.001875  Loss: -0.1451  Acc@1: 56.2500 (49.7554)  Acc@5: 87.5000 (86.4951)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2590/4579]  eta: 0:11:39  Lr: 0.001875  Loss: 0.2773  Acc@1: 62.5000 (49.7781)  Acc@5: 87.5000 (86.4748)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2600/4579]  eta: 0:11:36  Lr: 0.001875  Loss: -0.2742  Acc@1: 56.2500 (49.7958)  Acc@5: 87.5000 (86.4980)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2610/4579]  eta: 0:11:32  Lr: 0.001875  Loss: 0.0001  Acc@1: 56.2500 (49.8133)  Acc@5: 93.7500 (86.5066)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2620/4579]  eta: 0:11:29  Lr: 0.001875  Loss: -0.1774  Acc@1: 56.2500 (49.8450)  Acc@5: 87.5000 (86.5199)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2630/4579]  eta: 0:11:25  Lr: 0.001875  Loss: 0.0959  Acc@1: 56.2500 (49.8622)  Acc@5: 87.5000 (86.5189)  time: 0.3534  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2640/4579]  eta: 0:11:22  Lr: 0.001875  Loss: 0.3845  Acc@1: 56.2500 (49.8911)  Acc@5: 87.5000 (86.5368)  time: 0.3525  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2650/4579]  eta: 0:11:18  Lr: 0.001875  Loss: -0.3123  Acc@1: 50.0000 (49.9010)  Acc@5: 87.5000 (86.5499)  time: 0.3504  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2660/4579]  eta: 0:11:14  Lr: 0.001875  Loss: -0.5687  Acc@1: 56.2500 (49.9389)  Acc@5: 87.5000 (86.5675)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2670/4579]  eta: 0:11:11  Lr: 0.001875  Loss: -0.3304  Acc@1: 62.5000 (49.9579)  Acc@5: 87.5000 (86.5734)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [2680/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.3277  Acc@1: 50.0000 (49.9907)  Acc@5: 87.5000 (86.5885)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2690/4579]  eta: 0:11:04  Lr: 0.001875  Loss: 0.8591  Acc@1: 50.0000 (49.9907)  Acc@5: 87.5000 (86.5919)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2700/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.1809  Acc@1: 56.2500 (50.0069)  Acc@5: 87.5000 (86.5906)  time: 0.3541  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2710/4579]  eta: 0:10:57  Lr: 0.001875  Loss: 0.1498  Acc@1: 56.2500 (50.0323)  Acc@5: 81.2500 (86.5778)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2720/4579]  eta: 0:10:53  Lr: 0.001875  Loss: -0.0080  Acc@1: 62.5000 (50.0781)  Acc@5: 87.5000 (86.5835)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2730/4579]  eta: 0:10:50  Lr: 0.001875  Loss: 0.1920  Acc@1: 62.5000 (50.0847)  Acc@5: 87.5000 (86.5915)  time: 0.3511  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2740/4579]  eta: 0:10:46  Lr: 0.001875  Loss: 0.2639  Acc@1: 50.0000 (50.0935)  Acc@5: 87.5000 (86.5948)  time: 0.3518  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2750/4579]  eta: 0:10:43  Lr: 0.001875  Loss: -0.0350  Acc@1: 56.2500 (50.1181)  Acc@5: 87.5000 (86.6003)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2760/4579]  eta: 0:10:39  Lr: 0.001875  Loss: 0.0177  Acc@1: 56.2500 (50.1381)  Acc@5: 87.5000 (86.6104)  time: 0.3524  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2770/4579]  eta: 0:10:36  Lr: 0.001875  Loss: 0.3445  Acc@1: 56.2500 (50.1444)  Acc@5: 87.5000 (86.5955)  time: 0.3523  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2780/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.1312  Acc@1: 56.2500 (50.1888)  Acc@5: 87.5000 (86.6100)  time: 0.3523  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2790/4579]  eta: 0:10:29  Lr: 0.001875  Loss: 0.0445  Acc@1: 56.2500 (50.1903)  Acc@5: 87.5000 (86.6043)  time: 0.3528  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2800/4579]  eta: 0:10:25  Lr: 0.001875  Loss: -0.0738  Acc@1: 50.0000 (50.2053)  Acc@5: 87.5000 (86.6097)  time: 0.3533  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2810/4579]  eta: 0:10:22  Lr: 0.001875  Loss: -0.1797  Acc@1: 56.2500 (50.2424)  Acc@5: 87.5000 (86.6262)  time: 0.3517  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2820/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.0894  Acc@1: 62.5000 (50.2880)  Acc@5: 93.7500 (86.6404)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2830/4579]  eta: 0:10:15  Lr: 0.001875  Loss: -0.1201  Acc@1: 62.5000 (50.3069)  Acc@5: 87.5000 (86.6456)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2840/4579]  eta: 0:10:11  Lr: 0.001875  Loss: -0.1097  Acc@1: 62.5000 (50.3608)  Acc@5: 93.7500 (86.6596)  time: 0.3514  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [2850/4579]  eta: 0:10:08  Lr: 0.001875  Loss: -0.2135  Acc@1: 68.7500 (50.4078)  Acc@5: 93.7500 (86.6801)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2860/4579]  eta: 0:10:04  Lr: 0.001875  Loss: -0.3220  Acc@1: 62.5000 (50.4413)  Acc@5: 93.7500 (86.6961)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2870/4579]  eta: 0:10:01  Lr: 0.001875  Loss: 0.2127  Acc@1: 56.2500 (50.4724)  Acc@5: 93.7500 (86.7098)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2880/4579]  eta: 0:09:57  Lr: 0.001875  Loss: -0.5306  Acc@1: 50.0000 (50.4925)  Acc@5: 87.5000 (86.7038)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [2890/4579]  eta: 0:09:54  Lr: 0.001875  Loss: -0.6475  Acc@1: 56.2500 (50.5340)  Acc@5: 87.5000 (86.7282)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [2900/4579]  eta: 0:09:50  Lr: 0.001875  Loss: -0.1157  Acc@1: 62.5000 (50.5752)  Acc@5: 87.5000 (86.7287)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2910/4579]  eta: 0:09:47  Lr: 0.001875  Loss: -0.1686  Acc@1: 62.5000 (50.6033)  Acc@5: 87.5000 (86.7378)  time: 0.3530  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [2920/4579]  eta: 0:09:43  Lr: 0.001875  Loss: -0.1903  Acc@1: 56.2500 (50.6141)  Acc@5: 93.7500 (86.7490)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [2930/4579]  eta: 0:09:40  Lr: 0.001875  Loss: 0.2384  Acc@1: 56.2500 (50.6291)  Acc@5: 87.5000 (86.7515)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2940/4579]  eta: 0:09:36  Lr: 0.001875  Loss: -0.1626  Acc@1: 56.2500 (50.6482)  Acc@5: 87.5000 (86.7668)  time: 0.3529  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2950/4579]  eta: 0:09:33  Lr: 0.001875  Loss: -0.1511  Acc@1: 56.2500 (50.6799)  Acc@5: 87.5000 (86.7630)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2960/4579]  eta: 0:09:29  Lr: 0.001875  Loss: -0.0003  Acc@1: 56.2500 (50.7156)  Acc@5: 87.5000 (86.7760)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2970/4579]  eta: 0:09:25  Lr: 0.001875  Loss: -0.2195  Acc@1: 62.5000 (50.7573)  Acc@5: 93.7500 (86.7826)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [2980/4579]  eta: 0:09:22  Lr: 0.001875  Loss: 0.4697  Acc@1: 62.5000 (50.7736)  Acc@5: 87.5000 (86.7892)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [2990/4579]  eta: 0:09:18  Lr: 0.001875  Loss: -0.4224  Acc@1: 62.5000 (50.8149)  Acc@5: 87.5000 (86.8063)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3000/4579]  eta: 0:09:15  Lr: 0.001875  Loss: 0.0533  Acc@1: 56.2500 (50.8185)  Acc@5: 87.5000 (86.8044)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3010/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.0973  Acc@1: 56.2500 (50.8593)  Acc@5: 87.5000 (86.8150)  time: 0.3528  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3020/4579]  eta: 0:09:08  Lr: 0.001875  Loss: -0.2979  Acc@1: 68.7500 (50.8896)  Acc@5: 93.7500 (86.8256)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3030/4579]  eta: 0:09:04  Lr: 0.001875  Loss: 0.1004  Acc@1: 62.5000 (50.9197)  Acc@5: 87.5000 (86.8298)  time: 0.3528  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3040/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.2836  Acc@1: 56.2500 (50.9413)  Acc@5: 87.5000 (86.8362)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3050/4579]  eta: 0:08:57  Lr: 0.001875  Loss: -0.3509  Acc@1: 56.2500 (50.9608)  Acc@5: 93.7500 (86.8506)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3060/4579]  eta: 0:08:54  Lr: 0.001875  Loss: 0.2910  Acc@1: 62.5000 (50.9984)  Acc@5: 93.7500 (86.8732)  time: 0.3544  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3070/4579]  eta: 0:08:50  Lr: 0.001875  Loss: 0.2845  Acc@1: 56.2500 (51.0155)  Acc@5: 93.7500 (86.8772)  time: 0.3552  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3080/4579]  eta: 0:08:47  Lr: 0.001875  Loss: 0.0026  Acc@1: 50.0000 (51.0204)  Acc@5: 87.5000 (86.8752)  time: 0.3529  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3090/4579]  eta: 0:08:43  Lr: 0.001875  Loss: -0.4692  Acc@1: 62.5000 (51.0535)  Acc@5: 87.5000 (86.8813)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3100/4579]  eta: 0:08:40  Lr: 0.001875  Loss: -0.4341  Acc@1: 62.5000 (51.0823)  Acc@5: 87.5000 (86.8913)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3110/4579]  eta: 0:08:36  Lr: 0.001875  Loss: 0.4200  Acc@1: 62.5000 (51.1070)  Acc@5: 87.5000 (86.8893)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3120/4579]  eta: 0:08:33  Lr: 0.001875  Loss: -0.4458  Acc@1: 62.5000 (51.1375)  Acc@5: 87.5000 (86.9153)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3130/4579]  eta: 0:08:29  Lr: 0.001875  Loss: -0.0268  Acc@1: 56.2500 (51.1498)  Acc@5: 93.7500 (86.9251)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3140/4579]  eta: 0:08:26  Lr: 0.001875  Loss: -0.1872  Acc@1: 50.0000 (51.1481)  Acc@5: 93.7500 (86.9269)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3150/4579]  eta: 0:08:22  Lr: 0.001875  Loss: 0.2983  Acc@1: 50.0000 (51.1504)  Acc@5: 87.5000 (86.9268)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3160/4579]  eta: 0:08:19  Lr: 0.001875  Loss: 0.0426  Acc@1: 56.2500 (51.1804)  Acc@5: 93.7500 (86.9424)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3170/4579]  eta: 0:08:15  Lr: 0.001875  Loss: 0.2451  Acc@1: 56.2500 (51.1846)  Acc@5: 87.5000 (86.9383)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3180/4579]  eta: 0:08:12  Lr: 0.001875  Loss: -0.2832  Acc@1: 56.2500 (51.2064)  Acc@5: 87.5000 (86.9459)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3190/4579]  eta: 0:08:08  Lr: 0.001875  Loss: 0.3101  Acc@1: 56.2500 (51.2281)  Acc@5: 87.5000 (86.9516)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3200/4579]  eta: 0:08:05  Lr: 0.001875  Loss: -0.4633  Acc@1: 56.2500 (51.2340)  Acc@5: 87.5000 (86.9494)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3210/4579]  eta: 0:08:01  Lr: 0.001875  Loss: 0.0472  Acc@1: 56.2500 (51.2632)  Acc@5: 87.5000 (86.9628)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3220/4579]  eta: 0:07:58  Lr: 0.001875  Loss: -0.2817  Acc@1: 68.7500 (51.3059)  Acc@5: 87.5000 (86.9703)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3230/4579]  eta: 0:07:54  Lr: 0.001875  Loss: -0.0765  Acc@1: 62.5000 (51.3386)  Acc@5: 93.7500 (86.9893)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3240/4579]  eta: 0:07:50  Lr: 0.001875  Loss: -0.2144  Acc@1: 62.5000 (51.3807)  Acc@5: 93.7500 (87.0140)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3250/4579]  eta: 0:07:47  Lr: 0.001875  Loss: 0.1355  Acc@1: 62.5000 (51.4246)  Acc@5: 93.7500 (87.0348)  time: 0.3502  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3260/4579]  eta: 0:07:43  Lr: 0.001875  Loss: -0.1104  Acc@1: 62.5000 (51.4547)  Acc@5: 93.7500 (87.0458)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[1/1]  [3270/4579]  eta: 0:07:40  Lr: 0.001875  Loss: -0.1464  Acc@1: 62.5000 (51.4751)  Acc@5: 93.7500 (87.0586)  time: 0.3517  data: 0.0010  max mem: 2500
Train: Epoch[1/1]  [3280/4579]  eta: 0:07:36  Lr: 0.001875  Loss: 0.2388  Acc@1: 56.2500 (51.4896)  Acc@5: 93.7500 (87.0638)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3290/4579]  eta: 0:07:33  Lr: 0.001875  Loss: -0.4294  Acc@1: 56.2500 (51.5098)  Acc@5: 87.5000 (87.0632)  time: 0.3501  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3300/4579]  eta: 0:07:29  Lr: 0.001875  Loss: 0.3414  Acc@1: 56.2500 (51.5336)  Acc@5: 87.5000 (87.0797)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3310/4579]  eta: 0:07:26  Lr: 0.001875  Loss: -0.2039  Acc@1: 62.5000 (51.5611)  Acc@5: 93.7500 (87.0923)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3320/4579]  eta: 0:07:22  Lr: 0.001875  Loss: -0.1754  Acc@1: 62.5000 (51.5903)  Acc@5: 87.5000 (87.0935)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3330/4579]  eta: 0:07:19  Lr: 0.001875  Loss: -0.7661  Acc@1: 62.5000 (51.6380)  Acc@5: 93.7500 (87.1154)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3340/4579]  eta: 0:07:15  Lr: 0.001875  Loss: -0.2184  Acc@1: 62.5000 (51.6350)  Acc@5: 93.7500 (87.1259)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3350/4579]  eta: 0:07:12  Lr: 0.001875  Loss: -0.3319  Acc@1: 56.2500 (51.6693)  Acc@5: 87.5000 (87.1288)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3360/4579]  eta: 0:07:08  Lr: 0.001875  Loss: -0.5202  Acc@1: 56.2500 (51.6941)  Acc@5: 87.5000 (87.1374)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3370/4579]  eta: 0:07:05  Lr: 0.001875  Loss: -0.0083  Acc@1: 56.2500 (51.7168)  Acc@5: 87.5000 (87.1403)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3380/4579]  eta: 0:07:01  Lr: 0.001875  Loss: -0.1318  Acc@1: 56.2500 (51.7450)  Acc@5: 87.5000 (87.1432)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3390/4579]  eta: 0:06:58  Lr: 0.001875  Loss: -0.7090  Acc@1: 56.2500 (51.7639)  Acc@5: 87.5000 (87.1406)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3400/4579]  eta: 0:06:54  Lr: 0.001875  Loss: 0.3976  Acc@1: 56.2500 (51.7715)  Acc@5: 87.5000 (87.1564)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3410/4579]  eta: 0:06:51  Lr: 0.001875  Loss: -0.1129  Acc@1: 56.2500 (51.7938)  Acc@5: 87.5000 (87.1629)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3420/4579]  eta: 0:06:47  Lr: 0.001875  Loss: -0.2477  Acc@1: 56.2500 (51.8178)  Acc@5: 87.5000 (87.1693)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3430/4579]  eta: 0:06:44  Lr: 0.001875  Loss: -0.6061  Acc@1: 62.5000 (51.8471)  Acc@5: 93.7500 (87.1867)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [3440/4579]  eta: 0:06:40  Lr: 0.001875  Loss: -0.2326  Acc@1: 56.2500 (51.8545)  Acc@5: 93.7500 (87.1803)  time: 0.3541  data: 0.0016  max mem: 2500
Train: Epoch[1/1]  [3450/4579]  eta: 0:06:37  Lr: 0.001875  Loss: 0.1814  Acc@1: 56.2500 (51.8708)  Acc@5: 87.5000 (87.1903)  time: 0.3525  data: 0.0014  max mem: 2500
Train: Epoch[1/1]  [3460/4579]  eta: 0:06:33  Lr: 0.001875  Loss: -0.3189  Acc@1: 56.2500 (51.8745)  Acc@5: 93.7500 (87.2020)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3470/4579]  eta: 0:06:30  Lr: 0.001875  Loss: 0.3125  Acc@1: 56.2500 (51.8979)  Acc@5: 93.7500 (87.2191)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3480/4579]  eta: 0:06:26  Lr: 0.001875  Loss: 0.1748  Acc@1: 50.0000 (51.8942)  Acc@5: 87.5000 (87.2109)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3490/4579]  eta: 0:06:23  Lr: 0.001875  Loss: -0.3279  Acc@1: 56.2500 (51.9103)  Acc@5: 87.5000 (87.2171)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3500/4579]  eta: 0:06:19  Lr: 0.001875  Loss: 0.0254  Acc@1: 56.2500 (51.9280)  Acc@5: 87.5000 (87.2197)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3510/4579]  eta: 0:06:16  Lr: 0.001875  Loss: 0.0148  Acc@1: 56.2500 (51.9350)  Acc@5: 87.5000 (87.2294)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3520/4579]  eta: 0:06:12  Lr: 0.001875  Loss: -0.0414  Acc@1: 56.2500 (51.9614)  Acc@5: 87.5000 (87.2391)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3530/4579]  eta: 0:06:08  Lr: 0.001875  Loss: -0.0095  Acc@1: 56.2500 (51.9824)  Acc@5: 93.7500 (87.2540)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3540/4579]  eta: 0:06:05  Lr: 0.001875  Loss: -0.3823  Acc@1: 56.2500 (51.9998)  Acc@5: 93.7500 (87.2670)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3550/4579]  eta: 0:06:01  Lr: 0.001875  Loss: 0.2901  Acc@1: 62.5000 (52.0241)  Acc@5: 93.7500 (87.2747)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3560/4579]  eta: 0:05:58  Lr: 0.001875  Loss: -0.0253  Acc@1: 56.2500 (52.0412)  Acc@5: 93.7500 (87.2841)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3570/4579]  eta: 0:05:54  Lr: 0.001875  Loss: 0.5706  Acc@1: 56.2500 (52.0565)  Acc@5: 93.7500 (87.2760)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3580/4579]  eta: 0:05:51  Lr: 0.001875  Loss: -0.2497  Acc@1: 56.2500 (52.0769)  Acc@5: 87.5000 (87.2818)  time: 0.3532  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3590/4579]  eta: 0:05:47  Lr: 0.001875  Loss: -0.4508  Acc@1: 62.5000 (52.0938)  Acc@5: 93.7500 (87.2894)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [3600/4579]  eta: 0:05:44  Lr: 0.001875  Loss: -0.0552  Acc@1: 56.2500 (52.1192)  Acc@5: 93.7500 (87.2969)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [3610/4579]  eta: 0:05:40  Lr: 0.001875  Loss: -0.1850  Acc@1: 56.2500 (52.1410)  Acc@5: 93.7500 (87.3148)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3620/4579]  eta: 0:05:37  Lr: 0.001875  Loss: 0.5137  Acc@1: 56.2500 (52.1437)  Acc@5: 93.7500 (87.3170)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3630/4579]  eta: 0:05:33  Lr: 0.001875  Loss: -0.0377  Acc@1: 56.2500 (52.1654)  Acc@5: 93.7500 (87.3365)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3640/4579]  eta: 0:05:30  Lr: 0.001875  Loss: -0.1916  Acc@1: 62.5000 (52.1938)  Acc@5: 93.7500 (87.3421)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3650/4579]  eta: 0:05:26  Lr: 0.001875  Loss: -0.2794  Acc@1: 62.5000 (52.2151)  Acc@5: 93.7500 (87.3562)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3660/4579]  eta: 0:05:23  Lr: 0.001875  Loss: -0.2621  Acc@1: 62.5000 (52.2484)  Acc@5: 93.7500 (87.3754)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3670/4579]  eta: 0:05:19  Lr: 0.001875  Loss: 0.9121  Acc@1: 62.5000 (52.2695)  Acc@5: 93.7500 (87.3842)  time: 0.3524  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3680/4579]  eta: 0:05:16  Lr: 0.001875  Loss: -0.2496  Acc@1: 62.5000 (52.2973)  Acc@5: 93.7500 (87.4032)  time: 0.3526  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3690/4579]  eta: 0:05:12  Lr: 0.001875  Loss: -0.3625  Acc@1: 62.5000 (52.3131)  Acc@5: 93.7500 (87.4103)  time: 0.3521  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3700/4579]  eta: 0:05:09  Lr: 0.001875  Loss: 0.1695  Acc@1: 56.2500 (52.3321)  Acc@5: 87.5000 (87.4189)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3710/4579]  eta: 0:05:05  Lr: 0.001875  Loss: 0.0890  Acc@1: 56.2500 (52.3528)  Acc@5: 87.5000 (87.4259)  time: 0.3537  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3720/4579]  eta: 0:05:02  Lr: 0.001875  Loss: -0.2571  Acc@1: 56.2500 (52.3532)  Acc@5: 87.5000 (87.4278)  time: 0.3541  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3730/4579]  eta: 0:04:58  Lr: 0.001875  Loss: 0.1297  Acc@1: 56.2500 (52.3703)  Acc@5: 93.7500 (87.4330)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3740/4579]  eta: 0:04:55  Lr: 0.001875  Loss: -0.0888  Acc@1: 62.5000 (52.3974)  Acc@5: 93.7500 (87.4482)  time: 0.3542  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3750/4579]  eta: 0:04:51  Lr: 0.001875  Loss: 0.3352  Acc@1: 56.2500 (52.3994)  Acc@5: 87.5000 (87.4517)  time: 0.3552  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3760/4579]  eta: 0:04:48  Lr: 0.001875  Loss: -0.0459  Acc@1: 56.2500 (52.4196)  Acc@5: 87.5000 (87.4634)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3770/4579]  eta: 0:04:44  Lr: 0.001875  Loss: -0.2641  Acc@1: 62.5000 (52.4330)  Acc@5: 93.7500 (87.4718)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[1/1]  [3780/4579]  eta: 0:04:41  Lr: 0.001875  Loss: -0.0258  Acc@1: 62.5000 (52.4597)  Acc@5: 93.7500 (87.4884)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[1/1]  [3790/4579]  eta: 0:04:37  Lr: 0.001875  Loss: -0.0906  Acc@1: 62.5000 (52.4812)  Acc@5: 93.7500 (87.5033)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3800/4579]  eta: 0:04:34  Lr: 0.001875  Loss: -0.2282  Acc@1: 56.2500 (52.5026)  Acc@5: 93.7500 (87.5082)  time: 0.3536  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3810/4579]  eta: 0:04:30  Lr: 0.001875  Loss: 0.3454  Acc@1: 56.2500 (52.5141)  Acc@5: 87.5000 (87.5131)  time: 0.3535  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3820/4579]  eta: 0:04:27  Lr: 0.001875  Loss: -0.3598  Acc@1: 56.2500 (52.5157)  Acc@5: 93.7500 (87.5245)  time: 0.3520  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3830/4579]  eta: 0:04:23  Lr: 0.001875  Loss: 0.0911  Acc@1: 56.2500 (52.5271)  Acc@5: 93.7500 (87.5359)  time: 0.3531  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3840/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.4311  Acc@1: 62.5000 (52.5530)  Acc@5: 87.5000 (87.5423)  time: 0.3524  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3850/4579]  eta: 0:04:16  Lr: 0.001875  Loss: 0.7160  Acc@1: 62.5000 (52.5659)  Acc@5: 87.5000 (87.5487)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3860/4579]  eta: 0:04:12  Lr: 0.001875  Loss: -0.4243  Acc@1: 56.2500 (52.5868)  Acc@5: 87.5000 (87.5502)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3870/4579]  eta: 0:04:09  Lr: 0.001875  Loss: -0.1055  Acc@1: 56.2500 (52.6011)  Acc@5: 87.5000 (87.5549)  time: 0.3546  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3880/4579]  eta: 0:04:05  Lr: 0.001875  Loss: -0.1968  Acc@1: 56.2500 (52.6137)  Acc@5: 87.5000 (87.5612)  time: 0.3541  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3890/4579]  eta: 0:04:02  Lr: 0.001875  Loss: -0.1718  Acc@1: 50.0000 (52.6070)  Acc@5: 87.5000 (87.5626)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3900/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.3238  Acc@1: 56.2500 (52.6291)  Acc@5: 93.7500 (87.5753)  time: 0.3542  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3910/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.1089  Acc@1: 62.5000 (52.6528)  Acc@5: 93.7500 (87.5815)  time: 0.3539  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3920/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.1116  Acc@1: 56.2500 (52.6540)  Acc@5: 87.5000 (87.5845)  time: 0.3512  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [3930/4579]  eta: 0:03:48  Lr: 0.001875  Loss: 0.1284  Acc@1: 56.2500 (52.6695)  Acc@5: 87.5000 (87.5843)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3940/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.0516  Acc@1: 56.2500 (52.6881)  Acc@5: 93.7500 (87.6015)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [3950/4579]  eta: 0:03:41  Lr: 0.001875  Loss: -0.7213  Acc@1: 56.2500 (52.6876)  Acc@5: 93.7500 (87.5965)  time: 0.3528  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3960/4579]  eta: 0:03:37  Lr: 0.001875  Loss: -0.3100  Acc@1: 56.2500 (52.7203)  Acc@5: 87.5000 (87.6152)  time: 0.3542  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [3970/4579]  eta: 0:03:34  Lr: 0.001875  Loss: 0.0626  Acc@1: 62.5000 (52.7418)  Acc@5: 93.7500 (87.6212)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [3980/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 0.3960  Acc@1: 62.5000 (52.7694)  Acc@5: 93.7500 (87.6334)  time: 0.3541  data: 0.0010  max mem: 2500
Train: Epoch[1/1]  [3990/4579]  eta: 0:03:27  Lr: 0.001875  Loss: 0.2330  Acc@1: 56.2500 (52.7766)  Acc@5: 93.7500 (87.6362)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [4000/4579]  eta: 0:03:23  Lr: 0.001875  Loss: -0.1019  Acc@1: 56.2500 (52.7899)  Acc@5: 93.7500 (87.6484)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4010/4579]  eta: 0:03:20  Lr: 0.001875  Loss: 0.2428  Acc@1: 56.2500 (52.8141)  Acc@5: 87.5000 (87.6465)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4020/4579]  eta: 0:03:16  Lr: 0.001875  Loss: -0.3931  Acc@1: 62.5000 (52.8413)  Acc@5: 87.5000 (87.6632)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4030/4579]  eta: 0:03:13  Lr: 0.001875  Loss: -0.2937  Acc@1: 62.5000 (52.8575)  Acc@5: 93.7500 (87.6675)  time: 0.3536  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4040/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 0.5107  Acc@1: 62.5000 (52.8799)  Acc@5: 87.5000 (87.6670)  time: 0.3523  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4050/4579]  eta: 0:03:06  Lr: 0.001875  Loss: 0.1969  Acc@1: 62.5000 (52.8928)  Acc@5: 87.5000 (87.6759)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4060/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 0.3414  Acc@1: 56.2500 (52.9011)  Acc@5: 93.7500 (87.6801)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [4070/4579]  eta: 0:02:59  Lr: 0.001875  Loss: -0.4151  Acc@1: 62.5000 (52.9231)  Acc@5: 87.5000 (87.6827)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [4080/4579]  eta: 0:02:55  Lr: 0.001875  Loss: 0.3989  Acc@1: 62.5000 (52.9374)  Acc@5: 87.5000 (87.6822)  time: 0.3526  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4090/4579]  eta: 0:02:52  Lr: 0.001875  Loss: -0.0781  Acc@1: 62.5000 (52.9531)  Acc@5: 87.5000 (87.6864)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4100/4579]  eta: 0:02:48  Lr: 0.001875  Loss: -0.2604  Acc@1: 62.5000 (52.9749)  Acc@5: 93.7500 (87.6966)  time: 0.3510  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4110/4579]  eta: 0:02:45  Lr: 0.001875  Loss: -0.0104  Acc@1: 62.5000 (53.0057)  Acc@5: 87.5000 (87.6976)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4120/4579]  eta: 0:02:41  Lr: 0.001875  Loss: -0.2399  Acc@1: 62.5000 (53.0150)  Acc@5: 87.5000 (87.7063)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4538  Acc@1: 56.2500 (53.0410)  Acc@5: 93.7500 (87.7133)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4140/4579]  eta: 0:02:34  Lr: 0.001875  Loss: -0.4152  Acc@1: 62.5000 (53.0624)  Acc@5: 93.7500 (87.7249)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: 0.2361  Acc@1: 62.5000 (53.0851)  Acc@5: 93.7500 (87.7319)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4160/4579]  eta: 0:02:27  Lr: 0.001875  Loss: -0.3220  Acc@1: 62.5000 (53.1032)  Acc@5: 93.7500 (87.7358)  time: 0.3541  data: 0.0010  max mem: 2500
Train: Epoch[1/1]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: 0.1456  Acc@1: 56.2500 (53.1063)  Acc@5: 87.5000 (87.7323)  time: 0.3544  data: 0.0011  max mem: 2500
Train: Epoch[1/1]  [4180/4579]  eta: 0:02:20  Lr: 0.001875  Loss: 0.1181  Acc@1: 56.2500 (53.1198)  Acc@5: 87.5000 (87.7392)  time: 0.3525  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: 0.2143  Acc@1: 56.2500 (53.1332)  Acc@5: 87.5000 (87.7446)  time: 0.3525  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4200/4579]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0011  Acc@1: 56.2500 (53.1302)  Acc@5: 87.5000 (87.7455)  time: 0.3529  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: 1.2293  Acc@1: 56.2500 (53.1450)  Acc@5: 87.5000 (87.7464)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4220/4579]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1477  Acc@1: 62.5000 (53.1687)  Acc@5: 93.7500 (87.7562)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.1776  Acc@1: 62.5000 (53.1774)  Acc@5: 93.7500 (87.7615)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4240/4579]  eta: 0:01:59  Lr: 0.001875  Loss: 0.1059  Acc@1: 62.5000 (53.2009)  Acc@5: 87.5000 (87.7638)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: 0.1653  Acc@1: 62.5000 (53.2125)  Acc@5: 87.5000 (87.7676)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4260/4579]  eta: 0:01:52  Lr: 0.001875  Loss: -0.4982  Acc@1: 62.5000 (53.2387)  Acc@5: 87.5000 (87.7699)  time: 0.3519  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: -0.5379  Acc@1: 62.5000 (53.2648)  Acc@5: 93.7500 (87.7795)  time: 0.3517  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4280/4579]  eta: 0:01:45  Lr: 0.001875  Loss: -0.3371  Acc@1: 68.7500 (53.2907)  Acc@5: 93.7500 (87.7964)  time: 0.3518  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.0334  Acc@1: 62.5000 (53.3020)  Acc@5: 93.7500 (87.8088)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4300/4579]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6947  Acc@1: 62.5000 (53.3277)  Acc@5: 93.7500 (87.8197)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.4609  Acc@1: 56.2500 (53.3417)  Acc@5: 87.5000 (87.8248)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[1/1]  [4320/4579]  eta: 0:01:31  Lr: 0.001875  Loss: 0.3275  Acc@1: 56.2500 (53.3658)  Acc@5: 87.5000 (87.8283)  time: 0.3551  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0474  Acc@1: 62.5000 (53.3956)  Acc@5: 93.7500 (87.8391)  time: 0.3552  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [4340/4579]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5615  Acc@1: 62.5000 (53.4065)  Acc@5: 87.5000 (87.8398)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1189  Acc@1: 62.5000 (53.4317)  Acc@5: 93.7500 (87.8491)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4360/4579]  eta: 0:01:17  Lr: 0.001875  Loss: 0.1654  Acc@1: 62.5000 (53.4568)  Acc@5: 93.7500 (87.8569)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.1633  Acc@1: 62.5000 (53.4689)  Acc@5: 87.5000 (87.8603)  time: 0.3542  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4380/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3592  Acc@1: 56.2500 (53.4667)  Acc@5: 87.5000 (87.8567)  time: 0.3547  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6811  Acc@1: 56.2500 (53.4844)  Acc@5: 87.5000 (87.8687)  time: 0.3527  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: 0.0501  Acc@1: 62.5000 (53.5091)  Acc@5: 87.5000 (87.8721)  time: 0.3516  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: 0.0250  Acc@1: 62.5000 (53.5295)  Acc@5: 87.5000 (87.8840)  time: 0.3523  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0061  Acc@1: 68.7500 (53.5625)  Acc@5: 93.7500 (87.8902)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1567  Acc@1: 62.5000 (53.5644)  Acc@5: 93.7500 (87.9006)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/1]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.2070  Acc@1: 56.2500 (53.5915)  Acc@5: 93.7500 (87.9025)  time: 0.3506  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1258  Acc@1: 68.7500 (53.6200)  Acc@5: 93.7500 (87.9128)  time: 0.3506  data: 0.0002  max mem: 2500
Train: Epoch[1/1]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.2230  Acc@1: 62.5000 (53.6301)  Acc@5: 87.5000 (87.9049)  time: 0.3502  data: 0.0002  max mem: 2500
Train: Epoch[1/1]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5536  Acc@1: 56.2500 (53.6317)  Acc@5: 93.7500 (87.9166)  time: 0.3503  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4310  Acc@1: 56.2500 (53.6543)  Acc@5: 93.7500 (87.9282)  time: 0.3501  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2717  Acc@1: 62.5000 (53.6698)  Acc@5: 93.7500 (87.9286)  time: 0.3498  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0438  Acc@1: 56.2500 (53.6825)  Acc@5: 93.7500 (87.9332)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0938  Acc@1: 56.2500 (53.6937)  Acc@5: 93.7500 (87.9406)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/1]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.1404  Acc@1: 62.5000 (53.7174)  Acc@5: 93.7500 (87.9493)  time: 0.3490  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3367  Acc@1: 56.2500 (53.7174)  Acc@5: 93.7500 (87.9552)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1411  Acc@1: 56.2500 (53.7327)  Acc@5: 87.5000 (87.9569)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/1]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.3921  Acc@1: 62.5000 (53.7629)  Acc@5: 87.5000 (87.9587)  time: 0.3502  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.2573  Acc@1: 62.5000 (53.7670)  Acc@5: 87.5000 (87.9577)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[1/1]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.1779  Acc@1: 56.2500 (53.7916)  Acc@5: 93.7500 (87.9717)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[1/1]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 1.1330  Acc@1: 56.2500 (53.7887)  Acc@5: 87.5000 (87.9698)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[1/1] Total time: 0:26:51 (0.3520 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 1.1330  Acc@1: 56.2500 (53.7887)  Acc@5: 87.5000 (87.9698)
Test: [Task 1]  [   0/1627]  eta: 0:17:59  Loss: 1.3039 (1.3039)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6638  data: 0.4430  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:54  Loss: 1.3593 (1.2797)  Acc@1: 75.0000 (79.5455)  Acc@5: 100.0000 (95.4545)  time: 0.2564  data: 0.0406  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:22  Loss: 1.2540 (1.2587)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.7262)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:08  Loss: 1.2428 (1.2775)  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (97.1774)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:06:01  Loss: 1.4133 (1.3010)  Acc@1: 75.0000 (80.0305)  Acc@5: 100.0000 (96.6463)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:56  Loss: 1.2307 (1.2751)  Acc@1: 75.0000 (80.0245)  Acc@5: 100.0000 (96.8137)  time: 0.2180  data: 0.0013  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:51  Loss: 1.2317 (1.2967)  Acc@1: 75.0000 (79.6107)  Acc@5: 100.0000 (97.0287)  time: 0.2180  data: 0.0012  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:47  Loss: 1.2582 (1.2880)  Acc@1: 75.0000 (79.8415)  Acc@5: 100.0000 (97.0951)  time: 0.2170  data: 0.0003  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:44  Loss: 1.1396 (1.2701)  Acc@1: 81.2500 (80.4012)  Acc@5: 100.0000 (97.3765)  time: 0.2179  data: 0.0003  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:41  Loss: 1.1967 (1.2723)  Acc@1: 81.2500 (80.1511)  Acc@5: 100.0000 (96.9093)  time: 0.2177  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:38  Loss: 1.4283 (1.2976)  Acc@1: 75.0000 (79.5792)  Acc@5: 93.7500 (96.4728)  time: 0.2173  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:35  Loss: 1.3557 (1.2987)  Acc@1: 75.0000 (79.3356)  Acc@5: 100.0000 (96.6216)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:32  Loss: 1.3019 (1.3005)  Acc@1: 75.0000 (79.1322)  Acc@5: 100.0000 (96.3326)  time: 0.2173  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:30  Loss: 1.2614 (1.2979)  Acc@1: 75.0000 (78.8645)  Acc@5: 93.7500 (96.1832)  time: 0.2173  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:27  Loss: 1.1492 (1.2961)  Acc@1: 81.2500 (78.9450)  Acc@5: 93.7500 (96.2323)  time: 0.2173  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:25  Loss: 1.0973 (1.2870)  Acc@1: 75.0000 (78.9735)  Acc@5: 100.0000 (96.3576)  time: 0.2177  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:22  Loss: 1.1845 (1.2831)  Acc@1: 75.0000 (78.9596)  Acc@5: 100.0000 (96.3509)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:20  Loss: 1.2489 (1.2757)  Acc@1: 81.2500 (78.9474)  Acc@5: 100.0000 (96.4912)  time: 0.2181  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:18  Loss: 1.3036 (1.2874)  Acc@1: 75.0000 (78.5221)  Acc@5: 100.0000 (96.4088)  time: 0.2189  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:16  Loss: 1.3611 (1.2813)  Acc@1: 75.0000 (78.8285)  Acc@5: 93.7500 (96.3678)  time: 0.2190  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:13  Loss: 1.3611 (1.2851)  Acc@1: 81.2500 (78.7313)  Acc@5: 100.0000 (96.3619)  time: 0.2185  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:11  Loss: 1.3524 (1.2814)  Acc@1: 81.2500 (78.9100)  Acc@5: 93.7500 (96.3566)  time: 0.2184  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:09  Loss: 1.3133 (1.2868)  Acc@1: 81.2500 (78.7896)  Acc@5: 93.7500 (96.3518)  time: 0.2194  data: 0.0017  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:07  Loss: 1.2865 (1.2804)  Acc@1: 81.2500 (78.9502)  Acc@5: 100.0000 (96.3745)  time: 0.2201  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:04  Loss: 1.1410 (1.2734)  Acc@1: 81.2500 (79.2012)  Acc@5: 100.0000 (96.4471)  time: 0.2188  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:02  Loss: 1.2545 (1.2791)  Acc@1: 81.2500 (79.1086)  Acc@5: 100.0000 (96.3645)  time: 0.2194  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:05:00  Loss: 1.2990 (1.2780)  Acc@1: 81.2500 (79.1188)  Acc@5: 100.0000 (96.3602)  time: 0.2197  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:58  Loss: 1.2805 (1.2727)  Acc@1: 81.2500 (79.3127)  Acc@5: 100.0000 (96.4483)  time: 0.2193  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:55  Loss: 1.2320 (1.2727)  Acc@1: 81.2500 (79.2260)  Acc@5: 100.0000 (96.3746)  time: 0.2193  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:53  Loss: 1.1958 (1.2701)  Acc@1: 81.2500 (79.3170)  Acc@5: 100.0000 (96.4132)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:51  Loss: 1.1958 (1.2673)  Acc@1: 81.2500 (79.3812)  Acc@5: 100.0000 (96.4701)  time: 0.2192  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:49  Loss: 1.2331 (1.2703)  Acc@1: 81.2500 (79.3810)  Acc@5: 100.0000 (96.4027)  time: 0.2192  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:47  Loss: 1.3354 (1.2712)  Acc@1: 81.2500 (79.3808)  Acc@5: 100.0000 (96.4369)  time: 0.2201  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:44  Loss: 1.1192 (1.2704)  Acc@1: 81.2500 (79.5128)  Acc@5: 100.0000 (96.4502)  time: 0.2204  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:42  Loss: 1.0766 (1.2691)  Acc@1: 75.0000 (79.4905)  Acc@5: 100.0000 (96.4076)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:40  Loss: 1.1994 (1.2686)  Acc@1: 81.2500 (79.5228)  Acc@5: 100.0000 (96.4566)  time: 0.2194  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:38  Loss: 1.1957 (1.2690)  Acc@1: 81.2500 (79.4841)  Acc@5: 100.0000 (96.4162)  time: 0.2192  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:36  Loss: 1.1532 (1.2689)  Acc@1: 75.0000 (79.4643)  Acc@5: 100.0000 (96.4623)  time: 0.2198  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:33  Loss: 1.1828 (1.2671)  Acc@1: 81.2500 (79.5112)  Acc@5: 93.7500 (96.3911)  time: 0.2203  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:31  Loss: 1.2120 (1.2698)  Acc@1: 81.2500 (79.4437)  Acc@5: 93.7500 (96.3555)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:29  Loss: 1.2657 (1.2710)  Acc@1: 81.2500 (79.4888)  Acc@5: 100.0000 (96.3685)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:27  Loss: 1.2146 (1.2704)  Acc@1: 81.2500 (79.5316)  Acc@5: 93.7500 (96.3047)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:25  Loss: 1.1142 (1.2677)  Acc@1: 81.2500 (79.6318)  Acc@5: 93.7500 (96.3034)  time: 0.2193  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:22  Loss: 1.0297 (1.2656)  Acc@1: 81.2500 (79.6114)  Acc@5: 100.0000 (96.3457)  time: 0.2198  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:20  Loss: 1.2992 (1.2664)  Acc@1: 75.0000 (79.5635)  Acc@5: 100.0000 (96.3294)  time: 0.2191  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:18  Loss: 1.3641 (1.2698)  Acc@1: 75.0000 (79.4346)  Acc@5: 93.7500 (96.2583)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:16  Loss: 1.3290 (1.2692)  Acc@1: 75.0000 (79.3655)  Acc@5: 100.0000 (96.2717)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:14  Loss: 1.0838 (1.2664)  Acc@1: 81.2500 (79.4851)  Acc@5: 100.0000 (96.2712)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:11  Loss: 1.2959 (1.2717)  Acc@1: 81.2500 (79.3529)  Acc@5: 93.7500 (96.1798)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:09  Loss: 1.2959 (1.2725)  Acc@1: 75.0000 (79.2897)  Acc@5: 93.7500 (96.1813)  time: 0.2183  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:07  Loss: 1.2640 (1.2751)  Acc@1: 75.0000 (79.2415)  Acc@5: 93.7500 (96.0953)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:05  Loss: 1.3607 (1.2788)  Acc@1: 75.0000 (79.1707)  Acc@5: 93.7500 (96.0372)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:02  Loss: 1.3607 (1.2838)  Acc@1: 75.0000 (79.1027)  Acc@5: 93.7500 (96.0053)  time: 0.2182  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:04:00  Loss: 1.2121 (1.2796)  Acc@1: 81.2500 (79.2020)  Acc@5: 100.0000 (96.0334)  time: 0.2188  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:58  Loss: 1.1714 (1.2793)  Acc@1: 81.2500 (79.1936)  Acc@5: 100.0000 (96.0605)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:56  Loss: 1.3460 (1.2824)  Acc@1: 75.0000 (79.1629)  Acc@5: 93.7500 (96.0299)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:54  Loss: 1.3906 (1.2851)  Acc@1: 75.0000 (79.1332)  Acc@5: 93.7500 (96.0450)  time: 0.2179  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:51  Loss: 1.2332 (1.2828)  Acc@1: 81.2500 (79.1703)  Acc@5: 93.7500 (96.0486)  time: 0.2178  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:49  Loss: 1.2355 (1.2851)  Acc@1: 81.2500 (79.1308)  Acc@5: 93.7500 (96.0198)  time: 0.2182  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:47  Loss: 1.3533 (1.2838)  Acc@1: 81.2500 (79.1878)  Acc@5: 100.0000 (96.0660)  time: 0.2171  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:45  Loss: 1.2439 (1.2861)  Acc@1: 81.2500 (79.0869)  Acc@5: 100.0000 (96.0795)  time: 0.2174  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:42  Loss: 1.1920 (1.2843)  Acc@1: 81.2500 (79.1837)  Acc@5: 100.0000 (96.0925)  time: 0.2174  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:40  Loss: 1.1703 (1.2854)  Acc@1: 81.2500 (79.2170)  Acc@5: 100.0000 (96.0346)  time: 0.2167  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:38  Loss: 1.1703 (1.2838)  Acc@1: 81.2500 (79.2591)  Acc@5: 100.0000 (96.0578)  time: 0.2164  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 1.0444 (1.2824)  Acc@1: 81.2500 (79.2707)  Acc@5: 100.0000 (96.0608)  time: 0.2165  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:34  Loss: 1.2099 (1.2822)  Acc@1: 75.0000 (79.2435)  Acc@5: 100.0000 (96.0733)  time: 0.2171  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:31  Loss: 1.1243 (1.2801)  Acc@1: 81.2500 (79.2738)  Acc@5: 100.0000 (96.0760)  time: 0.2198  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:29  Loss: 1.2480 (1.2808)  Acc@1: 81.2500 (79.2474)  Acc@5: 93.7500 (96.0414)  time: 0.2193  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:27  Loss: 1.2655 (1.2787)  Acc@1: 81.2500 (79.3043)  Acc@5: 93.7500 (96.0352)  time: 0.2168  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 1.1996 (1.2772)  Acc@1: 81.2500 (79.3596)  Acc@5: 100.0000 (96.0745)  time: 0.2168  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:23  Loss: 1.2989 (1.2773)  Acc@1: 81.2500 (79.4490)  Acc@5: 100.0000 (96.0681)  time: 0.2174  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:20  Loss: 1.2949 (1.2752)  Acc@1: 81.2500 (79.4919)  Acc@5: 100.0000 (96.1058)  time: 0.2173  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:18  Loss: 1.0785 (1.2730)  Acc@1: 81.2500 (79.5510)  Acc@5: 100.0000 (96.1252)  time: 0.2161  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:16  Loss: 1.1851 (1.2747)  Acc@1: 75.0000 (79.4631)  Acc@5: 93.7500 (96.0927)  time: 0.2158  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 1.3648 (1.2753)  Acc@1: 75.0000 (79.4366)  Acc@5: 93.7500 (96.0442)  time: 0.2163  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:11  Loss: 1.2482 (1.2746)  Acc@1: 81.2500 (79.4774)  Acc@5: 93.7500 (96.0553)  time: 0.2176  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:09  Loss: 1.3334 (1.2778)  Acc@1: 81.2500 (79.4103)  Acc@5: 93.7500 (95.9921)  time: 0.2179  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:07  Loss: 1.2057 (1.2753)  Acc@1: 81.2500 (79.4747)  Acc@5: 100.0000 (96.0198)  time: 0.2174  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:05  Loss: 1.0749 (1.2744)  Acc@1: 81.2500 (79.4574)  Acc@5: 100.0000 (96.0227)  time: 0.2173  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 1.1847 (1.2762)  Acc@1: 81.2500 (79.4248)  Acc@5: 93.7500 (95.9861)  time: 0.2174  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:03:00  Loss: 1.3331 (1.2767)  Acc@1: 81.2500 (79.4476)  Acc@5: 93.7500 (95.9894)  time: 0.2179  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:58  Loss: 1.2387 (1.2762)  Acc@1: 81.2500 (79.4852)  Acc@5: 100.0000 (96.0080)  time: 0.2182  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:56  Loss: 1.0843 (1.2758)  Acc@1: 81.2500 (79.5067)  Acc@5: 100.0000 (96.0186)  time: 0.2188  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:54  Loss: 1.0843 (1.2751)  Acc@1: 81.2500 (79.5202)  Acc@5: 100.0000 (96.0364)  time: 0.2193  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 1.0854 (1.2732)  Acc@1: 81.2500 (79.5779)  Acc@5: 100.0000 (96.0612)  time: 0.2191  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:49  Loss: 1.2045 (1.2745)  Acc@1: 75.0000 (79.5241)  Acc@5: 100.0000 (96.0635)  time: 0.2183  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:47  Loss: 1.2045 (1.2741)  Acc@1: 81.2500 (79.5804)  Acc@5: 100.0000 (96.0729)  time: 0.2196  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:45  Loss: 1.1779 (1.2722)  Acc@1: 81.2500 (79.5996)  Acc@5: 93.7500 (96.0749)  time: 0.2199  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:43  Loss: 1.3325 (1.2751)  Acc@1: 75.0000 (79.5261)  Acc@5: 100.0000 (96.0840)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 1.4712 (1.2772)  Acc@1: 75.0000 (79.5384)  Acc@5: 93.7500 (96.0438)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 1.3138 (1.2776)  Acc@1: 81.2500 (79.5297)  Acc@5: 93.7500 (96.0530)  time: 0.2194  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:36  Loss: 1.3013 (1.2780)  Acc@1: 75.0000 (79.5349)  Acc@5: 100.0000 (96.0414)  time: 0.2194  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:34  Loss: 1.2367 (1.2764)  Acc@1: 87.5000 (79.5942)  Acc@5: 100.0000 (96.0505)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:32  Loss: 1.1607 (1.2758)  Acc@1: 81.2500 (79.5851)  Acc@5: 100.0000 (96.0392)  time: 0.2198  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 1.1914 (1.2742)  Acc@1: 81.2500 (79.6493)  Acc@5: 100.0000 (96.0680)  time: 0.2201  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 1.2527 (1.2750)  Acc@1: 81.2500 (79.6267)  Acc@5: 100.0000 (96.0699)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:25  Loss: 1.2344 (1.2742)  Acc@1: 81.2500 (79.6111)  Acc@5: 100.0000 (96.0848)  time: 0.2192  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:23  Loss: 1.0765 (1.2733)  Acc@1: 81.2500 (79.6151)  Acc@5: 100.0000 (96.1058)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:21  Loss: 1.1538 (1.2732)  Acc@1: 81.2500 (79.6254)  Acc@5: 100.0000 (96.1073)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 1.3574 (1.2761)  Acc@1: 75.0000 (79.5724)  Acc@5: 93.7500 (96.0835)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 1.4066 (1.2764)  Acc@1: 75.0000 (79.5704)  Acc@5: 93.7500 (96.0602)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 1.2921 (1.2766)  Acc@1: 81.2500 (79.5747)  Acc@5: 93.7500 (96.0497)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:12  Loss: 1.2495 (1.2766)  Acc@1: 81.2500 (79.5972)  Acc@5: 93.7500 (96.0455)  time: 0.2184  data: 0.0003  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:10  Loss: 1.0712 (1.2751)  Acc@1: 81.2500 (79.6375)  Acc@5: 100.0000 (96.0657)  time: 0.2197  data: 0.0005  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 1.0559 (1.2745)  Acc@1: 81.2500 (79.6470)  Acc@5: 100.0000 (96.0795)  time: 0.2195  data: 0.0005  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 1.1796 (1.2734)  Acc@1: 81.2500 (79.6741)  Acc@5: 100.0000 (96.0811)  time: 0.2189  data: 0.0006  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 1.2942 (1.2737)  Acc@1: 81.2500 (79.6654)  Acc@5: 93.7500 (96.0768)  time: 0.2194  data: 0.0006  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:01  Loss: 1.2942 (1.2742)  Acc@1: 81.2500 (79.6802)  Acc@5: 93.7500 (96.0551)  time: 0.2189  data: 0.0003  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:59  Loss: 1.1893 (1.2746)  Acc@1: 81.2500 (79.6889)  Acc@5: 93.7500 (96.0395)  time: 0.2189  data: 0.0003  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 1.2188 (1.2748)  Acc@1: 81.2500 (79.7033)  Acc@5: 100.0000 (96.0587)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 1.1633 (1.2733)  Acc@1: 81.2500 (79.7173)  Acc@5: 100.0000 (96.0888)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 1.1829 (1.2738)  Acc@1: 81.2500 (79.6973)  Acc@5: 100.0000 (96.0902)  time: 0.2198  data: 0.0004  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:50  Loss: 1.3006 (1.2745)  Acc@1: 75.0000 (79.6722)  Acc@5: 100.0000 (96.0972)  time: 0.2210  data: 0.0004  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:48  Loss: 1.3764 (1.2759)  Acc@1: 75.0000 (79.6364)  Acc@5: 100.0000 (96.0820)  time: 0.2204  data: 0.0003  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 1.3827 (1.2772)  Acc@1: 75.0000 (79.6122)  Acc@5: 100.0000 (96.0999)  time: 0.2183  data: 0.0003  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 1.4021 (1.2784)  Acc@1: 75.0000 (79.5667)  Acc@5: 100.0000 (96.0904)  time: 0.2182  data: 0.0003  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 1.2292 (1.2771)  Acc@1: 81.2500 (79.6135)  Acc@5: 100.0000 (96.0971)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 1.1449 (1.2761)  Acc@1: 81.2500 (79.6541)  Acc@5: 100.0000 (96.1091)  time: 0.2181  data: 0.0003  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:37  Loss: 1.2660 (1.2768)  Acc@1: 81.2500 (79.6359)  Acc@5: 100.0000 (96.1262)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 1.3515 (1.2777)  Acc@1: 75.0000 (79.6232)  Acc@5: 100.0000 (96.1167)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 1.2416 (1.2776)  Acc@1: 81.2500 (79.6211)  Acc@5: 93.7500 (96.1022)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 1.2163 (1.2787)  Acc@1: 81.2500 (79.5985)  Acc@5: 93.7500 (96.0931)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 1.2277 (1.2783)  Acc@1: 75.0000 (79.5710)  Acc@5: 100.0000 (96.1046)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 1.3076 (1.2795)  Acc@1: 75.0000 (79.5035)  Acc@5: 100.0000 (96.1058)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 1.2489 (1.2785)  Acc@1: 81.2500 (79.5276)  Acc@5: 100.0000 (96.1070)  time: 0.2192  data: 0.0004  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 1.2044 (1.2789)  Acc@1: 81.2500 (79.5264)  Acc@5: 100.0000 (96.1131)  time: 0.2200  data: 0.0004  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 1.2044 (1.2787)  Acc@1: 81.2500 (79.5351)  Acc@5: 93.7500 (96.1043)  time: 0.2203  data: 0.0004  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 1.1841 (1.2790)  Acc@1: 81.2500 (79.5437)  Acc@5: 93.7500 (96.1005)  time: 0.2193  data: 0.0005  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 1.1601 (1.2770)  Acc@1: 81.2500 (79.5326)  Acc@5: 100.0000 (96.1212)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 1.1601 (1.2775)  Acc@1: 75.0000 (79.4684)  Acc@5: 100.0000 (96.1174)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 1.3231 (1.2770)  Acc@1: 75.0000 (79.4581)  Acc@5: 100.0000 (96.1328)  time: 0.2185  data: 0.0003  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 1.1809 (1.2756)  Acc@1: 87.5000 (79.5147)  Acc@5: 100.0000 (96.1432)  time: 0.2186  data: 0.0003  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 0.9888 (1.2742)  Acc@1: 87.5000 (79.5420)  Acc@5: 100.0000 (96.1535)  time: 0.2192  data: 0.0003  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 1.1227 (1.2743)  Acc@1: 81.2500 (79.5361)  Acc@5: 100.0000 (96.1589)  time: 0.2195  data: 0.0004  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.2413 (1.2745)  Acc@1: 75.0000 (79.5302)  Acc@5: 100.0000 (96.1642)  time: 0.2190  data: 0.0004  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 1.1264 (1.2741)  Acc@1: 81.2500 (79.5661)  Acc@5: 100.0000 (96.1741)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 1.1555 (1.2735)  Acc@1: 81.2500 (79.5830)  Acc@5: 100.0000 (96.1931)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 1.1555 (1.2733)  Acc@1: 81.2500 (79.5815)  Acc@5: 100.0000 (96.1889)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 1.2185 (1.2735)  Acc@1: 75.0000 (79.5800)  Acc@5: 93.7500 (96.1939)  time: 0.2204  data: 0.0005  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.1963 (1.2727)  Acc@1: 81.2500 (79.6055)  Acc@5: 100.0000 (96.1988)  time: 0.2202  data: 0.0005  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.1436 (1.2731)  Acc@1: 81.2500 (79.5771)  Acc@5: 93.7500 (96.1858)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 1.1402 (1.2727)  Acc@1: 81.2500 (79.6022)  Acc@5: 93.7500 (96.1951)  time: 0.2186  data: 0.0003  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.1402 (1.2723)  Acc@1: 81.2500 (79.6094)  Acc@5: 100.0000 (96.1955)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.4237 (1.2741)  Acc@1: 75.0000 (79.5729)  Acc@5: 93.7500 (96.1696)  time: 0.2196  data: 0.0003  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.2764 (1.2738)  Acc@1: 75.0000 (79.5758)  Acc@5: 93.7500 (96.1659)  time: 0.2199  data: 0.0007  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.2634 (1.2748)  Acc@1: 81.2500 (79.5529)  Acc@5: 93.7500 (96.1578)  time: 0.2192  data: 0.0007  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.2794 (1.2753)  Acc@1: 81.2500 (79.5217)  Acc@5: 93.7500 (96.1542)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.2577 (1.2758)  Acc@1: 81.2500 (79.4995)  Acc@5: 100.0000 (96.1548)  time: 0.2186  data: 0.0003  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 1.2878 (1.2764)  Acc@1: 81.2500 (79.5113)  Acc@5: 93.7500 (96.1386)  time: 0.2208  data: 0.0003  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.3010 (1.2766)  Acc@1: 81.2500 (79.5104)  Acc@5: 93.7500 (96.1435)  time: 0.2206  data: 0.0003  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.2480 (1.2770)  Acc@1: 81.2500 (79.5137)  Acc@5: 100.0000 (96.1401)  time: 0.2181  data: 0.0003  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.0059 (1.2767)  Acc@1: 81.2500 (79.5086)  Acc@5: 100.0000 (96.1367)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.0006 (1.2756)  Acc@1: 81.2500 (79.5201)  Acc@5: 100.0000 (96.1456)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.0224 (1.2751)  Acc@1: 81.2500 (79.5395)  Acc@5: 100.0000 (96.1504)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 0.9842 (1.2738)  Acc@1: 87.5000 (79.5668)  Acc@5: 100.0000 (96.1632)  time: 0.2201  data: 0.0003  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 1.0873 (1.2738)  Acc@1: 87.5000 (79.5777)  Acc@5: 100.0000 (96.1678)  time: 0.2199  data: 0.0003  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 1.0873 (1.2726)  Acc@1: 87.5000 (79.6244)  Acc@5: 100.0000 (96.1763)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.0677 (1.2726)  Acc@1: 87.5000 (79.6268)  Acc@5: 100.0000 (96.1688)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.1852 (1.2722)  Acc@1: 81.2500 (79.6608)  Acc@5: 100.0000 (96.1694)  time: 0.2180  data: 0.0004  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.1883 (1.2725)  Acc@1: 81.2500 (79.6394)  Acc@5: 100.0000 (96.1659)  time: 0.2183  data: 0.0003  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.2366 (1.2735)  Acc@1: 75.0000 (79.6221)  Acc@5: 93.7500 (96.1352)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.2232 (1.2729)  Acc@1: 75.0000 (79.6206)  Acc@5: 93.7500 (96.1359)  time: 0.2181  data: 0.0003  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.1908 (1.2723)  Acc@1: 81.2500 (79.6268)  Acc@5: 93.7500 (96.1444)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.1088 (1.2716)  Acc@1: 81.2500 (79.6366)  Acc@5: 93.7500 (96.1394)  time: 0.2177  data: 0.0002  max mem: 2500
Test: [Task 1] Total time: 0:05:56 (0.2191 s / it)
* Acc@1 79.637 Acc@5 96.139 loss 1.272
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task1]	Acc@1: 79.6366	Acc@5: 96.1394	Loss: 1.2716
Train: Epoch[1/1]  [   0/3750]  eta: 0:53:22  Lr: 0.001875  Loss: 0.8481  Acc@1: 18.7500 (18.7500)  Acc@5: 75.0000 (75.0000)  time: 0.8540  data: 0.4890  max mem: 2500
Train: Epoch[1/1]  [  10/3750]  eta: 0:24:38  Lr: 0.001875  Loss: 0.8719  Acc@1: 12.5000 (17.0455)  Acc@5: 62.5000 (62.5000)  time: 0.3952  data: 0.0448  max mem: 2501
Train: Epoch[1/1]  [  20/3750]  eta: 0:23:16  Lr: 0.001875  Loss: 0.4181  Acc@1: 25.0000 (27.0833)  Acc@5: 81.2500 (73.8095)  time: 0.3504  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [  30/3750]  eta: 0:22:46  Lr: 0.001875  Loss: 0.3630  Acc@1: 37.5000 (29.8387)  Acc@5: 87.5000 (78.0242)  time: 0.3520  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [  40/3750]  eta: 0:22:29  Lr: 0.001875  Loss: 0.3039  Acc@1: 37.5000 (33.6890)  Acc@5: 87.5000 (81.0976)  time: 0.3528  data: 0.0012  max mem: 2501
Train: Epoch[1/1]  [  50/3750]  eta: 0:22:18  Lr: 0.001875  Loss: 0.1908  Acc@1: 50.0000 (36.8873)  Acc@5: 87.5000 (81.4951)  time: 0.3534  data: 0.0021  max mem: 2501
Train: Epoch[1/1]  [  60/3750]  eta: 0:22:09  Lr: 0.001875  Loss: 0.2127  Acc@1: 50.0000 (39.3443)  Acc@5: 87.5000 (82.7869)  time: 0.3529  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [  70/3750]  eta: 0:22:00  Lr: 0.001875  Loss: -0.0097  Acc@1: 56.2500 (42.2535)  Acc@5: 93.7500 (84.0669)  time: 0.3515  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [  80/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -0.2082  Acc@1: 56.2500 (44.3673)  Acc@5: 93.7500 (84.8765)  time: 0.3536  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [  90/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -0.1267  Acc@1: 56.2500 (45.1236)  Acc@5: 87.5000 (85.5082)  time: 0.3533  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 100/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.1802  Acc@1: 50.0000 (46.3490)  Acc@5: 93.7500 (86.1386)  time: 0.3502  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 110/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -0.3935  Acc@1: 56.2500 (47.3536)  Acc@5: 93.7500 (86.1486)  time: 0.3504  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 120/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -0.1812  Acc@1: 62.5000 (48.9669)  Acc@5: 93.7500 (86.9318)  time: 0.3525  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 130/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.4123  Acc@1: 62.5000 (49.7137)  Acc@5: 93.7500 (87.3092)  time: 0.3542  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 140/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.5807  Acc@1: 62.5000 (50.8422)  Acc@5: 93.7500 (87.6773)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 150/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.3595  Acc@1: 62.5000 (51.6970)  Acc@5: 93.7500 (87.8311)  time: 0.3531  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [ 160/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.4149  Acc@1: 62.5000 (52.6786)  Acc@5: 93.7500 (88.1988)  time: 0.3533  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [ 170/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.3618  Acc@1: 62.5000 (53.3626)  Acc@5: 93.7500 (88.4503)  time: 0.3523  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 180/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.4753  Acc@1: 68.7500 (54.1782)  Acc@5: 93.7500 (88.7776)  time: 0.3540  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [ 190/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.2643  Acc@1: 62.5000 (54.5812)  Acc@5: 93.7500 (88.8416)  time: 0.3529  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [ 200/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.1808  Acc@1: 62.5000 (55.2550)  Acc@5: 93.7500 (88.9614)  time: 0.3510  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [ 210/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.7187  Acc@1: 68.7500 (55.8945)  Acc@5: 93.7500 (89.1291)  time: 0.3522  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [ 220/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.5033  Acc@1: 62.5000 (56.0520)  Acc@5: 93.7500 (89.2534)  time: 0.3524  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 230/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.1260  Acc@1: 56.2500 (56.3312)  Acc@5: 93.7500 (89.4210)  time: 0.3519  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 240/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.4841  Acc@1: 68.7500 (57.0539)  Acc@5: 93.7500 (89.6525)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 250/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.2571  Acc@1: 68.7500 (57.3456)  Acc@5: 93.7500 (89.8157)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 260/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.3466  Acc@1: 62.5000 (57.6389)  Acc@5: 93.7500 (89.8228)  time: 0.3520  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 270/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.8813  Acc@1: 68.7500 (58.1181)  Acc@5: 93.7500 (89.9677)  time: 0.3531  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 280/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.4008  Acc@1: 68.7500 (58.5187)  Acc@5: 93.7500 (90.1023)  time: 0.3541  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 290/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.4832  Acc@1: 68.7500 (58.9347)  Acc@5: 93.7500 (90.1203)  time: 0.3533  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 300/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.5981  Acc@1: 68.7500 (59.3439)  Acc@5: 93.7500 (90.3862)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 310/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.1838  Acc@1: 68.7500 (59.5056)  Acc@5: 93.7500 (90.4743)  time: 0.3530  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 320/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -0.6033  Acc@1: 62.5000 (59.7936)  Acc@5: 93.7500 (90.4790)  time: 0.3544  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 330/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.4221  Acc@1: 68.7500 (60.2719)  Acc@5: 93.7500 (90.5211)  time: 0.3535  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 340/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.5043  Acc@1: 75.0000 (60.6122)  Acc@5: 93.7500 (90.5975)  time: 0.3520  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 350/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.1836  Acc@1: 75.0000 (60.8796)  Acc@5: 93.7500 (90.6161)  time: 0.3529  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 360/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.3153  Acc@1: 68.7500 (61.0630)  Acc@5: 93.7500 (90.6510)  time: 0.3541  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 370/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -0.6413  Acc@1: 62.5000 (61.1523)  Acc@5: 93.7500 (90.7177)  time: 0.3548  data: 0.0010  max mem: 2501
Train: Epoch[1/1]  [ 380/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.3414  Acc@1: 62.5000 (61.4173)  Acc@5: 93.7500 (90.7972)  time: 0.3544  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [ 390/3750]  eta: 0:19:49  Lr: 0.001875  Loss: 0.2353  Acc@1: 68.7500 (61.5090)  Acc@5: 93.7500 (90.8568)  time: 0.3535  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [ 400/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.3948  Acc@1: 68.7500 (61.7207)  Acc@5: 93.7500 (90.9913)  time: 0.3524  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [ 410/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.3770  Acc@1: 68.7500 (61.9069)  Acc@5: 93.7500 (91.0888)  time: 0.3523  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [ 420/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -1.1868  Acc@1: 75.0000 (62.0695)  Acc@5: 93.7500 (91.1520)  time: 0.3532  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [ 430/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.8281  Acc@1: 68.7500 (62.2100)  Acc@5: 100.0000 (91.3138)  time: 0.3525  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 440/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.2542  Acc@1: 68.7500 (62.2874)  Acc@5: 100.0000 (91.3974)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 450/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.8048  Acc@1: 68.7500 (62.5139)  Acc@5: 100.0000 (91.5327)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 460/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.2789  Acc@1: 68.7500 (62.5407)  Acc@5: 93.7500 (91.5537)  time: 0.3514  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 470/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.7937  Acc@1: 62.5000 (62.7123)  Acc@5: 93.7500 (91.6534)  time: 0.3534  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [ 480/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.2935  Acc@1: 75.0000 (62.9808)  Acc@5: 93.7500 (91.7230)  time: 0.3544  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [ 490/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.8054  Acc@1: 75.0000 (63.1746)  Acc@5: 93.7500 (91.8152)  time: 0.3533  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 500/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.5705  Acc@1: 75.0000 (63.3733)  Acc@5: 100.0000 (91.9037)  time: 0.3537  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 510/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.5272  Acc@1: 68.7500 (63.4540)  Acc@5: 93.7500 (91.9765)  time: 0.3532  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 520/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.6690  Acc@1: 75.0000 (63.6996)  Acc@5: 93.7500 (92.0226)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 530/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.8551  Acc@1: 75.0000 (63.8653)  Acc@5: 93.7500 (92.0433)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 540/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.2457  Acc@1: 68.7500 (63.9903)  Acc@5: 93.7500 (92.0518)  time: 0.3523  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [ 550/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.4183  Acc@1: 68.7500 (64.0767)  Acc@5: 93.7500 (92.1279)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 560/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.6750  Acc@1: 68.7500 (64.2268)  Acc@5: 100.0000 (92.2014)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 570/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.9248  Acc@1: 75.0000 (64.4812)  Acc@5: 100.0000 (92.2833)  time: 0.3528  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 580/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.9106  Acc@1: 75.0000 (64.5546)  Acc@5: 93.7500 (92.2655)  time: 0.3529  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 590/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.4739  Acc@1: 68.7500 (64.5516)  Acc@5: 93.7500 (92.3223)  time: 0.3521  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [ 600/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.7235  Acc@1: 68.7500 (64.6007)  Acc@5: 93.7500 (92.3461)  time: 0.3517  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 610/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.6933  Acc@1: 68.7500 (64.6993)  Acc@5: 93.7500 (92.3895)  time: 0.3526  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [ 620/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.5896  Acc@1: 68.7500 (64.8450)  Acc@5: 93.7500 (92.4316)  time: 0.3515  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 630/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.7857  Acc@1: 81.2500 (65.0753)  Acc@5: 93.7500 (92.4822)  time: 0.3515  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 640/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.5238  Acc@1: 75.0000 (65.1521)  Acc@5: 93.7500 (92.5020)  time: 0.3516  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 650/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.5894  Acc@1: 68.7500 (65.2170)  Acc@5: 93.7500 (92.5211)  time: 0.3513  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 660/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.8011  Acc@1: 75.0000 (65.4595)  Acc@5: 93.7500 (92.5681)  time: 0.3510  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 670/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.8358  Acc@1: 75.0000 (65.6110)  Acc@5: 93.7500 (92.5950)  time: 0.3503  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 680/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -1.0677  Acc@1: 75.0000 (65.7764)  Acc@5: 100.0000 (92.6670)  time: 0.3519  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [ 690/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.9547  Acc@1: 75.0000 (65.8647)  Acc@5: 100.0000 (92.7551)  time: 0.3524  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [ 700/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -1.2263  Acc@1: 81.2500 (66.0218)  Acc@5: 100.0000 (92.8049)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 710/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.5227  Acc@1: 75.0000 (66.1217)  Acc@5: 100.0000 (92.8622)  time: 0.3532  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [ 720/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.6198  Acc@1: 68.7500 (66.1928)  Acc@5: 100.0000 (92.9178)  time: 0.3523  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 730/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.6918  Acc@1: 68.7500 (66.2021)  Acc@5: 93.7500 (92.9207)  time: 0.3513  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 740/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -1.0078  Acc@1: 68.7500 (66.3377)  Acc@5: 93.7500 (92.9487)  time: 0.3506  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 750/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.7385  Acc@1: 68.7500 (66.3698)  Acc@5: 93.7500 (92.9344)  time: 0.3508  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 760/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.5951  Acc@1: 75.0000 (66.4750)  Acc@5: 93.7500 (92.9451)  time: 0.3513  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 770/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6656  Acc@1: 75.0000 (66.6586)  Acc@5: 100.0000 (93.0123)  time: 0.3509  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 780/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.7751  Acc@1: 75.0000 (66.7414)  Acc@5: 93.7500 (93.0218)  time: 0.3513  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 790/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.5922  Acc@1: 68.7500 (66.7905)  Acc@5: 93.7500 (93.0626)  time: 0.3516  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 800/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -1.0303  Acc@1: 75.0000 (66.9007)  Acc@5: 93.7500 (93.1102)  time: 0.3518  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [ 810/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.7159  Acc@1: 75.0000 (67.0469)  Acc@5: 100.0000 (93.1720)  time: 0.3519  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [ 820/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -0.9867  Acc@1: 75.0000 (67.1742)  Acc@5: 100.0000 (93.2095)  time: 0.3512  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 830/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.6895  Acc@1: 75.0000 (67.1856)  Acc@5: 93.7500 (93.2310)  time: 0.3537  data: 0.0016  max mem: 2501
Train: Epoch[1/1]  [ 840/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -1.0950  Acc@1: 75.0000 (67.2860)  Acc@5: 93.7500 (93.2372)  time: 0.3543  data: 0.0016  max mem: 2501
Train: Epoch[1/1]  [ 850/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.8157  Acc@1: 75.0000 (67.4207)  Acc@5: 93.7500 (93.2800)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 860/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -1.1272  Acc@1: 75.0000 (67.4869)  Acc@5: 100.0000 (93.3362)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 870/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.8369  Acc@1: 75.0000 (67.5875)  Acc@5: 100.0000 (93.3410)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 880/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.7166  Acc@1: 75.0000 (67.6433)  Acc@5: 93.7500 (93.3811)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 890/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.8209  Acc@1: 75.0000 (67.7399)  Acc@5: 100.0000 (93.4273)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 900/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.6391  Acc@1: 68.7500 (67.7580)  Acc@5: 93.7500 (93.4309)  time: 0.3520  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 910/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -1.0840  Acc@1: 68.7500 (67.8513)  Acc@5: 93.7500 (93.4481)  time: 0.3537  data: 0.0012  max mem: 2501
Train: Epoch[1/1]  [ 920/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.1838  Acc@1: 75.0000 (67.8950)  Acc@5: 93.7500 (93.4650)  time: 0.3548  data: 0.0011  max mem: 2501
Train: Epoch[1/1]  [ 930/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.6692  Acc@1: 81.2500 (68.0183)  Acc@5: 93.7500 (93.4748)  time: 0.3536  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 940/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.7788  Acc@1: 81.2500 (68.1589)  Acc@5: 93.7500 (93.4976)  time: 0.3537  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [ 950/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.9564  Acc@1: 81.2500 (68.2308)  Acc@5: 93.7500 (93.5200)  time: 0.3542  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 960/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.7022  Acc@1: 75.0000 (68.2622)  Acc@5: 93.7500 (93.5419)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [ 970/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.8330  Acc@1: 75.0000 (68.3252)  Acc@5: 100.0000 (93.5955)  time: 0.3535  data: 0.0008  max mem: 2501
Train: Epoch[1/1]  [ 980/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.8161  Acc@1: 75.0000 (68.4569)  Acc@5: 100.0000 (93.6290)  time: 0.3532  data: 0.0008  max mem: 2501
Train: Epoch[1/1]  [ 990/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -1.2594  Acc@1: 75.0000 (68.4977)  Acc@5: 100.0000 (93.6806)  time: 0.3525  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1000/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.8542  Acc@1: 75.0000 (68.5689)  Acc@5: 100.0000 (93.6813)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1010/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.9765  Acc@1: 81.2500 (68.6882)  Acc@5: 93.7500 (93.7191)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1020/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -1.1299  Acc@1: 75.0000 (68.7622)  Acc@5: 100.0000 (93.7316)  time: 0.3533  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1030/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.7019  Acc@1: 75.0000 (68.8046)  Acc@5: 93.7500 (93.7439)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1040/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.8773  Acc@1: 75.0000 (68.8461)  Acc@5: 100.0000 (93.7680)  time: 0.3511  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1050/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.3868  Acc@1: 68.7500 (68.8392)  Acc@5: 93.7500 (93.7857)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1060/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -0.7663  Acc@1: 68.7500 (68.9032)  Acc@5: 100.0000 (93.8207)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1070/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.7172  Acc@1: 75.0000 (68.9426)  Acc@5: 100.0000 (93.8317)  time: 0.3516  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1080/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.7228  Acc@1: 75.0000 (69.0160)  Acc@5: 93.7500 (93.8599)  time: 0.3508  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1090/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.4336  Acc@1: 75.0000 (69.0593)  Acc@5: 93.7500 (93.8302)  time: 0.3505  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1100/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.4319  Acc@1: 75.0000 (69.1303)  Acc@5: 93.7500 (93.8238)  time: 0.3508  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1110/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.3825  Acc@1: 75.0000 (69.1832)  Acc@5: 93.7500 (93.8175)  time: 0.3523  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1120/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.7095  Acc@1: 81.2500 (69.2574)  Acc@5: 93.7500 (93.8392)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1130/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -1.2699  Acc@1: 81.2500 (69.3192)  Acc@5: 100.0000 (93.8605)  time: 0.3520  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1140/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.6444  Acc@1: 75.0000 (69.3252)  Acc@5: 93.7500 (93.8486)  time: 0.3512  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1150/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.5491  Acc@1: 75.0000 (69.4016)  Acc@5: 93.7500 (93.8586)  time: 0.3508  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1160/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.4819  Acc@1: 75.0000 (69.4121)  Acc@5: 93.7500 (93.8846)  time: 0.3513  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1170/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -1.1017  Acc@1: 75.0000 (69.4972)  Acc@5: 100.0000 (93.9048)  time: 0.3517  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1180/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.7310  Acc@1: 75.0000 (69.5121)  Acc@5: 93.7500 (93.9141)  time: 0.3517  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1190/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -1.0861  Acc@1: 75.0000 (69.5476)  Acc@5: 93.7500 (93.9232)  time: 0.3528  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1200/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.9640  Acc@1: 81.2500 (69.6399)  Acc@5: 100.0000 (93.9634)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1210/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.8569  Acc@1: 75.0000 (69.6274)  Acc@5: 100.0000 (93.9719)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1220/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.7554  Acc@1: 75.0000 (69.6970)  Acc@5: 100.0000 (93.9855)  time: 0.3554  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [1230/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.8315  Acc@1: 75.0000 (69.6893)  Acc@5: 93.7500 (93.9734)  time: 0.3547  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [1240/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.9834  Acc@1: 62.5000 (69.7371)  Acc@5: 93.7500 (93.9867)  time: 0.3510  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1250/3750]  eta: 0:14:42  Lr: 0.001875  Loss: 0.3078  Acc@1: 75.0000 (69.7542)  Acc@5: 93.7500 (93.9948)  time: 0.3504  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1260/3750]  eta: 0:14:38  Lr: 0.001875  Loss: 0.3328  Acc@1: 75.0000 (69.7809)  Acc@5: 93.7500 (93.9730)  time: 0.3511  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1270/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.2937  Acc@1: 75.0000 (69.7876)  Acc@5: 93.7500 (93.9614)  time: 0.3505  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1280/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.1688  Acc@1: 68.7500 (69.7795)  Acc@5: 93.7500 (93.9452)  time: 0.3492  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1290/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -1.0518  Acc@1: 68.7500 (69.8441)  Acc@5: 93.7500 (93.9630)  time: 0.3500  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1300/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.4670  Acc@1: 75.0000 (69.8837)  Acc@5: 100.0000 (93.9806)  time: 0.3500  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1310/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -1.0709  Acc@1: 75.0000 (69.9228)  Acc@5: 93.7500 (93.9931)  time: 0.3502  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1320/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.9400  Acc@1: 81.2500 (70.0274)  Acc@5: 93.7500 (94.0055)  time: 0.3511  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1330/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -1.0075  Acc@1: 81.2500 (70.0648)  Acc@5: 93.7500 (94.0224)  time: 0.3509  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1340/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.0089  Acc@1: 81.2500 (70.1202)  Acc@5: 93.7500 (94.0483)  time: 0.3512  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1350/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.8146  Acc@1: 81.2500 (70.1564)  Acc@5: 93.7500 (94.0553)  time: 0.3509  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1360/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.7408  Acc@1: 75.0000 (70.2057)  Acc@5: 93.7500 (94.0760)  time: 0.3509  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1370/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.8939  Acc@1: 75.0000 (70.2225)  Acc@5: 93.7500 (94.0646)  time: 0.3510  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1380/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.9271  Acc@1: 81.2500 (70.2752)  Acc@5: 93.7500 (94.0668)  time: 0.3502  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [1390/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -1.1620  Acc@1: 81.2500 (70.3271)  Acc@5: 93.7500 (94.0780)  time: 0.3492  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1400/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.8919  Acc@1: 68.7500 (70.3337)  Acc@5: 93.7500 (94.0890)  time: 0.3497  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1410/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.9615  Acc@1: 75.0000 (70.3535)  Acc@5: 93.7500 (94.0999)  time: 0.3509  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1420/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.7842  Acc@1: 75.0000 (70.3774)  Acc@5: 93.7500 (94.1107)  time: 0.3507  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1430/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -1.0729  Acc@1: 75.0000 (70.4271)  Acc@5: 100.0000 (94.1256)  time: 0.3517  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1440/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.7584  Acc@1: 75.0000 (70.4936)  Acc@5: 93.7500 (94.1360)  time: 0.3524  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1450/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.8079  Acc@1: 75.0000 (70.5289)  Acc@5: 93.7500 (94.1290)  time: 0.3520  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1460/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.9179  Acc@1: 75.0000 (70.5724)  Acc@5: 93.7500 (94.1521)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1470/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.9562  Acc@1: 75.0000 (70.6025)  Acc@5: 100.0000 (94.1664)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1480/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9179  Acc@1: 75.0000 (70.6575)  Acc@5: 100.0000 (94.1847)  time: 0.3517  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1490/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.9001  Acc@1: 75.0000 (70.6615)  Acc@5: 93.7500 (94.1901)  time: 0.3523  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1500/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.7440  Acc@1: 68.7500 (70.6654)  Acc@5: 93.7500 (94.1914)  time: 0.3532  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1510/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -1.0042  Acc@1: 75.0000 (70.7148)  Acc@5: 93.7500 (94.2009)  time: 0.3533  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1520/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -1.1643  Acc@1: 75.0000 (70.7717)  Acc@5: 93.7500 (94.2143)  time: 0.3533  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1530/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.6300  Acc@1: 75.0000 (70.7871)  Acc@5: 100.0000 (94.2399)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1540/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -1.1601  Acc@1: 75.0000 (70.8428)  Acc@5: 100.0000 (94.2732)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1550/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -1.0016  Acc@1: 81.2500 (70.8817)  Acc@5: 100.0000 (94.2819)  time: 0.3531  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1560/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -1.0483  Acc@1: 81.2500 (70.9241)  Acc@5: 93.7500 (94.2905)  time: 0.3526  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1570/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.5562  Acc@1: 81.2500 (70.9659)  Acc@5: 93.7500 (94.3030)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1580/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.9417  Acc@1: 81.2500 (71.0349)  Acc@5: 100.0000 (94.3193)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1590/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.4543  Acc@1: 81.2500 (71.0363)  Acc@5: 93.7500 (94.3118)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1600/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.8374  Acc@1: 75.0000 (71.0767)  Acc@5: 93.7500 (94.3239)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1610/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -1.0441  Acc@1: 81.2500 (71.1127)  Acc@5: 93.7500 (94.3242)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1620/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.3770  Acc@1: 68.7500 (71.1097)  Acc@5: 93.7500 (94.3322)  time: 0.3544  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1630/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.9738  Acc@1: 75.0000 (71.1527)  Acc@5: 93.7500 (94.3363)  time: 0.3549  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [1640/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.4086  Acc@1: 81.2500 (71.1723)  Acc@5: 93.7500 (94.3327)  time: 0.3537  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [1650/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.5522  Acc@1: 75.0000 (71.1841)  Acc@5: 93.7500 (94.3292)  time: 0.3518  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1660/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.7690  Acc@1: 75.0000 (71.2410)  Acc@5: 93.7500 (94.3445)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1670/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.2635  Acc@1: 75.0000 (71.2560)  Acc@5: 93.7500 (94.3335)  time: 0.3532  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1680/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.3264  Acc@1: 75.0000 (71.2634)  Acc@5: 93.7500 (94.3486)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1690/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -1.1451  Acc@1: 75.0000 (71.3114)  Acc@5: 93.7500 (94.3562)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1700/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -1.0318  Acc@1: 81.2500 (71.3808)  Acc@5: 100.0000 (94.3783)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1710/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.0656  Acc@1: 81.2500 (71.4166)  Acc@5: 93.7500 (94.3783)  time: 0.3533  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1720/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.7261  Acc@1: 81.2500 (71.4555)  Acc@5: 100.0000 (94.4001)  time: 0.3537  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1730/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -1.0419  Acc@1: 81.2500 (71.4941)  Acc@5: 100.0000 (94.4071)  time: 0.3537  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1740/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.8125  Acc@1: 75.0000 (71.5250)  Acc@5: 100.0000 (94.4213)  time: 0.3528  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1750/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.3209  Acc@1: 75.0000 (71.5306)  Acc@5: 93.7500 (94.4210)  time: 0.3524  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1760/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -1.0687  Acc@1: 75.0000 (71.5822)  Acc@5: 93.7500 (94.4421)  time: 0.3535  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1770/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.4006  Acc@1: 81.2500 (71.6191)  Acc@5: 100.0000 (94.4382)  time: 0.3532  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1780/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.9850  Acc@1: 75.0000 (71.6381)  Acc@5: 93.7500 (94.4413)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1790/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -1.0182  Acc@1: 75.0000 (71.6709)  Acc@5: 100.0000 (94.4619)  time: 0.3532  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1800/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.4585  Acc@1: 75.0000 (71.7206)  Acc@5: 100.0000 (94.4822)  time: 0.3531  data: 0.0008  max mem: 2501
Train: Epoch[1/1]  [1810/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.2927  Acc@1: 81.2500 (71.7628)  Acc@5: 100.0000 (94.4954)  time: 0.3517  data: 0.0008  max mem: 2501
Train: Epoch[1/1]  [1820/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.4518  Acc@1: 81.2500 (71.7978)  Acc@5: 100.0000 (94.4879)  time: 0.3527  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1830/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.8076  Acc@1: 81.2500 (71.8323)  Acc@5: 93.7500 (94.4736)  time: 0.3529  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1840/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -1.0142  Acc@1: 75.0000 (71.8258)  Acc@5: 93.7500 (94.4663)  time: 0.3520  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1850/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.5370  Acc@1: 75.0000 (71.8733)  Acc@5: 93.7500 (94.4726)  time: 0.3526  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1860/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -1.1150  Acc@1: 81.2500 (71.9002)  Acc@5: 93.7500 (94.4754)  time: 0.3529  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1870/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -1.2744  Acc@1: 81.2500 (71.9568)  Acc@5: 100.0000 (94.5016)  time: 0.3520  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1880/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.7594  Acc@1: 81.2500 (71.9730)  Acc@5: 100.0000 (94.5076)  time: 0.3525  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1890/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.4424  Acc@1: 75.0000 (71.9923)  Acc@5: 100.0000 (94.5201)  time: 0.3535  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [1900/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.7682  Acc@1: 75.0000 (72.0082)  Acc@5: 93.7500 (94.5226)  time: 0.3529  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [1910/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.4446  Acc@1: 75.0000 (72.0271)  Acc@5: 93.7500 (94.5153)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1920/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -1.1843  Acc@1: 81.2500 (72.0686)  Acc@5: 93.7500 (94.5341)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1930/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7602  Acc@1: 81.2500 (72.1161)  Acc@5: 100.0000 (94.5365)  time: 0.3536  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [1940/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.8226  Acc@1: 81.2500 (72.1696)  Acc@5: 100.0000 (94.5518)  time: 0.3535  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1950/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4778  Acc@1: 81.2500 (72.2002)  Acc@5: 100.0000 (94.5509)  time: 0.3520  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1960/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -1.2133  Acc@1: 81.2500 (72.2622)  Acc@5: 100.0000 (94.5755)  time: 0.3521  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [1970/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -0.7639  Acc@1: 81.2500 (72.2761)  Acc@5: 100.0000 (94.5840)  time: 0.3535  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1980/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.5120  Acc@1: 75.0000 (72.3246)  Acc@5: 93.7500 (94.5861)  time: 0.3542  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [1990/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -1.0754  Acc@1: 81.2500 (72.3726)  Acc@5: 100.0000 (94.5976)  time: 0.3538  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2000/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.4967  Acc@1: 81.2500 (72.3919)  Acc@5: 100.0000 (94.6027)  time: 0.3538  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2010/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.9734  Acc@1: 75.0000 (72.4111)  Acc@5: 93.7500 (94.6047)  time: 0.3534  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2020/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.8493  Acc@1: 75.0000 (72.4177)  Acc@5: 100.0000 (94.6035)  time: 0.3519  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2030/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -1.1639  Acc@1: 75.0000 (72.4181)  Acc@5: 100.0000 (94.6147)  time: 0.3508  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2040/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.9093  Acc@1: 75.0000 (72.4461)  Acc@5: 93.7500 (94.6105)  time: 0.3507  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2050/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -1.2132  Acc@1: 81.2500 (72.4860)  Acc@5: 93.7500 (94.6185)  time: 0.3501  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2060/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.7494  Acc@1: 75.0000 (72.4739)  Acc@5: 93.7500 (94.6234)  time: 0.3499  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2070/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -1.0705  Acc@1: 75.0000 (72.4982)  Acc@5: 93.7500 (94.6312)  time: 0.3513  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2080/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.9615  Acc@1: 81.2500 (72.5192)  Acc@5: 100.0000 (94.6330)  time: 0.3512  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2090/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.5135  Acc@1: 81.2500 (72.5401)  Acc@5: 100.0000 (94.6497)  time: 0.3496  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2100/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.7834  Acc@1: 81.2500 (72.5934)  Acc@5: 100.0000 (94.6603)  time: 0.3514  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2110/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -1.0066  Acc@1: 81.2500 (72.6285)  Acc@5: 100.0000 (94.6708)  time: 0.3547  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2120/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -1.0453  Acc@1: 81.2500 (72.6544)  Acc@5: 100.0000 (94.6782)  time: 0.3556  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2130/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.7632  Acc@1: 75.0000 (72.6625)  Acc@5: 93.7500 (94.6827)  time: 0.3543  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2140/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.9594  Acc@1: 81.2500 (72.7055)  Acc@5: 100.0000 (94.6900)  time: 0.3539  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2150/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.3519  Acc@1: 75.0000 (72.6900)  Acc@5: 93.7500 (94.6856)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2160/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.9182  Acc@1: 68.7500 (72.7065)  Acc@5: 93.7500 (94.6697)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2170/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.8184  Acc@1: 81.2500 (72.7430)  Acc@5: 93.7500 (94.6856)  time: 0.3541  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2180/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -1.0675  Acc@1: 81.2500 (72.7591)  Acc@5: 100.0000 (94.6899)  time: 0.3544  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2190/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -1.0001  Acc@1: 75.0000 (72.7835)  Acc@5: 93.7500 (94.6828)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2200/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.6010  Acc@1: 75.0000 (72.7879)  Acc@5: 93.7500 (94.6928)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2210/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.9105  Acc@1: 75.0000 (72.8177)  Acc@5: 93.7500 (94.6941)  time: 0.3523  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2220/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.5907  Acc@1: 75.0000 (72.8219)  Acc@5: 100.0000 (94.7068)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2230/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.7504  Acc@1: 75.0000 (72.8457)  Acc@5: 93.7500 (94.7053)  time: 0.3528  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2240/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.5133  Acc@1: 81.2500 (72.8776)  Acc@5: 93.7500 (94.7066)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2250/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.6048  Acc@1: 75.0000 (72.9009)  Acc@5: 93.7500 (94.7024)  time: 0.3530  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2260/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.7505  Acc@1: 75.0000 (72.9296)  Acc@5: 93.7500 (94.7037)  time: 0.3515  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2270/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.9604  Acc@1: 75.0000 (72.9469)  Acc@5: 100.0000 (94.7077)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2280/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.3160  Acc@1: 75.0000 (72.9614)  Acc@5: 100.0000 (94.7145)  time: 0.3556  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2290/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.7295  Acc@1: 75.0000 (72.9785)  Acc@5: 100.0000 (94.7294)  time: 0.3559  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2300/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.7845  Acc@1: 81.2500 (73.0063)  Acc@5: 100.0000 (94.7333)  time: 0.3538  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2310/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.8476  Acc@1: 81.2500 (73.0285)  Acc@5: 93.7500 (94.7371)  time: 0.3530  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2320/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.8493  Acc@1: 81.2500 (73.0477)  Acc@5: 100.0000 (94.7490)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2330/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -1.0718  Acc@1: 81.2500 (73.0641)  Acc@5: 100.0000 (94.7635)  time: 0.3528  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2340/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.5350  Acc@1: 81.2500 (73.0831)  Acc@5: 100.0000 (94.7645)  time: 0.3519  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2350/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -1.0257  Acc@1: 81.2500 (73.0939)  Acc@5: 93.7500 (94.7655)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2360/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.6950  Acc@1: 75.0000 (73.0993)  Acc@5: 93.7500 (94.7692)  time: 0.3545  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2370/3750]  eta: 0:08:06  Lr: 0.001875  Loss: 0.1543  Acc@1: 75.0000 (73.0968)  Acc@5: 93.7500 (94.7649)  time: 0.3538  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [2380/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.5427  Acc@1: 75.0000 (73.1153)  Acc@5: 93.7500 (94.7711)  time: 0.3511  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [2390/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -1.2896  Acc@1: 81.2500 (73.1389)  Acc@5: 93.7500 (94.7642)  time: 0.3515  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2400/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.9212  Acc@1: 75.0000 (73.1596)  Acc@5: 93.7500 (94.7756)  time: 0.3535  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2410/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.8603  Acc@1: 75.0000 (73.1880)  Acc@5: 100.0000 (94.7921)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2420/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.7598  Acc@1: 75.0000 (73.1929)  Acc@5: 100.0000 (94.7878)  time: 0.3510  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2430/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.3332  Acc@1: 75.0000 (73.2106)  Acc@5: 93.7500 (94.7887)  time: 0.3525  data: 0.0012  max mem: 2501
Train: Epoch[1/1]  [2440/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.9460  Acc@1: 75.0000 (73.2256)  Acc@5: 93.7500 (94.7895)  time: 0.3524  data: 0.0012  max mem: 2501
Train: Epoch[1/1]  [2450/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -1.0767  Acc@1: 75.0000 (73.2558)  Acc@5: 93.7500 (94.8006)  time: 0.3513  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2460/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.9120  Acc@1: 81.2500 (73.2756)  Acc@5: 93.7500 (94.8039)  time: 0.3506  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2470/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -1.1322  Acc@1: 75.0000 (73.2876)  Acc@5: 93.7500 (94.8047)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2480/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.9628  Acc@1: 75.0000 (73.3071)  Acc@5: 93.7500 (94.8080)  time: 0.3537  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2490/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.7078  Acc@1: 75.0000 (73.3114)  Acc@5: 93.7500 (94.8163)  time: 0.3500  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2500/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -1.0262  Acc@1: 75.0000 (73.3357)  Acc@5: 93.7500 (94.8146)  time: 0.3486  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2510/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.6601  Acc@1: 81.2500 (73.3423)  Acc@5: 93.7500 (94.8228)  time: 0.3498  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2520/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.4579  Acc@1: 75.0000 (73.3563)  Acc@5: 93.7500 (94.8235)  time: 0.3503  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2530/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.8107  Acc@1: 75.0000 (73.3603)  Acc@5: 93.7500 (94.8217)  time: 0.3507  data: 0.0010  max mem: 2501
Train: Epoch[1/1]  [2540/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.8276  Acc@1: 75.0000 (73.3668)  Acc@5: 100.0000 (94.8298)  time: 0.3524  data: 0.0010  max mem: 2501
Train: Epoch[1/1]  [2550/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -1.1367  Acc@1: 75.0000 (73.3732)  Acc@5: 100.0000 (94.8403)  time: 0.3526  data: 0.0009  max mem: 2501
Train: Epoch[1/1]  [2560/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.5304  Acc@1: 81.2500 (73.3942)  Acc@5: 100.0000 (94.8458)  time: 0.3513  data: 0.0009  max mem: 2501
Train: Epoch[1/1]  [2570/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -1.0614  Acc@1: 81.2500 (73.4223)  Acc@5: 100.0000 (94.8585)  time: 0.3503  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2580/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -1.2675  Acc@1: 75.0000 (73.4163)  Acc@5: 100.0000 (94.8591)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2590/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.8489  Acc@1: 75.0000 (73.4297)  Acc@5: 100.0000 (94.8741)  time: 0.3525  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2600/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.4033  Acc@1: 81.2500 (73.4429)  Acc@5: 100.0000 (94.8746)  time: 0.3517  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [2610/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.8220  Acc@1: 81.2500 (73.4608)  Acc@5: 93.7500 (94.8798)  time: 0.3522  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [2620/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.8834  Acc@1: 75.0000 (73.4739)  Acc@5: 93.7500 (94.8851)  time: 0.3518  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2630/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.9050  Acc@1: 81.2500 (73.5177)  Acc@5: 100.0000 (94.8950)  time: 0.3511  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2640/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.8822  Acc@1: 81.2500 (73.5328)  Acc@5: 100.0000 (94.8930)  time: 0.3508  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2650/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -1.0570  Acc@1: 81.2500 (73.5666)  Acc@5: 100.0000 (94.9029)  time: 0.3520  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2660/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.6190  Acc@1: 81.2500 (73.6025)  Acc@5: 100.0000 (94.9173)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2670/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.0241  Acc@1: 81.2500 (73.6335)  Acc@5: 100.0000 (94.9247)  time: 0.3514  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2680/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.7932  Acc@1: 81.2500 (73.6526)  Acc@5: 93.7500 (94.9249)  time: 0.3516  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2690/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.9162  Acc@1: 75.0000 (73.6599)  Acc@5: 100.0000 (94.9322)  time: 0.3510  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2700/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.0372  Acc@1: 81.2500 (73.6926)  Acc@5: 100.0000 (94.9394)  time: 0.3519  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2710/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.6320  Acc@1: 81.2500 (73.7044)  Acc@5: 100.0000 (94.9419)  time: 0.3526  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2720/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.7903  Acc@1: 75.0000 (73.7160)  Acc@5: 100.0000 (94.9513)  time: 0.3523  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2730/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -1.2454  Acc@1: 75.0000 (73.7138)  Acc@5: 93.7500 (94.9515)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2740/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.3603  Acc@1: 75.0000 (73.7277)  Acc@5: 100.0000 (94.9631)  time: 0.3528  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2750/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.7205  Acc@1: 81.2500 (73.7527)  Acc@5: 100.0000 (94.9609)  time: 0.3528  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2760/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.6813  Acc@1: 81.2500 (73.7821)  Acc@5: 100.0000 (94.9746)  time: 0.3525  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2770/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.6399  Acc@1: 75.0000 (73.7550)  Acc@5: 100.0000 (94.9770)  time: 0.3520  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2780/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.2006  Acc@1: 68.7500 (73.7594)  Acc@5: 100.0000 (94.9771)  time: 0.3518  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2790/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.9539  Acc@1: 81.2500 (73.7796)  Acc@5: 93.7500 (94.9794)  time: 0.3521  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [2800/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -1.1360  Acc@1: 81.2500 (73.8129)  Acc@5: 100.0000 (94.9929)  time: 0.3518  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2810/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.6891  Acc@1: 75.0000 (73.8038)  Acc@5: 100.0000 (94.9884)  time: 0.3528  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2820/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -1.0644  Acc@1: 75.0000 (73.8191)  Acc@5: 100.0000 (94.9973)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2830/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.8903  Acc@1: 81.2500 (73.8608)  Acc@5: 100.0000 (95.0018)  time: 0.3521  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2840/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -1.2801  Acc@1: 81.2500 (73.8802)  Acc@5: 93.7500 (95.0018)  time: 0.3525  data: 0.0014  max mem: 2501
Train: Epoch[1/1]  [2850/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.5147  Acc@1: 81.2500 (73.9039)  Acc@5: 100.0000 (95.0105)  time: 0.3521  data: 0.0014  max mem: 2501
Train: Epoch[1/1]  [2860/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.7499  Acc@1: 81.2500 (73.8990)  Acc@5: 93.7500 (95.0061)  time: 0.3505  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [2870/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.8375  Acc@1: 81.2500 (73.9115)  Acc@5: 93.7500 (94.9996)  time: 0.3498  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [2880/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.7292  Acc@1: 81.2500 (73.9435)  Acc@5: 93.7500 (95.0039)  time: 0.3504  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2890/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -1.2000  Acc@1: 75.0000 (73.9515)  Acc@5: 93.7500 (95.0017)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2900/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.9561  Acc@1: 75.0000 (73.9508)  Acc@5: 93.7500 (94.9953)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2910/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.3377  Acc@1: 75.0000 (73.9694)  Acc@5: 93.7500 (94.9974)  time: 0.3523  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2920/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.4780  Acc@1: 81.2500 (73.9922)  Acc@5: 93.7500 (94.9974)  time: 0.3530  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2930/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.8398  Acc@1: 87.5000 (74.0319)  Acc@5: 100.0000 (95.0081)  time: 0.3529  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2940/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.9802  Acc@1: 81.2500 (74.0416)  Acc@5: 100.0000 (95.0102)  time: 0.3524  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2950/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -1.1150  Acc@1: 81.2500 (74.0342)  Acc@5: 93.7500 (95.0102)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [2960/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.6829  Acc@1: 75.0000 (74.0333)  Acc@5: 93.7500 (95.0080)  time: 0.3534  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [2970/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.8327  Acc@1: 75.0000 (74.0260)  Acc@5: 100.0000 (95.0185)  time: 0.3532  data: 0.0008  max mem: 2501
Train: Epoch[1/1]  [2980/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.9720  Acc@1: 75.0000 (74.0251)  Acc@5: 100.0000 (95.0164)  time: 0.3531  data: 0.0008  max mem: 2501
Train: Epoch[1/1]  [2990/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.8593  Acc@1: 75.0000 (74.0492)  Acc@5: 93.7500 (95.0184)  time: 0.3523  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3000/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.7265  Acc@1: 81.2500 (74.0607)  Acc@5: 100.0000 (95.0225)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3010/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -1.1299  Acc@1: 81.2500 (74.0908)  Acc@5: 100.0000 (95.0266)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3020/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.9004  Acc@1: 81.2500 (74.1000)  Acc@5: 93.7500 (95.0306)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3030/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -1.0218  Acc@1: 81.2500 (74.1216)  Acc@5: 93.7500 (95.0346)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3040/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.6897  Acc@1: 81.2500 (74.1306)  Acc@5: 100.0000 (95.0448)  time: 0.3535  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [3050/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -1.0633  Acc@1: 81.2500 (74.1458)  Acc@5: 100.0000 (95.0467)  time: 0.3538  data: 0.0012  max mem: 2501
Train: Epoch[1/1]  [3060/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.7345  Acc@1: 75.0000 (74.1404)  Acc@5: 93.7500 (95.0486)  time: 0.3531  data: 0.0010  max mem: 2501
Train: Epoch[1/1]  [3070/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.8818  Acc@1: 81.2500 (74.1697)  Acc@5: 93.7500 (95.0444)  time: 0.3525  data: 0.0011  max mem: 2501
Train: Epoch[1/1]  [3080/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.6149  Acc@1: 81.2500 (74.1622)  Acc@5: 93.7500 (95.0341)  time: 0.3538  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -1.0895  Acc@1: 75.0000 (74.1669)  Acc@5: 93.7500 (95.0360)  time: 0.3552  data: 0.0007  max mem: 2501
Train: Epoch[1/1]  [3100/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.9589  Acc@1: 75.0000 (74.1898)  Acc@5: 100.0000 (95.0419)  time: 0.3530  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.8737  Acc@1: 81.2500 (74.2185)  Acc@5: 100.0000 (95.0518)  time: 0.3530  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3120/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7914  Acc@1: 81.2500 (74.2230)  Acc@5: 100.0000 (95.0557)  time: 0.3538  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.7900  Acc@1: 75.0000 (74.2335)  Acc@5: 93.7500 (95.0555)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3140/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -1.1813  Acc@1: 75.0000 (74.2498)  Acc@5: 93.7500 (95.0553)  time: 0.3532  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3150/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.8370  Acc@1: 81.2500 (74.2740)  Acc@5: 93.7500 (95.0591)  time: 0.3533  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [3160/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -1.1679  Acc@1: 81.2500 (74.3020)  Acc@5: 100.0000 (95.0649)  time: 0.3543  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [3170/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -1.0224  Acc@1: 81.2500 (74.3200)  Acc@5: 100.0000 (95.0686)  time: 0.3544  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -1.1832  Acc@1: 75.0000 (74.3123)  Acc@5: 100.0000 (95.0762)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3190/3750]  eta: 0:03:17  Lr: 0.001875  Loss: -1.2833  Acc@1: 75.0000 (74.3282)  Acc@5: 100.0000 (95.0799)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -1.0649  Acc@1: 81.2500 (74.3440)  Acc@5: 100.0000 (95.0836)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3210/3750]  eta: 0:03:10  Lr: 0.001875  Loss: -0.9737  Acc@1: 81.2500 (74.3674)  Acc@5: 93.7500 (95.0814)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -1.0308  Acc@1: 81.2500 (74.3830)  Acc@5: 93.7500 (95.0850)  time: 0.3520  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3230/3750]  eta: 0:03:03  Lr: 0.001875  Loss: -0.5700  Acc@1: 81.2500 (74.4023)  Acc@5: 100.0000 (95.0925)  time: 0.3506  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -1.2993  Acc@1: 81.2500 (74.4273)  Acc@5: 100.0000 (95.1018)  time: 0.3503  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3250/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.6676  Acc@1: 81.2500 (74.4521)  Acc@5: 100.0000 (95.0977)  time: 0.3503  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.7448  Acc@1: 87.5000 (74.4806)  Acc@5: 100.0000 (95.1031)  time: 0.3514  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3270/3750]  eta: 0:02:49  Lr: 0.001875  Loss: -1.0192  Acc@1: 75.0000 (74.4841)  Acc@5: 100.0000 (95.1066)  time: 0.3526  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.8657  Acc@1: 75.0000 (74.4895)  Acc@5: 93.7500 (95.1044)  time: 0.3525  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3290/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.9320  Acc@1: 81.2500 (74.4986)  Acc@5: 100.0000 (95.1117)  time: 0.3515  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.9797  Acc@1: 75.0000 (74.4945)  Acc@5: 100.0000 (95.1075)  time: 0.3510  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3310/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -0.2576  Acc@1: 81.2500 (74.5224)  Acc@5: 100.0000 (95.1167)  time: 0.3508  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.2787  Acc@1: 81.2500 (74.5295)  Acc@5: 100.0000 (95.1182)  time: 0.3506  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3330/3750]  eta: 0:02:28  Lr: 0.001875  Loss: -1.4965  Acc@1: 75.0000 (74.5253)  Acc@5: 100.0000 (95.1253)  time: 0.3507  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.9991  Acc@1: 81.2500 (74.5529)  Acc@5: 100.0000 (95.1306)  time: 0.3512  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3350/3750]  eta: 0:02:21  Lr: 0.001875  Loss: -0.8270  Acc@1: 81.2500 (74.5710)  Acc@5: 100.0000 (95.1395)  time: 0.3518  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -1.3137  Acc@1: 81.2500 (74.6002)  Acc@5: 100.0000 (95.1465)  time: 0.3522  data: 0.0011  max mem: 2501
Train: Epoch[1/1]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.8360  Acc@1: 81.2500 (74.6088)  Acc@5: 100.0000 (95.1517)  time: 0.3517  data: 0.0012  max mem: 2501
Train: Epoch[1/1]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.9079  Acc@1: 75.0000 (74.6173)  Acc@5: 100.0000 (95.1568)  time: 0.3513  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.8874  Acc@1: 75.0000 (74.6148)  Acc@5: 93.7500 (95.1600)  time: 0.3502  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -1.3326  Acc@1: 81.2500 (74.6325)  Acc@5: 93.7500 (95.1632)  time: 0.3494  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.9779  Acc@1: 81.2500 (74.6464)  Acc@5: 100.0000 (95.1700)  time: 0.3507  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -1.0885  Acc@1: 81.2500 (74.6675)  Acc@5: 100.0000 (95.1787)  time: 0.3506  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.5654  Acc@1: 81.2500 (74.6703)  Acc@5: 93.7500 (95.1727)  time: 0.3506  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3440/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.8116  Acc@1: 81.2500 (74.7076)  Acc@5: 93.7500 (95.1795)  time: 0.3521  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -1.0950  Acc@1: 87.5000 (74.7302)  Acc@5: 100.0000 (95.1862)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3460/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -0.7133  Acc@1: 81.2500 (74.7291)  Acc@5: 93.7500 (95.1820)  time: 0.3539  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.9467  Acc@1: 75.0000 (74.7245)  Acc@5: 93.7500 (95.1779)  time: 0.3531  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3480/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -0.6871  Acc@1: 75.0000 (74.7343)  Acc@5: 93.7500 (95.1792)  time: 0.3517  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.6263  Acc@1: 75.0000 (74.7494)  Acc@5: 93.7500 (95.1769)  time: 0.3522  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3500/3750]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8369  Acc@1: 75.0000 (74.7590)  Acc@5: 93.7500 (95.1817)  time: 0.3518  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -1.2427  Acc@1: 75.0000 (74.7757)  Acc@5: 100.0000 (95.1883)  time: 0.3549  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3520/3750]  eta: 0:01:21  Lr: 0.001875  Loss: -1.0365  Acc@1: 81.2500 (74.7870)  Acc@5: 93.7500 (95.1825)  time: 0.3562  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -1.0956  Acc@1: 81.2500 (74.8000)  Acc@5: 93.7500 (95.1873)  time: 0.3533  data: 0.0010  max mem: 2501
Train: Epoch[1/1]  [3540/3750]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9922  Acc@1: 75.0000 (74.7953)  Acc@5: 93.7500 (95.1850)  time: 0.3525  data: 0.0010  max mem: 2501
Train: Epoch[1/1]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9092  Acc@1: 68.7500 (74.7941)  Acc@5: 93.7500 (95.1809)  time: 0.3524  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.9421  Acc@1: 81.2500 (74.8140)  Acc@5: 93.7500 (95.1822)  time: 0.3532  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -1.1767  Acc@1: 81.2500 (74.8180)  Acc@5: 93.7500 (95.1782)  time: 0.3532  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.5586  Acc@1: 81.2500 (74.8202)  Acc@5: 93.7500 (95.1794)  time: 0.3523  data: 0.0005  max mem: 2501
Train: Epoch[1/1]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.6910  Acc@1: 81.2500 (74.8468)  Acc@5: 93.7500 (95.1807)  time: 0.3530  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.1572  Acc@1: 81.2500 (74.8681)  Acc@5: 93.7500 (95.1836)  time: 0.3532  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -1.0463  Acc@1: 81.2500 (74.8910)  Acc@5: 100.0000 (95.1883)  time: 0.3520  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.9581  Acc@1: 81.2500 (74.9068)  Acc@5: 100.0000 (95.1930)  time: 0.3527  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6462  Acc@1: 81.2500 (74.9105)  Acc@5: 93.7500 (95.1838)  time: 0.3545  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.3552  Acc@1: 81.2500 (74.9348)  Acc@5: 100.0000 (95.1936)  time: 0.3552  data: 0.0013  max mem: 2501
Train: Epoch[1/1]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.9500  Acc@1: 81.2500 (74.9418)  Acc@5: 100.0000 (95.1880)  time: 0.3534  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0810  Acc@1: 75.0000 (74.9556)  Acc@5: 93.7500 (95.1960)  time: 0.3524  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.9122  Acc@1: 75.0000 (74.9591)  Acc@5: 100.0000 (95.1989)  time: 0.3530  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.4955  Acc@1: 75.0000 (74.9660)  Acc@5: 100.0000 (95.2034)  time: 0.3533  data: 0.0010  max mem: 2501
Train: Epoch[1/1]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -1.0267  Acc@1: 75.0000 (74.9780)  Acc@5: 93.7500 (95.1961)  time: 0.3548  data: 0.0012  max mem: 2501
Train: Epoch[1/1]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8599  Acc@1: 81.2500 (74.9932)  Acc@5: 93.7500 (95.2006)  time: 0.3540  data: 0.0006  max mem: 2501
Train: Epoch[1/1]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -1.1017  Acc@1: 81.2500 (75.0152)  Acc@5: 100.0000 (95.2034)  time: 0.3517  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7667  Acc@1: 81.2500 (75.0235)  Acc@5: 93.7500 (95.2079)  time: 0.3508  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -1.0944  Acc@1: 81.2500 (75.0369)  Acc@5: 100.0000 (95.2107)  time: 0.3505  data: 0.0003  max mem: 2501
Train: Epoch[1/1]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7395  Acc@1: 87.5000 (75.0702)  Acc@5: 100.0000 (95.2152)  time: 0.3513  data: 0.0004  max mem: 2501
Train: Epoch[1/1]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7070  Acc@1: 81.2500 (75.0733)  Acc@5: 93.7500 (95.2100)  time: 0.3520  data: 0.0008  max mem: 2501
Train: Epoch[1/1] Total time: 0:22:02 (0.3527 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.7070  Acc@1: 81.2500 (75.0733)  Acc@5: 93.7500 (95.2100)
Test: [Task 1]  [   0/1627]  eta: 0:17:50  Loss: 1.4671 (1.4671)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6577  data: 0.4390  max mem: 2501
Test: [Task 1]  [  10/1627]  eta: 0:07:00  Loss: 1.5063 (1.4179)  Acc@1: 68.7500 (68.1818)  Acc@5: 93.7500 (93.1818)  time: 0.2598  data: 0.0402  max mem: 2501
Test: [Task 1]  [  20/1627]  eta: 0:06:25  Loss: 1.4111 (1.3961)  Acc@1: 68.7500 (70.2381)  Acc@5: 93.7500 (93.4524)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 1]  [  30/1627]  eta: 0:06:12  Loss: 1.3188 (1.4205)  Acc@1: 68.7500 (68.9516)  Acc@5: 93.7500 (93.1452)  time: 0.2184  data: 0.0003  max mem: 2501
Test: [Task 1]  [  40/1627]  eta: 0:06:04  Loss: 1.5959 (1.4508)  Acc@1: 56.2500 (67.2256)  Acc@5: 93.7500 (92.5305)  time: 0.2188  data: 0.0004  max mem: 2501
Test: [Task 1]  [  50/1627]  eta: 0:05:58  Loss: 1.4521 (1.4242)  Acc@1: 62.5000 (67.7696)  Acc@5: 93.7500 (93.2598)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 1]  [  60/1627]  eta: 0:05:54  Loss: 1.4521 (1.4526)  Acc@1: 68.7500 (66.5984)  Acc@5: 93.7500 (93.0328)  time: 0.2193  data: 0.0004  max mem: 2501
Test: [Task 1]  [  70/1627]  eta: 0:05:51  Loss: 1.4390 (1.4450)  Acc@1: 62.5000 (66.9014)  Acc@5: 93.7500 (93.3099)  time: 0.2201  data: 0.0006  max mem: 2501
Test: [Task 1]  [  80/1627]  eta: 0:05:47  Loss: 1.3157 (1.4343)  Acc@1: 68.7500 (67.2840)  Acc@5: 100.0000 (93.6728)  time: 0.2198  data: 0.0006  max mem: 2501
Test: [Task 1]  [  90/1627]  eta: 0:05:44  Loss: 1.3515 (1.4345)  Acc@1: 68.7500 (67.3764)  Acc@5: 93.7500 (93.4753)  time: 0.2199  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 100/1627]  eta: 0:05:41  Loss: 1.6077 (1.4591)  Acc@1: 68.7500 (67.0173)  Acc@5: 87.5000 (92.6980)  time: 0.2203  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 110/1627]  eta: 0:05:39  Loss: 1.5361 (1.4600)  Acc@1: 62.5000 (66.8356)  Acc@5: 93.7500 (93.0743)  time: 0.2204  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 120/1627]  eta: 0:05:36  Loss: 1.4178 (1.4603)  Acc@1: 62.5000 (66.5289)  Acc@5: 93.7500 (93.0269)  time: 0.2211  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 130/1627]  eta: 0:05:34  Loss: 1.4178 (1.4560)  Acc@1: 62.5000 (66.5076)  Acc@5: 93.7500 (92.7481)  time: 0.2213  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 140/1627]  eta: 0:05:31  Loss: 1.3443 (1.4549)  Acc@1: 62.5000 (66.4894)  Acc@5: 93.7500 (92.8191)  time: 0.2204  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 150/1627]  eta: 0:05:28  Loss: 1.2708 (1.4433)  Acc@1: 68.7500 (66.9288)  Acc@5: 93.7500 (92.8394)  time: 0.2189  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 160/1627]  eta: 0:05:26  Loss: 1.3234 (1.4375)  Acc@1: 75.0000 (67.1972)  Acc@5: 100.0000 (93.0124)  time: 0.2186  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 170/1627]  eta: 0:05:23  Loss: 1.3635 (1.4303)  Acc@1: 68.7500 (67.2880)  Acc@5: 100.0000 (93.2749)  time: 0.2186  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 180/1627]  eta: 0:05:21  Loss: 1.4080 (1.4417)  Acc@1: 62.5000 (66.7818)  Acc@5: 93.7500 (93.1630)  time: 0.2185  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 190/1627]  eta: 0:05:18  Loss: 1.5022 (1.4360)  Acc@1: 62.5000 (67.0157)  Acc@5: 93.7500 (93.1937)  time: 0.2184  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 200/1627]  eta: 0:05:16  Loss: 1.4910 (1.4387)  Acc@1: 68.7500 (66.9776)  Acc@5: 93.7500 (93.1592)  time: 0.2184  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 210/1627]  eta: 0:05:14  Loss: 1.4485 (1.4354)  Acc@1: 68.7500 (67.0912)  Acc@5: 93.7500 (93.2464)  time: 0.2227  data: 0.0013  max mem: 2501
Test: [Task 1]  [ 220/1627]  eta: 0:05:11  Loss: 1.4485 (1.4410)  Acc@1: 68.7500 (67.0249)  Acc@5: 93.7500 (93.2692)  time: 0.2223  data: 0.0012  max mem: 2501
Test: [Task 1]  [ 230/1627]  eta: 0:05:09  Loss: 1.4668 (1.4352)  Acc@1: 68.7500 (67.1807)  Acc@5: 93.7500 (93.3171)  time: 0.2182  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 240/1627]  eta: 0:05:07  Loss: 1.3079 (1.4281)  Acc@1: 75.0000 (67.5052)  Acc@5: 93.7500 (93.3091)  time: 0.2183  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 250/1627]  eta: 0:05:04  Loss: 1.4324 (1.4336)  Acc@1: 62.5000 (67.2809)  Acc@5: 93.7500 (93.1524)  time: 0.2182  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 260/1627]  eta: 0:05:02  Loss: 1.4125 (1.4318)  Acc@1: 62.5000 (67.4330)  Acc@5: 93.7500 (93.1753)  time: 0.2182  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 270/1627]  eta: 0:04:59  Loss: 1.3851 (1.4251)  Acc@1: 68.7500 (67.6199)  Acc@5: 93.7500 (93.1734)  time: 0.2180  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 280/1627]  eta: 0:04:57  Loss: 1.3169 (1.4245)  Acc@1: 68.7500 (67.5712)  Acc@5: 93.7500 (93.1272)  time: 0.2176  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 290/1627]  eta: 0:04:55  Loss: 1.3169 (1.4220)  Acc@1: 68.7500 (67.5473)  Acc@5: 93.7500 (93.1701)  time: 0.2170  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 300/1627]  eta: 0:04:52  Loss: 1.3480 (1.4206)  Acc@1: 68.7500 (67.6703)  Acc@5: 93.7500 (93.2309)  time: 0.2171  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 310/1627]  eta: 0:04:50  Loss: 1.3480 (1.4235)  Acc@1: 75.0000 (67.7452)  Acc@5: 100.0000 (93.1672)  time: 0.2174  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 320/1627]  eta: 0:04:48  Loss: 1.5185 (1.4247)  Acc@1: 68.7500 (67.7375)  Acc@5: 93.7500 (93.1854)  time: 0.2171  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 330/1627]  eta: 0:04:45  Loss: 1.4616 (1.4240)  Acc@1: 62.5000 (67.7681)  Acc@5: 93.7500 (93.1835)  time: 0.2174  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 340/1627]  eta: 0:04:43  Loss: 1.3503 (1.4232)  Acc@1: 68.7500 (67.8519)  Acc@5: 93.7500 (93.1452)  time: 0.2179  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 350/1627]  eta: 0:04:41  Loss: 1.4162 (1.4228)  Acc@1: 68.7500 (67.8419)  Acc@5: 93.7500 (93.1268)  time: 0.2180  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 360/1627]  eta: 0:04:38  Loss: 1.3554 (1.4229)  Acc@1: 68.7500 (67.8670)  Acc@5: 93.7500 (93.0575)  time: 0.2178  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 370/1627]  eta: 0:04:36  Loss: 1.2620 (1.4221)  Acc@1: 68.7500 (67.9077)  Acc@5: 93.7500 (93.0593)  time: 0.2176  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 380/1627]  eta: 0:04:34  Loss: 1.3304 (1.4204)  Acc@1: 68.7500 (67.9462)  Acc@5: 93.7500 (93.0446)  time: 0.2191  data: 0.0020  max mem: 2501
Test: [Task 1]  [ 390/1627]  eta: 0:04:32  Loss: 1.4267 (1.4223)  Acc@1: 68.7500 (67.9188)  Acc@5: 93.7500 (92.9827)  time: 0.2190  data: 0.0020  max mem: 2501
Test: [Task 1]  [ 400/1627]  eta: 0:04:29  Loss: 1.4152 (1.4232)  Acc@1: 68.7500 (67.9707)  Acc@5: 93.7500 (92.9551)  time: 0.2176  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 410/1627]  eta: 0:04:27  Loss: 1.3374 (1.4227)  Acc@1: 68.7500 (67.9745)  Acc@5: 93.7500 (92.8832)  time: 0.2174  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 420/1627]  eta: 0:04:25  Loss: 1.2559 (1.4198)  Acc@1: 68.7500 (68.0968)  Acc@5: 93.7500 (92.9483)  time: 0.2173  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 430/1627]  eta: 0:04:23  Loss: 1.2505 (1.4179)  Acc@1: 75.0000 (68.1700)  Acc@5: 93.7500 (92.9669)  time: 0.2179  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 440/1627]  eta: 0:04:20  Loss: 1.4263 (1.4178)  Acc@1: 68.7500 (68.2115)  Acc@5: 93.7500 (92.9705)  time: 0.2183  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 450/1627]  eta: 0:04:18  Loss: 1.5773 (1.4219)  Acc@1: 62.5000 (68.0987)  Acc@5: 93.7500 (92.9601)  time: 0.2190  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 460/1627]  eta: 0:04:16  Loss: 1.4947 (1.4213)  Acc@1: 62.5000 (68.1128)  Acc@5: 93.7500 (92.9908)  time: 0.2209  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 470/1627]  eta: 0:04:14  Loss: 1.2474 (1.4181)  Acc@1: 75.0000 (68.2059)  Acc@5: 93.7500 (93.0202)  time: 0.2199  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 480/1627]  eta: 0:04:12  Loss: 1.4370 (1.4231)  Acc@1: 68.7500 (68.1133)  Acc@5: 93.7500 (92.9314)  time: 0.2177  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 490/1627]  eta: 0:04:09  Loss: 1.4370 (1.4242)  Acc@1: 68.7500 (67.9990)  Acc@5: 93.7500 (92.9608)  time: 0.2180  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 500/1627]  eta: 0:04:07  Loss: 1.4175 (1.4268)  Acc@1: 68.7500 (68.0015)  Acc@5: 93.7500 (92.9017)  time: 0.2185  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 510/1627]  eta: 0:04:05  Loss: 1.4455 (1.4303)  Acc@1: 62.5000 (67.9305)  Acc@5: 87.5000 (92.8205)  time: 0.2189  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 520/1627]  eta: 0:04:03  Loss: 1.4873 (1.4355)  Acc@1: 62.5000 (67.8263)  Acc@5: 93.7500 (92.8143)  time: 0.2199  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 530/1627]  eta: 0:04:01  Loss: 1.3506 (1.4307)  Acc@1: 68.7500 (67.9967)  Acc@5: 93.7500 (92.8555)  time: 0.2208  data: 0.0018  max mem: 2501
Test: [Task 1]  [ 540/1627]  eta: 0:03:58  Loss: 1.3193 (1.4305)  Acc@1: 75.0000 (67.9760)  Acc@5: 93.7500 (92.8604)  time: 0.2198  data: 0.0016  max mem: 2501
Test: [Task 1]  [ 550/1627]  eta: 0:03:56  Loss: 1.5271 (1.4335)  Acc@1: 68.7500 (67.9446)  Acc@5: 93.7500 (92.8199)  time: 0.2190  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 560/1627]  eta: 0:03:54  Loss: 1.5538 (1.4358)  Acc@1: 68.7500 (67.9144)  Acc@5: 93.7500 (92.8365)  time: 0.2194  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 570/1627]  eta: 0:03:52  Loss: 1.3268 (1.4340)  Acc@1: 68.7500 (67.8962)  Acc@5: 93.7500 (92.8634)  time: 0.2195  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 580/1627]  eta: 0:03:50  Loss: 1.3634 (1.4358)  Acc@1: 68.7500 (67.8464)  Acc@5: 93.7500 (92.8787)  time: 0.2195  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 590/1627]  eta: 0:03:47  Loss: 1.4147 (1.4349)  Acc@1: 68.7500 (67.8299)  Acc@5: 93.7500 (92.9569)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 600/1627]  eta: 0:03:45  Loss: 1.3741 (1.4376)  Acc@1: 62.5000 (67.7309)  Acc@5: 100.0000 (92.9700)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 610/1627]  eta: 0:03:43  Loss: 1.3415 (1.4356)  Acc@1: 68.7500 (67.8294)  Acc@5: 93.7500 (92.9726)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 620/1627]  eta: 0:03:41  Loss: 1.3570 (1.4365)  Acc@1: 75.0000 (67.8845)  Acc@5: 93.7500 (92.9046)  time: 0.2202  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 630/1627]  eta: 0:03:39  Loss: 1.3497 (1.4351)  Acc@1: 68.7500 (67.9378)  Acc@5: 93.7500 (92.9279)  time: 0.2206  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 1.1554 (1.4339)  Acc@1: 68.7500 (67.9505)  Acc@5: 93.7500 (92.9115)  time: 0.2195  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 650/1627]  eta: 0:03:34  Loss: 1.3645 (1.4337)  Acc@1: 68.7500 (67.9435)  Acc@5: 93.7500 (92.8763)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 660/1627]  eta: 0:03:32  Loss: 1.2908 (1.4314)  Acc@1: 68.7500 (68.0408)  Acc@5: 93.7500 (92.8896)  time: 0.2194  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 670/1627]  eta: 0:03:30  Loss: 1.3842 (1.4323)  Acc@1: 68.7500 (67.9676)  Acc@5: 93.7500 (92.8651)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 680/1627]  eta: 0:03:27  Loss: 1.3842 (1.4301)  Acc@1: 68.7500 (68.0158)  Acc@5: 93.7500 (92.8598)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 1.3687 (1.4287)  Acc@1: 68.7500 (68.0897)  Acc@5: 93.7500 (92.9179)  time: 0.2197  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 700/1627]  eta: 0:03:23  Loss: 1.4607 (1.4289)  Acc@1: 68.7500 (68.0991)  Acc@5: 93.7500 (92.9387)  time: 0.2198  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 710/1627]  eta: 0:03:21  Loss: 1.4397 (1.4266)  Acc@1: 68.7500 (68.1610)  Acc@5: 93.7500 (92.9677)  time: 0.2209  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 720/1627]  eta: 0:03:19  Loss: 1.2220 (1.4244)  Acc@1: 75.0000 (68.2386)  Acc@5: 100.0000 (93.0132)  time: 0.2215  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 730/1627]  eta: 0:03:17  Loss: 1.3513 (1.4263)  Acc@1: 68.7500 (68.1857)  Acc@5: 93.7500 (92.9976)  time: 0.2195  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 1.5080 (1.4268)  Acc@1: 68.7500 (68.2186)  Acc@5: 93.7500 (92.9487)  time: 0.2189  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 750/1627]  eta: 0:03:12  Loss: 1.4143 (1.4258)  Acc@1: 68.7500 (68.2756)  Acc@5: 93.7500 (92.9844)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 760/1627]  eta: 0:03:10  Loss: 1.4197 (1.4290)  Acc@1: 68.7500 (68.1997)  Acc@5: 93.7500 (92.9123)  time: 0.2196  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 770/1627]  eta: 0:03:08  Loss: 1.3558 (1.4265)  Acc@1: 68.7500 (68.2717)  Acc@5: 93.7500 (92.9556)  time: 0.2199  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 780/1627]  eta: 0:03:06  Loss: 1.2044 (1.4255)  Acc@1: 68.7500 (68.2778)  Acc@5: 93.7500 (92.9497)  time: 0.2193  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 1.3553 (1.4271)  Acc@1: 68.7500 (68.2522)  Acc@5: 93.7500 (92.9046)  time: 0.2197  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 800/1627]  eta: 0:03:01  Loss: 1.4618 (1.4275)  Acc@1: 68.7500 (68.2584)  Acc@5: 93.7500 (92.9151)  time: 0.2195  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 810/1627]  eta: 0:02:59  Loss: 1.3834 (1.4267)  Acc@1: 68.7500 (68.3107)  Acc@5: 93.7500 (92.9562)  time: 0.2192  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 820/1627]  eta: 0:02:57  Loss: 1.1900 (1.4263)  Acc@1: 75.0000 (68.3161)  Acc@5: 93.7500 (92.9659)  time: 0.2190  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 830/1627]  eta: 0:02:55  Loss: 1.1900 (1.4256)  Acc@1: 68.7500 (68.2837)  Acc@5: 93.7500 (92.9979)  time: 0.2187  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 1.1769 (1.4238)  Acc@1: 68.7500 (68.3190)  Acc@5: 93.7500 (93.0217)  time: 0.2187  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 850/1627]  eta: 0:02:50  Loss: 1.4854 (1.4248)  Acc@1: 68.7500 (68.3020)  Acc@5: 93.7500 (93.0303)  time: 0.2192  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 1.3825 (1.4246)  Acc@1: 68.7500 (68.3362)  Acc@5: 93.7500 (93.0386)  time: 0.2196  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 870/1627]  eta: 0:02:46  Loss: 1.3755 (1.4225)  Acc@1: 68.7500 (68.3984)  Acc@5: 93.7500 (93.0468)  time: 0.2212  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 880/1627]  eta: 0:02:44  Loss: 1.5032 (1.4255)  Acc@1: 68.7500 (68.3314)  Acc@5: 93.7500 (93.0335)  time: 0.2208  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 1.6546 (1.4276)  Acc@1: 62.5000 (68.2800)  Acc@5: 93.7500 (93.0205)  time: 0.2186  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 1.5370 (1.4283)  Acc@1: 62.5000 (68.2783)  Acc@5: 93.7500 (93.0147)  time: 0.2186  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 1.4548 (1.4284)  Acc@1: 62.5000 (68.2766)  Acc@5: 93.7500 (93.0228)  time: 0.2184  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 1.3260 (1.4270)  Acc@1: 68.7500 (68.3089)  Acc@5: 93.7500 (93.0375)  time: 0.2187  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 930/1627]  eta: 0:02:33  Loss: 1.3432 (1.4264)  Acc@1: 68.7500 (68.3002)  Acc@5: 93.7500 (92.9914)  time: 0.2191  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 1.3947 (1.4249)  Acc@1: 68.7500 (68.3050)  Acc@5: 93.7500 (93.0460)  time: 0.2189  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 1.4060 (1.4257)  Acc@1: 68.7500 (68.2768)  Acc@5: 93.7500 (93.0336)  time: 0.2184  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 1.3888 (1.4251)  Acc@1: 68.7500 (68.2752)  Acc@5: 93.7500 (93.0476)  time: 0.2182  data: 0.0003  max mem: 2501
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 1.2319 (1.4240)  Acc@1: 68.7500 (68.3187)  Acc@5: 93.7500 (93.0227)  time: 0.2182  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 980/1627]  eta: 0:02:22  Loss: 1.3451 (1.4238)  Acc@1: 68.7500 (68.3040)  Acc@5: 93.7500 (93.0237)  time: 0.2187  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 1.5611 (1.4268)  Acc@1: 62.5000 (68.2328)  Acc@5: 87.5000 (92.9869)  time: 0.2190  data: 0.0007  max mem: 2501
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 1.5438 (1.4271)  Acc@1: 62.5000 (68.2380)  Acc@5: 87.5000 (92.9758)  time: 0.2182  data: 0.0004  max mem: 2501
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 1.3941 (1.4272)  Acc@1: 68.7500 (68.2616)  Acc@5: 93.7500 (92.9649)  time: 0.2176  data: 0.0004  max mem: 2501
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 1.3941 (1.4272)  Acc@1: 68.7500 (68.2909)  Acc@5: 93.7500 (92.9726)  time: 0.2178  data: 0.0003  max mem: 2501
Test: [Task 1]  [1030/1627]  eta: 0:02:11  Loss: 1.2597 (1.4259)  Acc@1: 68.7500 (68.3196)  Acc@5: 93.7500 (92.9862)  time: 0.2183  data: 0.0003  max mem: 2501
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 1.2160 (1.4252)  Acc@1: 68.7500 (68.3297)  Acc@5: 93.7500 (92.9755)  time: 0.2212  data: 0.0005  max mem: 2501
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 1.3144 (1.4241)  Acc@1: 68.7500 (68.3456)  Acc@5: 93.7500 (92.9710)  time: 0.2215  data: 0.0005  max mem: 2501
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 1.4528 (1.4243)  Acc@1: 68.7500 (68.3023)  Acc@5: 93.7500 (92.9842)  time: 0.2196  data: 0.0004  max mem: 2501
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 1.4205 (1.4248)  Acc@1: 68.7500 (68.3532)  Acc@5: 93.7500 (92.9797)  time: 0.2196  data: 0.0004  max mem: 2501
Test: [Task 1]  [1080/1627]  eta: 0:02:00  Loss: 1.3929 (1.4253)  Acc@1: 68.7500 (68.3453)  Acc@5: 93.7500 (92.9579)  time: 0.2187  data: 0.0003  max mem: 2501
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 1.3559 (1.4253)  Acc@1: 68.7500 (68.3203)  Acc@5: 93.7500 (92.9709)  time: 0.2185  data: 0.0004  max mem: 2501
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 1.3083 (1.4235)  Acc@1: 68.7500 (68.3697)  Acc@5: 100.0000 (93.0120)  time: 0.2181  data: 0.0003  max mem: 2501
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 1.3626 (1.4242)  Acc@1: 68.7500 (68.3337)  Acc@5: 100.0000 (93.0131)  time: 0.2179  data: 0.0003  max mem: 2501
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 1.4283 (1.4249)  Acc@1: 62.5000 (68.3095)  Acc@5: 93.7500 (93.0196)  time: 0.2182  data: 0.0003  max mem: 2501
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 1.5411 (1.4265)  Acc@1: 62.5000 (68.2361)  Acc@5: 93.7500 (92.9874)  time: 0.2179  data: 0.0003  max mem: 2501
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 1.5411 (1.4277)  Acc@1: 62.5000 (68.2570)  Acc@5: 93.7500 (92.9886)  time: 0.2175  data: 0.0003  max mem: 2501
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 1.5635 (1.4290)  Acc@1: 68.7500 (68.2070)  Acc@5: 93.7500 (92.9518)  time: 0.2181  data: 0.0003  max mem: 2501
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 1.3558 (1.4277)  Acc@1: 68.7500 (68.2494)  Acc@5: 93.7500 (92.9694)  time: 0.2180  data: 0.0002  max mem: 2501
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 1.3326 (1.4269)  Acc@1: 75.0000 (68.2803)  Acc@5: 93.7500 (92.9761)  time: 0.2177  data: 0.0003  max mem: 2501
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 1.4815 (1.4278)  Acc@1: 68.7500 (68.2367)  Acc@5: 93.7500 (92.9773)  time: 0.2181  data: 0.0003  max mem: 2501
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 1.5244 (1.4289)  Acc@1: 62.5000 (68.2147)  Acc@5: 93.7500 (92.9524)  time: 0.2181  data: 0.0003  max mem: 2501
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 1.4046 (1.4287)  Acc@1: 68.7500 (68.2140)  Acc@5: 93.7500 (92.9382)  time: 0.2182  data: 0.0003  max mem: 2501
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 1.3594 (1.4300)  Acc@1: 62.5000 (68.1462)  Acc@5: 93.7500 (92.9088)  time: 0.2183  data: 0.0006  max mem: 2501
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 1.4547 (1.4297)  Acc@1: 62.5000 (68.1204)  Acc@5: 93.7500 (92.9259)  time: 0.2183  data: 0.0006  max mem: 2501
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 1.4559 (1.4308)  Acc@1: 62.5000 (68.0950)  Acc@5: 93.7500 (92.9021)  time: 0.2185  data: 0.0003  max mem: 2501
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 1.3544 (1.4297)  Acc@1: 68.7500 (68.1456)  Acc@5: 93.7500 (92.8989)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 1.4225 (1.4301)  Acc@1: 68.7500 (68.1355)  Acc@5: 87.5000 (92.8857)  time: 0.2191  data: 0.0004  max mem: 2501
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 1.4225 (1.4299)  Acc@1: 68.7500 (68.1602)  Acc@5: 93.7500 (92.9025)  time: 0.2190  data: 0.0004  max mem: 2501
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 1.3468 (1.4301)  Acc@1: 68.7500 (68.1697)  Acc@5: 93.7500 (92.8944)  time: 0.2192  data: 0.0004  max mem: 2501
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 1.2988 (1.4281)  Acc@1: 68.7500 (68.1889)  Acc@5: 93.7500 (92.9108)  time: 0.2191  data: 0.0003  max mem: 2501
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 1.2988 (1.4286)  Acc@1: 68.7500 (68.1497)  Acc@5: 93.7500 (92.9076)  time: 0.2191  data: 0.0003  max mem: 2501
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 1.4439 (1.4280)  Acc@1: 68.7500 (68.1639)  Acc@5: 93.7500 (92.9237)  time: 0.2193  data: 0.0004  max mem: 2501
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 1.2596 (1.4267)  Acc@1: 75.0000 (68.2208)  Acc@5: 100.0000 (92.9443)  time: 0.2200  data: 0.0003  max mem: 2501
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 1.1516 (1.4253)  Acc@1: 75.0000 (68.2769)  Acc@5: 100.0000 (92.9646)  time: 0.2197  data: 0.0003  max mem: 2501
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 1.2093 (1.4253)  Acc@1: 68.7500 (68.2851)  Acc@5: 93.7500 (92.9564)  time: 0.2193  data: 0.0003  max mem: 2501
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.4070 (1.4255)  Acc@1: 62.5000 (68.2560)  Acc@5: 93.7500 (92.9577)  time: 0.2193  data: 0.0003  max mem: 2501
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 1.3895 (1.4251)  Acc@1: 62.5000 (68.2642)  Acc@5: 93.7500 (92.9728)  time: 0.2194  data: 0.0006  max mem: 2501
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 1.2826 (1.4245)  Acc@1: 75.0000 (68.2632)  Acc@5: 93.7500 (92.9831)  time: 0.2196  data: 0.0007  max mem: 2501
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 1.2826 (1.4245)  Acc@1: 68.7500 (68.2622)  Acc@5: 93.7500 (92.9796)  time: 0.2229  data: 0.0006  max mem: 2501
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 1.3365 (1.4247)  Acc@1: 68.7500 (68.2567)  Acc@5: 93.7500 (92.9852)  time: 0.2233  data: 0.0013  max mem: 2501
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.3973 (1.4239)  Acc@1: 68.7500 (68.2962)  Acc@5: 93.7500 (93.0086)  time: 0.2195  data: 0.0011  max mem: 2501
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.2530 (1.4242)  Acc@1: 75.0000 (68.3084)  Acc@5: 93.7500 (93.0139)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 1.2474 (1.4237)  Acc@1: 75.0000 (68.3425)  Acc@5: 93.7500 (93.0369)  time: 0.2189  data: 0.0003  max mem: 2501
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.3281 (1.4235)  Acc@1: 68.7500 (68.3410)  Acc@5: 93.7500 (93.0419)  time: 0.2187  data: 0.0003  max mem: 2501
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.5651 (1.4251)  Acc@1: 62.5000 (68.3132)  Acc@5: 87.5000 (93.0075)  time: 0.2193  data: 0.0010  max mem: 2501
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 1.5143 (1.4248)  Acc@1: 62.5000 (68.3249)  Acc@5: 87.5000 (92.9953)  time: 0.2196  data: 0.0010  max mem: 2501
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.4272 (1.4258)  Acc@1: 68.7500 (68.2977)  Acc@5: 87.5000 (92.9833)  time: 0.2196  data: 0.0005  max mem: 2501
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.5247 (1.4263)  Acc@1: 68.7500 (68.2965)  Acc@5: 93.7500 (92.9800)  time: 0.2189  data: 0.0005  max mem: 2501
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.3516 (1.4267)  Acc@1: 68.7500 (68.2699)  Acc@5: 93.7500 (92.9852)  time: 0.2195  data: 0.0004  max mem: 2501
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 1.3981 (1.4275)  Acc@1: 62.5000 (68.2478)  Acc@5: 93.7500 (92.9566)  time: 0.2197  data: 0.0004  max mem: 2501
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 1.4942 (1.4276)  Acc@1: 68.7500 (68.2637)  Acc@5: 93.7500 (92.9536)  time: 0.2203  data: 0.0006  max mem: 2501
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.4212 (1.4278)  Acc@1: 68.7500 (68.2795)  Acc@5: 93.7500 (92.9589)  time: 0.2200  data: 0.0006  max mem: 2501
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.1659 (1.4277)  Acc@1: 68.7500 (68.2536)  Acc@5: 93.7500 (92.9558)  time: 0.2178  data: 0.0003  max mem: 2501
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.1656 (1.4267)  Acc@1: 75.0000 (68.2898)  Acc@5: 93.7500 (92.9652)  time: 0.2177  data: 0.0003  max mem: 2501
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.1656 (1.4260)  Acc@1: 75.0000 (68.3132)  Acc@5: 100.0000 (92.9825)  time: 0.2186  data: 0.0005  max mem: 2501
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 1.1939 (1.4250)  Acc@1: 68.7500 (68.3039)  Acc@5: 100.0000 (92.9916)  time: 0.2187  data: 0.0005  max mem: 2501
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 1.2188 (1.4249)  Acc@1: 68.7500 (68.2946)  Acc@5: 93.7500 (93.0085)  time: 0.2183  data: 0.0003  max mem: 2501
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 1.2188 (1.4237)  Acc@1: 75.0000 (68.3376)  Acc@5: 93.7500 (93.0133)  time: 0.2184  data: 0.0003  max mem: 2501
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.1794 (1.4236)  Acc@1: 75.0000 (68.3482)  Acc@5: 93.7500 (93.0140)  time: 0.2188  data: 0.0004  max mem: 2501
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.3488 (1.4231)  Acc@1: 68.7500 (68.3784)  Acc@5: 93.7500 (93.0226)  time: 0.2194  data: 0.0004  max mem: 2501
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.3776 (1.4235)  Acc@1: 68.7500 (68.3532)  Acc@5: 93.7500 (93.0233)  time: 0.2196  data: 0.0004  max mem: 2501
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.4415 (1.4246)  Acc@1: 62.5000 (68.3206)  Acc@5: 93.7500 (92.9927)  time: 0.2195  data: 0.0004  max mem: 2501
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.3929 (1.4238)  Acc@1: 68.7500 (68.3504)  Acc@5: 93.7500 (92.9974)  time: 0.2196  data: 0.0004  max mem: 2501
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.2743 (1.4233)  Acc@1: 68.7500 (68.3413)  Acc@5: 93.7500 (93.0059)  time: 0.2196  data: 0.0003  max mem: 2501
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.2359 (1.4225)  Acc@1: 68.7500 (68.3774)  Acc@5: 93.7500 (93.0086)  time: 0.2194  data: 0.0003  max mem: 2501
Test: [Task 1] Total time: 0:05:57 (0.2195 s / it)
* Acc@1 68.377 Acc@5 93.009 loss 1.422
Test: [Task 2]  [  0/625]  eta: 0:06:35  Loss: 0.3307 (0.3307)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6327  data: 0.4137  max mem: 2501
Test: [Task 2]  [ 10/625]  eta: 0:02:38  Loss: 0.4422 (0.4531)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (99.4318)  time: 0.2577  data: 0.0381  max mem: 2501
Test: [Task 2]  [ 20/625]  eta: 0:02:24  Loss: 0.3950 (0.4504)  Acc@1: 87.5000 (91.3690)  Acc@5: 100.0000 (99.4048)  time: 0.2199  data: 0.0007  max mem: 2501
Test: [Task 2]  [ 30/625]  eta: 0:02:18  Loss: 0.4585 (0.4735)  Acc@1: 87.5000 (91.1290)  Acc@5: 100.0000 (99.1935)  time: 0.2195  data: 0.0005  max mem: 2501
Test: [Task 2]  [ 40/625]  eta: 0:02:14  Loss: 0.4585 (0.4718)  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (99.2378)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 50/625]  eta: 0:02:10  Loss: 0.4924 (0.4981)  Acc@1: 87.5000 (90.3186)  Acc@5: 100.0000 (99.1422)  time: 0.2191  data: 0.0004  max mem: 2501
Test: [Task 2]  [ 60/625]  eta: 0:02:07  Loss: 0.5598 (0.4997)  Acc@1: 87.5000 (90.1639)  Acc@5: 100.0000 (99.2828)  time: 0.2191  data: 0.0003  max mem: 2501
Test: [Task 2]  [ 70/625]  eta: 0:02:05  Loss: 0.4858 (0.4944)  Acc@1: 93.7500 (90.4049)  Acc@5: 100.0000 (99.2958)  time: 0.2204  data: 0.0007  max mem: 2501
Test: [Task 2]  [ 80/625]  eta: 0:02:02  Loss: 0.4938 (0.5026)  Acc@1: 87.5000 (90.3549)  Acc@5: 100.0000 (99.0741)  time: 0.2206  data: 0.0008  max mem: 2501
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 0.5087 (0.5039)  Acc@1: 87.5000 (90.3159)  Acc@5: 100.0000 (99.1071)  time: 0.2195  data: 0.0004  max mem: 2501
Test: [Task 2]  [100/625]  eta: 0:01:57  Loss: 0.4941 (0.5033)  Acc@1: 93.7500 (90.5941)  Acc@5: 100.0000 (99.1337)  time: 0.2199  data: 0.0007  max mem: 2501
Test: [Task 2]  [110/625]  eta: 0:01:55  Loss: 0.4767 (0.5012)  Acc@1: 93.7500 (90.5405)  Acc@5: 100.0000 (99.0428)  time: 0.2194  data: 0.0007  max mem: 2501
Test: [Task 2]  [120/625]  eta: 0:01:52  Loss: 0.4767 (0.5016)  Acc@1: 93.7500 (90.5475)  Acc@5: 100.0000 (98.9669)  time: 0.2193  data: 0.0009  max mem: 2501
Test: [Task 2]  [130/625]  eta: 0:01:50  Loss: 0.4817 (0.5030)  Acc@1: 87.5000 (90.4580)  Acc@5: 100.0000 (99.0458)  time: 0.2193  data: 0.0012  max mem: 2501
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 0.4553 (0.5046)  Acc@1: 87.5000 (90.4255)  Acc@5: 100.0000 (99.0691)  time: 0.2187  data: 0.0006  max mem: 2501
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 0.5146 (0.5102)  Acc@1: 87.5000 (90.1904)  Acc@5: 100.0000 (98.9652)  time: 0.2183  data: 0.0003  max mem: 2501
Test: [Task 2]  [160/625]  eta: 0:01:43  Loss: 0.5146 (0.5141)  Acc@1: 87.5000 (89.9845)  Acc@5: 100.0000 (98.9130)  time: 0.2180  data: 0.0004  max mem: 2501
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 0.5141 (0.5166)  Acc@1: 87.5000 (89.8026)  Acc@5: 100.0000 (98.9401)  time: 0.2185  data: 0.0008  max mem: 2501
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 0.5141 (0.5170)  Acc@1: 87.5000 (89.8481)  Acc@5: 100.0000 (98.9641)  time: 0.2185  data: 0.0008  max mem: 2501
Test: [Task 2]  [190/625]  eta: 0:01:36  Loss: 0.4868 (0.5194)  Acc@1: 87.5000 (89.7251)  Acc@5: 100.0000 (98.9202)  time: 0.2179  data: 0.0004  max mem: 2501
Test: [Task 2]  [200/625]  eta: 0:01:34  Loss: 0.4528 (0.5174)  Acc@1: 87.5000 (89.7077)  Acc@5: 100.0000 (98.9428)  time: 0.2181  data: 0.0005  max mem: 2501
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 0.4493 (0.5198)  Acc@1: 93.7500 (89.5735)  Acc@5: 100.0000 (98.9633)  time: 0.2177  data: 0.0005  max mem: 2501
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 0.4458 (0.5153)  Acc@1: 93.7500 (89.8756)  Acc@5: 100.0000 (98.9819)  time: 0.2176  data: 0.0003  max mem: 2501
Test: [Task 2]  [230/625]  eta: 0:01:27  Loss: 0.4001 (0.5145)  Acc@1: 93.7500 (89.9351)  Acc@5: 100.0000 (98.9989)  time: 0.2177  data: 0.0003  max mem: 2501
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 0.5129 (0.5162)  Acc@1: 87.5000 (89.8081)  Acc@5: 100.0000 (98.9886)  time: 0.2179  data: 0.0003  max mem: 2501
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 0.5404 (0.5177)  Acc@1: 87.5000 (89.8406)  Acc@5: 100.0000 (98.9791)  time: 0.2183  data: 0.0003  max mem: 2501
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 0.5324 (0.5188)  Acc@1: 87.5000 (89.7749)  Acc@5: 100.0000 (98.9464)  time: 0.2188  data: 0.0003  max mem: 2501
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 0.5317 (0.5188)  Acc@1: 87.5000 (89.7371)  Acc@5: 100.0000 (98.9161)  time: 0.2186  data: 0.0003  max mem: 2501
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.5317 (0.5196)  Acc@1: 87.5000 (89.6575)  Acc@5: 100.0000 (98.8657)  time: 0.2177  data: 0.0003  max mem: 2501
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 0.5307 (0.5204)  Acc@1: 87.5000 (89.6263)  Acc@5: 100.0000 (98.8402)  time: 0.2182  data: 0.0004  max mem: 2501
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 0.5307 (0.5215)  Acc@1: 87.5000 (89.5349)  Acc@5: 100.0000 (98.8580)  time: 0.2191  data: 0.0004  max mem: 2501
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 0.5391 (0.5239)  Acc@1: 87.5000 (89.4895)  Acc@5: 100.0000 (98.8143)  time: 0.2186  data: 0.0003  max mem: 2501
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 0.3020 (0.5139)  Acc@1: 93.7500 (89.7780)  Acc@5: 100.0000 (98.8512)  time: 0.2180  data: 0.0003  max mem: 2501
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.2105 (0.5090)  Acc@1: 100.0000 (89.9924)  Acc@5: 100.0000 (98.8860)  time: 0.2188  data: 0.0003  max mem: 2501
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.2359 (0.5000)  Acc@1: 100.0000 (90.2309)  Acc@5: 100.0000 (98.9003)  time: 0.2215  data: 0.0004  max mem: 2501
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.2290 (0.4948)  Acc@1: 100.0000 (90.3668)  Acc@5: 100.0000 (98.9316)  time: 0.2212  data: 0.0004  max mem: 2501
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 0.4247 (0.4969)  Acc@1: 87.5000 (90.2874)  Acc@5: 100.0000 (98.9439)  time: 0.2186  data: 0.0004  max mem: 2501
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 0.4529 (0.4933)  Acc@1: 87.5000 (90.3470)  Acc@5: 100.0000 (98.9724)  time: 0.2184  data: 0.0004  max mem: 2501
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.4529 (0.4985)  Acc@1: 87.5000 (90.2231)  Acc@5: 100.0000 (98.9337)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.4432 (0.4970)  Acc@1: 87.5000 (90.2334)  Acc@5: 100.0000 (98.9130)  time: 0.2194  data: 0.0003  max mem: 2501
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.2631 (0.4912)  Acc@1: 93.7500 (90.3990)  Acc@5: 100.0000 (98.9401)  time: 0.2189  data: 0.0003  max mem: 2501
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 0.2173 (0.4886)  Acc@1: 100.0000 (90.4805)  Acc@5: 100.0000 (98.9355)  time: 0.2189  data: 0.0003  max mem: 2501
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 0.2921 (0.4865)  Acc@1: 100.0000 (90.6176)  Acc@5: 100.0000 (98.9608)  time: 0.2193  data: 0.0006  max mem: 2501
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.2921 (0.4837)  Acc@1: 100.0000 (90.7193)  Acc@5: 100.0000 (98.9704)  time: 0.2193  data: 0.0007  max mem: 2501
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.2163 (0.4778)  Acc@1: 100.0000 (90.8730)  Acc@5: 100.0000 (98.9938)  time: 0.2192  data: 0.0004  max mem: 2501
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.1810 (0.4712)  Acc@1: 100.0000 (91.0338)  Acc@5: 100.0000 (99.0161)  time: 0.2189  data: 0.0003  max mem: 2501
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 0.1897 (0.4668)  Acc@1: 93.7500 (91.1063)  Acc@5: 100.0000 (99.0374)  time: 0.2202  data: 0.0003  max mem: 2501
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 0.3088 (0.4653)  Acc@1: 93.7500 (91.1890)  Acc@5: 100.0000 (99.0446)  time: 0.2203  data: 0.0004  max mem: 2501
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.3726 (0.4639)  Acc@1: 93.7500 (91.2032)  Acc@5: 100.0000 (99.0644)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.2898 (0.4618)  Acc@1: 93.7500 (91.3060)  Acc@5: 100.0000 (99.0835)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.2967 (0.4599)  Acc@1: 100.0000 (91.3797)  Acc@5: 100.0000 (99.1018)  time: 0.2206  data: 0.0015  max mem: 2501
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.3794 (0.4605)  Acc@1: 93.7500 (91.2916)  Acc@5: 100.0000 (99.1071)  time: 0.2205  data: 0.0015  max mem: 2501
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 0.3292 (0.4606)  Acc@1: 93.7500 (91.3508)  Acc@5: 100.0000 (99.1123)  time: 0.2191  data: 0.0004  max mem: 2501
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.3163 (0.4578)  Acc@1: 93.7500 (91.4430)  Acc@5: 100.0000 (99.1290)  time: 0.2191  data: 0.0004  max mem: 2501
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.3163 (0.4563)  Acc@1: 93.7500 (91.4972)  Acc@5: 100.0000 (99.1451)  time: 0.2190  data: 0.0003  max mem: 2501
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.2515 (0.4511)  Acc@1: 93.7500 (91.6175)  Acc@5: 100.0000 (99.1606)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.1411 (0.4457)  Acc@1: 100.0000 (91.7669)  Acc@5: 100.0000 (99.1756)  time: 0.2194  data: 0.0003  max mem: 2501
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 0.1651 (0.4446)  Acc@1: 100.0000 (91.8236)  Acc@5: 100.0000 (99.1900)  time: 0.2191  data: 0.0003  max mem: 2501
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.2108 (0.4402)  Acc@1: 100.0000 (91.9535)  Acc@5: 100.0000 (99.2040)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.2476 (0.4382)  Acc@1: 100.0000 (91.9839)  Acc@5: 100.0000 (99.2174)  time: 0.2192  data: 0.0003  max mem: 2501
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.3653 (0.4384)  Acc@1: 93.7500 (91.9925)  Acc@5: 100.0000 (99.2304)  time: 0.2193  data: 0.0005  max mem: 2501
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.5177 (0.4424)  Acc@1: 93.7500 (91.8985)  Acc@5: 100.0000 (99.2021)  time: 0.2191  data: 0.0005  max mem: 2501
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.4571 (0.4424)  Acc@1: 87.5000 (91.8378)  Acc@5: 100.0000 (99.2150)  time: 0.2183  data: 0.0003  max mem: 2501
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.4288 (0.4421)  Acc@1: 93.7500 (91.8400)  Acc@5: 100.0000 (99.2200)  time: 0.2183  data: 0.0003  max mem: 2501
Test: [Task 2] Total time: 0:02:17 (0.2201 s / it)
* Acc@1 91.840 Acc@5 99.220 loss 0.442
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task2]	Acc@1: 80.1087	Acc@5: 96.1143	Loss: 0.9323	Forgetting: 11.2592	Backward: -11.2592
Train: Epoch[1/1]  [   0/3125]  eta: 0:38:54  Lr: 0.001875  Loss: 1.6182  Acc@1: 18.7500 (18.7500)  Acc@5: 43.7500 (43.7500)  time: 0.7471  data: 0.3711  max mem: 2501
Train: Epoch[1/1]  [  10/3125]  eta: 0:20:03  Lr: 0.001875  Loss: 1.3139  Acc@1: 31.2500 (31.8182)  Acc@5: 75.0000 (69.3182)  time: 0.3864  data: 0.0341  max mem: 2502
Train: Epoch[1/1]  [  20/3125]  eta: 0:19:05  Lr: 0.001875  Loss: 1.1261  Acc@1: 37.5000 (38.3929)  Acc@5: 75.0000 (76.4881)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [  30/3125]  eta: 0:18:43  Lr: 0.001875  Loss: 0.8926  Acc@1: 50.0000 (44.7581)  Acc@5: 87.5000 (81.0484)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [  40/3125]  eta: 0:18:32  Lr: 0.001875  Loss: 0.9839  Acc@1: 62.5000 (49.0854)  Acc@5: 93.7500 (83.9939)  time: 0.3517  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [  50/3125]  eta: 0:18:21  Lr: 0.001875  Loss: 0.5058  Acc@1: 62.5000 (51.4706)  Acc@5: 93.7500 (85.4167)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [  60/3125]  eta: 0:18:13  Lr: 0.001875  Loss: 0.8018  Acc@1: 68.7500 (54.4057)  Acc@5: 93.7500 (86.8852)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [  70/3125]  eta: 0:18:07  Lr: 0.001875  Loss: 0.4231  Acc@1: 62.5000 (55.1056)  Acc@5: 93.7500 (87.9401)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [  80/3125]  eta: 0:18:02  Lr: 0.001875  Loss: 0.3568  Acc@1: 62.5000 (56.1728)  Acc@5: 93.7500 (88.7346)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [  90/3125]  eta: 0:17:57  Lr: 0.001875  Loss: 0.0081  Acc@1: 68.7500 (57.9670)  Acc@5: 93.7500 (89.5604)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 100/3125]  eta: 0:17:52  Lr: 0.001875  Loss: 0.0877  Acc@1: 75.0000 (59.7772)  Acc@5: 100.0000 (90.0990)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 110/3125]  eta: 0:17:47  Lr: 0.001875  Loss: 0.1431  Acc@1: 75.0000 (60.5856)  Acc@5: 93.7500 (90.4279)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 120/3125]  eta: 0:17:44  Lr: 0.001875  Loss: 0.4118  Acc@1: 75.0000 (61.4669)  Acc@5: 100.0000 (91.0124)  time: 0.3527  data: 0.0014  max mem: 2502
Train: Epoch[1/1]  [ 130/3125]  eta: 0:17:39  Lr: 0.001875  Loss: -0.0083  Acc@1: 81.2500 (62.5477)  Acc@5: 100.0000 (91.4599)  time: 0.3524  data: 0.0013  max mem: 2502
Train: Epoch[1/1]  [ 140/3125]  eta: 0:17:35  Lr: 0.001875  Loss: 0.2722  Acc@1: 75.0000 (63.2535)  Acc@5: 100.0000 (91.7553)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 150/3125]  eta: 0:17:31  Lr: 0.001875  Loss: 0.3607  Acc@1: 75.0000 (64.2798)  Acc@5: 100.0000 (92.0944)  time: 0.3504  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 160/3125]  eta: 0:17:27  Lr: 0.001875  Loss: 0.1177  Acc@1: 68.7500 (64.5186)  Acc@5: 100.0000 (92.3525)  time: 0.3511  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 170/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.3880  Acc@1: 68.7500 (65.2412)  Acc@5: 93.7500 (92.5439)  time: 0.3520  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 180/3125]  eta: 0:17:19  Lr: 0.001875  Loss: 0.0318  Acc@1: 81.2500 (65.8494)  Acc@5: 100.0000 (92.8177)  time: 0.3516  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 190/3125]  eta: 0:17:16  Lr: 0.001875  Loss: -0.0444  Acc@1: 75.0000 (66.2631)  Acc@5: 100.0000 (92.9647)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 200/3125]  eta: 0:17:12  Lr: 0.001875  Loss: 0.0108  Acc@1: 75.0000 (66.6667)  Acc@5: 93.7500 (93.0348)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 210/3125]  eta: 0:17:08  Lr: 0.001875  Loss: 0.0669  Acc@1: 75.0000 (67.0616)  Acc@5: 100.0000 (93.3353)  time: 0.3518  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 220/3125]  eta: 0:17:05  Lr: 0.001875  Loss: -0.0424  Acc@1: 75.0000 (67.5905)  Acc@5: 100.0000 (93.4955)  time: 0.3515  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 230/3125]  eta: 0:17:01  Lr: 0.001875  Loss: 0.0262  Acc@1: 75.0000 (67.6407)  Acc@5: 93.7500 (93.4794)  time: 0.3518  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 240/3125]  eta: 0:16:58  Lr: 0.001875  Loss: -0.2297  Acc@1: 68.7500 (67.8683)  Acc@5: 93.7500 (93.5166)  time: 0.3539  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 250/3125]  eta: 0:16:54  Lr: 0.001875  Loss: -0.2842  Acc@1: 75.0000 (68.3018)  Acc@5: 100.0000 (93.7002)  time: 0.3542  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 260/3125]  eta: 0:16:51  Lr: 0.001875  Loss: 0.2819  Acc@1: 75.0000 (68.3190)  Acc@5: 93.7500 (93.7261)  time: 0.3535  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [ 270/3125]  eta: 0:16:47  Lr: 0.001875  Loss: -0.3937  Acc@1: 68.7500 (68.6116)  Acc@5: 93.7500 (93.8423)  time: 0.3545  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [ 280/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.2498  Acc@1: 75.0000 (69.0169)  Acc@5: 93.7500 (93.9057)  time: 0.3557  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 290/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.0384  Acc@1: 81.2500 (69.4158)  Acc@5: 100.0000 (94.0077)  time: 0.3556  data: 0.0013  max mem: 2502
Train: Epoch[1/1]  [ 300/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.2580  Acc@1: 81.2500 (69.5390)  Acc@5: 100.0000 (94.1030)  time: 0.3543  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [ 310/3125]  eta: 0:16:34  Lr: 0.001875  Loss: 0.1287  Acc@1: 75.0000 (69.6744)  Acc@5: 100.0000 (94.1720)  time: 0.3541  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 320/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.3877  Acc@1: 81.2500 (70.0350)  Acc@5: 100.0000 (94.2952)  time: 0.3544  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 330/3125]  eta: 0:16:27  Lr: 0.001875  Loss: 0.1053  Acc@1: 81.2500 (70.4116)  Acc@5: 100.0000 (94.3731)  time: 0.3532  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 340/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.3112  Acc@1: 81.2500 (70.6745)  Acc@5: 93.7500 (94.3732)  time: 0.3519  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [ 350/3125]  eta: 0:16:20  Lr: 0.001875  Loss: -0.3504  Acc@1: 75.0000 (70.8333)  Acc@5: 93.7500 (94.4444)  time: 0.3523  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [ 360/3125]  eta: 0:16:16  Lr: 0.001875  Loss: -0.2259  Acc@1: 75.0000 (70.8102)  Acc@5: 100.0000 (94.4945)  time: 0.3541  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [ 370/3125]  eta: 0:16:13  Lr: 0.001875  Loss: -0.4590  Acc@1: 75.0000 (71.0243)  Acc@5: 100.0000 (94.5755)  time: 0.3542  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [ 380/3125]  eta: 0:16:09  Lr: 0.001875  Loss: -0.2723  Acc@1: 81.2500 (71.3747)  Acc@5: 100.0000 (94.7014)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 390/3125]  eta: 0:16:06  Lr: 0.001875  Loss: 0.1327  Acc@1: 81.2500 (71.4354)  Acc@5: 100.0000 (94.7251)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 400/3125]  eta: 0:16:02  Lr: 0.001875  Loss: 0.3764  Acc@1: 75.0000 (71.5867)  Acc@5: 100.0000 (94.7943)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [ 410/3125]  eta: 0:15:59  Lr: 0.001875  Loss: -0.1557  Acc@1: 81.2500 (71.7305)  Acc@5: 100.0000 (94.8449)  time: 0.3533  data: 0.0008  max mem: 2502
Train: Epoch[1/1]  [ 420/3125]  eta: 0:15:55  Lr: 0.001875  Loss: -0.0017  Acc@1: 68.7500 (71.6746)  Acc@5: 100.0000 (94.9376)  time: 0.3536  data: 0.0009  max mem: 2502
Train: Epoch[1/1]  [ 430/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.2542  Acc@1: 75.0000 (71.8677)  Acc@5: 100.0000 (94.9826)  time: 0.3538  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 440/3125]  eta: 0:15:48  Lr: 0.001875  Loss: -0.5739  Acc@1: 81.2500 (72.1230)  Acc@5: 93.7500 (94.9972)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 450/3125]  eta: 0:15:44  Lr: 0.001875  Loss: -0.5543  Acc@1: 75.0000 (72.1729)  Acc@5: 93.7500 (94.9972)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 460/3125]  eta: 0:15:41  Lr: 0.001875  Loss: 0.0221  Acc@1: 75.0000 (72.3563)  Acc@5: 93.7500 (94.9973)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 470/3125]  eta: 0:15:37  Lr: 0.001875  Loss: -0.3004  Acc@1: 81.2500 (72.5849)  Acc@5: 100.0000 (95.0770)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 480/3125]  eta: 0:15:34  Lr: 0.001875  Loss: 0.0222  Acc@1: 81.2500 (72.7001)  Acc@5: 100.0000 (95.1403)  time: 0.3529  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 490/3125]  eta: 0:15:30  Lr: 0.001875  Loss: -0.7086  Acc@1: 81.2500 (72.9124)  Acc@5: 100.0000 (95.1884)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 500/3125]  eta: 0:15:27  Lr: 0.001875  Loss: 0.1142  Acc@1: 81.2500 (73.0040)  Acc@5: 100.0000 (95.1971)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 510/3125]  eta: 0:15:23  Lr: 0.001875  Loss: -0.2981  Acc@1: 81.2500 (73.1776)  Acc@5: 100.0000 (95.2544)  time: 0.3515  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 520/3125]  eta: 0:15:19  Lr: 0.001875  Loss: -0.5812  Acc@1: 81.2500 (73.3445)  Acc@5: 100.0000 (95.2975)  time: 0.3516  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 530/3125]  eta: 0:15:16  Lr: 0.001875  Loss: -0.3387  Acc@1: 75.0000 (73.4699)  Acc@5: 100.0000 (95.3037)  time: 0.3525  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 540/3125]  eta: 0:15:12  Lr: 0.001875  Loss: -0.5190  Acc@1: 81.2500 (73.5444)  Acc@5: 100.0000 (95.3443)  time: 0.3535  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 550/3125]  eta: 0:15:09  Lr: 0.001875  Loss: -0.3252  Acc@1: 81.2500 (73.6275)  Acc@5: 100.0000 (95.3721)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 560/3125]  eta: 0:15:05  Lr: 0.001875  Loss: -0.3976  Acc@1: 75.0000 (73.7411)  Acc@5: 93.7500 (95.3877)  time: 0.3524  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 570/3125]  eta: 0:15:02  Lr: 0.001875  Loss: -0.5586  Acc@1: 75.0000 (73.8288)  Acc@5: 93.7500 (95.3809)  time: 0.3514  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 580/3125]  eta: 0:14:58  Lr: 0.001875  Loss: -0.4580  Acc@1: 75.0000 (73.9243)  Acc@5: 100.0000 (95.4389)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 590/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.4462  Acc@1: 81.2500 (74.0271)  Acc@5: 100.0000 (95.4738)  time: 0.3532  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 600/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.5849  Acc@1: 81.2500 (74.1577)  Acc@5: 100.0000 (95.4763)  time: 0.3534  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 610/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.1577  Acc@1: 81.2500 (74.2328)  Acc@5: 100.0000 (95.5196)  time: 0.3532  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 620/3125]  eta: 0:14:44  Lr: 0.001875  Loss: -0.3197  Acc@1: 75.0000 (74.3156)  Acc@5: 100.0000 (95.5415)  time: 0.3535  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 630/3125]  eta: 0:14:41  Lr: 0.001875  Loss: -0.0458  Acc@1: 75.0000 (74.3958)  Acc@5: 100.0000 (95.5527)  time: 0.3554  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [ 640/3125]  eta: 0:14:37  Lr: 0.001875  Loss: -0.5490  Acc@1: 75.0000 (74.4930)  Acc@5: 100.0000 (95.6026)  time: 0.3546  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [ 650/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.6203  Acc@1: 81.2500 (74.5968)  Acc@5: 100.0000 (95.6509)  time: 0.3526  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [ 660/3125]  eta: 0:14:30  Lr: 0.001875  Loss: -0.2465  Acc@1: 81.2500 (74.6596)  Acc@5: 100.0000 (95.6884)  time: 0.3534  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [ 670/3125]  eta: 0:14:26  Lr: 0.001875  Loss: 0.1386  Acc@1: 81.2500 (74.7113)  Acc@5: 100.0000 (95.7154)  time: 0.3535  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 680/3125]  eta: 0:14:23  Lr: 0.001875  Loss: -0.4269  Acc@1: 81.2500 (74.7706)  Acc@5: 100.0000 (95.7507)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 690/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.6229  Acc@1: 81.2500 (74.7829)  Acc@5: 100.0000 (95.7941)  time: 0.3527  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 700/3125]  eta: 0:14:16  Lr: 0.001875  Loss: 0.0660  Acc@1: 75.0000 (74.8128)  Acc@5: 100.0000 (95.8096)  time: 0.3527  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 710/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.3077  Acc@1: 81.2500 (74.9297)  Acc@5: 93.7500 (95.8158)  time: 0.3524  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 720/3125]  eta: 0:14:09  Lr: 0.001875  Loss: 0.0222  Acc@1: 81.2500 (74.9567)  Acc@5: 100.0000 (95.8304)  time: 0.3533  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 730/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.5393  Acc@1: 81.2500 (75.0855)  Acc@5: 100.0000 (95.8618)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 740/3125]  eta: 0:14:02  Lr: 0.001875  Loss: -0.2115  Acc@1: 81.2500 (75.1265)  Acc@5: 100.0000 (95.8839)  time: 0.3530  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 750/3125]  eta: 0:13:58  Lr: 0.001875  Loss: -0.5202  Acc@1: 81.2500 (75.2663)  Acc@5: 100.0000 (95.9221)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 760/3125]  eta: 0:13:55  Lr: 0.001875  Loss: -0.5616  Acc@1: 87.5000 (75.3696)  Acc@5: 100.0000 (95.9757)  time: 0.3542  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 770/3125]  eta: 0:13:51  Lr: 0.001875  Loss: -0.4097  Acc@1: 81.2500 (75.4215)  Acc@5: 100.0000 (95.9955)  time: 0.3540  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 780/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.2395  Acc@1: 81.2500 (75.5522)  Acc@5: 100.0000 (96.0067)  time: 0.3511  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 790/3125]  eta: 0:13:44  Lr: 0.001875  Loss: -0.8830  Acc@1: 81.2500 (75.6242)  Acc@5: 100.0000 (96.0493)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 800/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.1468  Acc@1: 81.2500 (75.6866)  Acc@5: 100.0000 (96.0752)  time: 0.3507  data: 0.0009  max mem: 2502
Train: Epoch[1/1]  [ 810/3125]  eta: 0:13:37  Lr: 0.001875  Loss: -0.1978  Acc@1: 75.0000 (75.7090)  Acc@5: 100.0000 (96.0774)  time: 0.3516  data: 0.0009  max mem: 2502
Train: Epoch[1/1]  [ 820/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.3436  Acc@1: 81.2500 (75.7993)  Acc@5: 100.0000 (96.0719)  time: 0.3519  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 830/3125]  eta: 0:13:30  Lr: 0.001875  Loss: -0.5323  Acc@1: 81.2500 (75.8198)  Acc@5: 100.0000 (96.0815)  time: 0.3528  data: 0.0012  max mem: 2502
Train: Epoch[1/1]  [ 840/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.4205  Acc@1: 75.0000 (75.8844)  Acc@5: 100.0000 (96.1058)  time: 0.3531  data: 0.0014  max mem: 2502
Train: Epoch[1/1]  [ 850/3125]  eta: 0:13:23  Lr: 0.001875  Loss: -0.2684  Acc@1: 81.2500 (75.9254)  Acc@5: 100.0000 (96.1075)  time: 0.3540  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [ 860/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.6842  Acc@1: 81.2500 (75.9727)  Acc@5: 100.0000 (96.1310)  time: 0.3535  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [ 870/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.1234  Acc@1: 81.2500 (76.0548)  Acc@5: 100.0000 (96.1538)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [ 880/3125]  eta: 0:13:12  Lr: 0.001875  Loss: -0.2679  Acc@1: 81.2500 (76.0854)  Acc@5: 100.0000 (96.1691)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 890/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.4991  Acc@1: 81.2500 (76.1504)  Acc@5: 100.0000 (96.1911)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 900/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.1000  Acc@1: 81.2500 (76.2001)  Acc@5: 100.0000 (96.1848)  time: 0.3527  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 910/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.7578  Acc@1: 81.2500 (76.3172)  Acc@5: 100.0000 (96.2061)  time: 0.3533  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 920/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.0976  Acc@1: 87.5000 (76.3640)  Acc@5: 100.0000 (96.2201)  time: 0.3535  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [ 930/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.5065  Acc@1: 81.2500 (76.4501)  Acc@5: 100.0000 (96.2339)  time: 0.3526  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [ 940/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.0241  Acc@1: 81.2500 (76.4346)  Acc@5: 100.0000 (96.2407)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 950/3125]  eta: 0:12:47  Lr: 0.001875  Loss: 0.1267  Acc@1: 81.2500 (76.4787)  Acc@5: 100.0000 (96.2474)  time: 0.3516  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 960/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.4991  Acc@1: 81.2500 (76.5544)  Acc@5: 93.7500 (96.2409)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 970/3125]  eta: 0:12:40  Lr: 0.001875  Loss: 0.0686  Acc@1: 81.2500 (76.5577)  Acc@5: 93.7500 (96.2088)  time: 0.3514  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 980/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.4570  Acc@1: 81.2500 (76.6055)  Acc@5: 93.7500 (96.2347)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 990/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.4338  Acc@1: 81.2500 (76.5956)  Acc@5: 100.0000 (96.2538)  time: 0.3537  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1000/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.7105  Acc@1: 81.2500 (76.6046)  Acc@5: 100.0000 (96.2600)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1010/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.2882  Acc@1: 75.0000 (76.6073)  Acc@5: 93.7500 (96.2537)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1020/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.4777  Acc@1: 75.0000 (76.6773)  Acc@5: 100.0000 (96.2659)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1030/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.4776  Acc@1: 87.5000 (76.7580)  Acc@5: 100.0000 (96.2839)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1040/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.3526  Acc@1: 87.5000 (76.8612)  Acc@5: 100.0000 (96.3196)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1050/3125]  eta: 0:12:12  Lr: 0.001875  Loss: 0.0159  Acc@1: 87.5000 (76.8970)  Acc@5: 100.0000 (96.3249)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1060/3125]  eta: 0:12:08  Lr: 0.001875  Loss: 0.0496  Acc@1: 81.2500 (76.9380)  Acc@5: 100.0000 (96.3419)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [1070/3125]  eta: 0:12:05  Lr: 0.001875  Loss: 0.0203  Acc@1: 81.2500 (76.9666)  Acc@5: 100.0000 (96.3410)  time: 0.3522  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [1080/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.5915  Acc@1: 81.2500 (76.9773)  Acc@5: 100.0000 (96.3633)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1090/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.4067  Acc@1: 81.2500 (76.9821)  Acc@5: 100.0000 (96.3680)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1100/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.6127  Acc@1: 81.2500 (77.0436)  Acc@5: 100.0000 (96.3840)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1110/3125]  eta: 0:11:50  Lr: 0.001875  Loss: -0.8110  Acc@1: 81.2500 (77.0477)  Acc@5: 100.0000 (96.3996)  time: 0.3520  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [1120/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.5362  Acc@1: 81.2500 (77.0796)  Acc@5: 100.0000 (96.4095)  time: 0.3526  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [1130/3125]  eta: 0:11:43  Lr: 0.001875  Loss: -0.6409  Acc@1: 81.2500 (77.1165)  Acc@5: 100.0000 (96.4136)  time: 0.3566  data: 0.0016  max mem: 2502
Train: Epoch[1/1]  [1140/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.5524  Acc@1: 81.2500 (77.1472)  Acc@5: 100.0000 (96.4231)  time: 0.3557  data: 0.0016  max mem: 2502
Train: Epoch[1/1]  [1150/3125]  eta: 0:11:36  Lr: 0.001875  Loss: -0.1220  Acc@1: 81.2500 (77.1775)  Acc@5: 100.0000 (96.4487)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1160/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.4249  Acc@1: 81.2500 (77.2018)  Acc@5: 100.0000 (96.4578)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [1170/3125]  eta: 0:11:29  Lr: 0.001875  Loss: -0.5308  Acc@1: 81.2500 (77.2203)  Acc@5: 100.0000 (96.4560)  time: 0.3520  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [1180/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.1954  Acc@1: 81.2500 (77.2386)  Acc@5: 100.0000 (96.4649)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [1190/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.4908  Acc@1: 81.2500 (77.2723)  Acc@5: 100.0000 (96.4683)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1200/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.8701  Acc@1: 81.2500 (77.2846)  Acc@5: 100.0000 (96.4769)  time: 0.3516  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1210/3125]  eta: 0:11:15  Lr: 0.001875  Loss: -0.5373  Acc@1: 75.0000 (77.2915)  Acc@5: 100.0000 (96.4905)  time: 0.3528  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1220/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.1553  Acc@1: 87.5000 (77.3649)  Acc@5: 100.0000 (96.5090)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1230/3125]  eta: 0:11:08  Lr: 0.001875  Loss: -0.2908  Acc@1: 81.2500 (77.4015)  Acc@5: 100.0000 (96.5272)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1240/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.2199  Acc@1: 81.2500 (77.4527)  Acc@5: 100.0000 (96.5502)  time: 0.3526  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [1250/3125]  eta: 0:11:01  Lr: 0.001875  Loss: -0.5150  Acc@1: 81.2500 (77.4480)  Acc@5: 100.0000 (96.5528)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[1/1]  [1260/3125]  eta: 0:10:57  Lr: 0.001875  Loss: -0.6734  Acc@1: 81.2500 (77.4683)  Acc@5: 100.0000 (96.5652)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [1270/3125]  eta: 0:10:54  Lr: 0.001875  Loss: -0.4926  Acc@1: 87.5000 (77.5275)  Acc@5: 100.0000 (96.5726)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [1280/3125]  eta: 0:10:50  Lr: 0.001875  Loss: -0.2326  Acc@1: 87.5000 (77.5761)  Acc@5: 100.0000 (96.5749)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [1290/3125]  eta: 0:10:47  Lr: 0.001875  Loss: -0.5499  Acc@1: 81.2500 (77.6046)  Acc@5: 100.0000 (96.5966)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [1300/3125]  eta: 0:10:43  Lr: 0.001875  Loss: -0.6910  Acc@1: 81.2500 (77.6182)  Acc@5: 100.0000 (96.5940)  time: 0.3520  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1310/3125]  eta: 0:10:40  Lr: 0.001875  Loss: -0.4037  Acc@1: 81.2500 (77.6745)  Acc@5: 100.0000 (96.6152)  time: 0.3517  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1320/3125]  eta: 0:10:36  Lr: 0.001875  Loss: -0.5548  Acc@1: 87.5000 (77.7441)  Acc@5: 100.0000 (96.6266)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1330/3125]  eta: 0:10:33  Lr: 0.001875  Loss: -0.4783  Acc@1: 87.5000 (77.7940)  Acc@5: 100.0000 (96.6426)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1340/3125]  eta: 0:10:29  Lr: 0.001875  Loss: 0.1486  Acc@1: 81.2500 (77.7964)  Acc@5: 100.0000 (96.6350)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1350/3125]  eta: 0:10:26  Lr: 0.001875  Loss: -0.1266  Acc@1: 75.0000 (77.7942)  Acc@5: 93.7500 (96.6368)  time: 0.3499  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1360/3125]  eta: 0:10:22  Lr: 0.001875  Loss: -0.5621  Acc@1: 81.2500 (77.8058)  Acc@5: 100.0000 (96.6431)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1370/3125]  eta: 0:10:18  Lr: 0.001875  Loss: -0.0993  Acc@1: 87.5000 (77.8857)  Acc@5: 100.0000 (96.6585)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1380/3125]  eta: 0:10:15  Lr: 0.001875  Loss: -0.4472  Acc@1: 87.5000 (77.9191)  Acc@5: 100.0000 (96.6646)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1390/3125]  eta: 0:10:11  Lr: 0.001875  Loss: -0.2566  Acc@1: 81.2500 (77.9610)  Acc@5: 100.0000 (96.6795)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1400/3125]  eta: 0:10:08  Lr: 0.001875  Loss: -0.2738  Acc@1: 81.2500 (78.0202)  Acc@5: 100.0000 (96.6943)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1410/3125]  eta: 0:10:04  Lr: 0.001875  Loss: -0.2960  Acc@1: 81.2500 (78.0608)  Acc@5: 100.0000 (96.7045)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1420/3125]  eta: 0:10:01  Lr: 0.001875  Loss: -0.6388  Acc@1: 81.2500 (78.1184)  Acc@5: 100.0000 (96.7145)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1430/3125]  eta: 0:09:57  Lr: 0.001875  Loss: -0.5687  Acc@1: 81.2500 (78.1228)  Acc@5: 100.0000 (96.7287)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1440/3125]  eta: 0:09:54  Lr: 0.001875  Loss: -0.5815  Acc@1: 81.2500 (78.1445)  Acc@5: 100.0000 (96.7384)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1450/3125]  eta: 0:09:50  Lr: 0.001875  Loss: -0.4104  Acc@1: 81.2500 (78.1788)  Acc@5: 100.0000 (96.7479)  time: 0.3522  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1460/3125]  eta: 0:09:47  Lr: 0.001875  Loss: -0.1171  Acc@1: 81.2500 (78.2213)  Acc@5: 100.0000 (96.7659)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1470/3125]  eta: 0:09:43  Lr: 0.001875  Loss: -0.4073  Acc@1: 87.5000 (78.2801)  Acc@5: 100.0000 (96.7709)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1480/3125]  eta: 0:09:40  Lr: 0.001875  Loss: -0.2069  Acc@1: 87.5000 (78.3170)  Acc@5: 100.0000 (96.7800)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1490/3125]  eta: 0:09:36  Lr: 0.001875  Loss: -0.2501  Acc@1: 81.2500 (78.3032)  Acc@5: 93.7500 (96.7597)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1500/3125]  eta: 0:09:32  Lr: 0.001875  Loss: 0.0173  Acc@1: 75.0000 (78.3353)  Acc@5: 93.7500 (96.7688)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1510/3125]  eta: 0:09:29  Lr: 0.001875  Loss: -0.4029  Acc@1: 87.5000 (78.3670)  Acc@5: 100.0000 (96.7861)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[1/1]  [1520/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.1635  Acc@1: 81.2500 (78.3900)  Acc@5: 100.0000 (96.7825)  time: 0.3533  data: 0.0012  max mem: 2502
Train: Epoch[1/1]  [1530/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.3322  Acc@1: 81.2500 (78.4250)  Acc@5: 100.0000 (96.8036)  time: 0.3527  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1540/3125]  eta: 0:09:18  Lr: 0.001875  Loss: 0.0553  Acc@1: 81.2500 (78.4231)  Acc@5: 100.0000 (96.8121)  time: 0.3524  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1550/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.5360  Acc@1: 87.5000 (78.4655)  Acc@5: 100.0000 (96.8246)  time: 0.3541  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1560/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.4380  Acc@1: 87.5000 (78.4793)  Acc@5: 100.0000 (96.8370)  time: 0.3539  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1570/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4833  Acc@1: 81.2500 (78.4970)  Acc@5: 100.0000 (96.8213)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1580/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.7429  Acc@1: 81.2500 (78.5065)  Acc@5: 100.0000 (96.8256)  time: 0.3519  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1590/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.3824  Acc@1: 81.2500 (78.5277)  Acc@5: 100.0000 (96.8259)  time: 0.3529  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1600/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.6018  Acc@1: 87.5000 (78.5954)  Acc@5: 100.0000 (96.8301)  time: 0.3533  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1610/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.4697  Acc@1: 87.5000 (78.6002)  Acc@5: 100.0000 (96.8420)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1620/3125]  eta: 0:08:50  Lr: 0.001875  Loss: 0.0047  Acc@1: 75.0000 (78.6050)  Acc@5: 100.0000 (96.8499)  time: 0.3529  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1630/3125]  eta: 0:08:47  Lr: 0.001875  Loss: 0.2162  Acc@1: 81.2500 (78.6174)  Acc@5: 100.0000 (96.8501)  time: 0.3540  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1640/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.6590  Acc@1: 81.2500 (78.6296)  Acc@5: 100.0000 (96.8502)  time: 0.3530  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1650/3125]  eta: 0:08:40  Lr: 0.001875  Loss: -0.3135  Acc@1: 81.2500 (78.6569)  Acc@5: 100.0000 (96.8618)  time: 0.3519  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1660/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.7344  Acc@1: 81.2500 (78.6725)  Acc@5: 100.0000 (96.8694)  time: 0.3533  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1670/3125]  eta: 0:08:33  Lr: 0.001875  Loss: -0.6298  Acc@1: 81.2500 (78.7104)  Acc@5: 100.0000 (96.8731)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1680/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.4366  Acc@1: 81.2500 (78.7403)  Acc@5: 100.0000 (96.8769)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1690/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.4975  Acc@1: 81.2500 (78.7737)  Acc@5: 100.0000 (96.8879)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1700/3125]  eta: 0:08:22  Lr: 0.001875  Loss: -0.3817  Acc@1: 81.2500 (78.7992)  Acc@5: 100.0000 (96.8989)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1710/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.5692  Acc@1: 87.5000 (78.8391)  Acc@5: 100.0000 (96.9060)  time: 0.3543  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [1720/3125]  eta: 0:08:15  Lr: 0.001875  Loss: -0.6273  Acc@1: 81.2500 (78.8313)  Acc@5: 100.0000 (96.9059)  time: 0.3543  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [1730/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.2016  Acc@1: 75.0000 (78.8489)  Acc@5: 100.0000 (96.9093)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1740/3125]  eta: 0:08:08  Lr: 0.001875  Loss: -0.4716  Acc@1: 81.2500 (78.8879)  Acc@5: 100.0000 (96.9235)  time: 0.3532  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1750/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.2148  Acc@1: 81.2500 (78.8799)  Acc@5: 100.0000 (96.9160)  time: 0.3535  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1760/3125]  eta: 0:08:01  Lr: 0.001875  Loss: -0.5075  Acc@1: 81.2500 (78.9111)  Acc@5: 100.0000 (96.9158)  time: 0.3530  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1770/3125]  eta: 0:07:57  Lr: 0.001875  Loss: -0.7025  Acc@1: 87.5000 (78.9526)  Acc@5: 100.0000 (96.9226)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1780/3125]  eta: 0:07:54  Lr: 0.001875  Loss: -0.7062  Acc@1: 87.5000 (79.0076)  Acc@5: 100.0000 (96.9329)  time: 0.3523  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1790/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.2755  Acc@1: 87.5000 (79.0341)  Acc@5: 100.0000 (96.9361)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1800/3125]  eta: 0:07:47  Lr: 0.001875  Loss: -0.1965  Acc@1: 81.2500 (79.0464)  Acc@5: 100.0000 (96.9427)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1810/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.2315  Acc@1: 81.2500 (79.0723)  Acc@5: 100.0000 (96.9423)  time: 0.3536  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1820/3125]  eta: 0:07:40  Lr: 0.001875  Loss: -0.4355  Acc@1: 81.2500 (79.0534)  Acc@5: 100.0000 (96.9316)  time: 0.3527  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1830/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.2129  Acc@1: 75.0000 (79.0688)  Acc@5: 100.0000 (96.9347)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1840/3125]  eta: 0:07:33  Lr: 0.001875  Loss: -0.4561  Acc@1: 81.2500 (79.0705)  Acc@5: 100.0000 (96.9276)  time: 0.3506  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1850/3125]  eta: 0:07:29  Lr: 0.001875  Loss: 0.2851  Acc@1: 81.2500 (79.0991)  Acc@5: 100.0000 (96.9341)  time: 0.3511  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1860/3125]  eta: 0:07:26  Lr: 0.001875  Loss: -0.4108  Acc@1: 87.5000 (79.1342)  Acc@5: 100.0000 (96.9438)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1870/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.7157  Acc@1: 81.2500 (79.1455)  Acc@5: 100.0000 (96.9468)  time: 0.3507  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1880/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.4436  Acc@1: 81.2500 (79.1766)  Acc@5: 100.0000 (96.9564)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1890/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.3013  Acc@1: 87.5000 (79.2107)  Acc@5: 100.0000 (96.9692)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1900/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.5571  Acc@1: 87.5000 (79.2412)  Acc@5: 100.0000 (96.9753)  time: 0.3537  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1910/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.4524  Acc@1: 81.2500 (79.2517)  Acc@5: 100.0000 (96.9780)  time: 0.3540  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1920/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.7477  Acc@1: 81.2500 (79.2816)  Acc@5: 100.0000 (96.9872)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1930/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.5544  Acc@1: 87.5000 (79.3209)  Acc@5: 100.0000 (97.0028)  time: 0.3540  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1940/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.7492  Acc@1: 87.5000 (79.3373)  Acc@5: 100.0000 (97.0054)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1950/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.0213  Acc@1: 81.2500 (79.3535)  Acc@5: 100.0000 (97.0176)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1960/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.4583  Acc@1: 81.2500 (79.3632)  Acc@5: 100.0000 (97.0264)  time: 0.3548  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1970/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.4472  Acc@1: 81.2500 (79.3633)  Acc@5: 100.0000 (97.0288)  time: 0.3558  data: 0.0009  max mem: 2502
Train: Epoch[1/1]  [1980/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.7731  Acc@1: 81.2500 (79.3665)  Acc@5: 100.0000 (97.0343)  time: 0.3533  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [1990/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.2755  Acc@1: 81.2500 (79.3854)  Acc@5: 100.0000 (97.0398)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2000/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.3979  Acc@1: 81.2500 (79.3572)  Acc@5: 100.0000 (97.0421)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2010/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.5482  Acc@1: 81.2500 (79.4101)  Acc@5: 100.0000 (97.0506)  time: 0.3538  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2020/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.5801  Acc@1: 87.5000 (79.4347)  Acc@5: 100.0000 (97.0621)  time: 0.3545  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2030/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.7063  Acc@1: 81.2500 (79.4652)  Acc@5: 100.0000 (97.0643)  time: 0.3542  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2040/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.2353  Acc@1: 87.5000 (79.5076)  Acc@5: 100.0000 (97.0633)  time: 0.3540  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2050/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.5870  Acc@1: 87.5000 (79.5405)  Acc@5: 100.0000 (97.0716)  time: 0.3545  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [2060/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.3713  Acc@1: 87.5000 (79.5579)  Acc@5: 100.0000 (97.0676)  time: 0.3545  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2070/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.4684  Acc@1: 87.5000 (79.5811)  Acc@5: 100.0000 (97.0697)  time: 0.3533  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2080/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.5372  Acc@1: 81.2500 (79.5741)  Acc@5: 100.0000 (97.0777)  time: 0.3538  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2090/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.1432  Acc@1: 81.2500 (79.5672)  Acc@5: 100.0000 (97.0887)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2100/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.3684  Acc@1: 81.2500 (79.5812)  Acc@5: 100.0000 (97.0966)  time: 0.3535  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2110/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.4820  Acc@1: 81.2500 (79.5831)  Acc@5: 100.0000 (97.1045)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2120/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.3248  Acc@1: 81.2500 (79.5792)  Acc@5: 100.0000 (97.1122)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2130/3125]  eta: 0:05:50  Lr: 0.001875  Loss: -0.2593  Acc@1: 81.2500 (79.6105)  Acc@5: 100.0000 (97.1170)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2140/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.3918  Acc@1: 87.5000 (79.6269)  Acc@5: 100.0000 (97.1188)  time: 0.3533  data: 0.0012  max mem: 2502
Train: Epoch[1/1]  [2150/3125]  eta: 0:05:43  Lr: 0.001875  Loss: -0.6790  Acc@1: 81.2500 (79.6316)  Acc@5: 100.0000 (97.1321)  time: 0.3534  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [2160/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.5540  Acc@1: 81.2500 (79.6419)  Acc@5: 100.0000 (97.1367)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2170/3125]  eta: 0:05:36  Lr: 0.001875  Loss: -0.4365  Acc@1: 87.5000 (79.6522)  Acc@5: 100.0000 (97.1413)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [2180/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.4034  Acc@1: 81.2500 (79.6653)  Acc@5: 100.0000 (97.1343)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2190/3125]  eta: 0:05:29  Lr: 0.001875  Loss: -0.4033  Acc@1: 81.2500 (79.6811)  Acc@5: 100.0000 (97.1389)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2200/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.3823  Acc@1: 81.2500 (79.6939)  Acc@5: 100.0000 (97.1462)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2210/3125]  eta: 0:05:22  Lr: 0.001875  Loss: -0.4325  Acc@1: 81.2500 (79.7009)  Acc@5: 100.0000 (97.1450)  time: 0.3502  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2220/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.4576  Acc@1: 81.2500 (79.7163)  Acc@5: 100.0000 (97.1494)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2230/3125]  eta: 0:05:15  Lr: 0.001875  Loss: -0.4637  Acc@1: 81.2500 (79.7344)  Acc@5: 100.0000 (97.1481)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2240/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4884  Acc@1: 81.2500 (79.7328)  Acc@5: 100.0000 (97.1581)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2250/3125]  eta: 0:05:08  Lr: 0.001875  Loss: -0.6037  Acc@1: 81.2500 (79.7645)  Acc@5: 100.0000 (97.1679)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2260/3125]  eta: 0:05:04  Lr: 0.001875  Loss: -0.7182  Acc@1: 87.5000 (79.7988)  Acc@5: 100.0000 (97.1777)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2270/3125]  eta: 0:05:01  Lr: 0.001875  Loss: -0.1267  Acc@1: 87.5000 (79.8162)  Acc@5: 100.0000 (97.1819)  time: 0.3503  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2280/3125]  eta: 0:04:57  Lr: 0.001875  Loss: -0.5805  Acc@1: 81.2500 (79.8361)  Acc@5: 100.0000 (97.1860)  time: 0.3517  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2290/3125]  eta: 0:04:54  Lr: 0.001875  Loss: -0.4476  Acc@1: 81.2500 (79.8532)  Acc@5: 100.0000 (97.1874)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2300/3125]  eta: 0:04:50  Lr: 0.001875  Loss: -0.3617  Acc@1: 81.2500 (79.8539)  Acc@5: 100.0000 (97.1860)  time: 0.3510  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2310/3125]  eta: 0:04:47  Lr: 0.001875  Loss: -0.5417  Acc@1: 81.2500 (79.8680)  Acc@5: 100.0000 (97.1874)  time: 0.3505  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2320/3125]  eta: 0:04:43  Lr: 0.001875  Loss: -0.0373  Acc@1: 81.2500 (79.8847)  Acc@5: 100.0000 (97.1887)  time: 0.3499  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2330/3125]  eta: 0:04:40  Lr: 0.001875  Loss: -0.5241  Acc@1: 81.2500 (79.8960)  Acc@5: 100.0000 (97.1954)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2340/3125]  eta: 0:04:36  Lr: 0.001875  Loss: -0.3827  Acc@1: 81.2500 (79.8991)  Acc@5: 100.0000 (97.2047)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2350/3125]  eta: 0:04:33  Lr: 0.001875  Loss: -0.5297  Acc@1: 81.2500 (79.9128)  Acc@5: 100.0000 (97.2060)  time: 0.3503  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2360/3125]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6718  Acc@1: 81.2500 (79.9291)  Acc@5: 100.0000 (97.2152)  time: 0.3508  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2370/3125]  eta: 0:04:26  Lr: 0.001875  Loss: -0.4835  Acc@1: 87.5000 (79.9373)  Acc@5: 100.0000 (97.2137)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2380/3125]  eta: 0:04:22  Lr: 0.001875  Loss: -0.4062  Acc@1: 81.2500 (79.9428)  Acc@5: 100.0000 (97.2254)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2390/3125]  eta: 0:04:19  Lr: 0.001875  Loss: -0.7525  Acc@1: 87.5000 (79.9744)  Acc@5: 100.0000 (97.2292)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2400/3125]  eta: 0:04:15  Lr: 0.001875  Loss: -0.0486  Acc@1: 87.5000 (79.9901)  Acc@5: 100.0000 (97.2381)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2410/3125]  eta: 0:04:12  Lr: 0.001875  Loss: -0.4560  Acc@1: 81.2500 (79.9953)  Acc@5: 100.0000 (97.2444)  time: 0.3518  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2420/3125]  eta: 0:04:08  Lr: 0.001875  Loss: -0.1996  Acc@1: 81.2500 (79.9902)  Acc@5: 100.0000 (97.2506)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2430/3125]  eta: 0:04:04  Lr: 0.001875  Loss: -0.2742  Acc@1: 81.2500 (79.9928)  Acc@5: 100.0000 (97.2542)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2440/3125]  eta: 0:04:01  Lr: 0.001875  Loss: -0.3559  Acc@1: 81.2500 (80.0159)  Acc@5: 100.0000 (97.2603)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[1/1]  [2450/3125]  eta: 0:03:57  Lr: 0.001875  Loss: -0.6147  Acc@1: 87.5000 (80.0439)  Acc@5: 100.0000 (97.2639)  time: 0.3527  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [2460/3125]  eta: 0:03:54  Lr: 0.001875  Loss: -0.4895  Acc@1: 87.5000 (80.0691)  Acc@5: 100.0000 (97.2674)  time: 0.3527  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [2470/3125]  eta: 0:03:50  Lr: 0.001875  Loss: -0.2724  Acc@1: 87.5000 (80.0865)  Acc@5: 100.0000 (97.2683)  time: 0.3565  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2480/3125]  eta: 0:03:47  Lr: 0.001875  Loss: -0.2922  Acc@1: 75.0000 (80.0811)  Acc@5: 100.0000 (97.2667)  time: 0.3562  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2490/3125]  eta: 0:03:43  Lr: 0.001875  Loss: -0.6129  Acc@1: 81.2500 (80.0833)  Acc@5: 100.0000 (97.2702)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2500/3125]  eta: 0:03:40  Lr: 0.001875  Loss: -0.4522  Acc@1: 81.2500 (80.0980)  Acc@5: 100.0000 (97.2786)  time: 0.3518  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2510/3125]  eta: 0:03:36  Lr: 0.001875  Loss: -0.5619  Acc@1: 81.2500 (80.1050)  Acc@5: 100.0000 (97.2869)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2520/3125]  eta: 0:03:33  Lr: 0.001875  Loss: -0.7863  Acc@1: 81.2500 (80.1195)  Acc@5: 100.0000 (97.2952)  time: 0.3536  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [2530/3125]  eta: 0:03:29  Lr: 0.001875  Loss: -0.8253  Acc@1: 87.5000 (80.1487)  Acc@5: 100.0000 (97.3034)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2540/3125]  eta: 0:03:26  Lr: 0.001875  Loss: -0.2236  Acc@1: 81.2500 (80.1579)  Acc@5: 100.0000 (97.3042)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2550/3125]  eta: 0:03:22  Lr: 0.001875  Loss: -0.6880  Acc@1: 81.2500 (80.1818)  Acc@5: 100.0000 (97.3123)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2560/3125]  eta: 0:03:19  Lr: 0.001875  Loss: -0.3297  Acc@1: 81.2500 (80.2006)  Acc@5: 100.0000 (97.3131)  time: 0.3530  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2570/3125]  eta: 0:03:15  Lr: 0.001875  Loss: -0.3139  Acc@1: 87.5000 (80.2217)  Acc@5: 100.0000 (97.3114)  time: 0.3520  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2580/3125]  eta: 0:03:12  Lr: 0.001875  Loss: -0.4616  Acc@1: 87.5000 (80.2451)  Acc@5: 100.0000 (97.3194)  time: 0.3519  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2590/3125]  eta: 0:03:08  Lr: 0.001875  Loss: -0.5322  Acc@1: 81.2500 (80.2586)  Acc@5: 100.0000 (97.3249)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2600/3125]  eta: 0:03:05  Lr: 0.001875  Loss: -0.0247  Acc@1: 81.2500 (80.2864)  Acc@5: 100.0000 (97.3255)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2610/3125]  eta: 0:03:01  Lr: 0.001875  Loss: -0.6159  Acc@1: 87.5000 (80.2877)  Acc@5: 100.0000 (97.3334)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2620/3125]  eta: 0:02:58  Lr: 0.001875  Loss: -0.3956  Acc@1: 81.2500 (80.2890)  Acc@5: 100.0000 (97.3269)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2630/3125]  eta: 0:02:54  Lr: 0.001875  Loss: 0.0906  Acc@1: 81.2500 (80.2998)  Acc@5: 100.0000 (97.3323)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2640/3125]  eta: 0:02:50  Lr: 0.001875  Loss: -0.0536  Acc@1: 81.2500 (80.3058)  Acc@5: 100.0000 (97.3329)  time: 0.3543  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2650/3125]  eta: 0:02:47  Lr: 0.001875  Loss: -0.3865  Acc@1: 81.2500 (80.3117)  Acc@5: 100.0000 (97.3383)  time: 0.3530  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [2660/3125]  eta: 0:02:43  Lr: 0.001875  Loss: -0.6054  Acc@1: 81.2500 (80.3082)  Acc@5: 100.0000 (97.3459)  time: 0.3519  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2670/3125]  eta: 0:02:40  Lr: 0.001875  Loss: -0.6740  Acc@1: 81.2500 (80.3281)  Acc@5: 100.0000 (97.3512)  time: 0.3509  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2680/3125]  eta: 0:02:36  Lr: 0.001875  Loss: -0.5640  Acc@1: 81.2500 (80.3292)  Acc@5: 100.0000 (97.3541)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2690/3125]  eta: 0:02:33  Lr: 0.001875  Loss: -0.1965  Acc@1: 81.2500 (80.3442)  Acc@5: 100.0000 (97.3523)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2700/3125]  eta: 0:02:29  Lr: 0.001875  Loss: -0.4478  Acc@1: 81.2500 (80.3545)  Acc@5: 100.0000 (97.3621)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2710/3125]  eta: 0:02:26  Lr: 0.001875  Loss: -0.2503  Acc@1: 81.2500 (80.3716)  Acc@5: 100.0000 (97.3649)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2720/3125]  eta: 0:02:22  Lr: 0.001875  Loss: -0.5341  Acc@1: 87.5000 (80.4024)  Acc@5: 100.0000 (97.3677)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [2730/3125]  eta: 0:02:19  Lr: 0.001875  Loss: -0.7859  Acc@1: 87.5000 (80.4238)  Acc@5: 100.0000 (97.3750)  time: 0.3532  data: 0.0019  max mem: 2502
Train: Epoch[1/1]  [2740/3125]  eta: 0:02:15  Lr: 0.001875  Loss: -0.3619  Acc@1: 81.2500 (80.4291)  Acc@5: 100.0000 (97.3755)  time: 0.3526  data: 0.0012  max mem: 2502
Train: Epoch[1/1]  [2750/3125]  eta: 0:02:12  Lr: 0.001875  Loss: -0.1677  Acc@1: 81.2500 (80.4230)  Acc@5: 100.0000 (97.3760)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2760/3125]  eta: 0:02:08  Lr: 0.001875  Loss: -0.6081  Acc@1: 81.2500 (80.4351)  Acc@5: 100.0000 (97.3809)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2770/3125]  eta: 0:02:05  Lr: 0.001875  Loss: -0.4184  Acc@1: 87.5000 (80.4538)  Acc@5: 100.0000 (97.3836)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2780/3125]  eta: 0:02:01  Lr: 0.001875  Loss: -0.3644  Acc@1: 81.2500 (80.4544)  Acc@5: 100.0000 (97.3885)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2790/3125]  eta: 0:01:58  Lr: 0.001875  Loss: -0.3728  Acc@1: 81.2500 (80.4685)  Acc@5: 100.0000 (97.3934)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2800/3125]  eta: 0:01:54  Lr: 0.001875  Loss: -0.8189  Acc@1: 81.2500 (80.4713)  Acc@5: 100.0000 (97.3916)  time: 0.3509  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [2810/3125]  eta: 0:01:51  Lr: 0.001875  Loss: 0.1896  Acc@1: 81.2500 (80.4807)  Acc@5: 100.0000 (97.3919)  time: 0.3516  data: 0.0017  max mem: 2502
Train: Epoch[1/1]  [2820/3125]  eta: 0:01:47  Lr: 0.001875  Loss: -0.7766  Acc@1: 87.5000 (80.4989)  Acc@5: 100.0000 (97.3945)  time: 0.3514  data: 0.0012  max mem: 2502
Train: Epoch[1/1]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: 0.0302  Acc@1: 81.2500 (80.4972)  Acc@5: 100.0000 (97.3927)  time: 0.3523  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2840/3125]  eta: 0:01:40  Lr: 0.001875  Loss: -0.3770  Acc@1: 87.5000 (80.5328)  Acc@5: 100.0000 (97.3975)  time: 0.3517  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.3518  Acc@1: 87.5000 (80.5266)  Acc@5: 100.0000 (97.3957)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2860/3125]  eta: 0:01:33  Lr: 0.001875  Loss: -0.5186  Acc@1: 81.2500 (80.5335)  Acc@5: 100.0000 (97.3938)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: 0.0220  Acc@1: 81.2500 (80.5164)  Acc@5: 100.0000 (97.3964)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [2880/3125]  eta: 0:01:26  Lr: 0.001875  Loss: -0.4262  Acc@1: 81.2500 (80.5233)  Acc@5: 100.0000 (97.4032)  time: 0.3526  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.0468  Acc@1: 81.2500 (80.5236)  Acc@5: 100.0000 (97.3993)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [2900/3125]  eta: 0:01:19  Lr: 0.001875  Loss: -0.5093  Acc@1: 81.2500 (80.5304)  Acc@5: 100.0000 (97.4018)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.6564  Acc@1: 81.2500 (80.5393)  Acc@5: 100.0000 (97.4021)  time: 0.3524  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2920/3125]  eta: 0:01:12  Lr: 0.001875  Loss: -0.6558  Acc@1: 81.2500 (80.5503)  Acc@5: 100.0000 (97.4046)  time: 0.3539  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.8636  Acc@1: 87.5000 (80.5762)  Acc@5: 100.0000 (97.4092)  time: 0.3533  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2940/3125]  eta: 0:01:05  Lr: 0.001875  Loss: -0.4116  Acc@1: 87.5000 (80.5976)  Acc@5: 100.0000 (97.4116)  time: 0.3535  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.5873  Acc@1: 87.5000 (80.6210)  Acc@5: 100.0000 (97.4140)  time: 0.3520  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2960/3125]  eta: 0:00:58  Lr: 0.001875  Loss: -0.7331  Acc@1: 87.5000 (80.6527)  Acc@5: 100.0000 (97.4206)  time: 0.3508  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8226  Acc@1: 87.5000 (80.6547)  Acc@5: 100.0000 (97.4230)  time: 0.3507  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [2980/3125]  eta: 0:00:51  Lr: 0.001875  Loss: -0.2342  Acc@1: 81.2500 (80.6692)  Acc@5: 100.0000 (97.4191)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.3096  Acc@1: 81.2500 (80.6733)  Acc@5: 93.7500 (97.4173)  time: 0.3520  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.4214  Acc@1: 87.5000 (80.6981)  Acc@5: 100.0000 (97.4196)  time: 0.3520  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7533  Acc@1: 87.5000 (80.7290)  Acc@5: 100.0000 (97.4282)  time: 0.3530  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8517  Acc@1: 87.5000 (80.7597)  Acc@5: 100.0000 (97.4305)  time: 0.3534  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.4707  Acc@1: 81.2500 (80.7654)  Acc@5: 100.0000 (97.4287)  time: 0.3533  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.4853  Acc@1: 81.2500 (80.7855)  Acc@5: 100.0000 (97.4309)  time: 0.3541  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5087  Acc@1: 81.2500 (80.7829)  Acc@5: 100.0000 (97.4312)  time: 0.3534  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.5030  Acc@1: 81.2500 (80.7885)  Acc@5: 100.0000 (97.4314)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.6972  Acc@1: 87.5000 (80.8124)  Acc@5: 100.0000 (97.4398)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.4483  Acc@1: 87.5000 (80.8159)  Acc@5: 100.0000 (97.4420)  time: 0.3523  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.8000  Acc@1: 81.2500 (80.8416)  Acc@5: 100.0000 (97.4462)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5486  Acc@1: 81.2500 (80.8308)  Acc@5: 100.0000 (97.4504)  time: 0.3528  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4468  Acc@1: 81.2500 (80.8522)  Acc@5: 100.0000 (97.4526)  time: 0.3528  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5040  Acc@1: 87.5000 (80.8715)  Acc@5: 100.0000 (97.4607)  time: 0.3534  data: 0.0012  max mem: 2502
Train: Epoch[1/1]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6590  Acc@1: 81.2500 (80.8760)  Acc@5: 100.0000 (97.4580)  time: 0.3540  data: 0.0012  max mem: 2502
Train: Epoch[1/1] Total time: 0:18:22 (0.3526 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6590  Acc@1: 81.2500 (80.8760)  Acc@5: 100.0000 (97.4580)
Test: [Task 1]  [   0/1627]  eta: 0:16:29  Loss: 1.4744 (1.4744)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6083  data: 0.3879  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:51  Loss: 1.5110 (1.4241)  Acc@1: 68.7500 (68.1818)  Acc@5: 93.7500 (90.9091)  time: 0.2548  data: 0.0355  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:21  Loss: 1.4186 (1.4056)  Acc@1: 68.7500 (70.2381)  Acc@5: 93.7500 (91.9643)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:10  Loss: 1.3575 (1.4331)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (91.7339)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:06:03  Loss: 1.6051 (1.4638)  Acc@1: 56.2500 (66.9207)  Acc@5: 93.7500 (91.3110)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:58  Loss: 1.4585 (1.4368)  Acc@1: 62.5000 (67.4020)  Acc@5: 93.7500 (92.2794)  time: 0.2199  data: 0.0003  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:54  Loss: 1.4585 (1.4653)  Acc@1: 68.7500 (66.1885)  Acc@5: 93.7500 (91.7008)  time: 0.2200  data: 0.0003  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:50  Loss: 1.4576 (1.4579)  Acc@1: 62.5000 (66.4613)  Acc@5: 87.5000 (91.9014)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:46  Loss: 1.3525 (1.4478)  Acc@1: 68.7500 (66.7438)  Acc@5: 93.7500 (92.2068)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:43  Loss: 1.3742 (1.4476)  Acc@1: 68.7500 (66.8269)  Acc@5: 93.7500 (92.1703)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:40  Loss: 1.6096 (1.4719)  Acc@1: 68.7500 (66.5223)  Acc@5: 87.5000 (91.3366)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:38  Loss: 1.5685 (1.4732)  Acc@1: 62.5000 (66.3288)  Acc@5: 87.5000 (91.7230)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:35  Loss: 1.4523 (1.4740)  Acc@1: 62.5000 (65.9607)  Acc@5: 93.7500 (91.6322)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:33  Loss: 1.4344 (1.4695)  Acc@1: 62.5000 (65.9828)  Acc@5: 93.7500 (91.4599)  time: 0.2234  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:31  Loss: 1.3514 (1.4682)  Acc@1: 62.5000 (65.9574)  Acc@5: 93.7500 (91.4894)  time: 0.2230  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:28  Loss: 1.2759 (1.4564)  Acc@1: 68.7500 (66.3907)  Acc@5: 93.7500 (91.5563)  time: 0.2186  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:25  Loss: 1.3359 (1.4503)  Acc@1: 68.7500 (66.6925)  Acc@5: 93.7500 (91.7702)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:23  Loss: 1.3619 (1.4430)  Acc@1: 68.7500 (66.7032)  Acc@5: 93.7500 (91.9591)  time: 0.2180  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:20  Loss: 1.4164 (1.4544)  Acc@1: 62.5000 (66.1602)  Acc@5: 93.7500 (91.7127)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:18  Loss: 1.5285 (1.4489)  Acc@1: 62.5000 (66.3285)  Acc@5: 87.5000 (91.7212)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:15  Loss: 1.5285 (1.4514)  Acc@1: 62.5000 (66.2935)  Acc@5: 93.7500 (91.6978)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:13  Loss: 1.4479 (1.4480)  Acc@1: 68.7500 (66.4396)  Acc@5: 93.7500 (91.7950)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:11  Loss: 1.4479 (1.4539)  Acc@1: 68.7500 (66.4027)  Acc@5: 93.7500 (91.8269)  time: 0.2192  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:08  Loss: 1.4777 (1.4480)  Acc@1: 68.7500 (66.5855)  Acc@5: 93.7500 (91.9102)  time: 0.2192  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:06  Loss: 1.3136 (1.4407)  Acc@1: 75.0000 (66.8568)  Acc@5: 93.7500 (91.9606)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:05:04  Loss: 1.4417 (1.4460)  Acc@1: 62.5000 (66.6584)  Acc@5: 93.7500 (91.8327)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:05:01  Loss: 1.4353 (1.4442)  Acc@1: 62.5000 (66.8343)  Acc@5: 93.7500 (91.8343)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:59  Loss: 1.3924 (1.4373)  Acc@1: 68.7500 (67.0203)  Acc@5: 93.7500 (91.8589)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:57  Loss: 1.3290 (1.4367)  Acc@1: 68.7500 (66.9929)  Acc@5: 93.7500 (91.8372)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:54  Loss: 1.3290 (1.4340)  Acc@1: 68.7500 (66.9244)  Acc@5: 93.7500 (91.8385)  time: 0.2182  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:52  Loss: 1.3603 (1.4327)  Acc@1: 68.7500 (67.0058)  Acc@5: 93.7500 (91.8397)  time: 0.2180  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:50  Loss: 1.3603 (1.4356)  Acc@1: 68.7500 (67.0016)  Acc@5: 93.7500 (91.6801)  time: 0.2177  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:47  Loss: 1.5188 (1.4368)  Acc@1: 62.5000 (66.9393)  Acc@5: 87.5000 (91.7056)  time: 0.2174  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:45  Loss: 1.4645 (1.4360)  Acc@1: 62.5000 (66.9940)  Acc@5: 93.7500 (91.6730)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:43  Loss: 1.3522 (1.4352)  Acc@1: 68.7500 (67.0638)  Acc@5: 93.7500 (91.6606)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:41  Loss: 1.4290 (1.4349)  Acc@1: 68.7500 (67.0762)  Acc@5: 93.7500 (91.6132)  time: 0.2197  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:38  Loss: 1.3661 (1.4349)  Acc@1: 68.7500 (67.1226)  Acc@5: 93.7500 (91.5686)  time: 0.2177  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:36  Loss: 1.2913 (1.4340)  Acc@1: 68.7500 (67.1664)  Acc@5: 93.7500 (91.5431)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:34  Loss: 1.3443 (1.4324)  Acc@1: 68.7500 (67.2244)  Acc@5: 87.5000 (91.5354)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:31  Loss: 1.4486 (1.4344)  Acc@1: 68.7500 (67.2155)  Acc@5: 93.7500 (91.4642)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:29  Loss: 1.4214 (1.4353)  Acc@1: 68.7500 (67.2382)  Acc@5: 93.7500 (91.4277)  time: 0.2171  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:27  Loss: 1.3548 (1.4347)  Acc@1: 68.7500 (67.2597)  Acc@5: 87.5000 (91.3625)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:25  Loss: 1.2770 (1.4319)  Acc@1: 68.7500 (67.3990)  Acc@5: 93.7500 (91.4192)  time: 0.2184  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:22  Loss: 1.2515 (1.4299)  Acc@1: 75.0000 (67.4884)  Acc@5: 93.7500 (91.4298)  time: 0.2178  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:20  Loss: 1.4510 (1.4301)  Acc@1: 68.7500 (67.5312)  Acc@5: 93.7500 (91.4257)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:18  Loss: 1.5876 (1.4342)  Acc@1: 62.5000 (67.4335)  Acc@5: 93.7500 (91.4080)  time: 0.2166  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:16  Loss: 1.5011 (1.4334)  Acc@1: 62.5000 (67.4485)  Acc@5: 93.7500 (91.4317)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:13  Loss: 1.2521 (1.4301)  Acc@1: 75.0000 (67.5425)  Acc@5: 93.7500 (91.4809)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:11  Loss: 1.4544 (1.4351)  Acc@1: 68.7500 (67.4636)  Acc@5: 93.7500 (91.4241)  time: 0.2191  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:09  Loss: 1.4544 (1.4363)  Acc@1: 68.7500 (67.3498)  Acc@5: 93.7500 (91.3824)  time: 0.2172  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:07  Loss: 1.4386 (1.4391)  Acc@1: 68.7500 (67.3403)  Acc@5: 87.5000 (91.3174)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:04  Loss: 1.5010 (1.4426)  Acc@1: 62.5000 (67.2578)  Acc@5: 87.5000 (91.2427)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:04:02  Loss: 1.5071 (1.4477)  Acc@1: 62.5000 (67.1425)  Acc@5: 87.5000 (91.2188)  time: 0.2180  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:04:00  Loss: 1.3510 (1.4429)  Acc@1: 68.7500 (67.3140)  Acc@5: 93.7500 (91.2429)  time: 0.2191  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:58  Loss: 1.3330 (1.4427)  Acc@1: 68.7500 (67.3059)  Acc@5: 93.7500 (91.2200)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:56  Loss: 1.5470 (1.4457)  Acc@1: 68.7500 (67.2641)  Acc@5: 87.5000 (91.1525)  time: 0.2186  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:53  Loss: 1.5698 (1.4481)  Acc@1: 62.5000 (67.2348)  Acc@5: 87.5000 (91.1653)  time: 0.2186  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:51  Loss: 1.3480 (1.4463)  Acc@1: 68.7500 (67.2285)  Acc@5: 93.7500 (91.1996)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:49  Loss: 1.3818 (1.4482)  Acc@1: 68.7500 (67.1687)  Acc@5: 93.7500 (91.2113)  time: 0.2195  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:47  Loss: 1.4168 (1.4472)  Acc@1: 68.7500 (67.1531)  Acc@5: 93.7500 (91.2860)  time: 0.2199  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:45  Loss: 1.3828 (1.4499)  Acc@1: 62.5000 (67.0341)  Acc@5: 93.7500 (91.2854)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:43  Loss: 1.3527 (1.4480)  Acc@1: 62.5000 (67.1236)  Acc@5: 93.7500 (91.3052)  time: 0.2197  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:40  Loss: 1.3583 (1.4490)  Acc@1: 68.7500 (67.1498)  Acc@5: 87.5000 (91.2440)  time: 0.2194  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:38  Loss: 1.3586 (1.4475)  Acc@1: 68.7500 (67.2147)  Acc@5: 93.7500 (91.2738)  time: 0.2185  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 1.1721 (1.4462)  Acc@1: 68.7500 (67.2387)  Acc@5: 93.7500 (91.2734)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:34  Loss: 1.3702 (1.4461)  Acc@1: 68.7500 (67.2235)  Acc@5: 93.7500 (91.2538)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:32  Loss: 1.3057 (1.4438)  Acc@1: 68.7500 (67.3222)  Acc@5: 93.7500 (91.2821)  time: 0.2207  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:29  Loss: 1.4042 (1.4448)  Acc@1: 68.7500 (67.2597)  Acc@5: 93.7500 (91.2444)  time: 0.2204  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:27  Loss: 1.4174 (1.4426)  Acc@1: 68.7500 (67.3183)  Acc@5: 87.5000 (91.2445)  time: 0.2199  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 1.3721 (1.4412)  Acc@1: 68.7500 (67.4023)  Acc@5: 93.7500 (91.3079)  time: 0.2204  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:23  Loss: 1.4748 (1.4414)  Acc@1: 68.7500 (67.4215)  Acc@5: 93.7500 (91.3338)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:21  Loss: 1.4592 (1.4392)  Acc@1: 68.7500 (67.4842)  Acc@5: 93.7500 (91.3414)  time: 0.2204  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:18  Loss: 1.2277 (1.4370)  Acc@1: 68.7500 (67.5537)  Acc@5: 93.7500 (91.3922)  time: 0.2204  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:16  Loss: 1.3618 (1.4388)  Acc@1: 68.7500 (67.5103)  Acc@5: 93.7500 (91.3902)  time: 0.2192  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 1.5153 (1.4392)  Acc@1: 68.7500 (67.5439)  Acc@5: 87.5000 (91.3209)  time: 0.2194  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:12  Loss: 1.4152 (1.4381)  Acc@1: 68.7500 (67.6015)  Acc@5: 93.7500 (91.3615)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:10  Loss: 1.4239 (1.4414)  Acc@1: 68.7500 (67.5263)  Acc@5: 93.7500 (91.2533)  time: 0.2209  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:08  Loss: 1.3696 (1.4388)  Acc@1: 68.7500 (67.5908)  Acc@5: 93.7500 (91.3019)  time: 0.2203  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:05  Loss: 1.2121 (1.4379)  Acc@1: 68.7500 (67.5976)  Acc@5: 93.7500 (91.3092)  time: 0.2220  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 1.3653 (1.4394)  Acc@1: 68.7500 (67.5727)  Acc@5: 87.5000 (91.2374)  time: 0.2218  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:03:01  Loss: 1.4694 (1.4399)  Acc@1: 68.7500 (67.5718)  Acc@5: 87.5000 (91.2531)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:59  Loss: 1.4110 (1.4391)  Acc@1: 68.7500 (67.6248)  Acc@5: 93.7500 (91.2839)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:57  Loss: 1.2060 (1.4387)  Acc@1: 75.0000 (67.6309)  Acc@5: 93.7500 (91.2835)  time: 0.2204  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:54  Loss: 1.2060 (1.4380)  Acc@1: 68.7500 (67.6068)  Acc@5: 93.7500 (91.3057)  time: 0.2202  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 1.1802 (1.4361)  Acc@1: 68.7500 (67.6427)  Acc@5: 93.7500 (91.3273)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:50  Loss: 1.4847 (1.4371)  Acc@1: 68.7500 (67.6337)  Acc@5: 93.7500 (91.3190)  time: 0.2197  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 1.3911 (1.4369)  Acc@1: 68.7500 (67.6757)  Acc@5: 93.7500 (91.3255)  time: 0.2203  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:46  Loss: 1.3781 (1.4348)  Acc@1: 68.7500 (67.7454)  Acc@5: 93.7500 (91.3318)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:43  Loss: 1.5199 (1.4379)  Acc@1: 68.7500 (67.6717)  Acc@5: 93.7500 (91.3238)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 1.6709 (1.4400)  Acc@1: 56.2500 (67.6207)  Acc@5: 93.7500 (91.3230)  time: 0.2200  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 1.5641 (1.4406)  Acc@1: 62.5000 (67.6193)  Acc@5: 93.7500 (91.3221)  time: 0.2199  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 1.4573 (1.4407)  Acc@1: 62.5000 (67.6249)  Acc@5: 93.7500 (91.3351)  time: 0.2195  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 1.3264 (1.4393)  Acc@1: 68.7500 (67.6642)  Acc@5: 93.7500 (91.3681)  time: 0.2192  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:32  Loss: 1.3629 (1.4387)  Acc@1: 68.7500 (67.6557)  Acc@5: 93.7500 (91.3198)  time: 0.2200  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 1.4041 (1.4371)  Acc@1: 68.7500 (67.6674)  Acc@5: 93.7500 (91.3855)  time: 0.2199  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 1.4132 (1.4379)  Acc@1: 68.7500 (67.6393)  Acc@5: 93.7500 (91.3841)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 1.4006 (1.4373)  Acc@1: 68.7500 (67.6314)  Acc@5: 93.7500 (91.3892)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 1.2550 (1.4363)  Acc@1: 68.7500 (67.6815)  Acc@5: 93.7500 (91.3684)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:21  Loss: 1.3897 (1.4362)  Acc@1: 68.7500 (67.6542)  Acc@5: 87.5000 (91.3354)  time: 0.2194  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 1.5848 (1.4391)  Acc@1: 62.5000 (67.5832)  Acc@5: 87.5000 (91.2904)  time: 0.2198  data: 0.0007  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 1.5482 (1.4395)  Acc@1: 62.5000 (67.5949)  Acc@5: 87.5000 (91.2900)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 1.4242 (1.4396)  Acc@1: 68.7500 (67.6249)  Acc@5: 87.5000 (91.2587)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 1.4242 (1.4396)  Acc@1: 68.7500 (67.6481)  Acc@5: 87.5000 (91.2647)  time: 0.2180  data: 0.0003  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:10  Loss: 1.2568 (1.4383)  Acc@1: 68.7500 (67.6770)  Acc@5: 93.7500 (91.2767)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 1.2241 (1.4375)  Acc@1: 68.7500 (67.6873)  Acc@5: 93.7500 (91.2644)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 1.3162 (1.4364)  Acc@1: 68.7500 (67.7034)  Acc@5: 93.7500 (91.2643)  time: 0.2180  data: 0.0004  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 1.4555 (1.4367)  Acc@1: 68.7500 (67.6484)  Acc@5: 93.7500 (91.2818)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 1.4396 (1.4372)  Acc@1: 62.5000 (67.6937)  Acc@5: 93.7500 (91.2815)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:59  Loss: 1.4052 (1.4377)  Acc@1: 68.7500 (67.6862)  Acc@5: 87.5000 (91.2465)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 1.3648 (1.4377)  Acc@1: 62.5000 (67.6615)  Acc@5: 87.5000 (91.2466)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 1.3251 (1.4359)  Acc@1: 62.5000 (67.7055)  Acc@5: 93.7500 (91.2807)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 1.3864 (1.4366)  Acc@1: 62.5000 (67.6699)  Acc@5: 93.7500 (91.2860)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 1.4478 (1.4373)  Acc@1: 62.5000 (67.6517)  Acc@5: 93.7500 (91.3024)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 1.5756 (1.4390)  Acc@1: 62.5000 (67.5785)  Acc@5: 93.7500 (91.2854)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 1.5687 (1.4401)  Acc@1: 62.5000 (67.5997)  Acc@5: 87.5000 (91.2631)  time: 0.2197  data: 0.0007  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 1.5687 (1.4413)  Acc@1: 68.7500 (67.5500)  Acc@5: 87.5000 (91.2359)  time: 0.2200  data: 0.0007  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 1.3602 (1.4400)  Acc@1: 68.7500 (67.5926)  Acc@5: 93.7500 (91.2468)  time: 0.2188  data: 0.0005  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 1.3420 (1.4393)  Acc@1: 75.0000 (67.6292)  Acc@5: 93.7500 (91.2521)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 1.4919 (1.4402)  Acc@1: 68.7500 (67.5857)  Acc@5: 93.7500 (91.2627)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 1.5313 (1.4413)  Acc@1: 62.5000 (67.5640)  Acc@5: 93.7500 (91.2364)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 1.4232 (1.4411)  Acc@1: 68.7500 (67.5635)  Acc@5: 87.5000 (91.2209)  time: 0.2199  data: 0.0013  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 1.3821 (1.4424)  Acc@1: 62.5000 (67.5010)  Acc@5: 93.7500 (91.2005)  time: 0.2202  data: 0.0012  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 1.4557 (1.4421)  Acc@1: 62.5000 (67.4805)  Acc@5: 93.7500 (91.2213)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 1.4697 (1.4432)  Acc@1: 62.5000 (67.4553)  Acc@5: 93.7500 (91.1860)  time: 0.2213  data: 0.0005  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 1.3652 (1.4421)  Acc@1: 68.7500 (67.5010)  Acc@5: 87.5000 (91.1966)  time: 0.2211  data: 0.0006  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 1.4335 (1.4425)  Acc@1: 68.7500 (67.4910)  Acc@5: 87.5000 (91.1871)  time: 0.2185  data: 0.0004  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 1.4335 (1.4423)  Acc@1: 68.7500 (67.5159)  Acc@5: 93.7500 (91.1975)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 1.3723 (1.4425)  Acc@1: 68.7500 (67.5305)  Acc@5: 93.7500 (91.1880)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 1.3089 (1.4405)  Acc@1: 68.7500 (67.5498)  Acc@5: 93.7500 (91.2129)  time: 0.2198  data: 0.0009  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 1.3150 (1.4410)  Acc@1: 68.7500 (67.5058)  Acc@5: 93.7500 (91.2084)  time: 0.2195  data: 0.0009  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 1.4437 (1.4405)  Acc@1: 62.5000 (67.5202)  Acc@5: 93.7500 (91.2327)  time: 0.2190  data: 0.0007  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 1.2684 (1.4391)  Acc@1: 75.0000 (67.5820)  Acc@5: 93.7500 (91.2662)  time: 0.2193  data: 0.0006  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 1.1590 (1.4377)  Acc@1: 75.0000 (67.6429)  Acc@5: 100.0000 (91.2945)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 1.2288 (1.4377)  Acc@1: 68.7500 (67.6512)  Acc@5: 93.7500 (91.2847)  time: 0.2203  data: 0.0005  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.4308 (1.4379)  Acc@1: 62.5000 (67.6268)  Acc@5: 93.7500 (91.2985)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 1.4068 (1.4375)  Acc@1: 62.5000 (67.6305)  Acc@5: 93.7500 (91.3166)  time: 0.2197  data: 0.0003  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 1.2946 (1.4369)  Acc@1: 68.7500 (67.6249)  Acc@5: 93.7500 (91.3253)  time: 0.2199  data: 0.0003  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 1.2946 (1.4369)  Acc@1: 68.7500 (67.6240)  Acc@5: 93.7500 (91.3156)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 1.3581 (1.4371)  Acc@1: 68.7500 (67.6231)  Acc@5: 87.5000 (91.3197)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.4271 (1.4363)  Acc@1: 68.7500 (67.6627)  Acc@5: 93.7500 (91.3417)  time: 0.2202  data: 0.0003  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.2621 (1.4366)  Acc@1: 75.0000 (67.6704)  Acc@5: 93.7500 (91.3276)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 1.2574 (1.4360)  Acc@1: 68.7500 (67.7002)  Acc@5: 93.7500 (91.3536)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.3361 (1.4358)  Acc@1: 68.7500 (67.7032)  Acc@5: 93.7500 (91.3573)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.5837 (1.4374)  Acc@1: 62.5000 (67.6756)  Acc@5: 87.5000 (91.3216)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 1.5154 (1.4372)  Acc@1: 62.5000 (67.6830)  Acc@5: 87.5000 (91.3081)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.4391 (1.4381)  Acc@1: 68.7500 (67.6473)  Acc@5: 87.5000 (91.2776)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.5316 (1.4386)  Acc@1: 68.7500 (67.6420)  Acc@5: 87.5000 (91.2774)  time: 0.2216  data: 0.0004  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.3832 (1.4390)  Acc@1: 68.7500 (67.6156)  Acc@5: 93.7500 (91.2772)  time: 0.2213  data: 0.0004  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 1.4122 (1.4398)  Acc@1: 56.2500 (67.5937)  Acc@5: 93.7500 (91.2601)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 1.5009 (1.4399)  Acc@1: 68.7500 (67.6140)  Acc@5: 87.5000 (91.2517)  time: 0.2196  data: 0.0005  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.4279 (1.4401)  Acc@1: 68.7500 (67.6257)  Acc@5: 93.7500 (91.2600)  time: 0.2205  data: 0.0005  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.1730 (1.4400)  Acc@1: 68.7500 (67.5960)  Acc@5: 93.7500 (91.2599)  time: 0.2204  data: 0.0004  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.1730 (1.4390)  Acc@1: 75.0000 (67.6364)  Acc@5: 93.7500 (91.2763)  time: 0.2202  data: 0.0003  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.1754 (1.4384)  Acc@1: 75.0000 (67.6600)  Acc@5: 100.0000 (91.2925)  time: 0.2209  data: 0.0004  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 1.2100 (1.4374)  Acc@1: 68.7500 (67.6509)  Acc@5: 93.7500 (91.3125)  time: 0.2218  data: 0.0004  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 1.2230 (1.4374)  Acc@1: 68.7500 (67.6378)  Acc@5: 93.7500 (91.3322)  time: 0.2209  data: 0.0004  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 1.2230 (1.4361)  Acc@1: 75.0000 (67.6770)  Acc@5: 93.7500 (91.3477)  time: 0.2200  data: 0.0003  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.2195 (1.4361)  Acc@1: 68.7500 (67.6878)  Acc@5: 93.7500 (91.3511)  time: 0.2207  data: 0.0010  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.3635 (1.4355)  Acc@1: 68.7500 (67.7143)  Acc@5: 93.7500 (91.3702)  time: 0.2205  data: 0.0010  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.4076 (1.4359)  Acc@1: 68.7500 (67.6893)  Acc@5: 93.7500 (91.3694)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.4526 (1.4371)  Acc@1: 62.5000 (67.6530)  Acc@5: 87.5000 (91.3413)  time: 0.2204  data: 0.0004  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.4149 (1.4362)  Acc@1: 68.7500 (67.6831)  Acc@5: 93.7500 (91.3485)  time: 0.2220  data: 0.0005  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.3029 (1.4357)  Acc@1: 68.7500 (67.6743)  Acc@5: 93.7500 (91.3634)  time: 0.2211  data: 0.0004  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.2348 (1.4349)  Acc@1: 68.7500 (67.7128)  Acc@5: 93.7500 (91.3722)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 1] Total time: 0:05:57 (0.2197 s / it)
* Acc@1 67.713 Acc@5 91.372 loss 1.435
Test: [Task 2]  [  0/625]  eta: 0:06:14  Loss: 0.3451 (0.3451)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5986  data: 0.3772  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:35  Loss: 0.4611 (0.4857)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (97.7273)  time: 0.2530  data: 0.0346  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:23  Loss: 0.4246 (0.4845)  Acc@1: 87.5000 (90.7738)  Acc@5: 100.0000 (98.5119)  time: 0.2195  data: 0.0010  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:17  Loss: 0.4830 (0.5067)  Acc@1: 87.5000 (90.5242)  Acc@5: 100.0000 (98.3871)  time: 0.2200  data: 0.0011  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:13  Loss: 0.4830 (0.5055)  Acc@1: 93.7500 (90.7012)  Acc@5: 100.0000 (98.4756)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:10  Loss: 0.5409 (0.5337)  Acc@1: 87.5000 (89.3382)  Acc@5: 100.0000 (98.4069)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:07  Loss: 0.5847 (0.5344)  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (98.5656)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:04  Loss: 0.5123 (0.5285)  Acc@1: 93.7500 (89.6127)  Acc@5: 100.0000 (98.5915)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:01  Loss: 0.5143 (0.5371)  Acc@1: 87.5000 (89.4290)  Acc@5: 100.0000 (98.3796)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 0.5380 (0.5384)  Acc@1: 87.5000 (89.4231)  Acc@5: 100.0000 (98.4203)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:56  Loss: 0.5332 (0.5386)  Acc@1: 87.5000 (89.5421)  Acc@5: 100.0000 (98.3911)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 0.5144 (0.5361)  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (98.3108)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:52  Loss: 0.5144 (0.5364)  Acc@1: 87.5000 (89.5661)  Acc@5: 100.0000 (98.2438)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 0.5138 (0.5383)  Acc@1: 87.5000 (89.5038)  Acc@5: 100.0000 (98.3302)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 0.4928 (0.5399)  Acc@1: 87.5000 (89.4947)  Acc@5: 100.0000 (98.3156)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 0.5598 (0.5457)  Acc@1: 87.5000 (89.2384)  Acc@5: 100.0000 (98.1788)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 0.5629 (0.5493)  Acc@1: 87.5000 (89.0528)  Acc@5: 100.0000 (98.1366)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 0.5495 (0.5523)  Acc@1: 87.5000 (88.8523)  Acc@5: 100.0000 (98.1725)  time: 0.2177  data: 0.0003  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 0.5495 (0.5530)  Acc@1: 87.5000 (88.8467)  Acc@5: 100.0000 (98.2390)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:35  Loss: 0.5136 (0.5553)  Acc@1: 87.5000 (88.7762)  Acc@5: 100.0000 (98.2003)  time: 0.2183  data: 0.0005  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 0.5020 (0.5537)  Acc@1: 87.5000 (88.7749)  Acc@5: 100.0000 (98.2587)  time: 0.2183  data: 0.0005  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 0.5275 (0.5564)  Acc@1: 87.5000 (88.6256)  Acc@5: 100.0000 (98.2524)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 0.5275 (0.5517)  Acc@1: 93.7500 (88.9140)  Acc@5: 100.0000 (98.2749)  time: 0.2167  data: 0.0003  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 0.4447 (0.5509)  Acc@1: 93.7500 (89.0152)  Acc@5: 100.0000 (98.2955)  time: 0.2170  data: 0.0003  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 0.5715 (0.5533)  Acc@1: 87.5000 (88.8226)  Acc@5: 100.0000 (98.3143)  time: 0.2179  data: 0.0007  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 0.6035 (0.5547)  Acc@1: 87.5000 (88.8695)  Acc@5: 100.0000 (98.2819)  time: 0.2180  data: 0.0007  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 0.5710 (0.5555)  Acc@1: 87.5000 (88.8170)  Acc@5: 100.0000 (98.2280)  time: 0.2189  data: 0.0007  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 0.5517 (0.5552)  Acc@1: 87.5000 (88.8146)  Acc@5: 100.0000 (98.1780)  time: 0.2197  data: 0.0007  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.5552 (0.5559)  Acc@1: 87.5000 (88.7678)  Acc@5: 100.0000 (98.1317)  time: 0.2193  data: 0.0006  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 0.5641 (0.5566)  Acc@1: 87.5000 (88.7457)  Acc@5: 100.0000 (98.1100)  time: 0.2193  data: 0.0006  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 0.5641 (0.5574)  Acc@1: 87.5000 (88.6420)  Acc@5: 100.0000 (98.1105)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 0.5724 (0.5596)  Acc@1: 87.5000 (88.6254)  Acc@5: 100.0000 (98.0908)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 0.3331 (0.5495)  Acc@1: 93.7500 (88.9213)  Acc@5: 100.0000 (98.1308)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.2566 (0.5445)  Acc@1: 100.0000 (89.1427)  Acc@5: 100.0000 (98.1684)  time: 0.2194  data: 0.0008  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.2566 (0.5349)  Acc@1: 100.0000 (89.4062)  Acc@5: 100.0000 (98.2038)  time: 0.2197  data: 0.0008  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.2468 (0.5297)  Acc@1: 100.0000 (89.5299)  Acc@5: 100.0000 (98.2372)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 0.4752 (0.5319)  Acc@1: 87.5000 (89.4391)  Acc@5: 100.0000 (98.2341)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 0.4752 (0.5280)  Acc@1: 87.5000 (89.4879)  Acc@5: 100.0000 (98.2817)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.4723 (0.5331)  Acc@1: 87.5000 (89.3701)  Acc@5: 100.0000 (98.2119)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.5231 (0.5315)  Acc@1: 87.5000 (89.3862)  Acc@5: 100.0000 (98.1777)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.2860 (0.5253)  Acc@1: 93.7500 (89.5574)  Acc@5: 100.0000 (98.2076)  time: 0.2191  data: 0.0007  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 0.2374 (0.5228)  Acc@1: 93.7500 (89.6137)  Acc@5: 100.0000 (98.2208)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 0.3559 (0.5210)  Acc@1: 93.7500 (89.7268)  Acc@5: 100.0000 (98.2631)  time: 0.2198  data: 0.0003  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.3640 (0.5180)  Acc@1: 93.7500 (89.8492)  Acc@5: 100.0000 (98.2744)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.2428 (0.5118)  Acc@1: 100.0000 (90.0227)  Acc@5: 100.0000 (98.3135)  time: 0.2198  data: 0.0013  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.2097 (0.5058)  Acc@1: 100.0000 (90.1192)  Acc@5: 100.0000 (98.3509)  time: 0.2201  data: 0.0013  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 0.2211 (0.5012)  Acc@1: 93.7500 (90.1844)  Acc@5: 100.0000 (98.3867)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 0.3601 (0.4999)  Acc@1: 93.7500 (90.2601)  Acc@5: 100.0000 (98.4076)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.3977 (0.4982)  Acc@1: 93.7500 (90.2937)  Acc@5: 100.0000 (98.4407)  time: 0.2197  data: 0.0005  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.3235 (0.4963)  Acc@1: 93.7500 (90.3895)  Acc@5: 100.0000 (98.4470)  time: 0.2198  data: 0.0005  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.3981 (0.4951)  Acc@1: 93.7500 (90.4067)  Acc@5: 100.0000 (98.4780)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.4062 (0.4959)  Acc@1: 93.7500 (90.3253)  Acc@5: 100.0000 (98.4834)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 0.3953 (0.4966)  Acc@1: 93.7500 (90.3791)  Acc@5: 100.0000 (98.5005)  time: 0.2198  data: 0.0003  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.3579 (0.4940)  Acc@1: 93.7500 (90.4779)  Acc@5: 100.0000 (98.5169)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.3491 (0.4923)  Acc@1: 93.7500 (90.5499)  Acc@5: 100.0000 (98.5444)  time: 0.2206  data: 0.0007  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.2740 (0.4869)  Acc@1: 93.7500 (90.6874)  Acc@5: 100.0000 (98.5594)  time: 0.2210  data: 0.0007  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.1710 (0.4816)  Acc@1: 100.0000 (90.7977)  Acc@5: 100.0000 (98.5851)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 0.2166 (0.4811)  Acc@1: 100.0000 (90.8384)  Acc@5: 100.0000 (98.6099)  time: 0.2198  data: 0.0008  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.2481 (0.4767)  Acc@1: 100.0000 (90.9639)  Acc@5: 100.0000 (98.6338)  time: 0.2202  data: 0.0008  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.2694 (0.4744)  Acc@1: 93.7500 (91.0110)  Acc@5: 100.0000 (98.6358)  time: 0.2202  data: 0.0014  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.3893 (0.4748)  Acc@1: 93.7500 (91.0254)  Acc@5: 100.0000 (98.6585)  time: 0.2194  data: 0.0014  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.5579 (0.4792)  Acc@1: 87.5000 (90.9165)  Acc@5: 100.0000 (98.6088)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.5571 (0.4796)  Acc@1: 87.5000 (90.8414)  Acc@5: 100.0000 (98.6312)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.4789 (0.4791)  Acc@1: 87.5000 (90.8500)  Acc@5: 100.0000 (98.6400)  time: 0.2204  data: 0.0003  max mem: 2502
Test: [Task 2] Total time: 0:02:17 (0.2200 s / it)
* Acc@1 90.850 Acc@5 98.640 loss 0.479
Test: [Task 3]  [  0/625]  eta: 0:07:01  Loss: 0.2824 (0.2824)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6737  data: 0.4536  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:40  Loss: 0.2977 (0.3239)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (98.8636)  time: 0.2604  data: 0.0415  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:25  Loss: 0.2977 (0.3440)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (98.5119)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:19  Loss: 0.2492 (0.3261)  Acc@1: 100.0000 (95.9677)  Acc@5: 100.0000 (98.9919)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:15  Loss: 0.2009 (0.2933)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.2378)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:11  Loss: 0.2009 (0.2877)  Acc@1: 100.0000 (96.3235)  Acc@5: 100.0000 (99.3873)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:08  Loss: 0.2785 (0.2846)  Acc@1: 93.7500 (96.3115)  Acc@5: 100.0000 (99.4877)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:05  Loss: 0.1933 (0.2743)  Acc@1: 93.7500 (96.3028)  Acc@5: 100.0000 (99.5599)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:02  Loss: 0.1983 (0.2765)  Acc@1: 93.7500 (96.2191)  Acc@5: 100.0000 (99.5370)  time: 0.2191  data: 0.0006  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:59  Loss: 0.1989 (0.2770)  Acc@1: 100.0000 (96.3599)  Acc@5: 100.0000 (99.5192)  time: 0.2194  data: 0.0007  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:57  Loss: 0.2114 (0.2741)  Acc@1: 100.0000 (96.4728)  Acc@5: 100.0000 (99.5050)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:55  Loss: 0.1915 (0.2671)  Acc@1: 100.0000 (96.6779)  Acc@5: 100.0000 (99.5495)  time: 0.2207  data: 0.0008  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:52  Loss: 0.2172 (0.2686)  Acc@1: 100.0000 (96.6942)  Acc@5: 100.0000 (99.5351)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:50  Loss: 0.2549 (0.2704)  Acc@1: 100.0000 (96.6126)  Acc@5: 100.0000 (99.5706)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:47  Loss: 0.3101 (0.2771)  Acc@1: 93.7500 (96.4982)  Acc@5: 100.0000 (99.4681)  time: 0.2189  data: 0.0006  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:45  Loss: 0.3088 (0.2830)  Acc@1: 93.7500 (96.4404)  Acc@5: 100.0000 (99.4205)  time: 0.2185  data: 0.0004  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:43  Loss: 0.2847 (0.2843)  Acc@1: 100.0000 (96.4286)  Acc@5: 100.0000 (99.3401)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:40  Loss: 0.2208 (0.2826)  Acc@1: 100.0000 (96.4912)  Acc@5: 100.0000 (99.3787)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:38  Loss: 0.2519 (0.2838)  Acc@1: 93.7500 (96.4434)  Acc@5: 100.0000 (99.3439)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:36  Loss: 0.2636 (0.2822)  Acc@1: 93.7500 (96.4987)  Acc@5: 100.0000 (99.3783)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:34  Loss: 0.2636 (0.2840)  Acc@1: 93.7500 (96.3930)  Acc@5: 100.0000 (99.3470)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:31  Loss: 0.2505 (0.2832)  Acc@1: 100.0000 (96.4751)  Acc@5: 100.0000 (99.3483)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:29  Loss: 0.2954 (0.2874)  Acc@1: 100.0000 (96.3518)  Acc@5: 100.0000 (99.3213)  time: 0.2203  data: 0.0009  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:27  Loss: 0.3249 (0.2872)  Acc@1: 93.7500 (96.4015)  Acc@5: 100.0000 (99.3236)  time: 0.2197  data: 0.0009  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:25  Loss: 0.2342 (0.2903)  Acc@1: 93.7500 (96.2915)  Acc@5: 100.0000 (99.3257)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:22  Loss: 0.2185 (0.2878)  Acc@1: 93.7500 (96.3645)  Acc@5: 100.0000 (99.3277)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:20  Loss: 0.2093 (0.2874)  Acc@1: 100.0000 (96.3362)  Acc@5: 100.0000 (99.3295)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.2479 (0.2852)  Acc@1: 100.0000 (96.3792)  Acc@5: 100.0000 (99.3542)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:16  Loss: 0.2479 (0.2850)  Acc@1: 100.0000 (96.4190)  Acc@5: 100.0000 (99.3772)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:14  Loss: 0.2833 (0.2841)  Acc@1: 93.7500 (96.4132)  Acc@5: 100.0000 (99.3986)  time: 0.2205  data: 0.0003  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.2454 (0.2848)  Acc@1: 93.7500 (96.4078)  Acc@5: 100.0000 (99.3978)  time: 0.2207  data: 0.0004  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:09  Loss: 0.2339 (0.2866)  Acc@1: 93.7500 (96.3223)  Acc@5: 100.0000 (99.3368)  time: 0.2202  data: 0.0004  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.1693 (0.2840)  Acc@1: 93.7500 (96.3590)  Acc@5: 100.0000 (99.3575)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:05  Loss: 0.2213 (0.2847)  Acc@1: 93.7500 (96.3369)  Acc@5: 100.0000 (99.3769)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:02  Loss: 0.2504 (0.2824)  Acc@1: 100.0000 (96.4076)  Acc@5: 100.0000 (99.3952)  time: 0.2201  data: 0.0004  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.2267 (0.2824)  Acc@1: 100.0000 (96.3497)  Acc@5: 100.0000 (99.3946)  time: 0.2212  data: 0.0004  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.2944 (0.2851)  Acc@1: 93.7500 (96.2431)  Acc@5: 100.0000 (99.3594)  time: 0.2213  data: 0.0004  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.2700 (0.2861)  Acc@1: 93.7500 (96.1590)  Acc@5: 100.0000 (99.3598)  time: 0.2210  data: 0.0004  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:54  Loss: 0.2317 (0.2849)  Acc@1: 93.7500 (96.1942)  Acc@5: 100.0000 (99.3766)  time: 0.2204  data: 0.0004  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.2063 (0.2844)  Acc@1: 100.0000 (96.1957)  Acc@5: 100.0000 (99.3606)  time: 0.2207  data: 0.0004  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.2115 (0.2831)  Acc@1: 93.7500 (96.1970)  Acc@5: 100.0000 (99.3766)  time: 0.2207  data: 0.0004  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.2803 (0.2847)  Acc@1: 93.7500 (96.1983)  Acc@5: 100.0000 (99.3765)  time: 0.2210  data: 0.0004  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:45  Loss: 0.3048 (0.2854)  Acc@1: 100.0000 (96.1995)  Acc@5: 100.0000 (99.3765)  time: 0.2216  data: 0.0004  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:43  Loss: 0.2752 (0.2857)  Acc@1: 93.7500 (96.1862)  Acc@5: 100.0000 (99.3765)  time: 0.2208  data: 0.0003  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.3199 (0.2876)  Acc@1: 93.7500 (96.1451)  Acc@5: 100.0000 (99.3622)  time: 0.2204  data: 0.0007  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.2593 (0.2877)  Acc@1: 100.0000 (96.1336)  Acc@5: 100.0000 (99.3625)  time: 0.2199  data: 0.0007  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.2263 (0.2865)  Acc@1: 100.0000 (96.1632)  Acc@5: 100.0000 (99.3628)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.2263 (0.2870)  Acc@1: 93.7500 (96.0722)  Acc@5: 100.0000 (99.3631)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:32  Loss: 0.2713 (0.2875)  Acc@1: 93.7500 (96.0629)  Acc@5: 100.0000 (99.3503)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2804 (0.2877)  Acc@1: 93.7500 (96.0412)  Acc@5: 100.0000 (99.3381)  time: 0.2201  data: 0.0005  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2347 (0.2872)  Acc@1: 93.7500 (96.0080)  Acc@5: 100.0000 (99.3513)  time: 0.2199  data: 0.0005  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.2340 (0.2868)  Acc@1: 93.7500 (96.0250)  Acc@5: 100.0000 (99.3640)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.2569 (0.2880)  Acc@1: 93.7500 (95.9933)  Acc@5: 100.0000 (99.3642)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.3414 (0.2896)  Acc@1: 93.7500 (95.9393)  Acc@5: 100.0000 (99.3409)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2904 (0.2908)  Acc@1: 93.7500 (95.9219)  Acc@5: 100.0000 (99.3184)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2902 (0.2912)  Acc@1: 93.7500 (95.9165)  Acc@5: 100.0000 (99.2967)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2507 (0.2913)  Acc@1: 100.0000 (95.9447)  Acc@5: 100.0000 (99.2870)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.2507 (0.2917)  Acc@1: 100.0000 (95.9391)  Acc@5: 100.0000 (99.2776)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2589 (0.2938)  Acc@1: 93.7500 (95.9015)  Acc@5: 100.0000 (99.2577)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.2587 (0.2928)  Acc@1: 100.0000 (95.9391)  Acc@5: 100.0000 (99.2703)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.2105 (0.2919)  Acc@1: 100.0000 (95.9443)  Acc@5: 100.0000 (99.2720)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.2105 (0.2911)  Acc@1: 100.0000 (95.9595)  Acc@5: 100.0000 (99.2840)  time: 0.2217  data: 0.0019  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2513 (0.2925)  Acc@1: 93.7500 (95.9138)  Acc@5: 100.0000 (99.2854)  time: 0.2208  data: 0.0019  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.2375 (0.2920)  Acc@1: 93.7500 (95.9200)  Acc@5: 100.0000 (99.2900)  time: 0.2213  data: 0.0019  max mem: 2502
Test: [Task 3] Total time: 0:02:17 (0.2207 s / it)
* Acc@1 95.920 Acc@5 99.290 loss 0.292
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task3]	Acc@1: 84.8276	Acc@5: 96.4341	Loss: 0.7353	Forgetting: 6.4569	Backward: -6.4569
Train: Epoch[1/1]  [   0/1142]  eta: 0:14:48  Lr: 0.001875  Loss: 1.0257  Acc@1: 18.7500 (18.7500)  Acc@5: 50.0000 (50.0000)  time: 0.7783  data: 0.4084  max mem: 2502
Train: Epoch[1/1]  [  10/1142]  eta: 0:07:21  Lr: 0.001875  Loss: 0.8297  Acc@1: 25.0000 (21.5909)  Acc@5: 68.7500 (65.3409)  time: 0.3898  data: 0.0374  max mem: 2502
Train: Epoch[1/1]  [  20/1142]  eta: 0:06:56  Lr: 0.001875  Loss: 0.5830  Acc@1: 31.2500 (28.5714)  Acc@5: 81.2500 (73.8095)  time: 0.3510  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [  30/1142]  eta: 0:06:45  Lr: 0.001875  Loss: 0.5587  Acc@1: 37.5000 (33.2661)  Acc@5: 81.2500 (77.4194)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[1/1]  [  40/1142]  eta: 0:06:38  Lr: 0.001875  Loss: 0.4164  Acc@1: 43.7500 (36.4329)  Acc@5: 87.5000 (78.5061)  time: 0.3520  data: 0.0010  max mem: 2502
Train: Epoch[1/1]  [  50/1142]  eta: 0:06:33  Lr: 0.001875  Loss: 0.3386  Acc@1: 50.0000 (39.4608)  Acc@5: 87.5000 (80.3922)  time: 0.3533  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [  60/1142]  eta: 0:06:28  Lr: 0.001875  Loss: 0.1726  Acc@1: 50.0000 (41.1885)  Acc@5: 87.5000 (81.8648)  time: 0.3531  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [  70/1142]  eta: 0:06:23  Lr: 0.001875  Loss: 0.5831  Acc@1: 43.7500 (41.0211)  Acc@5: 87.5000 (83.0986)  time: 0.3523  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [  80/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.1968  Acc@1: 43.7500 (42.9012)  Acc@5: 87.5000 (83.7191)  time: 0.3536  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [  90/1142]  eta: 0:06:16  Lr: 0.001875  Loss: 0.5641  Acc@1: 56.2500 (43.9560)  Acc@5: 87.5000 (84.0659)  time: 0.3579  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 100/1142]  eta: 0:06:12  Lr: 0.001875  Loss: -0.4141  Acc@1: 50.0000 (44.9257)  Acc@5: 93.7500 (84.5916)  time: 0.3579  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 110/1142]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2696  Acc@1: 50.0000 (46.1712)  Acc@5: 93.7500 (85.0225)  time: 0.3549  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 120/1142]  eta: 0:06:05  Lr: 0.001875  Loss: 0.1361  Acc@1: 56.2500 (46.6942)  Acc@5: 87.5000 (85.0723)  time: 0.3572  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 130/1142]  eta: 0:06:01  Lr: 0.001875  Loss: 0.1161  Acc@1: 56.2500 (47.3282)  Acc@5: 87.5000 (85.4962)  time: 0.3554  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 140/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.1957  Acc@1: 50.0000 (47.9610)  Acc@5: 87.5000 (85.7270)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 150/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.1794  Acc@1: 56.2500 (48.5099)  Acc@5: 87.5000 (86.0513)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 160/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.2833  Acc@1: 56.2500 (48.7578)  Acc@5: 87.5000 (86.1413)  time: 0.3522  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 170/1142]  eta: 0:05:46  Lr: 0.001875  Loss: 0.1429  Acc@1: 56.2500 (49.3787)  Acc@5: 87.5000 (86.4035)  time: 0.3520  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 180/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.0572  Acc@1: 56.2500 (49.6547)  Acc@5: 93.7500 (86.6022)  time: 0.3537  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 190/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.3186  Acc@1: 56.2500 (50.4908)  Acc@5: 93.7500 (86.9437)  time: 0.3533  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 200/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.0203  Acc@1: 62.5000 (50.5597)  Acc@5: 93.7500 (87.0647)  time: 0.3528  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 210/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.5167  Acc@1: 62.5000 (51.1256)  Acc@5: 93.7500 (87.2927)  time: 0.3525  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 220/1142]  eta: 0:05:27  Lr: 0.001875  Loss: 0.0666  Acc@1: 62.5000 (51.5554)  Acc@5: 93.7500 (87.3869)  time: 0.3520  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 230/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.4581  Acc@1: 62.5000 (51.9751)  Acc@5: 93.7500 (87.5812)  time: 0.3530  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 240/1142]  eta: 0:05:20  Lr: 0.001875  Loss: -0.3390  Acc@1: 62.5000 (52.0488)  Acc@5: 93.7500 (87.8112)  time: 0.3531  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 250/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.2157  Acc@1: 56.2500 (52.4402)  Acc@5: 93.7500 (87.8735)  time: 0.3530  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 260/1142]  eta: 0:05:13  Lr: 0.001875  Loss: 0.0380  Acc@1: 56.2500 (52.5862)  Acc@5: 87.5000 (88.0029)  time: 0.3528  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 270/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.1352  Acc@1: 56.2500 (52.8367)  Acc@5: 87.5000 (88.0074)  time: 0.3528  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 280/1142]  eta: 0:05:05  Lr: 0.001875  Loss: -0.3164  Acc@1: 56.2500 (52.8915)  Acc@5: 87.5000 (88.0783)  time: 0.3525  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 290/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.3899  Acc@1: 56.2500 (53.1143)  Acc@5: 87.5000 (88.1443)  time: 0.3551  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 300/1142]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5919  Acc@1: 62.5000 (53.3223)  Acc@5: 87.5000 (88.2475)  time: 0.3550  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 310/1142]  eta: 0:04:55  Lr: 0.001875  Loss: 0.3321  Acc@1: 56.2500 (53.3360)  Acc@5: 87.5000 (88.2034)  time: 0.3530  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 320/1142]  eta: 0:04:51  Lr: 0.001875  Loss: -0.0753  Acc@1: 56.2500 (53.3100)  Acc@5: 87.5000 (88.2593)  time: 0.3537  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 330/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.0031  Acc@1: 56.2500 (53.5310)  Acc@5: 93.7500 (88.4063)  time: 0.3536  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 340/1142]  eta: 0:04:44  Lr: 0.001875  Loss: 0.1156  Acc@1: 62.5000 (53.7573)  Acc@5: 93.7500 (88.5447)  time: 0.3540  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 350/1142]  eta: 0:04:40  Lr: 0.001875  Loss: -0.3639  Acc@1: 56.2500 (53.8462)  Acc@5: 93.7500 (88.5506)  time: 0.3546  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 360/1142]  eta: 0:04:37  Lr: 0.001875  Loss: -0.6925  Acc@1: 62.5000 (54.1205)  Acc@5: 93.7500 (88.7812)  time: 0.3543  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 370/1142]  eta: 0:04:33  Lr: 0.001875  Loss: -0.3105  Acc@1: 62.5000 (54.3127)  Acc@5: 100.0000 (88.9825)  time: 0.3533  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 380/1142]  eta: 0:04:30  Lr: 0.001875  Loss: -0.1522  Acc@1: 62.5000 (54.5768)  Acc@5: 93.7500 (89.0420)  time: 0.3549  data: 0.0013  max mem: 2502
Train: Epoch[1/1]  [ 390/1142]  eta: 0:04:26  Lr: 0.001875  Loss: -0.0112  Acc@1: 56.2500 (54.6995)  Acc@5: 87.5000 (89.0345)  time: 0.3554  data: 0.0013  max mem: 2502
Train: Epoch[1/1]  [ 400/1142]  eta: 0:04:23  Lr: 0.001875  Loss: -0.1574  Acc@1: 56.2500 (54.8161)  Acc@5: 93.7500 (89.1677)  time: 0.3544  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 410/1142]  eta: 0:04:19  Lr: 0.001875  Loss: -0.2778  Acc@1: 56.2500 (55.0182)  Acc@5: 93.7500 (89.2184)  time: 0.3543  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 420/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.2408  Acc@1: 62.5000 (54.9733)  Acc@5: 87.5000 (89.2815)  time: 0.3536  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 430/1142]  eta: 0:04:12  Lr: 0.001875  Loss: 0.1897  Acc@1: 50.0000 (54.9739)  Acc@5: 87.5000 (89.3126)  time: 0.3530  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 440/1142]  eta: 0:04:08  Lr: 0.001875  Loss: 0.2045  Acc@1: 56.2500 (55.0028)  Acc@5: 87.5000 (89.2857)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 450/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.2635  Acc@1: 56.2500 (55.0028)  Acc@5: 87.5000 (89.2323)  time: 0.3536  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [ 460/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.6891  Acc@1: 56.2500 (55.2061)  Acc@5: 87.5000 (89.3438)  time: 0.3538  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [ 470/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.5067  Acc@1: 62.5000 (55.3079)  Acc@5: 93.7500 (89.3976)  time: 0.3529  data: 0.0008  max mem: 2502
Train: Epoch[1/1]  [ 480/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.0175  Acc@1: 62.5000 (55.3274)  Acc@5: 93.7500 (89.5010)  time: 0.3520  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [ 490/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -0.4467  Acc@1: 62.5000 (55.4353)  Acc@5: 93.7500 (89.5112)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 500/1142]  eta: 0:03:47  Lr: 0.001875  Loss: -0.0230  Acc@1: 62.5000 (55.5763)  Acc@5: 87.5000 (89.4960)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 510/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.5151  Acc@1: 62.5000 (55.6751)  Acc@5: 93.7500 (89.5915)  time: 0.3506  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 520/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.2279  Acc@1: 62.5000 (55.7222)  Acc@5: 93.7500 (89.6473)  time: 0.3509  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 530/1142]  eta: 0:03:36  Lr: 0.001875  Loss: -0.5533  Acc@1: 56.2500 (55.7910)  Acc@5: 93.7500 (89.7128)  time: 0.3512  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 540/1142]  eta: 0:03:33  Lr: 0.001875  Loss: -0.3440  Acc@1: 56.2500 (55.8457)  Acc@5: 93.7500 (89.7759)  time: 0.3511  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 550/1142]  eta: 0:03:29  Lr: 0.001875  Loss: -0.5103  Acc@1: 68.7500 (56.0685)  Acc@5: 93.7500 (89.8707)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 560/1142]  eta: 0:03:26  Lr: 0.001875  Loss: -0.4872  Acc@1: 62.5000 (56.1163)  Acc@5: 93.7500 (89.8953)  time: 0.3532  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 570/1142]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4858  Acc@1: 62.5000 (56.1843)  Acc@5: 93.7500 (89.9299)  time: 0.3527  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 580/1142]  eta: 0:03:18  Lr: 0.001875  Loss: -0.6415  Acc@1: 56.2500 (56.2177)  Acc@5: 93.7500 (89.9527)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 590/1142]  eta: 0:03:15  Lr: 0.001875  Loss: 0.1539  Acc@1: 56.2500 (56.2077)  Acc@5: 87.5000 (89.9429)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 600/1142]  eta: 0:03:11  Lr: 0.001875  Loss: 0.2326  Acc@1: 62.5000 (56.2708)  Acc@5: 87.5000 (90.0270)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 610/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.2065  Acc@1: 62.5000 (56.4546)  Acc@5: 93.7500 (90.0880)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 620/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.3936  Acc@1: 62.5000 (56.6023)  Acc@5: 93.7500 (90.0866)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 630/1142]  eta: 0:03:01  Lr: 0.001875  Loss: -0.6674  Acc@1: 62.5000 (56.6957)  Acc@5: 93.7500 (90.1644)  time: 0.3520  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 640/1142]  eta: 0:02:57  Lr: 0.001875  Loss: 0.0604  Acc@1: 62.5000 (56.7668)  Acc@5: 93.7500 (90.1619)  time: 0.3519  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 650/1142]  eta: 0:02:53  Lr: 0.001875  Loss: -0.3495  Acc@1: 62.5000 (56.7876)  Acc@5: 93.7500 (90.2170)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 660/1142]  eta: 0:02:50  Lr: 0.001875  Loss: -0.3018  Acc@1: 62.5000 (56.9308)  Acc@5: 93.7500 (90.2421)  time: 0.3519  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 670/1142]  eta: 0:02:46  Lr: 0.001875  Loss: -0.7434  Acc@1: 68.7500 (57.0697)  Acc@5: 93.7500 (90.2850)  time: 0.3519  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 680/1142]  eta: 0:02:43  Lr: 0.001875  Loss: -0.5671  Acc@1: 68.7500 (57.1953)  Acc@5: 93.7500 (90.3451)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 690/1142]  eta: 0:02:39  Lr: 0.001875  Loss: -0.0525  Acc@1: 62.5000 (57.2268)  Acc@5: 93.7500 (90.3582)  time: 0.3531  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 700/1142]  eta: 0:02:36  Lr: 0.001875  Loss: -0.1468  Acc@1: 56.2500 (57.2397)  Acc@5: 93.7500 (90.3887)  time: 0.3525  data: 0.0002  max mem: 2502
Train: Epoch[1/1]  [ 710/1142]  eta: 0:02:32  Lr: 0.001875  Loss: -0.1085  Acc@1: 62.5000 (57.3488)  Acc@5: 93.7500 (90.4184)  time: 0.3523  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 720/1142]  eta: 0:02:29  Lr: 0.001875  Loss: -0.5482  Acc@1: 62.5000 (57.4116)  Acc@5: 93.7500 (90.4213)  time: 0.3523  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 730/1142]  eta: 0:02:25  Lr: 0.001875  Loss: -0.0529  Acc@1: 56.2500 (57.3016)  Acc@5: 87.5000 (90.3899)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 740/1142]  eta: 0:02:22  Lr: 0.001875  Loss: -0.2465  Acc@1: 56.2500 (57.3296)  Acc@5: 87.5000 (90.4099)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 750/1142]  eta: 0:02:18  Lr: 0.001875  Loss: -0.2895  Acc@1: 62.5000 (57.3985)  Acc@5: 87.5000 (90.4128)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 760/1142]  eta: 0:02:15  Lr: 0.001875  Loss: -0.4332  Acc@1: 62.5000 (57.4244)  Acc@5: 93.7500 (90.4648)  time: 0.3538  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 770/1142]  eta: 0:02:11  Lr: 0.001875  Loss: -0.8260  Acc@1: 62.5000 (57.4578)  Acc@5: 87.5000 (90.4588)  time: 0.3541  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [ 780/1142]  eta: 0:02:07  Lr: 0.001875  Loss: -0.3275  Acc@1: 62.5000 (57.5304)  Acc@5: 87.5000 (90.5010)  time: 0.3534  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 790/1142]  eta: 0:02:04  Lr: 0.001875  Loss: -0.0819  Acc@1: 62.5000 (57.5616)  Acc@5: 93.7500 (90.5341)  time: 0.3524  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 800/1142]  eta: 0:02:00  Lr: 0.001875  Loss: -0.6192  Acc@1: 62.5000 (57.6779)  Acc@5: 100.0000 (90.6289)  time: 0.3541  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 810/1142]  eta: 0:01:57  Lr: 0.001875  Loss: -0.2298  Acc@1: 68.7500 (57.8144)  Acc@5: 93.7500 (90.6597)  time: 0.3555  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 820/1142]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3197  Acc@1: 68.7500 (57.8563)  Acc@5: 93.7500 (90.6745)  time: 0.3535  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 830/1142]  eta: 0:01:50  Lr: 0.001875  Loss: -0.2580  Acc@1: 56.2500 (57.8219)  Acc@5: 93.7500 (90.7040)  time: 0.3528  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 840/1142]  eta: 0:01:46  Lr: 0.001875  Loss: -0.3834  Acc@1: 56.2500 (57.8181)  Acc@5: 93.7500 (90.7773)  time: 0.3538  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 850/1142]  eta: 0:01:43  Lr: 0.001875  Loss: -0.5603  Acc@1: 62.5000 (57.8878)  Acc@5: 93.7500 (90.7902)  time: 0.3534  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 860/1142]  eta: 0:01:39  Lr: 0.001875  Loss: -0.2572  Acc@1: 62.5000 (57.9486)  Acc@5: 87.5000 (90.7666)  time: 0.3527  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 870/1142]  eta: 0:01:36  Lr: 0.001875  Loss: -0.5615  Acc@1: 56.2500 (58.0152)  Acc@5: 93.7500 (90.8223)  time: 0.3524  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 880/1142]  eta: 0:01:32  Lr: 0.001875  Loss: -0.5792  Acc@1: 56.2500 (58.0236)  Acc@5: 93.7500 (90.8130)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 890/1142]  eta: 0:01:29  Lr: 0.001875  Loss: -0.1207  Acc@1: 56.2500 (58.0177)  Acc@5: 93.7500 (90.8109)  time: 0.3523  data: 0.0008  max mem: 2502
Train: Epoch[1/1]  [ 900/1142]  eta: 0:01:25  Lr: 0.001875  Loss: 0.0815  Acc@1: 56.2500 (58.0466)  Acc@5: 93.7500 (90.8088)  time: 0.3524  data: 0.0008  max mem: 2502
Train: Epoch[1/1]  [ 910/1142]  eta: 0:01:22  Lr: 0.001875  Loss: -0.2057  Acc@1: 62.5000 (58.1435)  Acc@5: 87.5000 (90.8137)  time: 0.3541  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 920/1142]  eta: 0:01:18  Lr: 0.001875  Loss: -0.2799  Acc@1: 62.5000 (58.2519)  Acc@5: 93.7500 (90.8455)  time: 0.3544  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4973  Acc@1: 62.5000 (58.2975)  Acc@5: 93.7500 (90.8969)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 940/1142]  eta: 0:01:11  Lr: 0.001875  Loss: -0.2692  Acc@1: 62.5000 (58.3887)  Acc@5: 93.7500 (90.9139)  time: 0.3520  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6951  Acc@1: 68.7500 (58.3991)  Acc@5: 93.7500 (90.9437)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [ 960/1142]  eta: 0:01:04  Lr: 0.001875  Loss: -0.3873  Acc@1: 62.5000 (58.4092)  Acc@5: 93.7500 (90.9599)  time: 0.3528  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.0511  Acc@1: 56.2500 (58.3805)  Acc@5: 93.7500 (90.9629)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[1/1]  [ 980/1142]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4583  Acc@1: 56.2500 (58.4098)  Acc@5: 93.7500 (90.9531)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[1/1]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.2043  Acc@1: 62.5000 (58.4511)  Acc@5: 93.7500 (91.0129)  time: 0.3520  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1000/1142]  eta: 0:00:50  Lr: 0.001875  Loss: -0.4212  Acc@1: 62.5000 (58.5227)  Acc@5: 93.7500 (91.0152)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[1/1]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.7014  Acc@1: 62.5000 (58.5621)  Acc@5: 93.7500 (91.0608)  time: 0.3522  data: 0.0009  max mem: 2502
Train: Epoch[1/1]  [1020/1142]  eta: 0:00:43  Lr: 0.001875  Loss: 0.2078  Acc@1: 56.2500 (58.5394)  Acc@5: 93.7500 (91.0749)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.6075  Acc@1: 56.2500 (58.5597)  Acc@5: 93.7500 (91.0584)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1040/1142]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0077  Acc@1: 62.5000 (58.6275)  Acc@5: 93.7500 (91.0543)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.5458  Acc@1: 68.7500 (58.7119)  Acc@5: 93.7500 (91.0561)  time: 0.3522  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.5791  Acc@1: 68.7500 (58.7594)  Acc@5: 93.7500 (91.0639)  time: 0.3532  data: 0.0003  max mem: 2502
Train: Epoch[1/1]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.8656  Acc@1: 62.5000 (58.8235)  Acc@5: 93.7500 (91.1064)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0897  Acc@1: 62.5000 (58.9269)  Acc@5: 100.0000 (91.1367)  time: 0.3542  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.2954  Acc@1: 68.7500 (59.0112)  Acc@5: 93.7500 (91.1721)  time: 0.3543  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.3827  Acc@1: 68.7500 (59.0713)  Acc@5: 93.7500 (91.2182)  time: 0.3537  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.4087  Acc@1: 62.5000 (59.1022)  Acc@5: 93.7500 (91.2297)  time: 0.3535  data: 0.0005  max mem: 2502
Train: Epoch[1/1]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.2275  Acc@1: 62.5000 (59.1380)  Acc@5: 93.7500 (91.2244)  time: 0.3523  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5397  Acc@1: 62.5000 (59.1678)  Acc@5: 93.7500 (91.2412)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6498  Acc@1: 62.5000 (59.2189)  Acc@5: 93.7500 (91.2577)  time: 0.3524  data: 0.0004  max mem: 2502
Train: Epoch[1/1]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1989  Acc@1: 62.5000 (59.2171)  Acc@5: 93.7500 (91.2565)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[1/1] Total time: 0:06:43 (0.3534 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 18265, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 18265, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 18265, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 18265, 4: 0}, 8: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1989  Acc@1: 62.5000 (59.2171)  Acc@5: 93.7500 (91.2565)
Test: [Task 1]  [   0/1627]  eta: 0:25:27  Loss: 1.4829 (1.4829)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.9388  data: 0.7201  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:07:38  Loss: 1.5487 (1.4470)  Acc@1: 68.7500 (68.1818)  Acc@5: 93.7500 (90.3409)  time: 0.2838  data: 0.0658  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:45  Loss: 1.4420 (1.4286)  Acc@1: 68.7500 (69.6429)  Acc@5: 93.7500 (91.3690)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:26  Loss: 1.3792 (1.4598)  Acc@1: 68.7500 (67.7419)  Acc@5: 93.7500 (90.9274)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:06:14  Loss: 1.6419 (1.4905)  Acc@1: 56.2500 (66.1585)  Acc@5: 87.5000 (90.0915)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:06:06  Loss: 1.4797 (1.4641)  Acc@1: 62.5000 (66.7892)  Acc@5: 87.5000 (90.6863)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:06:01  Loss: 1.4797 (1.4927)  Acc@1: 68.7500 (65.6762)  Acc@5: 87.5000 (89.9590)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:56  Loss: 1.4797 (1.4847)  Acc@1: 62.5000 (65.8451)  Acc@5: 87.5000 (90.0528)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:52  Loss: 1.3771 (1.4750)  Acc@1: 62.5000 (66.1265)  Acc@5: 93.7500 (90.5864)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:48  Loss: 1.3953 (1.4757)  Acc@1: 68.7500 (66.1401)  Acc@5: 93.7500 (90.5220)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:45  Loss: 1.6286 (1.4999)  Acc@1: 62.5000 (65.8416)  Acc@5: 81.2500 (89.6658)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:42  Loss: 1.5858 (1.5008)  Acc@1: 62.5000 (65.7095)  Acc@5: 87.5000 (90.1464)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:39  Loss: 1.4773 (1.5023)  Acc@1: 62.5000 (65.3926)  Acc@5: 93.7500 (89.9793)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:36  Loss: 1.4728 (1.4976)  Acc@1: 62.5000 (65.4580)  Acc@5: 87.5000 (89.8378)  time: 0.2201  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:33  Loss: 1.3721 (1.4963)  Acc@1: 62.5000 (65.3812)  Acc@5: 87.5000 (89.7606)  time: 0.2213  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:31  Loss: 1.2923 (1.4847)  Acc@1: 68.7500 (65.7285)  Acc@5: 93.7500 (89.9007)  time: 0.2206  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:28  Loss: 1.3604 (1.4790)  Acc@1: 68.7500 (65.8773)  Acc@5: 93.7500 (90.1009)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:26  Loss: 1.4117 (1.4713)  Acc@1: 68.7500 (65.8991)  Acc@5: 93.7500 (90.2047)  time: 0.2221  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:23  Loss: 1.4416 (1.4826)  Acc@1: 62.5000 (65.4006)  Acc@5: 87.5000 (89.9517)  time: 0.2217  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:21  Loss: 1.5504 (1.4771)  Acc@1: 62.5000 (65.6086)  Acc@5: 87.5000 (89.9542)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:18  Loss: 1.5504 (1.4798)  Acc@1: 62.5000 (65.5473)  Acc@5: 93.7500 (89.9876)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:16  Loss: 1.4698 (1.4761)  Acc@1: 68.7500 (65.7287)  Acc@5: 93.7500 (90.0474)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:13  Loss: 1.4698 (1.4823)  Acc@1: 68.7500 (65.6109)  Acc@5: 87.5000 (90.0735)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:10  Loss: 1.5113 (1.4762)  Acc@1: 62.5000 (65.7738)  Acc@5: 93.7500 (90.1786)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:08  Loss: 1.3577 (1.4690)  Acc@1: 68.7500 (65.9751)  Acc@5: 93.7500 (90.1971)  time: 0.2178  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:05:06  Loss: 1.4822 (1.4746)  Acc@1: 62.5000 (65.7869)  Acc@5: 87.5000 (90.0398)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:05:03  Loss: 1.4631 (1.4726)  Acc@1: 62.5000 (65.9962)  Acc@5: 93.7500 (90.0862)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:05:01  Loss: 1.4159 (1.4655)  Acc@1: 68.7500 (66.2131)  Acc@5: 93.7500 (90.1522)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:58  Loss: 1.3492 (1.4648)  Acc@1: 68.7500 (66.2144)  Acc@5: 93.7500 (90.1468)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:56  Loss: 1.3492 (1.4621)  Acc@1: 68.7500 (66.1297)  Acc@5: 87.5000 (90.1847)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:53  Loss: 1.3875 (1.4605)  Acc@1: 68.7500 (66.2375)  Acc@5: 93.7500 (90.2409)  time: 0.2181  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:51  Loss: 1.3875 (1.4636)  Acc@1: 68.7500 (66.2379)  Acc@5: 87.5000 (90.0924)  time: 0.2183  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:49  Loss: 1.5608 (1.4647)  Acc@1: 62.5000 (66.1994)  Acc@5: 87.5000 (90.0896)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:46  Loss: 1.4966 (1.4639)  Acc@1: 62.5000 (66.2764)  Acc@5: 87.5000 (90.0302)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:44  Loss: 1.3801 (1.4634)  Acc@1: 68.7500 (66.3123)  Acc@5: 93.7500 (90.0477)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:42  Loss: 1.4499 (1.4629)  Acc@1: 62.5000 (66.3105)  Acc@5: 93.7500 (90.0285)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:39  Loss: 1.3925 (1.4630)  Acc@1: 62.5000 (66.3262)  Acc@5: 87.5000 (89.9931)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:37  Loss: 1.3204 (1.4623)  Acc@1: 68.7500 (66.3747)  Acc@5: 87.5000 (89.9427)  time: 0.2177  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:35  Loss: 1.3754 (1.4607)  Acc@1: 68.7500 (66.4534)  Acc@5: 87.5000 (89.9278)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:32  Loss: 1.4744 (1.4627)  Acc@1: 68.7500 (66.4482)  Acc@5: 87.5000 (89.8497)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:30  Loss: 1.4400 (1.4636)  Acc@1: 68.7500 (66.4744)  Acc@5: 93.7500 (89.8379)  time: 0.2179  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:28  Loss: 1.3986 (1.4631)  Acc@1: 68.7500 (66.5146)  Acc@5: 87.5000 (89.7962)  time: 0.2180  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:26  Loss: 1.3108 (1.4603)  Acc@1: 68.7500 (66.6568)  Acc@5: 93.7500 (89.8901)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:23  Loss: 1.2778 (1.4583)  Acc@1: 75.0000 (66.7488)  Acc@5: 93.7500 (89.9072)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:21  Loss: 1.4654 (1.4584)  Acc@1: 68.7500 (66.8084)  Acc@5: 93.7500 (89.9235)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:19  Loss: 1.6074 (1.4625)  Acc@1: 62.5000 (66.6990)  Acc@5: 87.5000 (89.8836)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:17  Loss: 1.5285 (1.4619)  Acc@1: 62.5000 (66.6757)  Acc@5: 87.5000 (89.9132)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:14  Loss: 1.2727 (1.4586)  Acc@1: 68.7500 (66.7463)  Acc@5: 93.7500 (89.9682)  time: 0.2217  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:12  Loss: 1.4783 (1.4635)  Acc@1: 68.7500 (66.6710)  Acc@5: 87.5000 (89.8779)  time: 0.2220  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:10  Loss: 1.4783 (1.4646)  Acc@1: 68.7500 (66.5733)  Acc@5: 87.5000 (89.8294)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:08  Loss: 1.4631 (1.4673)  Acc@1: 68.7500 (66.5793)  Acc@5: 87.5000 (89.7705)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:06  Loss: 1.5046 (1.4708)  Acc@1: 62.5000 (66.5117)  Acc@5: 87.5000 (89.6649)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:04:03  Loss: 1.5332 (1.4758)  Acc@1: 62.5000 (66.4107)  Acc@5: 87.5000 (89.6233)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:04:01  Loss: 1.3645 (1.4710)  Acc@1: 68.7500 (66.5725)  Acc@5: 93.7500 (89.6657)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:59  Loss: 1.3583 (1.4709)  Acc@1: 68.7500 (66.5550)  Acc@5: 87.5000 (89.6257)  time: 0.2195  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:57  Loss: 1.5616 (1.4740)  Acc@1: 68.7500 (66.5041)  Acc@5: 87.5000 (89.5758)  time: 0.2196  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:54  Loss: 1.5955 (1.4764)  Acc@1: 62.5000 (66.4773)  Acc@5: 87.5000 (89.5499)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:52  Loss: 1.3657 (1.4745)  Acc@1: 68.7500 (66.4733)  Acc@5: 93.7500 (89.5906)  time: 0.2207  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:50  Loss: 1.4110 (1.4764)  Acc@1: 68.7500 (66.4049)  Acc@5: 93.7500 (89.5977)  time: 0.2205  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:48  Loss: 1.4614 (1.4754)  Acc@1: 62.5000 (66.3917)  Acc@5: 93.7500 (89.6362)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:46  Loss: 1.4089 (1.4782)  Acc@1: 62.5000 (66.2750)  Acc@5: 93.7500 (89.5799)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:43  Loss: 1.3885 (1.4762)  Acc@1: 62.5000 (66.3768)  Acc@5: 87.5000 (89.6277)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:41  Loss: 1.4018 (1.4771)  Acc@1: 68.7500 (66.3849)  Acc@5: 87.5000 (89.5733)  time: 0.2217  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:39  Loss: 1.3925 (1.4756)  Acc@1: 62.5000 (66.4422)  Acc@5: 93.7500 (89.6097)  time: 0.2219  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:37  Loss: 1.1895 (1.4742)  Acc@1: 68.7500 (66.4782)  Acc@5: 93.7500 (89.6256)  time: 0.2194  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:35  Loss: 1.4024 (1.4742)  Acc@1: 68.7500 (66.4651)  Acc@5: 87.5000 (89.5641)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:32  Loss: 1.3266 (1.4718)  Acc@1: 68.7500 (66.5753)  Acc@5: 87.5000 (89.6085)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:30  Loss: 1.4276 (1.4728)  Acc@1: 68.7500 (66.5238)  Acc@5: 87.5000 (89.5771)  time: 0.2205  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:28  Loss: 1.4276 (1.4706)  Acc@1: 68.7500 (66.5932)  Acc@5: 87.5000 (89.6017)  time: 0.2204  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:26  Loss: 1.3970 (1.4691)  Acc@1: 68.7500 (66.6516)  Acc@5: 93.7500 (89.6708)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:24  Loss: 1.5025 (1.4693)  Acc@1: 68.7500 (66.6726)  Acc@5: 93.7500 (89.6844)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:21  Loss: 1.4686 (1.4670)  Acc@1: 68.7500 (66.7370)  Acc@5: 87.5000 (89.6888)  time: 0.2203  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:19  Loss: 1.2617 (1.4648)  Acc@1: 68.7500 (66.8083)  Acc@5: 93.7500 (89.7451)  time: 0.2207  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:17  Loss: 1.3921 (1.4666)  Acc@1: 68.7500 (66.7750)  Acc@5: 93.7500 (89.7401)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:15  Loss: 1.5355 (1.4669)  Acc@1: 68.7500 (66.8016)  Acc@5: 87.5000 (89.6845)  time: 0.2198  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:13  Loss: 1.4425 (1.4659)  Acc@1: 68.7500 (66.8609)  Acc@5: 87.5000 (89.7220)  time: 0.2197  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:10  Loss: 1.4425 (1.4691)  Acc@1: 68.7500 (66.7953)  Acc@5: 87.5000 (89.6271)  time: 0.2187  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:08  Loss: 1.3953 (1.4666)  Acc@1: 68.7500 (66.8693)  Acc@5: 93.7500 (89.6968)  time: 0.2208  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:06  Loss: 1.2411 (1.4656)  Acc@1: 68.7500 (66.8854)  Acc@5: 93.7500 (89.7087)  time: 0.2209  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:04  Loss: 1.3776 (1.4672)  Acc@1: 62.5000 (66.8616)  Acc@5: 87.5000 (89.6176)  time: 0.2184  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:03:02  Loss: 1.5141 (1.4676)  Acc@1: 62.5000 (66.8383)  Acc@5: 87.5000 (89.6380)  time: 0.2185  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:59  Loss: 1.4453 (1.4670)  Acc@1: 68.7500 (66.8927)  Acc@5: 93.7500 (89.6270)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:57  Loss: 1.2377 (1.4665)  Acc@1: 75.0000 (66.9077)  Acc@5: 93.7500 (89.6468)  time: 0.2180  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:55  Loss: 1.2304 (1.4659)  Acc@1: 68.7500 (66.8773)  Acc@5: 93.7500 (89.6360)  time: 0.2177  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:53  Loss: 1.2083 (1.4641)  Acc@1: 68.7500 (66.9070)  Acc@5: 93.7500 (89.6626)  time: 0.2186  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:50  Loss: 1.5276 (1.4651)  Acc@1: 68.7500 (66.8772)  Acc@5: 93.7500 (89.6445)  time: 0.2187  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 1.4105 (1.4649)  Acc@1: 68.7500 (66.9135)  Acc@5: 87.5000 (89.6414)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:46  Loss: 1.4029 (1.4627)  Acc@1: 68.7500 (66.9920)  Acc@5: 93.7500 (89.6455)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:44  Loss: 1.5407 (1.4658)  Acc@1: 68.7500 (66.9197)  Acc@5: 87.5000 (89.6212)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:42  Loss: 1.6999 (1.4679)  Acc@1: 56.2500 (66.8701)  Acc@5: 87.5000 (89.5903)  time: 0.2196  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 1.5853 (1.4685)  Acc@1: 56.2500 (66.8632)  Acc@5: 87.5000 (89.5810)  time: 0.2197  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 1.4980 (1.4686)  Acc@1: 62.5000 (66.8771)  Acc@5: 87.5000 (89.5993)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 1.3548 (1.4671)  Acc@1: 62.5000 (66.9110)  Acc@5: 93.7500 (89.6512)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:33  Loss: 1.3799 (1.4665)  Acc@1: 62.5000 (66.9106)  Acc@5: 87.5000 (89.6147)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:31  Loss: 1.4289 (1.4649)  Acc@1: 68.7500 (66.9168)  Acc@5: 93.7500 (89.6918)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 1.4441 (1.4657)  Acc@1: 68.7500 (66.8901)  Acc@5: 93.7500 (89.6622)  time: 0.2189  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 1.4135 (1.4651)  Acc@1: 68.7500 (66.8835)  Acc@5: 87.5000 (89.6722)  time: 0.2190  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 1.2819 (1.4641)  Acc@1: 68.7500 (66.9284)  Acc@5: 87.5000 (89.6498)  time: 0.2194  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:22  Loss: 1.4025 (1.4639)  Acc@1: 68.7500 (66.8960)  Acc@5: 87.5000 (89.6279)  time: 0.2192  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:20  Loss: 1.6042 (1.4668)  Acc@1: 56.2500 (66.8327)  Acc@5: 87.5000 (89.5938)  time: 0.2218  data: 0.0007  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 1.5980 (1.4672)  Acc@1: 62.5000 (66.8394)  Acc@5: 87.5000 (89.5729)  time: 0.2224  data: 0.0009  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 1.4548 (1.4673)  Acc@1: 68.7500 (66.8707)  Acc@5: 87.5000 (89.5524)  time: 0.2193  data: 0.0005  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 1.4548 (1.4673)  Acc@1: 68.7500 (66.9013)  Acc@5: 87.5000 (89.5752)  time: 0.2194  data: 0.0009  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:11  Loss: 1.3065 (1.4660)  Acc@1: 68.7500 (66.9374)  Acc@5: 93.7500 (89.5975)  time: 0.2203  data: 0.0010  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:09  Loss: 1.2932 (1.4652)  Acc@1: 68.7500 (66.9549)  Acc@5: 87.5000 (89.5833)  time: 0.2206  data: 0.0004  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 1.3375 (1.4640)  Acc@1: 68.7500 (66.9779)  Acc@5: 87.5000 (89.5932)  time: 0.2202  data: 0.0004  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 1.4895 (1.4643)  Acc@1: 68.7500 (66.9298)  Acc@5: 87.5000 (89.5912)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 1.4532 (1.4648)  Acc@1: 62.5000 (66.9701)  Acc@5: 87.5000 (89.5833)  time: 0.2197  data: 0.0006  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:02:00  Loss: 1.4378 (1.4653)  Acc@1: 68.7500 (66.9635)  Acc@5: 87.5000 (89.5641)  time: 0.2198  data: 0.0006  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:58  Loss: 1.4090 (1.4653)  Acc@1: 62.5000 (66.9455)  Acc@5: 87.5000 (89.5509)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 1.3545 (1.4635)  Acc@1: 62.5000 (66.9959)  Acc@5: 93.7500 (89.6004)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 1.4101 (1.4642)  Acc@1: 62.5000 (66.9667)  Acc@5: 93.7500 (89.6040)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 1.4840 (1.4649)  Acc@1: 62.5000 (66.9492)  Acc@5: 93.7500 (89.6131)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 1.5932 (1.4666)  Acc@1: 62.5000 (66.8711)  Acc@5: 87.5000 (89.5944)  time: 0.2192  data: 0.0009  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:47  Loss: 1.5932 (1.4677)  Acc@1: 62.5000 (66.8712)  Acc@5: 87.5000 (89.5760)  time: 0.2194  data: 0.0007  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 1.5971 (1.4690)  Acc@1: 62.5000 (66.8223)  Acc@5: 87.5000 (89.5417)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 1.3958 (1.4677)  Acc@1: 62.5000 (66.8605)  Acc@5: 87.5000 (89.5618)  time: 0.2188  data: 0.0007  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 1.3629 (1.4670)  Acc@1: 75.0000 (66.8926)  Acc@5: 93.7500 (89.5709)  time: 0.2205  data: 0.0013  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 1.5316 (1.4679)  Acc@1: 68.7500 (66.8395)  Acc@5: 93.7500 (89.5798)  time: 0.2206  data: 0.0010  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:36  Loss: 1.5699 (1.4691)  Acc@1: 62.5000 (66.8084)  Acc@5: 87.5000 (89.5466)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 1.4545 (1.4689)  Acc@1: 62.5000 (66.8141)  Acc@5: 87.5000 (89.5400)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 1.3981 (1.4701)  Acc@1: 62.5000 (66.7475)  Acc@5: 87.5000 (89.5076)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 1.4735 (1.4698)  Acc@1: 62.5000 (66.7127)  Acc@5: 93.7500 (89.5270)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 1.4879 (1.4709)  Acc@1: 62.5000 (66.6785)  Acc@5: 87.5000 (89.4953)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:25  Loss: 1.3941 (1.4698)  Acc@1: 68.7500 (66.7305)  Acc@5: 87.5000 (89.4994)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 1.4561 (1.4702)  Acc@1: 68.7500 (66.7166)  Acc@5: 87.5000 (89.4884)  time: 0.2203  data: 0.0005  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 1.4561 (1.4699)  Acc@1: 68.7500 (66.7427)  Acc@5: 93.7500 (89.4974)  time: 0.2202  data: 0.0005  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 1.3835 (1.4702)  Acc@1: 68.7500 (66.7486)  Acc@5: 87.5000 (89.4719)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 1.3320 (1.4682)  Acc@1: 68.7500 (66.7642)  Acc@5: 87.5000 (89.4955)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:14  Loss: 1.3320 (1.4687)  Acc@1: 68.7500 (66.7215)  Acc@5: 87.5000 (89.4752)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 1.4554 (1.4681)  Acc@1: 62.5000 (66.7419)  Acc@5: 87.5000 (89.5033)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 1.2907 (1.4668)  Acc@1: 75.0000 (66.8049)  Acc@5: 93.7500 (89.5452)  time: 0.2201  data: 0.0013  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 1.1912 (1.4654)  Acc@1: 75.0000 (66.8622)  Acc@5: 93.7500 (89.5770)  time: 0.2207  data: 0.0015  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 1.2520 (1.4653)  Acc@1: 68.7500 (66.8576)  Acc@5: 93.7500 (89.5755)  time: 0.2191  data: 0.0005  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:03  Loss: 1.4579 (1.4655)  Acc@1: 62.5000 (66.8391)  Acc@5: 87.5000 (89.5833)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 1.4463 (1.4652)  Acc@1: 62.5000 (66.8486)  Acc@5: 93.7500 (89.6003)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 1.3334 (1.4646)  Acc@1: 68.7500 (66.8488)  Acc@5: 93.7500 (89.6032)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 1.3334 (1.4645)  Acc@1: 68.7500 (66.8536)  Acc@5: 87.5000 (89.5970)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 1.4021 (1.4647)  Acc@1: 68.7500 (66.8583)  Acc@5: 87.5000 (89.5999)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:52  Loss: 1.4690 (1.4640)  Acc@1: 68.7500 (66.9033)  Acc@5: 93.7500 (89.6208)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.2923 (1.4643)  Acc@1: 75.0000 (66.8986)  Acc@5: 93.7500 (89.6101)  time: 0.2187  data: 0.0006  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 1.3071 (1.4638)  Acc@1: 68.7500 (66.9206)  Acc@5: 93.7500 (89.6439)  time: 0.2182  data: 0.0006  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.3621 (1.4636)  Acc@1: 62.5000 (66.9115)  Acc@5: 93.7500 (89.6420)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.6103 (1.4651)  Acc@1: 62.5000 (66.8850)  Acc@5: 87.5000 (89.6183)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 1.5422 (1.4649)  Acc@1: 62.5000 (66.8850)  Acc@5: 87.5000 (89.6122)  time: 0.2201  data: 0.0004  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.4980 (1.4659)  Acc@1: 68.7500 (66.8548)  Acc@5: 87.5000 (89.5848)  time: 0.2205  data: 0.0004  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.5667 (1.4663)  Acc@1: 68.7500 (66.8549)  Acc@5: 87.5000 (89.5962)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.4029 (1.4668)  Acc@1: 62.5000 (66.8210)  Acc@5: 93.7500 (89.5947)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 1.4257 (1.4676)  Acc@1: 56.2500 (66.8045)  Acc@5: 93.7500 (89.5679)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 1.5209 (1.4676)  Acc@1: 68.7500 (66.8218)  Acc@5: 87.5000 (89.5666)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.4430 (1.4678)  Acc@1: 68.7500 (66.8346)  Acc@5: 93.7500 (89.5778)  time: 0.2196  data: 0.0010  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.2062 (1.4677)  Acc@1: 68.7500 (66.8059)  Acc@5: 93.7500 (89.5806)  time: 0.2203  data: 0.0010  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.2062 (1.4667)  Acc@1: 75.0000 (66.8434)  Acc@5: 93.7500 (89.5957)  time: 0.2207  data: 0.0005  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.2235 (1.4661)  Acc@1: 75.0000 (66.8721)  Acc@5: 93.7500 (89.6105)  time: 0.2202  data: 0.0005  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 1.2219 (1.4651)  Acc@1: 62.5000 (66.8640)  Acc@5: 93.7500 (89.6252)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 1.2531 (1.4651)  Acc@1: 62.5000 (66.8520)  Acc@5: 93.7500 (89.6397)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 1.2531 (1.4638)  Acc@1: 75.0000 (66.8922)  Acc@5: 93.7500 (89.6661)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.2423 (1.4638)  Acc@1: 68.7500 (66.9040)  Acc@5: 93.7500 (89.6722)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.3834 (1.4632)  Acc@1: 68.7500 (66.9355)  Acc@5: 87.5000 (89.6861)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.4400 (1.4637)  Acc@1: 68.7500 (66.9115)  Acc@5: 87.5000 (89.6920)  time: 0.2203  data: 0.0004  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.4826 (1.4648)  Acc@1: 62.5000 (66.8684)  Acc@5: 87.5000 (89.6705)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.4302 (1.4639)  Acc@1: 62.5000 (66.8956)  Acc@5: 87.5000 (89.6764)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.3490 (1.4634)  Acc@1: 62.5000 (66.8877)  Acc@5: 93.7500 (89.6977)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.2543 (1.4626)  Acc@1: 68.7500 (66.9292)  Acc@5: 93.7500 (89.7088)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1] Total time: 0:05:57 (0.2199 s / it)
* Acc@1 66.929 Acc@5 89.709 loss 1.463
Test: [Task 2]  [  0/625]  eta: 0:06:03  Loss: 1.5472 (1.5472)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5813  data: 0.3605  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:35  Loss: 1.8917 (1.9199)  Acc@1: 56.2500 (51.1364)  Acc@5: 81.2500 (84.6591)  time: 0.2521  data: 0.0331  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:23  Loss: 1.7983 (1.8477)  Acc@1: 50.0000 (51.7857)  Acc@5: 81.2500 (86.3095)  time: 0.2196  data: 0.0005  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:17  Loss: 1.7135 (1.8049)  Acc@1: 56.2500 (54.6371)  Acc@5: 87.5000 (87.0968)  time: 0.2199  data: 0.0006  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:13  Loss: 1.7135 (1.8039)  Acc@1: 56.2500 (54.5732)  Acc@5: 87.5000 (87.5000)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:10  Loss: 1.9625 (1.8449)  Acc@1: 50.0000 (53.6765)  Acc@5: 81.2500 (85.7843)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:07  Loss: 1.9625 (1.8535)  Acc@1: 50.0000 (53.3811)  Acc@5: 81.2500 (85.8607)  time: 0.2210  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:04  Loss: 1.7665 (1.8421)  Acc@1: 50.0000 (53.2570)  Acc@5: 87.5000 (86.3556)  time: 0.2209  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:02  Loss: 1.7665 (1.8448)  Acc@1: 56.2500 (53.0864)  Acc@5: 87.5000 (86.2654)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 1.8567 (1.8509)  Acc@1: 56.2500 (52.8846)  Acc@5: 81.2500 (86.0577)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:57  Loss: 1.8567 (1.8602)  Acc@1: 56.2500 (52.6609)  Acc@5: 87.5000 (86.1386)  time: 0.2197  data: 0.0003  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:55  Loss: 1.7484 (1.8487)  Acc@1: 56.2500 (52.6464)  Acc@5: 87.5000 (86.3176)  time: 0.2210  data: 0.0009  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:52  Loss: 1.7484 (1.8411)  Acc@1: 56.2500 (52.8409)  Acc@5: 87.5000 (86.4669)  time: 0.2212  data: 0.0009  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:50  Loss: 1.8835 (1.8475)  Acc@1: 50.0000 (52.5763)  Acc@5: 87.5000 (86.3550)  time: 0.2198  data: 0.0003  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 1.8910 (1.8499)  Acc@1: 50.0000 (52.5709)  Acc@5: 87.5000 (86.3032)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 1.8965 (1.8550)  Acc@1: 50.0000 (52.4007)  Acc@5: 81.2500 (86.2169)  time: 0.2202  data: 0.0006  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:43  Loss: 1.8946 (1.8525)  Acc@1: 50.0000 (52.5233)  Acc@5: 81.2500 (86.2189)  time: 0.2197  data: 0.0006  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:41  Loss: 1.7869 (1.8490)  Acc@1: 56.2500 (52.7047)  Acc@5: 87.5000 (86.4401)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 1.9317 (1.8517)  Acc@1: 50.0000 (52.6588)  Acc@5: 87.5000 (86.4641)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:36  Loss: 1.9614 (1.8553)  Acc@1: 50.0000 (52.7160)  Acc@5: 81.2500 (86.2893)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:34  Loss: 1.9337 (1.8561)  Acc@1: 50.0000 (52.6119)  Acc@5: 87.5000 (86.3495)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 1.9412 (1.8579)  Acc@1: 50.0000 (52.6066)  Acc@5: 87.5000 (86.3448)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 1.9023 (1.8587)  Acc@1: 50.0000 (52.4604)  Acc@5: 87.5000 (86.3971)  time: 0.2209  data: 0.0004  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:27  Loss: 1.8136 (1.8534)  Acc@1: 50.0000 (52.9221)  Acc@5: 87.5000 (86.4989)  time: 0.2207  data: 0.0005  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:25  Loss: 1.8492 (1.8544)  Acc@1: 56.2500 (52.8527)  Acc@5: 87.5000 (86.5145)  time: 0.2189  data: 0.0007  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 1.8779 (1.8501)  Acc@1: 56.2500 (53.0627)  Acc@5: 87.5000 (86.5289)  time: 0.2186  data: 0.0006  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 1.7590 (1.8485)  Acc@1: 56.2500 (53.0891)  Acc@5: 87.5000 (86.5661)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 1.7590 (1.8503)  Acc@1: 50.0000 (52.9520)  Acc@5: 87.5000 (86.4622)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:16  Loss: 1.7969 (1.8500)  Acc@1: 50.0000 (52.8915)  Acc@5: 87.5000 (86.4769)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 1.8741 (1.8517)  Acc@1: 50.0000 (52.7921)  Acc@5: 87.5000 (86.5120)  time: 0.2180  data: 0.0003  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 1.9699 (1.8519)  Acc@1: 50.0000 (52.8239)  Acc@5: 87.5000 (86.4826)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 1.7805 (1.8539)  Acc@1: 56.2500 (52.7934)  Acc@5: 87.5000 (86.5153)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 1.5820 (1.8428)  Acc@1: 62.5000 (53.2321)  Acc@5: 93.7500 (86.8185)  time: 0.2186  data: 0.0007  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:05  Loss: 1.5460 (1.8353)  Acc@1: 62.5000 (53.3610)  Acc@5: 93.7500 (86.9713)  time: 0.2193  data: 0.0015  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 1.4131 (1.8191)  Acc@1: 68.7500 (54.1239)  Acc@5: 93.7500 (87.2434)  time: 0.2188  data: 0.0011  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 1.3237 (1.8081)  Acc@1: 75.0000 (54.4338)  Acc@5: 100.0000 (87.5356)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 1.5933 (1.8102)  Acc@1: 50.0000 (54.3975)  Acc@5: 93.7500 (87.5000)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 1.7151 (1.8047)  Acc@1: 50.0000 (54.5654)  Acc@5: 87.5000 (87.6179)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 1.6750 (1.8064)  Acc@1: 62.5000 (54.6424)  Acc@5: 87.5000 (87.5656)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 1.7550 (1.8051)  Acc@1: 62.5000 (54.7474)  Acc@5: 87.5000 (87.6119)  time: 0.2196  data: 0.0010  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 1.4566 (1.7956)  Acc@1: 68.7500 (55.0966)  Acc@5: 93.7500 (87.8273)  time: 0.2186  data: 0.0010  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 1.4354 (1.7926)  Acc@1: 68.7500 (55.2616)  Acc@5: 93.7500 (87.9562)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 1.6974 (1.7927)  Acc@1: 56.2500 (55.2553)  Acc@5: 93.7500 (87.9454)  time: 0.2187  data: 0.0007  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 1.6974 (1.7892)  Acc@1: 56.2500 (55.3364)  Acc@5: 93.7500 (87.9930)  time: 0.2190  data: 0.0006  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 1.4352 (1.7814)  Acc@1: 56.2500 (55.5414)  Acc@5: 93.7500 (88.1803)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 1.4959 (1.7769)  Acc@1: 62.5000 (55.6541)  Acc@5: 100.0000 (88.3453)  time: 0.2184  data: 0.0005  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 1.5949 (1.7749)  Acc@1: 56.2500 (55.6399)  Acc@5: 93.7500 (88.4219)  time: 0.2186  data: 0.0005  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 1.8005 (1.7794)  Acc@1: 50.0000 (55.5334)  Acc@5: 87.5000 (88.3094)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 1.8438 (1.7778)  Acc@1: 56.2500 (55.5743)  Acc@5: 87.5000 (88.3706)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 1.6550 (1.7742)  Acc@1: 56.2500 (55.6772)  Acc@5: 93.7500 (88.4674)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 1.7383 (1.7759)  Acc@1: 56.2500 (55.6262)  Acc@5: 87.5000 (88.4232)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 1.8566 (1.7778)  Acc@1: 50.0000 (55.5528)  Acc@5: 87.5000 (88.3929)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 1.9390 (1.7861)  Acc@1: 50.0000 (55.4223)  Acc@5: 81.2500 (88.1838)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 2.0336 (1.7898)  Acc@1: 50.0000 (55.2731)  Acc@5: 81.2500 (88.1944)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 1.7443 (1.7891)  Acc@1: 50.0000 (55.2334)  Acc@5: 81.2500 (88.1585)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.3898 (1.7799)  Acc@1: 62.5000 (55.5581)  Acc@5: 93.7500 (88.3167)  time: 0.2190  data: 0.0007  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 1.3351 (1.7742)  Acc@1: 75.0000 (55.7932)  Acc@5: 93.7500 (88.4247)  time: 0.2189  data: 0.0007  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 1.5741 (1.7750)  Acc@1: 62.5000 (55.6918)  Acc@5: 93.7500 (88.4413)  time: 0.2203  data: 0.0004  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 1.6938 (1.7705)  Acc@1: 56.2500 (55.7982)  Acc@5: 93.7500 (88.5650)  time: 0.2205  data: 0.0004  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.4206 (1.7643)  Acc@1: 62.5000 (55.9433)  Acc@5: 93.7500 (88.6633)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.6157 (1.7680)  Acc@1: 62.5000 (55.8652)  Acc@5: 93.7500 (88.5607)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.0338 (1.7758)  Acc@1: 50.0000 (55.7181)  Acc@5: 75.0000 (88.2876)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 1.9325 (1.7734)  Acc@1: 50.0000 (55.8172)  Acc@5: 87.5000 (88.3655)  time: 0.2214  data: 0.0004  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.8190 (1.7736)  Acc@1: 56.2500 (55.8700)  Acc@5: 87.5000 (88.3500)  time: 0.2211  data: 0.0004  max mem: 2502
Test: [Task 2] Total time: 0:02:17 (0.2202 s / it)
* Acc@1 55.870 Acc@5 88.350 loss 1.774
Test: [Task 3]  [  0/625]  eta: 0:06:35  Loss: 0.2834 (0.2834)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6322  data: 0.4118  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:37  Loss: 0.2986 (0.3252)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (98.2955)  time: 0.2561  data: 0.0377  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:24  Loss: 0.2986 (0.3453)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (98.2143)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:18  Loss: 0.2504 (0.3274)  Acc@1: 100.0000 (95.9677)  Acc@5: 100.0000 (98.7903)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:14  Loss: 0.2018 (0.2945)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.0854)  time: 0.2199  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:11  Loss: 0.2018 (0.2888)  Acc@1: 100.0000 (96.3235)  Acc@5: 100.0000 (99.2647)  time: 0.2204  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:07  Loss: 0.2812 (0.2858)  Acc@1: 93.7500 (96.2090)  Acc@5: 100.0000 (99.3852)  time: 0.2202  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:05  Loss: 0.1938 (0.2755)  Acc@1: 93.7500 (96.2148)  Acc@5: 100.0000 (99.4718)  time: 0.2209  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:02  Loss: 0.1988 (0.2776)  Acc@1: 93.7500 (96.1420)  Acc@5: 100.0000 (99.4599)  time: 0.2214  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:02:00  Loss: 0.1992 (0.2781)  Acc@1: 100.0000 (96.2912)  Acc@5: 100.0000 (99.4505)  time: 0.2201  data: 0.0003  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:57  Loss: 0.2119 (0.2751)  Acc@1: 100.0000 (96.4109)  Acc@5: 100.0000 (99.4431)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:55  Loss: 0.1920 (0.2682)  Acc@1: 100.0000 (96.6216)  Acc@5: 100.0000 (99.4932)  time: 0.2210  data: 0.0008  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:52  Loss: 0.2181 (0.2697)  Acc@1: 100.0000 (96.6426)  Acc@5: 100.0000 (99.4835)  time: 0.2204  data: 0.0007  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:50  Loss: 0.2556 (0.2715)  Acc@1: 100.0000 (96.5649)  Acc@5: 100.0000 (99.5229)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:48  Loss: 0.3115 (0.2782)  Acc@1: 93.7500 (96.4539)  Acc@5: 100.0000 (99.3794)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:45  Loss: 0.3090 (0.2840)  Acc@1: 93.7500 (96.3990)  Acc@5: 100.0000 (99.3377)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:43  Loss: 0.2848 (0.2854)  Acc@1: 100.0000 (96.3898)  Acc@5: 100.0000 (99.2624)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:41  Loss: 0.2210 (0.2837)  Acc@1: 100.0000 (96.4547)  Acc@5: 100.0000 (99.3056)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:38  Loss: 0.2528 (0.2849)  Acc@1: 93.7500 (96.4088)  Acc@5: 100.0000 (99.2749)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:36  Loss: 0.2656 (0.2832)  Acc@1: 93.7500 (96.4660)  Acc@5: 100.0000 (99.3128)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:34  Loss: 0.2656 (0.2851)  Acc@1: 93.7500 (96.3619)  Acc@5: 100.0000 (99.2848)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:31  Loss: 0.2507 (0.2843)  Acc@1: 100.0000 (96.4455)  Acc@5: 100.0000 (99.2891)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:29  Loss: 0.2975 (0.2885)  Acc@1: 100.0000 (96.3235)  Acc@5: 100.0000 (99.2647)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:27  Loss: 0.3254 (0.2882)  Acc@1: 93.7500 (96.3745)  Acc@5: 100.0000 (99.2695)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:25  Loss: 0.2346 (0.2913)  Acc@1: 93.7500 (96.2656)  Acc@5: 100.0000 (99.2739)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:22  Loss: 0.2196 (0.2889)  Acc@1: 93.7500 (96.3396)  Acc@5: 100.0000 (99.2779)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:20  Loss: 0.2088 (0.2884)  Acc@1: 100.0000 (96.3123)  Acc@5: 100.0000 (99.2816)  time: 0.2182  data: 0.0007  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.2496 (0.2863)  Acc@1: 100.0000 (96.3561)  Acc@5: 100.0000 (99.3081)  time: 0.2186  data: 0.0007  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:16  Loss: 0.2496 (0.2860)  Acc@1: 100.0000 (96.3968)  Acc@5: 100.0000 (99.3327)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:13  Loss: 0.2840 (0.2852)  Acc@1: 93.7500 (96.3918)  Acc@5: 100.0000 (99.3557)  time: 0.2170  data: 0.0003  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.2464 (0.2858)  Acc@1: 93.7500 (96.3870)  Acc@5: 100.0000 (99.3563)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:09  Loss: 0.2340 (0.2876)  Acc@1: 93.7500 (96.3023)  Acc@5: 100.0000 (99.2765)  time: 0.2177  data: 0.0003  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.1694 (0.2850)  Acc@1: 93.7500 (96.3396)  Acc@5: 100.0000 (99.2991)  time: 0.2177  data: 0.0003  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:04  Loss: 0.2227 (0.2857)  Acc@1: 93.7500 (96.3180)  Acc@5: 100.0000 (99.3202)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:02  Loss: 0.2534 (0.2834)  Acc@1: 100.0000 (96.3893)  Acc@5: 100.0000 (99.3402)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.2281 (0.2834)  Acc@1: 100.0000 (96.3319)  Acc@5: 100.0000 (99.3412)  time: 0.2176  data: 0.0006  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.2947 (0.2861)  Acc@1: 93.7500 (96.2258)  Acc@5: 100.0000 (99.3075)  time: 0.2192  data: 0.0011  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.2705 (0.2871)  Acc@1: 93.7500 (96.1422)  Acc@5: 100.0000 (99.3093)  time: 0.2185  data: 0.0007  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.2323 (0.2860)  Acc@1: 93.7500 (96.1778)  Acc@5: 100.0000 (99.3274)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.2072 (0.2854)  Acc@1: 100.0000 (96.1797)  Acc@5: 100.0000 (99.3127)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.2111 (0.2841)  Acc@1: 93.7500 (96.1814)  Acc@5: 100.0000 (99.3298)  time: 0.2180  data: 0.0006  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.2811 (0.2858)  Acc@1: 93.7500 (96.1831)  Acc@5: 100.0000 (99.3309)  time: 0.2179  data: 0.0006  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:45  Loss: 0.3064 (0.2864)  Acc@1: 100.0000 (96.1847)  Acc@5: 100.0000 (99.3319)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.2760 (0.2867)  Acc@1: 93.7500 (96.1717)  Acc@5: 100.0000 (99.3329)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.3207 (0.2886)  Acc@1: 93.7500 (96.1310)  Acc@5: 100.0000 (99.3197)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.2620 (0.2887)  Acc@1: 100.0000 (96.1197)  Acc@5: 100.0000 (99.3210)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.2276 (0.2875)  Acc@1: 100.0000 (96.1497)  Acc@5: 100.0000 (99.3221)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.2276 (0.2880)  Acc@1: 93.7500 (96.0589)  Acc@5: 100.0000 (99.3232)  time: 0.2180  data: 0.0003  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.2718 (0.2885)  Acc@1: 93.7500 (96.0499)  Acc@5: 100.0000 (99.3113)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2838 (0.2887)  Acc@1: 93.7500 (96.0285)  Acc@5: 100.0000 (99.2999)  time: 0.2185  data: 0.0006  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2373 (0.2882)  Acc@1: 93.7500 (95.9955)  Acc@5: 100.0000 (99.3139)  time: 0.2184  data: 0.0006  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.2373 (0.2878)  Acc@1: 93.7500 (96.0127)  Acc@5: 100.0000 (99.3273)  time: 0.2177  data: 0.0003  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.2583 (0.2890)  Acc@1: 93.7500 (95.9813)  Acc@5: 100.0000 (99.3282)  time: 0.2189  data: 0.0006  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.3417 (0.2906)  Acc@1: 93.7500 (95.9275)  Acc@5: 100.0000 (99.3056)  time: 0.2191  data: 0.0007  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2907 (0.2918)  Acc@1: 93.7500 (95.9104)  Acc@5: 100.0000 (99.2837)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2907 (0.2922)  Acc@1: 93.7500 (95.9052)  Acc@5: 100.0000 (99.2627)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2528 (0.2923)  Acc@1: 100.0000 (95.9336)  Acc@5: 100.0000 (99.2536)  time: 0.2193  data: 0.0005  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.2528 (0.2927)  Acc@1: 100.0000 (95.9282)  Acc@5: 100.0000 (99.2447)  time: 0.2196  data: 0.0005  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2602 (0.2948)  Acc@1: 93.7500 (95.8907)  Acc@5: 100.0000 (99.2255)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.2592 (0.2939)  Acc@1: 100.0000 (95.9285)  Acc@5: 100.0000 (99.2386)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.2111 (0.2929)  Acc@1: 100.0000 (95.9339)  Acc@5: 100.0000 (99.2408)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.2111 (0.2921)  Acc@1: 100.0000 (95.9493)  Acc@5: 100.0000 (99.2533)  time: 0.2202  data: 0.0004  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2523 (0.2935)  Acc@1: 93.7500 (95.9038)  Acc@5: 100.0000 (99.2552)  time: 0.2201  data: 0.0003  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.2376 (0.2930)  Acc@1: 93.7500 (95.9100)  Acc@5: 100.0000 (99.2600)  time: 0.2201  data: 0.0003  max mem: 2502
Test: [Task 3] Total time: 0:02:17 (0.2197 s / it)
* Acc@1 95.910 Acc@5 99.260 loss 0.293
Test: [Task 4]  [ 0/29]  eta: 0:00:18  Loss: 2.4243 (2.4243)  Acc@1: 37.5000 (37.5000)  Acc@5: 75.0000 (75.0000)  time: 0.6478  data: 0.4272  max mem: 2502
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 2.5906 (2.3263)  Acc@1: 31.2500 (34.6591)  Acc@5: 68.7500 (76.7045)  time: 0.2581  data: 0.0391  max mem: 2502
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 2.6461 (2.6949)  Acc@1: 25.0000 (29.4643)  Acc@5: 62.5000 (60.7143)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 3.0182 (2.6188)  Acc@1: 18.7500 (31.5904)  Acc@5: 43.7500 (60.7843)  time: 0.2218  data: 0.0003  max mem: 2502
Test: [Task 4] Total time: 0:00:06 (0.2408 s / it)
* Acc@1 31.590 Acc@5 60.784 loss 2.619
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 16, 5: 16, 6: 16, 7: 16, 8: 0, 9: 0, 10: 0, 11: 0, 12: 9984, 13: 9984, 14: 9984, 15: 9984, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 48, 5: 48, 6: 48, 7: 48, 8: 0, 9: 0, 10: 0, 11: 0, 12: 411, 13: 411, 14: 411, 15: 411, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task4]	Acc@1: 62.5749	Acc@5: 84.5258	Loss: 1.5370	Forgetting: 16.2291	Backward: -16.2291
Train: Epoch[1/1]  [   0/3750]  eta: 0:47:34  Lr: 0.001875  Loss: 1.2911  Acc@1: 6.2500 (6.2500)  Acc@5: 37.5000 (37.5000)  time: 0.7612  data: 0.3915  max mem: 2502
Train: Epoch[1/1]  [  10/3750]  eta: 0:24:12  Lr: 0.001875  Loss: 1.1629  Acc@1: 18.7500 (15.9091)  Acc@5: 62.5000 (56.8182)  time: 0.3883  data: 0.0360  max mem: 2503
Train: Epoch[1/1]  [  20/3750]  eta: 0:23:06  Lr: 0.001875  Loss: 0.8247  Acc@1: 25.0000 (29.4643)  Acc@5: 68.7500 (72.3214)  time: 0.3523  data: 0.0009  max mem: 2503
Train: Epoch[1/1]  [  30/3750]  eta: 0:22:39  Lr: 0.001875  Loss: 0.6759  Acc@1: 43.7500 (35.8871)  Acc@5: 87.5000 (78.2258)  time: 0.3528  data: 0.0009  max mem: 2503
Train: Epoch[1/1]  [  40/3750]  eta: 0:22:23  Lr: 0.001875  Loss: 0.4066  Acc@1: 56.2500 (41.0061)  Acc@5: 93.7500 (82.0122)  time: 0.3522  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [  50/3750]  eta: 0:22:12  Lr: 0.001875  Loss: 0.2285  Acc@1: 56.2500 (43.9951)  Acc@5: 93.7500 (83.5784)  time: 0.3518  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [  60/3750]  eta: 0:22:03  Lr: 0.001875  Loss: 0.5978  Acc@1: 56.2500 (46.5164)  Acc@5: 93.7500 (85.3484)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [  70/3750]  eta: 0:21:57  Lr: 0.001875  Loss: 0.4156  Acc@1: 62.5000 (49.1197)  Acc@5: 93.7500 (86.9718)  time: 0.3531  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [  80/3750]  eta: 0:21:51  Lr: 0.001875  Loss: 0.0984  Acc@1: 62.5000 (50.3858)  Acc@5: 100.0000 (88.1944)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [  90/3750]  eta: 0:21:46  Lr: 0.001875  Loss: 0.2654  Acc@1: 62.5000 (52.4725)  Acc@5: 100.0000 (89.0110)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 100/3750]  eta: 0:21:41  Lr: 0.001875  Loss: 0.0620  Acc@1: 68.7500 (54.0223)  Acc@5: 100.0000 (89.6658)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 110/3750]  eta: 0:21:37  Lr: 0.001875  Loss: 0.0613  Acc@1: 75.0000 (55.7432)  Acc@5: 93.7500 (90.2590)  time: 0.3540  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 120/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.0950  Acc@1: 68.7500 (56.5599)  Acc@5: 93.7500 (90.7541)  time: 0.3533  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 130/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.1038  Acc@1: 62.5000 (57.3950)  Acc@5: 100.0000 (91.1737)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 140/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -0.3755  Acc@1: 62.5000 (57.8457)  Acc@5: 100.0000 (91.5337)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 150/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.2928  Acc@1: 62.5000 (58.2781)  Acc@5: 93.7500 (91.7219)  time: 0.3535  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 160/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.0132  Acc@1: 68.7500 (58.9286)  Acc@5: 93.7500 (91.9643)  time: 0.3553  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 170/3750]  eta: 0:21:11  Lr: 0.001875  Loss: 0.0538  Acc@1: 68.7500 (59.1374)  Acc@5: 93.7500 (92.2880)  time: 0.3543  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 180/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.1874  Acc@1: 75.0000 (59.8757)  Acc@5: 100.0000 (92.6105)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 190/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.2856  Acc@1: 75.0000 (60.3730)  Acc@5: 100.0000 (92.8665)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 200/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.4860  Acc@1: 68.7500 (61.0386)  Acc@5: 100.0000 (93.0659)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 210/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.1887  Acc@1: 68.7500 (61.5225)  Acc@5: 100.0000 (93.2168)  time: 0.3531  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [ 220/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.2843  Acc@1: 68.7500 (61.9910)  Acc@5: 93.7500 (93.3258)  time: 0.3522  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [ 230/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.3265  Acc@1: 68.7500 (62.0400)  Acc@5: 100.0000 (93.5335)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 240/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.3486  Acc@1: 62.5000 (62.2407)  Acc@5: 100.0000 (93.6722)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 250/3750]  eta: 0:20:40  Lr: 0.001875  Loss: 0.0524  Acc@1: 68.7500 (62.4253)  Acc@5: 93.7500 (93.7500)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 260/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -0.4689  Acc@1: 68.7500 (62.7634)  Acc@5: 93.7500 (93.8697)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 270/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.2154  Acc@1: 68.7500 (62.8690)  Acc@5: 100.0000 (94.0037)  time: 0.3521  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 280/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.2231  Acc@1: 68.7500 (63.2340)  Acc@5: 93.7500 (94.0391)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 290/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.4760  Acc@1: 68.7500 (63.3162)  Acc@5: 93.7500 (94.1581)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 300/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.5372  Acc@1: 68.7500 (63.4344)  Acc@5: 100.0000 (94.2691)  time: 0.3511  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 310/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.5937  Acc@1: 68.7500 (63.4445)  Acc@5: 100.0000 (94.3931)  time: 0.3533  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [ 320/3750]  eta: 0:20:13  Lr: 0.001875  Loss: 0.0742  Acc@1: 68.7500 (63.5903)  Acc@5: 100.0000 (94.5288)  time: 0.3533  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [ 330/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.6071  Acc@1: 68.7500 (63.9728)  Acc@5: 100.0000 (94.6563)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 340/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.2632  Acc@1: 68.7500 (64.0946)  Acc@5: 100.0000 (94.7397)  time: 0.3546  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [ 350/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.4947  Acc@1: 68.7500 (64.3875)  Acc@5: 100.0000 (94.8362)  time: 0.3544  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [ 360/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.5475  Acc@1: 68.7500 (64.6122)  Acc@5: 100.0000 (94.8753)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 370/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.6225  Acc@1: 68.7500 (64.8248)  Acc@5: 100.0000 (94.9798)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 380/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.8428  Acc@1: 68.7500 (65.0262)  Acc@5: 100.0000 (95.0623)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 390/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -0.4898  Acc@1: 75.0000 (65.3453)  Acc@5: 100.0000 (95.0927)  time: 0.3522  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 400/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.0629  Acc@1: 75.0000 (65.5549)  Acc@5: 100.0000 (95.1527)  time: 0.3525  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 410/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.3187  Acc@1: 68.7500 (65.5870)  Acc@5: 100.0000 (95.2251)  time: 0.3521  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 420/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.0208  Acc@1: 68.7500 (65.6770)  Acc@5: 100.0000 (95.2939)  time: 0.3531  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 430/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.4321  Acc@1: 68.7500 (65.8498)  Acc@5: 100.0000 (95.3741)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 440/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.2012  Acc@1: 68.7500 (65.9014)  Acc@5: 100.0000 (95.4507)  time: 0.3542  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 450/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.1939  Acc@1: 68.7500 (65.9784)  Acc@5: 100.0000 (95.4823)  time: 0.3536  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 460/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.2743  Acc@1: 75.0000 (66.2554)  Acc@5: 100.0000 (95.5125)  time: 0.3515  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [ 470/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.5842  Acc@1: 75.0000 (66.4013)  Acc@5: 93.7500 (95.5281)  time: 0.3520  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [ 480/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.2750  Acc@1: 68.7500 (66.4111)  Acc@5: 100.0000 (95.5301)  time: 0.3522  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [ 490/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.7583  Acc@1: 68.7500 (66.4842)  Acc@5: 100.0000 (95.5830)  time: 0.3519  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [ 500/3750]  eta: 0:19:08  Lr: 0.001875  Loss: 0.0391  Acc@1: 68.7500 (66.4671)  Acc@5: 93.7500 (95.5838)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 510/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.3112  Acc@1: 68.7500 (66.5484)  Acc@5: 93.7500 (95.6213)  time: 0.3521  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 520/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.5126  Acc@1: 68.7500 (66.6387)  Acc@5: 100.0000 (95.6094)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 530/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.5461  Acc@1: 68.7500 (66.7491)  Acc@5: 100.0000 (95.6803)  time: 0.3516  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 540/3750]  eta: 0:18:53  Lr: 0.001875  Loss: 0.0609  Acc@1: 68.7500 (66.7052)  Acc@5: 100.0000 (95.7255)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 550/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.4140  Acc@1: 62.5000 (66.7423)  Acc@5: 100.0000 (95.7237)  time: 0.3514  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 560/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.5306  Acc@1: 75.0000 (66.9006)  Acc@5: 93.7500 (95.7331)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 570/3750]  eta: 0:18:42  Lr: 0.001875  Loss: 0.2778  Acc@1: 75.0000 (66.9877)  Acc@5: 100.0000 (95.7750)  time: 0.3516  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 580/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.0676  Acc@1: 68.7500 (67.0396)  Acc@5: 100.0000 (95.7939)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 590/3750]  eta: 0:18:35  Lr: 0.001875  Loss: 0.0482  Acc@1: 68.7500 (67.0157)  Acc@5: 100.0000 (95.8228)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 600/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.4394  Acc@1: 68.7500 (67.1069)  Acc@5: 100.0000 (95.8507)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 610/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.4384  Acc@1: 68.7500 (67.1645)  Acc@5: 100.0000 (95.8777)  time: 0.3541  data: 0.0013  max mem: 2503
Train: Epoch[1/1]  [ 620/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.3148  Acc@1: 68.7500 (67.2605)  Acc@5: 100.0000 (95.9340)  time: 0.3541  data: 0.0014  max mem: 2503
Train: Epoch[1/1]  [ 630/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.4150  Acc@1: 75.0000 (67.4128)  Acc@5: 100.0000 (95.9786)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 640/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.2639  Acc@1: 68.7500 (67.4727)  Acc@5: 100.0000 (96.0121)  time: 0.3534  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 650/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.1206  Acc@1: 68.7500 (67.5211)  Acc@5: 100.0000 (96.0349)  time: 0.3581  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 660/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.5738  Acc@1: 68.7500 (67.6059)  Acc@5: 100.0000 (96.0477)  time: 0.3573  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 670/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.8489  Acc@1: 68.7500 (67.6323)  Acc@5: 100.0000 (96.0507)  time: 0.3521  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 680/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.6784  Acc@1: 68.7500 (67.6395)  Acc@5: 100.0000 (96.0720)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 690/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.6813  Acc@1: 68.7500 (67.7641)  Acc@5: 100.0000 (96.1107)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 700/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.2491  Acc@1: 75.0000 (67.8495)  Acc@5: 100.0000 (96.1394)  time: 0.3537  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 710/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.7118  Acc@1: 75.0000 (68.0116)  Acc@5: 100.0000 (96.1850)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 720/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.3130  Acc@1: 75.0000 (67.9785)  Acc@5: 100.0000 (96.1772)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 730/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.2017  Acc@1: 68.7500 (68.0233)  Acc@5: 93.7500 (96.2038)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 740/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.5766  Acc@1: 75.0000 (68.1511)  Acc@5: 100.0000 (96.2213)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 750/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.8183  Acc@1: 81.2500 (68.2423)  Acc@5: 100.0000 (96.2467)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 760/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.3300  Acc@1: 68.7500 (68.2572)  Acc@5: 100.0000 (96.2549)  time: 0.3514  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 770/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.7340  Acc@1: 75.0000 (68.3771)  Acc@5: 100.0000 (96.2792)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 780/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.8176  Acc@1: 75.0000 (68.4699)  Acc@5: 100.0000 (96.2948)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 790/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.7387  Acc@1: 75.0000 (68.4814)  Acc@5: 100.0000 (96.3101)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 800/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -0.4877  Acc@1: 75.0000 (68.5939)  Acc@5: 100.0000 (96.3327)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 810/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.6265  Acc@1: 75.0000 (68.6190)  Acc@5: 100.0000 (96.3702)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 820/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -0.5453  Acc@1: 68.7500 (68.6434)  Acc@5: 100.0000 (96.3840)  time: 0.3521  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 830/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.5518  Acc@1: 75.0000 (68.7575)  Acc@5: 100.0000 (96.4125)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 840/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.2907  Acc@1: 75.0000 (68.7872)  Acc@5: 100.0000 (96.4254)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 850/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.2382  Acc@1: 68.7500 (68.8675)  Acc@5: 100.0000 (96.4454)  time: 0.3521  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 860/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.5838  Acc@1: 68.7500 (68.8807)  Acc@5: 100.0000 (96.4649)  time: 0.3526  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 870/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.3482  Acc@1: 75.0000 (68.9653)  Acc@5: 100.0000 (96.4839)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [ 880/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.2379  Acc@1: 75.0000 (68.9699)  Acc@5: 100.0000 (96.5096)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [ 890/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.4052  Acc@1: 75.0000 (69.0867)  Acc@5: 100.0000 (96.5067)  time: 0.3521  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 900/3750]  eta: 0:16:46  Lr: 0.001875  Loss: 0.1911  Acc@1: 75.0000 (69.1107)  Acc@5: 100.0000 (96.5108)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 910/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.8201  Acc@1: 68.7500 (69.1411)  Acc@5: 100.0000 (96.5491)  time: 0.3533  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 920/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.3360  Acc@1: 68.7500 (69.1911)  Acc@5: 100.0000 (96.5662)  time: 0.3538  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 930/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.2044  Acc@1: 75.0000 (69.2468)  Acc@5: 100.0000 (96.5897)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 940/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.4798  Acc@1: 75.0000 (69.3478)  Acc@5: 100.0000 (96.5994)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 950/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.6220  Acc@1: 75.0000 (69.3612)  Acc@5: 100.0000 (96.6351)  time: 0.3518  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [ 960/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.7255  Acc@1: 68.7500 (69.4134)  Acc@5: 100.0000 (96.6376)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 970/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.3051  Acc@1: 75.0000 (69.4516)  Acc@5: 100.0000 (96.6401)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 980/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.4429  Acc@1: 75.0000 (69.5400)  Acc@5: 100.0000 (96.6743)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [ 990/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.5430  Acc@1: 75.0000 (69.5951)  Acc@5: 100.0000 (96.6953)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1000/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.3194  Acc@1: 68.7500 (69.6054)  Acc@5: 100.0000 (96.6908)  time: 0.3515  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1010/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.2282  Acc@1: 75.0000 (69.6588)  Acc@5: 100.0000 (96.7050)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1020/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.4907  Acc@1: 68.7500 (69.6560)  Acc@5: 100.0000 (96.7067)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1030/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.6125  Acc@1: 68.7500 (69.7321)  Acc@5: 100.0000 (96.7325)  time: 0.3531  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1040/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.2030  Acc@1: 75.0000 (69.7767)  Acc@5: 100.0000 (96.7519)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1050/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.6760  Acc@1: 75.0000 (69.8799)  Acc@5: 100.0000 (96.7531)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1060/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -0.5782  Acc@1: 75.0000 (69.8574)  Acc@5: 100.0000 (96.7660)  time: 0.3541  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [1070/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -0.6521  Acc@1: 75.0000 (69.9113)  Acc@5: 100.0000 (96.7729)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [1080/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.6473  Acc@1: 75.0000 (69.9237)  Acc@5: 100.0000 (96.7912)  time: 0.3516  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1090/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.2710  Acc@1: 75.0000 (69.9358)  Acc@5: 100.0000 (96.7977)  time: 0.3513  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1100/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.1968  Acc@1: 68.7500 (69.9364)  Acc@5: 100.0000 (96.7870)  time: 0.3544  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1110/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.4395  Acc@1: 75.0000 (70.0270)  Acc@5: 100.0000 (96.8103)  time: 0.3544  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1120/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.5080  Acc@1: 75.0000 (70.0881)  Acc@5: 100.0000 (96.8332)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1130/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.5158  Acc@1: 75.0000 (70.1039)  Acc@5: 100.0000 (96.8501)  time: 0.3516  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1140/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.3881  Acc@1: 75.0000 (70.1797)  Acc@5: 100.0000 (96.8668)  time: 0.3520  data: 0.0011  max mem: 2503
Train: Epoch[1/1]  [1150/3750]  eta: 0:15:17  Lr: 0.001875  Loss: 0.0643  Acc@1: 75.0000 (70.1781)  Acc@5: 100.0000 (96.8831)  time: 0.3522  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [1160/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -0.6736  Acc@1: 75.0000 (70.2143)  Acc@5: 100.0000 (96.8885)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1170/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.1475  Acc@1: 75.0000 (70.2124)  Acc@5: 100.0000 (96.8937)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1180/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.4956  Acc@1: 75.0000 (70.2688)  Acc@5: 100.0000 (96.9094)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1190/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -0.3604  Acc@1: 75.0000 (70.2981)  Acc@5: 100.0000 (96.9091)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1200/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.3594  Acc@1: 75.0000 (70.3268)  Acc@5: 100.0000 (96.9140)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1210/3750]  eta: 0:14:56  Lr: 0.001875  Loss: 0.0945  Acc@1: 75.0000 (70.3293)  Acc@5: 100.0000 (96.9189)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1220/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.6109  Acc@1: 75.0000 (70.3726)  Acc@5: 100.0000 (96.9287)  time: 0.3515  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1230/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.0521  Acc@1: 75.0000 (70.4001)  Acc@5: 100.0000 (96.9334)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1240/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.8659  Acc@1: 75.0000 (70.3969)  Acc@5: 100.0000 (96.9329)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1250/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.9001  Acc@1: 75.0000 (70.4436)  Acc@5: 100.0000 (96.9524)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1260/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -0.6915  Acc@1: 75.0000 (70.4946)  Acc@5: 100.0000 (96.9667)  time: 0.3520  data: 0.0011  max mem: 2503
Train: Epoch[1/1]  [1270/3750]  eta: 0:14:34  Lr: 0.001875  Loss: 0.1185  Acc@1: 75.0000 (70.5252)  Acc@5: 100.0000 (96.9660)  time: 0.3520  data: 0.0016  max mem: 2503
Train: Epoch[1/1]  [1280/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.8952  Acc@1: 75.0000 (70.5699)  Acc@5: 100.0000 (96.9848)  time: 0.3525  data: 0.0016  max mem: 2503
Train: Epoch[1/1]  [1290/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.6669  Acc@1: 75.0000 (70.6139)  Acc@5: 100.0000 (96.9839)  time: 0.3538  data: 0.0011  max mem: 2503
Train: Epoch[1/1]  [1300/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.2808  Acc@1: 75.0000 (70.6091)  Acc@5: 100.0000 (96.9879)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1310/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.1172  Acc@1: 68.7500 (70.6140)  Acc@5: 100.0000 (96.9823)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1320/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.5071  Acc@1: 68.7500 (70.6709)  Acc@5: 100.0000 (96.9909)  time: 0.3519  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [1330/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.6898  Acc@1: 68.7500 (70.6705)  Acc@5: 100.0000 (96.9994)  time: 0.3541  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [1340/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.3394  Acc@1: 68.7500 (70.7028)  Acc@5: 100.0000 (97.0032)  time: 0.3537  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1350/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.5311  Acc@1: 75.0000 (70.7023)  Acc@5: 100.0000 (97.0207)  time: 0.3526  data: 0.0014  max mem: 2503
Train: Epoch[1/1]  [1360/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -0.8636  Acc@1: 68.7500 (70.7247)  Acc@5: 100.0000 (97.0242)  time: 0.3532  data: 0.0021  max mem: 2503
Train: Epoch[1/1]  [1370/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.4884  Acc@1: 75.0000 (70.7148)  Acc@5: 100.0000 (97.0323)  time: 0.3524  data: 0.0011  max mem: 2503
Train: Epoch[1/1]  [1380/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.2771  Acc@1: 75.0000 (70.7413)  Acc@5: 100.0000 (97.0402)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1390/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.7992  Acc@1: 75.0000 (70.8034)  Acc@5: 100.0000 (97.0525)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1400/3750]  eta: 0:13:48  Lr: 0.001875  Loss: 0.0059  Acc@1: 81.2500 (70.8512)  Acc@5: 100.0000 (97.0601)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1410/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.4322  Acc@1: 75.0000 (70.8584)  Acc@5: 100.0000 (97.0588)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1420/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.4982  Acc@1: 68.7500 (70.8700)  Acc@5: 100.0000 (97.0619)  time: 0.3535  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1430/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.7222  Acc@1: 75.0000 (70.9382)  Acc@5: 100.0000 (97.0781)  time: 0.3537  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1440/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.7888  Acc@1: 75.0000 (70.9663)  Acc@5: 100.0000 (97.0854)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1450/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.3823  Acc@1: 75.0000 (70.9898)  Acc@5: 100.0000 (97.0925)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1460/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.4869  Acc@1: 75.0000 (71.0258)  Acc@5: 100.0000 (97.0910)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1470/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.5902  Acc@1: 75.0000 (71.0359)  Acc@5: 100.0000 (97.1023)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1480/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.4019  Acc@1: 75.0000 (71.0964)  Acc@5: 100.0000 (97.1092)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1490/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.7884  Acc@1: 75.0000 (71.1184)  Acc@5: 100.0000 (97.1202)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1500/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.6002  Acc@1: 75.0000 (71.1651)  Acc@5: 100.0000 (97.1269)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1510/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.7732  Acc@1: 81.2500 (71.2194)  Acc@5: 100.0000 (97.1418)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1520/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.6993  Acc@1: 68.7500 (71.2032)  Acc@5: 100.0000 (97.1483)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1530/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.5695  Acc@1: 68.7500 (71.2157)  Acc@5: 100.0000 (97.1628)  time: 0.3518  data: 0.0015  max mem: 2503
Train: Epoch[1/1]  [1540/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.6263  Acc@1: 75.0000 (71.2484)  Acc@5: 100.0000 (97.1731)  time: 0.3528  data: 0.0015  max mem: 2503
Train: Epoch[1/1]  [1550/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.5876  Acc@1: 75.0000 (71.2726)  Acc@5: 100.0000 (97.1873)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1560/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.5991  Acc@1: 75.0000 (71.3004)  Acc@5: 100.0000 (97.1933)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1570/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.5813  Acc@1: 68.7500 (71.3001)  Acc@5: 100.0000 (97.1953)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1580/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.4943  Acc@1: 68.7500 (71.3077)  Acc@5: 100.0000 (97.2051)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1590/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.5182  Acc@1: 75.0000 (71.3270)  Acc@5: 100.0000 (97.2109)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1600/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.6443  Acc@1: 75.0000 (71.3695)  Acc@5: 100.0000 (97.2088)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1610/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.6830  Acc@1: 75.0000 (71.3726)  Acc@5: 100.0000 (97.2028)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1620/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.5728  Acc@1: 75.0000 (71.3718)  Acc@5: 100.0000 (97.2008)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1630/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.6790  Acc@1: 68.7500 (71.3749)  Acc@5: 100.0000 (97.2103)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1640/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.8003  Acc@1: 75.0000 (71.4275)  Acc@5: 100.0000 (97.2044)  time: 0.3513  data: 0.0009  max mem: 2503
Train: Epoch[1/1]  [1650/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.4069  Acc@1: 81.2500 (71.4643)  Acc@5: 100.0000 (97.2176)  time: 0.3509  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [1660/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.1525  Acc@1: 75.0000 (71.4780)  Acc@5: 100.0000 (97.2268)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1670/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.0761  Acc@1: 68.7500 (71.4692)  Acc@5: 100.0000 (97.2359)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1680/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.3325  Acc@1: 68.7500 (71.4642)  Acc@5: 100.0000 (97.2338)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1690/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.0502  Acc@1: 75.0000 (71.5109)  Acc@5: 100.0000 (97.2428)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1700/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.6475  Acc@1: 75.0000 (71.5351)  Acc@5: 100.0000 (97.2443)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1710/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.2015  Acc@1: 75.0000 (71.5809)  Acc@5: 100.0000 (97.2421)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1720/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.8464  Acc@1: 75.0000 (71.5863)  Acc@5: 100.0000 (97.2400)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1730/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.6768  Acc@1: 75.0000 (71.5916)  Acc@5: 100.0000 (97.2415)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1740/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.6279  Acc@1: 75.0000 (71.6076)  Acc@5: 100.0000 (97.2394)  time: 0.3507  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1750/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.7888  Acc@1: 81.2500 (71.6591)  Acc@5: 100.0000 (97.2444)  time: 0.3519  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [1760/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.3919  Acc@1: 81.2500 (71.6674)  Acc@5: 100.0000 (97.2530)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1770/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -0.4970  Acc@1: 75.0000 (71.6968)  Acc@5: 100.0000 (97.2614)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1780/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.3674  Acc@1: 75.0000 (71.7223)  Acc@5: 100.0000 (97.2733)  time: 0.3532  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1790/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.7373  Acc@1: 81.2500 (71.7616)  Acc@5: 100.0000 (97.2711)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1800/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.3814  Acc@1: 75.0000 (71.7310)  Acc@5: 100.0000 (97.2793)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1810/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.3490  Acc@1: 68.7500 (71.7594)  Acc@5: 100.0000 (97.2909)  time: 0.3514  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1820/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.5284  Acc@1: 81.2500 (71.8046)  Acc@5: 100.0000 (97.3023)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1830/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.3936  Acc@1: 75.0000 (71.8050)  Acc@5: 100.0000 (97.3170)  time: 0.3546  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1840/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.3070  Acc@1: 75.0000 (71.8394)  Acc@5: 100.0000 (97.3282)  time: 0.3548  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1850/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -0.6761  Acc@1: 75.0000 (71.8531)  Acc@5: 100.0000 (97.3359)  time: 0.3538  data: 0.0009  max mem: 2503
Train: Epoch[1/1]  [1860/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.2476  Acc@1: 75.0000 (71.8901)  Acc@5: 100.0000 (97.3401)  time: 0.3534  data: 0.0009  max mem: 2503
Train: Epoch[1/1]  [1870/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.4018  Acc@1: 75.0000 (71.9168)  Acc@5: 100.0000 (97.3510)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1880/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -0.7127  Acc@1: 75.0000 (71.9464)  Acc@5: 100.0000 (97.3518)  time: 0.3541  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [1890/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.6179  Acc@1: 81.2500 (71.9857)  Acc@5: 100.0000 (97.3559)  time: 0.3540  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [1900/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.4315  Acc@1: 81.2500 (72.0049)  Acc@5: 100.0000 (97.3534)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1910/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.6735  Acc@1: 68.7500 (71.9878)  Acc@5: 100.0000 (97.3541)  time: 0.3533  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1920/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.3635  Acc@1: 75.0000 (72.0295)  Acc@5: 100.0000 (97.3647)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1930/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.3296  Acc@1: 81.2500 (72.0643)  Acc@5: 100.0000 (97.3718)  time: 0.3555  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1940/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.6884  Acc@1: 75.0000 (72.1052)  Acc@5: 100.0000 (97.3789)  time: 0.3548  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1950/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4774  Acc@1: 75.0000 (72.1169)  Acc@5: 100.0000 (97.3828)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1960/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -0.5044  Acc@1: 75.0000 (72.1411)  Acc@5: 100.0000 (97.3929)  time: 0.3543  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [1970/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -0.9718  Acc@1: 75.0000 (72.1905)  Acc@5: 100.0000 (97.3998)  time: 0.3539  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [1980/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.3477  Acc@1: 75.0000 (72.1984)  Acc@5: 100.0000 (97.4129)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [1990/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.5352  Acc@1: 75.0000 (72.2470)  Acc@5: 100.0000 (97.4134)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [2000/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -0.3676  Acc@1: 81.2500 (72.2951)  Acc@5: 100.0000 (97.4200)  time: 0.3538  data: 0.0010  max mem: 2503
Train: Epoch[1/1]  [2010/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.6601  Acc@1: 75.0000 (72.2899)  Acc@5: 100.0000 (97.4235)  time: 0.3529  data: 0.0010  max mem: 2503
Train: Epoch[1/1]  [2020/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -0.1488  Acc@1: 75.0000 (72.3002)  Acc@5: 100.0000 (97.4301)  time: 0.3544  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2030/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.2649  Acc@1: 75.0000 (72.3289)  Acc@5: 100.0000 (97.4305)  time: 0.3540  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2040/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.6490  Acc@1: 75.0000 (72.3542)  Acc@5: 100.0000 (97.4339)  time: 0.3535  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2050/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.7426  Acc@1: 75.0000 (72.3732)  Acc@5: 100.0000 (97.4403)  time: 0.3553  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2060/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.8477  Acc@1: 81.2500 (72.4072)  Acc@5: 100.0000 (97.4375)  time: 0.3539  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2070/3750]  eta: 0:09:52  Lr: 0.001875  Loss: 0.0149  Acc@1: 81.2500 (72.4107)  Acc@5: 100.0000 (97.4469)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2080/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.4632  Acc@1: 75.0000 (72.4201)  Acc@5: 100.0000 (97.4531)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2090/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.6806  Acc@1: 75.0000 (72.4504)  Acc@5: 100.0000 (97.4653)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2100/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.7637  Acc@1: 75.0000 (72.4566)  Acc@5: 100.0000 (97.4685)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2110/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.4101  Acc@1: 75.0000 (72.4775)  Acc@5: 100.0000 (97.4745)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2120/3750]  eta: 0:09:34  Lr: 0.001875  Loss: 0.0166  Acc@1: 75.0000 (72.4776)  Acc@5: 100.0000 (97.4776)  time: 0.3515  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2130/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.6778  Acc@1: 75.0000 (72.4806)  Acc@5: 100.0000 (97.4806)  time: 0.3510  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2140/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.7738  Acc@1: 68.7500 (72.4661)  Acc@5: 100.0000 (97.4837)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2150/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.4393  Acc@1: 68.7500 (72.4634)  Acc@5: 100.0000 (97.4866)  time: 0.3522  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2160/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.4206  Acc@1: 75.0000 (72.5069)  Acc@5: 100.0000 (97.4896)  time: 0.3525  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2170/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.5556  Acc@1: 81.2500 (72.5271)  Acc@5: 100.0000 (97.4983)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2180/3750]  eta: 0:09:13  Lr: 0.001875  Loss: 0.0412  Acc@1: 81.2500 (72.5269)  Acc@5: 100.0000 (97.5011)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2190/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.6069  Acc@1: 75.0000 (72.5553)  Acc@5: 100.0000 (97.5040)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2200/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.3990  Acc@1: 75.0000 (72.5466)  Acc@5: 100.0000 (97.5068)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2210/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.8625  Acc@1: 68.7500 (72.5351)  Acc@5: 100.0000 (97.5068)  time: 0.3524  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2220/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.6609  Acc@1: 75.0000 (72.5518)  Acc@5: 100.0000 (97.5124)  time: 0.3522  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2230/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.4387  Acc@1: 75.0000 (72.5375)  Acc@5: 100.0000 (97.5151)  time: 0.3510  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2240/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.5514  Acc@1: 75.0000 (72.5513)  Acc@5: 100.0000 (97.5095)  time: 0.3512  data: 0.0002  max mem: 2503
Train: Epoch[1/1]  [2250/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.6625  Acc@1: 75.0000 (72.5539)  Acc@5: 100.0000 (97.5150)  time: 0.3523  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2260/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.8305  Acc@1: 75.0000 (72.5951)  Acc@5: 100.0000 (97.5232)  time: 0.3540  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2270/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.4316  Acc@1: 75.0000 (72.6249)  Acc@5: 100.0000 (97.5286)  time: 0.3547  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [2280/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.3982  Acc@1: 75.0000 (72.6354)  Acc@5: 100.0000 (97.5285)  time: 0.3543  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [2290/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.7942  Acc@1: 81.2500 (72.6648)  Acc@5: 100.0000 (97.5256)  time: 0.3537  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2300/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.4770  Acc@1: 81.2500 (72.6641)  Acc@5: 100.0000 (97.5228)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [2310/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.4743  Acc@1: 75.0000 (72.6796)  Acc@5: 100.0000 (97.5227)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2320/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.2192  Acc@1: 75.0000 (72.6788)  Acc@5: 100.0000 (97.5280)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2330/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.4829  Acc@1: 75.0000 (72.6941)  Acc@5: 100.0000 (97.5359)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2340/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.1543  Acc@1: 75.0000 (72.6880)  Acc@5: 100.0000 (97.5411)  time: 0.3521  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2350/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.5980  Acc@1: 75.0000 (72.7058)  Acc@5: 100.0000 (97.5409)  time: 0.3511  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2360/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.8826  Acc@1: 75.0000 (72.7261)  Acc@5: 100.0000 (97.5461)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2370/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.7101  Acc@1: 81.2500 (72.7541)  Acc@5: 100.0000 (97.5564)  time: 0.3507  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2380/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.3953  Acc@1: 75.0000 (72.7583)  Acc@5: 100.0000 (97.5588)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2390/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6676  Acc@1: 68.7500 (72.7651)  Acc@5: 100.0000 (97.5638)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2400/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.7057  Acc@1: 75.0000 (72.7796)  Acc@5: 100.0000 (97.5661)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2410/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.6363  Acc@1: 75.0000 (72.7991)  Acc@5: 100.0000 (97.5684)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2420/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.1119  Acc@1: 75.0000 (72.8082)  Acc@5: 100.0000 (97.5656)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2430/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.0514  Acc@1: 81.2500 (72.8301)  Acc@5: 100.0000 (97.5730)  time: 0.3536  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2440/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.8566  Acc@1: 81.2500 (72.8544)  Acc@5: 100.0000 (97.5753)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2450/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.5228  Acc@1: 75.0000 (72.8606)  Acc@5: 100.0000 (97.5801)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2460/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.1985  Acc@1: 68.7500 (72.8616)  Acc@5: 100.0000 (97.5848)  time: 0.3529  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2470/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.6389  Acc@1: 75.0000 (72.8956)  Acc@5: 100.0000 (97.5895)  time: 0.3533  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2480/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.7358  Acc@1: 75.0000 (72.9167)  Acc@5: 100.0000 (97.5942)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2490/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.4817  Acc@1: 75.0000 (72.9351)  Acc@5: 100.0000 (97.5938)  time: 0.3543  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2500/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.5983  Acc@1: 81.2500 (72.9658)  Acc@5: 100.0000 (97.6010)  time: 0.3553  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2510/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.9522  Acc@1: 75.0000 (72.9714)  Acc@5: 100.0000 (97.6080)  time: 0.3543  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2520/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.5186  Acc@1: 75.0000 (72.9844)  Acc@5: 100.0000 (97.6076)  time: 0.3525  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2530/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.4767  Acc@1: 75.0000 (73.0047)  Acc@5: 100.0000 (97.6121)  time: 0.3535  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2540/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.6057  Acc@1: 81.2500 (73.0274)  Acc@5: 100.0000 (97.6166)  time: 0.3537  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2550/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.6566  Acc@1: 81.2500 (73.0522)  Acc@5: 100.0000 (97.6259)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2560/3750]  eta: 0:06:59  Lr: 0.001875  Loss: 0.0513  Acc@1: 81.2500 (73.0623)  Acc@5: 100.0000 (97.6328)  time: 0.3537  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2570/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.6246  Acc@1: 81.2500 (73.0868)  Acc@5: 100.0000 (97.6347)  time: 0.3541  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2580/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.7324  Acc@1: 75.0000 (73.0918)  Acc@5: 100.0000 (97.6390)  time: 0.3543  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2590/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.2548  Acc@1: 75.0000 (73.0944)  Acc@5: 100.0000 (97.6385)  time: 0.3540  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2600/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.2856  Acc@1: 75.0000 (73.1113)  Acc@5: 100.0000 (97.6427)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2610/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.4591  Acc@1: 75.0000 (73.1329)  Acc@5: 100.0000 (97.6446)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2620/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.3635  Acc@1: 75.0000 (73.1353)  Acc@5: 100.0000 (97.6416)  time: 0.3534  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2630/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.4819  Acc@1: 68.7500 (73.1162)  Acc@5: 100.0000 (97.6340)  time: 0.3533  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2640/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.3577  Acc@1: 75.0000 (73.1375)  Acc@5: 100.0000 (97.6358)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2650/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6200  Acc@1: 75.0000 (73.1304)  Acc@5: 100.0000 (97.6353)  time: 0.3537  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2660/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.6567  Acc@1: 75.0000 (73.1633)  Acc@5: 100.0000 (97.6395)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2670/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.3462  Acc@1: 81.2500 (73.1725)  Acc@5: 100.0000 (97.6460)  time: 0.3524  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2680/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8034  Acc@1: 75.0000 (73.1840)  Acc@5: 100.0000 (97.6478)  time: 0.3521  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2690/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.9684  Acc@1: 81.2500 (73.2256)  Acc@5: 100.0000 (97.6473)  time: 0.3514  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2700/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.5082  Acc@1: 75.0000 (73.2229)  Acc@5: 100.0000 (97.6467)  time: 0.3517  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2710/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.3625  Acc@1: 75.0000 (73.2225)  Acc@5: 100.0000 (97.6462)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2720/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.5696  Acc@1: 75.0000 (73.2359)  Acc@5: 100.0000 (97.6479)  time: 0.3521  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2730/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.3875  Acc@1: 75.0000 (73.2378)  Acc@5: 100.0000 (97.6497)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2740/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6145  Acc@1: 75.0000 (73.2693)  Acc@5: 100.0000 (97.6560)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2750/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.2827  Acc@1: 75.0000 (73.2643)  Acc@5: 100.0000 (97.6577)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2760/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.3703  Acc@1: 68.7500 (73.2547)  Acc@5: 100.0000 (97.6594)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2770/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.4741  Acc@1: 75.0000 (73.2655)  Acc@5: 100.0000 (97.6656)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2780/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.9357  Acc@1: 75.0000 (73.2762)  Acc@5: 100.0000 (97.6695)  time: 0.3506  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2790/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.8057  Acc@1: 75.0000 (73.2869)  Acc@5: 100.0000 (97.6688)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2800/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6981  Acc@1: 75.0000 (73.2953)  Acc@5: 100.0000 (97.6727)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2810/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.4307  Acc@1: 75.0000 (73.2946)  Acc@5: 100.0000 (97.6788)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2820/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.4460  Acc@1: 75.0000 (73.3140)  Acc@5: 100.0000 (97.6803)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2830/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.6106  Acc@1: 75.0000 (73.3199)  Acc@5: 100.0000 (97.6841)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2840/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.5967  Acc@1: 75.0000 (73.3325)  Acc@5: 100.0000 (97.6879)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2850/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.6048  Acc@1: 75.0000 (73.3471)  Acc@5: 100.0000 (97.6894)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2860/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.7892  Acc@1: 81.2500 (73.3638)  Acc@5: 100.0000 (97.6931)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [2870/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.4850  Acc@1: 81.2500 (73.3825)  Acc@5: 100.0000 (97.6990)  time: 0.3519  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [2880/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.7796  Acc@1: 75.0000 (73.4012)  Acc@5: 100.0000 (97.7026)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2890/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.7689  Acc@1: 75.0000 (73.4045)  Acc@5: 100.0000 (97.7062)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2900/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.4414  Acc@1: 75.0000 (73.4230)  Acc@5: 100.0000 (97.7120)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [2910/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.5603  Acc@1: 75.0000 (73.4413)  Acc@5: 100.0000 (97.7156)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [2920/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.5103  Acc@1: 75.0000 (73.4487)  Acc@5: 100.0000 (97.7212)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2930/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.3837  Acc@1: 75.0000 (73.4540)  Acc@5: 100.0000 (97.7248)  time: 0.3511  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2940/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.3702  Acc@1: 75.0000 (73.4805)  Acc@5: 100.0000 (97.7261)  time: 0.3525  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2950/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.8066  Acc@1: 81.2500 (73.5090)  Acc@5: 100.0000 (97.7296)  time: 0.3524  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [2960/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.3612  Acc@1: 81.2500 (73.5267)  Acc@5: 100.0000 (97.7373)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2970/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.7354  Acc@1: 75.0000 (73.5274)  Acc@5: 100.0000 (97.7343)  time: 0.3525  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [2980/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.6228  Acc@1: 75.0000 (73.5470)  Acc@5: 100.0000 (97.7357)  time: 0.3528  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [2990/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5516  Acc@1: 75.0000 (73.5394)  Acc@5: 100.0000 (97.7370)  time: 0.3532  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [3000/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.3687  Acc@1: 75.0000 (73.5463)  Acc@5: 100.0000 (97.7424)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3010/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.5828  Acc@1: 75.0000 (73.5594)  Acc@5: 100.0000 (97.7416)  time: 0.3543  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3020/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5096  Acc@1: 81.2500 (73.5828)  Acc@5: 100.0000 (97.7491)  time: 0.3553  data: 0.0011  max mem: 2503
Train: Epoch[1/1]  [3030/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.7407  Acc@1: 75.0000 (73.5916)  Acc@5: 100.0000 (97.7503)  time: 0.3551  data: 0.0011  max mem: 2503
Train: Epoch[1/1]  [3040/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.5544  Acc@1: 75.0000 (73.6086)  Acc@5: 100.0000 (97.7557)  time: 0.3550  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3050/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.3897  Acc@1: 81.2500 (73.6255)  Acc@5: 100.0000 (97.7548)  time: 0.3559  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [3060/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.0697  Acc@1: 75.0000 (73.6197)  Acc@5: 100.0000 (97.7479)  time: 0.3544  data: 0.0014  max mem: 2503
Train: Epoch[1/1]  [3070/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4309  Acc@1: 75.0000 (73.6466)  Acc@5: 100.0000 (97.7532)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [3080/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.6259  Acc@1: 81.2500 (73.6652)  Acc@5: 100.0000 (97.7584)  time: 0.3507  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.5487  Acc@1: 81.2500 (73.6796)  Acc@5: 100.0000 (97.7576)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [3100/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.5411  Acc@1: 81.2500 (73.7000)  Acc@5: 100.0000 (97.7628)  time: 0.3518  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.4952  Acc@1: 75.0000 (73.7022)  Acc@5: 100.0000 (97.7640)  time: 0.3532  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3120/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.4403  Acc@1: 81.2500 (73.7204)  Acc@5: 100.0000 (97.7651)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6671  Acc@1: 81.2500 (73.7384)  Acc@5: 100.0000 (97.7723)  time: 0.3537  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3140/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5268  Acc@1: 81.2500 (73.7683)  Acc@5: 100.0000 (97.7774)  time: 0.3535  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3150/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.3442  Acc@1: 81.2500 (73.7782)  Acc@5: 100.0000 (97.7785)  time: 0.3525  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3160/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.6576  Acc@1: 81.2500 (73.8038)  Acc@5: 100.0000 (97.7855)  time: 0.3526  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [3170/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -0.7876  Acc@1: 81.2500 (73.8056)  Acc@5: 100.0000 (97.7905)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -0.6191  Acc@1: 75.0000 (73.8231)  Acc@5: 100.0000 (97.7955)  time: 0.3532  data: 0.0013  max mem: 2503
Train: Epoch[1/1]  [3190/3750]  eta: 0:03:17  Lr: 0.001875  Loss: -0.1338  Acc@1: 81.2500 (73.8327)  Acc@5: 100.0000 (97.7985)  time: 0.3533  data: 0.0010  max mem: 2503
Train: Epoch[1/1]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.6513  Acc@1: 75.0000 (73.8187)  Acc@5: 100.0000 (97.8015)  time: 0.3516  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [3210/3750]  eta: 0:03:10  Lr: 0.001875  Loss: -0.8333  Acc@1: 75.0000 (73.8360)  Acc@5: 100.0000 (97.8025)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.2997  Acc@1: 75.0000 (73.8241)  Acc@5: 100.0000 (97.8074)  time: 0.3530  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [3230/3750]  eta: 0:03:03  Lr: 0.001875  Loss: 0.0864  Acc@1: 75.0000 (73.8374)  Acc@5: 100.0000 (97.8103)  time: 0.3538  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.4480  Acc@1: 75.0000 (73.8410)  Acc@5: 100.0000 (97.8132)  time: 0.3540  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3250/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.8614  Acc@1: 81.2500 (73.8542)  Acc@5: 100.0000 (97.8103)  time: 0.3558  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.5683  Acc@1: 75.0000 (73.8654)  Acc@5: 100.0000 (97.8151)  time: 0.3552  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3270/3750]  eta: 0:02:49  Lr: 0.001875  Loss: -0.5791  Acc@1: 75.0000 (73.8536)  Acc@5: 100.0000 (97.8103)  time: 0.3536  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.2540  Acc@1: 75.0000 (73.8704)  Acc@5: 100.0000 (97.8113)  time: 0.3538  data: 0.0017  max mem: 2503
Train: Epoch[1/1]  [3290/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.5544  Acc@1: 75.0000 (73.8681)  Acc@5: 100.0000 (97.8122)  time: 0.3566  data: 0.0013  max mem: 2503
Train: Epoch[1/1]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.7046  Acc@1: 75.0000 (73.8734)  Acc@5: 100.0000 (97.8151)  time: 0.3557  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [3310/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -0.3562  Acc@1: 75.0000 (73.8674)  Acc@5: 100.0000 (97.8179)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.3864  Acc@1: 75.0000 (73.8878)  Acc@5: 100.0000 (97.8188)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3330/3750]  eta: 0:02:28  Lr: 0.001875  Loss: -0.4571  Acc@1: 81.2500 (73.8967)  Acc@5: 100.0000 (97.8235)  time: 0.3527  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.5955  Acc@1: 81.2500 (73.9131)  Acc@5: 100.0000 (97.8281)  time: 0.3531  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [3350/3750]  eta: 0:02:21  Lr: 0.001875  Loss: -0.1553  Acc@1: 81.2500 (73.9201)  Acc@5: 100.0000 (97.8271)  time: 0.3524  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.3850  Acc@1: 81.2500 (73.9270)  Acc@5: 100.0000 (97.8317)  time: 0.3542  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.0760  Acc@1: 68.7500 (73.9154)  Acc@5: 100.0000 (97.8326)  time: 0.3547  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4921  Acc@1: 68.7500 (73.9241)  Acc@5: 100.0000 (97.8316)  time: 0.3538  data: 0.0010  max mem: 2503
Train: Epoch[1/1]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1526  Acc@1: 81.2500 (73.9439)  Acc@5: 100.0000 (97.8362)  time: 0.3536  data: 0.0010  max mem: 2503
Train: Epoch[1/1]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.7307  Acc@1: 81.2500 (73.9488)  Acc@5: 100.0000 (97.8389)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.4352  Acc@1: 75.0000 (73.9629)  Acc@5: 100.0000 (97.8379)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.5570  Acc@1: 75.0000 (73.9513)  Acc@5: 100.0000 (97.8387)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.5249  Acc@1: 68.7500 (73.9580)  Acc@5: 100.0000 (97.8450)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3440/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.5137  Acc@1: 81.2500 (73.9792)  Acc@5: 100.0000 (97.8422)  time: 0.3524  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.9023  Acc@1: 81.2500 (73.9967)  Acc@5: 100.0000 (97.8412)  time: 0.3547  data: 0.0012  max mem: 2503
Train: Epoch[1/1]  [3460/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -0.4893  Acc@1: 75.0000 (73.9923)  Acc@5: 100.0000 (97.8438)  time: 0.3546  data: 0.0013  max mem: 2503
Train: Epoch[1/1]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.3993  Acc@1: 75.0000 (74.0042)  Acc@5: 100.0000 (97.8500)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3480/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -0.6050  Acc@1: 81.2500 (74.0251)  Acc@5: 100.0000 (97.8508)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.4305  Acc@1: 81.2500 (74.0243)  Acc@5: 100.0000 (97.8516)  time: 0.3532  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3500/3750]  eta: 0:01:28  Lr: 0.001875  Loss: -0.4662  Acc@1: 75.0000 (74.0271)  Acc@5: 100.0000 (97.8560)  time: 0.3542  data: 0.0011  max mem: 2503
Train: Epoch[1/1]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5229  Acc@1: 81.2500 (74.0512)  Acc@5: 100.0000 (97.8585)  time: 0.3537  data: 0.0011  max mem: 2503
Train: Epoch[1/1]  [3520/3750]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7259  Acc@1: 81.2500 (74.0592)  Acc@5: 100.0000 (97.8610)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6793  Acc@1: 75.0000 (74.0601)  Acc@5: 100.0000 (97.8653)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3540/3750]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7740  Acc@1: 75.0000 (74.0751)  Acc@5: 100.0000 (97.8696)  time: 0.3516  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.4871  Acc@1: 75.0000 (74.0724)  Acc@5: 100.0000 (97.8668)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.3965  Acc@1: 75.0000 (74.0803)  Acc@5: 100.0000 (97.8693)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.5235  Acc@1: 75.0000 (74.0846)  Acc@5: 100.0000 (97.8647)  time: 0.3514  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.3833  Acc@1: 75.0000 (74.0872)  Acc@5: 100.0000 (97.8707)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.6302  Acc@1: 75.0000 (74.0915)  Acc@5: 100.0000 (97.8714)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[1/1]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.7613  Acc@1: 75.0000 (74.0905)  Acc@5: 100.0000 (97.8721)  time: 0.3525  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.7685  Acc@1: 75.0000 (74.0913)  Acc@5: 100.0000 (97.8711)  time: 0.3524  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.2638  Acc@1: 75.0000 (74.0921)  Acc@5: 100.0000 (97.8718)  time: 0.3512  data: 0.0007  max mem: 2503
Train: Epoch[1/1]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.5530  Acc@1: 81.2500 (74.1049)  Acc@5: 100.0000 (97.8742)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.9050  Acc@1: 81.2500 (74.1091)  Acc@5: 100.0000 (97.8783)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.9166  Acc@1: 75.0000 (74.1184)  Acc@5: 100.0000 (97.8807)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[1/1]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.3281  Acc@1: 75.0000 (74.1037)  Acc@5: 100.0000 (97.8848)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6307  Acc@1: 75.0000 (74.1062)  Acc@5: 100.0000 (97.8906)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8169  Acc@1: 81.2500 (74.1307)  Acc@5: 100.0000 (97.8912)  time: 0.3507  data: 0.0003  max mem: 2503
Train: Epoch[1/1]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.3497  Acc@1: 81.2500 (74.1584)  Acc@5: 100.0000 (97.8935)  time: 0.3508  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6797  Acc@1: 81.2500 (74.1793)  Acc@5: 100.0000 (97.8975)  time: 0.3507  data: 0.0008  max mem: 2503
Train: Epoch[1/1]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4082  Acc@1: 81.2500 (74.1849)  Acc@5: 100.0000 (97.8998)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7054  Acc@1: 75.0000 (74.1854)  Acc@5: 100.0000 (97.9021)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6183  Acc@1: 75.0000 (74.1909)  Acc@5: 100.0000 (97.9044)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6537  Acc@1: 75.0000 (74.2031)  Acc@5: 100.0000 (97.9016)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[1/1]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6824  Acc@1: 75.0000 (74.1933)  Acc@5: 100.0000 (97.9017)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[1/1] Total time: 0:22:02 (0.3527 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 18265, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 18265, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 18265, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 18265, 4: 0}, 8: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}}
Averaged stats: Lr: 0.001875  Loss: -0.6824  Acc@1: 75.0000 (74.1933)  Acc@5: 100.0000 (97.9017)
Test: [Task 1]  [   0/1627]  eta: 0:15:59  Loss: 1.5240 (1.5240)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5898  data: 0.3687  max mem: 2503
Test: [Task 1]  [  10/1627]  eta: 0:06:46  Loss: 1.5800 (1.4830)  Acc@1: 68.7500 (65.9091)  Acc@5: 93.7500 (89.7727)  time: 0.2516  data: 0.0341  max mem: 2503
Test: [Task 1]  [  20/1627]  eta: 0:06:19  Loss: 1.4890 (1.4620)  Acc@1: 68.7500 (66.3690)  Acc@5: 93.7500 (90.4762)  time: 0.2183  data: 0.0005  max mem: 2503
Test: [Task 1]  [  30/1627]  eta: 0:06:07  Loss: 1.4143 (1.4891)  Acc@1: 62.5000 (64.9194)  Acc@5: 93.7500 (89.9194)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 1]  [  40/1627]  eta: 0:06:01  Loss: 1.6544 (1.5201)  Acc@1: 56.2500 (63.8720)  Acc@5: 87.5000 (88.5671)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 1]  [  50/1627]  eta: 0:05:55  Loss: 1.4956 (1.4937)  Acc@1: 62.5000 (64.7059)  Acc@5: 87.5000 (89.2157)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 1]  [  60/1627]  eta: 0:05:52  Loss: 1.4956 (1.5229)  Acc@1: 62.5000 (63.5246)  Acc@5: 87.5000 (88.3197)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 1]  [  70/1627]  eta: 0:05:48  Loss: 1.5073 (1.5158)  Acc@1: 56.2500 (63.5563)  Acc@5: 87.5000 (88.3803)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [  80/1627]  eta: 0:05:45  Loss: 1.4059 (1.5061)  Acc@1: 62.5000 (63.8889)  Acc@5: 87.5000 (88.7346)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 1]  [  90/1627]  eta: 0:05:42  Loss: 1.4289 (1.5074)  Acc@1: 62.5000 (63.7363)  Acc@5: 87.5000 (88.6676)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 100/1627]  eta: 0:05:39  Loss: 1.6351 (1.5309)  Acc@1: 62.5000 (63.5520)  Acc@5: 81.2500 (87.7475)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 110/1627]  eta: 0:05:37  Loss: 1.6225 (1.5321)  Acc@1: 62.5000 (63.4009)  Acc@5: 87.5000 (88.2320)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 120/1627]  eta: 0:05:34  Loss: 1.5018 (1.5341)  Acc@1: 62.5000 (63.1198)  Acc@5: 87.5000 (88.0165)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 130/1627]  eta: 0:05:32  Loss: 1.5018 (1.5292)  Acc@1: 56.2500 (63.2634)  Acc@5: 87.5000 (87.8340)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 140/1627]  eta: 0:05:29  Loss: 1.3826 (1.5277)  Acc@1: 62.5000 (63.1206)  Acc@5: 87.5000 (87.8989)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 150/1627]  eta: 0:05:27  Loss: 1.3207 (1.5156)  Acc@1: 68.7500 (63.5762)  Acc@5: 93.7500 (88.1623)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 160/1627]  eta: 0:05:24  Loss: 1.3757 (1.5098)  Acc@1: 68.7500 (63.7811)  Acc@5: 93.7500 (88.3540)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 170/1627]  eta: 0:05:22  Loss: 1.4520 (1.5021)  Acc@1: 62.5000 (63.8889)  Acc@5: 87.5000 (88.4503)  time: 0.2185  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 180/1627]  eta: 0:05:19  Loss: 1.4804 (1.5131)  Acc@1: 62.5000 (63.4669)  Acc@5: 87.5000 (88.2942)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 190/1627]  eta: 0:05:17  Loss: 1.5861 (1.5075)  Acc@1: 56.2500 (63.6780)  Acc@5: 87.5000 (88.3835)  time: 0.2204  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 200/1627]  eta: 0:05:15  Loss: 1.5861 (1.5099)  Acc@1: 62.5000 (63.6194)  Acc@5: 87.5000 (88.3706)  time: 0.2205  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 210/1627]  eta: 0:05:13  Loss: 1.4798 (1.5057)  Acc@1: 68.7500 (63.8626)  Acc@5: 87.5000 (88.4775)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 220/1627]  eta: 0:05:10  Loss: 1.4798 (1.5123)  Acc@1: 68.7500 (63.7161)  Acc@5: 87.5000 (88.4333)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 230/1627]  eta: 0:05:08  Loss: 1.5344 (1.5060)  Acc@1: 62.5000 (63.8528)  Acc@5: 87.5000 (88.5281)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 240/1627]  eta: 0:05:06  Loss: 1.3787 (1.4985)  Acc@1: 68.7500 (64.0820)  Acc@5: 87.5000 (88.6151)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 250/1627]  eta: 0:05:03  Loss: 1.4891 (1.5041)  Acc@1: 62.5000 (63.9193)  Acc@5: 87.5000 (88.4462)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 260/1627]  eta: 0:05:02  Loss: 1.5124 (1.5027)  Acc@1: 62.5000 (64.1044)  Acc@5: 87.5000 (88.4818)  time: 0.2237  data: 0.0017  max mem: 2503
Test: [Task 1]  [ 270/1627]  eta: 0:04:59  Loss: 1.4535 (1.4959)  Acc@1: 68.7500 (64.3450)  Acc@5: 87.5000 (88.5839)  time: 0.2232  data: 0.0017  max mem: 2503
Test: [Task 1]  [ 280/1627]  eta: 0:04:57  Loss: 1.3777 (1.4951)  Acc@1: 68.7500 (64.3906)  Acc@5: 87.5000 (88.5899)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 290/1627]  eta: 0:04:55  Loss: 1.3777 (1.4923)  Acc@1: 62.5000 (64.3256)  Acc@5: 87.5000 (88.6168)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 300/1627]  eta: 0:04:52  Loss: 1.4077 (1.4906)  Acc@1: 68.7500 (64.4518)  Acc@5: 87.5000 (88.7043)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 310/1627]  eta: 0:04:50  Loss: 1.4077 (1.4939)  Acc@1: 68.7500 (64.4494)  Acc@5: 87.5000 (88.6053)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 320/1627]  eta: 0:04:48  Loss: 1.5899 (1.4949)  Acc@1: 62.5000 (64.4470)  Acc@5: 87.5000 (88.5709)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 330/1627]  eta: 0:04:46  Loss: 1.5045 (1.4944)  Acc@1: 62.5000 (64.5582)  Acc@5: 87.5000 (88.5385)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 340/1627]  eta: 0:04:44  Loss: 1.3995 (1.4937)  Acc@1: 68.7500 (64.6444)  Acc@5: 93.7500 (88.5814)  time: 0.2222  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 350/1627]  eta: 0:04:41  Loss: 1.4862 (1.4932)  Acc@1: 62.5000 (64.6546)  Acc@5: 93.7500 (88.5862)  time: 0.2234  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 360/1627]  eta: 0:04:39  Loss: 1.4228 (1.4933)  Acc@1: 62.5000 (64.6814)  Acc@5: 87.5000 (88.5734)  time: 0.2199  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 370/1627]  eta: 0:04:37  Loss: 1.3441 (1.4926)  Acc@1: 62.5000 (64.7406)  Acc@5: 87.5000 (88.5613)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 380/1627]  eta: 0:04:35  Loss: 1.4189 (1.4909)  Acc@1: 62.5000 (64.7966)  Acc@5: 87.5000 (88.5499)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 390/1627]  eta: 0:04:32  Loss: 1.4862 (1.4931)  Acc@1: 62.5000 (64.7698)  Acc@5: 87.5000 (88.4591)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 400/1627]  eta: 0:04:30  Loss: 1.4594 (1.4940)  Acc@1: 62.5000 (64.8379)  Acc@5: 93.7500 (88.4507)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 410/1627]  eta: 0:04:28  Loss: 1.4270 (1.4935)  Acc@1: 68.7500 (64.8875)  Acc@5: 87.5000 (88.4428)  time: 0.2195  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 420/1627]  eta: 0:04:26  Loss: 1.3425 (1.4911)  Acc@1: 68.7500 (64.9792)  Acc@5: 93.7500 (88.5095)  time: 0.2198  data: 0.0019  max mem: 2503
Test: [Task 1]  [ 430/1627]  eta: 0:04:23  Loss: 1.2997 (1.4893)  Acc@1: 68.7500 (65.0667)  Acc@5: 93.7500 (88.5441)  time: 0.2186  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 440/1627]  eta: 0:04:21  Loss: 1.4876 (1.4895)  Acc@1: 68.7500 (65.1219)  Acc@5: 87.5000 (88.5204)  time: 0.2177  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 450/1627]  eta: 0:04:19  Loss: 1.6536 (1.4936)  Acc@1: 62.5000 (65.0083)  Acc@5: 87.5000 (88.4839)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 460/1627]  eta: 0:04:16  Loss: 1.5375 (1.4929)  Acc@1: 62.5000 (65.0217)  Acc@5: 87.5000 (88.5304)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 470/1627]  eta: 0:04:14  Loss: 1.3085 (1.4897)  Acc@1: 68.7500 (65.0478)  Acc@5: 93.7500 (88.5616)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 480/1627]  eta: 0:04:12  Loss: 1.5237 (1.4946)  Acc@1: 62.5000 (64.9818)  Acc@5: 87.5000 (88.4615)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 490/1627]  eta: 0:04:10  Loss: 1.5237 (1.4957)  Acc@1: 62.5000 (64.8931)  Acc@5: 87.5000 (88.4292)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 500/1627]  eta: 0:04:07  Loss: 1.4908 (1.4983)  Acc@1: 62.5000 (64.9202)  Acc@5: 87.5000 (88.3608)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 510/1627]  eta: 0:04:05  Loss: 1.5323 (1.5017)  Acc@1: 62.5000 (64.8483)  Acc@5: 81.2500 (88.2583)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 520/1627]  eta: 0:04:03  Loss: 1.5709 (1.5068)  Acc@1: 62.5000 (64.7433)  Acc@5: 87.5000 (88.2318)  time: 0.2176  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 530/1627]  eta: 0:04:01  Loss: 1.3930 (1.5019)  Acc@1: 68.7500 (64.8894)  Acc@5: 93.7500 (88.3004)  time: 0.2176  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 540/1627]  eta: 0:03:58  Loss: 1.3800 (1.5018)  Acc@1: 68.7500 (64.8567)  Acc@5: 87.5000 (88.2740)  time: 0.2176  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 550/1627]  eta: 0:03:56  Loss: 1.6001 (1.5051)  Acc@1: 62.5000 (64.8140)  Acc@5: 87.5000 (88.2373)  time: 0.2175  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 560/1627]  eta: 0:03:54  Loss: 1.6300 (1.5074)  Acc@1: 62.5000 (64.7839)  Acc@5: 87.5000 (88.2242)  time: 0.2173  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 570/1627]  eta: 0:03:52  Loss: 1.4057 (1.5055)  Acc@1: 62.5000 (64.8095)  Acc@5: 93.7500 (88.2771)  time: 0.2171  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 580/1627]  eta: 0:03:49  Loss: 1.4405 (1.5075)  Acc@1: 68.7500 (64.7590)  Acc@5: 87.5000 (88.2315)  time: 0.2166  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 590/1627]  eta: 0:03:47  Loss: 1.5241 (1.5067)  Acc@1: 62.5000 (64.7420)  Acc@5: 87.5000 (88.2826)  time: 0.2173  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 600/1627]  eta: 0:03:45  Loss: 1.4398 (1.5095)  Acc@1: 62.5000 (64.6319)  Acc@5: 87.5000 (88.2176)  time: 0.2177  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 610/1627]  eta: 0:03:43  Loss: 1.4219 (1.5074)  Acc@1: 62.5000 (64.7504)  Acc@5: 87.5000 (88.2876)  time: 0.2173  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 620/1627]  eta: 0:03:41  Loss: 1.4241 (1.5082)  Acc@1: 68.7500 (64.7544)  Acc@5: 87.5000 (88.2347)  time: 0.2170  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 630/1627]  eta: 0:03:38  Loss: 1.4427 (1.5066)  Acc@1: 62.5000 (64.8277)  Acc@5: 87.5000 (88.2726)  time: 0.2176  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 1.2045 (1.5052)  Acc@1: 68.7500 (64.8888)  Acc@5: 93.7500 (88.2898)  time: 0.2175  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 650/1627]  eta: 0:03:34  Loss: 1.4205 (1.5051)  Acc@1: 68.7500 (64.8810)  Acc@5: 81.2500 (88.2296)  time: 0.2162  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 660/1627]  eta: 0:03:32  Loss: 1.3820 (1.5027)  Acc@1: 68.7500 (64.9584)  Acc@5: 87.5000 (88.2848)  time: 0.2168  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 670/1627]  eta: 0:03:29  Loss: 1.4518 (1.5036)  Acc@1: 68.7500 (64.9311)  Acc@5: 87.5000 (88.2638)  time: 0.2176  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 680/1627]  eta: 0:03:27  Loss: 1.4518 (1.5013)  Acc@1: 68.7500 (65.0239)  Acc@5: 87.5000 (88.2893)  time: 0.2176  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 1.4291 (1.4999)  Acc@1: 68.7500 (65.0778)  Acc@5: 93.7500 (88.3683)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 700/1627]  eta: 0:03:23  Loss: 1.5131 (1.5001)  Acc@1: 68.7500 (65.0945)  Acc@5: 93.7500 (88.3827)  time: 0.2175  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 710/1627]  eta: 0:03:21  Loss: 1.5050 (1.4978)  Acc@1: 68.7500 (65.1723)  Acc@5: 87.5000 (88.3966)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 720/1627]  eta: 0:03:18  Loss: 1.3065 (1.4956)  Acc@1: 68.7500 (65.2479)  Acc@5: 87.5000 (88.4449)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 730/1627]  eta: 0:03:16  Loss: 1.4001 (1.4973)  Acc@1: 62.5000 (65.2103)  Acc@5: 87.5000 (88.4234)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 1.5580 (1.4976)  Acc@1: 68.7500 (65.2497)  Acc@5: 81.2500 (88.3519)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 750/1627]  eta: 0:03:12  Loss: 1.4479 (1.4965)  Acc@1: 68.7500 (65.3129)  Acc@5: 87.5000 (88.3905)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 760/1627]  eta: 0:03:10  Loss: 1.4479 (1.4998)  Acc@1: 62.5000 (65.2595)  Acc@5: 87.5000 (88.2802)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 770/1627]  eta: 0:03:07  Loss: 1.4124 (1.4972)  Acc@1: 62.5000 (65.3372)  Acc@5: 87.5000 (88.3431)  time: 0.2202  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 780/1627]  eta: 0:03:05  Loss: 1.2758 (1.4963)  Acc@1: 68.7500 (65.3569)  Acc@5: 93.7500 (88.3563)  time: 0.2194  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 1.4170 (1.4979)  Acc@1: 62.5000 (65.3129)  Acc@5: 87.5000 (88.2822)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 800/1627]  eta: 0:03:01  Loss: 1.5330 (1.4982)  Acc@1: 62.5000 (65.3012)  Acc@5: 87.5000 (88.2803)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 810/1627]  eta: 0:02:59  Loss: 1.4739 (1.4977)  Acc@1: 68.7500 (65.3437)  Acc@5: 87.5000 (88.2784)  time: 0.2201  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 820/1627]  eta: 0:02:56  Loss: 1.2977 (1.4971)  Acc@1: 68.7500 (65.3776)  Acc@5: 87.5000 (88.2917)  time: 0.2201  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 830/1627]  eta: 0:02:54  Loss: 1.2688 (1.4965)  Acc@1: 68.7500 (65.3505)  Acc@5: 87.5000 (88.2747)  time: 0.2201  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 1.2454 (1.4947)  Acc@1: 68.7500 (65.3686)  Acc@5: 93.7500 (88.3026)  time: 0.2204  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 850/1627]  eta: 0:02:50  Loss: 1.5443 (1.4960)  Acc@1: 62.5000 (65.3129)  Acc@5: 93.7500 (88.2932)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 1.4508 (1.4956)  Acc@1: 62.5000 (65.3600)  Acc@5: 87.5000 (88.2985)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 870/1627]  eta: 0:02:45  Loss: 1.4259 (1.4935)  Acc@1: 68.7500 (65.4348)  Acc@5: 93.7500 (88.3108)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 880/1627]  eta: 0:02:43  Loss: 1.5658 (1.4966)  Acc@1: 62.5000 (65.3590)  Acc@5: 87.5000 (88.2591)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 1.7461 (1.4987)  Acc@1: 56.2500 (65.3199)  Acc@5: 87.5000 (88.2365)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 1.6062 (1.4993)  Acc@1: 56.2500 (65.3233)  Acc@5: 81.2500 (88.2214)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 1.5145 (1.4994)  Acc@1: 62.5000 (65.3403)  Acc@5: 87.5000 (88.2409)  time: 0.2202  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 1.3867 (1.4979)  Acc@1: 62.5000 (65.3909)  Acc@5: 93.7500 (88.3008)  time: 0.2197  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 930/1627]  eta: 0:02:32  Loss: 1.4204 (1.4973)  Acc@1: 62.5000 (65.4001)  Acc@5: 87.5000 (88.2653)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 1.4522 (1.4958)  Acc@1: 62.5000 (65.3892)  Acc@5: 93.7500 (88.3435)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 1.4672 (1.4967)  Acc@1: 62.5000 (65.3523)  Acc@5: 93.7500 (88.3084)  time: 0.2197  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 1.4520 (1.4960)  Acc@1: 68.7500 (65.3486)  Acc@5: 87.5000 (88.3260)  time: 0.2198  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 1.3057 (1.4951)  Acc@1: 68.7500 (65.3836)  Acc@5: 87.5000 (88.3046)  time: 0.2203  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 980/1627]  eta: 0:02:21  Loss: 1.4515 (1.4952)  Acc@1: 62.5000 (65.3479)  Acc@5: 87.5000 (88.2900)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 1.6264 (1.4981)  Acc@1: 56.2500 (65.2687)  Acc@5: 87.5000 (88.2253)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 1.6165 (1.4985)  Acc@1: 62.5000 (65.2785)  Acc@5: 87.5000 (88.2055)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 1.5086 (1.4986)  Acc@1: 68.7500 (65.2881)  Acc@5: 87.5000 (88.1924)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 1.5086 (1.4986)  Acc@1: 68.7500 (65.3097)  Acc@5: 87.5000 (88.2101)  time: 0.2203  data: 0.0011  max mem: 2503
Test: [Task 1]  [1030/1627]  eta: 0:02:10  Loss: 1.3264 (1.4972)  Acc@1: 68.7500 (65.3552)  Acc@5: 87.5000 (88.2274)  time: 0.2200  data: 0.0011  max mem: 2503
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 1.3213 (1.4963)  Acc@1: 62.5000 (65.3818)  Acc@5: 87.5000 (88.2265)  time: 0.2207  data: 0.0004  max mem: 2503
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 1.3504 (1.4952)  Acc@1: 62.5000 (65.3961)  Acc@5: 87.5000 (88.2493)  time: 0.2210  data: 0.0004  max mem: 2503
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 1.5029 (1.4954)  Acc@1: 62.5000 (65.3511)  Acc@5: 87.5000 (88.2481)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 1.4701 (1.4960)  Acc@1: 62.5000 (65.3653)  Acc@5: 87.5000 (88.2411)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 1]  [1080/1627]  eta: 0:01:59  Loss: 1.4700 (1.4966)  Acc@1: 62.5000 (65.3446)  Acc@5: 87.5000 (88.2343)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 1.4650 (1.4965)  Acc@1: 62.5000 (65.3357)  Acc@5: 87.5000 (88.2275)  time: 0.2208  data: 0.0003  max mem: 2503
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 1.3777 (1.4947)  Acc@1: 62.5000 (65.3837)  Acc@5: 93.7500 (88.2607)  time: 0.2207  data: 0.0004  max mem: 2503
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 1.4288 (1.4953)  Acc@1: 62.5000 (65.3578)  Acc@5: 93.7500 (88.2651)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 1.5361 (1.4960)  Acc@1: 62.5000 (65.3379)  Acc@5: 87.5000 (88.2527)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 1.6227 (1.4977)  Acc@1: 56.2500 (65.2686)  Acc@5: 87.5000 (88.2405)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 1.6227 (1.4988)  Acc@1: 62.5000 (65.2662)  Acc@5: 87.5000 (88.2230)  time: 0.2185  data: 0.0003  max mem: 2503
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 1.6332 (1.5001)  Acc@1: 62.5000 (65.2150)  Acc@5: 81.2500 (88.1679)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 1.4460 (1.4987)  Acc@1: 62.5000 (65.2509)  Acc@5: 87.5000 (88.1891)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 1.3845 (1.4980)  Acc@1: 68.7500 (65.2914)  Acc@5: 93.7500 (88.2045)  time: 0.2190  data: 0.0002  max mem: 2503
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 1.5532 (1.4989)  Acc@1: 68.7500 (65.2519)  Acc@5: 93.7500 (88.2197)  time: 0.2192  data: 0.0002  max mem: 2503
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 1.6048 (1.5000)  Acc@1: 62.5000 (65.2340)  Acc@5: 87.5000 (88.1770)  time: 0.2178  data: 0.0002  max mem: 2503
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 1.4709 (1.4998)  Acc@1: 62.5000 (65.2425)  Acc@5: 87.5000 (88.1817)  time: 0.2187  data: 0.0006  max mem: 2503
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 1.4382 (1.5010)  Acc@1: 62.5000 (65.1631)  Acc@5: 87.5000 (88.1451)  time: 0.2193  data: 0.0006  max mem: 2503
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 1.4884 (1.5007)  Acc@1: 62.5000 (65.1362)  Acc@5: 87.5000 (88.1552)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 1.4968 (1.5018)  Acc@1: 62.5000 (65.1147)  Acc@5: 87.5000 (88.1245)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 1.4305 (1.5006)  Acc@1: 62.5000 (65.1642)  Acc@5: 87.5000 (88.1396)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 1.4657 (1.5011)  Acc@1: 62.5000 (65.1379)  Acc@5: 87.5000 (88.1345)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 1.4657 (1.5008)  Acc@1: 62.5000 (65.1665)  Acc@5: 93.7500 (88.1443)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 1.4033 (1.5011)  Acc@1: 68.7500 (65.1751)  Acc@5: 87.5000 (88.1294)  time: 0.2190  data: 0.0009  max mem: 2503
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 1.3598 (1.4991)  Acc@1: 68.7500 (65.1981)  Acc@5: 87.5000 (88.1538)  time: 0.2189  data: 0.0009  max mem: 2503
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 1.3598 (1.4997)  Acc@1: 62.5000 (65.1578)  Acc@5: 87.5000 (88.1197)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 1.5178 (1.4992)  Acc@1: 62.5000 (65.1806)  Acc@5: 87.5000 (88.1533)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 1.3495 (1.4978)  Acc@1: 75.0000 (65.2412)  Acc@5: 93.7500 (88.1913)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 1.2101 (1.4964)  Acc@1: 75.0000 (65.2914)  Acc@5: 93.7500 (88.2286)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 1.2815 (1.4964)  Acc@1: 68.7500 (65.2986)  Acc@5: 93.7500 (88.2231)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.5081 (1.4967)  Acc@1: 62.5000 (65.2871)  Acc@5: 87.5000 (88.2317)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 1.4634 (1.4963)  Acc@1: 62.5000 (65.2989)  Acc@5: 87.5000 (88.2494)  time: 0.2224  data: 0.0004  max mem: 2503
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 1.3973 (1.4957)  Acc@1: 68.7500 (65.3058)  Acc@5: 87.5000 (88.2531)  time: 0.2226  data: 0.0004  max mem: 2503
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 1.3973 (1.4955)  Acc@1: 68.7500 (65.3127)  Acc@5: 87.5000 (88.2522)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 1.4361 (1.4957)  Acc@1: 62.5000 (65.3150)  Acc@5: 87.5000 (88.2513)  time: 0.2198  data: 0.0003  max mem: 2503
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.4969 (1.4950)  Acc@1: 68.7500 (65.3307)  Acc@5: 93.7500 (88.2773)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.3171 (1.4953)  Acc@1: 68.7500 (65.3328)  Acc@5: 87.5000 (88.2539)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 1.3277 (1.4949)  Acc@1: 62.5000 (65.3349)  Acc@5: 87.5000 (88.2840)  time: 0.2198  data: 0.0003  max mem: 2503
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.4031 (1.4946)  Acc@1: 62.5000 (65.3237)  Acc@5: 93.7500 (88.2829)  time: 0.2202  data: 0.0003  max mem: 2503
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.6315 (1.4962)  Acc@1: 62.5000 (65.3040)  Acc@5: 81.2500 (88.2469)  time: 0.2201  data: 0.0003  max mem: 2503
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 1.5879 (1.4959)  Acc@1: 62.5000 (65.3019)  Acc@5: 87.5000 (88.2373)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.5090 (1.4969)  Acc@1: 62.5000 (65.2739)  Acc@5: 87.5000 (88.2107)  time: 0.2209  data: 0.0007  max mem: 2503
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.5959 (1.4973)  Acc@1: 62.5000 (65.2764)  Acc@5: 87.5000 (88.2144)  time: 0.2209  data: 0.0007  max mem: 2503
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.4426 (1.4979)  Acc@1: 56.2500 (65.2405)  Acc@5: 87.5000 (88.2138)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 1.4727 (1.4986)  Acc@1: 56.2500 (65.2304)  Acc@5: 87.5000 (88.1879)  time: 0.2197  data: 0.0003  max mem: 2503
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 1.5659 (1.4987)  Acc@1: 68.7500 (65.2540)  Acc@5: 87.5000 (88.1875)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.4656 (1.4988)  Acc@1: 68.7500 (65.2607)  Acc@5: 87.5000 (88.1995)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.2264 (1.4987)  Acc@1: 68.7500 (65.2300)  Acc@5: 93.7500 (88.1990)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.2264 (1.4977)  Acc@1: 75.0000 (65.2696)  Acc@5: 93.7500 (88.2191)  time: 0.2218  data: 0.0004  max mem: 2503
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.2351 (1.4971)  Acc@1: 75.0000 (65.3045)  Acc@5: 93.7500 (88.2307)  time: 0.2217  data: 0.0004  max mem: 2503
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 1.2425 (1.4960)  Acc@1: 62.5000 (65.2985)  Acc@5: 93.7500 (88.2463)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 1.2622 (1.4961)  Acc@1: 62.5000 (65.2845)  Acc@5: 87.5000 (88.2616)  time: 0.2207  data: 0.0014  max mem: 2503
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 1.2622 (1.4947)  Acc@1: 75.0000 (65.3307)  Acc@5: 93.7500 (88.2928)  time: 0.2206  data: 0.0013  max mem: 2503
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.2898 (1.4947)  Acc@1: 68.7500 (65.3525)  Acc@5: 93.7500 (88.2837)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.4013 (1.4942)  Acc@1: 68.7500 (65.3740)  Acc@5: 87.5000 (88.2946)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.4637 (1.4946)  Acc@1: 62.5000 (65.3598)  Acc@5: 87.5000 (88.3014)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.5206 (1.4957)  Acc@1: 56.2500 (65.3186)  Acc@5: 87.5000 (88.2847)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.5104 (1.4949)  Acc@1: 62.5000 (65.3476)  Acc@5: 87.5000 (88.2876)  time: 0.2185  data: 0.0003  max mem: 2503
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.3712 (1.4943)  Acc@1: 62.5000 (65.3455)  Acc@5: 87.5000 (88.2981)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.2745 (1.4935)  Acc@1: 68.7500 (65.3888)  Acc@5: 93.7500 (88.3067)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1] Total time: 0:05:57 (0.2196 s / it)
* Acc@1 65.389 Acc@5 88.307 loss 1.494
Test: [Task 2]  [  0/625]  eta: 0:06:37  Loss: 1.8810 (1.8810)  Acc@1: 37.5000 (37.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6360  data: 0.4071  max mem: 2503
Test: [Task 2]  [ 10/625]  eta: 0:02:38  Loss: 2.1467 (2.2248)  Acc@1: 31.2500 (30.6818)  Acc@5: 81.2500 (79.5455)  time: 0.2570  data: 0.0378  max mem: 2503
Test: [Task 2]  [ 20/625]  eta: 0:02:24  Loss: 2.0283 (2.1116)  Acc@1: 31.2500 (33.0357)  Acc@5: 81.2500 (80.9524)  time: 0.2197  data: 0.0009  max mem: 2503
Test: [Task 2]  [ 30/625]  eta: 0:02:18  Loss: 1.9697 (2.0661)  Acc@1: 37.5000 (35.2823)  Acc@5: 81.2500 (82.6613)  time: 0.2191  data: 0.0007  max mem: 2503
Test: [Task 2]  [ 40/625]  eta: 0:02:14  Loss: 2.0247 (2.0744)  Acc@1: 37.5000 (35.5183)  Acc@5: 81.2500 (83.0793)  time: 0.2192  data: 0.0012  max mem: 2503
Test: [Task 2]  [ 50/625]  eta: 0:02:10  Loss: 2.1937 (2.1126)  Acc@1: 37.5000 (35.4167)  Acc@5: 81.2500 (81.6176)  time: 0.2195  data: 0.0011  max mem: 2503
Test: [Task 2]  [ 60/625]  eta: 0:02:07  Loss: 2.2191 (2.1156)  Acc@1: 37.5000 (35.4508)  Acc@5: 75.0000 (81.5574)  time: 0.2192  data: 0.0010  max mem: 2503
Test: [Task 2]  [ 70/625]  eta: 0:02:04  Loss: 2.0576 (2.1060)  Acc@1: 31.2500 (35.2993)  Acc@5: 87.5000 (82.3944)  time: 0.2190  data: 0.0010  max mem: 2503
Test: [Task 2]  [ 80/625]  eta: 0:02:02  Loss: 2.0576 (2.1100)  Acc@1: 31.2500 (35.2623)  Acc@5: 87.5000 (82.2531)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 2.1791 (2.1178)  Acc@1: 31.2500 (34.6841)  Acc@5: 81.2500 (82.2802)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 2]  [100/625]  eta: 0:01:57  Loss: 2.1575 (2.1264)  Acc@1: 31.2500 (34.5297)  Acc@5: 81.2500 (82.1163)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 2.0236 (2.1157)  Acc@1: 31.2500 (34.6284)  Acc@5: 81.2500 (82.2072)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 2]  [120/625]  eta: 0:01:52  Loss: 2.0236 (2.1079)  Acc@1: 31.2500 (34.5041)  Acc@5: 87.5000 (82.4380)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 2]  [130/625]  eta: 0:01:50  Loss: 2.1566 (2.1190)  Acc@1: 31.2500 (33.9218)  Acc@5: 81.2500 (82.3950)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 2.1912 (2.1225)  Acc@1: 31.2500 (33.8652)  Acc@5: 81.2500 (82.2252)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 2.1778 (2.1273)  Acc@1: 31.2500 (33.8576)  Acc@5: 75.0000 (81.9536)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 2]  [160/625]  eta: 0:01:43  Loss: 2.1270 (2.1257)  Acc@1: 31.2500 (33.8509)  Acc@5: 75.0000 (81.9876)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 2.0946 (2.1220)  Acc@1: 31.2500 (34.0643)  Acc@5: 81.2500 (82.1272)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 2.1462 (2.1235)  Acc@1: 31.2500 (34.0815)  Acc@5: 81.2500 (82.1133)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 2]  [190/625]  eta: 0:01:36  Loss: 2.2036 (2.1278)  Acc@1: 31.2500 (33.9332)  Acc@5: 75.0000 (81.9699)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 2]  [200/625]  eta: 0:01:34  Loss: 2.1896 (2.1294)  Acc@1: 31.2500 (33.6443)  Acc@5: 81.2500 (82.1828)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 2.1966 (2.1315)  Acc@1: 31.2500 (33.5308)  Acc@5: 87.5000 (82.1386)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 2.1966 (2.1322)  Acc@1: 31.2500 (33.3710)  Acc@5: 87.5000 (82.2681)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 2]  [230/625]  eta: 0:01:27  Loss: 2.0651 (2.1266)  Acc@1: 31.2500 (33.4957)  Acc@5: 87.5000 (82.3593)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 2]  [240/625]  eta: 0:01:25  Loss: 2.1077 (2.1288)  Acc@1: 31.2500 (33.4544)  Acc@5: 81.2500 (82.3133)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 2.1044 (2.1230)  Acc@1: 31.2500 (33.6155)  Acc@5: 81.2500 (82.2460)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 2.0525 (2.1205)  Acc@1: 37.5000 (33.5249)  Acc@5: 81.2500 (82.3276)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 2.0525 (2.1214)  Acc@1: 31.2500 (33.6024)  Acc@5: 81.2500 (82.1494)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 2]  [280/625]  eta: 0:01:16  Loss: 1.9965 (2.1209)  Acc@1: 31.2500 (33.5854)  Acc@5: 81.2500 (82.1397)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 2.1695 (2.1224)  Acc@1: 31.2500 (33.4622)  Acc@5: 81.2500 (82.1735)  time: 0.2207  data: 0.0004  max mem: 2503
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 2.2137 (2.1231)  Acc@1: 31.2500 (33.4510)  Acc@5: 81.2500 (82.1221)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 2.1671 (2.1240)  Acc@1: 31.2500 (33.4807)  Acc@5: 81.2500 (82.1744)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 1.9141 (2.1146)  Acc@1: 31.2500 (33.5475)  Acc@5: 87.5000 (82.5156)  time: 0.2179  data: 0.0004  max mem: 2503
Test: [Task 2]  [330/625]  eta: 0:01:05  Loss: 1.8783 (2.1069)  Acc@1: 31.2500 (33.4403)  Acc@5: 93.7500 (82.7795)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 1.5738 (2.0886)  Acc@1: 43.7500 (34.3109)  Acc@5: 93.7500 (83.1195)  time: 0.2197  data: 0.0009  max mem: 2503
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 1.4724 (2.0746)  Acc@1: 50.0000 (34.6688)  Acc@5: 93.7500 (83.4580)  time: 0.2194  data: 0.0009  max mem: 2503
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 1.7747 (2.0760)  Acc@1: 43.7500 (34.6087)  Acc@5: 87.5000 (83.5007)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 1.9770 (2.0697)  Acc@1: 37.5000 (34.7372)  Acc@5: 87.5000 (83.6759)  time: 0.2181  data: 0.0004  max mem: 2503
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 1.8322 (2.0681)  Acc@1: 50.0000 (34.9738)  Acc@5: 87.5000 (83.6286)  time: 0.2178  data: 0.0004  max mem: 2503
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 1.9005 (2.0659)  Acc@1: 37.5000 (34.9904)  Acc@5: 81.2500 (83.7276)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 1.7792 (2.0553)  Acc@1: 37.5000 (35.3335)  Acc@5: 93.7500 (83.9776)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 1.7749 (2.0553)  Acc@1: 37.5000 (35.2494)  Acc@5: 93.7500 (84.1089)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 2.0685 (2.0584)  Acc@1: 31.2500 (35.0505)  Acc@5: 87.5000 (84.1004)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 2.0717 (2.0533)  Acc@1: 31.2500 (35.3103)  Acc@5: 87.5000 (84.1502)  time: 0.2187  data: 0.0007  max mem: 2503
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 1.6379 (2.0446)  Acc@1: 43.7500 (35.5584)  Acc@5: 93.7500 (84.3679)  time: 0.2182  data: 0.0007  max mem: 2503
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 1.7919 (2.0425)  Acc@1: 43.7500 (35.4906)  Acc@5: 93.7500 (84.5482)  time: 0.2180  data: 0.0008  max mem: 2503
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 1.9723 (2.0392)  Acc@1: 37.5000 (35.5884)  Acc@5: 87.5000 (84.6123)  time: 0.2183  data: 0.0008  max mem: 2503
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 2.0503 (2.0470)  Acc@1: 31.2500 (35.3503)  Acc@5: 81.2500 (84.4878)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 2.0801 (2.0459)  Acc@1: 25.0000 (35.2781)  Acc@5: 81.2500 (84.5374)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 1.8369 (2.0400)  Acc@1: 37.5000 (35.5143)  Acc@5: 87.5000 (84.6614)  time: 0.2176  data: 0.0003  max mem: 2503
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 1.9334 (2.0402)  Acc@1: 37.5000 (35.6038)  Acc@5: 87.5000 (84.5933)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 2.0728 (2.0419)  Acc@1: 31.2500 (35.5920)  Acc@5: 81.2500 (84.5646)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 2.3742 (2.0553)  Acc@1: 25.0000 (35.1967)  Acc@5: 81.2500 (84.3690)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 2.4811 (2.0599)  Acc@1: 18.7500 (35.0518)  Acc@5: 75.0000 (84.3338)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 1.9580 (2.0569)  Acc@1: 37.5000 (35.1895)  Acc@5: 81.2500 (84.2999)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.6064 (2.0467)  Acc@1: 50.0000 (35.5830)  Acc@5: 93.7500 (84.5054)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 1.5338 (2.0420)  Acc@1: 50.0000 (35.6506)  Acc@5: 93.7500 (84.6702)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 1.8483 (2.0433)  Acc@1: 31.2500 (35.5626)  Acc@5: 93.7500 (84.7088)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 1.9410 (2.0394)  Acc@1: 25.0000 (35.5314)  Acc@5: 93.7500 (84.8537)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.6036 (2.0317)  Acc@1: 43.7500 (35.7974)  Acc@5: 93.7500 (84.9831)  time: 0.2177  data: 0.0003  max mem: 2503
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.8196 (2.0376)  Acc@1: 37.5000 (35.6177)  Acc@5: 87.5000 (84.9210)  time: 0.2171  data: 0.0003  max mem: 2503
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.4526 (2.0486)  Acc@1: 18.7500 (35.3417)  Acc@5: 75.0000 (84.6768)  time: 0.2177  data: 0.0009  max mem: 2503
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 2.2566 (2.0472)  Acc@1: 25.0000 (35.3462)  Acc@5: 81.2500 (84.7625)  time: 0.2181  data: 0.0009  max mem: 2503
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 2.1992 (2.0482)  Acc@1: 31.2500 (35.2800)  Acc@5: 87.5000 (84.7600)  time: 0.2182  data: 0.0009  max mem: 2503
Test: [Task 2] Total time: 0:02:17 (0.2197 s / it)
* Acc@1 35.280 Acc@5 84.760 loss 2.048
Test: [Task 3]  [  0/625]  eta: 0:06:45  Loss: 0.2871 (0.2871)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6485  data: 0.4287  max mem: 2503
Test: [Task 3]  [ 10/625]  eta: 0:02:37  Loss: 0.3017 (0.3322)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (98.2955)  time: 0.2559  data: 0.0393  max mem: 2503
Test: [Task 3]  [ 20/625]  eta: 0:02:24  Loss: 0.3017 (0.3530)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (98.2143)  time: 0.2181  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 30/625]  eta: 0:02:18  Loss: 0.2558 (0.3340)  Acc@1: 100.0000 (95.9677)  Acc@5: 100.0000 (98.7903)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 40/625]  eta: 0:02:13  Loss: 0.2051 (0.3003)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.0854)  time: 0.2175  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 50/625]  eta: 0:02:10  Loss: 0.2051 (0.2950)  Acc@1: 100.0000 (96.2010)  Acc@5: 100.0000 (99.0196)  time: 0.2170  data: 0.0003  max mem: 2503
Test: [Task 3]  [ 60/625]  eta: 0:02:06  Loss: 0.2899 (0.2919)  Acc@1: 93.7500 (96.1066)  Acc@5: 100.0000 (99.0779)  time: 0.2170  data: 0.0003  max mem: 2503
Test: [Task 3]  [ 70/625]  eta: 0:02:04  Loss: 0.1961 (0.2813)  Acc@1: 93.7500 (96.1268)  Acc@5: 100.0000 (99.2077)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 3]  [ 80/625]  eta: 0:02:01  Loss: 0.2060 (0.2834)  Acc@1: 93.7500 (96.0648)  Acc@5: 100.0000 (99.2284)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 3]  [ 90/625]  eta: 0:01:59  Loss: 0.2060 (0.2839)  Acc@1: 100.0000 (96.2225)  Acc@5: 100.0000 (99.2445)  time: 0.2181  data: 0.0006  max mem: 2503
Test: [Task 3]  [100/625]  eta: 0:01:56  Loss: 0.2186 (0.2808)  Acc@1: 100.0000 (96.3490)  Acc@5: 100.0000 (99.2574)  time: 0.2190  data: 0.0014  max mem: 2503
Test: [Task 3]  [110/625]  eta: 0:01:54  Loss: 0.1955 (0.2739)  Acc@1: 100.0000 (96.5653)  Acc@5: 100.0000 (99.3243)  time: 0.2180  data: 0.0011  max mem: 2503
Test: [Task 3]  [120/625]  eta: 0:01:51  Loss: 0.2216 (0.2753)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.2769)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 3]  [130/625]  eta: 0:01:49  Loss: 0.2611 (0.2771)  Acc@1: 100.0000 (96.5172)  Acc@5: 100.0000 (99.3321)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 3]  [140/625]  eta: 0:01:47  Loss: 0.3148 (0.2838)  Acc@1: 93.7500 (96.4096)  Acc@5: 100.0000 (99.1578)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 3]  [150/625]  eta: 0:01:44  Loss: 0.3128 (0.2896)  Acc@1: 93.7500 (96.3576)  Acc@5: 100.0000 (99.1308)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 3]  [160/625]  eta: 0:01:42  Loss: 0.2946 (0.2909)  Acc@1: 100.0000 (96.3509)  Acc@5: 100.0000 (99.0683)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 3]  [170/625]  eta: 0:01:40  Loss: 0.2259 (0.2892)  Acc@1: 100.0000 (96.4181)  Acc@5: 100.0000 (99.1228)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 3]  [180/625]  eta: 0:01:38  Loss: 0.2602 (0.2904)  Acc@1: 93.7500 (96.3743)  Acc@5: 100.0000 (99.1022)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 3]  [190/625]  eta: 0:01:35  Loss: 0.2784 (0.2888)  Acc@1: 93.7500 (96.4332)  Acc@5: 100.0000 (99.1492)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 3]  [200/625]  eta: 0:01:33  Loss: 0.2784 (0.2907)  Acc@1: 93.7500 (96.3308)  Acc@5: 100.0000 (99.1294)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 3]  [210/625]  eta: 0:01:31  Loss: 0.2567 (0.2899)  Acc@1: 100.0000 (96.4159)  Acc@5: 100.0000 (99.1410)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 3]  [220/625]  eta: 0:01:29  Loss: 0.3012 (0.2941)  Acc@1: 100.0000 (96.2952)  Acc@5: 100.0000 (99.1233)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [230/625]  eta: 0:01:27  Loss: 0.3310 (0.2938)  Acc@1: 93.7500 (96.3474)  Acc@5: 100.0000 (99.1342)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 3]  [240/625]  eta: 0:01:24  Loss: 0.2414 (0.2969)  Acc@1: 93.7500 (96.2396)  Acc@5: 100.0000 (99.1442)  time: 0.2204  data: 0.0006  max mem: 2503
Test: [Task 3]  [250/625]  eta: 0:01:22  Loss: 0.2240 (0.2944)  Acc@1: 93.7500 (96.3147)  Acc@5: 100.0000 (99.1534)  time: 0.2197  data: 0.0006  max mem: 2503
Test: [Task 3]  [260/625]  eta: 0:01:20  Loss: 0.2117 (0.2940)  Acc@1: 100.0000 (96.2883)  Acc@5: 100.0000 (99.1619)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.2537 (0.2918)  Acc@1: 100.0000 (96.3330)  Acc@5: 100.0000 (99.1928)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 3]  [280/625]  eta: 0:01:15  Loss: 0.2537 (0.2915)  Acc@1: 100.0000 (96.3746)  Acc@5: 100.0000 (99.2215)  time: 0.2196  data: 0.0005  max mem: 2503
Test: [Task 3]  [290/625]  eta: 0:01:13  Loss: 0.2875 (0.2907)  Acc@1: 93.7500 (96.3703)  Acc@5: 100.0000 (99.2483)  time: 0.2194  data: 0.0005  max mem: 2503
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.2501 (0.2912)  Acc@1: 93.7500 (96.3663)  Acc@5: 100.0000 (99.2525)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 3]  [310/625]  eta: 0:01:09  Loss: 0.2354 (0.2930)  Acc@1: 93.7500 (96.2822)  Acc@5: 100.0000 (99.1760)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.1732 (0.2904)  Acc@1: 93.7500 (96.3201)  Acc@5: 100.0000 (99.2017)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 3]  [330/625]  eta: 0:01:04  Loss: 0.2285 (0.2911)  Acc@1: 93.7500 (96.2991)  Acc@5: 100.0000 (99.2258)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 3]  [340/625]  eta: 0:01:02  Loss: 0.2575 (0.2888)  Acc@1: 100.0000 (96.3710)  Acc@5: 100.0000 (99.2485)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.2326 (0.2888)  Acc@1: 100.0000 (96.3141)  Acc@5: 100.0000 (99.2343)  time: 0.2197  data: 0.0003  max mem: 2503
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.2976 (0.2914)  Acc@1: 93.7500 (96.2084)  Acc@5: 100.0000 (99.2036)  time: 0.2206  data: 0.0007  max mem: 2503
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.2762 (0.2925)  Acc@1: 93.7500 (96.1253)  Acc@5: 100.0000 (99.2082)  time: 0.2204  data: 0.0010  max mem: 2503
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.2353 (0.2913)  Acc@1: 93.7500 (96.1614)  Acc@5: 100.0000 (99.2290)  time: 0.2209  data: 0.0008  max mem: 2503
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.2127 (0.2908)  Acc@1: 100.0000 (96.1637)  Acc@5: 100.0000 (99.2168)  time: 0.2207  data: 0.0005  max mem: 2503
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.2147 (0.2895)  Acc@1: 93.7500 (96.1658)  Acc@5: 100.0000 (99.2363)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.2929 (0.2912)  Acc@1: 93.7500 (96.1375)  Acc@5: 100.0000 (99.2397)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 3]  [420/625]  eta: 0:00:45  Loss: 0.3114 (0.2919)  Acc@1: 100.0000 (96.1401)  Acc@5: 100.0000 (99.2429)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.2784 (0.2921)  Acc@1: 93.7500 (96.1282)  Acc@5: 100.0000 (99.2459)  time: 0.2199  data: 0.0003  max mem: 2503
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.3265 (0.2940)  Acc@1: 93.7500 (96.0884)  Acc@5: 100.0000 (99.2347)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.2675 (0.2941)  Acc@1: 93.7500 (96.0643)  Acc@5: 100.0000 (99.2378)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.2333 (0.2930)  Acc@1: 100.0000 (96.0954)  Acc@5: 100.0000 (99.2408)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.2333 (0.2935)  Acc@1: 93.7500 (96.0058)  Acc@5: 100.0000 (99.2436)  time: 0.2192  data: 0.0005  max mem: 2503
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.2755 (0.2939)  Acc@1: 93.7500 (95.9849)  Acc@5: 100.0000 (99.2334)  time: 0.2187  data: 0.0005  max mem: 2503
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2914 (0.2941)  Acc@1: 93.7500 (95.9649)  Acc@5: 100.0000 (99.2108)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2444 (0.2936)  Acc@1: 93.7500 (95.9331)  Acc@5: 100.0000 (99.2265)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.2408 (0.2933)  Acc@1: 93.7500 (95.9516)  Acc@5: 100.0000 (99.2417)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.2611 (0.2944)  Acc@1: 93.7500 (95.9213)  Acc@5: 100.0000 (99.2442)  time: 0.2182  data: 0.0005  max mem: 2503
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.3489 (0.2960)  Acc@1: 93.7500 (95.8686)  Acc@5: 100.0000 (99.2232)  time: 0.2185  data: 0.0005  max mem: 2503
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2949 (0.2972)  Acc@1: 93.7500 (95.8526)  Acc@5: 100.0000 (99.2029)  time: 0.2193  data: 0.0007  max mem: 2503
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2949 (0.2977)  Acc@1: 93.7500 (95.8371)  Acc@5: 100.0000 (99.1833)  time: 0.2191  data: 0.0007  max mem: 2503
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2586 (0.2977)  Acc@1: 93.7500 (95.8668)  Acc@5: 100.0000 (99.1756)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.2586 (0.2982)  Acc@1: 100.0000 (95.8625)  Acc@5: 100.0000 (99.1681)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2685 (0.3002)  Acc@1: 93.7500 (95.8262)  Acc@5: 100.0000 (99.1502)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.2627 (0.2992)  Acc@1: 100.0000 (95.8651)  Acc@5: 100.0000 (99.1646)  time: 0.2204  data: 0.0005  max mem: 2503
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.2136 (0.2983)  Acc@1: 100.0000 (95.8715)  Acc@5: 100.0000 (99.1681)  time: 0.2204  data: 0.0005  max mem: 2503
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.2136 (0.2974)  Acc@1: 100.0000 (95.8879)  Acc@5: 100.0000 (99.1817)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2587 (0.2989)  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (99.1848)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.2446 (0.2985)  Acc@1: 93.7500 (95.8400)  Acc@5: 100.0000 (99.1900)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 3] Total time: 0:02:17 (0.2200 s / it)
* Acc@1 95.840 Acc@5 99.190 loss 0.298
Test: [Task 4]  [ 0/29]  eta: 0:00:17  Loss: 2.4274 (2.4274)  Acc@1: 37.5000 (37.5000)  Acc@5: 75.0000 (75.0000)  time: 0.6134  data: 0.3923  max mem: 2503
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 2.6130 (2.3545)  Acc@1: 31.2500 (34.0909)  Acc@5: 68.7500 (75.5682)  time: 0.2561  data: 0.0360  max mem: 2503
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 2.6980 (2.7269)  Acc@1: 25.0000 (28.8690)  Acc@5: 62.5000 (59.8214)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 3.0533 (2.6599)  Acc@1: 18.7500 (30.9368)  Acc@5: 43.7500 (57.7342)  time: 0.2153  data: 0.0003  max mem: 2503
Test: [Task 4] Total time: 0:00:06 (0.2373 s / it)
* Acc@1 30.937 Acc@5 57.734 loss 2.660
Test: [Task 5]  [  0/625]  eta: 0:06:45  Loss: 0.2968 (0.2968)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6491  data: 0.4317  max mem: 2503
Test: [Task 5]  [ 10/625]  eta: 0:02:38  Loss: 0.5497 (0.5993)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (99.4318)  time: 0.2575  data: 0.0395  max mem: 2503
Test: [Task 5]  [ 20/625]  eta: 0:02:24  Loss: 0.4831 (0.5504)  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (99.4048)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 30/625]  eta: 0:02:18  Loss: 0.5599 (0.5767)  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (99.3952)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 40/625]  eta: 0:02:14  Loss: 0.6502 (0.5677)  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (98.9329)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 50/625]  eta: 0:02:10  Loss: 0.6180 (0.5816)  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (98.6520)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 60/625]  eta: 0:02:07  Loss: 0.5376 (0.5709)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6680)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 70/625]  eta: 0:02:05  Loss: 0.4955 (0.5714)  Acc@1: 87.5000 (87.2359)  Acc@5: 100.0000 (98.6796)  time: 0.2202  data: 0.0005  max mem: 2503
Test: [Task 5]  [ 80/625]  eta: 0:02:02  Loss: 0.6151 (0.5873)  Acc@1: 87.5000 (86.4969)  Acc@5: 100.0000 (98.5340)  time: 0.2205  data: 0.0013  max mem: 2503
Test: [Task 5]  [ 90/625]  eta: 0:01:59  Loss: 0.5171 (0.5755)  Acc@1: 87.5000 (86.7445)  Acc@5: 100.0000 (98.5577)  time: 0.2197  data: 0.0011  max mem: 2503
Test: [Task 5]  [100/625]  eta: 0:01:57  Loss: 0.5019 (0.5821)  Acc@1: 87.5000 (86.6337)  Acc@5: 100.0000 (98.4530)  time: 0.2201  data: 0.0005  max mem: 2503
Test: [Task 5]  [110/625]  eta: 0:01:55  Loss: 0.5576 (0.5806)  Acc@1: 87.5000 (86.8243)  Acc@5: 100.0000 (98.5360)  time: 0.2202  data: 0.0005  max mem: 2503
Test: [Task 5]  [120/625]  eta: 0:01:52  Loss: 0.4732 (0.5711)  Acc@1: 87.5000 (86.9835)  Acc@5: 100.0000 (98.5537)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [130/625]  eta: 0:01:50  Loss: 0.5212 (0.5745)  Acc@1: 87.5000 (86.7366)  Acc@5: 100.0000 (98.5210)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 5]  [140/625]  eta: 0:01:47  Loss: 0.5929 (0.5732)  Acc@1: 81.2500 (86.7021)  Acc@5: 100.0000 (98.4929)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 5]  [150/625]  eta: 0:01:45  Loss: 0.5924 (0.5739)  Acc@1: 87.5000 (86.6308)  Acc@5: 100.0000 (98.5099)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 5]  [160/625]  eta: 0:01:43  Loss: 0.7013 (0.5804)  Acc@1: 87.5000 (86.6460)  Acc@5: 100.0000 (98.4084)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 5]  [170/625]  eta: 0:01:40  Loss: 0.6413 (0.5869)  Acc@1: 81.2500 (86.3304)  Acc@5: 100.0000 (98.3187)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 5]  [180/625]  eta: 0:01:38  Loss: 0.6076 (0.5864)  Acc@1: 87.5000 (86.4641)  Acc@5: 100.0000 (98.3425)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 5]  [190/625]  eta: 0:01:36  Loss: 0.6499 (0.5965)  Acc@1: 87.5000 (86.1584)  Acc@5: 100.0000 (98.2003)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 5]  [200/625]  eta: 0:01:34  Loss: 0.5884 (0.5927)  Acc@1: 87.5000 (86.3495)  Acc@5: 100.0000 (98.2276)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 5]  [210/625]  eta: 0:01:31  Loss: 0.5418 (0.5975)  Acc@1: 87.5000 (86.1967)  Acc@5: 100.0000 (98.1043)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 5]  [220/625]  eta: 0:01:29  Loss: 0.7046 (0.5979)  Acc@1: 81.2500 (86.1425)  Acc@5: 100.0000 (98.0769)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 5]  [230/625]  eta: 0:01:27  Loss: 0.5347 (0.5969)  Acc@1: 87.5000 (86.1742)  Acc@5: 100.0000 (98.0790)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [240/625]  eta: 0:01:25  Loss: 0.5692 (0.6003)  Acc@1: 87.5000 (86.0218)  Acc@5: 100.0000 (98.0290)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [250/625]  eta: 0:01:22  Loss: 0.6549 (0.6025)  Acc@1: 81.2500 (85.9313)  Acc@5: 100.0000 (97.9831)  time: 0.2187  data: 0.0004  max mem: 2503
Test: [Task 5]  [260/625]  eta: 0:01:20  Loss: 0.6596 (0.6066)  Acc@1: 81.2500 (85.7040)  Acc@5: 93.7500 (97.9167)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 5]  [270/625]  eta: 0:01:18  Loss: 0.5797 (0.6050)  Acc@1: 81.2500 (85.7242)  Acc@5: 100.0000 (97.9474)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 5]  [280/625]  eta: 0:01:16  Loss: 0.5509 (0.6035)  Acc@1: 87.5000 (85.7651)  Acc@5: 100.0000 (97.9760)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 5]  [290/625]  eta: 0:01:13  Loss: 0.4799 (0.6027)  Acc@1: 87.5000 (85.8247)  Acc@5: 100.0000 (97.9811)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 5]  [300/625]  eta: 0:01:11  Loss: 0.5252 (0.6055)  Acc@1: 81.2500 (85.7143)  Acc@5: 100.0000 (97.9859)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 5]  [310/625]  eta: 0:01:09  Loss: 0.6844 (0.6065)  Acc@1: 81.2500 (85.5908)  Acc@5: 100.0000 (97.9502)  time: 0.2192  data: 0.0005  max mem: 2503
Test: [Task 5]  [320/625]  eta: 0:01:07  Loss: 0.7099 (0.6085)  Acc@1: 87.5000 (85.6698)  Acc@5: 100.0000 (97.9361)  time: 0.2186  data: 0.0005  max mem: 2503
Test: [Task 5]  [330/625]  eta: 0:01:05  Loss: 0.5636 (0.6083)  Acc@1: 87.5000 (85.7062)  Acc@5: 100.0000 (97.9418)  time: 0.2178  data: 0.0005  max mem: 2503
Test: [Task 5]  [340/625]  eta: 0:01:02  Loss: 0.4990 (0.6046)  Acc@1: 87.5000 (85.8138)  Acc@5: 100.0000 (97.9655)  time: 0.2178  data: 0.0005  max mem: 2503
Test: [Task 5]  [350/625]  eta: 0:01:00  Loss: 0.6587 (0.6107)  Acc@1: 81.2500 (85.6125)  Acc@5: 100.0000 (97.9345)  time: 0.2178  data: 0.0004  max mem: 2503
Test: [Task 5]  [360/625]  eta: 0:00:58  Loss: 0.6587 (0.6080)  Acc@1: 81.2500 (85.6821)  Acc@5: 100.0000 (97.9398)  time: 0.2181  data: 0.0004  max mem: 2503
Test: [Task 5]  [370/625]  eta: 0:00:56  Loss: 0.5119 (0.6058)  Acc@1: 87.5000 (85.7648)  Acc@5: 100.0000 (97.9784)  time: 0.2185  data: 0.0005  max mem: 2503
Test: [Task 5]  [380/625]  eta: 0:00:53  Loss: 0.6192 (0.6072)  Acc@1: 87.5000 (85.6955)  Acc@5: 100.0000 (97.9659)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 5]  [390/625]  eta: 0:00:51  Loss: 0.6277 (0.6091)  Acc@1: 81.2500 (85.5499)  Acc@5: 100.0000 (97.9699)  time: 0.2177  data: 0.0003  max mem: 2503
Test: [Task 5]  [400/625]  eta: 0:00:49  Loss: 0.5485 (0.6074)  Acc@1: 81.2500 (85.6297)  Acc@5: 100.0000 (98.0050)  time: 0.2176  data: 0.0004  max mem: 2503
Test: [Task 5]  [410/625]  eta: 0:00:47  Loss: 0.4870 (0.6068)  Acc@1: 87.5000 (85.6904)  Acc@5: 100.0000 (97.9927)  time: 0.2179  data: 0.0004  max mem: 2503
Test: [Task 5]  [420/625]  eta: 0:00:45  Loss: 0.5256 (0.6057)  Acc@1: 87.5000 (85.7185)  Acc@5: 100.0000 (97.9958)  time: 0.2181  data: 0.0004  max mem: 2503
Test: [Task 5]  [430/625]  eta: 0:00:42  Loss: 0.4851 (0.6028)  Acc@1: 87.5000 (85.7744)  Acc@5: 100.0000 (98.0133)  time: 0.2184  data: 0.0008  max mem: 2503
Test: [Task 5]  [440/625]  eta: 0:00:40  Loss: 0.5365 (0.6031)  Acc@1: 87.5000 (85.7001)  Acc@5: 100.0000 (98.0159)  time: 0.2181  data: 0.0007  max mem: 2503
Test: [Task 5]  [450/625]  eta: 0:00:38  Loss: 0.5763 (0.6012)  Acc@1: 87.5000 (85.7400)  Acc@5: 100.0000 (98.0460)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 5]  [460/625]  eta: 0:00:36  Loss: 0.5763 (0.6008)  Acc@1: 87.5000 (85.8053)  Acc@5: 100.0000 (98.0748)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 5]  [470/625]  eta: 0:00:34  Loss: 0.5344 (0.5975)  Acc@1: 87.5000 (85.9076)  Acc@5: 100.0000 (98.1157)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 5]  [480/625]  eta: 0:00:31  Loss: 0.4292 (0.5965)  Acc@1: 87.5000 (85.9148)  Acc@5: 100.0000 (98.1289)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 5]  [490/625]  eta: 0:00:29  Loss: 0.4638 (0.5956)  Acc@1: 87.5000 (85.9980)  Acc@5: 100.0000 (98.1161)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 5]  [500/625]  eta: 0:00:27  Loss: 0.5986 (0.5973)  Acc@1: 81.2500 (85.8782)  Acc@5: 100.0000 (98.0913)  time: 0.2186  data: 0.0010  max mem: 2503
Test: [Task 5]  [510/625]  eta: 0:00:25  Loss: 0.6740 (0.5978)  Acc@1: 81.2500 (85.8244)  Acc@5: 100.0000 (98.0920)  time: 0.2181  data: 0.0010  max mem: 2503
Test: [Task 5]  [520/625]  eta: 0:00:23  Loss: 0.6233 (0.5971)  Acc@1: 81.2500 (85.8085)  Acc@5: 100.0000 (98.0926)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 5]  [530/625]  eta: 0:00:20  Loss: 0.4822 (0.5947)  Acc@1: 87.5000 (85.8875)  Acc@5: 100.0000 (98.1050)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 5]  [540/625]  eta: 0:00:18  Loss: 0.4822 (0.5936)  Acc@1: 87.5000 (85.9519)  Acc@5: 100.0000 (98.0707)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 5]  [550/625]  eta: 0:00:16  Loss: 0.5346 (0.5938)  Acc@1: 87.5000 (85.9687)  Acc@5: 100.0000 (98.0603)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 5]  [560/625]  eta: 0:00:14  Loss: 0.5869 (0.5937)  Acc@1: 81.2500 (85.9626)  Acc@5: 100.0000 (98.0392)  time: 0.2197  data: 0.0010  max mem: 2503
Test: [Task 5]  [570/625]  eta: 0:00:12  Loss: 0.5032 (0.5922)  Acc@1: 87.5000 (86.0223)  Acc@5: 100.0000 (98.0517)  time: 0.2217  data: 0.0027  max mem: 2503
Test: [Task 5]  [580/625]  eta: 0:00:09  Loss: 0.5503 (0.5939)  Acc@1: 87.5000 (86.0155)  Acc@5: 100.0000 (98.0529)  time: 0.2206  data: 0.0021  max mem: 2503
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 0.6041 (0.5932)  Acc@1: 87.5000 (86.0300)  Acc@5: 100.0000 (98.0541)  time: 0.2197  data: 0.0006  max mem: 2503
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 0.5700 (0.5929)  Acc@1: 87.5000 (86.0545)  Acc@5: 100.0000 (98.0761)  time: 0.2194  data: 0.0006  max mem: 2503
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.5612 (0.5928)  Acc@1: 87.5000 (86.0577)  Acc@5: 100.0000 (98.0872)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.4986 (0.5917)  Acc@1: 87.5000 (86.1312)  Acc@5: 100.0000 (98.0878)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.5176 (0.5923)  Acc@1: 87.5000 (86.1000)  Acc@5: 100.0000 (98.0900)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 5] Total time: 0:02:17 (0.2198 s / it)
* Acc@1 86.100 Acc@5 98.090 loss 0.592
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 16, 5: 16, 6: 16, 7: 16, 8: 0, 9: 0, 10: 0, 11: 0, 12: 9984, 13: 9984, 14: 9984, 15: 9984, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 48, 5: 48, 6: 48, 7: 48, 8: 0, 9: 0, 10: 0, 11: 0, 12: 411, 13: 411, 14: 411, 15: 411, 16: 0, 17: 0, 18: 0, 19: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000}}
[Average accuracy till task5]	Acc@1: 62.7091	Acc@5: 85.6162	Loss: 1.4185	Forgetting: 17.8854	Backward: -17.8854
Total training time: 2:24:41
